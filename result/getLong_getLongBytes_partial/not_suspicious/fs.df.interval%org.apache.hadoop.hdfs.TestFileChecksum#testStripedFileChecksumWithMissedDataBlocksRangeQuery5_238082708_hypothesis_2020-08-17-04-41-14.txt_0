reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-29278098-172.17.0.6-1597639333928:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42590,DS-ef48cd24-5a7d-44e3-8db2-4506aa5753d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40821,DS-1fa5c3af-030e-4e91-95d4-6899f4c5dda8,DISK], DatanodeInfoWithStorage[127.0.0.1:37100,DS-71615b67-bbd1-4f7c-a5c5-f8bccd6e0d81,DISK], DatanodeInfoWithStorage[127.0.0.1:37807,DS-bbf04c11-7262-4948-9201-6a506936aad7,DISK], DatanodeInfoWithStorage[127.0.0.1:35532,DS-2bf752b4-8db3-46b6-857b-a151e7756159,DISK], DatanodeInfoWithStorage[127.0.0.1:34341,DS-5d735807-0e9c-448d-af14-6ca5b109741a,DISK], DatanodeInfoWithStorage[127.0.0.1:40598,DS-cb252df1-490f-4c38-8564-b7916549cec0,DISK], DatanodeInfoWithStorage[127.0.0.1:36035,DS-4550da88-e79f-4fb1-8b16-81e07f3514b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-29278098-172.17.0.6-1597639333928:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42590,DS-ef48cd24-5a7d-44e3-8db2-4506aa5753d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40821,DS-1fa5c3af-030e-4e91-95d4-6899f4c5dda8,DISK], DatanodeInfoWithStorage[127.0.0.1:37100,DS-71615b67-bbd1-4f7c-a5c5-f8bccd6e0d81,DISK], DatanodeInfoWithStorage[127.0.0.1:37807,DS-bbf04c11-7262-4948-9201-6a506936aad7,DISK], DatanodeInfoWithStorage[127.0.0.1:35532,DS-2bf752b4-8db3-46b6-857b-a151e7756159,DISK], DatanodeInfoWithStorage[127.0.0.1:34341,DS-5d735807-0e9c-448d-af14-6ca5b109741a,DISK], DatanodeInfoWithStorage[127.0.0.1:40598,DS-cb252df1-490f-4c38-8564-b7916549cec0,DISK], DatanodeInfoWithStorage[127.0.0.1:36035,DS-4550da88-e79f-4fb1-8b16-81e07f3514b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1416592515-172.17.0.6-1597639987065:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35825,DS-9f0c2906-a31c-41b0-9a05-567793c8c7f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41909,DS-7f209388-c5ab-4c4b-8f0e-dd989f51223d,DISK], DatanodeInfoWithStorage[127.0.0.1:35071,DS-b3278d52-08aa-4de7-9dc5-9cbe74ee6501,DISK], DatanodeInfoWithStorage[127.0.0.1:38217,DS-8b10fd52-5f97-46b8-a5f1-fd4352567a75,DISK], DatanodeInfoWithStorage[127.0.0.1:38015,DS-785e7e09-b67d-48c7-ae51-9637f7aa13d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33103,DS-a9f2b76d-3edd-45ed-81cb-85aec0466d07,DISK], DatanodeInfoWithStorage[127.0.0.1:41794,DS-be226df5-c450-45e4-a89d-69440d3e5a62,DISK], DatanodeInfoWithStorage[127.0.0.1:37873,DS-fb159e5a-f99a-40bb-ba9c-47b000d42bb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1416592515-172.17.0.6-1597639987065:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35825,DS-9f0c2906-a31c-41b0-9a05-567793c8c7f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41909,DS-7f209388-c5ab-4c4b-8f0e-dd989f51223d,DISK], DatanodeInfoWithStorage[127.0.0.1:35071,DS-b3278d52-08aa-4de7-9dc5-9cbe74ee6501,DISK], DatanodeInfoWithStorage[127.0.0.1:38217,DS-8b10fd52-5f97-46b8-a5f1-fd4352567a75,DISK], DatanodeInfoWithStorage[127.0.0.1:38015,DS-785e7e09-b67d-48c7-ae51-9637f7aa13d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33103,DS-a9f2b76d-3edd-45ed-81cb-85aec0466d07,DISK], DatanodeInfoWithStorage[127.0.0.1:41794,DS-be226df5-c450-45e4-a89d-69440d3e5a62,DISK], DatanodeInfoWithStorage[127.0.0.1:37873,DS-fb159e5a-f99a-40bb-ba9c-47b000d42bb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-839866700-172.17.0.6-1597640972666:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39241,DS-45aa5f6e-b863-4ac8-919c-3d9f14dc28ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43429,DS-4d56dd98-c3d0-4e04-b5c1-024b1544c674,DISK], DatanodeInfoWithStorage[127.0.0.1:35443,DS-a9948074-2515-45ad-ad47-99a595b4d874,DISK], DatanodeInfoWithStorage[127.0.0.1:32982,DS-b8ade5da-8843-4255-9dfa-bb9d05fa7927,DISK], DatanodeInfoWithStorage[127.0.0.1:33690,DS-540704aa-504b-4843-bd1e-27f520ecee20,DISK], DatanodeInfoWithStorage[127.0.0.1:39288,DS-89b1ebcc-8e58-49f8-a7a5-c8462f1f6064,DISK], DatanodeInfoWithStorage[127.0.0.1:34219,DS-2aba0693-41b6-4510-9903-a35699b56824,DISK], DatanodeInfoWithStorage[127.0.0.1:45679,DS-29d6f761-fb75-4ffe-a911-fea397b5eed5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-839866700-172.17.0.6-1597640972666:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39241,DS-45aa5f6e-b863-4ac8-919c-3d9f14dc28ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43429,DS-4d56dd98-c3d0-4e04-b5c1-024b1544c674,DISK], DatanodeInfoWithStorage[127.0.0.1:35443,DS-a9948074-2515-45ad-ad47-99a595b4d874,DISK], DatanodeInfoWithStorage[127.0.0.1:32982,DS-b8ade5da-8843-4255-9dfa-bb9d05fa7927,DISK], DatanodeInfoWithStorage[127.0.0.1:33690,DS-540704aa-504b-4843-bd1e-27f520ecee20,DISK], DatanodeInfoWithStorage[127.0.0.1:39288,DS-89b1ebcc-8e58-49f8-a7a5-c8462f1f6064,DISK], DatanodeInfoWithStorage[127.0.0.1:34219,DS-2aba0693-41b6-4510-9903-a35699b56824,DISK], DatanodeInfoWithStorage[127.0.0.1:45679,DS-29d6f761-fb75-4ffe-a911-fea397b5eed5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-497945261-172.17.0.6-1597641354447:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41060,DS-f5aa25a0-0d67-4c99-a915-c91245a9f6ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43716,DS-44fdab8b-6db1-4287-8efb-22066713cf70,DISK], DatanodeInfoWithStorage[127.0.0.1:33018,DS-7b4dde9e-9766-4d3c-a443-a31b97db359c,DISK], DatanodeInfoWithStorage[127.0.0.1:33895,DS-effab52c-e105-4db1-ae34-a0d6f85c70b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36521,DS-8c542ff2-b3fa-4ab2-8dfd-6ad68aca5aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:33283,DS-048bcb05-3638-4f5e-afbd-81849d780be6,DISK], DatanodeInfoWithStorage[127.0.0.1:33261,DS-dc15ef82-e995-451f-8fc4-3b2d11f30c05,DISK], DatanodeInfoWithStorage[127.0.0.1:42430,DS-9974fdc3-76b1-465e-9fdf-20140a4a8214,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-497945261-172.17.0.6-1597641354447:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41060,DS-f5aa25a0-0d67-4c99-a915-c91245a9f6ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43716,DS-44fdab8b-6db1-4287-8efb-22066713cf70,DISK], DatanodeInfoWithStorage[127.0.0.1:33018,DS-7b4dde9e-9766-4d3c-a443-a31b97db359c,DISK], DatanodeInfoWithStorage[127.0.0.1:33895,DS-effab52c-e105-4db1-ae34-a0d6f85c70b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36521,DS-8c542ff2-b3fa-4ab2-8dfd-6ad68aca5aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:33283,DS-048bcb05-3638-4f5e-afbd-81849d780be6,DISK], DatanodeInfoWithStorage[127.0.0.1:33261,DS-dc15ef82-e995-451f-8fc4-3b2d11f30c05,DISK], DatanodeInfoWithStorage[127.0.0.1:42430,DS-9974fdc3-76b1-465e-9fdf-20140a4a8214,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1702288118-172.17.0.6-1597641615357:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37610,DS-b45ed41b-76b0-40b0-8659-cd4be45376d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39075,DS-5f400cd2-79f9-46cb-947b-7a389c172ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:36702,DS-a78b0b61-bd0e-4667-bda9-1c7af178e28b,DISK], DatanodeInfoWithStorage[127.0.0.1:44047,DS-35955732-ff58-486d-96da-9d228f64db09,DISK], DatanodeInfoWithStorage[127.0.0.1:37940,DS-1ebc813f-a05c-45c8-9968-96d5b641c32e,DISK], DatanodeInfoWithStorage[127.0.0.1:40382,DS-22045fd8-d6ca-4b96-9e50-6e417d0c5521,DISK], DatanodeInfoWithStorage[127.0.0.1:45585,DS-cb94a005-6fac-4eaf-a1ac-f9b80b0f236e,DISK], DatanodeInfoWithStorage[127.0.0.1:41754,DS-67f07f44-817f-4761-be3b-7bb749d43c4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1702288118-172.17.0.6-1597641615357:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37610,DS-b45ed41b-76b0-40b0-8659-cd4be45376d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39075,DS-5f400cd2-79f9-46cb-947b-7a389c172ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:36702,DS-a78b0b61-bd0e-4667-bda9-1c7af178e28b,DISK], DatanodeInfoWithStorage[127.0.0.1:44047,DS-35955732-ff58-486d-96da-9d228f64db09,DISK], DatanodeInfoWithStorage[127.0.0.1:37940,DS-1ebc813f-a05c-45c8-9968-96d5b641c32e,DISK], DatanodeInfoWithStorage[127.0.0.1:40382,DS-22045fd8-d6ca-4b96-9e50-6e417d0c5521,DISK], DatanodeInfoWithStorage[127.0.0.1:45585,DS-cb94a005-6fac-4eaf-a1ac-f9b80b0f236e,DISK], DatanodeInfoWithStorage[127.0.0.1:41754,DS-67f07f44-817f-4761-be3b-7bb749d43c4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2115299159-172.17.0.6-1597641794396:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45033,DS-bf1eda82-da64-4375-a758-b670273bb40a,DISK], DatanodeInfoWithStorage[127.0.0.1:33692,DS-71c9017c-320b-444f-8acf-4d043dac3bda,DISK], DatanodeInfoWithStorage[127.0.0.1:33388,DS-1fdaa966-55f0-4198-8e69-24eafe61dc4f,DISK], DatanodeInfoWithStorage[127.0.0.1:45131,DS-0f889719-7022-4818-859d-2ba18045135c,DISK], DatanodeInfoWithStorage[127.0.0.1:44053,DS-ce34e333-b913-46a2-b4b9-feb012a0eb18,DISK], DatanodeInfoWithStorage[127.0.0.1:34309,DS-83afc4cd-07cc-4b75-9f28-bfb5c85a1d23,DISK], DatanodeInfoWithStorage[127.0.0.1:44841,DS-27d9e121-6877-4f8a-9a9c-e1cff2ae4f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40343,DS-1c541b86-ccc8-428b-86bf-803000a97cdc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2115299159-172.17.0.6-1597641794396:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45033,DS-bf1eda82-da64-4375-a758-b670273bb40a,DISK], DatanodeInfoWithStorage[127.0.0.1:33692,DS-71c9017c-320b-444f-8acf-4d043dac3bda,DISK], DatanodeInfoWithStorage[127.0.0.1:33388,DS-1fdaa966-55f0-4198-8e69-24eafe61dc4f,DISK], DatanodeInfoWithStorage[127.0.0.1:45131,DS-0f889719-7022-4818-859d-2ba18045135c,DISK], DatanodeInfoWithStorage[127.0.0.1:44053,DS-ce34e333-b913-46a2-b4b9-feb012a0eb18,DISK], DatanodeInfoWithStorage[127.0.0.1:34309,DS-83afc4cd-07cc-4b75-9f28-bfb5c85a1d23,DISK], DatanodeInfoWithStorage[127.0.0.1:44841,DS-27d9e121-6877-4f8a-9a9c-e1cff2ae4f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40343,DS-1c541b86-ccc8-428b-86bf-803000a97cdc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-878791094-172.17.0.6-1597642028635:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38016,DS-6da49536-8f02-4a3c-b4d4-c2c7dc74116d,DISK], DatanodeInfoWithStorage[127.0.0.1:33522,DS-02442500-6bf2-4ec7-855c-cf555d3505ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39723,DS-083d59d2-bbc8-4cd4-880a-2656be060b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40093,DS-43f4daa8-7539-483a-a64a-27c4cb13ce61,DISK], DatanodeInfoWithStorage[127.0.0.1:38442,DS-684f1301-a361-4b72-a156-82c5053fdb65,DISK], DatanodeInfoWithStorage[127.0.0.1:43239,DS-6a7ae571-1846-4e3a-bc45-8e60500b0903,DISK], DatanodeInfoWithStorage[127.0.0.1:37997,DS-315f609b-f619-4699-bcd6-1c19145a6013,DISK], DatanodeInfoWithStorage[127.0.0.1:45843,DS-eadc86e2-b198-40dc-b4a5-84e767b17806,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-878791094-172.17.0.6-1597642028635:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38016,DS-6da49536-8f02-4a3c-b4d4-c2c7dc74116d,DISK], DatanodeInfoWithStorage[127.0.0.1:33522,DS-02442500-6bf2-4ec7-855c-cf555d3505ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39723,DS-083d59d2-bbc8-4cd4-880a-2656be060b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40093,DS-43f4daa8-7539-483a-a64a-27c4cb13ce61,DISK], DatanodeInfoWithStorage[127.0.0.1:38442,DS-684f1301-a361-4b72-a156-82c5053fdb65,DISK], DatanodeInfoWithStorage[127.0.0.1:43239,DS-6a7ae571-1846-4e3a-bc45-8e60500b0903,DISK], DatanodeInfoWithStorage[127.0.0.1:37997,DS-315f609b-f619-4699-bcd6-1c19145a6013,DISK], DatanodeInfoWithStorage[127.0.0.1:45843,DS-eadc86e2-b198-40dc-b4a5-84e767b17806,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-558659513-172.17.0.6-1597642218905:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45255,DS-e92efb41-6a40-44b8-b5da-6e37b7681fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:37948,DS-44329086-6862-41fa-a902-98cbca0cff5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37242,DS-de459575-abe2-4851-8c61-cdf6419cfac0,DISK], DatanodeInfoWithStorage[127.0.0.1:40190,DS-a2d23df9-dda5-497e-99b1-7973abc7edab,DISK], DatanodeInfoWithStorage[127.0.0.1:36824,DS-685ce3ac-2fbe-440b-9cb3-5545730219ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33764,DS-eaabaa9a-3ae8-4f16-991e-ef24b1bb133b,DISK], DatanodeInfoWithStorage[127.0.0.1:33940,DS-360b076d-b0b6-4d8a-a88e-7c883e2ab6f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44635,DS-5035c0a8-8048-4876-b86f-1e1325075c0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-558659513-172.17.0.6-1597642218905:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45255,DS-e92efb41-6a40-44b8-b5da-6e37b7681fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:37948,DS-44329086-6862-41fa-a902-98cbca0cff5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37242,DS-de459575-abe2-4851-8c61-cdf6419cfac0,DISK], DatanodeInfoWithStorage[127.0.0.1:40190,DS-a2d23df9-dda5-497e-99b1-7973abc7edab,DISK], DatanodeInfoWithStorage[127.0.0.1:36824,DS-685ce3ac-2fbe-440b-9cb3-5545730219ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33764,DS-eaabaa9a-3ae8-4f16-991e-ef24b1bb133b,DISK], DatanodeInfoWithStorage[127.0.0.1:33940,DS-360b076d-b0b6-4d8a-a88e-7c883e2ab6f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44635,DS-5035c0a8-8048-4876-b86f-1e1325075c0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-238865839-172.17.0.6-1597642259153:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44394,DS-79bba763-cbab-4076-ae16-03efc2ee79ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34920,DS-c514bdee-fd4a-4c4a-8ae3-8bc191b130c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33149,DS-e29ff0a8-3291-44f5-be8d-d0a0988b8bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:42131,DS-8568a0d5-809b-4b1b-90c5-97a47100c68d,DISK], DatanodeInfoWithStorage[127.0.0.1:37605,DS-dee4b47b-195f-40f5-b29e-a423fafd60fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37540,DS-85982dce-0192-4f6d-9605-364460de1e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:39909,DS-2438b2d8-7663-4d14-82cb-6b29e2266a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41850,DS-ca316362-3f8d-4652-918e-a2bc04ff0133,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-238865839-172.17.0.6-1597642259153:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44394,DS-79bba763-cbab-4076-ae16-03efc2ee79ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34920,DS-c514bdee-fd4a-4c4a-8ae3-8bc191b130c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33149,DS-e29ff0a8-3291-44f5-be8d-d0a0988b8bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:42131,DS-8568a0d5-809b-4b1b-90c5-97a47100c68d,DISK], DatanodeInfoWithStorage[127.0.0.1:37605,DS-dee4b47b-195f-40f5-b29e-a423fafd60fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37540,DS-85982dce-0192-4f6d-9605-364460de1e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:39909,DS-2438b2d8-7663-4d14-82cb-6b29e2266a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41850,DS-ca316362-3f8d-4652-918e-a2bc04ff0133,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1461938665-172.17.0.6-1597642298711:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38301,DS-e9b27d4f-73f2-4b1f-9e21-08910a983f37,DISK], DatanodeInfoWithStorage[127.0.0.1:34034,DS-0b5aaf1a-506d-48e5-8160-159496aca5be,DISK], DatanodeInfoWithStorage[127.0.0.1:36452,DS-e8ae5c54-9914-44fb-a746-85ae96845d41,DISK], DatanodeInfoWithStorage[127.0.0.1:33905,DS-1a2ecd04-cbd6-4349-99d8-909c8c246038,DISK], DatanodeInfoWithStorage[127.0.0.1:33021,DS-2987c1d9-b4ab-462c-9c22-b168a0974ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:45555,DS-7c17dc3a-7788-41fb-ad68-80f852b38762,DISK], DatanodeInfoWithStorage[127.0.0.1:44299,DS-11ec5179-a8c1-4d7b-a969-89f8e16d2455,DISK], DatanodeInfoWithStorage[127.0.0.1:35204,DS-14922168-2748-4673-a6f2-f8357cd2699c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1461938665-172.17.0.6-1597642298711:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38301,DS-e9b27d4f-73f2-4b1f-9e21-08910a983f37,DISK], DatanodeInfoWithStorage[127.0.0.1:34034,DS-0b5aaf1a-506d-48e5-8160-159496aca5be,DISK], DatanodeInfoWithStorage[127.0.0.1:36452,DS-e8ae5c54-9914-44fb-a746-85ae96845d41,DISK], DatanodeInfoWithStorage[127.0.0.1:33905,DS-1a2ecd04-cbd6-4349-99d8-909c8c246038,DISK], DatanodeInfoWithStorage[127.0.0.1:33021,DS-2987c1d9-b4ab-462c-9c22-b168a0974ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:45555,DS-7c17dc3a-7788-41fb-ad68-80f852b38762,DISK], DatanodeInfoWithStorage[127.0.0.1:44299,DS-11ec5179-a8c1-4d7b-a969-89f8e16d2455,DISK], DatanodeInfoWithStorage[127.0.0.1:35204,DS-14922168-2748-4673-a6f2-f8357cd2699c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1601458230-172.17.0.6-1597642604105:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41878,DS-1d2463b2-1a3a-47d4-b1f9-4bce92b0424f,DISK], DatanodeInfoWithStorage[127.0.0.1:43156,DS-17063647-7958-477d-9900-c0f05234674b,DISK], DatanodeInfoWithStorage[127.0.0.1:33292,DS-c05b6cbf-da74-45c2-aea9-99393bb328d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44016,DS-0a37a07b-3ed2-45b2-96ed-3d053382ae3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46055,DS-965f5b16-6e2b-4c9e-8dbe-d1f9bdcb15b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34189,DS-83521bd4-f188-4b98-9d6b-bc7f263a99bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40271,DS-2e886627-a1ba-4d4b-9dcd-adf700c94bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:45195,DS-d0aa3a95-6f1e-4eb5-84be-d70aff4f9c4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1601458230-172.17.0.6-1597642604105:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41878,DS-1d2463b2-1a3a-47d4-b1f9-4bce92b0424f,DISK], DatanodeInfoWithStorage[127.0.0.1:43156,DS-17063647-7958-477d-9900-c0f05234674b,DISK], DatanodeInfoWithStorage[127.0.0.1:33292,DS-c05b6cbf-da74-45c2-aea9-99393bb328d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44016,DS-0a37a07b-3ed2-45b2-96ed-3d053382ae3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46055,DS-965f5b16-6e2b-4c9e-8dbe-d1f9bdcb15b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34189,DS-83521bd4-f188-4b98-9d6b-bc7f263a99bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40271,DS-2e886627-a1ba-4d4b-9dcd-adf700c94bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:45195,DS-d0aa3a95-6f1e-4eb5-84be-d70aff4f9c4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-922928580-172.17.0.6-1597642639179:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46543,DS-c8e01605-d19c-4253-a759-e7249fbde6df,DISK], DatanodeInfoWithStorage[127.0.0.1:39076,DS-de069524-e077-47f2-84ac-903dcf631df9,DISK], DatanodeInfoWithStorage[127.0.0.1:41753,DS-7754c7f6-835c-4d49-88dd-f14d08072e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:40096,DS-606b71d2-0fa5-4aea-bbb1-136518a05bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:33022,DS-df6bc52a-574d-4747-92a0-ff23e300a128,DISK], DatanodeInfoWithStorage[127.0.0.1:39962,DS-758809ed-6653-4c27-92d0-7c2467a8b50c,DISK], DatanodeInfoWithStorage[127.0.0.1:45538,DS-7e204322-5b72-43a2-b4a4-3737b9e3b894,DISK], DatanodeInfoWithStorage[127.0.0.1:34704,DS-2f806800-8757-46d0-a5a7-c650a6704ed0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-922928580-172.17.0.6-1597642639179:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46543,DS-c8e01605-d19c-4253-a759-e7249fbde6df,DISK], DatanodeInfoWithStorage[127.0.0.1:39076,DS-de069524-e077-47f2-84ac-903dcf631df9,DISK], DatanodeInfoWithStorage[127.0.0.1:41753,DS-7754c7f6-835c-4d49-88dd-f14d08072e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:40096,DS-606b71d2-0fa5-4aea-bbb1-136518a05bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:33022,DS-df6bc52a-574d-4747-92a0-ff23e300a128,DISK], DatanodeInfoWithStorage[127.0.0.1:39962,DS-758809ed-6653-4c27-92d0-7c2467a8b50c,DISK], DatanodeInfoWithStorage[127.0.0.1:45538,DS-7e204322-5b72-43a2-b4a4-3737b9e3b894,DISK], DatanodeInfoWithStorage[127.0.0.1:34704,DS-2f806800-8757-46d0-a5a7-c650a6704ed0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-273404402-172.17.0.6-1597642678663:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35259,DS-04f979c3-53d7-4053-9865-4d7512c4a037,DISK], DatanodeInfoWithStorage[127.0.0.1:46090,DS-39c9b128-fd38-4384-badf-8e1328b98cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:39117,DS-838d8324-f70f-45ec-a79f-95f2e20f36d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33556,DS-3122e342-8d80-4cba-abe3-d864c106a171,DISK], DatanodeInfoWithStorage[127.0.0.1:42260,DS-b5461926-59f7-4b30-83bb-a2293aa1dd30,DISK], DatanodeInfoWithStorage[127.0.0.1:33381,DS-99cf2d12-276f-4210-b6ae-2319914c9bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:34638,DS-55ea5b51-1195-41f4-a8d9-3d47c09a488b,DISK], DatanodeInfoWithStorage[127.0.0.1:39826,DS-1da7a0c9-d02e-4be2-ac34-b44b3e936880,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-273404402-172.17.0.6-1597642678663:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35259,DS-04f979c3-53d7-4053-9865-4d7512c4a037,DISK], DatanodeInfoWithStorage[127.0.0.1:46090,DS-39c9b128-fd38-4384-badf-8e1328b98cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:39117,DS-838d8324-f70f-45ec-a79f-95f2e20f36d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33556,DS-3122e342-8d80-4cba-abe3-d864c106a171,DISK], DatanodeInfoWithStorage[127.0.0.1:42260,DS-b5461926-59f7-4b30-83bb-a2293aa1dd30,DISK], DatanodeInfoWithStorage[127.0.0.1:33381,DS-99cf2d12-276f-4210-b6ae-2319914c9bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:34638,DS-55ea5b51-1195-41f4-a8d9-3d47c09a488b,DISK], DatanodeInfoWithStorage[127.0.0.1:39826,DS-1da7a0c9-d02e-4be2-ac34-b44b3e936880,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1812364126-172.17.0.6-1597642821214:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39734,DS-dc84622a-756e-43bd-a766-f2f77492fc9e,DISK], DatanodeInfoWithStorage[127.0.0.1:33976,DS-08f971c6-4a05-4e5d-9bbc-6f9cf0976022,DISK], DatanodeInfoWithStorage[127.0.0.1:42322,DS-ee7c931f-c02c-4c1f-87f2-ae4f25521b75,DISK], DatanodeInfoWithStorage[127.0.0.1:38599,DS-4bdf5d94-9904-490e-aff3-c4521bf2aa6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40093,DS-2fc6b875-0c4f-40f2-950b-825ec1836d03,DISK], DatanodeInfoWithStorage[127.0.0.1:38677,DS-84fc3ed5-6541-4612-9b83-114f67865063,DISK], DatanodeInfoWithStorage[127.0.0.1:43409,DS-577e37ca-1c43-4d93-bc36-06f77dc96995,DISK], DatanodeInfoWithStorage[127.0.0.1:46563,DS-03ac2632-2467-47b9-beb9-0f88a7926225,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1812364126-172.17.0.6-1597642821214:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39734,DS-dc84622a-756e-43bd-a766-f2f77492fc9e,DISK], DatanodeInfoWithStorage[127.0.0.1:33976,DS-08f971c6-4a05-4e5d-9bbc-6f9cf0976022,DISK], DatanodeInfoWithStorage[127.0.0.1:42322,DS-ee7c931f-c02c-4c1f-87f2-ae4f25521b75,DISK], DatanodeInfoWithStorage[127.0.0.1:38599,DS-4bdf5d94-9904-490e-aff3-c4521bf2aa6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40093,DS-2fc6b875-0c4f-40f2-950b-825ec1836d03,DISK], DatanodeInfoWithStorage[127.0.0.1:38677,DS-84fc3ed5-6541-4612-9b83-114f67865063,DISK], DatanodeInfoWithStorage[127.0.0.1:43409,DS-577e37ca-1c43-4d93-bc36-06f77dc96995,DISK], DatanodeInfoWithStorage[127.0.0.1:46563,DS-03ac2632-2467-47b9-beb9-0f88a7926225,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-623265715-172.17.0.6-1597643112337:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46420,DS-9349634d-6bc6-4dd7-be22-b8660a62cd8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44669,DS-3acc4946-6974-473e-973e-5ad3dae163d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38946,DS-1182af75-da38-44f1-be31-595241114ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:37159,DS-2cd07bd5-dd34-4efa-bb22-a137f8ff23b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37851,DS-69a29af0-97c2-4323-83fb-892e5f7725c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45519,DS-688788f4-d523-4c29-ae48-54939c4e3313,DISK], DatanodeInfoWithStorage[127.0.0.1:42626,DS-dc960250-5768-4b8f-b718-3b2d9f15c0dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40340,DS-10523824-8c47-4efc-9d63-bdf26f8c1108,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-623265715-172.17.0.6-1597643112337:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46420,DS-9349634d-6bc6-4dd7-be22-b8660a62cd8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44669,DS-3acc4946-6974-473e-973e-5ad3dae163d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38946,DS-1182af75-da38-44f1-be31-595241114ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:37159,DS-2cd07bd5-dd34-4efa-bb22-a137f8ff23b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37851,DS-69a29af0-97c2-4323-83fb-892e5f7725c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45519,DS-688788f4-d523-4c29-ae48-54939c4e3313,DISK], DatanodeInfoWithStorage[127.0.0.1:42626,DS-dc960250-5768-4b8f-b718-3b2d9f15c0dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40340,DS-10523824-8c47-4efc-9d63-bdf26f8c1108,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-842312737-172.17.0.6-1597643218022:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39832,DS-8a21e2ab-ecef-4520-8e6f-ccf5d7a95e61,DISK], DatanodeInfoWithStorage[127.0.0.1:45515,DS-c260e50a-3230-42f2-983a-bb29407d0510,DISK], DatanodeInfoWithStorage[127.0.0.1:38925,DS-fa75f265-753d-4c81-9342-aa1dc6a6e621,DISK], DatanodeInfoWithStorage[127.0.0.1:34794,DS-f7423edf-1a24-4682-a28c-3c8d1abd0c90,DISK], DatanodeInfoWithStorage[127.0.0.1:45312,DS-07e458bc-bdc5-4394-bca3-ce059921d74a,DISK], DatanodeInfoWithStorage[127.0.0.1:43077,DS-57e84e6e-6a43-443d-921e-042ec5566c60,DISK], DatanodeInfoWithStorage[127.0.0.1:38018,DS-9e7dc837-430c-4a5c-8cbb-5e40a9e8332b,DISK], DatanodeInfoWithStorage[127.0.0.1:44238,DS-e84de0aa-d06a-4a4a-a532-58baa441ff49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-842312737-172.17.0.6-1597643218022:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39832,DS-8a21e2ab-ecef-4520-8e6f-ccf5d7a95e61,DISK], DatanodeInfoWithStorage[127.0.0.1:45515,DS-c260e50a-3230-42f2-983a-bb29407d0510,DISK], DatanodeInfoWithStorage[127.0.0.1:38925,DS-fa75f265-753d-4c81-9342-aa1dc6a6e621,DISK], DatanodeInfoWithStorage[127.0.0.1:34794,DS-f7423edf-1a24-4682-a28c-3c8d1abd0c90,DISK], DatanodeInfoWithStorage[127.0.0.1:45312,DS-07e458bc-bdc5-4394-bca3-ce059921d74a,DISK], DatanodeInfoWithStorage[127.0.0.1:43077,DS-57e84e6e-6a43-443d-921e-042ec5566c60,DISK], DatanodeInfoWithStorage[127.0.0.1:38018,DS-9e7dc837-430c-4a5c-8cbb-5e40a9e8332b,DISK], DatanodeInfoWithStorage[127.0.0.1:44238,DS-e84de0aa-d06a-4a4a-a532-58baa441ff49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-954804371-172.17.0.6-1597643327665:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41670,DS-08d30192-8c51-4a6e-a963-1fc4e4a10959,DISK], DatanodeInfoWithStorage[127.0.0.1:43407,DS-59566498-c36f-4a04-b6d0-085622ce9e98,DISK], DatanodeInfoWithStorage[127.0.0.1:41774,DS-122dc93c-d783-4f56-99dd-2fcb8c611a80,DISK], DatanodeInfoWithStorage[127.0.0.1:43488,DS-227c15fe-6cba-4691-8588-3fde10ee9b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45457,DS-bf606a74-62b4-4794-b27b-61c07410a761,DISK], DatanodeInfoWithStorage[127.0.0.1:45900,DS-86e480cd-f5aa-4560-a2d9-7bbb016a7bad,DISK], DatanodeInfoWithStorage[127.0.0.1:40196,DS-5553441e-1643-49eb-99bc-a5d2bfffd227,DISK], DatanodeInfoWithStorage[127.0.0.1:44224,DS-220099a0-5e0e-448c-baed-f398ea769833,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-954804371-172.17.0.6-1597643327665:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41670,DS-08d30192-8c51-4a6e-a963-1fc4e4a10959,DISK], DatanodeInfoWithStorage[127.0.0.1:43407,DS-59566498-c36f-4a04-b6d0-085622ce9e98,DISK], DatanodeInfoWithStorage[127.0.0.1:41774,DS-122dc93c-d783-4f56-99dd-2fcb8c611a80,DISK], DatanodeInfoWithStorage[127.0.0.1:43488,DS-227c15fe-6cba-4691-8588-3fde10ee9b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45457,DS-bf606a74-62b4-4794-b27b-61c07410a761,DISK], DatanodeInfoWithStorage[127.0.0.1:45900,DS-86e480cd-f5aa-4560-a2d9-7bbb016a7bad,DISK], DatanodeInfoWithStorage[127.0.0.1:40196,DS-5553441e-1643-49eb-99bc-a5d2bfffd227,DISK], DatanodeInfoWithStorage[127.0.0.1:44224,DS-220099a0-5e0e-448c-baed-f398ea769833,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-216696617-172.17.0.6-1597643414954:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35546,DS-aec28e54-59a5-43b3-b12c-28cddfb4cff0,DISK], DatanodeInfoWithStorage[127.0.0.1:44689,DS-3d623c2f-9070-476b-964f-3d973abeb719,DISK], DatanodeInfoWithStorage[127.0.0.1:46731,DS-18ae98a9-8070-424e-a7c7-cdbd47ae7f79,DISK], DatanodeInfoWithStorage[127.0.0.1:32899,DS-6eefdb1f-62f3-4b1e-8791-8c89602cb076,DISK], DatanodeInfoWithStorage[127.0.0.1:45474,DS-d7b36ecc-f1d8-42bb-bb89-54180a79ce5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33903,DS-86e492e7-349f-40c7-ade6-6df812ff1f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:45361,DS-ae42b251-8ec7-4d4a-9792-0933b91d616e,DISK], DatanodeInfoWithStorage[127.0.0.1:33758,DS-f2e943f4-90e9-4dc6-8a6a-ba17907e93cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-216696617-172.17.0.6-1597643414954:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35546,DS-aec28e54-59a5-43b3-b12c-28cddfb4cff0,DISK], DatanodeInfoWithStorage[127.0.0.1:44689,DS-3d623c2f-9070-476b-964f-3d973abeb719,DISK], DatanodeInfoWithStorage[127.0.0.1:46731,DS-18ae98a9-8070-424e-a7c7-cdbd47ae7f79,DISK], DatanodeInfoWithStorage[127.0.0.1:32899,DS-6eefdb1f-62f3-4b1e-8791-8c89602cb076,DISK], DatanodeInfoWithStorage[127.0.0.1:45474,DS-d7b36ecc-f1d8-42bb-bb89-54180a79ce5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33903,DS-86e492e7-349f-40c7-ade6-6df812ff1f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:45361,DS-ae42b251-8ec7-4d4a-9792-0933b91d616e,DISK], DatanodeInfoWithStorage[127.0.0.1:33758,DS-f2e943f4-90e9-4dc6-8a6a-ba17907e93cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-518658888-172.17.0.6-1597643460695:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44943,DS-703a8d4f-536b-4dd0-86be-d1f390e0ebde,DISK], DatanodeInfoWithStorage[127.0.0.1:37450,DS-9f5d579f-e721-46c9-bd9e-2d7f99f9925d,DISK], DatanodeInfoWithStorage[127.0.0.1:35246,DS-b31444a4-7d4d-4c00-8bbd-7c2d6e9e17f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34552,DS-d78c64a6-2866-4a00-8896-fcc5ff00c9ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44192,DS-4d6106fa-07ac-440c-84cf-91df14d30b26,DISK], DatanodeInfoWithStorage[127.0.0.1:40958,DS-1e09dbbe-c64a-4567-adf0-5c9af9f54969,DISK], DatanodeInfoWithStorage[127.0.0.1:34810,DS-04a12d51-00f1-4101-9a1e-88cead8f24ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35275,DS-eaa12327-aa68-486a-b046-37079bbd10be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-518658888-172.17.0.6-1597643460695:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44943,DS-703a8d4f-536b-4dd0-86be-d1f390e0ebde,DISK], DatanodeInfoWithStorage[127.0.0.1:37450,DS-9f5d579f-e721-46c9-bd9e-2d7f99f9925d,DISK], DatanodeInfoWithStorage[127.0.0.1:35246,DS-b31444a4-7d4d-4c00-8bbd-7c2d6e9e17f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34552,DS-d78c64a6-2866-4a00-8896-fcc5ff00c9ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44192,DS-4d6106fa-07ac-440c-84cf-91df14d30b26,DISK], DatanodeInfoWithStorage[127.0.0.1:40958,DS-1e09dbbe-c64a-4567-adf0-5c9af9f54969,DISK], DatanodeInfoWithStorage[127.0.0.1:34810,DS-04a12d51-00f1-4101-9a1e-88cead8f24ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35275,DS-eaa12327-aa68-486a-b046-37079bbd10be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1431446124-172.17.0.6-1597643796000:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43191,DS-7f45a9e3-fc7d-48c2-b0ce-90e66543464a,DISK], DatanodeInfoWithStorage[127.0.0.1:40501,DS-39fdb65c-59cc-4377-8f80-d8f3220b374d,DISK], DatanodeInfoWithStorage[127.0.0.1:46535,DS-70a20498-8a32-42e4-972f-ef42e812aaae,DISK], DatanodeInfoWithStorage[127.0.0.1:37873,DS-0b657fdb-15fb-41c8-a1d8-ac5709747024,DISK], DatanodeInfoWithStorage[127.0.0.1:39603,DS-679fc6fe-c33b-41e8-9e4e-d7a1757947f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37754,DS-52aee2d5-a1cc-4ae9-8d82-985da7d31cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:37951,DS-96b8393c-a2fa-4135-9850-2d2773638be6,DISK], DatanodeInfoWithStorage[127.0.0.1:43936,DS-c1f04d67-ba50-4a0a-8135-dbd57531c0d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1431446124-172.17.0.6-1597643796000:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43191,DS-7f45a9e3-fc7d-48c2-b0ce-90e66543464a,DISK], DatanodeInfoWithStorage[127.0.0.1:40501,DS-39fdb65c-59cc-4377-8f80-d8f3220b374d,DISK], DatanodeInfoWithStorage[127.0.0.1:46535,DS-70a20498-8a32-42e4-972f-ef42e812aaae,DISK], DatanodeInfoWithStorage[127.0.0.1:37873,DS-0b657fdb-15fb-41c8-a1d8-ac5709747024,DISK], DatanodeInfoWithStorage[127.0.0.1:39603,DS-679fc6fe-c33b-41e8-9e4e-d7a1757947f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37754,DS-52aee2d5-a1cc-4ae9-8d82-985da7d31cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:37951,DS-96b8393c-a2fa-4135-9850-2d2773638be6,DISK], DatanodeInfoWithStorage[127.0.0.1:43936,DS-c1f04d67-ba50-4a0a-8135-dbd57531c0d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1627144077-172.17.0.6-1597644067316:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37658,DS-098f34e2-bae9-4b78-bc9e-32e1919b7c46,DISK], DatanodeInfoWithStorage[127.0.0.1:43337,DS-9a4c6cde-04bf-4f59-b35c-c11eef24121d,DISK], DatanodeInfoWithStorage[127.0.0.1:33281,DS-90bcab10-65a5-4ace-b712-19145cdeeb2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42845,DS-00bbbeeb-77fa-411e-817e-edae89819704,DISK], DatanodeInfoWithStorage[127.0.0.1:41038,DS-c48ea8e9-ac88-4095-80c9-b58dc33f2aed,DISK], DatanodeInfoWithStorage[127.0.0.1:38500,DS-3904ed79-6ba6-43d9-bd82-d6a5d59b408c,DISK], DatanodeInfoWithStorage[127.0.0.1:35999,DS-631b576c-6c84-4b4b-ae81-25175bdce1e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38232,DS-b7870b8d-7830-4522-a5a5-0ac4a9b818a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1627144077-172.17.0.6-1597644067316:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37658,DS-098f34e2-bae9-4b78-bc9e-32e1919b7c46,DISK], DatanodeInfoWithStorage[127.0.0.1:43337,DS-9a4c6cde-04bf-4f59-b35c-c11eef24121d,DISK], DatanodeInfoWithStorage[127.0.0.1:33281,DS-90bcab10-65a5-4ace-b712-19145cdeeb2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42845,DS-00bbbeeb-77fa-411e-817e-edae89819704,DISK], DatanodeInfoWithStorage[127.0.0.1:41038,DS-c48ea8e9-ac88-4095-80c9-b58dc33f2aed,DISK], DatanodeInfoWithStorage[127.0.0.1:38500,DS-3904ed79-6ba6-43d9-bd82-d6a5d59b408c,DISK], DatanodeInfoWithStorage[127.0.0.1:35999,DS-631b576c-6c84-4b4b-ae81-25175bdce1e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38232,DS-b7870b8d-7830-4522-a5a5-0ac4a9b818a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-627234394-172.17.0.6-1597644476440:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35128,DS-71730b45-b30d-4678-8358-3486904cb9a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41582,DS-6d8a0255-2e24-48a7-881b-f96100c9fa72,DISK], DatanodeInfoWithStorage[127.0.0.1:42548,DS-37fcc464-c762-41d3-a7e6-0176ffca0757,DISK], DatanodeInfoWithStorage[127.0.0.1:36139,DS-6ecb5a16-a149-44e6-9b40-0dca7250bb29,DISK], DatanodeInfoWithStorage[127.0.0.1:36431,DS-b966bbbc-5ef2-4d24-a844-14c3780d52ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36316,DS-f98543b9-2160-4952-a8bb-bc4eafe959d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37422,DS-be696876-fc7c-408d-9ced-7dad29d66173,DISK], DatanodeInfoWithStorage[127.0.0.1:43396,DS-cc34342b-fdb0-449b-88f4-1fe4c72ab0e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-627234394-172.17.0.6-1597644476440:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35128,DS-71730b45-b30d-4678-8358-3486904cb9a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41582,DS-6d8a0255-2e24-48a7-881b-f96100c9fa72,DISK], DatanodeInfoWithStorage[127.0.0.1:42548,DS-37fcc464-c762-41d3-a7e6-0176ffca0757,DISK], DatanodeInfoWithStorage[127.0.0.1:36139,DS-6ecb5a16-a149-44e6-9b40-0dca7250bb29,DISK], DatanodeInfoWithStorage[127.0.0.1:36431,DS-b966bbbc-5ef2-4d24-a844-14c3780d52ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36316,DS-f98543b9-2160-4952-a8bb-bc4eafe959d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37422,DS-be696876-fc7c-408d-9ced-7dad29d66173,DISK], DatanodeInfoWithStorage[127.0.0.1:43396,DS-cc34342b-fdb0-449b-88f4-1fe4c72ab0e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5636
