reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1878531851-172.17.0.5-1597685034470:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32956,DS-71d4d0c4-460e-4905-9707-6bdea757907e,DISK], DatanodeInfoWithStorage[127.0.0.1:35429,DS-66bce4ed-5645-4174-97ea-dd4f3c552683,DISK], DatanodeInfoWithStorage[127.0.0.1:37395,DS-03440e77-0b8f-4dab-a6f0-98b45fcd9feb,DISK], DatanodeInfoWithStorage[127.0.0.1:37404,DS-f555a4ef-b09b-48ee-9978-7def573f7c16,DISK], DatanodeInfoWithStorage[127.0.0.1:42762,DS-e8cfcfd3-cb5c-4c13-8bac-1054e10511f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43786,DS-b611cebc-2b5b-4058-a84b-ad6c7690926e,DISK], DatanodeInfoWithStorage[127.0.0.1:33681,DS-eacb066f-2c26-4772-ad94-139ec2f61c09,DISK], DatanodeInfoWithStorage[127.0.0.1:38409,DS-c665a3a1-377b-49c0-b297-a9ff0b11def6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1878531851-172.17.0.5-1597685034470:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32956,DS-71d4d0c4-460e-4905-9707-6bdea757907e,DISK], DatanodeInfoWithStorage[127.0.0.1:35429,DS-66bce4ed-5645-4174-97ea-dd4f3c552683,DISK], DatanodeInfoWithStorage[127.0.0.1:37395,DS-03440e77-0b8f-4dab-a6f0-98b45fcd9feb,DISK], DatanodeInfoWithStorage[127.0.0.1:37404,DS-f555a4ef-b09b-48ee-9978-7def573f7c16,DISK], DatanodeInfoWithStorage[127.0.0.1:42762,DS-e8cfcfd3-cb5c-4c13-8bac-1054e10511f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43786,DS-b611cebc-2b5b-4058-a84b-ad6c7690926e,DISK], DatanodeInfoWithStorage[127.0.0.1:33681,DS-eacb066f-2c26-4772-ad94-139ec2f61c09,DISK], DatanodeInfoWithStorage[127.0.0.1:38409,DS-c665a3a1-377b-49c0-b297-a9ff0b11def6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1216742052-172.17.0.5-1597685506248:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42317,DS-b923bb18-9606-4c3b-b2a4-81cbe5fe7565,DISK], DatanodeInfoWithStorage[127.0.0.1:43088,DS-9588c9a1-2b2f-40da-aed2-cfbf97fa1ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:46400,DS-0d0efbeb-791a-4a60-abb5-e3cf12df61e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38272,DS-3a21bf03-402b-4cb7-948b-1ce70fce991c,DISK], DatanodeInfoWithStorage[127.0.0.1:32901,DS-f901594d-7ef4-4fa1-b4aa-8a0bbacd5182,DISK], DatanodeInfoWithStorage[127.0.0.1:40177,DS-c96f13a2-2300-4e0a-a770-3a89b9f4fa2e,DISK], DatanodeInfoWithStorage[127.0.0.1:41160,DS-e037536b-b84e-407b-a2cd-30b625a9f7b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34514,DS-ea16064d-982e-4bd8-be07-7b93ab97184f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1216742052-172.17.0.5-1597685506248:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42317,DS-b923bb18-9606-4c3b-b2a4-81cbe5fe7565,DISK], DatanodeInfoWithStorage[127.0.0.1:43088,DS-9588c9a1-2b2f-40da-aed2-cfbf97fa1ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:46400,DS-0d0efbeb-791a-4a60-abb5-e3cf12df61e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38272,DS-3a21bf03-402b-4cb7-948b-1ce70fce991c,DISK], DatanodeInfoWithStorage[127.0.0.1:32901,DS-f901594d-7ef4-4fa1-b4aa-8a0bbacd5182,DISK], DatanodeInfoWithStorage[127.0.0.1:40177,DS-c96f13a2-2300-4e0a-a770-3a89b9f4fa2e,DISK], DatanodeInfoWithStorage[127.0.0.1:41160,DS-e037536b-b84e-407b-a2cd-30b625a9f7b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34514,DS-ea16064d-982e-4bd8-be07-7b93ab97184f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-936548854-172.17.0.5-1597685795431:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37310,DS-53ac5ede-8106-4fa3-aab2-d8cb1f6e0442,DISK], DatanodeInfoWithStorage[127.0.0.1:45901,DS-7e9379cb-f39e-4f76-ae0c-f6b013e7e929,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-6a9d6df5-9236-4d97-995e-606e95b7bccf,DISK], DatanodeInfoWithStorage[127.0.0.1:41447,DS-c7bb9d2d-9a2b-43f3-99a0-c19e8a3627af,DISK], DatanodeInfoWithStorage[127.0.0.1:40620,DS-edc396f7-39ac-481b-a223-605677a0a748,DISK], DatanodeInfoWithStorage[127.0.0.1:45714,DS-efc82cae-8a07-4c13-9ba0-aa6a7a15306f,DISK], DatanodeInfoWithStorage[127.0.0.1:43460,DS-b81d2e52-0b4a-4c0b-8bac-eb0f5270fec5,DISK], DatanodeInfoWithStorage[127.0.0.1:38115,DS-61f3d9b8-36b8-455c-8184-54a2e5f83481,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-936548854-172.17.0.5-1597685795431:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37310,DS-53ac5ede-8106-4fa3-aab2-d8cb1f6e0442,DISK], DatanodeInfoWithStorage[127.0.0.1:45901,DS-7e9379cb-f39e-4f76-ae0c-f6b013e7e929,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-6a9d6df5-9236-4d97-995e-606e95b7bccf,DISK], DatanodeInfoWithStorage[127.0.0.1:41447,DS-c7bb9d2d-9a2b-43f3-99a0-c19e8a3627af,DISK], DatanodeInfoWithStorage[127.0.0.1:40620,DS-edc396f7-39ac-481b-a223-605677a0a748,DISK], DatanodeInfoWithStorage[127.0.0.1:45714,DS-efc82cae-8a07-4c13-9ba0-aa6a7a15306f,DISK], DatanodeInfoWithStorage[127.0.0.1:43460,DS-b81d2e52-0b4a-4c0b-8bac-eb0f5270fec5,DISK], DatanodeInfoWithStorage[127.0.0.1:38115,DS-61f3d9b8-36b8-455c-8184-54a2e5f83481,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2011998279-172.17.0.5-1597685859851:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43140,DS-6046f584-17e5-4a1d-8c53-20bad45d1453,DISK], DatanodeInfoWithStorage[127.0.0.1:36644,DS-ced5233d-98b8-4344-a0ec-550949c4d318,DISK], DatanodeInfoWithStorage[127.0.0.1:43671,DS-63a7c2b0-2cbb-4645-8265-af9cf47bd176,DISK], DatanodeInfoWithStorage[127.0.0.1:34164,DS-e4543e4a-9b98-460a-adc1-d6689bdfa678,DISK], DatanodeInfoWithStorage[127.0.0.1:42523,DS-deabfa53-9e9e-4f6e-a081-7f903b7c7440,DISK], DatanodeInfoWithStorage[127.0.0.1:35172,DS-30ceedbc-2264-40d8-a395-d0c9c5d738de,DISK], DatanodeInfoWithStorage[127.0.0.1:41378,DS-f823e0fd-2b60-4b15-b0f5-e1c3bea324d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44621,DS-6ca12c01-9f53-4245-ba26-9583c22f73d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2011998279-172.17.0.5-1597685859851:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43140,DS-6046f584-17e5-4a1d-8c53-20bad45d1453,DISK], DatanodeInfoWithStorage[127.0.0.1:36644,DS-ced5233d-98b8-4344-a0ec-550949c4d318,DISK], DatanodeInfoWithStorage[127.0.0.1:43671,DS-63a7c2b0-2cbb-4645-8265-af9cf47bd176,DISK], DatanodeInfoWithStorage[127.0.0.1:34164,DS-e4543e4a-9b98-460a-adc1-d6689bdfa678,DISK], DatanodeInfoWithStorage[127.0.0.1:42523,DS-deabfa53-9e9e-4f6e-a081-7f903b7c7440,DISK], DatanodeInfoWithStorage[127.0.0.1:35172,DS-30ceedbc-2264-40d8-a395-d0c9c5d738de,DISK], DatanodeInfoWithStorage[127.0.0.1:41378,DS-f823e0fd-2b60-4b15-b0f5-e1c3bea324d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44621,DS-6ca12c01-9f53-4245-ba26-9583c22f73d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1397223601-172.17.0.5-1597686273405:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34305,DS-cbc93f5e-c478-443d-9ca8-d30a614a9af5,DISK], DatanodeInfoWithStorage[127.0.0.1:36294,DS-2e26f21e-d518-452c-ab6a-ac4304bffb93,DISK], DatanodeInfoWithStorage[127.0.0.1:37587,DS-ef1866bc-d35b-481c-9ab9-2ad7bc541efd,DISK], DatanodeInfoWithStorage[127.0.0.1:37484,DS-b1506548-40c3-457f-9c7c-9b356df1c32e,DISK], DatanodeInfoWithStorage[127.0.0.1:36488,DS-8aacb9f8-1ac9-4ea8-a81e-40cf159db6be,DISK], DatanodeInfoWithStorage[127.0.0.1:35016,DS-ccde0739-8bfd-461d-8fc1-e332b54fb274,DISK], DatanodeInfoWithStorage[127.0.0.1:45795,DS-52dbd3b6-4a6f-4d65-b59f-367753acf3de,DISK], DatanodeInfoWithStorage[127.0.0.1:39763,DS-8e40ac1e-6d82-4a49-8459-6beb5a57a905,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1397223601-172.17.0.5-1597686273405:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34305,DS-cbc93f5e-c478-443d-9ca8-d30a614a9af5,DISK], DatanodeInfoWithStorage[127.0.0.1:36294,DS-2e26f21e-d518-452c-ab6a-ac4304bffb93,DISK], DatanodeInfoWithStorage[127.0.0.1:37587,DS-ef1866bc-d35b-481c-9ab9-2ad7bc541efd,DISK], DatanodeInfoWithStorage[127.0.0.1:37484,DS-b1506548-40c3-457f-9c7c-9b356df1c32e,DISK], DatanodeInfoWithStorage[127.0.0.1:36488,DS-8aacb9f8-1ac9-4ea8-a81e-40cf159db6be,DISK], DatanodeInfoWithStorage[127.0.0.1:35016,DS-ccde0739-8bfd-461d-8fc1-e332b54fb274,DISK], DatanodeInfoWithStorage[127.0.0.1:45795,DS-52dbd3b6-4a6f-4d65-b59f-367753acf3de,DISK], DatanodeInfoWithStorage[127.0.0.1:39763,DS-8e40ac1e-6d82-4a49-8459-6beb5a57a905,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-636922033-172.17.0.5-1597686383231:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37471,DS-32daa72c-9604-45c8-ba3e-bd703ccc7d10,DISK], DatanodeInfoWithStorage[127.0.0.1:43845,DS-f07be686-b798-42e7-89e6-820e4570c79a,DISK], DatanodeInfoWithStorage[127.0.0.1:32963,DS-08e90219-0d67-493e-9c4c-8504f02f483c,DISK], DatanodeInfoWithStorage[127.0.0.1:32929,DS-c43c6ffb-29cd-42a9-bb0f-00b824c58601,DISK], DatanodeInfoWithStorage[127.0.0.1:46235,DS-67d5f219-b6f1-4848-9de8-7fd5a675c4c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33891,DS-76908ca7-911c-4c92-8ca7-2be9b23eb36c,DISK], DatanodeInfoWithStorage[127.0.0.1:44903,DS-b80be883-adda-46d4-9f31-48754f2f2692,DISK], DatanodeInfoWithStorage[127.0.0.1:40328,DS-915229e8-a9bd-4edc-a207-3ed5ebd8dd13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-636922033-172.17.0.5-1597686383231:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37471,DS-32daa72c-9604-45c8-ba3e-bd703ccc7d10,DISK], DatanodeInfoWithStorage[127.0.0.1:43845,DS-f07be686-b798-42e7-89e6-820e4570c79a,DISK], DatanodeInfoWithStorage[127.0.0.1:32963,DS-08e90219-0d67-493e-9c4c-8504f02f483c,DISK], DatanodeInfoWithStorage[127.0.0.1:32929,DS-c43c6ffb-29cd-42a9-bb0f-00b824c58601,DISK], DatanodeInfoWithStorage[127.0.0.1:46235,DS-67d5f219-b6f1-4848-9de8-7fd5a675c4c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33891,DS-76908ca7-911c-4c92-8ca7-2be9b23eb36c,DISK], DatanodeInfoWithStorage[127.0.0.1:44903,DS-b80be883-adda-46d4-9f31-48754f2f2692,DISK], DatanodeInfoWithStorage[127.0.0.1:40328,DS-915229e8-a9bd-4edc-a207-3ed5ebd8dd13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1572578763-172.17.0.5-1597686633473:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44530,DS-67bdb527-fb69-42d3-baaa-f21998f64a53,DISK], DatanodeInfoWithStorage[127.0.0.1:36919,DS-bd2a5db6-c478-4ef6-bcdf-fd0c0a92b5bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40009,DS-913e0d38-16b0-4575-806b-3626e3537692,DISK], DatanodeInfoWithStorage[127.0.0.1:46881,DS-f15628e0-f63a-4cda-8aea-9f60e41bc1ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45186,DS-db6393cf-49a3-494e-9670-c0d76c1c8ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:34001,DS-23058ea4-3db8-4e5b-a014-9beee95da13f,DISK], DatanodeInfoWithStorage[127.0.0.1:40682,DS-4ea16319-68d2-4ac1-a42f-e83ba4aa2de8,DISK], DatanodeInfoWithStorage[127.0.0.1:38018,DS-a5a82f2d-a6ba-46d8-9894-de54b3961f8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1572578763-172.17.0.5-1597686633473:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44530,DS-67bdb527-fb69-42d3-baaa-f21998f64a53,DISK], DatanodeInfoWithStorage[127.0.0.1:36919,DS-bd2a5db6-c478-4ef6-bcdf-fd0c0a92b5bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40009,DS-913e0d38-16b0-4575-806b-3626e3537692,DISK], DatanodeInfoWithStorage[127.0.0.1:46881,DS-f15628e0-f63a-4cda-8aea-9f60e41bc1ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45186,DS-db6393cf-49a3-494e-9670-c0d76c1c8ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:34001,DS-23058ea4-3db8-4e5b-a014-9beee95da13f,DISK], DatanodeInfoWithStorage[127.0.0.1:40682,DS-4ea16319-68d2-4ac1-a42f-e83ba4aa2de8,DISK], DatanodeInfoWithStorage[127.0.0.1:38018,DS-a5a82f2d-a6ba-46d8-9894-de54b3961f8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-781488069-172.17.0.5-1597686735819:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40351,DS-020f2381-8f45-4faf-85bf-42f806d0c21d,DISK], DatanodeInfoWithStorage[127.0.0.1:40633,DS-d1aa133c-4d14-4d48-b436-79aa1fdac4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44632,DS-39ab8031-42e6-4172-a346-e96d5f5e50a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42150,DS-38d6428e-6547-4566-a7b3-8f1f602293ba,DISK], DatanodeInfoWithStorage[127.0.0.1:32820,DS-7bfe548b-3500-4f50-9a73-c7a1eb761b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40724,DS-8b61a1c5-fab2-481f-8e8e-9cdbfcdfc263,DISK], DatanodeInfoWithStorage[127.0.0.1:35230,DS-c82f2384-4dc7-4bdc-a0c0-97d3af38226a,DISK], DatanodeInfoWithStorage[127.0.0.1:44044,DS-c07d3e67-0dcc-4289-bfee-0e0d8ae4e26e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-781488069-172.17.0.5-1597686735819:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40351,DS-020f2381-8f45-4faf-85bf-42f806d0c21d,DISK], DatanodeInfoWithStorage[127.0.0.1:40633,DS-d1aa133c-4d14-4d48-b436-79aa1fdac4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44632,DS-39ab8031-42e6-4172-a346-e96d5f5e50a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42150,DS-38d6428e-6547-4566-a7b3-8f1f602293ba,DISK], DatanodeInfoWithStorage[127.0.0.1:32820,DS-7bfe548b-3500-4f50-9a73-c7a1eb761b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40724,DS-8b61a1c5-fab2-481f-8e8e-9cdbfcdfc263,DISK], DatanodeInfoWithStorage[127.0.0.1:35230,DS-c82f2384-4dc7-4bdc-a0c0-97d3af38226a,DISK], DatanodeInfoWithStorage[127.0.0.1:44044,DS-c07d3e67-0dcc-4289-bfee-0e0d8ae4e26e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-845452898-172.17.0.5-1597686816547:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34094,DS-25223226-20fa-442b-947b-128c887654ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45647,DS-18536422-5807-4e09-aa79-fed649281319,DISK], DatanodeInfoWithStorage[127.0.0.1:43746,DS-e5356e9a-e4f1-41fb-91b9-0eb62f69e28a,DISK], DatanodeInfoWithStorage[127.0.0.1:40583,DS-536fbc72-258b-4dd5-ae78-89ff802d7be5,DISK], DatanodeInfoWithStorage[127.0.0.1:35339,DS-4fbeb81f-a0df-4178-b179-a98c9ae6acc4,DISK], DatanodeInfoWithStorage[127.0.0.1:43576,DS-7fafce26-9f8f-46cf-8fe7-7fb12749313c,DISK], DatanodeInfoWithStorage[127.0.0.1:36776,DS-592750e9-ba46-4609-b573-4711133874cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38112,DS-4d3dc144-02fd-4998-86a3-5983cc64bcb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-845452898-172.17.0.5-1597686816547:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34094,DS-25223226-20fa-442b-947b-128c887654ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45647,DS-18536422-5807-4e09-aa79-fed649281319,DISK], DatanodeInfoWithStorage[127.0.0.1:43746,DS-e5356e9a-e4f1-41fb-91b9-0eb62f69e28a,DISK], DatanodeInfoWithStorage[127.0.0.1:40583,DS-536fbc72-258b-4dd5-ae78-89ff802d7be5,DISK], DatanodeInfoWithStorage[127.0.0.1:35339,DS-4fbeb81f-a0df-4178-b179-a98c9ae6acc4,DISK], DatanodeInfoWithStorage[127.0.0.1:43576,DS-7fafce26-9f8f-46cf-8fe7-7fb12749313c,DISK], DatanodeInfoWithStorage[127.0.0.1:36776,DS-592750e9-ba46-4609-b573-4711133874cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38112,DS-4d3dc144-02fd-4998-86a3-5983cc64bcb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-959727535-172.17.0.5-1597687048492:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46621,DS-7861b037-a140-4a44-ae2a-b6f64d556145,DISK], DatanodeInfoWithStorage[127.0.0.1:39116,DS-a8caa34f-02a5-45ee-a667-62284e585a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39668,DS-79a7ddb4-2495-4953-8a55-0ea39fadfb71,DISK], DatanodeInfoWithStorage[127.0.0.1:39778,DS-5831efe6-0ab1-4db2-b777-a45137671b29,DISK], DatanodeInfoWithStorage[127.0.0.1:46742,DS-2c3a2988-348e-4a3b-839a-4f37e05bfe49,DISK], DatanodeInfoWithStorage[127.0.0.1:33432,DS-4be9a953-2996-4522-b5df-cf492ef489cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40885,DS-7f951c83-57a4-4943-b0ca-d7f279d358b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38110,DS-25b9f02a-26f4-43ce-9a92-bf355a9b10f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-959727535-172.17.0.5-1597687048492:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46621,DS-7861b037-a140-4a44-ae2a-b6f64d556145,DISK], DatanodeInfoWithStorage[127.0.0.1:39116,DS-a8caa34f-02a5-45ee-a667-62284e585a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39668,DS-79a7ddb4-2495-4953-8a55-0ea39fadfb71,DISK], DatanodeInfoWithStorage[127.0.0.1:39778,DS-5831efe6-0ab1-4db2-b777-a45137671b29,DISK], DatanodeInfoWithStorage[127.0.0.1:46742,DS-2c3a2988-348e-4a3b-839a-4f37e05bfe49,DISK], DatanodeInfoWithStorage[127.0.0.1:33432,DS-4be9a953-2996-4522-b5df-cf492ef489cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40885,DS-7f951c83-57a4-4943-b0ca-d7f279d358b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38110,DS-25b9f02a-26f4-43ce-9a92-bf355a9b10f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1125570894-172.17.0.5-1597687160330:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46018,DS-6ff475bd-34f5-4a98-89d5-1e15abd18629,DISK], DatanodeInfoWithStorage[127.0.0.1:45654,DS-5dfa6b48-67a8-4064-94e7-0d6e2f91223e,DISK], DatanodeInfoWithStorage[127.0.0.1:35170,DS-2cedb33e-d47a-4722-b0f5-2231346a5f00,DISK], DatanodeInfoWithStorage[127.0.0.1:36869,DS-001bcfff-f38d-46a5-a483-d99860c53b63,DISK], DatanodeInfoWithStorage[127.0.0.1:40484,DS-e8f0dd8b-43c4-4e35-8d86-a592449e2a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:46571,DS-1539a8fa-d24d-40ca-ba73-81317245fee3,DISK], DatanodeInfoWithStorage[127.0.0.1:35009,DS-e51ba75b-f2b4-411a-a6cf-94a2d8ba11eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45282,DS-57209f24-1167-4d97-b6e8-ed15c9f5bf04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1125570894-172.17.0.5-1597687160330:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46018,DS-6ff475bd-34f5-4a98-89d5-1e15abd18629,DISK], DatanodeInfoWithStorage[127.0.0.1:45654,DS-5dfa6b48-67a8-4064-94e7-0d6e2f91223e,DISK], DatanodeInfoWithStorage[127.0.0.1:35170,DS-2cedb33e-d47a-4722-b0f5-2231346a5f00,DISK], DatanodeInfoWithStorage[127.0.0.1:36869,DS-001bcfff-f38d-46a5-a483-d99860c53b63,DISK], DatanodeInfoWithStorage[127.0.0.1:40484,DS-e8f0dd8b-43c4-4e35-8d86-a592449e2a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:46571,DS-1539a8fa-d24d-40ca-ba73-81317245fee3,DISK], DatanodeInfoWithStorage[127.0.0.1:35009,DS-e51ba75b-f2b4-411a-a6cf-94a2d8ba11eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45282,DS-57209f24-1167-4d97-b6e8-ed15c9f5bf04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1406711301-172.17.0.5-1597687678745:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39992,DS-7ab04975-0b07-4028-8ccc-5c8ae5d8c2bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35575,DS-77e425e1-825a-40ed-90da-05d59e58db38,DISK], DatanodeInfoWithStorage[127.0.0.1:39120,DS-9c64815c-cd44-4480-9ef5-62a2d52b171e,DISK], DatanodeInfoWithStorage[127.0.0.1:38571,DS-27aceccf-a93a-447f-9971-f17669f7abf8,DISK], DatanodeInfoWithStorage[127.0.0.1:43146,DS-1778ea5d-d07a-425e-ab2b-5bc95e301e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:36112,DS-d052624d-704d-47e1-97b6-2520bfe3fc46,DISK], DatanodeInfoWithStorage[127.0.0.1:46031,DS-a2cb2793-8889-4b65-8c79-b7bacf70b06c,DISK], DatanodeInfoWithStorage[127.0.0.1:39389,DS-2b839db3-41be-40a5-a878-064b627d6516,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1406711301-172.17.0.5-1597687678745:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39992,DS-7ab04975-0b07-4028-8ccc-5c8ae5d8c2bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35575,DS-77e425e1-825a-40ed-90da-05d59e58db38,DISK], DatanodeInfoWithStorage[127.0.0.1:39120,DS-9c64815c-cd44-4480-9ef5-62a2d52b171e,DISK], DatanodeInfoWithStorage[127.0.0.1:38571,DS-27aceccf-a93a-447f-9971-f17669f7abf8,DISK], DatanodeInfoWithStorage[127.0.0.1:43146,DS-1778ea5d-d07a-425e-ab2b-5bc95e301e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:36112,DS-d052624d-704d-47e1-97b6-2520bfe3fc46,DISK], DatanodeInfoWithStorage[127.0.0.1:46031,DS-a2cb2793-8889-4b65-8c79-b7bacf70b06c,DISK], DatanodeInfoWithStorage[127.0.0.1:39389,DS-2b839db3-41be-40a5-a878-064b627d6516,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2085585795-172.17.0.5-1597687757017:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41490,DS-7fa8532a-918d-4a39-bd74-d4e845520755,DISK], DatanodeInfoWithStorage[127.0.0.1:43479,DS-ea3dad9d-54b2-40af-b7af-89bbd83ca812,DISK], DatanodeInfoWithStorage[127.0.0.1:45167,DS-e7e1cbda-c485-490d-84ca-8988f47190f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45613,DS-e9899dda-c29d-46e6-98bb-a125a4c32fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:44914,DS-4641c785-bb7f-4a19-a201-ccdb2f6f886f,DISK], DatanodeInfoWithStorage[127.0.0.1:37887,DS-33fcf835-64d1-44a1-a646-70fe3e7b23d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44010,DS-2a17e56f-08c5-4676-afac-1c4b01599ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:38113,DS-f8f08c1d-9755-4724-accd-00c80e6e5fb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2085585795-172.17.0.5-1597687757017:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41490,DS-7fa8532a-918d-4a39-bd74-d4e845520755,DISK], DatanodeInfoWithStorage[127.0.0.1:43479,DS-ea3dad9d-54b2-40af-b7af-89bbd83ca812,DISK], DatanodeInfoWithStorage[127.0.0.1:45167,DS-e7e1cbda-c485-490d-84ca-8988f47190f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45613,DS-e9899dda-c29d-46e6-98bb-a125a4c32fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:44914,DS-4641c785-bb7f-4a19-a201-ccdb2f6f886f,DISK], DatanodeInfoWithStorage[127.0.0.1:37887,DS-33fcf835-64d1-44a1-a646-70fe3e7b23d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44010,DS-2a17e56f-08c5-4676-afac-1c4b01599ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:38113,DS-f8f08c1d-9755-4724-accd-00c80e6e5fb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-219476573-172.17.0.5-1597688216466:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33524,DS-7449af62-73a8-4dcf-aade-4bf99d87245e,DISK], DatanodeInfoWithStorage[127.0.0.1:43362,DS-97975153-636c-437f-9c36-1ddc01ab3f17,DISK], DatanodeInfoWithStorage[127.0.0.1:38089,DS-992ac0de-4bff-41e2-875e-3e19ceeee924,DISK], DatanodeInfoWithStorage[127.0.0.1:33708,DS-93c08929-38cd-40fd-a3cf-bfa7f31e994a,DISK], DatanodeInfoWithStorage[127.0.0.1:42534,DS-27ea84d7-2a67-4059-8cf8-89eb97469140,DISK], DatanodeInfoWithStorage[127.0.0.1:40295,DS-34e1b594-2b82-4bc4-b984-8d502b962965,DISK], DatanodeInfoWithStorage[127.0.0.1:38763,DS-e2ad2977-ec1b-44eb-8a40-77b8797e656f,DISK], DatanodeInfoWithStorage[127.0.0.1:43119,DS-e173bd6c-5e1e-411f-a37b-456979d246dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-219476573-172.17.0.5-1597688216466:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33524,DS-7449af62-73a8-4dcf-aade-4bf99d87245e,DISK], DatanodeInfoWithStorage[127.0.0.1:43362,DS-97975153-636c-437f-9c36-1ddc01ab3f17,DISK], DatanodeInfoWithStorage[127.0.0.1:38089,DS-992ac0de-4bff-41e2-875e-3e19ceeee924,DISK], DatanodeInfoWithStorage[127.0.0.1:33708,DS-93c08929-38cd-40fd-a3cf-bfa7f31e994a,DISK], DatanodeInfoWithStorage[127.0.0.1:42534,DS-27ea84d7-2a67-4059-8cf8-89eb97469140,DISK], DatanodeInfoWithStorage[127.0.0.1:40295,DS-34e1b594-2b82-4bc4-b984-8d502b962965,DISK], DatanodeInfoWithStorage[127.0.0.1:38763,DS-e2ad2977-ec1b-44eb-8a40-77b8797e656f,DISK], DatanodeInfoWithStorage[127.0.0.1:43119,DS-e173bd6c-5e1e-411f-a37b-456979d246dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1492356063-172.17.0.5-1597688356410:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38588,DS-fd2b4cc6-7837-4d1a-9c19-4bceb1d986c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45755,DS-aacb94d8-024f-4a6e-aa51-6e37dc15f812,DISK], DatanodeInfoWithStorage[127.0.0.1:43047,DS-f5fb2672-edd7-43b1-9557-3a4cb8ebab01,DISK], DatanodeInfoWithStorage[127.0.0.1:35317,DS-aa58fdb3-1788-46e7-941a-3f0c679469f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38467,DS-14fc7f87-49da-40f3-864f-4effbab281f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43874,DS-5b84c388-b1f6-43f1-a412-86b1b8b2d6e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44254,DS-c014ee16-7cbf-498a-86a9-1851ea30b041,DISK], DatanodeInfoWithStorage[127.0.0.1:32885,DS-f6bade4d-04b7-4bdb-8610-14f899f1f83d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1492356063-172.17.0.5-1597688356410:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38588,DS-fd2b4cc6-7837-4d1a-9c19-4bceb1d986c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45755,DS-aacb94d8-024f-4a6e-aa51-6e37dc15f812,DISK], DatanodeInfoWithStorage[127.0.0.1:43047,DS-f5fb2672-edd7-43b1-9557-3a4cb8ebab01,DISK], DatanodeInfoWithStorage[127.0.0.1:35317,DS-aa58fdb3-1788-46e7-941a-3f0c679469f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38467,DS-14fc7f87-49da-40f3-864f-4effbab281f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43874,DS-5b84c388-b1f6-43f1-a412-86b1b8b2d6e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44254,DS-c014ee16-7cbf-498a-86a9-1851ea30b041,DISK], DatanodeInfoWithStorage[127.0.0.1:32885,DS-f6bade4d-04b7-4bdb-8610-14f899f1f83d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1849139214-172.17.0.5-1597689396565:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40845,DS-ccf299f4-8810-4115-8119-1ed0ac19b310,DISK], DatanodeInfoWithStorage[127.0.0.1:35389,DS-ed0ffb2c-da93-475e-9cdf-9ef9a66742b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35652,DS-407d4173-0b06-4da1-8508-de3c331e03e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45010,DS-5d35e1d3-3494-46b4-a7ca-9f22c93bfc1a,DISK], DatanodeInfoWithStorage[127.0.0.1:42989,DS-11614c5c-4305-4635-9a24-46d2e6a013f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42517,DS-bd00b52d-42f5-4c0e-a17a-852b3247cf0a,DISK], DatanodeInfoWithStorage[127.0.0.1:44770,DS-8a20c274-849c-44bc-86c7-bc8f6f1f60b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42294,DS-7888c963-9b08-4554-92e0-37eef82b2a14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1849139214-172.17.0.5-1597689396565:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40845,DS-ccf299f4-8810-4115-8119-1ed0ac19b310,DISK], DatanodeInfoWithStorage[127.0.0.1:35389,DS-ed0ffb2c-da93-475e-9cdf-9ef9a66742b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35652,DS-407d4173-0b06-4da1-8508-de3c331e03e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45010,DS-5d35e1d3-3494-46b4-a7ca-9f22c93bfc1a,DISK], DatanodeInfoWithStorage[127.0.0.1:42989,DS-11614c5c-4305-4635-9a24-46d2e6a013f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42517,DS-bd00b52d-42f5-4c0e-a17a-852b3247cf0a,DISK], DatanodeInfoWithStorage[127.0.0.1:44770,DS-8a20c274-849c-44bc-86c7-bc8f6f1f60b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42294,DS-7888c963-9b08-4554-92e0-37eef82b2a14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2003274291-172.17.0.5-1597689563517:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43974,DS-456cb536-4c98-4c05-b847-b6a88aa62c30,DISK], DatanodeInfoWithStorage[127.0.0.1:44208,DS-73f7ff7f-1b32-4999-b61d-220fde2032f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46078,DS-2cb60720-bb44-4892-94e3-a859583209c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35378,DS-62d2a41f-694d-4c98-8c6e-180725a0da54,DISK], DatanodeInfoWithStorage[127.0.0.1:43717,DS-76414a84-8748-4dab-ae41-fc0f05c3bcc8,DISK], DatanodeInfoWithStorage[127.0.0.1:43881,DS-15403311-6415-4881-bf67-396bdebbbb8b,DISK], DatanodeInfoWithStorage[127.0.0.1:40151,DS-dbc94582-033d-466f-bc8b-159dc73f5038,DISK], DatanodeInfoWithStorage[127.0.0.1:44197,DS-2db88d89-59d1-4582-b035-6311bbe7b776,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2003274291-172.17.0.5-1597689563517:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43974,DS-456cb536-4c98-4c05-b847-b6a88aa62c30,DISK], DatanodeInfoWithStorage[127.0.0.1:44208,DS-73f7ff7f-1b32-4999-b61d-220fde2032f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46078,DS-2cb60720-bb44-4892-94e3-a859583209c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35378,DS-62d2a41f-694d-4c98-8c6e-180725a0da54,DISK], DatanodeInfoWithStorage[127.0.0.1:43717,DS-76414a84-8748-4dab-ae41-fc0f05c3bcc8,DISK], DatanodeInfoWithStorage[127.0.0.1:43881,DS-15403311-6415-4881-bf67-396bdebbbb8b,DISK], DatanodeInfoWithStorage[127.0.0.1:40151,DS-dbc94582-033d-466f-bc8b-159dc73f5038,DISK], DatanodeInfoWithStorage[127.0.0.1:44197,DS-2db88d89-59d1-4582-b035-6311bbe7b776,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5416
