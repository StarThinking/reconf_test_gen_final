reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 60
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 60
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1944178345-172.17.0.21-1597739963745:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36330,DS-bc2d1fe4-ff8d-4543-815c-07708cb68f18,DISK], DatanodeInfoWithStorage[127.0.0.1:36179,DS-0da49582-6f3b-481e-8049-b79c76c318f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36242,DS-48c0c2da-53e8-4c19-9feb-c1fc3aa83bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:44211,DS-a11c7875-f83e-4687-808a-b5d5d9981869,DISK], DatanodeInfoWithStorage[127.0.0.1:34281,DS-3a8d050c-0735-4e57-b5de-5925716eef05,DISK], DatanodeInfoWithStorage[127.0.0.1:44624,DS-a2b04e4c-986b-42ed-9786-fdf1e6c8a777,DISK], DatanodeInfoWithStorage[127.0.0.1:39049,DS-638d54ca-3300-4d08-bdb9-689968b3ecd8,DISK], DatanodeInfoWithStorage[127.0.0.1:40357,DS-cca7e9e4-e253-49d5-9ccf-31cf1013728a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1944178345-172.17.0.21-1597739963745:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36330,DS-bc2d1fe4-ff8d-4543-815c-07708cb68f18,DISK], DatanodeInfoWithStorage[127.0.0.1:36179,DS-0da49582-6f3b-481e-8049-b79c76c318f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36242,DS-48c0c2da-53e8-4c19-9feb-c1fc3aa83bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:44211,DS-a11c7875-f83e-4687-808a-b5d5d9981869,DISK], DatanodeInfoWithStorage[127.0.0.1:34281,DS-3a8d050c-0735-4e57-b5de-5925716eef05,DISK], DatanodeInfoWithStorage[127.0.0.1:44624,DS-a2b04e4c-986b-42ed-9786-fdf1e6c8a777,DISK], DatanodeInfoWithStorage[127.0.0.1:39049,DS-638d54ca-3300-4d08-bdb9-689968b3ecd8,DISK], DatanodeInfoWithStorage[127.0.0.1:40357,DS-cca7e9e4-e253-49d5-9ccf-31cf1013728a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 60
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-957015552-172.17.0.21-1597740151336:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38984,DS-6082b737-b4b9-42b5-b611-c1e971215f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:35343,DS-08c65c3c-30f0-438b-9fec-0a1e886a70ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45794,DS-0bbd15b9-3c3d-4e60-b0a7-5fa9a1b9ea73,DISK], DatanodeInfoWithStorage[127.0.0.1:43416,DS-cd82acd7-67a5-4ffc-b708-45ea31a4d5ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45374,DS-c7658e17-2d7b-4842-bca8-a4bb53e83a99,DISK], DatanodeInfoWithStorage[127.0.0.1:34306,DS-2a30ddbd-af67-4171-8119-53936dd8df87,DISK], DatanodeInfoWithStorage[127.0.0.1:38476,DS-d1d25bfc-50d8-40c4-828f-b105447f1544,DISK], DatanodeInfoWithStorage[127.0.0.1:35794,DS-bc259012-7cdd-408f-a307-8286f2e448ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-957015552-172.17.0.21-1597740151336:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38984,DS-6082b737-b4b9-42b5-b611-c1e971215f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:35343,DS-08c65c3c-30f0-438b-9fec-0a1e886a70ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45794,DS-0bbd15b9-3c3d-4e60-b0a7-5fa9a1b9ea73,DISK], DatanodeInfoWithStorage[127.0.0.1:43416,DS-cd82acd7-67a5-4ffc-b708-45ea31a4d5ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45374,DS-c7658e17-2d7b-4842-bca8-a4bb53e83a99,DISK], DatanodeInfoWithStorage[127.0.0.1:34306,DS-2a30ddbd-af67-4171-8119-53936dd8df87,DISK], DatanodeInfoWithStorage[127.0.0.1:38476,DS-d1d25bfc-50d8-40c4-828f-b105447f1544,DISK], DatanodeInfoWithStorage[127.0.0.1:35794,DS-bc259012-7cdd-408f-a307-8286f2e448ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 60
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-864967818-172.17.0.21-1597740205057:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35951,DS-fe123edb-fa4a-416f-860e-86cc69297e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38884,DS-e7b4c0ba-3ab5-41a5-b850-a9338fdb0520,DISK], DatanodeInfoWithStorage[127.0.0.1:40904,DS-cf3f519f-c780-4fb3-ae7f-4fe20e695511,DISK], DatanodeInfoWithStorage[127.0.0.1:41793,DS-c446bf93-a640-4fa5-8fdc-faf696c8c647,DISK], DatanodeInfoWithStorage[127.0.0.1:41095,DS-5c8cad7b-5c15-4834-a8c7-56252be7f0c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42095,DS-b445deb2-dfe0-42bc-9368-81e01a89c2df,DISK], DatanodeInfoWithStorage[127.0.0.1:35710,DS-f3913580-8012-4834-bcd1-29d8f9a27acb,DISK], DatanodeInfoWithStorage[127.0.0.1:33177,DS-0961fb66-76ad-44fc-9dbb-98daddc10d36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-864967818-172.17.0.21-1597740205057:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35951,DS-fe123edb-fa4a-416f-860e-86cc69297e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38884,DS-e7b4c0ba-3ab5-41a5-b850-a9338fdb0520,DISK], DatanodeInfoWithStorage[127.0.0.1:40904,DS-cf3f519f-c780-4fb3-ae7f-4fe20e695511,DISK], DatanodeInfoWithStorage[127.0.0.1:41793,DS-c446bf93-a640-4fa5-8fdc-faf696c8c647,DISK], DatanodeInfoWithStorage[127.0.0.1:41095,DS-5c8cad7b-5c15-4834-a8c7-56252be7f0c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42095,DS-b445deb2-dfe0-42bc-9368-81e01a89c2df,DISK], DatanodeInfoWithStorage[127.0.0.1:35710,DS-f3913580-8012-4834-bcd1-29d8f9a27acb,DISK], DatanodeInfoWithStorage[127.0.0.1:33177,DS-0961fb66-76ad-44fc-9dbb-98daddc10d36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 60
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-546117661-172.17.0.21-1597740373923:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42885,DS-6f3b298a-90fa-4912-ba2a-faef2f03087b,DISK], DatanodeInfoWithStorage[127.0.0.1:42735,DS-d04edc89-16cf-4979-a2c5-a2dd421bdbfe,DISK], DatanodeInfoWithStorage[127.0.0.1:39967,DS-b0dca375-2b30-4f4f-bd22-c70472af52bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33075,DS-fcb35f91-11ab-41ce-854f-8424f7cb9304,DISK], DatanodeInfoWithStorage[127.0.0.1:36291,DS-868ee959-c353-48d3-afc9-6d66a492676a,DISK], DatanodeInfoWithStorage[127.0.0.1:38658,DS-c3abaaec-4c72-4dbb-978b-7d7c08d814bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34156,DS-c0744a4d-d249-476f-a994-4540c5be3701,DISK], DatanodeInfoWithStorage[127.0.0.1:37602,DS-e6bf9e6c-a0b1-4d0f-8aa6-004fd8bb3365,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-546117661-172.17.0.21-1597740373923:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42885,DS-6f3b298a-90fa-4912-ba2a-faef2f03087b,DISK], DatanodeInfoWithStorage[127.0.0.1:42735,DS-d04edc89-16cf-4979-a2c5-a2dd421bdbfe,DISK], DatanodeInfoWithStorage[127.0.0.1:39967,DS-b0dca375-2b30-4f4f-bd22-c70472af52bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33075,DS-fcb35f91-11ab-41ce-854f-8424f7cb9304,DISK], DatanodeInfoWithStorage[127.0.0.1:36291,DS-868ee959-c353-48d3-afc9-6d66a492676a,DISK], DatanodeInfoWithStorage[127.0.0.1:38658,DS-c3abaaec-4c72-4dbb-978b-7d7c08d814bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34156,DS-c0744a4d-d249-476f-a994-4540c5be3701,DISK], DatanodeInfoWithStorage[127.0.0.1:37602,DS-e6bf9e6c-a0b1-4d0f-8aa6-004fd8bb3365,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 60
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-639058930-172.17.0.21-1597740947617:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35266,DS-85f55422-a7c5-4374-a827-50459edfa166,DISK], DatanodeInfoWithStorage[127.0.0.1:45466,DS-cfe6d99a-e04a-476a-a245-2293058dc47d,DISK], DatanodeInfoWithStorage[127.0.0.1:33120,DS-16503b92-cbad-4a35-bd2f-12dfd2109d23,DISK], DatanodeInfoWithStorage[127.0.0.1:39509,DS-cdbc44d8-8db7-46d1-a8eb-26136109d4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34295,DS-ebfafdde-2d7c-480d-854e-e6646cc4a4bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45698,DS-2edd9d6c-eed3-48b6-be82-e0ccb51671c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43559,DS-fd3dfd5b-93a5-496d-97b6-9c527f354ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:32817,DS-27505398-5018-40e4-9477-1f12c8c5d1a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-639058930-172.17.0.21-1597740947617:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35266,DS-85f55422-a7c5-4374-a827-50459edfa166,DISK], DatanodeInfoWithStorage[127.0.0.1:45466,DS-cfe6d99a-e04a-476a-a245-2293058dc47d,DISK], DatanodeInfoWithStorage[127.0.0.1:33120,DS-16503b92-cbad-4a35-bd2f-12dfd2109d23,DISK], DatanodeInfoWithStorage[127.0.0.1:39509,DS-cdbc44d8-8db7-46d1-a8eb-26136109d4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34295,DS-ebfafdde-2d7c-480d-854e-e6646cc4a4bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45698,DS-2edd9d6c-eed3-48b6-be82-e0ccb51671c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43559,DS-fd3dfd5b-93a5-496d-97b6-9c527f354ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:32817,DS-27505398-5018-40e4-9477-1f12c8c5d1a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 60
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2107129034-172.17.0.21-1597741324018:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43982,DS-021b8fe4-445e-4995-bfb7-7a82d3c46236,DISK], DatanodeInfoWithStorage[127.0.0.1:34471,DS-efb4fa22-d6d3-41a2-9d78-f33d9c27f366,DISK], DatanodeInfoWithStorage[127.0.0.1:39821,DS-3f03ea22-ed2b-48e9-9ddd-138329105b35,DISK], DatanodeInfoWithStorage[127.0.0.1:38175,DS-127815d1-b5c3-4dc4-93d1-32d5438e847a,DISK], DatanodeInfoWithStorage[127.0.0.1:36099,DS-cfa1f80a-f0ab-4055-9583-b3e5eb9a95cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41222,DS-6ec87d0c-89e7-49be-9198-d6c524deb5b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39337,DS-01265afa-6b55-407c-ad3a-970749ea32e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33473,DS-ed2c6804-7964-4a26-9673-be947bfb6e5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2107129034-172.17.0.21-1597741324018:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43982,DS-021b8fe4-445e-4995-bfb7-7a82d3c46236,DISK], DatanodeInfoWithStorage[127.0.0.1:34471,DS-efb4fa22-d6d3-41a2-9d78-f33d9c27f366,DISK], DatanodeInfoWithStorage[127.0.0.1:39821,DS-3f03ea22-ed2b-48e9-9ddd-138329105b35,DISK], DatanodeInfoWithStorage[127.0.0.1:38175,DS-127815d1-b5c3-4dc4-93d1-32d5438e847a,DISK], DatanodeInfoWithStorage[127.0.0.1:36099,DS-cfa1f80a-f0ab-4055-9583-b3e5eb9a95cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41222,DS-6ec87d0c-89e7-49be-9198-d6c524deb5b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39337,DS-01265afa-6b55-407c-ad3a-970749ea32e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33473,DS-ed2c6804-7964-4a26-9673-be947bfb6e5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 60
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-258251828-172.17.0.21-1597741888362:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33484,DS-f2212efa-efd1-42d2-9415-07cb14296368,DISK], DatanodeInfoWithStorage[127.0.0.1:42454,DS-2940396d-7327-4089-863f-c40aebbe1985,DISK], DatanodeInfoWithStorage[127.0.0.1:43790,DS-7c5d788a-afec-471e-9ae1-23438aaf0036,DISK], DatanodeInfoWithStorage[127.0.0.1:36272,DS-e42d668d-38ce-422a-82a5-5da9066e448c,DISK], DatanodeInfoWithStorage[127.0.0.1:37457,DS-9c26f938-fc7b-4a44-9510-f7951133486e,DISK], DatanodeInfoWithStorage[127.0.0.1:40477,DS-fd409f22-4b18-4abe-b21f-987256321721,DISK], DatanodeInfoWithStorage[127.0.0.1:42988,DS-3af2a40f-a529-4e07-a4d7-b87ceaa068e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45576,DS-20e06d78-df2a-431e-9fa5-1cee204ba9a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-258251828-172.17.0.21-1597741888362:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33484,DS-f2212efa-efd1-42d2-9415-07cb14296368,DISK], DatanodeInfoWithStorage[127.0.0.1:42454,DS-2940396d-7327-4089-863f-c40aebbe1985,DISK], DatanodeInfoWithStorage[127.0.0.1:43790,DS-7c5d788a-afec-471e-9ae1-23438aaf0036,DISK], DatanodeInfoWithStorage[127.0.0.1:36272,DS-e42d668d-38ce-422a-82a5-5da9066e448c,DISK], DatanodeInfoWithStorage[127.0.0.1:37457,DS-9c26f938-fc7b-4a44-9510-f7951133486e,DISK], DatanodeInfoWithStorage[127.0.0.1:40477,DS-fd409f22-4b18-4abe-b21f-987256321721,DISK], DatanodeInfoWithStorage[127.0.0.1:42988,DS-3af2a40f-a529-4e07-a4d7-b87ceaa068e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45576,DS-20e06d78-df2a-431e-9fa5-1cee204ba9a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 60
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-307038308-172.17.0.21-1597742017834:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36839,DS-f85d7083-29b6-4b46-b370-e6f575ad490f,DISK], DatanodeInfoWithStorage[127.0.0.1:35784,DS-600f4f5c-a525-4ead-9cd5-593f3efc2156,DISK], DatanodeInfoWithStorage[127.0.0.1:38057,DS-620e4ddf-5452-48c4-9565-e9ca934307ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34022,DS-077967c8-a773-4d45-bba2-cc903dacb6b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45464,DS-8e6c550a-7574-4023-804e-c1251c1e0ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:40455,DS-8f49e7d3-32d7-45ae-88c7-a3d6d7ac2897,DISK], DatanodeInfoWithStorage[127.0.0.1:35593,DS-6de66d14-637c-4128-aa58-38a3217458be,DISK], DatanodeInfoWithStorage[127.0.0.1:39044,DS-26f3ca7a-aaf4-4683-9087-830b95412614,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-307038308-172.17.0.21-1597742017834:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36839,DS-f85d7083-29b6-4b46-b370-e6f575ad490f,DISK], DatanodeInfoWithStorage[127.0.0.1:35784,DS-600f4f5c-a525-4ead-9cd5-593f3efc2156,DISK], DatanodeInfoWithStorage[127.0.0.1:38057,DS-620e4ddf-5452-48c4-9565-e9ca934307ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34022,DS-077967c8-a773-4d45-bba2-cc903dacb6b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45464,DS-8e6c550a-7574-4023-804e-c1251c1e0ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:40455,DS-8f49e7d3-32d7-45ae-88c7-a3d6d7ac2897,DISK], DatanodeInfoWithStorage[127.0.0.1:35593,DS-6de66d14-637c-4128-aa58-38a3217458be,DISK], DatanodeInfoWithStorage[127.0.0.1:39044,DS-26f3ca7a-aaf4-4683-9087-830b95412614,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 60
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1271704585-172.17.0.21-1597742434463:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32988,DS-5f2a8b8b-a0ab-4d47-9a45-0dd1ae69e145,DISK], DatanodeInfoWithStorage[127.0.0.1:35637,DS-38f808a0-2316-415d-ab1d-39380192414e,DISK], DatanodeInfoWithStorage[127.0.0.1:38812,DS-df36182f-b509-43fa-8250-35fafd4571f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46498,DS-9bf7dbd1-2468-49ee-b75c-1835f8a169ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43803,DS-68a84f08-7fe1-4ce9-a3cd-f79101aac26b,DISK], DatanodeInfoWithStorage[127.0.0.1:40748,DS-92a49ad7-beb2-483c-90f9-1e71df70fbf1,DISK], DatanodeInfoWithStorage[127.0.0.1:35214,DS-e4fcca99-0dc5-47b7-8148-72d9ae8e89e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33112,DS-0ed2e004-23f0-4d1d-8954-cc358fb1deba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1271704585-172.17.0.21-1597742434463:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32988,DS-5f2a8b8b-a0ab-4d47-9a45-0dd1ae69e145,DISK], DatanodeInfoWithStorage[127.0.0.1:35637,DS-38f808a0-2316-415d-ab1d-39380192414e,DISK], DatanodeInfoWithStorage[127.0.0.1:38812,DS-df36182f-b509-43fa-8250-35fafd4571f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46498,DS-9bf7dbd1-2468-49ee-b75c-1835f8a169ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43803,DS-68a84f08-7fe1-4ce9-a3cd-f79101aac26b,DISK], DatanodeInfoWithStorage[127.0.0.1:40748,DS-92a49ad7-beb2-483c-90f9-1e71df70fbf1,DISK], DatanodeInfoWithStorage[127.0.0.1:35214,DS-e4fcca99-0dc5-47b7-8148-72d9ae8e89e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33112,DS-0ed2e004-23f0-4d1d-8954-cc358fb1deba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 60
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-693776828-172.17.0.21-1597742580798:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42978,DS-ff042d4a-8d65-45b6-8d09-2048b281a1a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35267,DS-48841ee3-7c16-4dcb-bea2-454c6ee4d9f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42982,DS-5dcac981-1a7b-4f4a-9e4b-772415524144,DISK], DatanodeInfoWithStorage[127.0.0.1:33258,DS-fa2373b1-3495-411a-b798-890e7b49b68e,DISK], DatanodeInfoWithStorage[127.0.0.1:38422,DS-a8e73ef0-4388-44ed-954c-28962eeafe4b,DISK], DatanodeInfoWithStorage[127.0.0.1:36081,DS-1ebb5e96-a591-49c7-a894-01886e901a38,DISK], DatanodeInfoWithStorage[127.0.0.1:39418,DS-7c9dc9e1-58aa-4200-96ee-3aca2745eb2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42190,DS-8f4b8cf4-7fd6-47b5-a8ed-9188ee94e46a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-693776828-172.17.0.21-1597742580798:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42978,DS-ff042d4a-8d65-45b6-8d09-2048b281a1a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35267,DS-48841ee3-7c16-4dcb-bea2-454c6ee4d9f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42982,DS-5dcac981-1a7b-4f4a-9e4b-772415524144,DISK], DatanodeInfoWithStorage[127.0.0.1:33258,DS-fa2373b1-3495-411a-b798-890e7b49b68e,DISK], DatanodeInfoWithStorage[127.0.0.1:38422,DS-a8e73ef0-4388-44ed-954c-28962eeafe4b,DISK], DatanodeInfoWithStorage[127.0.0.1:36081,DS-1ebb5e96-a591-49c7-a894-01886e901a38,DISK], DatanodeInfoWithStorage[127.0.0.1:39418,DS-7c9dc9e1-58aa-4200-96ee-3aca2745eb2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42190,DS-8f4b8cf4-7fd6-47b5-a8ed-9188ee94e46a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 60
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1722330593-172.17.0.21-1597742769604:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41367,DS-ef06a886-fbc4-4041-8cd7-e07d6f33041b,DISK], DatanodeInfoWithStorage[127.0.0.1:35365,DS-18d02a89-8f52-41fd-be83-808967c1cac6,DISK], DatanodeInfoWithStorage[127.0.0.1:33322,DS-95c97922-9859-43fd-9780-864b05f75959,DISK], DatanodeInfoWithStorage[127.0.0.1:35093,DS-fc54768c-a6b0-4615-91d0-6ae021e53cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:43478,DS-86c98603-9d7c-4c3c-8106-880989d4da8f,DISK], DatanodeInfoWithStorage[127.0.0.1:34476,DS-07f2220a-804b-4c3f-9175-a735c7f3d973,DISK], DatanodeInfoWithStorage[127.0.0.1:37486,DS-f94aa0a0-fad3-41b2-bc5e-c2e42eb848c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45133,DS-570e0a17-2e5b-46c6-a4bb-a499cc9391f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1722330593-172.17.0.21-1597742769604:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41367,DS-ef06a886-fbc4-4041-8cd7-e07d6f33041b,DISK], DatanodeInfoWithStorage[127.0.0.1:35365,DS-18d02a89-8f52-41fd-be83-808967c1cac6,DISK], DatanodeInfoWithStorage[127.0.0.1:33322,DS-95c97922-9859-43fd-9780-864b05f75959,DISK], DatanodeInfoWithStorage[127.0.0.1:35093,DS-fc54768c-a6b0-4615-91d0-6ae021e53cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:43478,DS-86c98603-9d7c-4c3c-8106-880989d4da8f,DISK], DatanodeInfoWithStorage[127.0.0.1:34476,DS-07f2220a-804b-4c3f-9175-a735c7f3d973,DISK], DatanodeInfoWithStorage[127.0.0.1:37486,DS-f94aa0a0-fad3-41b2-bc5e-c2e42eb848c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45133,DS-570e0a17-2e5b-46c6-a4bb-a499cc9391f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 60
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1447193539-172.17.0.21-1597743804232:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46247,DS-d89b4f70-7bf2-40f5-93f8-bc4afcdf7fee,DISK], DatanodeInfoWithStorage[127.0.0.1:37060,DS-19677f4d-8d63-4f8a-822a-38b4df9105d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39582,DS-d28db85f-fc18-415b-9a2b-9f27d7b2d7b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37672,DS-51b04dd5-6926-4aa0-aa6a-fd92a921f8ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44610,DS-c12dc468-a1d8-40b5-b0c9-b1cfa540e8eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35208,DS-485066f7-4e48-4227-873b-d80e46f883da,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-4e1e6ee6-e9ea-4ae9-ad77-0fc81a387b60,DISK], DatanodeInfoWithStorage[127.0.0.1:37621,DS-e016a0ea-8436-4a27-8eca-5ae57474c4e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1447193539-172.17.0.21-1597743804232:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46247,DS-d89b4f70-7bf2-40f5-93f8-bc4afcdf7fee,DISK], DatanodeInfoWithStorage[127.0.0.1:37060,DS-19677f4d-8d63-4f8a-822a-38b4df9105d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39582,DS-d28db85f-fc18-415b-9a2b-9f27d7b2d7b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37672,DS-51b04dd5-6926-4aa0-aa6a-fd92a921f8ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44610,DS-c12dc468-a1d8-40b5-b0c9-b1cfa540e8eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35208,DS-485066f7-4e48-4227-873b-d80e46f883da,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-4e1e6ee6-e9ea-4ae9-ad77-0fc81a387b60,DISK], DatanodeInfoWithStorage[127.0.0.1:37621,DS-e016a0ea-8436-4a27-8eca-5ae57474c4e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 60
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1502563962-172.17.0.21-1597744886866:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40987,DS-21a08b0d-4256-49b6-a9c5-8520584e014b,DISK], DatanodeInfoWithStorage[127.0.0.1:34938,DS-cbb043d7-5b2f-4a1d-ab1f-70c698343f14,DISK], DatanodeInfoWithStorage[127.0.0.1:32802,DS-61bbca09-0ed7-47b0-ba40-65f7c54c1d55,DISK], DatanodeInfoWithStorage[127.0.0.1:34094,DS-9ff957ac-a1e6-4fcc-9825-a5a67f5154dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43107,DS-a59e6de1-bf42-4c77-b704-53a5de8b0486,DISK], DatanodeInfoWithStorage[127.0.0.1:36376,DS-c0457ddc-dc63-4ccb-a20f-ea42e1e68402,DISK], DatanodeInfoWithStorage[127.0.0.1:44065,DS-f9d0989b-c046-449f-8259-8c7921a2d2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40153,DS-555aceb9-0028-4ed8-a756-6fd32f1ecf15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1502563962-172.17.0.21-1597744886866:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40987,DS-21a08b0d-4256-49b6-a9c5-8520584e014b,DISK], DatanodeInfoWithStorage[127.0.0.1:34938,DS-cbb043d7-5b2f-4a1d-ab1f-70c698343f14,DISK], DatanodeInfoWithStorage[127.0.0.1:32802,DS-61bbca09-0ed7-47b0-ba40-65f7c54c1d55,DISK], DatanodeInfoWithStorage[127.0.0.1:34094,DS-9ff957ac-a1e6-4fcc-9825-a5a67f5154dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43107,DS-a59e6de1-bf42-4c77-b704-53a5de8b0486,DISK], DatanodeInfoWithStorage[127.0.0.1:36376,DS-c0457ddc-dc63-4ccb-a20f-ea42e1e68402,DISK], DatanodeInfoWithStorage[127.0.0.1:44065,DS-f9d0989b-c046-449f-8259-8c7921a2d2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40153,DS-555aceb9-0028-4ed8-a756-6fd32f1ecf15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 60
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-89620465-172.17.0.21-1597746167223:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43515,DS-8fae2836-ca2e-498e-961a-786fd1a91e60,DISK], DatanodeInfoWithStorage[127.0.0.1:34046,DS-1cf50d5a-340f-4c89-8163-fc8d17824c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:38927,DS-e2b2b20e-f28f-471c-97b4-a949725d18eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39561,DS-c0993cd5-d029-47f2-8c6f-04ec5f68afe6,DISK], DatanodeInfoWithStorage[127.0.0.1:34178,DS-6d7db7ca-3904-4fa5-bfac-194ebebd726d,DISK], DatanodeInfoWithStorage[127.0.0.1:38513,DS-b8c35dc8-af01-4796-bc87-4d4dde0c2be3,DISK], DatanodeInfoWithStorage[127.0.0.1:41108,DS-9d930e72-f65f-4e3a-822f-b1e83c62dacf,DISK], DatanodeInfoWithStorage[127.0.0.1:43870,DS-2a16707f-d009-48d9-9fc1-928f45eda1ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-89620465-172.17.0.21-1597746167223:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43515,DS-8fae2836-ca2e-498e-961a-786fd1a91e60,DISK], DatanodeInfoWithStorage[127.0.0.1:34046,DS-1cf50d5a-340f-4c89-8163-fc8d17824c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:38927,DS-e2b2b20e-f28f-471c-97b4-a949725d18eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39561,DS-c0993cd5-d029-47f2-8c6f-04ec5f68afe6,DISK], DatanodeInfoWithStorage[127.0.0.1:34178,DS-6d7db7ca-3904-4fa5-bfac-194ebebd726d,DISK], DatanodeInfoWithStorage[127.0.0.1:38513,DS-b8c35dc8-af01-4796-bc87-4d4dde0c2be3,DISK], DatanodeInfoWithStorage[127.0.0.1:41108,DS-9d930e72-f65f-4e3a-822f-b1e83c62dacf,DISK], DatanodeInfoWithStorage[127.0.0.1:43870,DS-2a16707f-d009-48d9-9fc1-928f45eda1ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 7025
