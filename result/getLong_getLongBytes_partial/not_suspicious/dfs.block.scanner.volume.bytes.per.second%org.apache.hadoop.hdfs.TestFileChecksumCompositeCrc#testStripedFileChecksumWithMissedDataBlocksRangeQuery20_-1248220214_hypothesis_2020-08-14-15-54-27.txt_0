reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1315724974-172.17.0.14-1597420481968:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44660,DS-fdda803f-c6fa-4810-82f0-c82a46b9cee1,DISK], DatanodeInfoWithStorage[127.0.0.1:45709,DS-ceb6a5e2-3be9-4334-8cd4-066af144d4b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43713,DS-54249c1b-9743-41f3-975b-ddf274d08080,DISK], DatanodeInfoWithStorage[127.0.0.1:40106,DS-4a0c0bd9-0bda-49b8-a573-6a8677a3e780,DISK], DatanodeInfoWithStorage[127.0.0.1:41424,DS-eca073c2-82a2-418f-90bb-c1aca24e0970,DISK], DatanodeInfoWithStorage[127.0.0.1:43533,DS-a1433d46-612d-43b5-8a81-4164e501bc12,DISK], DatanodeInfoWithStorage[127.0.0.1:42200,DS-5d868789-eb60-4ca1-a584-527b5df15529,DISK], DatanodeInfoWithStorage[127.0.0.1:37994,DS-5528ac52-1461-42d0-800f-03574ac408d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1315724974-172.17.0.14-1597420481968:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44660,DS-fdda803f-c6fa-4810-82f0-c82a46b9cee1,DISK], DatanodeInfoWithStorage[127.0.0.1:45709,DS-ceb6a5e2-3be9-4334-8cd4-066af144d4b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43713,DS-54249c1b-9743-41f3-975b-ddf274d08080,DISK], DatanodeInfoWithStorage[127.0.0.1:40106,DS-4a0c0bd9-0bda-49b8-a573-6a8677a3e780,DISK], DatanodeInfoWithStorage[127.0.0.1:41424,DS-eca073c2-82a2-418f-90bb-c1aca24e0970,DISK], DatanodeInfoWithStorage[127.0.0.1:43533,DS-a1433d46-612d-43b5-8a81-4164e501bc12,DISK], DatanodeInfoWithStorage[127.0.0.1:42200,DS-5d868789-eb60-4ca1-a584-527b5df15529,DISK], DatanodeInfoWithStorage[127.0.0.1:37994,DS-5528ac52-1461-42d0-800f-03574ac408d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1837047913-172.17.0.14-1597422197048:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34381,DS-84e90ca4-3bf9-42f8-9a19-aab1cb401c59,DISK], DatanodeInfoWithStorage[127.0.0.1:43727,DS-e97b03a6-864d-45cd-98bb-29bd46268cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:41312,DS-aa257ff0-715f-4ace-8772-11acbc1c9f05,DISK], DatanodeInfoWithStorage[127.0.0.1:42770,DS-b0c676e7-af5f-4fc0-9546-01dabc9c103c,DISK], DatanodeInfoWithStorage[127.0.0.1:46254,DS-32b0bea3-e723-4756-92ba-b520461ff088,DISK], DatanodeInfoWithStorage[127.0.0.1:35783,DS-f50d9885-52bc-497d-986a-a4666bbbda37,DISK], DatanodeInfoWithStorage[127.0.0.1:46192,DS-f51044b5-d03c-47ed-8f22-50495b23053e,DISK], DatanodeInfoWithStorage[127.0.0.1:45152,DS-f39a8fde-381e-4a2d-9407-dc80ec4840bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1837047913-172.17.0.14-1597422197048:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34381,DS-84e90ca4-3bf9-42f8-9a19-aab1cb401c59,DISK], DatanodeInfoWithStorage[127.0.0.1:43727,DS-e97b03a6-864d-45cd-98bb-29bd46268cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:41312,DS-aa257ff0-715f-4ace-8772-11acbc1c9f05,DISK], DatanodeInfoWithStorage[127.0.0.1:42770,DS-b0c676e7-af5f-4fc0-9546-01dabc9c103c,DISK], DatanodeInfoWithStorage[127.0.0.1:46254,DS-32b0bea3-e723-4756-92ba-b520461ff088,DISK], DatanodeInfoWithStorage[127.0.0.1:35783,DS-f50d9885-52bc-497d-986a-a4666bbbda37,DISK], DatanodeInfoWithStorage[127.0.0.1:46192,DS-f51044b5-d03c-47ed-8f22-50495b23053e,DISK], DatanodeInfoWithStorage[127.0.0.1:45152,DS-f39a8fde-381e-4a2d-9407-dc80ec4840bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1600489736-172.17.0.14-1597422780991:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42686,DS-a86ef997-b9cc-4314-83d8-11f1f8adc87b,DISK], DatanodeInfoWithStorage[127.0.0.1:36186,DS-0ddafdf4-7507-4192-9f57-a6141dfd8008,DISK], DatanodeInfoWithStorage[127.0.0.1:43547,DS-632a9d8c-c464-4bbc-9889-1df7373521d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35879,DS-c4e731f3-79a5-4de7-b0b2-bb867eecad28,DISK], DatanodeInfoWithStorage[127.0.0.1:37726,DS-22f003ef-c6a2-427a-a3f7-55e342cc6cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:34264,DS-85f93bf4-2acf-4852-af9b-0f453c869ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:45567,DS-f44bfecb-d4aa-479a-9f42-802970e52aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:41537,DS-4382c9d5-4b46-4603-8884-405fdb18deab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1600489736-172.17.0.14-1597422780991:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42686,DS-a86ef997-b9cc-4314-83d8-11f1f8adc87b,DISK], DatanodeInfoWithStorage[127.0.0.1:36186,DS-0ddafdf4-7507-4192-9f57-a6141dfd8008,DISK], DatanodeInfoWithStorage[127.0.0.1:43547,DS-632a9d8c-c464-4bbc-9889-1df7373521d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35879,DS-c4e731f3-79a5-4de7-b0b2-bb867eecad28,DISK], DatanodeInfoWithStorage[127.0.0.1:37726,DS-22f003ef-c6a2-427a-a3f7-55e342cc6cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:34264,DS-85f93bf4-2acf-4852-af9b-0f453c869ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:45567,DS-f44bfecb-d4aa-479a-9f42-802970e52aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:41537,DS-4382c9d5-4b46-4603-8884-405fdb18deab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1837579215-172.17.0.14-1597423345541:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42490,DS-bb034956-71e3-4850-bddb-98858803020b,DISK], DatanodeInfoWithStorage[127.0.0.1:44244,DS-a88b8e24-0b78-4772-9835-1a975e53db3e,DISK], DatanodeInfoWithStorage[127.0.0.1:43027,DS-a0fa4d44-74f8-4521-a916-018f4f755aad,DISK], DatanodeInfoWithStorage[127.0.0.1:46237,DS-edbb4b59-c9a1-4c4f-bb28-626ea59628bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39117,DS-7843dda7-c573-40a7-b4ad-915b3c8889ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43532,DS-63212361-d233-4c91-abc5-930746ba6a23,DISK], DatanodeInfoWithStorage[127.0.0.1:37671,DS-5a5872ee-be9f-4655-a860-07997f6c24b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37520,DS-99422845-4c79-419f-9236-cb0b42f8a227,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1837579215-172.17.0.14-1597423345541:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42490,DS-bb034956-71e3-4850-bddb-98858803020b,DISK], DatanodeInfoWithStorage[127.0.0.1:44244,DS-a88b8e24-0b78-4772-9835-1a975e53db3e,DISK], DatanodeInfoWithStorage[127.0.0.1:43027,DS-a0fa4d44-74f8-4521-a916-018f4f755aad,DISK], DatanodeInfoWithStorage[127.0.0.1:46237,DS-edbb4b59-c9a1-4c4f-bb28-626ea59628bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39117,DS-7843dda7-c573-40a7-b4ad-915b3c8889ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43532,DS-63212361-d233-4c91-abc5-930746ba6a23,DISK], DatanodeInfoWithStorage[127.0.0.1:37671,DS-5a5872ee-be9f-4655-a860-07997f6c24b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37520,DS-99422845-4c79-419f-9236-cb0b42f8a227,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-43431039-172.17.0.14-1597424274174:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43712,DS-d576e57a-3e50-4e3a-af67-a08e9c387ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:34529,DS-2161351b-fa05-42e1-bc8d-b212357e7f33,DISK], DatanodeInfoWithStorage[127.0.0.1:42324,DS-b9b64f34-2873-4ed0-bc01-2f0e0e2a6ead,DISK], DatanodeInfoWithStorage[127.0.0.1:37220,DS-2085b020-5438-496d-a5ee-5d2c8b9aa445,DISK], DatanodeInfoWithStorage[127.0.0.1:41348,DS-8dc81492-39e5-4db4-8199-ea17ecb76469,DISK], DatanodeInfoWithStorage[127.0.0.1:32940,DS-1d0635f6-9ebc-401f-99c0-dbf87a797a63,DISK], DatanodeInfoWithStorage[127.0.0.1:41407,DS-1729784c-bf19-4d8d-8ddc-6a2de0a9581b,DISK], DatanodeInfoWithStorage[127.0.0.1:35055,DS-7ac9d1a2-3005-4120-a130-bdb32c9c68a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-43431039-172.17.0.14-1597424274174:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43712,DS-d576e57a-3e50-4e3a-af67-a08e9c387ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:34529,DS-2161351b-fa05-42e1-bc8d-b212357e7f33,DISK], DatanodeInfoWithStorage[127.0.0.1:42324,DS-b9b64f34-2873-4ed0-bc01-2f0e0e2a6ead,DISK], DatanodeInfoWithStorage[127.0.0.1:37220,DS-2085b020-5438-496d-a5ee-5d2c8b9aa445,DISK], DatanodeInfoWithStorage[127.0.0.1:41348,DS-8dc81492-39e5-4db4-8199-ea17ecb76469,DISK], DatanodeInfoWithStorage[127.0.0.1:32940,DS-1d0635f6-9ebc-401f-99c0-dbf87a797a63,DISK], DatanodeInfoWithStorage[127.0.0.1:41407,DS-1729784c-bf19-4d8d-8ddc-6a2de0a9581b,DISK], DatanodeInfoWithStorage[127.0.0.1:35055,DS-7ac9d1a2-3005-4120-a130-bdb32c9c68a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-597552653-172.17.0.14-1597425411752:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36123,DS-953b5708-db10-4543-83d4-70bc723b60f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39673,DS-d5288857-f5a4-4294-a983-dd83e2250b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:45994,DS-86bf7f5a-0688-4e20-a316-1259733df859,DISK], DatanodeInfoWithStorage[127.0.0.1:36882,DS-38324a80-1813-46cc-9517-1e4eee9ceb1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44607,DS-73ec1a5e-ae2d-47c5-aa7c-2ed35f2cc316,DISK], DatanodeInfoWithStorage[127.0.0.1:44379,DS-54b599b9-5166-43ff-8fae-7ead8b076013,DISK], DatanodeInfoWithStorage[127.0.0.1:37414,DS-10c6ef68-6b8f-446b-a7c2-d861756611de,DISK], DatanodeInfoWithStorage[127.0.0.1:33195,DS-765b3f35-73aa-47b5-83cd-7b4058197912,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-597552653-172.17.0.14-1597425411752:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36123,DS-953b5708-db10-4543-83d4-70bc723b60f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39673,DS-d5288857-f5a4-4294-a983-dd83e2250b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:45994,DS-86bf7f5a-0688-4e20-a316-1259733df859,DISK], DatanodeInfoWithStorage[127.0.0.1:36882,DS-38324a80-1813-46cc-9517-1e4eee9ceb1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44607,DS-73ec1a5e-ae2d-47c5-aa7c-2ed35f2cc316,DISK], DatanodeInfoWithStorage[127.0.0.1:44379,DS-54b599b9-5166-43ff-8fae-7ead8b076013,DISK], DatanodeInfoWithStorage[127.0.0.1:37414,DS-10c6ef68-6b8f-446b-a7c2-d861756611de,DISK], DatanodeInfoWithStorage[127.0.0.1:33195,DS-765b3f35-73aa-47b5-83cd-7b4058197912,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1390561190-172.17.0.14-1597425900321:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35382,DS-4458af5e-60b9-4569-84d0-b5a029af958f,DISK], DatanodeInfoWithStorage[127.0.0.1:32774,DS-2f5cf599-afaf-4251-b4d0-1a5387bc802a,DISK], DatanodeInfoWithStorage[127.0.0.1:40500,DS-0e9387be-318c-4ee4-b7bf-6c1a92d471cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37034,DS-7105b643-2cbf-470a-98ca-b9b5f54c6117,DISK], DatanodeInfoWithStorage[127.0.0.1:35867,DS-c07970e1-dd18-4908-920b-129d6ba695db,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-ae8df0ad-edd0-4205-9119-81f1c161d930,DISK], DatanodeInfoWithStorage[127.0.0.1:39884,DS-738e64b8-8135-44e4-a95c-6ccfd0353ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:34207,DS-d20dfc8f-16d7-4556-8e94-efb1a7001a39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1390561190-172.17.0.14-1597425900321:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35382,DS-4458af5e-60b9-4569-84d0-b5a029af958f,DISK], DatanodeInfoWithStorage[127.0.0.1:32774,DS-2f5cf599-afaf-4251-b4d0-1a5387bc802a,DISK], DatanodeInfoWithStorage[127.0.0.1:40500,DS-0e9387be-318c-4ee4-b7bf-6c1a92d471cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37034,DS-7105b643-2cbf-470a-98ca-b9b5f54c6117,DISK], DatanodeInfoWithStorage[127.0.0.1:35867,DS-c07970e1-dd18-4908-920b-129d6ba695db,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-ae8df0ad-edd0-4205-9119-81f1c161d930,DISK], DatanodeInfoWithStorage[127.0.0.1:39884,DS-738e64b8-8135-44e4-a95c-6ccfd0353ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:34207,DS-d20dfc8f-16d7-4556-8e94-efb1a7001a39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1536738111-172.17.0.14-1597425938327:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46267,DS-aee03d7e-a05a-40f3-b1ca-654d22c391b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43401,DS-97de8220-dec7-4c29-aa33-89c6fd535099,DISK], DatanodeInfoWithStorage[127.0.0.1:42728,DS-bfd4a152-4c99-45d4-8476-6937c1f85749,DISK], DatanodeInfoWithStorage[127.0.0.1:44972,DS-6596d5c6-102e-44e6-9869-808b4b1539ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33060,DS-60a437a5-6186-4291-ac41-ac09b5016af2,DISK], DatanodeInfoWithStorage[127.0.0.1:37665,DS-a985be3e-c70c-4bdb-9e38-f5fdb3e5e1d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43409,DS-1eded497-bd6e-4516-bb72-d0ce7d75134a,DISK], DatanodeInfoWithStorage[127.0.0.1:46282,DS-f0149118-b9f2-48b2-9099-ebf12dbc199b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1536738111-172.17.0.14-1597425938327:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46267,DS-aee03d7e-a05a-40f3-b1ca-654d22c391b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43401,DS-97de8220-dec7-4c29-aa33-89c6fd535099,DISK], DatanodeInfoWithStorage[127.0.0.1:42728,DS-bfd4a152-4c99-45d4-8476-6937c1f85749,DISK], DatanodeInfoWithStorage[127.0.0.1:44972,DS-6596d5c6-102e-44e6-9869-808b4b1539ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33060,DS-60a437a5-6186-4291-ac41-ac09b5016af2,DISK], DatanodeInfoWithStorage[127.0.0.1:37665,DS-a985be3e-c70c-4bdb-9e38-f5fdb3e5e1d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43409,DS-1eded497-bd6e-4516-bb72-d0ce7d75134a,DISK], DatanodeInfoWithStorage[127.0.0.1:46282,DS-f0149118-b9f2-48b2-9099-ebf12dbc199b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1130353782-172.17.0.14-1597426596082:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46052,DS-b7385230-fed8-40ed-aedf-28a24f8825ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42750,DS-5025b8e3-8cc3-478f-af6b-e8e3a7907b37,DISK], DatanodeInfoWithStorage[127.0.0.1:39488,DS-26fa7e6a-fb92-4d06-8d13-cfc2e6aee00a,DISK], DatanodeInfoWithStorage[127.0.0.1:41827,DS-6ad14143-5835-4082-bcf0-b6b8a56e2a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:42980,DS-4816f685-adfd-40ea-a8ed-0ccf5f5c5e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44523,DS-38db3269-9ed8-46f9-b8a8-f6249a7a1b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:45498,DS-634d2912-416a-444d-ba8c-2c74f72b2719,DISK], DatanodeInfoWithStorage[127.0.0.1:43455,DS-7511dbbf-e0c3-4c8d-8c87-6ff8a757fb23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1130353782-172.17.0.14-1597426596082:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46052,DS-b7385230-fed8-40ed-aedf-28a24f8825ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42750,DS-5025b8e3-8cc3-478f-af6b-e8e3a7907b37,DISK], DatanodeInfoWithStorage[127.0.0.1:39488,DS-26fa7e6a-fb92-4d06-8d13-cfc2e6aee00a,DISK], DatanodeInfoWithStorage[127.0.0.1:41827,DS-6ad14143-5835-4082-bcf0-b6b8a56e2a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:42980,DS-4816f685-adfd-40ea-a8ed-0ccf5f5c5e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44523,DS-38db3269-9ed8-46f9-b8a8-f6249a7a1b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:45498,DS-634d2912-416a-444d-ba8c-2c74f72b2719,DISK], DatanodeInfoWithStorage[127.0.0.1:43455,DS-7511dbbf-e0c3-4c8d-8c87-6ff8a757fb23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-467013893-172.17.0.14-1597426861253:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39723,DS-09fb3ad7-1055-4071-99cc-e13aec4b60c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45024,DS-0b2d1829-585b-4318-a89e-35e46ba236ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36788,DS-ead3e672-1ca6-4995-9231-4dc4713f5c72,DISK], DatanodeInfoWithStorage[127.0.0.1:37383,DS-28f9a386-d3e3-4440-aac5-bb2204417c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39784,DS-54f3c5c6-9922-4862-bb84-1f9ef979337e,DISK], DatanodeInfoWithStorage[127.0.0.1:38163,DS-48afd949-092f-46e4-9829-1f57f3e4d1d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45438,DS-1d4a88d1-26af-4eb3-8195-2ce10e6b7bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:39010,DS-f6be810b-9b97-45e6-8359-e8cdb7d27793,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-467013893-172.17.0.14-1597426861253:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39723,DS-09fb3ad7-1055-4071-99cc-e13aec4b60c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45024,DS-0b2d1829-585b-4318-a89e-35e46ba236ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36788,DS-ead3e672-1ca6-4995-9231-4dc4713f5c72,DISK], DatanodeInfoWithStorage[127.0.0.1:37383,DS-28f9a386-d3e3-4440-aac5-bb2204417c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39784,DS-54f3c5c6-9922-4862-bb84-1f9ef979337e,DISK], DatanodeInfoWithStorage[127.0.0.1:38163,DS-48afd949-092f-46e4-9829-1f57f3e4d1d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45438,DS-1d4a88d1-26af-4eb3-8195-2ce10e6b7bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:39010,DS-f6be810b-9b97-45e6-8359-e8cdb7d27793,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 6832
