reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1391943781-172.17.0.6-1597736798192:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32944,DS-7f4c9541-8ac4-44f2-8a39-12b370ce4a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35059,DS-311fa8c3-e002-429a-86ac-a88c213776f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39597,DS-b504d93d-391b-4b51-8980-abf64f7fd5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37642,DS-a9c196e1-76af-4645-9f90-6d4fa0393108,DISK], DatanodeInfoWithStorage[127.0.0.1:42439,DS-af5818ae-bc9b-4574-afec-a040e25085bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42413,DS-0108e78a-bd06-441a-a3d4-4c8199559d01,DISK], DatanodeInfoWithStorage[127.0.0.1:46839,DS-dddc61b3-f0d5-4b9b-949d-3b23cb165fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:39387,DS-eb5a781c-d81d-439d-87f9-46bccf195cf9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1391943781-172.17.0.6-1597736798192:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32944,DS-7f4c9541-8ac4-44f2-8a39-12b370ce4a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35059,DS-311fa8c3-e002-429a-86ac-a88c213776f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39597,DS-b504d93d-391b-4b51-8980-abf64f7fd5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37642,DS-a9c196e1-76af-4645-9f90-6d4fa0393108,DISK], DatanodeInfoWithStorage[127.0.0.1:42439,DS-af5818ae-bc9b-4574-afec-a040e25085bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42413,DS-0108e78a-bd06-441a-a3d4-4c8199559d01,DISK], DatanodeInfoWithStorage[127.0.0.1:46839,DS-dddc61b3-f0d5-4b9b-949d-3b23cb165fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:39387,DS-eb5a781c-d81d-439d-87f9-46bccf195cf9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1186382553-172.17.0.6-1597737095852:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46317,DS-19a92a99-414a-46bf-be3d-7862c151e6f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38375,DS-90b55440-25f4-4f68-ac55-1e2baa18add1,DISK], DatanodeInfoWithStorage[127.0.0.1:39057,DS-ef42c797-61cc-4145-a414-e3bc602a5eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:43300,DS-61ef6a4c-686d-4cdf-a0f3-cdc30eed28d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38398,DS-f202dc71-ce8f-4401-a907-5deb959270d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36498,DS-aae652c7-be3f-4855-a5b9-efbe06479e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:37466,DS-4d00db07-13ba-47db-9b9c-ec7e6bb7112b,DISK], DatanodeInfoWithStorage[127.0.0.1:44706,DS-ca92ccba-8719-401c-bddd-05b504d405ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1186382553-172.17.0.6-1597737095852:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46317,DS-19a92a99-414a-46bf-be3d-7862c151e6f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38375,DS-90b55440-25f4-4f68-ac55-1e2baa18add1,DISK], DatanodeInfoWithStorage[127.0.0.1:39057,DS-ef42c797-61cc-4145-a414-e3bc602a5eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:43300,DS-61ef6a4c-686d-4cdf-a0f3-cdc30eed28d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38398,DS-f202dc71-ce8f-4401-a907-5deb959270d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36498,DS-aae652c7-be3f-4855-a5b9-efbe06479e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:37466,DS-4d00db07-13ba-47db-9b9c-ec7e6bb7112b,DISK], DatanodeInfoWithStorage[127.0.0.1:44706,DS-ca92ccba-8719-401c-bddd-05b504d405ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-178553316-172.17.0.6-1597737528861:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40247,DS-3eae1dc7-eaa6-4432-b3cc-75096c2bd587,DISK], DatanodeInfoWithStorage[127.0.0.1:42802,DS-3f7817a8-ae9f-4ad6-8de9-376dbd527ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:34925,DS-f77c5290-e4d7-4b29-a910-3953abf8b200,DISK], DatanodeInfoWithStorage[127.0.0.1:33650,DS-8e89ecdd-fb0e-4b02-a2e6-2ed6128809f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42077,DS-dab585d8-a677-449e-91c8-3c3b2ebd4f57,DISK], DatanodeInfoWithStorage[127.0.0.1:35186,DS-3a08bb3b-06a5-445a-8338-88e88f4e99d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42832,DS-0a9efad9-fb7b-422f-a2cc-89f2efaa67e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39695,DS-4e2d17b7-9fae-47d2-8d94-67b7ce7bf989,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-178553316-172.17.0.6-1597737528861:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40247,DS-3eae1dc7-eaa6-4432-b3cc-75096c2bd587,DISK], DatanodeInfoWithStorage[127.0.0.1:42802,DS-3f7817a8-ae9f-4ad6-8de9-376dbd527ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:34925,DS-f77c5290-e4d7-4b29-a910-3953abf8b200,DISK], DatanodeInfoWithStorage[127.0.0.1:33650,DS-8e89ecdd-fb0e-4b02-a2e6-2ed6128809f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42077,DS-dab585d8-a677-449e-91c8-3c3b2ebd4f57,DISK], DatanodeInfoWithStorage[127.0.0.1:35186,DS-3a08bb3b-06a5-445a-8338-88e88f4e99d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42832,DS-0a9efad9-fb7b-422f-a2cc-89f2efaa67e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39695,DS-4e2d17b7-9fae-47d2-8d94-67b7ce7bf989,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1508601109-172.17.0.6-1597737575333:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44687,DS-50be4568-e4c3-46c8-88bb-d0b610530d89,DISK], DatanodeInfoWithStorage[127.0.0.1:39426,DS-2f1f20ce-5a26-4dfa-9c21-fe24bfc7bee1,DISK], DatanodeInfoWithStorage[127.0.0.1:34907,DS-a127257d-86c0-4a7f-936f-df9d64a50de4,DISK], DatanodeInfoWithStorage[127.0.0.1:33827,DS-ac3c5ba2-d556-4740-aad6-6b543c74fe73,DISK], DatanodeInfoWithStorage[127.0.0.1:46843,DS-7f97e33c-e821-4e1c-b931-6c005461a998,DISK], DatanodeInfoWithStorage[127.0.0.1:34808,DS-20380641-f14b-4d89-a88b-afe30a9f8804,DISK], DatanodeInfoWithStorage[127.0.0.1:40256,DS-42d8fb81-4e14-4e9e-b9ff-fb986be81209,DISK], DatanodeInfoWithStorage[127.0.0.1:33347,DS-12ebbecd-e223-4263-bca7-a30c9ee9d039,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1508601109-172.17.0.6-1597737575333:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44687,DS-50be4568-e4c3-46c8-88bb-d0b610530d89,DISK], DatanodeInfoWithStorage[127.0.0.1:39426,DS-2f1f20ce-5a26-4dfa-9c21-fe24bfc7bee1,DISK], DatanodeInfoWithStorage[127.0.0.1:34907,DS-a127257d-86c0-4a7f-936f-df9d64a50de4,DISK], DatanodeInfoWithStorage[127.0.0.1:33827,DS-ac3c5ba2-d556-4740-aad6-6b543c74fe73,DISK], DatanodeInfoWithStorage[127.0.0.1:46843,DS-7f97e33c-e821-4e1c-b931-6c005461a998,DISK], DatanodeInfoWithStorage[127.0.0.1:34808,DS-20380641-f14b-4d89-a88b-afe30a9f8804,DISK], DatanodeInfoWithStorage[127.0.0.1:40256,DS-42d8fb81-4e14-4e9e-b9ff-fb986be81209,DISK], DatanodeInfoWithStorage[127.0.0.1:33347,DS-12ebbecd-e223-4263-bca7-a30c9ee9d039,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1637611779-172.17.0.6-1597737909142:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40508,DS-56922511-4cd7-43f5-a213-5a334e1664b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35158,DS-90662a3e-63c2-498e-912d-81e50834fced,DISK], DatanodeInfoWithStorage[127.0.0.1:37449,DS-8d232c42-33c7-4e80-a33e-ed86e61eb7e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42272,DS-8c83fe5a-3bc3-443a-bafa-121f6f371fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:38348,DS-ca816bb1-a51b-4117-be73-653b21e76243,DISK], DatanodeInfoWithStorage[127.0.0.1:45819,DS-0f7d138d-339d-4c25-b7b3-75d416c07909,DISK], DatanodeInfoWithStorage[127.0.0.1:34153,DS-df6d02a4-e485-471c-8920-b49ebd30e94d,DISK], DatanodeInfoWithStorage[127.0.0.1:37344,DS-e02372f8-421c-46b8-8fdd-71928df4af1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1637611779-172.17.0.6-1597737909142:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40508,DS-56922511-4cd7-43f5-a213-5a334e1664b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35158,DS-90662a3e-63c2-498e-912d-81e50834fced,DISK], DatanodeInfoWithStorage[127.0.0.1:37449,DS-8d232c42-33c7-4e80-a33e-ed86e61eb7e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42272,DS-8c83fe5a-3bc3-443a-bafa-121f6f371fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:38348,DS-ca816bb1-a51b-4117-be73-653b21e76243,DISK], DatanodeInfoWithStorage[127.0.0.1:45819,DS-0f7d138d-339d-4c25-b7b3-75d416c07909,DISK], DatanodeInfoWithStorage[127.0.0.1:34153,DS-df6d02a4-e485-471c-8920-b49ebd30e94d,DISK], DatanodeInfoWithStorage[127.0.0.1:37344,DS-e02372f8-421c-46b8-8fdd-71928df4af1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2102600625-172.17.0.6-1597738199200:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40709,DS-18f9717c-9bf5-4950-8091-140b22926024,DISK], DatanodeInfoWithStorage[127.0.0.1:35304,DS-351a4029-3662-4b5a-bcb1-589201791fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:34933,DS-72a0c0ed-b53f-4e62-b0f9-21d85eaa2641,DISK], DatanodeInfoWithStorage[127.0.0.1:37379,DS-80422281-73fb-448e-8291-262470725cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:46525,DS-4b457cd2-66dc-4927-af76-1e0805b842a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37678,DS-e80acc72-d935-494e-b97d-cc7d42a4950f,DISK], DatanodeInfoWithStorage[127.0.0.1:44698,DS-7a8b6c91-3db9-45a3-99d9-6ea3622fd43c,DISK], DatanodeInfoWithStorage[127.0.0.1:44068,DS-0cf86db5-994c-450e-9fa7-e50c52cf176e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2102600625-172.17.0.6-1597738199200:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40709,DS-18f9717c-9bf5-4950-8091-140b22926024,DISK], DatanodeInfoWithStorage[127.0.0.1:35304,DS-351a4029-3662-4b5a-bcb1-589201791fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:34933,DS-72a0c0ed-b53f-4e62-b0f9-21d85eaa2641,DISK], DatanodeInfoWithStorage[127.0.0.1:37379,DS-80422281-73fb-448e-8291-262470725cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:46525,DS-4b457cd2-66dc-4927-af76-1e0805b842a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37678,DS-e80acc72-d935-494e-b97d-cc7d42a4950f,DISK], DatanodeInfoWithStorage[127.0.0.1:44698,DS-7a8b6c91-3db9-45a3-99d9-6ea3622fd43c,DISK], DatanodeInfoWithStorage[127.0.0.1:44068,DS-0cf86db5-994c-450e-9fa7-e50c52cf176e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1254157695-172.17.0.6-1597738464082:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39446,DS-fc490da8-7290-408f-8762-ba5e195420b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35232,DS-45971970-e233-4ded-b56f-e67bd16b660f,DISK], DatanodeInfoWithStorage[127.0.0.1:42820,DS-12591a4a-b6dc-412d-aba8-c283d34c0c08,DISK], DatanodeInfoWithStorage[127.0.0.1:45071,DS-0804eae4-3700-499c-a336-837370c025ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34000,DS-e4a26cd3-0627-4902-8abf-458dbc1ee013,DISK], DatanodeInfoWithStorage[127.0.0.1:40880,DS-813f3ec8-d429-435b-b7b8-560e881a3bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:37126,DS-9ea041c5-2f0f-4414-8ecf-c5c50f71253e,DISK], DatanodeInfoWithStorage[127.0.0.1:42506,DS-26ecb755-fd14-4a8d-930a-6d02d06251dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1254157695-172.17.0.6-1597738464082:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39446,DS-fc490da8-7290-408f-8762-ba5e195420b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35232,DS-45971970-e233-4ded-b56f-e67bd16b660f,DISK], DatanodeInfoWithStorage[127.0.0.1:42820,DS-12591a4a-b6dc-412d-aba8-c283d34c0c08,DISK], DatanodeInfoWithStorage[127.0.0.1:45071,DS-0804eae4-3700-499c-a336-837370c025ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34000,DS-e4a26cd3-0627-4902-8abf-458dbc1ee013,DISK], DatanodeInfoWithStorage[127.0.0.1:40880,DS-813f3ec8-d429-435b-b7b8-560e881a3bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:37126,DS-9ea041c5-2f0f-4414-8ecf-c5c50f71253e,DISK], DatanodeInfoWithStorage[127.0.0.1:42506,DS-26ecb755-fd14-4a8d-930a-6d02d06251dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1989151529-172.17.0.6-1597738498985:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39521,DS-a0ef1c16-0902-40b6-a91b-903e373280c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43871,DS-965c039f-e101-4dd0-babf-998367b91dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:46294,DS-d4d4a6a3-63e6-44b8-9ac8-385e29c1602a,DISK], DatanodeInfoWithStorage[127.0.0.1:38248,DS-128fe328-a1a5-4789-bbdc-4fbc4d753482,DISK], DatanodeInfoWithStorage[127.0.0.1:33788,DS-7e1b3f0c-4d92-42df-812c-08d296755b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44897,DS-64731af3-2aac-486f-9b87-d9f3a8ff05c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40740,DS-7c6c6593-0d70-442a-9273-f43bb1522bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:38676,DS-db5eac66-53df-47d1-89a5-2279c60a6a74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1989151529-172.17.0.6-1597738498985:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39521,DS-a0ef1c16-0902-40b6-a91b-903e373280c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43871,DS-965c039f-e101-4dd0-babf-998367b91dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:46294,DS-d4d4a6a3-63e6-44b8-9ac8-385e29c1602a,DISK], DatanodeInfoWithStorage[127.0.0.1:38248,DS-128fe328-a1a5-4789-bbdc-4fbc4d753482,DISK], DatanodeInfoWithStorage[127.0.0.1:33788,DS-7e1b3f0c-4d92-42df-812c-08d296755b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44897,DS-64731af3-2aac-486f-9b87-d9f3a8ff05c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40740,DS-7c6c6593-0d70-442a-9273-f43bb1522bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:38676,DS-db5eac66-53df-47d1-89a5-2279c60a6a74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1649132926-172.17.0.6-1597739028884:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41551,DS-e8815596-4fd5-4159-951c-1dbf7db31f23,DISK], DatanodeInfoWithStorage[127.0.0.1:39956,DS-41931f90-9e3d-4784-a644-99218856bb1c,DISK], DatanodeInfoWithStorage[127.0.0.1:33949,DS-cc0351f1-42c3-42ba-af96-ec3f485b17d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39013,DS-01f8adaa-84a0-452a-81ba-d39c77b23f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:45046,DS-c9f44452-05fe-4ea3-b781-bdb95af655b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41590,DS-df15d84c-e6d2-4c48-a22c-d423345c725c,DISK], DatanodeInfoWithStorage[127.0.0.1:40455,DS-87eab77f-04f8-4343-974e-c27c2d4d9b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:38833,DS-ca353c6b-57cc-427d-9ff6-2543c30f9ff2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1649132926-172.17.0.6-1597739028884:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41551,DS-e8815596-4fd5-4159-951c-1dbf7db31f23,DISK], DatanodeInfoWithStorage[127.0.0.1:39956,DS-41931f90-9e3d-4784-a644-99218856bb1c,DISK], DatanodeInfoWithStorage[127.0.0.1:33949,DS-cc0351f1-42c3-42ba-af96-ec3f485b17d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39013,DS-01f8adaa-84a0-452a-81ba-d39c77b23f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:45046,DS-c9f44452-05fe-4ea3-b781-bdb95af655b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41590,DS-df15d84c-e6d2-4c48-a22c-d423345c725c,DISK], DatanodeInfoWithStorage[127.0.0.1:40455,DS-87eab77f-04f8-4343-974e-c27c2d4d9b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:38833,DS-ca353c6b-57cc-427d-9ff6-2543c30f9ff2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1805505697-172.17.0.6-1597740084579:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45882,DS-37d62313-8d26-4aa2-b084-2c1b990f9310,DISK], DatanodeInfoWithStorage[127.0.0.1:43602,DS-f8fef7e9-b68e-4556-93c2-9874ce80d9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45374,DS-ce3018e9-9ec0-4118-8855-4bc90295fd31,DISK], DatanodeInfoWithStorage[127.0.0.1:40616,DS-c046987e-8f1f-4c42-946e-93b69624d2eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41683,DS-43b204dd-6689-435a-a29e-a851d198d662,DISK], DatanodeInfoWithStorage[127.0.0.1:45371,DS-ebc2436d-4091-4bc2-8cc2-40be0c93f716,DISK], DatanodeInfoWithStorage[127.0.0.1:45360,DS-7765d9fc-af3d-4e0c-89c6-6ad7f0d8b8a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40387,DS-393551af-d34a-42ce-adae-1315456ebb30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1805505697-172.17.0.6-1597740084579:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45882,DS-37d62313-8d26-4aa2-b084-2c1b990f9310,DISK], DatanodeInfoWithStorage[127.0.0.1:43602,DS-f8fef7e9-b68e-4556-93c2-9874ce80d9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45374,DS-ce3018e9-9ec0-4118-8855-4bc90295fd31,DISK], DatanodeInfoWithStorage[127.0.0.1:40616,DS-c046987e-8f1f-4c42-946e-93b69624d2eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41683,DS-43b204dd-6689-435a-a29e-a851d198d662,DISK], DatanodeInfoWithStorage[127.0.0.1:45371,DS-ebc2436d-4091-4bc2-8cc2-40be0c93f716,DISK], DatanodeInfoWithStorage[127.0.0.1:45360,DS-7765d9fc-af3d-4e0c-89c6-6ad7f0d8b8a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40387,DS-393551af-d34a-42ce-adae-1315456ebb30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-528536133-172.17.0.6-1597740601255:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38881,DS-c33ce034-6cc8-460e-842b-7b815ce65ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:38468,DS-4212b03e-1a2e-4316-a4ca-11e0cad339cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44689,DS-1de8367f-784e-4514-b5d6-00c04abbf49d,DISK], DatanodeInfoWithStorage[127.0.0.1:38961,DS-83fa6438-b134-4d45-b2d8-b3df35cc67a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43821,DS-b0831a1d-c2e5-4f0e-88fa-6ee28532b0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44032,DS-39d44cf1-3c2b-4939-aec3-a7c72e3f73cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44830,DS-a0e31d46-51e6-4c72-8f4d-bc84bae1b307,DISK], DatanodeInfoWithStorage[127.0.0.1:34728,DS-6a1cc3d9-2078-4b96-b774-7254a81d68db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-528536133-172.17.0.6-1597740601255:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38881,DS-c33ce034-6cc8-460e-842b-7b815ce65ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:38468,DS-4212b03e-1a2e-4316-a4ca-11e0cad339cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44689,DS-1de8367f-784e-4514-b5d6-00c04abbf49d,DISK], DatanodeInfoWithStorage[127.0.0.1:38961,DS-83fa6438-b134-4d45-b2d8-b3df35cc67a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43821,DS-b0831a1d-c2e5-4f0e-88fa-6ee28532b0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44032,DS-39d44cf1-3c2b-4939-aec3-a7c72e3f73cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44830,DS-a0e31d46-51e6-4c72-8f4d-bc84bae1b307,DISK], DatanodeInfoWithStorage[127.0.0.1:34728,DS-6a1cc3d9-2078-4b96-b774-7254a81d68db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-88262052-172.17.0.6-1597740854069:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44864,DS-7adba5e7-a0cb-4e68-b604-1353a1111c23,DISK], DatanodeInfoWithStorage[127.0.0.1:34208,DS-4759bbc7-7544-4cf1-b8f4-df517aa6fee0,DISK], DatanodeInfoWithStorage[127.0.0.1:43296,DS-7e972a92-1cf8-438d-9434-ede1aa28b0d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42720,DS-3af5cfea-cb6f-416c-8f01-fe1fbd71bfba,DISK], DatanodeInfoWithStorage[127.0.0.1:38479,DS-330f1285-d84b-4971-82fc-9ae0e95819f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36281,DS-4fc945d9-0bd5-4ceb-874e-02dba830a4ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38008,DS-b71edca5-edc8-401f-a20b-2bc75e5ae848,DISK], DatanodeInfoWithStorage[127.0.0.1:46827,DS-2f73674d-bb07-4f1a-808f-de6663013c07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-88262052-172.17.0.6-1597740854069:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44864,DS-7adba5e7-a0cb-4e68-b604-1353a1111c23,DISK], DatanodeInfoWithStorage[127.0.0.1:34208,DS-4759bbc7-7544-4cf1-b8f4-df517aa6fee0,DISK], DatanodeInfoWithStorage[127.0.0.1:43296,DS-7e972a92-1cf8-438d-9434-ede1aa28b0d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42720,DS-3af5cfea-cb6f-416c-8f01-fe1fbd71bfba,DISK], DatanodeInfoWithStorage[127.0.0.1:38479,DS-330f1285-d84b-4971-82fc-9ae0e95819f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36281,DS-4fc945d9-0bd5-4ceb-874e-02dba830a4ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38008,DS-b71edca5-edc8-401f-a20b-2bc75e5ae848,DISK], DatanodeInfoWithStorage[127.0.0.1:46827,DS-2f73674d-bb07-4f1a-808f-de6663013c07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1224876927-172.17.0.6-1597741479168:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40622,DS-12d8c825-c914-4116-9a6d-842c2624b851,DISK], DatanodeInfoWithStorage[127.0.0.1:42739,DS-3acabf59-df5d-4f4a-a62d-54d42b2f14d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46448,DS-f16ccb06-9570-4064-94bd-bbf9ee3da318,DISK], DatanodeInfoWithStorage[127.0.0.1:32779,DS-fb2fb6b5-691a-476a-a3a2-9c144e7ed0d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34048,DS-65736136-dad8-48e1-81c8-390c17ead1f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37153,DS-358ce9db-7528-4a8c-827b-2d92783268f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40830,DS-aafd6031-7c4d-4453-8ab1-1ae28f2f0051,DISK], DatanodeInfoWithStorage[127.0.0.1:41861,DS-cb439f43-e30d-4fe6-afa3-6d8396e391de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1224876927-172.17.0.6-1597741479168:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40622,DS-12d8c825-c914-4116-9a6d-842c2624b851,DISK], DatanodeInfoWithStorage[127.0.0.1:42739,DS-3acabf59-df5d-4f4a-a62d-54d42b2f14d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46448,DS-f16ccb06-9570-4064-94bd-bbf9ee3da318,DISK], DatanodeInfoWithStorage[127.0.0.1:32779,DS-fb2fb6b5-691a-476a-a3a2-9c144e7ed0d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34048,DS-65736136-dad8-48e1-81c8-390c17ead1f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37153,DS-358ce9db-7528-4a8c-827b-2d92783268f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40830,DS-aafd6031-7c4d-4453-8ab1-1ae28f2f0051,DISK], DatanodeInfoWithStorage[127.0.0.1:41861,DS-cb439f43-e30d-4fe6-afa3-6d8396e391de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-305730283-172.17.0.6-1597742325970:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38553,DS-b03de1f1-4f58-4985-bc08-97c77b994bad,DISK], DatanodeInfoWithStorage[127.0.0.1:45816,DS-0f2d71fb-e809-42bc-b8a1-ea6acb73d3ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46105,DS-0aa13126-b9ec-4bd1-81d5-c7373a5f062b,DISK], DatanodeInfoWithStorage[127.0.0.1:39014,DS-06457224-8b21-4287-b661-73885303a751,DISK], DatanodeInfoWithStorage[127.0.0.1:38352,DS-161b77e2-5bdf-4ead-9b16-05c74295acd4,DISK], DatanodeInfoWithStorage[127.0.0.1:37422,DS-27437d07-c2f6-4c84-b27c-ac86223987b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46236,DS-a4c77427-bf7d-4e00-a7eb-ff1fb894068e,DISK], DatanodeInfoWithStorage[127.0.0.1:42473,DS-1e96af01-b7a4-4302-aeb2-df29d22e581b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-305730283-172.17.0.6-1597742325970:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38553,DS-b03de1f1-4f58-4985-bc08-97c77b994bad,DISK], DatanodeInfoWithStorage[127.0.0.1:45816,DS-0f2d71fb-e809-42bc-b8a1-ea6acb73d3ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46105,DS-0aa13126-b9ec-4bd1-81d5-c7373a5f062b,DISK], DatanodeInfoWithStorage[127.0.0.1:39014,DS-06457224-8b21-4287-b661-73885303a751,DISK], DatanodeInfoWithStorage[127.0.0.1:38352,DS-161b77e2-5bdf-4ead-9b16-05c74295acd4,DISK], DatanodeInfoWithStorage[127.0.0.1:37422,DS-27437d07-c2f6-4c84-b27c-ac86223987b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46236,DS-a4c77427-bf7d-4e00-a7eb-ff1fb894068e,DISK], DatanodeInfoWithStorage[127.0.0.1:42473,DS-1e96af01-b7a4-4302-aeb2-df29d22e581b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1033023161-172.17.0.6-1597742422252:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38079,DS-829dfbef-88b3-46b8-a3ef-8a90431c3d63,DISK], DatanodeInfoWithStorage[127.0.0.1:44657,DS-4dcfa579-2670-4a7c-a065-8ccfef6c47b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44074,DS-ab37b4ee-d9bd-4889-be52-1a8bbeb7cbe5,DISK], DatanodeInfoWithStorage[127.0.0.1:35303,DS-74af9973-1e54-4875-bb05-7dff32daec07,DISK], DatanodeInfoWithStorage[127.0.0.1:37539,DS-94dc8479-d0c7-4f4d-8704-8f22524f56ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37030,DS-3928ff84-5a84-4bb5-b245-82bb8418d88e,DISK], DatanodeInfoWithStorage[127.0.0.1:39061,DS-e947e47a-0c4e-4637-ad00-d3b0393d8964,DISK], DatanodeInfoWithStorage[127.0.0.1:46431,DS-58ffbc67-2db2-40f9-b730-4c49d7918cc8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1033023161-172.17.0.6-1597742422252:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38079,DS-829dfbef-88b3-46b8-a3ef-8a90431c3d63,DISK], DatanodeInfoWithStorage[127.0.0.1:44657,DS-4dcfa579-2670-4a7c-a065-8ccfef6c47b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44074,DS-ab37b4ee-d9bd-4889-be52-1a8bbeb7cbe5,DISK], DatanodeInfoWithStorage[127.0.0.1:35303,DS-74af9973-1e54-4875-bb05-7dff32daec07,DISK], DatanodeInfoWithStorage[127.0.0.1:37539,DS-94dc8479-d0c7-4f4d-8704-8f22524f56ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37030,DS-3928ff84-5a84-4bb5-b245-82bb8418d88e,DISK], DatanodeInfoWithStorage[127.0.0.1:39061,DS-e947e47a-0c4e-4637-ad00-d3b0393d8964,DISK], DatanodeInfoWithStorage[127.0.0.1:46431,DS-58ffbc67-2db2-40f9-b730-4c49d7918cc8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1319383952-172.17.0.6-1597742610869:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44279,DS-715e71a0-bbf4-40c8-b341-ea175ad65727,DISK], DatanodeInfoWithStorage[127.0.0.1:45002,DS-8bf52c71-8419-47d9-9ecc-92eabebdc2a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45744,DS-b4a21417-dd15-4430-9212-fec61d26bea0,DISK], DatanodeInfoWithStorage[127.0.0.1:35546,DS-11e0e61e-b202-4152-b43a-ea84c04bc607,DISK], DatanodeInfoWithStorage[127.0.0.1:34760,DS-e5957fef-c925-4f48-883c-6a1a5c391dab,DISK], DatanodeInfoWithStorage[127.0.0.1:39827,DS-52d635da-97bd-493c-a7d3-368275150fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:40928,DS-cd1f840a-3475-472f-8d81-d5d917677c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46783,DS-c8a175c0-a900-4f05-a681-77187da0c4d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1319383952-172.17.0.6-1597742610869:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44279,DS-715e71a0-bbf4-40c8-b341-ea175ad65727,DISK], DatanodeInfoWithStorage[127.0.0.1:45002,DS-8bf52c71-8419-47d9-9ecc-92eabebdc2a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45744,DS-b4a21417-dd15-4430-9212-fec61d26bea0,DISK], DatanodeInfoWithStorage[127.0.0.1:35546,DS-11e0e61e-b202-4152-b43a-ea84c04bc607,DISK], DatanodeInfoWithStorage[127.0.0.1:34760,DS-e5957fef-c925-4f48-883c-6a1a5c391dab,DISK], DatanodeInfoWithStorage[127.0.0.1:39827,DS-52d635da-97bd-493c-a7d3-368275150fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:40928,DS-cd1f840a-3475-472f-8d81-d5d917677c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46783,DS-c8a175c0-a900-4f05-a681-77187da0c4d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1287152331-172.17.0.6-1597742905696:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35060,DS-f5db28d8-af99-401e-956b-3774b06513f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43756,DS-b0c14a86-cd6a-4be8-bcfd-976c2c33a348,DISK], DatanodeInfoWithStorage[127.0.0.1:38454,DS-e3085547-541e-4d64-b945-ad93f4427c22,DISK], DatanodeInfoWithStorage[127.0.0.1:35533,DS-7bc2df7a-c6ee-4a69-832c-5e63e6438499,DISK], DatanodeInfoWithStorage[127.0.0.1:39320,DS-ce2780b7-c618-40cd-88d0-fab9716d8775,DISK], DatanodeInfoWithStorage[127.0.0.1:35831,DS-48c27fbc-4397-44c6-abab-013c4c93b1cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46543,DS-9c74b587-d94e-424e-914e-10a447740452,DISK], DatanodeInfoWithStorage[127.0.0.1:34431,DS-4472497f-b1dd-49ea-a534-c12c5ad78367,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1287152331-172.17.0.6-1597742905696:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35060,DS-f5db28d8-af99-401e-956b-3774b06513f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43756,DS-b0c14a86-cd6a-4be8-bcfd-976c2c33a348,DISK], DatanodeInfoWithStorage[127.0.0.1:38454,DS-e3085547-541e-4d64-b945-ad93f4427c22,DISK], DatanodeInfoWithStorage[127.0.0.1:35533,DS-7bc2df7a-c6ee-4a69-832c-5e63e6438499,DISK], DatanodeInfoWithStorage[127.0.0.1:39320,DS-ce2780b7-c618-40cd-88d0-fab9716d8775,DISK], DatanodeInfoWithStorage[127.0.0.1:35831,DS-48c27fbc-4397-44c6-abab-013c4c93b1cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46543,DS-9c74b587-d94e-424e-914e-10a447740452,DISK], DatanodeInfoWithStorage[127.0.0.1:34431,DS-4472497f-b1dd-49ea-a534-c12c5ad78367,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-941644016-172.17.0.6-1597743239724:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44471,DS-76641897-c387-408f-9aab-b99d699f1b84,DISK], DatanodeInfoWithStorage[127.0.0.1:37098,DS-bb5b070f-1b90-4294-8fa8-0a30a1af9869,DISK], DatanodeInfoWithStorage[127.0.0.1:35213,DS-41b2ea02-96f0-4351-bb36-021f48ebde87,DISK], DatanodeInfoWithStorage[127.0.0.1:33324,DS-3bd6b332-008f-4ab6-9d11-cac5d5e904f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46026,DS-3eb90a28-8b8b-43f6-b864-b5af83938c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:35669,DS-4eeeb8f7-4348-491b-998a-2e6b337b040c,DISK], DatanodeInfoWithStorage[127.0.0.1:35027,DS-ab3a4289-cb08-4b7f-ad13-7a49903284d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35002,DS-86afa220-4bee-40e2-b431-e98b1cada74f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-941644016-172.17.0.6-1597743239724:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44471,DS-76641897-c387-408f-9aab-b99d699f1b84,DISK], DatanodeInfoWithStorage[127.0.0.1:37098,DS-bb5b070f-1b90-4294-8fa8-0a30a1af9869,DISK], DatanodeInfoWithStorage[127.0.0.1:35213,DS-41b2ea02-96f0-4351-bb36-021f48ebde87,DISK], DatanodeInfoWithStorage[127.0.0.1:33324,DS-3bd6b332-008f-4ab6-9d11-cac5d5e904f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46026,DS-3eb90a28-8b8b-43f6-b864-b5af83938c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:35669,DS-4eeeb8f7-4348-491b-998a-2e6b337b040c,DISK], DatanodeInfoWithStorage[127.0.0.1:35027,DS-ab3a4289-cb08-4b7f-ad13-7a49903284d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35002,DS-86afa220-4bee-40e2-b431-e98b1cada74f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1106378008-172.17.0.6-1597743661015:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45430,DS-f041b47a-e8f6-40ba-bc78-088cb6e46d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:33101,DS-89301ae6-7082-4e06-8c43-d6e7e1b474fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41691,DS-d97aa5c3-054e-44e2-bd53-a7715ec4d614,DISK], DatanodeInfoWithStorage[127.0.0.1:44286,DS-6a5a3085-d735-4adb-87d0-473613b24928,DISK], DatanodeInfoWithStorage[127.0.0.1:42011,DS-64756c0f-c877-4d0e-8a44-fb0b325da49b,DISK], DatanodeInfoWithStorage[127.0.0.1:33400,DS-40057750-acb9-4a06-b929-e279f6c88c15,DISK], DatanodeInfoWithStorage[127.0.0.1:45830,DS-0d0ce417-e22d-46cd-83c1-e7ff3a3e2405,DISK], DatanodeInfoWithStorage[127.0.0.1:43199,DS-937f20ce-13e7-4ab0-b822-8ae377be0abe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1106378008-172.17.0.6-1597743661015:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45430,DS-f041b47a-e8f6-40ba-bc78-088cb6e46d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:33101,DS-89301ae6-7082-4e06-8c43-d6e7e1b474fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41691,DS-d97aa5c3-054e-44e2-bd53-a7715ec4d614,DISK], DatanodeInfoWithStorage[127.0.0.1:44286,DS-6a5a3085-d735-4adb-87d0-473613b24928,DISK], DatanodeInfoWithStorage[127.0.0.1:42011,DS-64756c0f-c877-4d0e-8a44-fb0b325da49b,DISK], DatanodeInfoWithStorage[127.0.0.1:33400,DS-40057750-acb9-4a06-b929-e279f6c88c15,DISK], DatanodeInfoWithStorage[127.0.0.1:45830,DS-0d0ce417-e22d-46cd-83c1-e7ff3a3e2405,DISK], DatanodeInfoWithStorage[127.0.0.1:43199,DS-937f20ce-13e7-4ab0-b822-8ae377be0abe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 7046
