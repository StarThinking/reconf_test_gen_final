reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1642392891-172.17.0.3-1597734800512:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42756,DS-6a084f24-a84a-4426-8bee-e52fb56e1a00,DISK], DatanodeInfoWithStorage[127.0.0.1:36490,DS-8a8b6a80-3096-485e-8047-50e48814e1c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38912,DS-befa5bd6-91df-4775-8ee2-c10fa746c583,DISK], DatanodeInfoWithStorage[127.0.0.1:37196,DS-fad1a180-154c-463e-b341-53f9f7b9d793,DISK], DatanodeInfoWithStorage[127.0.0.1:46599,DS-3930b7d8-8720-4210-a9f7-25728bfc3a34,DISK], DatanodeInfoWithStorage[127.0.0.1:36039,DS-8a5a5d7f-4905-4eb1-81b7-04a5d0aef6c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41126,DS-3a69af91-d980-4a4f-951f-9ecbe5d73df8,DISK], DatanodeInfoWithStorage[127.0.0.1:43399,DS-d7cdd321-3598-4768-9c56-a5ed066255fb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1642392891-172.17.0.3-1597734800512:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42756,DS-6a084f24-a84a-4426-8bee-e52fb56e1a00,DISK], DatanodeInfoWithStorage[127.0.0.1:36490,DS-8a8b6a80-3096-485e-8047-50e48814e1c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38912,DS-befa5bd6-91df-4775-8ee2-c10fa746c583,DISK], DatanodeInfoWithStorage[127.0.0.1:37196,DS-fad1a180-154c-463e-b341-53f9f7b9d793,DISK], DatanodeInfoWithStorage[127.0.0.1:46599,DS-3930b7d8-8720-4210-a9f7-25728bfc3a34,DISK], DatanodeInfoWithStorage[127.0.0.1:36039,DS-8a5a5d7f-4905-4eb1-81b7-04a5d0aef6c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41126,DS-3a69af91-d980-4a4f-951f-9ecbe5d73df8,DISK], DatanodeInfoWithStorage[127.0.0.1:43399,DS-d7cdd321-3598-4768-9c56-a5ed066255fb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1013298920-172.17.0.3-1597735018570:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45808,DS-b0c741a9-483f-4b1c-bc38-028286d496a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42134,DS-7cc28164-27eb-4075-ad55-c39070ddda9b,DISK], DatanodeInfoWithStorage[127.0.0.1:35718,DS-eb4e7cb9-586d-4cc0-aa61-15269b9505b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36774,DS-56e2abd8-c70f-41d7-a3e0-c6e8d6feca3a,DISK], DatanodeInfoWithStorage[127.0.0.1:40400,DS-9b229814-daf2-47e9-b40c-42e013a513aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38269,DS-e23f26bb-9b61-47d3-9705-ff8486a997dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34057,DS-3a552d9e-4db9-41d3-a254-8c1b1eab80bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46738,DS-a2432546-bec4-4acd-a78d-aed72ea2aba4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1013298920-172.17.0.3-1597735018570:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45808,DS-b0c741a9-483f-4b1c-bc38-028286d496a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42134,DS-7cc28164-27eb-4075-ad55-c39070ddda9b,DISK], DatanodeInfoWithStorage[127.0.0.1:35718,DS-eb4e7cb9-586d-4cc0-aa61-15269b9505b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36774,DS-56e2abd8-c70f-41d7-a3e0-c6e8d6feca3a,DISK], DatanodeInfoWithStorage[127.0.0.1:40400,DS-9b229814-daf2-47e9-b40c-42e013a513aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38269,DS-e23f26bb-9b61-47d3-9705-ff8486a997dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34057,DS-3a552d9e-4db9-41d3-a254-8c1b1eab80bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46738,DS-a2432546-bec4-4acd-a78d-aed72ea2aba4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-579709928-172.17.0.3-1597735366668:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43662,DS-fdb45dfc-31a4-45d7-a2ee-7fa161813284,DISK], DatanodeInfoWithStorage[127.0.0.1:42936,DS-9ead9856-579c-4c17-a8b3-dc9a46901d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:41037,DS-723b595a-80b0-4bf5-8ce3-605efb2d6043,DISK], DatanodeInfoWithStorage[127.0.0.1:40299,DS-6d977299-a1de-4c8d-a339-3902c9e58e71,DISK], DatanodeInfoWithStorage[127.0.0.1:36937,DS-3b024f5c-b2f5-4fd9-9c05-b23603c0e810,DISK], DatanodeInfoWithStorage[127.0.0.1:45823,DS-1d68c70f-29e8-4951-b22f-34aa8210a71f,DISK], DatanodeInfoWithStorage[127.0.0.1:34855,DS-91759faa-e8ce-4f9e-ba5c-f7e198f24934,DISK], DatanodeInfoWithStorage[127.0.0.1:34482,DS-832f6c7e-5857-4185-8380-dfbf2140abc8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-579709928-172.17.0.3-1597735366668:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43662,DS-fdb45dfc-31a4-45d7-a2ee-7fa161813284,DISK], DatanodeInfoWithStorage[127.0.0.1:42936,DS-9ead9856-579c-4c17-a8b3-dc9a46901d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:41037,DS-723b595a-80b0-4bf5-8ce3-605efb2d6043,DISK], DatanodeInfoWithStorage[127.0.0.1:40299,DS-6d977299-a1de-4c8d-a339-3902c9e58e71,DISK], DatanodeInfoWithStorage[127.0.0.1:36937,DS-3b024f5c-b2f5-4fd9-9c05-b23603c0e810,DISK], DatanodeInfoWithStorage[127.0.0.1:45823,DS-1d68c70f-29e8-4951-b22f-34aa8210a71f,DISK], DatanodeInfoWithStorage[127.0.0.1:34855,DS-91759faa-e8ce-4f9e-ba5c-f7e198f24934,DISK], DatanodeInfoWithStorage[127.0.0.1:34482,DS-832f6c7e-5857-4185-8380-dfbf2140abc8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-775017390-172.17.0.3-1597735434087:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42871,DS-8ebcbc03-7055-4789-b79a-6ce393d13308,DISK], DatanodeInfoWithStorage[127.0.0.1:43461,DS-10826cb5-aa53-4354-b085-4acfc26717a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38500,DS-f03f3ce7-59fc-49e9-ae3a-b91c4dcf31ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38783,DS-f8bb0f96-29ae-4706-91de-118e19578995,DISK], DatanodeInfoWithStorage[127.0.0.1:40648,DS-d980e46f-7e01-4673-9c4f-aca17004dd92,DISK], DatanodeInfoWithStorage[127.0.0.1:43678,DS-a74db526-c888-4fd5-a259-c0e809f88b06,DISK], DatanodeInfoWithStorage[127.0.0.1:44513,DS-e984b613-e06d-4fc0-b59e-1ea33dc946d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46179,DS-8263288f-928e-4ac9-b917-c013f23155c9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-775017390-172.17.0.3-1597735434087:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42871,DS-8ebcbc03-7055-4789-b79a-6ce393d13308,DISK], DatanodeInfoWithStorage[127.0.0.1:43461,DS-10826cb5-aa53-4354-b085-4acfc26717a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38500,DS-f03f3ce7-59fc-49e9-ae3a-b91c4dcf31ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38783,DS-f8bb0f96-29ae-4706-91de-118e19578995,DISK], DatanodeInfoWithStorage[127.0.0.1:40648,DS-d980e46f-7e01-4673-9c4f-aca17004dd92,DISK], DatanodeInfoWithStorage[127.0.0.1:43678,DS-a74db526-c888-4fd5-a259-c0e809f88b06,DISK], DatanodeInfoWithStorage[127.0.0.1:44513,DS-e984b613-e06d-4fc0-b59e-1ea33dc946d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46179,DS-8263288f-928e-4ac9-b917-c013f23155c9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1045815611-172.17.0.3-1597735550873:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40924,DS-625428a9-dbc1-4038-895d-afc4d2ea7809,DISK], DatanodeInfoWithStorage[127.0.0.1:37172,DS-3bc7d6f9-dccc-41b1-aa25-b9951c31c948,DISK], DatanodeInfoWithStorage[127.0.0.1:42609,DS-e8102594-4325-446d-a662-f2e4569a0e42,DISK], DatanodeInfoWithStorage[127.0.0.1:34060,DS-8bbd1c51-1b22-48bd-9529-f73506996bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:42941,DS-4a16c4f5-0c29-4e71-b35f-9023b6058c76,DISK], DatanodeInfoWithStorage[127.0.0.1:45491,DS-c5390502-10d3-4a4a-b521-ad5dedef3e21,DISK], DatanodeInfoWithStorage[127.0.0.1:43264,DS-0e803b6f-d1ca-4e31-879a-39beb378d399,DISK], DatanodeInfoWithStorage[127.0.0.1:41043,DS-91b2274e-4db6-489e-a4af-84662bd9a618,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1045815611-172.17.0.3-1597735550873:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40924,DS-625428a9-dbc1-4038-895d-afc4d2ea7809,DISK], DatanodeInfoWithStorage[127.0.0.1:37172,DS-3bc7d6f9-dccc-41b1-aa25-b9951c31c948,DISK], DatanodeInfoWithStorage[127.0.0.1:42609,DS-e8102594-4325-446d-a662-f2e4569a0e42,DISK], DatanodeInfoWithStorage[127.0.0.1:34060,DS-8bbd1c51-1b22-48bd-9529-f73506996bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:42941,DS-4a16c4f5-0c29-4e71-b35f-9023b6058c76,DISK], DatanodeInfoWithStorage[127.0.0.1:45491,DS-c5390502-10d3-4a4a-b521-ad5dedef3e21,DISK], DatanodeInfoWithStorage[127.0.0.1:43264,DS-0e803b6f-d1ca-4e31-879a-39beb378d399,DISK], DatanodeInfoWithStorage[127.0.0.1:41043,DS-91b2274e-4db6-489e-a4af-84662bd9a618,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-626068572-172.17.0.3-1597735633554:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34588,DS-baea014a-f502-4c32-8a9e-b6d60cd1f703,DISK], DatanodeInfoWithStorage[127.0.0.1:38104,DS-601bc605-3707-452a-a0e4-fa6881d5f985,DISK], DatanodeInfoWithStorage[127.0.0.1:39136,DS-97207339-6862-4878-84ee-01d80278462b,DISK], DatanodeInfoWithStorage[127.0.0.1:39201,DS-7f8e5acd-8b7e-4378-89f3-27268b9af5d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39451,DS-6e1d701b-63c0-4629-9bf8-679d3a158060,DISK], DatanodeInfoWithStorage[127.0.0.1:43968,DS-2df30f0c-605b-4016-9705-c40561a42cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:36682,DS-8ff80ea6-cc7c-4f98-b70e-a5d6af8edf60,DISK], DatanodeInfoWithStorage[127.0.0.1:36310,DS-537167c0-7837-4001-b05a-a3e957d04c84,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-626068572-172.17.0.3-1597735633554:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34588,DS-baea014a-f502-4c32-8a9e-b6d60cd1f703,DISK], DatanodeInfoWithStorage[127.0.0.1:38104,DS-601bc605-3707-452a-a0e4-fa6881d5f985,DISK], DatanodeInfoWithStorage[127.0.0.1:39136,DS-97207339-6862-4878-84ee-01d80278462b,DISK], DatanodeInfoWithStorage[127.0.0.1:39201,DS-7f8e5acd-8b7e-4378-89f3-27268b9af5d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39451,DS-6e1d701b-63c0-4629-9bf8-679d3a158060,DISK], DatanodeInfoWithStorage[127.0.0.1:43968,DS-2df30f0c-605b-4016-9705-c40561a42cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:36682,DS-8ff80ea6-cc7c-4f98-b70e-a5d6af8edf60,DISK], DatanodeInfoWithStorage[127.0.0.1:36310,DS-537167c0-7837-4001-b05a-a3e957d04c84,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1081964232-172.17.0.3-1597735749444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41588,DS-d2518afc-005c-41bf-9a99-b07f6aee900a,DISK], DatanodeInfoWithStorage[127.0.0.1:40097,DS-fb099d58-758d-4a42-bb4b-bcb8740db231,DISK], DatanodeInfoWithStorage[127.0.0.1:34112,DS-3d048746-5529-4a8e-900b-38a7e67364d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39238,DS-ba141643-a711-4112-bce6-0dff115be785,DISK], DatanodeInfoWithStorage[127.0.0.1:35738,DS-7b73e505-9452-4eed-bebc-d51f816f558b,DISK], DatanodeInfoWithStorage[127.0.0.1:38710,DS-4d4dd3f9-d18e-4b60-9c9f-f8da2ebb40f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44872,DS-c0b9a953-600c-441d-8085-148c27873a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:34511,DS-93113971-7a79-4a79-8206-b438c5328288,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1081964232-172.17.0.3-1597735749444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41588,DS-d2518afc-005c-41bf-9a99-b07f6aee900a,DISK], DatanodeInfoWithStorage[127.0.0.1:40097,DS-fb099d58-758d-4a42-bb4b-bcb8740db231,DISK], DatanodeInfoWithStorage[127.0.0.1:34112,DS-3d048746-5529-4a8e-900b-38a7e67364d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39238,DS-ba141643-a711-4112-bce6-0dff115be785,DISK], DatanodeInfoWithStorage[127.0.0.1:35738,DS-7b73e505-9452-4eed-bebc-d51f816f558b,DISK], DatanodeInfoWithStorage[127.0.0.1:38710,DS-4d4dd3f9-d18e-4b60-9c9f-f8da2ebb40f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44872,DS-c0b9a953-600c-441d-8085-148c27873a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:34511,DS-93113971-7a79-4a79-8206-b438c5328288,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1676213871-172.17.0.3-1597735782255:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35481,DS-b7ab4a10-e664-4f4c-bdca-bda15257dfb8,DISK], DatanodeInfoWithStorage[127.0.0.1:38908,DS-01d4dbac-9dda-4745-8739-b3b4c473f15f,DISK], DatanodeInfoWithStorage[127.0.0.1:35135,DS-7e186273-0e8a-441b-9d36-cbab64aa032d,DISK], DatanodeInfoWithStorage[127.0.0.1:40284,DS-be7fd801-8c5c-45de-9700-689c15e9cf78,DISK], DatanodeInfoWithStorage[127.0.0.1:38153,DS-3ecf632c-081b-4ed3-ad13-be75f066eea2,DISK], DatanodeInfoWithStorage[127.0.0.1:36222,DS-2c5c41f9-c4a4-4964-9a43-7c0ee0b23c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34048,DS-f46cc422-9daa-4d90-956d-4ee6a288a89b,DISK], DatanodeInfoWithStorage[127.0.0.1:45096,DS-5dc2f60c-03ef-4f51-bda7-62ec3aa68893,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1676213871-172.17.0.3-1597735782255:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35481,DS-b7ab4a10-e664-4f4c-bdca-bda15257dfb8,DISK], DatanodeInfoWithStorage[127.0.0.1:38908,DS-01d4dbac-9dda-4745-8739-b3b4c473f15f,DISK], DatanodeInfoWithStorage[127.0.0.1:35135,DS-7e186273-0e8a-441b-9d36-cbab64aa032d,DISK], DatanodeInfoWithStorage[127.0.0.1:40284,DS-be7fd801-8c5c-45de-9700-689c15e9cf78,DISK], DatanodeInfoWithStorage[127.0.0.1:38153,DS-3ecf632c-081b-4ed3-ad13-be75f066eea2,DISK], DatanodeInfoWithStorage[127.0.0.1:36222,DS-2c5c41f9-c4a4-4964-9a43-7c0ee0b23c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34048,DS-f46cc422-9daa-4d90-956d-4ee6a288a89b,DISK], DatanodeInfoWithStorage[127.0.0.1:45096,DS-5dc2f60c-03ef-4f51-bda7-62ec3aa68893,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1839435935-172.17.0.3-1597735862105:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46371,DS-1779307a-adfd-48f7-8cba-8277f3236991,DISK], DatanodeInfoWithStorage[127.0.0.1:38857,DS-8ac6c401-5ea4-4040-9779-2ba9a19fa06a,DISK], DatanodeInfoWithStorage[127.0.0.1:38097,DS-6b9e36df-7bf5-4d94-a96c-f4aed41a1de8,DISK], DatanodeInfoWithStorage[127.0.0.1:43929,DS-d76c2367-6d39-4ca0-a6c2-61d2847c2b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:38226,DS-f0571723-93b6-48d3-9755-11bd9f38356e,DISK], DatanodeInfoWithStorage[127.0.0.1:41892,DS-6afe9d49-0101-40d1-a4d7-faa4f8723844,DISK], DatanodeInfoWithStorage[127.0.0.1:34741,DS-6b665a4d-39ac-4ecb-a776-660419c8573b,DISK], DatanodeInfoWithStorage[127.0.0.1:38003,DS-2abbee23-20fe-4ec0-881e-62a998bea79c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1839435935-172.17.0.3-1597735862105:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46371,DS-1779307a-adfd-48f7-8cba-8277f3236991,DISK], DatanodeInfoWithStorage[127.0.0.1:38857,DS-8ac6c401-5ea4-4040-9779-2ba9a19fa06a,DISK], DatanodeInfoWithStorage[127.0.0.1:38097,DS-6b9e36df-7bf5-4d94-a96c-f4aed41a1de8,DISK], DatanodeInfoWithStorage[127.0.0.1:43929,DS-d76c2367-6d39-4ca0-a6c2-61d2847c2b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:38226,DS-f0571723-93b6-48d3-9755-11bd9f38356e,DISK], DatanodeInfoWithStorage[127.0.0.1:41892,DS-6afe9d49-0101-40d1-a4d7-faa4f8723844,DISK], DatanodeInfoWithStorage[127.0.0.1:34741,DS-6b665a4d-39ac-4ecb-a776-660419c8573b,DISK], DatanodeInfoWithStorage[127.0.0.1:38003,DS-2abbee23-20fe-4ec0-881e-62a998bea79c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-821873763-172.17.0.3-1597735899966:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40240,DS-c56c680c-876e-4ccf-8650-96b6f1130d94,DISK], DatanodeInfoWithStorage[127.0.0.1:36640,DS-c1e39cc3-cf1a-4ba0-88b2-092b395c3172,DISK], DatanodeInfoWithStorage[127.0.0.1:40786,DS-3e4d6535-58a3-40a6-a3d0-4e5cf3cb79a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37941,DS-b35b2f9a-a7c6-4ff6-aa26-f56c0062bcb3,DISK], DatanodeInfoWithStorage[127.0.0.1:32808,DS-cd8d4166-d6b1-4398-8421-a4a8bfe659e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46050,DS-7101fe5d-231f-4765-a17e-7aebc1f8c9d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38754,DS-7f160474-81d4-42c8-99d5-036ab935c9aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40274,DS-a1001f34-8c3b-4f15-bc0c-936a294775f2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-821873763-172.17.0.3-1597735899966:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40240,DS-c56c680c-876e-4ccf-8650-96b6f1130d94,DISK], DatanodeInfoWithStorage[127.0.0.1:36640,DS-c1e39cc3-cf1a-4ba0-88b2-092b395c3172,DISK], DatanodeInfoWithStorage[127.0.0.1:40786,DS-3e4d6535-58a3-40a6-a3d0-4e5cf3cb79a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37941,DS-b35b2f9a-a7c6-4ff6-aa26-f56c0062bcb3,DISK], DatanodeInfoWithStorage[127.0.0.1:32808,DS-cd8d4166-d6b1-4398-8421-a4a8bfe659e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46050,DS-7101fe5d-231f-4765-a17e-7aebc1f8c9d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38754,DS-7f160474-81d4-42c8-99d5-036ab935c9aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40274,DS-a1001f34-8c3b-4f15-bc0c-936a294775f2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-776827506-172.17.0.3-1597736035294:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45300,DS-c84daefa-d015-45f4-ac1a-5ad81eedfc5d,DISK], DatanodeInfoWithStorage[127.0.0.1:33533,DS-71ab647f-954c-4600-8017-5a201424ec29,DISK], DatanodeInfoWithStorage[127.0.0.1:35615,DS-daf5faeb-341a-4c49-a6e1-476963cbcfeb,DISK], DatanodeInfoWithStorage[127.0.0.1:33356,DS-795bbb17-9a05-4649-8eee-3cb5da09ea3e,DISK], DatanodeInfoWithStorage[127.0.0.1:45230,DS-f5268ba7-54cd-4dd5-9fb2-95af1cdd084c,DISK], DatanodeInfoWithStorage[127.0.0.1:36986,DS-29684ab2-0994-48cf-afeb-42a77d6910d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34373,DS-d562e13e-f484-4976-9c46-d9d4e9f34b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:43932,DS-dff2c562-fea4-47bf-ba50-b8c36f9bd09d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-776827506-172.17.0.3-1597736035294:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45300,DS-c84daefa-d015-45f4-ac1a-5ad81eedfc5d,DISK], DatanodeInfoWithStorage[127.0.0.1:33533,DS-71ab647f-954c-4600-8017-5a201424ec29,DISK], DatanodeInfoWithStorage[127.0.0.1:35615,DS-daf5faeb-341a-4c49-a6e1-476963cbcfeb,DISK], DatanodeInfoWithStorage[127.0.0.1:33356,DS-795bbb17-9a05-4649-8eee-3cb5da09ea3e,DISK], DatanodeInfoWithStorage[127.0.0.1:45230,DS-f5268ba7-54cd-4dd5-9fb2-95af1cdd084c,DISK], DatanodeInfoWithStorage[127.0.0.1:36986,DS-29684ab2-0994-48cf-afeb-42a77d6910d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34373,DS-d562e13e-f484-4976-9c46-d9d4e9f34b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:43932,DS-dff2c562-fea4-47bf-ba50-b8c36f9bd09d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1635587405-172.17.0.3-1597736194379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41625,DS-4776f2ae-21f9-4b64-bb6b-2e741379244e,DISK], DatanodeInfoWithStorage[127.0.0.1:45704,DS-f8a8014a-d7d6-4b92-8582-b5a2b7e6ff98,DISK], DatanodeInfoWithStorage[127.0.0.1:33399,DS-9b43e300-d9d7-4526-8b0a-5bc41a998a33,DISK], DatanodeInfoWithStorage[127.0.0.1:37103,DS-57b10a66-2a6f-4c56-b2bb-cd320887ba38,DISK], DatanodeInfoWithStorage[127.0.0.1:33344,DS-796a7218-cce6-4f7f-8736-28d0a8ac9295,DISK], DatanodeInfoWithStorage[127.0.0.1:36650,DS-896d8fde-0115-4e90-86e1-ac2d9460afbf,DISK], DatanodeInfoWithStorage[127.0.0.1:41260,DS-4e4cc09f-a64d-4866-beb7-8f5cb28a9f34,DISK], DatanodeInfoWithStorage[127.0.0.1:41109,DS-988e3bcc-1c0a-460c-883d-d12fd661d789,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1635587405-172.17.0.3-1597736194379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41625,DS-4776f2ae-21f9-4b64-bb6b-2e741379244e,DISK], DatanodeInfoWithStorage[127.0.0.1:45704,DS-f8a8014a-d7d6-4b92-8582-b5a2b7e6ff98,DISK], DatanodeInfoWithStorage[127.0.0.1:33399,DS-9b43e300-d9d7-4526-8b0a-5bc41a998a33,DISK], DatanodeInfoWithStorage[127.0.0.1:37103,DS-57b10a66-2a6f-4c56-b2bb-cd320887ba38,DISK], DatanodeInfoWithStorage[127.0.0.1:33344,DS-796a7218-cce6-4f7f-8736-28d0a8ac9295,DISK], DatanodeInfoWithStorage[127.0.0.1:36650,DS-896d8fde-0115-4e90-86e1-ac2d9460afbf,DISK], DatanodeInfoWithStorage[127.0.0.1:41260,DS-4e4cc09f-a64d-4866-beb7-8f5cb28a9f34,DISK], DatanodeInfoWithStorage[127.0.0.1:41109,DS-988e3bcc-1c0a-460c-883d-d12fd661d789,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1193629815-172.17.0.3-1597736501617:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41035,DS-6e320939-9bce-4cfe-8fa2-50e8eab36b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:33355,DS-7d64ef20-eb77-4628-8ea4-228283adb193,DISK], DatanodeInfoWithStorage[127.0.0.1:33752,DS-4d979be4-0824-44a5-9956-9b22b6271ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:46171,DS-f9af1dab-13f4-40b7-8583-e692edba1d87,DISK], DatanodeInfoWithStorage[127.0.0.1:46121,DS-0e548fbc-4dad-49b9-b38d-a3d6273e574a,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-3186c3d8-0e1d-4fd6-9765-dfdce4741530,DISK], DatanodeInfoWithStorage[127.0.0.1:36384,DS-1001f3f5-790c-40fd-98cc-3ec0e05c50ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39414,DS-e1633c62-4db0-4c93-a58e-fb11a0d39106,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1193629815-172.17.0.3-1597736501617:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41035,DS-6e320939-9bce-4cfe-8fa2-50e8eab36b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:33355,DS-7d64ef20-eb77-4628-8ea4-228283adb193,DISK], DatanodeInfoWithStorage[127.0.0.1:33752,DS-4d979be4-0824-44a5-9956-9b22b6271ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:46171,DS-f9af1dab-13f4-40b7-8583-e692edba1d87,DISK], DatanodeInfoWithStorage[127.0.0.1:46121,DS-0e548fbc-4dad-49b9-b38d-a3d6273e574a,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-3186c3d8-0e1d-4fd6-9765-dfdce4741530,DISK], DatanodeInfoWithStorage[127.0.0.1:36384,DS-1001f3f5-790c-40fd-98cc-3ec0e05c50ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39414,DS-e1633c62-4db0-4c93-a58e-fb11a0d39106,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-210119770-172.17.0.3-1597737033417:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33106,DS-b40368e8-f235-4b8c-9b06-08f6467e5298,DISK], DatanodeInfoWithStorage[127.0.0.1:44313,DS-051fc729-dbcc-4583-9289-2133ec29208f,DISK], DatanodeInfoWithStorage[127.0.0.1:33718,DS-5e23358d-bf25-4593-9465-63d7045e06a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46429,DS-976e1381-70d9-4a1c-a85c-6009c5534cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:35037,DS-ca5d38a8-1fdb-4553-9e42-2f4573fe07ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45630,DS-d7c1ee48-91aa-4c85-a83d-210ce2c98745,DISK], DatanodeInfoWithStorage[127.0.0.1:39003,DS-17905f17-77b6-4e24-8a69-487b14a036ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41564,DS-3f41ff4b-3a93-4ef3-a63d-b64924c7b550,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-210119770-172.17.0.3-1597737033417:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33106,DS-b40368e8-f235-4b8c-9b06-08f6467e5298,DISK], DatanodeInfoWithStorage[127.0.0.1:44313,DS-051fc729-dbcc-4583-9289-2133ec29208f,DISK], DatanodeInfoWithStorage[127.0.0.1:33718,DS-5e23358d-bf25-4593-9465-63d7045e06a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46429,DS-976e1381-70d9-4a1c-a85c-6009c5534cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:35037,DS-ca5d38a8-1fdb-4553-9e42-2f4573fe07ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45630,DS-d7c1ee48-91aa-4c85-a83d-210ce2c98745,DISK], DatanodeInfoWithStorage[127.0.0.1:39003,DS-17905f17-77b6-4e24-8a69-487b14a036ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41564,DS-3f41ff4b-3a93-4ef3-a63d-b64924c7b550,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1847623750-172.17.0.3-1597737108047:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34568,DS-6e522434-8d71-4153-8dc4-99eaf1588975,DISK], DatanodeInfoWithStorage[127.0.0.1:34462,DS-cff5896e-00c6-475d-bfc6-b4c58e41f195,DISK], DatanodeInfoWithStorage[127.0.0.1:41245,DS-87b99b48-0930-495d-909d-7defa097dcc5,DISK], DatanodeInfoWithStorage[127.0.0.1:44870,DS-2f55e0cd-ba8b-4224-9f79-1bd1dd2cd9e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38689,DS-01f46bff-0bed-45d1-8c56-b5d429e57f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39271,DS-2543903a-0968-4469-8d9c-c2a3cf66a2d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34605,DS-fb133259-2f1c-4736-8941-ac4700d4e22e,DISK], DatanodeInfoWithStorage[127.0.0.1:43733,DS-d10c032d-cf00-4c19-b7a9-39cbaf623044,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1847623750-172.17.0.3-1597737108047:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34568,DS-6e522434-8d71-4153-8dc4-99eaf1588975,DISK], DatanodeInfoWithStorage[127.0.0.1:34462,DS-cff5896e-00c6-475d-bfc6-b4c58e41f195,DISK], DatanodeInfoWithStorage[127.0.0.1:41245,DS-87b99b48-0930-495d-909d-7defa097dcc5,DISK], DatanodeInfoWithStorage[127.0.0.1:44870,DS-2f55e0cd-ba8b-4224-9f79-1bd1dd2cd9e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38689,DS-01f46bff-0bed-45d1-8c56-b5d429e57f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39271,DS-2543903a-0968-4469-8d9c-c2a3cf66a2d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34605,DS-fb133259-2f1c-4736-8941-ac4700d4e22e,DISK], DatanodeInfoWithStorage[127.0.0.1:43733,DS-d10c032d-cf00-4c19-b7a9-39cbaf623044,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-910818192-172.17.0.3-1597737142617:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33133,DS-117cb554-cdbf-45b0-8ce1-9323df6a1bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:40231,DS-198021e6-466d-493d-b332-b81be5f874be,DISK], DatanodeInfoWithStorage[127.0.0.1:42299,DS-8163d1ca-c545-429f-83bc-35cb53b707b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42398,DS-f16a4f60-7c01-458d-999a-0aefcb59d560,DISK], DatanodeInfoWithStorage[127.0.0.1:32938,DS-729a589b-e8a7-4aa4-ae65-02a72089c512,DISK], DatanodeInfoWithStorage[127.0.0.1:44699,DS-7b0d24a3-de95-4341-a13c-e1c1bd685648,DISK], DatanodeInfoWithStorage[127.0.0.1:35402,DS-9e5b4ad3-c77b-47ac-8c6f-642f350decbb,DISK], DatanodeInfoWithStorage[127.0.0.1:45741,DS-2fe39591-ab20-4725-b1a4-8c7c1eee618b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-910818192-172.17.0.3-1597737142617:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33133,DS-117cb554-cdbf-45b0-8ce1-9323df6a1bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:40231,DS-198021e6-466d-493d-b332-b81be5f874be,DISK], DatanodeInfoWithStorage[127.0.0.1:42299,DS-8163d1ca-c545-429f-83bc-35cb53b707b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42398,DS-f16a4f60-7c01-458d-999a-0aefcb59d560,DISK], DatanodeInfoWithStorage[127.0.0.1:32938,DS-729a589b-e8a7-4aa4-ae65-02a72089c512,DISK], DatanodeInfoWithStorage[127.0.0.1:44699,DS-7b0d24a3-de95-4341-a13c-e1c1bd685648,DISK], DatanodeInfoWithStorage[127.0.0.1:35402,DS-9e5b4ad3-c77b-47ac-8c6f-642f350decbb,DISK], DatanodeInfoWithStorage[127.0.0.1:45741,DS-2fe39591-ab20-4725-b1a4-8c7c1eee618b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-72442961-172.17.0.3-1597737382288:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45696,DS-ba144a2b-09ac-4c24-8f8d-6a9b4eabe5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38077,DS-3d2f97da-19e1-4238-ae26-e5009dec0ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:43129,DS-2a714e6b-ef1a-40e4-9954-5136d70bd7c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43023,DS-74789df2-0257-4b37-9832-f5706f23d102,DISK], DatanodeInfoWithStorage[127.0.0.1:41057,DS-3d9a1236-13de-43aa-aeee-ec814885f5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46293,DS-b0403362-3f01-4ea6-8e02-637d6d8ccc0f,DISK], DatanodeInfoWithStorage[127.0.0.1:46793,DS-97a6ea52-58f8-422c-81c0-7c2432f5678a,DISK], DatanodeInfoWithStorage[127.0.0.1:42604,DS-080a208f-484c-4b2b-8d1d-23c5d1100600,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-72442961-172.17.0.3-1597737382288:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45696,DS-ba144a2b-09ac-4c24-8f8d-6a9b4eabe5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38077,DS-3d2f97da-19e1-4238-ae26-e5009dec0ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:43129,DS-2a714e6b-ef1a-40e4-9954-5136d70bd7c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43023,DS-74789df2-0257-4b37-9832-f5706f23d102,DISK], DatanodeInfoWithStorage[127.0.0.1:41057,DS-3d9a1236-13de-43aa-aeee-ec814885f5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46293,DS-b0403362-3f01-4ea6-8e02-637d6d8ccc0f,DISK], DatanodeInfoWithStorage[127.0.0.1:46793,DS-97a6ea52-58f8-422c-81c0-7c2432f5678a,DISK], DatanodeInfoWithStorage[127.0.0.1:42604,DS-080a208f-484c-4b2b-8d1d-23c5d1100600,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1961053277-172.17.0.3-1597737789226:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35818,DS-8d09af9d-4c2a-41b3-ae4f-7548aea94739,DISK], DatanodeInfoWithStorage[127.0.0.1:45914,DS-82cdc03b-add5-4d75-8037-52817ec3543e,DISK], DatanodeInfoWithStorage[127.0.0.1:41304,DS-8236a879-9365-4068-b61e-8bcd52ca5c16,DISK], DatanodeInfoWithStorage[127.0.0.1:42330,DS-49ba99ce-df1c-4a6d-bd43-3b46acddfeea,DISK], DatanodeInfoWithStorage[127.0.0.1:42093,DS-e4696c70-d194-4f15-9d7f-8c4eefef757a,DISK], DatanodeInfoWithStorage[127.0.0.1:42279,DS-b47815b3-5fee-4f6c-855c-4717b09c5672,DISK], DatanodeInfoWithStorage[127.0.0.1:33277,DS-4bf3e5ff-799a-4bc7-8648-47b91fffcfd3,DISK], DatanodeInfoWithStorage[127.0.0.1:45121,DS-10069d2c-bc49-4b7b-87c6-edd5454eb607,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1961053277-172.17.0.3-1597737789226:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35818,DS-8d09af9d-4c2a-41b3-ae4f-7548aea94739,DISK], DatanodeInfoWithStorage[127.0.0.1:45914,DS-82cdc03b-add5-4d75-8037-52817ec3543e,DISK], DatanodeInfoWithStorage[127.0.0.1:41304,DS-8236a879-9365-4068-b61e-8bcd52ca5c16,DISK], DatanodeInfoWithStorage[127.0.0.1:42330,DS-49ba99ce-df1c-4a6d-bd43-3b46acddfeea,DISK], DatanodeInfoWithStorage[127.0.0.1:42093,DS-e4696c70-d194-4f15-9d7f-8c4eefef757a,DISK], DatanodeInfoWithStorage[127.0.0.1:42279,DS-b47815b3-5fee-4f6c-855c-4717b09c5672,DISK], DatanodeInfoWithStorage[127.0.0.1:33277,DS-4bf3e5ff-799a-4bc7-8648-47b91fffcfd3,DISK], DatanodeInfoWithStorage[127.0.0.1:45121,DS-10069d2c-bc49-4b7b-87c6-edd5454eb607,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1184856399-172.17.0.3-1597738139752:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35615,DS-941db336-999c-4b74-9d5e-1739fe45cb54,DISK], DatanodeInfoWithStorage[127.0.0.1:39457,DS-99004558-e6a8-4896-a088-f36df8e674c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39281,DS-2544ae25-ae44-46ac-a988-dd1aa1a91293,DISK], DatanodeInfoWithStorage[127.0.0.1:38412,DS-6ebe5d31-1f72-4a71-a3bb-539fa1bc08f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38451,DS-c03f1059-721c-49a1-8a31-ac27f175a25f,DISK], DatanodeInfoWithStorage[127.0.0.1:33597,DS-c115f23c-4128-4b83-8ada-02deb591f5de,DISK], DatanodeInfoWithStorage[127.0.0.1:35036,DS-62ec50bc-4f00-4571-9472-3599287704f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34637,DS-dc0e30f2-5fff-421f-9e35-bd1f7e61ca17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1184856399-172.17.0.3-1597738139752:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35615,DS-941db336-999c-4b74-9d5e-1739fe45cb54,DISK], DatanodeInfoWithStorage[127.0.0.1:39457,DS-99004558-e6a8-4896-a088-f36df8e674c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39281,DS-2544ae25-ae44-46ac-a988-dd1aa1a91293,DISK], DatanodeInfoWithStorage[127.0.0.1:38412,DS-6ebe5d31-1f72-4a71-a3bb-539fa1bc08f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38451,DS-c03f1059-721c-49a1-8a31-ac27f175a25f,DISK], DatanodeInfoWithStorage[127.0.0.1:33597,DS-c115f23c-4128-4b83-8ada-02deb591f5de,DISK], DatanodeInfoWithStorage[127.0.0.1:35036,DS-62ec50bc-4f00-4571-9472-3599287704f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34637,DS-dc0e30f2-5fff-421f-9e35-bd1f7e61ca17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-639804739-172.17.0.3-1597738172810:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42596,DS-e29487cb-0e79-4a84-8b24-ed557817cec1,DISK], DatanodeInfoWithStorage[127.0.0.1:34765,DS-bfc75a09-4795-4fd8-9077-09fba195903d,DISK], DatanodeInfoWithStorage[127.0.0.1:36075,DS-520f4197-3f50-4b50-889b-3f5203f6cdc8,DISK], DatanodeInfoWithStorage[127.0.0.1:40567,DS-9ccdb0dd-5ede-4247-b1a0-f34f421c0ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:35423,DS-7c3e8ddb-9759-40e3-bfab-9b7d6dcb0972,DISK], DatanodeInfoWithStorage[127.0.0.1:38042,DS-31616bf6-a8dc-4417-9ee0-5b43a6450ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:38300,DS-eaa0b053-5139-400d-9261-f0f781eb3a06,DISK], DatanodeInfoWithStorage[127.0.0.1:37125,DS-752f561b-06f4-4d5f-bb9d-34e955082fe4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-639804739-172.17.0.3-1597738172810:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42596,DS-e29487cb-0e79-4a84-8b24-ed557817cec1,DISK], DatanodeInfoWithStorage[127.0.0.1:34765,DS-bfc75a09-4795-4fd8-9077-09fba195903d,DISK], DatanodeInfoWithStorage[127.0.0.1:36075,DS-520f4197-3f50-4b50-889b-3f5203f6cdc8,DISK], DatanodeInfoWithStorage[127.0.0.1:40567,DS-9ccdb0dd-5ede-4247-b1a0-f34f421c0ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:35423,DS-7c3e8ddb-9759-40e3-bfab-9b7d6dcb0972,DISK], DatanodeInfoWithStorage[127.0.0.1:38042,DS-31616bf6-a8dc-4417-9ee0-5b43a6450ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:38300,DS-eaa0b053-5139-400d-9261-f0f781eb3a06,DISK], DatanodeInfoWithStorage[127.0.0.1:37125,DS-752f561b-06f4-4d5f-bb9d-34e955082fe4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-592524040-172.17.0.3-1597738359043:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44032,DS-00a26603-01ff-413a-8aec-a46c17a28425,DISK], DatanodeInfoWithStorage[127.0.0.1:36794,DS-a483ab26-d455-4402-843d-e8a9a254453a,DISK], DatanodeInfoWithStorage[127.0.0.1:37456,DS-59aa6316-4ae3-446b-9184-2f026517bc72,DISK], DatanodeInfoWithStorage[127.0.0.1:35560,DS-854aac36-7c8b-4fa9-9021-a68a7164e91b,DISK], DatanodeInfoWithStorage[127.0.0.1:33459,DS-002816e4-afb8-47bd-a608-c1cfe900b2d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38551,DS-cab9721d-152f-43f7-b10c-cce21747d1fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46752,DS-ff7572a3-03ea-48db-a5e6-34eb263c8460,DISK], DatanodeInfoWithStorage[127.0.0.1:35841,DS-798eb602-8f0e-4049-95e6-773aaae70598,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-592524040-172.17.0.3-1597738359043:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44032,DS-00a26603-01ff-413a-8aec-a46c17a28425,DISK], DatanodeInfoWithStorage[127.0.0.1:36794,DS-a483ab26-d455-4402-843d-e8a9a254453a,DISK], DatanodeInfoWithStorage[127.0.0.1:37456,DS-59aa6316-4ae3-446b-9184-2f026517bc72,DISK], DatanodeInfoWithStorage[127.0.0.1:35560,DS-854aac36-7c8b-4fa9-9021-a68a7164e91b,DISK], DatanodeInfoWithStorage[127.0.0.1:33459,DS-002816e4-afb8-47bd-a608-c1cfe900b2d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38551,DS-cab9721d-152f-43f7-b10c-cce21747d1fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46752,DS-ff7572a3-03ea-48db-a5e6-34eb263c8460,DISK], DatanodeInfoWithStorage[127.0.0.1:35841,DS-798eb602-8f0e-4049-95e6-773aaae70598,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-211904160-172.17.0.3-1597738394523:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40462,DS-0999a330-9d0c-4351-9e06-a3a68d0eef05,DISK], DatanodeInfoWithStorage[127.0.0.1:37243,DS-e9211356-c336-4567-acf3-e5ca848b5521,DISK], DatanodeInfoWithStorage[127.0.0.1:46400,DS-8812ff05-2734-4be4-93d3-d7b301365db2,DISK], DatanodeInfoWithStorage[127.0.0.1:41115,DS-97a35238-424d-4bc0-af8e-93cc4737d3b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35248,DS-4ff3e01f-effb-4607-8ac0-837cdc1f4361,DISK], DatanodeInfoWithStorage[127.0.0.1:40118,DS-74fb3315-5244-49d3-9bd4-3a77094a9171,DISK], DatanodeInfoWithStorage[127.0.0.1:38277,DS-c480cc58-d0b0-4c50-919a-723684bdc324,DISK], DatanodeInfoWithStorage[127.0.0.1:40762,DS-e62c87f7-d065-4d4d-bc24-beb1c6c34d6b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-211904160-172.17.0.3-1597738394523:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40462,DS-0999a330-9d0c-4351-9e06-a3a68d0eef05,DISK], DatanodeInfoWithStorage[127.0.0.1:37243,DS-e9211356-c336-4567-acf3-e5ca848b5521,DISK], DatanodeInfoWithStorage[127.0.0.1:46400,DS-8812ff05-2734-4be4-93d3-d7b301365db2,DISK], DatanodeInfoWithStorage[127.0.0.1:41115,DS-97a35238-424d-4bc0-af8e-93cc4737d3b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35248,DS-4ff3e01f-effb-4607-8ac0-837cdc1f4361,DISK], DatanodeInfoWithStorage[127.0.0.1:40118,DS-74fb3315-5244-49d3-9bd4-3a77094a9171,DISK], DatanodeInfoWithStorage[127.0.0.1:38277,DS-c480cc58-d0b0-4c50-919a-723684bdc324,DISK], DatanodeInfoWithStorage[127.0.0.1:40762,DS-e62c87f7-d065-4d4d-bc24-beb1c6c34d6b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-948176810-172.17.0.3-1597738501389:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42033,DS-1f0f1399-a39a-487a-8bbe-a0e1f586a725,DISK], DatanodeInfoWithStorage[127.0.0.1:43151,DS-14e0ec9b-0c77-4f8c-a292-3d887999883d,DISK], DatanodeInfoWithStorage[127.0.0.1:38017,DS-5f8213f7-a1e3-4871-87e1-d525c2d479f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36817,DS-c56f43e9-c4da-4354-a7b5-14727ad484f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42469,DS-bf190723-b294-4c04-a6d4-46618983bf8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45497,DS-22a74a91-b467-4c33-80af-8b3517a9e6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43707,DS-dfafed4c-2301-4f4d-a15c-10d8dd9483cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45602,DS-dcdb6e3f-631e-496c-a62e-ac023cc25506,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-948176810-172.17.0.3-1597738501389:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42033,DS-1f0f1399-a39a-487a-8bbe-a0e1f586a725,DISK], DatanodeInfoWithStorage[127.0.0.1:43151,DS-14e0ec9b-0c77-4f8c-a292-3d887999883d,DISK], DatanodeInfoWithStorage[127.0.0.1:38017,DS-5f8213f7-a1e3-4871-87e1-d525c2d479f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36817,DS-c56f43e9-c4da-4354-a7b5-14727ad484f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42469,DS-bf190723-b294-4c04-a6d4-46618983bf8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45497,DS-22a74a91-b467-4c33-80af-8b3517a9e6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43707,DS-dfafed4c-2301-4f4d-a15c-10d8dd9483cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45602,DS-dcdb6e3f-631e-496c-a62e-ac023cc25506,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-819437601-172.17.0.3-1597738750419:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35982,DS-c4be958e-2948-4bb6-8e4d-6477a09b175c,DISK], DatanodeInfoWithStorage[127.0.0.1:41213,DS-1d6291e0-225a-45e3-bc67-b41b25e219cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46312,DS-8bda386e-f415-49a3-918d-87360b1a2876,DISK], DatanodeInfoWithStorage[127.0.0.1:41865,DS-f6f6e1b5-d0fe-45dd-a80a-d98ce903e1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:32872,DS-eed8a8a3-0532-4b20-888a-05c2aa579ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:39836,DS-f9504f91-a6d5-40a5-bd02-8aa03c89d3e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45573,DS-fc47c7f0-26b0-4032-8be7-36ff8d6ac3d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38520,DS-8bf6b0aa-9d4c-42c6-82ce-20886b807cfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-819437601-172.17.0.3-1597738750419:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35982,DS-c4be958e-2948-4bb6-8e4d-6477a09b175c,DISK], DatanodeInfoWithStorage[127.0.0.1:41213,DS-1d6291e0-225a-45e3-bc67-b41b25e219cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46312,DS-8bda386e-f415-49a3-918d-87360b1a2876,DISK], DatanodeInfoWithStorage[127.0.0.1:41865,DS-f6f6e1b5-d0fe-45dd-a80a-d98ce903e1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:32872,DS-eed8a8a3-0532-4b20-888a-05c2aa579ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:39836,DS-f9504f91-a6d5-40a5-bd02-8aa03c89d3e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45573,DS-fc47c7f0-26b0-4032-8be7-36ff8d6ac3d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38520,DS-8bf6b0aa-9d4c-42c6-82ce-20886b807cfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1869817172-172.17.0.3-1597738923237:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44589,DS-d368a0e8-a45b-46aa-ae93-6f49ff95d967,DISK], DatanodeInfoWithStorage[127.0.0.1:37716,DS-6e7e5fe8-de10-4029-9e25-9948e3f9cf41,DISK], DatanodeInfoWithStorage[127.0.0.1:33251,DS-9946dbb5-05d9-47fc-93ac-5c31a4397b48,DISK], DatanodeInfoWithStorage[127.0.0.1:46487,DS-2094cb34-09d4-499b-8a95-347d3af0d033,DISK], DatanodeInfoWithStorage[127.0.0.1:44840,DS-8d52f083-765f-4576-bb7b-4327b5528637,DISK], DatanodeInfoWithStorage[127.0.0.1:38399,DS-9ca1b9f9-d58d-45c0-9fdc-ce6afb7596f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38997,DS-e81cd64b-5eb8-4173-b321-c7d24b442227,DISK], DatanodeInfoWithStorage[127.0.0.1:36680,DS-bda851b2-da89-4665-afc2-21087d0eca4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1869817172-172.17.0.3-1597738923237:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44589,DS-d368a0e8-a45b-46aa-ae93-6f49ff95d967,DISK], DatanodeInfoWithStorage[127.0.0.1:37716,DS-6e7e5fe8-de10-4029-9e25-9948e3f9cf41,DISK], DatanodeInfoWithStorage[127.0.0.1:33251,DS-9946dbb5-05d9-47fc-93ac-5c31a4397b48,DISK], DatanodeInfoWithStorage[127.0.0.1:46487,DS-2094cb34-09d4-499b-8a95-347d3af0d033,DISK], DatanodeInfoWithStorage[127.0.0.1:44840,DS-8d52f083-765f-4576-bb7b-4327b5528637,DISK], DatanodeInfoWithStorage[127.0.0.1:38399,DS-9ca1b9f9-d58d-45c0-9fdc-ce6afb7596f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38997,DS-e81cd64b-5eb8-4173-b321-c7d24b442227,DISK], DatanodeInfoWithStorage[127.0.0.1:36680,DS-bda851b2-da89-4665-afc2-21087d0eca4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1477640934-172.17.0.3-1597739272808:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38443,DS-ac4b755c-c8cd-4c95-bd21-33e786044909,DISK], DatanodeInfoWithStorage[127.0.0.1:46858,DS-f5478921-d811-4bee-af9b-931463acea2f,DISK], DatanodeInfoWithStorage[127.0.0.1:44321,DS-d263fd22-4db5-41dc-9f7f-977c9a89b86f,DISK], DatanodeInfoWithStorage[127.0.0.1:38193,DS-0ac563e3-c257-4e4f-8f01-4168ae62050d,DISK], DatanodeInfoWithStorage[127.0.0.1:35226,DS-39cdc8e8-fbd4-41e5-becc-a9ca11f4e2b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43964,DS-23c819e9-c455-4db8-a2c8-a8c6f23f2020,DISK], DatanodeInfoWithStorage[127.0.0.1:41199,DS-f603626d-0cba-44ed-b09a-9ca6e02c6b15,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-eb84ffae-ff8e-4cb7-90a3-dd423084b640,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1477640934-172.17.0.3-1597739272808:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38443,DS-ac4b755c-c8cd-4c95-bd21-33e786044909,DISK], DatanodeInfoWithStorage[127.0.0.1:46858,DS-f5478921-d811-4bee-af9b-931463acea2f,DISK], DatanodeInfoWithStorage[127.0.0.1:44321,DS-d263fd22-4db5-41dc-9f7f-977c9a89b86f,DISK], DatanodeInfoWithStorage[127.0.0.1:38193,DS-0ac563e3-c257-4e4f-8f01-4168ae62050d,DISK], DatanodeInfoWithStorage[127.0.0.1:35226,DS-39cdc8e8-fbd4-41e5-becc-a9ca11f4e2b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43964,DS-23c819e9-c455-4db8-a2c8-a8c6f23f2020,DISK], DatanodeInfoWithStorage[127.0.0.1:41199,DS-f603626d-0cba-44ed-b09a-9ca6e02c6b15,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-eb84ffae-ff8e-4cb7-90a3-dd423084b640,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1071771986-172.17.0.3-1597739386241:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34017,DS-44bd7ac3-e563-41d5-b055-f297c8213290,DISK], DatanodeInfoWithStorage[127.0.0.1:41168,DS-a70f7e26-5b82-48da-b39b-e5cca320c6d9,DISK], DatanodeInfoWithStorage[127.0.0.1:32868,DS-8854b06c-551a-435e-b515-d1ea38488161,DISK], DatanodeInfoWithStorage[127.0.0.1:42623,DS-949c1ed9-4506-4213-b25d-eb4e7f91ce3c,DISK], DatanodeInfoWithStorage[127.0.0.1:43036,DS-6fef6d50-2ac3-44e0-aeac-35749b7d2a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40456,DS-126eeb09-cae7-46ed-a25e-0bd268f2c939,DISK], DatanodeInfoWithStorage[127.0.0.1:38729,DS-c760ff14-ba04-4be3-b775-53c410e05191,DISK], DatanodeInfoWithStorage[127.0.0.1:46248,DS-3de43c19-873c-44d6-82c9-6206fe71b81d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1071771986-172.17.0.3-1597739386241:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34017,DS-44bd7ac3-e563-41d5-b055-f297c8213290,DISK], DatanodeInfoWithStorage[127.0.0.1:41168,DS-a70f7e26-5b82-48da-b39b-e5cca320c6d9,DISK], DatanodeInfoWithStorage[127.0.0.1:32868,DS-8854b06c-551a-435e-b515-d1ea38488161,DISK], DatanodeInfoWithStorage[127.0.0.1:42623,DS-949c1ed9-4506-4213-b25d-eb4e7f91ce3c,DISK], DatanodeInfoWithStorage[127.0.0.1:43036,DS-6fef6d50-2ac3-44e0-aeac-35749b7d2a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40456,DS-126eeb09-cae7-46ed-a25e-0bd268f2c939,DISK], DatanodeInfoWithStorage[127.0.0.1:38729,DS-c760ff14-ba04-4be3-b775-53c410e05191,DISK], DatanodeInfoWithStorage[127.0.0.1:46248,DS-3de43c19-873c-44d6-82c9-6206fe71b81d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1748968808-172.17.0.3-1597739521702:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36439,DS-2a95c7fd-1ca5-405d-9c5f-34cce637d21c,DISK], DatanodeInfoWithStorage[127.0.0.1:42494,DS-ad6d8307-0e35-4afe-a8d4-041f2e4fdea0,DISK], DatanodeInfoWithStorage[127.0.0.1:33860,DS-8ecd7b1a-320a-43cb-b156-4edd69b4b07d,DISK], DatanodeInfoWithStorage[127.0.0.1:45760,DS-bba25239-e2e9-4da8-a407-3c8e3121b0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45261,DS-c5b20a20-d909-4f1d-a264-9f16b62da46d,DISK], DatanodeInfoWithStorage[127.0.0.1:39732,DS-29b22024-ea1e-44d2-b210-eae9b1919c33,DISK], DatanodeInfoWithStorage[127.0.0.1:41245,DS-8461700e-d1bf-4d32-8090-884a0bbc5e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:44346,DS-cde138a8-738d-451e-92ae-2c6016830239,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1748968808-172.17.0.3-1597739521702:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36439,DS-2a95c7fd-1ca5-405d-9c5f-34cce637d21c,DISK], DatanodeInfoWithStorage[127.0.0.1:42494,DS-ad6d8307-0e35-4afe-a8d4-041f2e4fdea0,DISK], DatanodeInfoWithStorage[127.0.0.1:33860,DS-8ecd7b1a-320a-43cb-b156-4edd69b4b07d,DISK], DatanodeInfoWithStorage[127.0.0.1:45760,DS-bba25239-e2e9-4da8-a407-3c8e3121b0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45261,DS-c5b20a20-d909-4f1d-a264-9f16b62da46d,DISK], DatanodeInfoWithStorage[127.0.0.1:39732,DS-29b22024-ea1e-44d2-b210-eae9b1919c33,DISK], DatanodeInfoWithStorage[127.0.0.1:41245,DS-8461700e-d1bf-4d32-8090-884a0bbc5e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:44346,DS-cde138a8-738d-451e-92ae-2c6016830239,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2083342718-172.17.0.3-1597739589800:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46725,DS-cebd3a53-6539-4b6b-bd17-2d4d4e2446c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41393,DS-0e1ec272-10f8-4c38-ba2a-d1b3b969e967,DISK], DatanodeInfoWithStorage[127.0.0.1:34886,DS-1fae8db6-b137-40c5-b0dd-259ed596cab9,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-74092689-2b92-44fd-b66d-7a01b8acb36e,DISK], DatanodeInfoWithStorage[127.0.0.1:45234,DS-b88e1d88-6e42-4385-95ca-32f70a803989,DISK], DatanodeInfoWithStorage[127.0.0.1:41322,DS-7281094a-780c-462a-8181-cfa29c0a8c60,DISK], DatanodeInfoWithStorage[127.0.0.1:44709,DS-5e07a21c-10c8-446d-84de-80d0543ef61b,DISK], DatanodeInfoWithStorage[127.0.0.1:34671,DS-19d2a1e7-f8f3-4172-bc4e-6b2632b979e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2083342718-172.17.0.3-1597739589800:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46725,DS-cebd3a53-6539-4b6b-bd17-2d4d4e2446c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41393,DS-0e1ec272-10f8-4c38-ba2a-d1b3b969e967,DISK], DatanodeInfoWithStorage[127.0.0.1:34886,DS-1fae8db6-b137-40c5-b0dd-259ed596cab9,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-74092689-2b92-44fd-b66d-7a01b8acb36e,DISK], DatanodeInfoWithStorage[127.0.0.1:45234,DS-b88e1d88-6e42-4385-95ca-32f70a803989,DISK], DatanodeInfoWithStorage[127.0.0.1:41322,DS-7281094a-780c-462a-8181-cfa29c0a8c60,DISK], DatanodeInfoWithStorage[127.0.0.1:44709,DS-5e07a21c-10c8-446d-84de-80d0543ef61b,DISK], DatanodeInfoWithStorage[127.0.0.1:34671,DS-19d2a1e7-f8f3-4172-bc4e-6b2632b979e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1976408658-172.17.0.3-1597739783496:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45111,DS-7a593698-83ed-4e09-905c-c09d5cafba55,DISK], DatanodeInfoWithStorage[127.0.0.1:43538,DS-5e40c52b-784a-4cc9-ab4b-c812990dba46,DISK], DatanodeInfoWithStorage[127.0.0.1:45659,DS-ed5bca32-3b95-454d-b4c5-27ef94dfcee4,DISK], DatanodeInfoWithStorage[127.0.0.1:39901,DS-174644d7-d713-4875-80d9-f34fd6301e96,DISK], DatanodeInfoWithStorage[127.0.0.1:35529,DS-0124ad8d-79cf-4c3a-aa89-646732c64465,DISK], DatanodeInfoWithStorage[127.0.0.1:42724,DS-e1918104-95f2-47b3-a2ea-98393a48c495,DISK], DatanodeInfoWithStorage[127.0.0.1:33139,DS-2351984a-5ef6-482f-818d-3081752be980,DISK], DatanodeInfoWithStorage[127.0.0.1:39446,DS-5293e2d6-6b99-481c-b301-31eacad06ef1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1976408658-172.17.0.3-1597739783496:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45111,DS-7a593698-83ed-4e09-905c-c09d5cafba55,DISK], DatanodeInfoWithStorage[127.0.0.1:43538,DS-5e40c52b-784a-4cc9-ab4b-c812990dba46,DISK], DatanodeInfoWithStorage[127.0.0.1:45659,DS-ed5bca32-3b95-454d-b4c5-27ef94dfcee4,DISK], DatanodeInfoWithStorage[127.0.0.1:39901,DS-174644d7-d713-4875-80d9-f34fd6301e96,DISK], DatanodeInfoWithStorage[127.0.0.1:35529,DS-0124ad8d-79cf-4c3a-aa89-646732c64465,DISK], DatanodeInfoWithStorage[127.0.0.1:42724,DS-e1918104-95f2-47b3-a2ea-98393a48c495,DISK], DatanodeInfoWithStorage[127.0.0.1:33139,DS-2351984a-5ef6-482f-818d-3081752be980,DISK], DatanodeInfoWithStorage[127.0.0.1:39446,DS-5293e2d6-6b99-481c-b301-31eacad06ef1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 23 out of 50
result: false positive !!!
Total execution time in seconds : 5259
