reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1000000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1000000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1012016475-172.17.0.8-1597373919487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34872,DS-db7165a2-9828-4557-86fe-1affaf88ebd8,DISK], DatanodeInfoWithStorage[127.0.0.1:33593,DS-130b1b9a-afa6-4c05-8f70-d08f16e8ca9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40558,DS-290b8487-a9b6-4a07-afd6-c310ce8254f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37424,DS-c4b2a8cd-0766-4e70-aba4-384e39cbe73a,DISK], DatanodeInfoWithStorage[127.0.0.1:44147,DS-8c11a5d3-d052-4d67-992a-362d4b795fde,DISK], DatanodeInfoWithStorage[127.0.0.1:38669,DS-1661bad0-41d1-4c38-90f2-81c03bbe810f,DISK], DatanodeInfoWithStorage[127.0.0.1:37452,DS-68b35bb4-6ecc-4b6e-8859-dae1d4235b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44872,DS-5bb1fec6-3c32-4b4f-9a15-7498e6fe8738,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1012016475-172.17.0.8-1597373919487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34872,DS-db7165a2-9828-4557-86fe-1affaf88ebd8,DISK], DatanodeInfoWithStorage[127.0.0.1:33593,DS-130b1b9a-afa6-4c05-8f70-d08f16e8ca9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40558,DS-290b8487-a9b6-4a07-afd6-c310ce8254f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37424,DS-c4b2a8cd-0766-4e70-aba4-384e39cbe73a,DISK], DatanodeInfoWithStorage[127.0.0.1:44147,DS-8c11a5d3-d052-4d67-992a-362d4b795fde,DISK], DatanodeInfoWithStorage[127.0.0.1:38669,DS-1661bad0-41d1-4c38-90f2-81c03bbe810f,DISK], DatanodeInfoWithStorage[127.0.0.1:37452,DS-68b35bb4-6ecc-4b6e-8859-dae1d4235b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44872,DS-5bb1fec6-3c32-4b4f-9a15-7498e6fe8738,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1000000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1341332016-172.17.0.8-1597373952057:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32891,DS-791ae55b-87dc-4b63-9f4c-80f4c1056695,DISK], DatanodeInfoWithStorage[127.0.0.1:44966,DS-39e15a4c-29d0-4c8a-a961-a9c33bd70843,DISK], DatanodeInfoWithStorage[127.0.0.1:43718,DS-cc5feb2a-8f8f-4174-bd82-0862ab7aeef9,DISK], DatanodeInfoWithStorage[127.0.0.1:41763,DS-225b57eb-c830-43e6-9549-d701e2a8b5fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43436,DS-d8d51f5d-f072-49c9-af3f-faf53288f995,DISK], DatanodeInfoWithStorage[127.0.0.1:44662,DS-80d3c06b-cc66-4535-a9c8-53026fcd62da,DISK], DatanodeInfoWithStorage[127.0.0.1:41497,DS-8528191b-7ab0-4c1a-b958-bd647aba57ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37422,DS-33b6533f-a7c7-469c-ae1a-944195001600,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1341332016-172.17.0.8-1597373952057:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32891,DS-791ae55b-87dc-4b63-9f4c-80f4c1056695,DISK], DatanodeInfoWithStorage[127.0.0.1:44966,DS-39e15a4c-29d0-4c8a-a961-a9c33bd70843,DISK], DatanodeInfoWithStorage[127.0.0.1:43718,DS-cc5feb2a-8f8f-4174-bd82-0862ab7aeef9,DISK], DatanodeInfoWithStorage[127.0.0.1:41763,DS-225b57eb-c830-43e6-9549-d701e2a8b5fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43436,DS-d8d51f5d-f072-49c9-af3f-faf53288f995,DISK], DatanodeInfoWithStorage[127.0.0.1:44662,DS-80d3c06b-cc66-4535-a9c8-53026fcd62da,DISK], DatanodeInfoWithStorage[127.0.0.1:41497,DS-8528191b-7ab0-4c1a-b958-bd647aba57ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37422,DS-33b6533f-a7c7-469c-ae1a-944195001600,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1000000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-532381442-172.17.0.8-1597374093680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43276,DS-bfe3d12c-1c21-4a10-a067-f21e5a0c7e33,DISK], DatanodeInfoWithStorage[127.0.0.1:45859,DS-a0794d8e-a81e-402f-9478-b7bf1b6d897a,DISK], DatanodeInfoWithStorage[127.0.0.1:46115,DS-7b3ef07a-71ea-40fa-a4dc-c611bf72f0ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43536,DS-a0d8df6f-089e-42ac-9fc1-0b7dee55a071,DISK], DatanodeInfoWithStorage[127.0.0.1:34998,DS-21cfb89e-6db6-46e6-a21e-1548ac9275b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43313,DS-943677b4-4521-4c42-9c16-31ea24e8d569,DISK], DatanodeInfoWithStorage[127.0.0.1:38248,DS-4c53a38f-89d6-4fcd-b132-1cbbcae748d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42174,DS-b55aa0b7-322a-4159-9e17-76388635af0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-532381442-172.17.0.8-1597374093680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43276,DS-bfe3d12c-1c21-4a10-a067-f21e5a0c7e33,DISK], DatanodeInfoWithStorage[127.0.0.1:45859,DS-a0794d8e-a81e-402f-9478-b7bf1b6d897a,DISK], DatanodeInfoWithStorage[127.0.0.1:46115,DS-7b3ef07a-71ea-40fa-a4dc-c611bf72f0ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43536,DS-a0d8df6f-089e-42ac-9fc1-0b7dee55a071,DISK], DatanodeInfoWithStorage[127.0.0.1:34998,DS-21cfb89e-6db6-46e6-a21e-1548ac9275b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43313,DS-943677b4-4521-4c42-9c16-31ea24e8d569,DISK], DatanodeInfoWithStorage[127.0.0.1:38248,DS-4c53a38f-89d6-4fcd-b132-1cbbcae748d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42174,DS-b55aa0b7-322a-4159-9e17-76388635af0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1000000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1011966682-172.17.0.8-1597374568965:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35132,DS-d8a1f096-653a-457b-98c8-f73a26dbd4de,DISK], DatanodeInfoWithStorage[127.0.0.1:41731,DS-6dd44f9a-228f-4c2d-b4fe-ac8000e362c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39811,DS-e417da14-06e0-44e6-9b72-dfe3a6ade5f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40278,DS-7a0e4ade-8bd2-4807-8de8-3fbbd45d4b15,DISK], DatanodeInfoWithStorage[127.0.0.1:43720,DS-3870079e-8df8-42e9-a27b-a0e50883552e,DISK], DatanodeInfoWithStorage[127.0.0.1:38575,DS-5d60a554-819d-4d90-8e0e-0f186611d332,DISK], DatanodeInfoWithStorage[127.0.0.1:40614,DS-ac85450e-b17f-43a7-9912-e7e14776a4ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33413,DS-a894372c-af13-4320-bb69-1b20997de8d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1011966682-172.17.0.8-1597374568965:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35132,DS-d8a1f096-653a-457b-98c8-f73a26dbd4de,DISK], DatanodeInfoWithStorage[127.0.0.1:41731,DS-6dd44f9a-228f-4c2d-b4fe-ac8000e362c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39811,DS-e417da14-06e0-44e6-9b72-dfe3a6ade5f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40278,DS-7a0e4ade-8bd2-4807-8de8-3fbbd45d4b15,DISK], DatanodeInfoWithStorage[127.0.0.1:43720,DS-3870079e-8df8-42e9-a27b-a0e50883552e,DISK], DatanodeInfoWithStorage[127.0.0.1:38575,DS-5d60a554-819d-4d90-8e0e-0f186611d332,DISK], DatanodeInfoWithStorage[127.0.0.1:40614,DS-ac85450e-b17f-43a7-9912-e7e14776a4ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33413,DS-a894372c-af13-4320-bb69-1b20997de8d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1000000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1942604497-172.17.0.8-1597374764890:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41529,DS-2f8959e2-74d4-49d6-9f9b-02f9d13fc981,DISK], DatanodeInfoWithStorage[127.0.0.1:34491,DS-e4bf0f3c-4193-4133-8db5-5e75ea341361,DISK], DatanodeInfoWithStorage[127.0.0.1:40646,DS-faaa4170-42a4-42c0-a06b-345cd7598551,DISK], DatanodeInfoWithStorage[127.0.0.1:34748,DS-63d48bff-7fe1-44ba-afef-8227ce194c64,DISK], DatanodeInfoWithStorage[127.0.0.1:34755,DS-d7be7684-0b08-4648-85bf-902f9e260f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:46050,DS-05a4a3df-bfc0-40b1-82fb-c6073c550ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:33676,DS-f89c5a00-e97c-4c30-b880-3899c24e51ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41599,DS-821ca00f-4632-4637-9952-4e3d7f033e41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1942604497-172.17.0.8-1597374764890:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41529,DS-2f8959e2-74d4-49d6-9f9b-02f9d13fc981,DISK], DatanodeInfoWithStorage[127.0.0.1:34491,DS-e4bf0f3c-4193-4133-8db5-5e75ea341361,DISK], DatanodeInfoWithStorage[127.0.0.1:40646,DS-faaa4170-42a4-42c0-a06b-345cd7598551,DISK], DatanodeInfoWithStorage[127.0.0.1:34748,DS-63d48bff-7fe1-44ba-afef-8227ce194c64,DISK], DatanodeInfoWithStorage[127.0.0.1:34755,DS-d7be7684-0b08-4648-85bf-902f9e260f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:46050,DS-05a4a3df-bfc0-40b1-82fb-c6073c550ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:33676,DS-f89c5a00-e97c-4c30-b880-3899c24e51ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41599,DS-821ca00f-4632-4637-9952-4e3d7f033e41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1000000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1080638370-172.17.0.8-1597375126213:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35318,DS-ce1d16c3-827b-46c0-a315-7644c73b52e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43713,DS-14707886-3488-459a-a134-b217baee4e01,DISK], DatanodeInfoWithStorage[127.0.0.1:38095,DS-bfaa75eb-95b2-42d9-a047-a319d3688673,DISK], DatanodeInfoWithStorage[127.0.0.1:33590,DS-a60f94b5-30ec-476e-8ed6-0a524195ee7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44518,DS-130d1f77-223f-49f4-a903-6624d6b2e502,DISK], DatanodeInfoWithStorage[127.0.0.1:40514,DS-9a4ef6f2-6d96-4f23-9efd-b0a25df870cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42188,DS-0c86f59d-58a1-4b04-8faa-6239b41ec9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40197,DS-9e0edbcf-5b19-4d11-a3f1-d394eaadb067,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1080638370-172.17.0.8-1597375126213:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35318,DS-ce1d16c3-827b-46c0-a315-7644c73b52e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43713,DS-14707886-3488-459a-a134-b217baee4e01,DISK], DatanodeInfoWithStorage[127.0.0.1:38095,DS-bfaa75eb-95b2-42d9-a047-a319d3688673,DISK], DatanodeInfoWithStorage[127.0.0.1:33590,DS-a60f94b5-30ec-476e-8ed6-0a524195ee7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44518,DS-130d1f77-223f-49f4-a903-6624d6b2e502,DISK], DatanodeInfoWithStorage[127.0.0.1:40514,DS-9a4ef6f2-6d96-4f23-9efd-b0a25df870cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42188,DS-0c86f59d-58a1-4b04-8faa-6239b41ec9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40197,DS-9e0edbcf-5b19-4d11-a3f1-d394eaadb067,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1000000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-761789913-172.17.0.8-1597375165789:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35306,DS-6910071c-ec29-4480-b699-6b166c91b756,DISK], DatanodeInfoWithStorage[127.0.0.1:43741,DS-6c8d3b8f-a119-4a21-a45e-80b9c5dfd7e3,DISK], DatanodeInfoWithStorage[127.0.0.1:32873,DS-72fbb439-57df-4587-8cda-dd6a6b36b2bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39982,DS-e0ee3460-ca65-40b4-8f92-963e73396be8,DISK], DatanodeInfoWithStorage[127.0.0.1:36655,DS-bb80ec9a-9835-44b7-b1dc-9ebbd869453a,DISK], DatanodeInfoWithStorage[127.0.0.1:46600,DS-e231e9bf-12a6-4241-a4a4-e0b21922b917,DISK], DatanodeInfoWithStorage[127.0.0.1:40014,DS-bd42a3a5-c484-4d4a-b675-1106d69a92c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43757,DS-ce66e10a-0ddb-4b5c-9d60-39f5256142d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-761789913-172.17.0.8-1597375165789:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35306,DS-6910071c-ec29-4480-b699-6b166c91b756,DISK], DatanodeInfoWithStorage[127.0.0.1:43741,DS-6c8d3b8f-a119-4a21-a45e-80b9c5dfd7e3,DISK], DatanodeInfoWithStorage[127.0.0.1:32873,DS-72fbb439-57df-4587-8cda-dd6a6b36b2bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39982,DS-e0ee3460-ca65-40b4-8f92-963e73396be8,DISK], DatanodeInfoWithStorage[127.0.0.1:36655,DS-bb80ec9a-9835-44b7-b1dc-9ebbd869453a,DISK], DatanodeInfoWithStorage[127.0.0.1:46600,DS-e231e9bf-12a6-4241-a4a4-e0b21922b917,DISK], DatanodeInfoWithStorage[127.0.0.1:40014,DS-bd42a3a5-c484-4d4a-b675-1106d69a92c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43757,DS-ce66e10a-0ddb-4b5c-9d60-39f5256142d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1000000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-267125191-172.17.0.8-1597375361374:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36591,DS-b86677da-b1bb-48ae-afe7-7af61599dfb2,DISK], DatanodeInfoWithStorage[127.0.0.1:44717,DS-0b9b6b00-86ed-4014-9071-c040fa1da6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39945,DS-f5ef9dc5-7dd6-4ce6-9499-9d281230f626,DISK], DatanodeInfoWithStorage[127.0.0.1:46435,DS-ccbaae64-0e15-4692-bf48-abbc53efcbcd,DISK], DatanodeInfoWithStorage[127.0.0.1:32980,DS-0c60d3ec-49c1-4fa9-968e-cda18e0a08f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35295,DS-8a22c826-17d2-4f57-91b8-0940cb4468a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44422,DS-01b15532-05f9-45ce-897a-e54cc24f7d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:42261,DS-9765ff06-fd5c-4bac-88ba-2da3e16de4be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-267125191-172.17.0.8-1597375361374:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36591,DS-b86677da-b1bb-48ae-afe7-7af61599dfb2,DISK], DatanodeInfoWithStorage[127.0.0.1:44717,DS-0b9b6b00-86ed-4014-9071-c040fa1da6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39945,DS-f5ef9dc5-7dd6-4ce6-9499-9d281230f626,DISK], DatanodeInfoWithStorage[127.0.0.1:46435,DS-ccbaae64-0e15-4692-bf48-abbc53efcbcd,DISK], DatanodeInfoWithStorage[127.0.0.1:32980,DS-0c60d3ec-49c1-4fa9-968e-cda18e0a08f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35295,DS-8a22c826-17d2-4f57-91b8-0940cb4468a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44422,DS-01b15532-05f9-45ce-897a-e54cc24f7d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:42261,DS-9765ff06-fd5c-4bac-88ba-2da3e16de4be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1000000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1476871834-172.17.0.8-1597375742396:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44929,DS-950a045c-6626-4fef-8b6c-e2ec569cceb5,DISK], DatanodeInfoWithStorage[127.0.0.1:41974,DS-3d589613-bf0d-408c-a085-b030c3e8cecc,DISK], DatanodeInfoWithStorage[127.0.0.1:39641,DS-90741970-9fcc-4759-8d3c-5caadda8a885,DISK], DatanodeInfoWithStorage[127.0.0.1:34521,DS-13dbb2b2-d8fa-47f3-b3ef-5cc888d83816,DISK], DatanodeInfoWithStorage[127.0.0.1:39940,DS-67708b2b-5600-43c1-a2a9-d2939b12bef1,DISK], DatanodeInfoWithStorage[127.0.0.1:41095,DS-f58a0272-25da-49dc-9957-c0a32760b98f,DISK], DatanodeInfoWithStorage[127.0.0.1:45125,DS-33b62c60-78cb-46d3-bb48-db1a2b32a8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44368,DS-f2eab822-e727-4074-a36e-ebdba0e475c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1476871834-172.17.0.8-1597375742396:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44929,DS-950a045c-6626-4fef-8b6c-e2ec569cceb5,DISK], DatanodeInfoWithStorage[127.0.0.1:41974,DS-3d589613-bf0d-408c-a085-b030c3e8cecc,DISK], DatanodeInfoWithStorage[127.0.0.1:39641,DS-90741970-9fcc-4759-8d3c-5caadda8a885,DISK], DatanodeInfoWithStorage[127.0.0.1:34521,DS-13dbb2b2-d8fa-47f3-b3ef-5cc888d83816,DISK], DatanodeInfoWithStorage[127.0.0.1:39940,DS-67708b2b-5600-43c1-a2a9-d2939b12bef1,DISK], DatanodeInfoWithStorage[127.0.0.1:41095,DS-f58a0272-25da-49dc-9957-c0a32760b98f,DISK], DatanodeInfoWithStorage[127.0.0.1:45125,DS-33b62c60-78cb-46d3-bb48-db1a2b32a8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44368,DS-f2eab822-e727-4074-a36e-ebdba0e475c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1000000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1354443142-172.17.0.8-1597377492598:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45135,DS-f8e5f12c-81d6-47da-8251-98c77d9baaf5,DISK], DatanodeInfoWithStorage[127.0.0.1:38088,DS-2b9de922-b71b-40ff-b36e-3412ea44ec78,DISK], DatanodeInfoWithStorage[127.0.0.1:40394,DS-bd954176-6ec7-4ad6-97e1-d3c42d43357c,DISK], DatanodeInfoWithStorage[127.0.0.1:35810,DS-79c7c40b-76d1-474b-87c8-ffec081a5e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:33591,DS-5b2cd51d-419a-433c-a187-0bed3e577555,DISK], DatanodeInfoWithStorage[127.0.0.1:37472,DS-b16bb2ff-b13b-4082-bf40-b0fb7a5644d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37096,DS-63a83817-9cca-487a-bf42-8c30cde9f622,DISK], DatanodeInfoWithStorage[127.0.0.1:41448,DS-761a7edf-2b28-486f-ab95-c2155df9eab8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1354443142-172.17.0.8-1597377492598:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45135,DS-f8e5f12c-81d6-47da-8251-98c77d9baaf5,DISK], DatanodeInfoWithStorage[127.0.0.1:38088,DS-2b9de922-b71b-40ff-b36e-3412ea44ec78,DISK], DatanodeInfoWithStorage[127.0.0.1:40394,DS-bd954176-6ec7-4ad6-97e1-d3c42d43357c,DISK], DatanodeInfoWithStorage[127.0.0.1:35810,DS-79c7c40b-76d1-474b-87c8-ffec081a5e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:33591,DS-5b2cd51d-419a-433c-a187-0bed3e577555,DISK], DatanodeInfoWithStorage[127.0.0.1:37472,DS-b16bb2ff-b13b-4082-bf40-b0fb7a5644d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37096,DS-63a83817-9cca-487a-bf42-8c30cde9f622,DISK], DatanodeInfoWithStorage[127.0.0.1:41448,DS-761a7edf-2b28-486f-ab95-c2155df9eab8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1000000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-351833025-172.17.0.8-1597377652729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46595,DS-939f15fc-5b68-4b4d-b2dd-bba04e3c8cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:44783,DS-6c07c94a-b015-4db3-af29-a1cf8f6026a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33681,DS-8925a552-5cad-4b92-a323-bf0d3e86a0e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44532,DS-58a8ec8e-52c7-4863-ba77-1bd413edd701,DISK], DatanodeInfoWithStorage[127.0.0.1:43956,DS-c21e6a42-647d-444e-a044-d280db8d50cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44960,DS-d1017a6d-ec62-4d96-9376-845e2e23f40e,DISK], DatanodeInfoWithStorage[127.0.0.1:43480,DS-311528af-b495-4f62-b34a-f621e22cfbc9,DISK], DatanodeInfoWithStorage[127.0.0.1:35425,DS-c8bd1934-f036-46d8-b228-0b6a9474d525,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-351833025-172.17.0.8-1597377652729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46595,DS-939f15fc-5b68-4b4d-b2dd-bba04e3c8cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:44783,DS-6c07c94a-b015-4db3-af29-a1cf8f6026a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33681,DS-8925a552-5cad-4b92-a323-bf0d3e86a0e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44532,DS-58a8ec8e-52c7-4863-ba77-1bd413edd701,DISK], DatanodeInfoWithStorage[127.0.0.1:43956,DS-c21e6a42-647d-444e-a044-d280db8d50cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44960,DS-d1017a6d-ec62-4d96-9376-845e2e23f40e,DISK], DatanodeInfoWithStorage[127.0.0.1:43480,DS-311528af-b495-4f62-b34a-f621e22cfbc9,DISK], DatanodeInfoWithStorage[127.0.0.1:35425,DS-c8bd1934-f036-46d8-b228-0b6a9474d525,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1000000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-766305548-172.17.0.8-1597377797136:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32878,DS-8cadfc68-987a-4c58-b918-f818bb702f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33854,DS-f1b144be-66dd-4cf2-a5f7-9f78921bd7b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46135,DS-4624cbfa-ba3e-4c57-b42e-e561b4395ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:43519,DS-6046b35f-b449-4fe2-928e-871d460ba9e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36144,DS-059ebf1e-fe6c-4cd6-8c30-2971e951b7a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42276,DS-c456fc08-d057-4c7c-8212-5d557722dfcb,DISK], DatanodeInfoWithStorage[127.0.0.1:40975,DS-786e873d-5070-454c-97da-978d8eeac047,DISK], DatanodeInfoWithStorage[127.0.0.1:43771,DS-284c1276-0b45-4746-a0d5-5868ab2efa36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-766305548-172.17.0.8-1597377797136:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32878,DS-8cadfc68-987a-4c58-b918-f818bb702f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33854,DS-f1b144be-66dd-4cf2-a5f7-9f78921bd7b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46135,DS-4624cbfa-ba3e-4c57-b42e-e561b4395ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:43519,DS-6046b35f-b449-4fe2-928e-871d460ba9e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36144,DS-059ebf1e-fe6c-4cd6-8c30-2971e951b7a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42276,DS-c456fc08-d057-4c7c-8212-5d557722dfcb,DISK], DatanodeInfoWithStorage[127.0.0.1:40975,DS-786e873d-5070-454c-97da-978d8eeac047,DISK], DatanodeInfoWithStorage[127.0.0.1:43771,DS-284c1276-0b45-4746-a0d5-5868ab2efa36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1000000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-675700744-172.17.0.8-1597378029281:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41054,DS-9781fc6c-d498-4884-8e44-5921106ba2d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41947,DS-1765059c-295c-4edb-96ee-3c8a389f0894,DISK], DatanodeInfoWithStorage[127.0.0.1:42123,DS-6db42075-3c96-4992-a01b-f6c047b10c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43944,DS-8c5381c3-e976-432f-8845-ceaca9dbb30a,DISK], DatanodeInfoWithStorage[127.0.0.1:44326,DS-688babeb-a9bc-4437-809d-9d7e9f7f14fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33753,DS-1c54fd73-25b5-49ea-bafa-ee4e1df7fe18,DISK], DatanodeInfoWithStorage[127.0.0.1:44729,DS-d68fb9ef-626b-4fd0-985b-4262afab2d17,DISK], DatanodeInfoWithStorage[127.0.0.1:42506,DS-9a01eda3-bfe2-4186-b783-90611c82554d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-675700744-172.17.0.8-1597378029281:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41054,DS-9781fc6c-d498-4884-8e44-5921106ba2d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41947,DS-1765059c-295c-4edb-96ee-3c8a389f0894,DISK], DatanodeInfoWithStorage[127.0.0.1:42123,DS-6db42075-3c96-4992-a01b-f6c047b10c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43944,DS-8c5381c3-e976-432f-8845-ceaca9dbb30a,DISK], DatanodeInfoWithStorage[127.0.0.1:44326,DS-688babeb-a9bc-4437-809d-9d7e9f7f14fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33753,DS-1c54fd73-25b5-49ea-bafa-ee4e1df7fe18,DISK], DatanodeInfoWithStorage[127.0.0.1:44729,DS-d68fb9ef-626b-4fd0-985b-4262afab2d17,DISK], DatanodeInfoWithStorage[127.0.0.1:42506,DS-9a01eda3-bfe2-4186-b783-90611c82554d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1000000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1573749487-172.17.0.8-1597378640556:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33199,DS-0f4d1356-17bc-41a6-92c8-4ac7c4fe830d,DISK], DatanodeInfoWithStorage[127.0.0.1:46098,DS-19c119c5-885b-41a7-a37a-bfe2437cc147,DISK], DatanodeInfoWithStorage[127.0.0.1:37319,DS-02a4efdb-3123-44d0-908d-05bb6c669f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:33243,DS-ce44f96c-1d6e-4ee6-8d53-7c8c6bc89861,DISK], DatanodeInfoWithStorage[127.0.0.1:39845,DS-a50c3b5e-a0c7-4527-8bfd-662dc5f18856,DISK], DatanodeInfoWithStorage[127.0.0.1:36267,DS-b865db39-73eb-4995-931e-ed135c41c69c,DISK], DatanodeInfoWithStorage[127.0.0.1:33665,DS-b28c76ef-39a4-45c8-a019-3beeaa15ed20,DISK], DatanodeInfoWithStorage[127.0.0.1:46265,DS-dfb46f86-595b-42b8-af0a-dbf3ca6f1c30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1573749487-172.17.0.8-1597378640556:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33199,DS-0f4d1356-17bc-41a6-92c8-4ac7c4fe830d,DISK], DatanodeInfoWithStorage[127.0.0.1:46098,DS-19c119c5-885b-41a7-a37a-bfe2437cc147,DISK], DatanodeInfoWithStorage[127.0.0.1:37319,DS-02a4efdb-3123-44d0-908d-05bb6c669f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:33243,DS-ce44f96c-1d6e-4ee6-8d53-7c8c6bc89861,DISK], DatanodeInfoWithStorage[127.0.0.1:39845,DS-a50c3b5e-a0c7-4527-8bfd-662dc5f18856,DISK], DatanodeInfoWithStorage[127.0.0.1:36267,DS-b865db39-73eb-4995-931e-ed135c41c69c,DISK], DatanodeInfoWithStorage[127.0.0.1:33665,DS-b28c76ef-39a4-45c8-a019-3beeaa15ed20,DISK], DatanodeInfoWithStorage[127.0.0.1:46265,DS-dfb46f86-595b-42b8-af0a-dbf3ca6f1c30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5589
