reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-139427848-172.17.0.8-1597600506856:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43746,DS-9e47238f-189b-43f7-af4e-955dba84e9c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33571,DS-6cc232ed-2ecf-4102-8de3-dbe6e705be32,DISK], DatanodeInfoWithStorage[127.0.0.1:33672,DS-67073b30-4329-482c-83f0-ed1db7d16609,DISK], DatanodeInfoWithStorage[127.0.0.1:33948,DS-cf1923f9-3421-4a8e-92d2-b86c1c97355f,DISK], DatanodeInfoWithStorage[127.0.0.1:38396,DS-a0f4fe98-33c3-48b1-91a9-209632013e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:46637,DS-cce6364d-b51e-4c17-9538-488e47a066a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37596,DS-a6e2f630-0bb7-48c8-87b4-5389811d0b66,DISK], DatanodeInfoWithStorage[127.0.0.1:46318,DS-eba53b0e-b62e-45fd-88af-aa425a76d648,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-139427848-172.17.0.8-1597600506856:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43746,DS-9e47238f-189b-43f7-af4e-955dba84e9c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33571,DS-6cc232ed-2ecf-4102-8de3-dbe6e705be32,DISK], DatanodeInfoWithStorage[127.0.0.1:33672,DS-67073b30-4329-482c-83f0-ed1db7d16609,DISK], DatanodeInfoWithStorage[127.0.0.1:33948,DS-cf1923f9-3421-4a8e-92d2-b86c1c97355f,DISK], DatanodeInfoWithStorage[127.0.0.1:38396,DS-a0f4fe98-33c3-48b1-91a9-209632013e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:46637,DS-cce6364d-b51e-4c17-9538-488e47a066a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37596,DS-a6e2f630-0bb7-48c8-87b4-5389811d0b66,DISK], DatanodeInfoWithStorage[127.0.0.1:46318,DS-eba53b0e-b62e-45fd-88af-aa425a76d648,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-959233755-172.17.0.8-1597600921233:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33568,DS-960105a9-8c27-4d3f-98eb-f27a993c49e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42838,DS-7e5b793b-71db-44b4-b5c7-f3c50a165f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:46827,DS-3ea3dbcb-943a-4c49-93b7-b9a933a16d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45211,DS-d30d8d8a-cd41-4e8c-958b-22d2394b1887,DISK], DatanodeInfoWithStorage[127.0.0.1:41480,DS-c2e50ba0-dd98-4048-bffb-bcfec6fae646,DISK], DatanodeInfoWithStorage[127.0.0.1:34706,DS-8580e9bc-612a-4e6d-921d-f6ea4e895cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:46145,DS-6e2ab7c5-861f-448e-8157-0e662d731f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44863,DS-c3280537-1673-4cec-bf1f-10bca9bbf1e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-959233755-172.17.0.8-1597600921233:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33568,DS-960105a9-8c27-4d3f-98eb-f27a993c49e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42838,DS-7e5b793b-71db-44b4-b5c7-f3c50a165f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:46827,DS-3ea3dbcb-943a-4c49-93b7-b9a933a16d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45211,DS-d30d8d8a-cd41-4e8c-958b-22d2394b1887,DISK], DatanodeInfoWithStorage[127.0.0.1:41480,DS-c2e50ba0-dd98-4048-bffb-bcfec6fae646,DISK], DatanodeInfoWithStorage[127.0.0.1:34706,DS-8580e9bc-612a-4e6d-921d-f6ea4e895cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:46145,DS-6e2ab7c5-861f-448e-8157-0e662d731f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44863,DS-c3280537-1673-4cec-bf1f-10bca9bbf1e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-249962030-172.17.0.8-1597601076971:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42818,DS-fef6e03e-2258-4d68-9683-a876913e2e60,DISK], DatanodeInfoWithStorage[127.0.0.1:42895,DS-b5fdc500-7127-469c-81e0-ad3c1e4a0a22,DISK], DatanodeInfoWithStorage[127.0.0.1:37412,DS-60a3c021-327a-4c6a-92b8-6d024ac9ac6b,DISK], DatanodeInfoWithStorage[127.0.0.1:38646,DS-60631bb2-fb55-44df-9073-2167719bf194,DISK], DatanodeInfoWithStorage[127.0.0.1:43610,DS-9b728a06-835e-4a12-ba68-395f6cb85cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:33803,DS-7fc4f374-fbb3-4a08-a07b-c23e0aea4843,DISK], DatanodeInfoWithStorage[127.0.0.1:36289,DS-1e1f7531-f9e6-49d8-8640-30b7afa9f8f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42409,DS-9821e7dc-e521-41f0-80c9-43a64b6590bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-249962030-172.17.0.8-1597601076971:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42818,DS-fef6e03e-2258-4d68-9683-a876913e2e60,DISK], DatanodeInfoWithStorage[127.0.0.1:42895,DS-b5fdc500-7127-469c-81e0-ad3c1e4a0a22,DISK], DatanodeInfoWithStorage[127.0.0.1:37412,DS-60a3c021-327a-4c6a-92b8-6d024ac9ac6b,DISK], DatanodeInfoWithStorage[127.0.0.1:38646,DS-60631bb2-fb55-44df-9073-2167719bf194,DISK], DatanodeInfoWithStorage[127.0.0.1:43610,DS-9b728a06-835e-4a12-ba68-395f6cb85cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:33803,DS-7fc4f374-fbb3-4a08-a07b-c23e0aea4843,DISK], DatanodeInfoWithStorage[127.0.0.1:36289,DS-1e1f7531-f9e6-49d8-8640-30b7afa9f8f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42409,DS-9821e7dc-e521-41f0-80c9-43a64b6590bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1971765147-172.17.0.8-1597601131612:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44336,DS-943e3cce-5624-44f3-b62d-0bbeca654e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45604,DS-71d2c829-f9e8-4a1e-906f-fc1322efd7c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37656,DS-23df5969-609d-4586-be2a-df7c29f7c126,DISK], DatanodeInfoWithStorage[127.0.0.1:42196,DS-43ffbd85-f677-43c4-941d-90882f5d05c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40845,DS-24ea4a71-086f-43fa-b63d-4f998972e5f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38425,DS-fac372ce-94c0-4cbb-bb62-0db32fbd2eef,DISK], DatanodeInfoWithStorage[127.0.0.1:36955,DS-924df37c-0201-4369-ab3d-4bf6dfa2a11b,DISK], DatanodeInfoWithStorage[127.0.0.1:33045,DS-24ea7d3a-332f-4e11-9443-a5f5aa41ea36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1971765147-172.17.0.8-1597601131612:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44336,DS-943e3cce-5624-44f3-b62d-0bbeca654e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45604,DS-71d2c829-f9e8-4a1e-906f-fc1322efd7c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37656,DS-23df5969-609d-4586-be2a-df7c29f7c126,DISK], DatanodeInfoWithStorage[127.0.0.1:42196,DS-43ffbd85-f677-43c4-941d-90882f5d05c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40845,DS-24ea4a71-086f-43fa-b63d-4f998972e5f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38425,DS-fac372ce-94c0-4cbb-bb62-0db32fbd2eef,DISK], DatanodeInfoWithStorage[127.0.0.1:36955,DS-924df37c-0201-4369-ab3d-4bf6dfa2a11b,DISK], DatanodeInfoWithStorage[127.0.0.1:33045,DS-24ea7d3a-332f-4e11-9443-a5f5aa41ea36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-220996435-172.17.0.8-1597601284610:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39018,DS-2e0108ee-7bc9-4ffb-bc70-3b7d2d3b54fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35674,DS-81db32c3-a49e-47b8-8e31-c9078142e8fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40853,DS-bcd6f6bf-55b4-4b6a-9df3-0f682db46830,DISK], DatanodeInfoWithStorage[127.0.0.1:42663,DS-f7beebb9-eb37-45fa-8a39-9815a136a4be,DISK], DatanodeInfoWithStorage[127.0.0.1:41429,DS-765e25a2-e71b-4cd2-acb5-c7cb2f2f2125,DISK], DatanodeInfoWithStorage[127.0.0.1:39069,DS-3d7353be-c10b-4044-b057-4eafe52bb27c,DISK], DatanodeInfoWithStorage[127.0.0.1:41029,DS-745093e9-e1c4-49cd-b8a5-a7931fdc467a,DISK], DatanodeInfoWithStorage[127.0.0.1:36414,DS-2aa275fa-eb0e-4705-8c59-320ab1088126,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-220996435-172.17.0.8-1597601284610:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39018,DS-2e0108ee-7bc9-4ffb-bc70-3b7d2d3b54fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35674,DS-81db32c3-a49e-47b8-8e31-c9078142e8fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40853,DS-bcd6f6bf-55b4-4b6a-9df3-0f682db46830,DISK], DatanodeInfoWithStorage[127.0.0.1:42663,DS-f7beebb9-eb37-45fa-8a39-9815a136a4be,DISK], DatanodeInfoWithStorage[127.0.0.1:41429,DS-765e25a2-e71b-4cd2-acb5-c7cb2f2f2125,DISK], DatanodeInfoWithStorage[127.0.0.1:39069,DS-3d7353be-c10b-4044-b057-4eafe52bb27c,DISK], DatanodeInfoWithStorage[127.0.0.1:41029,DS-745093e9-e1c4-49cd-b8a5-a7931fdc467a,DISK], DatanodeInfoWithStorage[127.0.0.1:36414,DS-2aa275fa-eb0e-4705-8c59-320ab1088126,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1505385378-172.17.0.8-1597602226876:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35462,DS-c34ee3bd-9520-40c1-8dbd-e0a48ef72d27,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-7302c08f-1ece-49e9-8893-f2ecc6638081,DISK], DatanodeInfoWithStorage[127.0.0.1:35029,DS-c193d5e4-af3d-4d9d-aeb6-4c42dee0f28d,DISK], DatanodeInfoWithStorage[127.0.0.1:46715,DS-b6503f7f-4c3e-4f5c-9c64-b5fdf3157611,DISK], DatanodeInfoWithStorage[127.0.0.1:38777,DS-733edc72-6454-42f9-a4f0-1be40c1db459,DISK], DatanodeInfoWithStorage[127.0.0.1:36152,DS-c32f98d5-982a-445e-be46-a1a19ac6d415,DISK], DatanodeInfoWithStorage[127.0.0.1:35626,DS-5f46d12e-0cf2-4b8c-b3b4-28b704a6b5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38445,DS-1cd1192f-b5cd-4d78-9794-adbccece6fe7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1505385378-172.17.0.8-1597602226876:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35462,DS-c34ee3bd-9520-40c1-8dbd-e0a48ef72d27,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-7302c08f-1ece-49e9-8893-f2ecc6638081,DISK], DatanodeInfoWithStorage[127.0.0.1:35029,DS-c193d5e4-af3d-4d9d-aeb6-4c42dee0f28d,DISK], DatanodeInfoWithStorage[127.0.0.1:46715,DS-b6503f7f-4c3e-4f5c-9c64-b5fdf3157611,DISK], DatanodeInfoWithStorage[127.0.0.1:38777,DS-733edc72-6454-42f9-a4f0-1be40c1db459,DISK], DatanodeInfoWithStorage[127.0.0.1:36152,DS-c32f98d5-982a-445e-be46-a1a19ac6d415,DISK], DatanodeInfoWithStorage[127.0.0.1:35626,DS-5f46d12e-0cf2-4b8c-b3b4-28b704a6b5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38445,DS-1cd1192f-b5cd-4d78-9794-adbccece6fe7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-712638374-172.17.0.8-1597603036926:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34428,DS-94a4cf0d-9740-4e45-a206-297474838ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:38583,DS-f128672b-a587-40d1-8464-822badbad4cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34134,DS-df89077e-abc4-47fc-a854-38820a15758a,DISK], DatanodeInfoWithStorage[127.0.0.1:38212,DS-3b93122f-a9c6-4e3d-ac3d-59c00554789e,DISK], DatanodeInfoWithStorage[127.0.0.1:34206,DS-c72d47df-752a-4b41-a9da-ba7c5ba1ee15,DISK], DatanodeInfoWithStorage[127.0.0.1:36248,DS-86ee2426-603e-4f59-a4c2-bfe3e38e6cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:33029,DS-a9f7f733-265c-4f0b-890f-1deca0fc5a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40880,DS-13d4e40a-aa04-4ab0-bdc8-4e6b56f44843,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-712638374-172.17.0.8-1597603036926:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34428,DS-94a4cf0d-9740-4e45-a206-297474838ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:38583,DS-f128672b-a587-40d1-8464-822badbad4cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34134,DS-df89077e-abc4-47fc-a854-38820a15758a,DISK], DatanodeInfoWithStorage[127.0.0.1:38212,DS-3b93122f-a9c6-4e3d-ac3d-59c00554789e,DISK], DatanodeInfoWithStorage[127.0.0.1:34206,DS-c72d47df-752a-4b41-a9da-ba7c5ba1ee15,DISK], DatanodeInfoWithStorage[127.0.0.1:36248,DS-86ee2426-603e-4f59-a4c2-bfe3e38e6cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:33029,DS-a9f7f733-265c-4f0b-890f-1deca0fc5a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40880,DS-13d4e40a-aa04-4ab0-bdc8-4e6b56f44843,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1918850564-172.17.0.8-1597604720566:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38702,DS-08c9f3bd-3f41-43e7-833e-2431b43a6b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34580,DS-11bd3e8b-0cbc-4150-b26d-3a7d6d38a3a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44120,DS-507167ac-24ae-4edd-bdd4-d330258601cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36187,DS-dc05e5aa-9dd4-45e7-8768-c69c8db915bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46018,DS-5a96d82f-d699-4216-8f1e-9db4b6f64b64,DISK], DatanodeInfoWithStorage[127.0.0.1:46863,DS-8caba767-785b-4d0e-a063-8ee4b8b9f904,DISK], DatanodeInfoWithStorage[127.0.0.1:42496,DS-32ea5100-40aa-447d-b6e2-8338f77cb6a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43891,DS-547b0e55-0cc1-4d51-8182-836bedb378f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1918850564-172.17.0.8-1597604720566:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38702,DS-08c9f3bd-3f41-43e7-833e-2431b43a6b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34580,DS-11bd3e8b-0cbc-4150-b26d-3a7d6d38a3a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44120,DS-507167ac-24ae-4edd-bdd4-d330258601cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36187,DS-dc05e5aa-9dd4-45e7-8768-c69c8db915bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46018,DS-5a96d82f-d699-4216-8f1e-9db4b6f64b64,DISK], DatanodeInfoWithStorage[127.0.0.1:46863,DS-8caba767-785b-4d0e-a063-8ee4b8b9f904,DISK], DatanodeInfoWithStorage[127.0.0.1:42496,DS-32ea5100-40aa-447d-b6e2-8338f77cb6a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43891,DS-547b0e55-0cc1-4d51-8182-836bedb378f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2116818608-172.17.0.8-1597605116334:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33776,DS-6c5315fd-cad8-491c-8beb-c1790b5c16bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46026,DS-61b2a5e3-7e7e-4ef9-a321-e2543753a2a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38627,DS-b613f861-410e-447c-9a5b-5b1fe7bafbf5,DISK], DatanodeInfoWithStorage[127.0.0.1:35401,DS-57a33ed0-f7fb-462a-81a7-8be8afb5d82b,DISK], DatanodeInfoWithStorage[127.0.0.1:42645,DS-fe5c2680-d2ca-4a6b-ac09-14ccc4a71d01,DISK], DatanodeInfoWithStorage[127.0.0.1:37147,DS-55ba0661-b60a-422e-83d5-5432ee863125,DISK], DatanodeInfoWithStorage[127.0.0.1:46484,DS-9c7bc5cf-188f-417a-aa8f-c7994ad2fa88,DISK], DatanodeInfoWithStorage[127.0.0.1:33506,DS-1feafb5f-553b-433a-8979-9825f6aef4bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2116818608-172.17.0.8-1597605116334:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33776,DS-6c5315fd-cad8-491c-8beb-c1790b5c16bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46026,DS-61b2a5e3-7e7e-4ef9-a321-e2543753a2a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38627,DS-b613f861-410e-447c-9a5b-5b1fe7bafbf5,DISK], DatanodeInfoWithStorage[127.0.0.1:35401,DS-57a33ed0-f7fb-462a-81a7-8be8afb5d82b,DISK], DatanodeInfoWithStorage[127.0.0.1:42645,DS-fe5c2680-d2ca-4a6b-ac09-14ccc4a71d01,DISK], DatanodeInfoWithStorage[127.0.0.1:37147,DS-55ba0661-b60a-422e-83d5-5432ee863125,DISK], DatanodeInfoWithStorage[127.0.0.1:46484,DS-9c7bc5cf-188f-417a-aa8f-c7994ad2fa88,DISK], DatanodeInfoWithStorage[127.0.0.1:33506,DS-1feafb5f-553b-433a-8979-9825f6aef4bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1015101037-172.17.0.8-1597607069345:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36378,DS-949ad2bc-6cf5-495f-b0e9-d9d886e98cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:42038,DS-da01757f-578f-4cf3-8e1e-38745a7c54cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43541,DS-c34b0121-635e-4a18-98d4-257205816b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:40612,DS-85a33889-1aa5-4334-badd-9d417dd8c966,DISK], DatanodeInfoWithStorage[127.0.0.1:44292,DS-e90d47ca-f149-4fe7-bec0-d4c9e4ed8cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:46499,DS-9a4b28e9-9b5f-4807-a5a8-68166ce7af6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36325,DS-133def70-5c81-450b-be2f-db3e06885d89,DISK], DatanodeInfoWithStorage[127.0.0.1:35235,DS-3ca846b3-d9c1-492e-b4cf-dfd266178b91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1015101037-172.17.0.8-1597607069345:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36378,DS-949ad2bc-6cf5-495f-b0e9-d9d886e98cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:42038,DS-da01757f-578f-4cf3-8e1e-38745a7c54cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43541,DS-c34b0121-635e-4a18-98d4-257205816b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:40612,DS-85a33889-1aa5-4334-badd-9d417dd8c966,DISK], DatanodeInfoWithStorage[127.0.0.1:44292,DS-e90d47ca-f149-4fe7-bec0-d4c9e4ed8cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:46499,DS-9a4b28e9-9b5f-4807-a5a8-68166ce7af6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36325,DS-133def70-5c81-450b-be2f-db3e06885d89,DISK], DatanodeInfoWithStorage[127.0.0.1:35235,DS-3ca846b3-d9c1-492e-b4cf-dfd266178b91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2129267937-172.17.0.8-1597607728081:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33056,DS-9b414975-a3c3-4e32-adbe-595f19b36d90,DISK], DatanodeInfoWithStorage[127.0.0.1:35833,DS-89122b51-dc97-40a4-a57f-e5472ebcd590,DISK], DatanodeInfoWithStorage[127.0.0.1:45321,DS-185b748d-b3b4-42fa-a1fb-302615d8fa29,DISK], DatanodeInfoWithStorage[127.0.0.1:41787,DS-155cc5da-6b89-4e4c-a1c0-418552c8fd23,DISK], DatanodeInfoWithStorage[127.0.0.1:40176,DS-e8f3c5b2-0061-476f-91b9-2156d469a82a,DISK], DatanodeInfoWithStorage[127.0.0.1:35590,DS-0554cbde-42cf-41fb-a0b1-abe25db209ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46109,DS-8a28cffe-e7a0-44bc-b6bb-d4dcc17ed96c,DISK], DatanodeInfoWithStorage[127.0.0.1:40619,DS-3751d0a9-3de9-431d-854d-4785da9ec523,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2129267937-172.17.0.8-1597607728081:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33056,DS-9b414975-a3c3-4e32-adbe-595f19b36d90,DISK], DatanodeInfoWithStorage[127.0.0.1:35833,DS-89122b51-dc97-40a4-a57f-e5472ebcd590,DISK], DatanodeInfoWithStorage[127.0.0.1:45321,DS-185b748d-b3b4-42fa-a1fb-302615d8fa29,DISK], DatanodeInfoWithStorage[127.0.0.1:41787,DS-155cc5da-6b89-4e4c-a1c0-418552c8fd23,DISK], DatanodeInfoWithStorage[127.0.0.1:40176,DS-e8f3c5b2-0061-476f-91b9-2156d469a82a,DISK], DatanodeInfoWithStorage[127.0.0.1:35590,DS-0554cbde-42cf-41fb-a0b1-abe25db209ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46109,DS-8a28cffe-e7a0-44bc-b6bb-d4dcc17ed96c,DISK], DatanodeInfoWithStorage[127.0.0.1:40619,DS-3751d0a9-3de9-431d-854d-4785da9ec523,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 7416
