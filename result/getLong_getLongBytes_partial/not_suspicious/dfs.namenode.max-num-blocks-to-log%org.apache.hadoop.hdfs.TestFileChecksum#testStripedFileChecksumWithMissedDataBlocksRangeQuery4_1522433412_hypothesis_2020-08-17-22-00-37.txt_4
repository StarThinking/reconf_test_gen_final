reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1557640555-172.17.0.8-1597701927898:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38164,DS-231e66f2-586d-4783-a8ef-57bf316f3b43,DISK], DatanodeInfoWithStorage[127.0.0.1:40444,DS-671d2565-a585-47f9-a4df-44fd15c09d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43783,DS-d66cbb58-6111-4ed4-ae9d-e464a36e1c78,DISK], DatanodeInfoWithStorage[127.0.0.1:39248,DS-a9ca6903-0633-41e0-9e2e-65f07c26646e,DISK], DatanodeInfoWithStorage[127.0.0.1:45513,DS-5deb49cc-3067-44c2-809c-a69050e11095,DISK], DatanodeInfoWithStorage[127.0.0.1:43067,DS-c3a6fc09-c10d-4d71-9db0-21cfe8f996bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40387,DS-8eee7cec-3f5b-429a-a9f6-8f6ad39a3a63,DISK], DatanodeInfoWithStorage[127.0.0.1:33100,DS-7389cb4e-423e-40ca-a1e1-1f0433ebb685,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1557640555-172.17.0.8-1597701927898:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38164,DS-231e66f2-586d-4783-a8ef-57bf316f3b43,DISK], DatanodeInfoWithStorage[127.0.0.1:40444,DS-671d2565-a585-47f9-a4df-44fd15c09d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43783,DS-d66cbb58-6111-4ed4-ae9d-e464a36e1c78,DISK], DatanodeInfoWithStorage[127.0.0.1:39248,DS-a9ca6903-0633-41e0-9e2e-65f07c26646e,DISK], DatanodeInfoWithStorage[127.0.0.1:45513,DS-5deb49cc-3067-44c2-809c-a69050e11095,DISK], DatanodeInfoWithStorage[127.0.0.1:43067,DS-c3a6fc09-c10d-4d71-9db0-21cfe8f996bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40387,DS-8eee7cec-3f5b-429a-a9f6-8f6ad39a3a63,DISK], DatanodeInfoWithStorage[127.0.0.1:33100,DS-7389cb4e-423e-40ca-a1e1-1f0433ebb685,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1093039113-172.17.0.8-1597702044231:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40484,DS-b635311a-e270-41b0-b1b4-19418b5285a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35848,DS-d3b6f05a-1ea8-46e2-9e5e-1b2cbabef1e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46779,DS-e5ff5d5c-d0cb-4060-b131-65f490f51d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:37917,DS-5284366c-1e4f-4b74-94af-9a206760c917,DISK], DatanodeInfoWithStorage[127.0.0.1:36273,DS-c7e020e0-395d-4a30-a159-2a32c59e281e,DISK], DatanodeInfoWithStorage[127.0.0.1:38401,DS-4384588f-a6f0-4a26-8841-b9facef49d83,DISK], DatanodeInfoWithStorage[127.0.0.1:34747,DS-e68e7f35-6ca0-4820-b593-47bde48a9b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:41389,DS-3ec8de2e-fb47-49b7-a259-3b6a6f7eb2b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1093039113-172.17.0.8-1597702044231:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40484,DS-b635311a-e270-41b0-b1b4-19418b5285a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35848,DS-d3b6f05a-1ea8-46e2-9e5e-1b2cbabef1e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46779,DS-e5ff5d5c-d0cb-4060-b131-65f490f51d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:37917,DS-5284366c-1e4f-4b74-94af-9a206760c917,DISK], DatanodeInfoWithStorage[127.0.0.1:36273,DS-c7e020e0-395d-4a30-a159-2a32c59e281e,DISK], DatanodeInfoWithStorage[127.0.0.1:38401,DS-4384588f-a6f0-4a26-8841-b9facef49d83,DISK], DatanodeInfoWithStorage[127.0.0.1:34747,DS-e68e7f35-6ca0-4820-b593-47bde48a9b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:41389,DS-3ec8de2e-fb47-49b7-a259-3b6a6f7eb2b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1925159535-172.17.0.8-1597702914645:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46372,DS-bb2db8b2-a361-45ab-b78c-13b45ff15da3,DISK], DatanodeInfoWithStorage[127.0.0.1:41834,DS-9b2b2b8e-ff4e-4e76-a2c4-5ffd5c34abdf,DISK], DatanodeInfoWithStorage[127.0.0.1:42324,DS-f97887ef-a2ab-425e-bc9a-0089698083b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36733,DS-03888334-d496-4474-804c-da23b599c420,DISK], DatanodeInfoWithStorage[127.0.0.1:33900,DS-3e07e188-e6b9-4cb5-9547-f0b90ac09eeb,DISK], DatanodeInfoWithStorage[127.0.0.1:43890,DS-1b0a405e-dcf4-4eed-852f-b051899ced4a,DISK], DatanodeInfoWithStorage[127.0.0.1:45566,DS-94dbf86a-42ba-43bf-8e1e-f5ec622c78aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39126,DS-eb3c6107-5ed4-47f3-ae81-564bca8564fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1925159535-172.17.0.8-1597702914645:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46372,DS-bb2db8b2-a361-45ab-b78c-13b45ff15da3,DISK], DatanodeInfoWithStorage[127.0.0.1:41834,DS-9b2b2b8e-ff4e-4e76-a2c4-5ffd5c34abdf,DISK], DatanodeInfoWithStorage[127.0.0.1:42324,DS-f97887ef-a2ab-425e-bc9a-0089698083b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36733,DS-03888334-d496-4474-804c-da23b599c420,DISK], DatanodeInfoWithStorage[127.0.0.1:33900,DS-3e07e188-e6b9-4cb5-9547-f0b90ac09eeb,DISK], DatanodeInfoWithStorage[127.0.0.1:43890,DS-1b0a405e-dcf4-4eed-852f-b051899ced4a,DISK], DatanodeInfoWithStorage[127.0.0.1:45566,DS-94dbf86a-42ba-43bf-8e1e-f5ec622c78aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39126,DS-eb3c6107-5ed4-47f3-ae81-564bca8564fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-857123439-172.17.0.8-1597702991326:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33121,DS-f17fe897-fb02-47dd-9005-aecbf369fc8f,DISK], DatanodeInfoWithStorage[127.0.0.1:38362,DS-0f98461e-26bd-486b-a14d-fa4a3ad3a7df,DISK], DatanodeInfoWithStorage[127.0.0.1:39339,DS-6d48d2ec-58d5-4113-8b41-8788d69ab65e,DISK], DatanodeInfoWithStorage[127.0.0.1:38382,DS-12060a61-3254-421f-9f8e-e3a7fe1c5ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:46660,DS-cee19870-790e-4cc4-958b-93bdf270b019,DISK], DatanodeInfoWithStorage[127.0.0.1:45444,DS-5474cfcd-447f-45ea-a32d-47507ba842ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35775,DS-7ae40d26-f165-4f7c-a8c3-4609652dbe82,DISK], DatanodeInfoWithStorage[127.0.0.1:45381,DS-d0fe3976-2dbb-47e9-b4c3-3072a4517586,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-857123439-172.17.0.8-1597702991326:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33121,DS-f17fe897-fb02-47dd-9005-aecbf369fc8f,DISK], DatanodeInfoWithStorage[127.0.0.1:38362,DS-0f98461e-26bd-486b-a14d-fa4a3ad3a7df,DISK], DatanodeInfoWithStorage[127.0.0.1:39339,DS-6d48d2ec-58d5-4113-8b41-8788d69ab65e,DISK], DatanodeInfoWithStorage[127.0.0.1:38382,DS-12060a61-3254-421f-9f8e-e3a7fe1c5ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:46660,DS-cee19870-790e-4cc4-958b-93bdf270b019,DISK], DatanodeInfoWithStorage[127.0.0.1:45444,DS-5474cfcd-447f-45ea-a32d-47507ba842ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35775,DS-7ae40d26-f165-4f7c-a8c3-4609652dbe82,DISK], DatanodeInfoWithStorage[127.0.0.1:45381,DS-d0fe3976-2dbb-47e9-b4c3-3072a4517586,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1002005426-172.17.0.8-1597703182166:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44846,DS-1dedcf26-d677-45cb-90b0-49e677c3688e,DISK], DatanodeInfoWithStorage[127.0.0.1:33111,DS-679df8a2-18e1-40ae-857d-f21667fb8999,DISK], DatanodeInfoWithStorage[127.0.0.1:33000,DS-1f44926a-08ba-4385-9cdc-4bef588bff03,DISK], DatanodeInfoWithStorage[127.0.0.1:45581,DS-c227d47b-fe5e-41a9-a147-20b88edc6175,DISK], DatanodeInfoWithStorage[127.0.0.1:45886,DS-3e672c09-f9b1-4ab7-a8f3-6fb69ee094d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41636,DS-d9e339fd-0d5e-4f53-a54c-27cc1dae780c,DISK], DatanodeInfoWithStorage[127.0.0.1:44432,DS-13b3917d-2615-442f-8ac7-462db4cd7e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40696,DS-cfc63422-b445-45a7-b076-ad2de006b1ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1002005426-172.17.0.8-1597703182166:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44846,DS-1dedcf26-d677-45cb-90b0-49e677c3688e,DISK], DatanodeInfoWithStorage[127.0.0.1:33111,DS-679df8a2-18e1-40ae-857d-f21667fb8999,DISK], DatanodeInfoWithStorage[127.0.0.1:33000,DS-1f44926a-08ba-4385-9cdc-4bef588bff03,DISK], DatanodeInfoWithStorage[127.0.0.1:45581,DS-c227d47b-fe5e-41a9-a147-20b88edc6175,DISK], DatanodeInfoWithStorage[127.0.0.1:45886,DS-3e672c09-f9b1-4ab7-a8f3-6fb69ee094d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41636,DS-d9e339fd-0d5e-4f53-a54c-27cc1dae780c,DISK], DatanodeInfoWithStorage[127.0.0.1:44432,DS-13b3917d-2615-442f-8ac7-462db4cd7e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40696,DS-cfc63422-b445-45a7-b076-ad2de006b1ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-717833118-172.17.0.8-1597703219761:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41117,DS-6295fe28-5037-49ac-941e-552ec56cc975,DISK], DatanodeInfoWithStorage[127.0.0.1:40653,DS-68223e49-6280-4f4d-998d-d39bbe0e6df9,DISK], DatanodeInfoWithStorage[127.0.0.1:33714,DS-7432e4da-c215-4282-ba3c-0d773dc6c49c,DISK], DatanodeInfoWithStorage[127.0.0.1:41405,DS-6527cf8e-e6eb-4365-8be0-c24210caf6c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46549,DS-22684343-8b31-4174-9c9a-d2217354388a,DISK], DatanodeInfoWithStorage[127.0.0.1:38414,DS-27f5f17c-6c1e-4cfb-b2a0-16629f07f820,DISK], DatanodeInfoWithStorage[127.0.0.1:38443,DS-6296539b-6fab-4a21-b20c-129544fb2622,DISK], DatanodeInfoWithStorage[127.0.0.1:40358,DS-73d7f210-d7ec-4e5d-8479-1a8ede568353,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-717833118-172.17.0.8-1597703219761:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41117,DS-6295fe28-5037-49ac-941e-552ec56cc975,DISK], DatanodeInfoWithStorage[127.0.0.1:40653,DS-68223e49-6280-4f4d-998d-d39bbe0e6df9,DISK], DatanodeInfoWithStorage[127.0.0.1:33714,DS-7432e4da-c215-4282-ba3c-0d773dc6c49c,DISK], DatanodeInfoWithStorage[127.0.0.1:41405,DS-6527cf8e-e6eb-4365-8be0-c24210caf6c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46549,DS-22684343-8b31-4174-9c9a-d2217354388a,DISK], DatanodeInfoWithStorage[127.0.0.1:38414,DS-27f5f17c-6c1e-4cfb-b2a0-16629f07f820,DISK], DatanodeInfoWithStorage[127.0.0.1:38443,DS-6296539b-6fab-4a21-b20c-129544fb2622,DISK], DatanodeInfoWithStorage[127.0.0.1:40358,DS-73d7f210-d7ec-4e5d-8479-1a8ede568353,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1504452355-172.17.0.8-1597703502431:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36172,DS-04e037f0-ce3f-4623-b1ae-a479062a4a34,DISK], DatanodeInfoWithStorage[127.0.0.1:45094,DS-baa08dbc-0a01-4d5a-a89e-60fc1f06d886,DISK], DatanodeInfoWithStorage[127.0.0.1:44191,DS-58cc5d56-3f10-4120-baaa-5e82d8b1cf1b,DISK], DatanodeInfoWithStorage[127.0.0.1:40678,DS-53ae4fd8-ad45-4e72-a84b-10c8ac8831f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45426,DS-333f7b07-139d-448c-a3cf-e32d56269a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:33019,DS-968aa850-b19d-4bc7-bc74-915007fb982e,DISK], DatanodeInfoWithStorage[127.0.0.1:33501,DS-1447dcc5-f93e-420f-8c07-8cff926a13cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38837,DS-73324350-706d-40f9-ab62-24936136472e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1504452355-172.17.0.8-1597703502431:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36172,DS-04e037f0-ce3f-4623-b1ae-a479062a4a34,DISK], DatanodeInfoWithStorage[127.0.0.1:45094,DS-baa08dbc-0a01-4d5a-a89e-60fc1f06d886,DISK], DatanodeInfoWithStorage[127.0.0.1:44191,DS-58cc5d56-3f10-4120-baaa-5e82d8b1cf1b,DISK], DatanodeInfoWithStorage[127.0.0.1:40678,DS-53ae4fd8-ad45-4e72-a84b-10c8ac8831f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45426,DS-333f7b07-139d-448c-a3cf-e32d56269a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:33019,DS-968aa850-b19d-4bc7-bc74-915007fb982e,DISK], DatanodeInfoWithStorage[127.0.0.1:33501,DS-1447dcc5-f93e-420f-8c07-8cff926a13cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38837,DS-73324350-706d-40f9-ab62-24936136472e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1167958512-172.17.0.8-1597703857798:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45280,DS-25f04f22-ae16-4e27-87cd-8ebb803dda13,DISK], DatanodeInfoWithStorage[127.0.0.1:46305,DS-3b16f7b6-4f4d-43fb-b996-865af5abd80f,DISK], DatanodeInfoWithStorage[127.0.0.1:46683,DS-85c971c7-27c5-465f-9fc5-b4933d7d21af,DISK], DatanodeInfoWithStorage[127.0.0.1:41884,DS-9bf8ee94-595b-42fb-85a4-17909d901055,DISK], DatanodeInfoWithStorage[127.0.0.1:34511,DS-2a76bd15-b81f-4679-85db-6c095550bcb0,DISK], DatanodeInfoWithStorage[127.0.0.1:45517,DS-4613c5ca-526d-4fc8-9940-ea6b0697cd19,DISK], DatanodeInfoWithStorage[127.0.0.1:35106,DS-a4c4142c-23ae-47ce-b1c0-c66824492711,DISK], DatanodeInfoWithStorage[127.0.0.1:42345,DS-ef302dc5-e652-47b7-9738-f685573f931a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1167958512-172.17.0.8-1597703857798:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45280,DS-25f04f22-ae16-4e27-87cd-8ebb803dda13,DISK], DatanodeInfoWithStorage[127.0.0.1:46305,DS-3b16f7b6-4f4d-43fb-b996-865af5abd80f,DISK], DatanodeInfoWithStorage[127.0.0.1:46683,DS-85c971c7-27c5-465f-9fc5-b4933d7d21af,DISK], DatanodeInfoWithStorage[127.0.0.1:41884,DS-9bf8ee94-595b-42fb-85a4-17909d901055,DISK], DatanodeInfoWithStorage[127.0.0.1:34511,DS-2a76bd15-b81f-4679-85db-6c095550bcb0,DISK], DatanodeInfoWithStorage[127.0.0.1:45517,DS-4613c5ca-526d-4fc8-9940-ea6b0697cd19,DISK], DatanodeInfoWithStorage[127.0.0.1:35106,DS-a4c4142c-23ae-47ce-b1c0-c66824492711,DISK], DatanodeInfoWithStorage[127.0.0.1:42345,DS-ef302dc5-e652-47b7-9738-f685573f931a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-699323318-172.17.0.8-1597703927791:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43026,DS-6a22edd5-9f37-4c6d-8ad8-1d00df2e584e,DISK], DatanodeInfoWithStorage[127.0.0.1:40250,DS-02446f87-f313-499a-90b0-4b2e7ae48843,DISK], DatanodeInfoWithStorage[127.0.0.1:34352,DS-2c231fe6-e2df-451b-83b8-737b3e350049,DISK], DatanodeInfoWithStorage[127.0.0.1:37786,DS-5e353c13-1b3d-4ba2-9fbd-be4524040cad,DISK], DatanodeInfoWithStorage[127.0.0.1:38451,DS-b053e35e-bc1a-4af8-a17e-6a70ffa48a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39943,DS-6bde753e-fe60-47e4-836a-43a92a9823d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33644,DS-4411caec-9c6a-4125-b4d3-9a827db5b441,DISK], DatanodeInfoWithStorage[127.0.0.1:34445,DS-216b292b-7307-408e-b31e-7120018800b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-699323318-172.17.0.8-1597703927791:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43026,DS-6a22edd5-9f37-4c6d-8ad8-1d00df2e584e,DISK], DatanodeInfoWithStorage[127.0.0.1:40250,DS-02446f87-f313-499a-90b0-4b2e7ae48843,DISK], DatanodeInfoWithStorage[127.0.0.1:34352,DS-2c231fe6-e2df-451b-83b8-737b3e350049,DISK], DatanodeInfoWithStorage[127.0.0.1:37786,DS-5e353c13-1b3d-4ba2-9fbd-be4524040cad,DISK], DatanodeInfoWithStorage[127.0.0.1:38451,DS-b053e35e-bc1a-4af8-a17e-6a70ffa48a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39943,DS-6bde753e-fe60-47e4-836a-43a92a9823d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33644,DS-4411caec-9c6a-4125-b4d3-9a827db5b441,DISK], DatanodeInfoWithStorage[127.0.0.1:34445,DS-216b292b-7307-408e-b31e-7120018800b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-593173123-172.17.0.8-1597704767775:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44352,DS-cf401c13-3c16-4673-a106-fe6c034ab2bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46544,DS-41d8622c-d419-4f9c-89ad-8b37203f4f15,DISK], DatanodeInfoWithStorage[127.0.0.1:43236,DS-85ff02fd-12b7-461d-8abf-d8a7f9f749e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43365,DS-2f15db4f-b656-45ad-98bb-de3e847423ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37318,DS-c0714288-7333-4ff9-a2df-f46646ee3f55,DISK], DatanodeInfoWithStorage[127.0.0.1:36375,DS-5c2f55c2-578e-4437-905a-9ab8ccd66a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36508,DS-7bca2440-30bb-475d-bd7e-dfbc9fef73bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35982,DS-fdb654e1-cb4d-41f1-9da3-01a47b9dafc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-593173123-172.17.0.8-1597704767775:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44352,DS-cf401c13-3c16-4673-a106-fe6c034ab2bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46544,DS-41d8622c-d419-4f9c-89ad-8b37203f4f15,DISK], DatanodeInfoWithStorage[127.0.0.1:43236,DS-85ff02fd-12b7-461d-8abf-d8a7f9f749e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43365,DS-2f15db4f-b656-45ad-98bb-de3e847423ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37318,DS-c0714288-7333-4ff9-a2df-f46646ee3f55,DISK], DatanodeInfoWithStorage[127.0.0.1:36375,DS-5c2f55c2-578e-4437-905a-9ab8ccd66a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36508,DS-7bca2440-30bb-475d-bd7e-dfbc9fef73bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35982,DS-fdb654e1-cb4d-41f1-9da3-01a47b9dafc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-498343122-172.17.0.8-1597705050234:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42011,DS-0dd57176-fb3c-463a-bff4-a697deafd8db,DISK], DatanodeInfoWithStorage[127.0.0.1:43926,DS-cf834cbe-13b2-4d92-8443-a31eeed3024b,DISK], DatanodeInfoWithStorage[127.0.0.1:34554,DS-bfbcce02-c00a-4455-b42e-ce32788a8822,DISK], DatanodeInfoWithStorage[127.0.0.1:34223,DS-836f80f8-11b8-45f9-bc2d-72f04896901a,DISK], DatanodeInfoWithStorage[127.0.0.1:46439,DS-dde96357-2fd8-456d-a574-0b7a81c0dcbf,DISK], DatanodeInfoWithStorage[127.0.0.1:35474,DS-d0d9afdc-408f-4204-b865-c27510cf5bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:35039,DS-00b79507-fa58-41aa-a054-19027f7a2152,DISK], DatanodeInfoWithStorage[127.0.0.1:42329,DS-5a11437e-98b7-44c3-8e96-a3d40c4f63d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-498343122-172.17.0.8-1597705050234:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42011,DS-0dd57176-fb3c-463a-bff4-a697deafd8db,DISK], DatanodeInfoWithStorage[127.0.0.1:43926,DS-cf834cbe-13b2-4d92-8443-a31eeed3024b,DISK], DatanodeInfoWithStorage[127.0.0.1:34554,DS-bfbcce02-c00a-4455-b42e-ce32788a8822,DISK], DatanodeInfoWithStorage[127.0.0.1:34223,DS-836f80f8-11b8-45f9-bc2d-72f04896901a,DISK], DatanodeInfoWithStorage[127.0.0.1:46439,DS-dde96357-2fd8-456d-a574-0b7a81c0dcbf,DISK], DatanodeInfoWithStorage[127.0.0.1:35474,DS-d0d9afdc-408f-4204-b865-c27510cf5bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:35039,DS-00b79507-fa58-41aa-a054-19027f7a2152,DISK], DatanodeInfoWithStorage[127.0.0.1:42329,DS-5a11437e-98b7-44c3-8e96-a3d40c4f63d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1475327503-172.17.0.8-1597705119889:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40969,DS-bad9474a-0638-41e7-a529-0b394ee14cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:42620,DS-c945a2a2-6015-4dc3-ae95-1d42cd66a2ca,DISK], DatanodeInfoWithStorage[127.0.0.1:32873,DS-31d6fce4-4370-4d2b-ab37-8c7a0cad6ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:43082,DS-1efbf557-55a7-4a67-ad5d-ea29e69ab0aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41669,DS-3232f776-1f2f-4f02-b268-511a6b0cf2e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46082,DS-72e7a8ef-9b7e-44b6-ab14-6d18218b84f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36824,DS-fbb4bb1a-d537-4733-a2c1-4e831194fd9a,DISK], DatanodeInfoWithStorage[127.0.0.1:41081,DS-b302d242-1dce-4e4f-8d00-071cc0e2382d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1475327503-172.17.0.8-1597705119889:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40969,DS-bad9474a-0638-41e7-a529-0b394ee14cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:42620,DS-c945a2a2-6015-4dc3-ae95-1d42cd66a2ca,DISK], DatanodeInfoWithStorage[127.0.0.1:32873,DS-31d6fce4-4370-4d2b-ab37-8c7a0cad6ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:43082,DS-1efbf557-55a7-4a67-ad5d-ea29e69ab0aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41669,DS-3232f776-1f2f-4f02-b268-511a6b0cf2e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46082,DS-72e7a8ef-9b7e-44b6-ab14-6d18218b84f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36824,DS-fbb4bb1a-d537-4733-a2c1-4e831194fd9a,DISK], DatanodeInfoWithStorage[127.0.0.1:41081,DS-b302d242-1dce-4e4f-8d00-071cc0e2382d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-719199612-172.17.0.8-1597705155563:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33091,DS-aaddf9d8-1e15-4b83-a76e-facfe63442d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38754,DS-96adfc8c-9c61-4aed-9871-4b4e7b12fe59,DISK], DatanodeInfoWithStorage[127.0.0.1:36071,DS-a81c97ad-23de-4866-8572-fbda60a55aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:33547,DS-d83ed24b-1f87-43e0-a0e1-2f0329254736,DISK], DatanodeInfoWithStorage[127.0.0.1:37371,DS-ca607319-521e-4688-bebb-f583236bacb0,DISK], DatanodeInfoWithStorage[127.0.0.1:46326,DS-3f0f7b5d-78df-4e8e-91ae-886631f86f18,DISK], DatanodeInfoWithStorage[127.0.0.1:42250,DS-0dea2ab9-b85c-4bb9-8d92-9ec1013c9176,DISK], DatanodeInfoWithStorage[127.0.0.1:35916,DS-865379b6-7ad9-4f08-ab7b-b428ff1004c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-719199612-172.17.0.8-1597705155563:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33091,DS-aaddf9d8-1e15-4b83-a76e-facfe63442d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38754,DS-96adfc8c-9c61-4aed-9871-4b4e7b12fe59,DISK], DatanodeInfoWithStorage[127.0.0.1:36071,DS-a81c97ad-23de-4866-8572-fbda60a55aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:33547,DS-d83ed24b-1f87-43e0-a0e1-2f0329254736,DISK], DatanodeInfoWithStorage[127.0.0.1:37371,DS-ca607319-521e-4688-bebb-f583236bacb0,DISK], DatanodeInfoWithStorage[127.0.0.1:46326,DS-3f0f7b5d-78df-4e8e-91ae-886631f86f18,DISK], DatanodeInfoWithStorage[127.0.0.1:42250,DS-0dea2ab9-b85c-4bb9-8d92-9ec1013c9176,DISK], DatanodeInfoWithStorage[127.0.0.1:35916,DS-865379b6-7ad9-4f08-ab7b-b428ff1004c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-428140411-172.17.0.8-1597705452786:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34881,DS-f2ead984-5cdd-42ae-ab8e-7f25494bfd56,DISK], DatanodeInfoWithStorage[127.0.0.1:45713,DS-4c11d889-725f-43e1-a42b-b4c30e1505c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33153,DS-eb7d52de-780c-44cb-927c-d70695ad7f77,DISK], DatanodeInfoWithStorage[127.0.0.1:35731,DS-c70b70b8-1535-4e5a-b707-9fc96ba85ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:41020,DS-6611b9f1-1358-47e8-bbf9-5bbd686bd8ea,DISK], DatanodeInfoWithStorage[127.0.0.1:32963,DS-bf7734e7-c34a-468b-af10-34706783db28,DISK], DatanodeInfoWithStorage[127.0.0.1:36716,DS-08cc746f-919c-4eeb-9ab5-beab429e8afd,DISK], DatanodeInfoWithStorage[127.0.0.1:38679,DS-8a345448-2e8e-4a63-bf07-eb92c4f2d873,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-428140411-172.17.0.8-1597705452786:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34881,DS-f2ead984-5cdd-42ae-ab8e-7f25494bfd56,DISK], DatanodeInfoWithStorage[127.0.0.1:45713,DS-4c11d889-725f-43e1-a42b-b4c30e1505c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33153,DS-eb7d52de-780c-44cb-927c-d70695ad7f77,DISK], DatanodeInfoWithStorage[127.0.0.1:35731,DS-c70b70b8-1535-4e5a-b707-9fc96ba85ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:41020,DS-6611b9f1-1358-47e8-bbf9-5bbd686bd8ea,DISK], DatanodeInfoWithStorage[127.0.0.1:32963,DS-bf7734e7-c34a-468b-af10-34706783db28,DISK], DatanodeInfoWithStorage[127.0.0.1:36716,DS-08cc746f-919c-4eeb-9ab5-beab429e8afd,DISK], DatanodeInfoWithStorage[127.0.0.1:38679,DS-8a345448-2e8e-4a63-bf07-eb92c4f2d873,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-661597468-172.17.0.8-1597705764868:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35145,DS-e24e757a-e3db-46ed-8d4a-34c118fcee7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37271,DS-6a4a12e4-d971-45b5-ba74-5e3764a379a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33030,DS-5ba52665-b1f4-4540-b4d1-2e4b3d060f96,DISK], DatanodeInfoWithStorage[127.0.0.1:46784,DS-65aa8c7e-dfa0-4d3a-8bdd-473f8518351e,DISK], DatanodeInfoWithStorage[127.0.0.1:36766,DS-eb0413b9-586a-444f-ab99-afce38445ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:35386,DS-7d9b1da0-511f-476b-a8f9-ffbc0070f800,DISK], DatanodeInfoWithStorage[127.0.0.1:46734,DS-a32e5d23-4402-4917-a3c7-b07329a2061d,DISK], DatanodeInfoWithStorage[127.0.0.1:34083,DS-9d68a811-9ffe-43c3-8247-b32b0e2dd523,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-661597468-172.17.0.8-1597705764868:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35145,DS-e24e757a-e3db-46ed-8d4a-34c118fcee7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37271,DS-6a4a12e4-d971-45b5-ba74-5e3764a379a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33030,DS-5ba52665-b1f4-4540-b4d1-2e4b3d060f96,DISK], DatanodeInfoWithStorage[127.0.0.1:46784,DS-65aa8c7e-dfa0-4d3a-8bdd-473f8518351e,DISK], DatanodeInfoWithStorage[127.0.0.1:36766,DS-eb0413b9-586a-444f-ab99-afce38445ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:35386,DS-7d9b1da0-511f-476b-a8f9-ffbc0070f800,DISK], DatanodeInfoWithStorage[127.0.0.1:46734,DS-a32e5d23-4402-4917-a3c7-b07329a2061d,DISK], DatanodeInfoWithStorage[127.0.0.1:34083,DS-9d68a811-9ffe-43c3-8247-b32b0e2dd523,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1456686755-172.17.0.8-1597705984035:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44822,DS-e56c77b3-45fc-4b79-bb6d-9152daadd434,DISK], DatanodeInfoWithStorage[127.0.0.1:35736,DS-b78b9ad1-cd06-46e1-a5b8-d5473e0d3c86,DISK], DatanodeInfoWithStorage[127.0.0.1:34007,DS-fd4337d5-cb4e-41ab-9987-8ad2fa86806e,DISK], DatanodeInfoWithStorage[127.0.0.1:42322,DS-17965cc6-d861-4ddd-9af6-ebc308722fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:45428,DS-5f6a2cc9-9e02-4fb6-87d2-6e07414ce166,DISK], DatanodeInfoWithStorage[127.0.0.1:38556,DS-7c7a8372-916f-4b14-a168-1301603fc853,DISK], DatanodeInfoWithStorage[127.0.0.1:41160,DS-787fa508-2028-4a7a-b3f9-4aa30f29336f,DISK], DatanodeInfoWithStorage[127.0.0.1:32803,DS-d3b30f38-ab24-416e-9dc8-b5d60717b160,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1456686755-172.17.0.8-1597705984035:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44822,DS-e56c77b3-45fc-4b79-bb6d-9152daadd434,DISK], DatanodeInfoWithStorage[127.0.0.1:35736,DS-b78b9ad1-cd06-46e1-a5b8-d5473e0d3c86,DISK], DatanodeInfoWithStorage[127.0.0.1:34007,DS-fd4337d5-cb4e-41ab-9987-8ad2fa86806e,DISK], DatanodeInfoWithStorage[127.0.0.1:42322,DS-17965cc6-d861-4ddd-9af6-ebc308722fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:45428,DS-5f6a2cc9-9e02-4fb6-87d2-6e07414ce166,DISK], DatanodeInfoWithStorage[127.0.0.1:38556,DS-7c7a8372-916f-4b14-a168-1301603fc853,DISK], DatanodeInfoWithStorage[127.0.0.1:41160,DS-787fa508-2028-4a7a-b3f9-4aa30f29336f,DISK], DatanodeInfoWithStorage[127.0.0.1:32803,DS-d3b30f38-ab24-416e-9dc8-b5d60717b160,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1760081734-172.17.0.8-1597706466324:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39738,DS-e4eafb21-962e-414c-991b-203252bd0937,DISK], DatanodeInfoWithStorage[127.0.0.1:41623,DS-abc184f1-627e-4d90-889d-0eac2a8b39da,DISK], DatanodeInfoWithStorage[127.0.0.1:36074,DS-f5377a2a-e43a-432c-bad8-9ba7ad54c344,DISK], DatanodeInfoWithStorage[127.0.0.1:45439,DS-fae8fdab-25a1-4af2-b6b9-e30820e4c03b,DISK], DatanodeInfoWithStorage[127.0.0.1:42319,DS-73327d39-799d-4228-87b6-8c0693ad0569,DISK], DatanodeInfoWithStorage[127.0.0.1:43695,DS-99b39b05-e86f-4f9b-b02b-548e127b383e,DISK], DatanodeInfoWithStorage[127.0.0.1:40837,DS-8d827f41-e8d0-45bf-a208-1737580f29c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46216,DS-213eee54-f09a-4472-9d30-f319c71e3bf3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1760081734-172.17.0.8-1597706466324:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39738,DS-e4eafb21-962e-414c-991b-203252bd0937,DISK], DatanodeInfoWithStorage[127.0.0.1:41623,DS-abc184f1-627e-4d90-889d-0eac2a8b39da,DISK], DatanodeInfoWithStorage[127.0.0.1:36074,DS-f5377a2a-e43a-432c-bad8-9ba7ad54c344,DISK], DatanodeInfoWithStorage[127.0.0.1:45439,DS-fae8fdab-25a1-4af2-b6b9-e30820e4c03b,DISK], DatanodeInfoWithStorage[127.0.0.1:42319,DS-73327d39-799d-4228-87b6-8c0693ad0569,DISK], DatanodeInfoWithStorage[127.0.0.1:43695,DS-99b39b05-e86f-4f9b-b02b-548e127b383e,DISK], DatanodeInfoWithStorage[127.0.0.1:40837,DS-8d827f41-e8d0-45bf-a208-1737580f29c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46216,DS-213eee54-f09a-4472-9d30-f319c71e3bf3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1041183027-172.17.0.8-1597706771347:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44462,DS-7ca395da-5b63-44e5-a803-3a6ca26190dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40016,DS-979e92ea-aec0-4a9a-8b95-612b074b6ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:41910,DS-4bb29946-cfe5-482f-b3bd-a79e95a17de6,DISK], DatanodeInfoWithStorage[127.0.0.1:37815,DS-ae026fbb-907c-48bf-9188-687a612c36d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46641,DS-2669cc08-1a09-4cf6-90c7-023a0703e6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36833,DS-631d12fe-9450-4e72-8b2d-44d741ed9a87,DISK], DatanodeInfoWithStorage[127.0.0.1:33452,DS-75624661-85bd-403d-95a6-850e1fbbd0d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40312,DS-308eb84a-8659-4ea6-83ee-757781c79fa0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1041183027-172.17.0.8-1597706771347:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44462,DS-7ca395da-5b63-44e5-a803-3a6ca26190dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40016,DS-979e92ea-aec0-4a9a-8b95-612b074b6ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:41910,DS-4bb29946-cfe5-482f-b3bd-a79e95a17de6,DISK], DatanodeInfoWithStorage[127.0.0.1:37815,DS-ae026fbb-907c-48bf-9188-687a612c36d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46641,DS-2669cc08-1a09-4cf6-90c7-023a0703e6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36833,DS-631d12fe-9450-4e72-8b2d-44d741ed9a87,DISK], DatanodeInfoWithStorage[127.0.0.1:33452,DS-75624661-85bd-403d-95a6-850e1fbbd0d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40312,DS-308eb84a-8659-4ea6-83ee-757781c79fa0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5251
