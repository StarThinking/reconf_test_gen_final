reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-480069518-172.17.0.10-1597378363450:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39554,DS-dab5c903-66a5-4f6e-9354-53bae7e0e649,DISK], DatanodeInfoWithStorage[127.0.0.1:41753,DS-ca588e02-1a2f-4479-8c97-64943ed7f830,DISK], DatanodeInfoWithStorage[127.0.0.1:35773,DS-79c55be1-f361-4fda-b7b6-f7e37eb66b29,DISK], DatanodeInfoWithStorage[127.0.0.1:44815,DS-d17e3ec5-8f2c-4bc6-8a5b-09d44b79f712,DISK], DatanodeInfoWithStorage[127.0.0.1:34673,DS-34748a6b-4a1b-4578-ba98-3c75e15cd012,DISK], DatanodeInfoWithStorage[127.0.0.1:45904,DS-b672f829-df06-48fc-b9dd-f20c56c97f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:45309,DS-87ea417c-edb9-42e6-8e54-49fe59e55d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:35886,DS-9a992bfd-53a8-46a5-98cb-5d0a919a573c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-480069518-172.17.0.10-1597378363450:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39554,DS-dab5c903-66a5-4f6e-9354-53bae7e0e649,DISK], DatanodeInfoWithStorage[127.0.0.1:41753,DS-ca588e02-1a2f-4479-8c97-64943ed7f830,DISK], DatanodeInfoWithStorage[127.0.0.1:35773,DS-79c55be1-f361-4fda-b7b6-f7e37eb66b29,DISK], DatanodeInfoWithStorage[127.0.0.1:44815,DS-d17e3ec5-8f2c-4bc6-8a5b-09d44b79f712,DISK], DatanodeInfoWithStorage[127.0.0.1:34673,DS-34748a6b-4a1b-4578-ba98-3c75e15cd012,DISK], DatanodeInfoWithStorage[127.0.0.1:45904,DS-b672f829-df06-48fc-b9dd-f20c56c97f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:45309,DS-87ea417c-edb9-42e6-8e54-49fe59e55d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:35886,DS-9a992bfd-53a8-46a5-98cb-5d0a919a573c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1776248738-172.17.0.10-1597378601744:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33515,DS-d884d2a8-a2fc-4379-b191-cf38bb49f56d,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-a19fa1e4-d6e3-476d-be23-1b2d21b5c268,DISK], DatanodeInfoWithStorage[127.0.0.1:45609,DS-b43e9317-2fc8-4185-a181-aa92be247c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39576,DS-9b78a0fb-4128-4475-800b-d20b64789e80,DISK], DatanodeInfoWithStorage[127.0.0.1:41817,DS-5a3fa864-791e-4ead-82b3-470a4a7de2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38721,DS-d852dd66-81d0-4722-8998-0357e3b85244,DISK], DatanodeInfoWithStorage[127.0.0.1:40499,DS-67d245a3-4c48-4b51-8474-13ec0927bc6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36532,DS-6a259fa6-4919-4501-b4ee-552edb95961d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1776248738-172.17.0.10-1597378601744:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33515,DS-d884d2a8-a2fc-4379-b191-cf38bb49f56d,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-a19fa1e4-d6e3-476d-be23-1b2d21b5c268,DISK], DatanodeInfoWithStorage[127.0.0.1:45609,DS-b43e9317-2fc8-4185-a181-aa92be247c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39576,DS-9b78a0fb-4128-4475-800b-d20b64789e80,DISK], DatanodeInfoWithStorage[127.0.0.1:41817,DS-5a3fa864-791e-4ead-82b3-470a4a7de2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38721,DS-d852dd66-81d0-4722-8998-0357e3b85244,DISK], DatanodeInfoWithStorage[127.0.0.1:40499,DS-67d245a3-4c48-4b51-8474-13ec0927bc6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36532,DS-6a259fa6-4919-4501-b4ee-552edb95961d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1213907612-172.17.0.10-1597379239890:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37657,DS-02c224b3-6804-437b-95f5-2ecb75b57554,DISK], DatanodeInfoWithStorage[127.0.0.1:41387,DS-13f2f748-558f-467f-8d86-c2fa228af80f,DISK], DatanodeInfoWithStorage[127.0.0.1:46814,DS-f7060ced-e2a6-4568-9e56-5ccfc2eec2a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40930,DS-921f844d-fa07-4549-9a27-fd8d2881448b,DISK], DatanodeInfoWithStorage[127.0.0.1:44331,DS-135b79c4-53c6-4375-869c-e45c81c51f82,DISK], DatanodeInfoWithStorage[127.0.0.1:33551,DS-7b7a4423-025d-485d-847f-5bdfe525ce0a,DISK], DatanodeInfoWithStorage[127.0.0.1:45682,DS-9227633a-ffa5-467b-8e89-e65480f84f64,DISK], DatanodeInfoWithStorage[127.0.0.1:36665,DS-8454fe2d-0184-44dc-81aa-2facfc8173b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1213907612-172.17.0.10-1597379239890:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37657,DS-02c224b3-6804-437b-95f5-2ecb75b57554,DISK], DatanodeInfoWithStorage[127.0.0.1:41387,DS-13f2f748-558f-467f-8d86-c2fa228af80f,DISK], DatanodeInfoWithStorage[127.0.0.1:46814,DS-f7060ced-e2a6-4568-9e56-5ccfc2eec2a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40930,DS-921f844d-fa07-4549-9a27-fd8d2881448b,DISK], DatanodeInfoWithStorage[127.0.0.1:44331,DS-135b79c4-53c6-4375-869c-e45c81c51f82,DISK], DatanodeInfoWithStorage[127.0.0.1:33551,DS-7b7a4423-025d-485d-847f-5bdfe525ce0a,DISK], DatanodeInfoWithStorage[127.0.0.1:45682,DS-9227633a-ffa5-467b-8e89-e65480f84f64,DISK], DatanodeInfoWithStorage[127.0.0.1:36665,DS-8454fe2d-0184-44dc-81aa-2facfc8173b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1273992837-172.17.0.10-1597379383650:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32836,DS-0a344e84-7e85-48f5-8f44-907a70b22af1,DISK], DatanodeInfoWithStorage[127.0.0.1:45436,DS-766ad5aa-ce1a-417a-a24a-79a051d402de,DISK], DatanodeInfoWithStorage[127.0.0.1:34745,DS-8fe8ec2f-963f-4c94-8327-c7be5b70cbfc,DISK], DatanodeInfoWithStorage[127.0.0.1:43594,DS-7222e42b-9376-4156-8230-10e0364f6383,DISK], DatanodeInfoWithStorage[127.0.0.1:38330,DS-5f51e743-2c65-429c-908a-cb9c71be50d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43305,DS-f314c384-7323-49d8-bd89-bef43153f406,DISK], DatanodeInfoWithStorage[127.0.0.1:35237,DS-073299e9-6b8d-4738-ac35-58d3f7d66bda,DISK], DatanodeInfoWithStorage[127.0.0.1:33914,DS-2d7c8d8a-a403-40e1-bbe8-aac3eee329cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1273992837-172.17.0.10-1597379383650:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32836,DS-0a344e84-7e85-48f5-8f44-907a70b22af1,DISK], DatanodeInfoWithStorage[127.0.0.1:45436,DS-766ad5aa-ce1a-417a-a24a-79a051d402de,DISK], DatanodeInfoWithStorage[127.0.0.1:34745,DS-8fe8ec2f-963f-4c94-8327-c7be5b70cbfc,DISK], DatanodeInfoWithStorage[127.0.0.1:43594,DS-7222e42b-9376-4156-8230-10e0364f6383,DISK], DatanodeInfoWithStorage[127.0.0.1:38330,DS-5f51e743-2c65-429c-908a-cb9c71be50d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43305,DS-f314c384-7323-49d8-bd89-bef43153f406,DISK], DatanodeInfoWithStorage[127.0.0.1:35237,DS-073299e9-6b8d-4738-ac35-58d3f7d66bda,DISK], DatanodeInfoWithStorage[127.0.0.1:33914,DS-2d7c8d8a-a403-40e1-bbe8-aac3eee329cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-410105871-172.17.0.10-1597379587114:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41070,DS-6c46c137-e524-4384-9bfa-2eedd771d766,DISK], DatanodeInfoWithStorage[127.0.0.1:39184,DS-80fc390c-443c-4786-aea0-9af658c7404b,DISK], DatanodeInfoWithStorage[127.0.0.1:44487,DS-3fac8c1a-8899-425c-95cb-9971b7575832,DISK], DatanodeInfoWithStorage[127.0.0.1:43391,DS-7ab6b0bd-7940-40c3-a26e-97a92bc37d44,DISK], DatanodeInfoWithStorage[127.0.0.1:35838,DS-9f075644-9511-4b25-9cb9-e9406e4bea3e,DISK], DatanodeInfoWithStorage[127.0.0.1:33006,DS-bca3da16-8128-468e-93e1-9e8b22aa92e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34865,DS-6a71bd7d-168e-40dc-b04c-af8a8c83cfac,DISK], DatanodeInfoWithStorage[127.0.0.1:44527,DS-6ee193a5-8ad5-41b5-97d7-f64192cf02bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-410105871-172.17.0.10-1597379587114:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41070,DS-6c46c137-e524-4384-9bfa-2eedd771d766,DISK], DatanodeInfoWithStorage[127.0.0.1:39184,DS-80fc390c-443c-4786-aea0-9af658c7404b,DISK], DatanodeInfoWithStorage[127.0.0.1:44487,DS-3fac8c1a-8899-425c-95cb-9971b7575832,DISK], DatanodeInfoWithStorage[127.0.0.1:43391,DS-7ab6b0bd-7940-40c3-a26e-97a92bc37d44,DISK], DatanodeInfoWithStorage[127.0.0.1:35838,DS-9f075644-9511-4b25-9cb9-e9406e4bea3e,DISK], DatanodeInfoWithStorage[127.0.0.1:33006,DS-bca3da16-8128-468e-93e1-9e8b22aa92e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34865,DS-6a71bd7d-168e-40dc-b04c-af8a8c83cfac,DISK], DatanodeInfoWithStorage[127.0.0.1:44527,DS-6ee193a5-8ad5-41b5-97d7-f64192cf02bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2134511854-172.17.0.10-1597379726379:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32825,DS-4518c0d7-e8fe-44d1-a114-f82795f33cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:37065,DS-a021b185-bc78-4085-8ea2-80e716fbb618,DISK], DatanodeInfoWithStorage[127.0.0.1:39750,DS-8cdba5ae-d755-4cfd-a91e-cbfa73f90dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:33392,DS-2f7e5391-4808-4c1d-b705-8e92802e330e,DISK], DatanodeInfoWithStorage[127.0.0.1:43047,DS-d6981e32-d383-43d6-8185-f4e77b652231,DISK], DatanodeInfoWithStorage[127.0.0.1:33731,DS-7ffce1c6-8c0d-45bd-92f3-a1aa8591bfe0,DISK], DatanodeInfoWithStorage[127.0.0.1:35257,DS-1005aff4-4359-4055-b051-20acc5789d76,DISK], DatanodeInfoWithStorage[127.0.0.1:36756,DS-897e7ee7-138c-45b3-94ae-79e4151ef1ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2134511854-172.17.0.10-1597379726379:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32825,DS-4518c0d7-e8fe-44d1-a114-f82795f33cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:37065,DS-a021b185-bc78-4085-8ea2-80e716fbb618,DISK], DatanodeInfoWithStorage[127.0.0.1:39750,DS-8cdba5ae-d755-4cfd-a91e-cbfa73f90dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:33392,DS-2f7e5391-4808-4c1d-b705-8e92802e330e,DISK], DatanodeInfoWithStorage[127.0.0.1:43047,DS-d6981e32-d383-43d6-8185-f4e77b652231,DISK], DatanodeInfoWithStorage[127.0.0.1:33731,DS-7ffce1c6-8c0d-45bd-92f3-a1aa8591bfe0,DISK], DatanodeInfoWithStorage[127.0.0.1:35257,DS-1005aff4-4359-4055-b051-20acc5789d76,DISK], DatanodeInfoWithStorage[127.0.0.1:36756,DS-897e7ee7-138c-45b3-94ae-79e4151ef1ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-316820635-172.17.0.10-1597380110405:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37943,DS-fb8ce081-f883-42d0-a10e-8e9c39a9d982,DISK], DatanodeInfoWithStorage[127.0.0.1:33412,DS-21ac5a6e-71e6-4435-a9ff-5474180284bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40822,DS-c61ac366-1f02-4611-929f-669a47cb8a98,DISK], DatanodeInfoWithStorage[127.0.0.1:46031,DS-0dbe209e-7601-437a-8c72-926dc4e21fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:40969,DS-76a216c4-98c6-4561-b9da-0029037c1302,DISK], DatanodeInfoWithStorage[127.0.0.1:44050,DS-c67322f8-e9c1-4ef6-ad1e-df157ff6ede2,DISK], DatanodeInfoWithStorage[127.0.0.1:33234,DS-ac1768fa-d39e-4743-a768-a8061b3d1372,DISK], DatanodeInfoWithStorage[127.0.0.1:46507,DS-6ad60fc1-1f15-4ce1-bf3d-0bf3b4c3a169,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-316820635-172.17.0.10-1597380110405:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37943,DS-fb8ce081-f883-42d0-a10e-8e9c39a9d982,DISK], DatanodeInfoWithStorage[127.0.0.1:33412,DS-21ac5a6e-71e6-4435-a9ff-5474180284bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40822,DS-c61ac366-1f02-4611-929f-669a47cb8a98,DISK], DatanodeInfoWithStorage[127.0.0.1:46031,DS-0dbe209e-7601-437a-8c72-926dc4e21fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:40969,DS-76a216c4-98c6-4561-b9da-0029037c1302,DISK], DatanodeInfoWithStorage[127.0.0.1:44050,DS-c67322f8-e9c1-4ef6-ad1e-df157ff6ede2,DISK], DatanodeInfoWithStorage[127.0.0.1:33234,DS-ac1768fa-d39e-4743-a768-a8061b3d1372,DISK], DatanodeInfoWithStorage[127.0.0.1:46507,DS-6ad60fc1-1f15-4ce1-bf3d-0bf3b4c3a169,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1339331370-172.17.0.10-1597381101269:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44466,DS-97163d7a-4eac-4640-b454-86741efc2e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:35561,DS-24a7d059-3319-4bc5-a319-b90a2f986feb,DISK], DatanodeInfoWithStorage[127.0.0.1:37336,DS-4b10b2c4-0601-4207-97f3-1d230727a202,DISK], DatanodeInfoWithStorage[127.0.0.1:33451,DS-d3553144-60a0-49b3-b72a-fc5db547c20d,DISK], DatanodeInfoWithStorage[127.0.0.1:44736,DS-33887d27-fbc7-42b6-872d-a5854f3cc90c,DISK], DatanodeInfoWithStorage[127.0.0.1:45132,DS-31088acf-5261-478b-a644-20645f331482,DISK], DatanodeInfoWithStorage[127.0.0.1:37627,DS-1ef7cfbc-833e-4843-af5f-5401cc47c24c,DISK], DatanodeInfoWithStorage[127.0.0.1:46445,DS-13ffedb8-c9e7-40db-8383-1ab51b08b36f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1339331370-172.17.0.10-1597381101269:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44466,DS-97163d7a-4eac-4640-b454-86741efc2e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:35561,DS-24a7d059-3319-4bc5-a319-b90a2f986feb,DISK], DatanodeInfoWithStorage[127.0.0.1:37336,DS-4b10b2c4-0601-4207-97f3-1d230727a202,DISK], DatanodeInfoWithStorage[127.0.0.1:33451,DS-d3553144-60a0-49b3-b72a-fc5db547c20d,DISK], DatanodeInfoWithStorage[127.0.0.1:44736,DS-33887d27-fbc7-42b6-872d-a5854f3cc90c,DISK], DatanodeInfoWithStorage[127.0.0.1:45132,DS-31088acf-5261-478b-a644-20645f331482,DISK], DatanodeInfoWithStorage[127.0.0.1:37627,DS-1ef7cfbc-833e-4843-af5f-5401cc47c24c,DISK], DatanodeInfoWithStorage[127.0.0.1:46445,DS-13ffedb8-c9e7-40db-8383-1ab51b08b36f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-433518195-172.17.0.10-1597381627534:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35151,DS-24a78615-3949-4580-9161-1da5070f16f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33462,DS-5b468d27-aa8f-4a1e-8727-7a0ec322782a,DISK], DatanodeInfoWithStorage[127.0.0.1:41032,DS-efc0e50d-7c03-4a38-afc3-33abd922265c,DISK], DatanodeInfoWithStorage[127.0.0.1:42421,DS-b1b0e2f8-fd71-4126-9f10-b10ea0de6daa,DISK], DatanodeInfoWithStorage[127.0.0.1:35783,DS-a09f827e-8bda-4a3b-83ce-63a0db315bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:45271,DS-d51b28aa-7a09-4a49-9733-be2b79d1eca9,DISK], DatanodeInfoWithStorage[127.0.0.1:44548,DS-3fbc2fd4-92fd-4070-b9a6-319ddfd08042,DISK], DatanodeInfoWithStorage[127.0.0.1:46562,DS-0fc88950-0c55-428d-9abf-3283465cb627,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-433518195-172.17.0.10-1597381627534:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35151,DS-24a78615-3949-4580-9161-1da5070f16f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33462,DS-5b468d27-aa8f-4a1e-8727-7a0ec322782a,DISK], DatanodeInfoWithStorage[127.0.0.1:41032,DS-efc0e50d-7c03-4a38-afc3-33abd922265c,DISK], DatanodeInfoWithStorage[127.0.0.1:42421,DS-b1b0e2f8-fd71-4126-9f10-b10ea0de6daa,DISK], DatanodeInfoWithStorage[127.0.0.1:35783,DS-a09f827e-8bda-4a3b-83ce-63a0db315bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:45271,DS-d51b28aa-7a09-4a49-9733-be2b79d1eca9,DISK], DatanodeInfoWithStorage[127.0.0.1:44548,DS-3fbc2fd4-92fd-4070-b9a6-319ddfd08042,DISK], DatanodeInfoWithStorage[127.0.0.1:46562,DS-0fc88950-0c55-428d-9abf-3283465cb627,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2076036148-172.17.0.10-1597381660019:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43238,DS-b306c935-b862-4962-8f80-8e9dee455d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40945,DS-4f11d32f-be12-42db-bd6a-ade6696992e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40685,DS-fe5bb5aa-a172-415c-b6eb-1ce449c2700a,DISK], DatanodeInfoWithStorage[127.0.0.1:38454,DS-5a258b7e-743c-4a45-a6f5-f07420c4eb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45786,DS-abacfa58-a1a1-4c8b-a6e7-2823ea3ca1af,DISK], DatanodeInfoWithStorage[127.0.0.1:35839,DS-53f59b59-4268-445e-9c20-c3fae84f28e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39815,DS-1ae69ca0-8320-429d-a28d-a5fd99ce164f,DISK], DatanodeInfoWithStorage[127.0.0.1:43969,DS-d19dab73-7b04-49a6-ae12-a9ff565ac03d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2076036148-172.17.0.10-1597381660019:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43238,DS-b306c935-b862-4962-8f80-8e9dee455d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40945,DS-4f11d32f-be12-42db-bd6a-ade6696992e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40685,DS-fe5bb5aa-a172-415c-b6eb-1ce449c2700a,DISK], DatanodeInfoWithStorage[127.0.0.1:38454,DS-5a258b7e-743c-4a45-a6f5-f07420c4eb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45786,DS-abacfa58-a1a1-4c8b-a6e7-2823ea3ca1af,DISK], DatanodeInfoWithStorage[127.0.0.1:35839,DS-53f59b59-4268-445e-9c20-c3fae84f28e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39815,DS-1ae69ca0-8320-429d-a28d-a5fd99ce164f,DISK], DatanodeInfoWithStorage[127.0.0.1:43969,DS-d19dab73-7b04-49a6-ae12-a9ff565ac03d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-789565180-172.17.0.10-1597382105818:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43682,DS-87e8769d-2e35-440b-a8bc-f3c60e13feed,DISK], DatanodeInfoWithStorage[127.0.0.1:41538,DS-2f999f6d-b857-46cf-80f2-4e30a364f723,DISK], DatanodeInfoWithStorage[127.0.0.1:38980,DS-de036201-9b2b-437e-94fd-9a0b1aac5927,DISK], DatanodeInfoWithStorage[127.0.0.1:38784,DS-2139a328-6353-4185-993d-de2dc38e6728,DISK], DatanodeInfoWithStorage[127.0.0.1:39821,DS-a3bbefb5-0a68-4936-aa11-9290a16557f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37299,DS-537d1dbc-e4b7-47a1-abe3-4bd27bafb3d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38675,DS-9e4e3b03-3467-4583-b279-adf38dba0c61,DISK], DatanodeInfoWithStorage[127.0.0.1:44125,DS-feb17cec-386d-420b-9624-471c70196c6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-789565180-172.17.0.10-1597382105818:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43682,DS-87e8769d-2e35-440b-a8bc-f3c60e13feed,DISK], DatanodeInfoWithStorage[127.0.0.1:41538,DS-2f999f6d-b857-46cf-80f2-4e30a364f723,DISK], DatanodeInfoWithStorage[127.0.0.1:38980,DS-de036201-9b2b-437e-94fd-9a0b1aac5927,DISK], DatanodeInfoWithStorage[127.0.0.1:38784,DS-2139a328-6353-4185-993d-de2dc38e6728,DISK], DatanodeInfoWithStorage[127.0.0.1:39821,DS-a3bbefb5-0a68-4936-aa11-9290a16557f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37299,DS-537d1dbc-e4b7-47a1-abe3-4bd27bafb3d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38675,DS-9e4e3b03-3467-4583-b279-adf38dba0c61,DISK], DatanodeInfoWithStorage[127.0.0.1:44125,DS-feb17cec-386d-420b-9624-471c70196c6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-782342142-172.17.0.10-1597382219931:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36752,DS-d2e54d50-e8f3-4d91-b61e-1e0150f3b758,DISK], DatanodeInfoWithStorage[127.0.0.1:41162,DS-e7e03552-2915-4317-9b86-2b32ed246711,DISK], DatanodeInfoWithStorage[127.0.0.1:36180,DS-2485991b-3766-4521-a429-c381db99c0ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40124,DS-f58f4c09-a1d9-4535-8178-a7cff5b99a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46399,DS-4f7da00f-f02a-4372-9f4b-6b788983daa4,DISK], DatanodeInfoWithStorage[127.0.0.1:42915,DS-4b154084-69ec-45c9-95e7-2c6c38410929,DISK], DatanodeInfoWithStorage[127.0.0.1:41231,DS-4a5c3cd2-af8b-4b51-b939-7bf4a4705c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:32975,DS-a895caad-e735-426b-b032-bb5d47d156c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-782342142-172.17.0.10-1597382219931:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36752,DS-d2e54d50-e8f3-4d91-b61e-1e0150f3b758,DISK], DatanodeInfoWithStorage[127.0.0.1:41162,DS-e7e03552-2915-4317-9b86-2b32ed246711,DISK], DatanodeInfoWithStorage[127.0.0.1:36180,DS-2485991b-3766-4521-a429-c381db99c0ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40124,DS-f58f4c09-a1d9-4535-8178-a7cff5b99a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46399,DS-4f7da00f-f02a-4372-9f4b-6b788983daa4,DISK], DatanodeInfoWithStorage[127.0.0.1:42915,DS-4b154084-69ec-45c9-95e7-2c6c38410929,DISK], DatanodeInfoWithStorage[127.0.0.1:41231,DS-4a5c3cd2-af8b-4b51-b939-7bf4a4705c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:32975,DS-a895caad-e735-426b-b032-bb5d47d156c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1554688596-172.17.0.10-1597382694410:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34711,DS-7b82c34e-fe87-457e-a0f4-e56732237d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:46470,DS-6897dded-550f-4f4d-b142-af2fa88c1b11,DISK], DatanodeInfoWithStorage[127.0.0.1:42367,DS-19016008-1ba3-4621-998d-47b7192ab1c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38091,DS-91f71a11-46de-4de5-9939-abb921b65701,DISK], DatanodeInfoWithStorage[127.0.0.1:33951,DS-7bb73003-53fc-44f6-89ff-e417f33fba2d,DISK], DatanodeInfoWithStorage[127.0.0.1:34620,DS-5110f8bc-5907-4fe4-805d-ea826030482f,DISK], DatanodeInfoWithStorage[127.0.0.1:39879,DS-c1222ff7-3631-44e2-abc8-9340a3d55a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:44530,DS-36ef9b5d-0863-4efb-a994-d77376662791,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1554688596-172.17.0.10-1597382694410:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34711,DS-7b82c34e-fe87-457e-a0f4-e56732237d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:46470,DS-6897dded-550f-4f4d-b142-af2fa88c1b11,DISK], DatanodeInfoWithStorage[127.0.0.1:42367,DS-19016008-1ba3-4621-998d-47b7192ab1c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38091,DS-91f71a11-46de-4de5-9939-abb921b65701,DISK], DatanodeInfoWithStorage[127.0.0.1:33951,DS-7bb73003-53fc-44f6-89ff-e417f33fba2d,DISK], DatanodeInfoWithStorage[127.0.0.1:34620,DS-5110f8bc-5907-4fe4-805d-ea826030482f,DISK], DatanodeInfoWithStorage[127.0.0.1:39879,DS-c1222ff7-3631-44e2-abc8-9340a3d55a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:44530,DS-36ef9b5d-0863-4efb-a994-d77376662791,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-671329773-172.17.0.10-1597382960400:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45473,DS-43194b2a-579f-4505-8a07-5b62ea06a7a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37096,DS-70d26a5d-a542-4f6e-9ff6-ca92d878bedf,DISK], DatanodeInfoWithStorage[127.0.0.1:46276,DS-9b4ba545-a2e1-424a-84ab-91f6810f2dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:43545,DS-8a480852-0ff3-45f5-bf3c-32ffd74b5221,DISK], DatanodeInfoWithStorage[127.0.0.1:45487,DS-fe7950ce-8908-47ab-9a38-19cbc41c4961,DISK], DatanodeInfoWithStorage[127.0.0.1:43017,DS-fa396919-c6c3-429f-abd7-33990bca3c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:38815,DS-70de1b33-9a57-4d4a-b1b4-c3f5962134b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34905,DS-917b31d1-c4ed-459b-8053-8fca168d9dc4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-671329773-172.17.0.10-1597382960400:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45473,DS-43194b2a-579f-4505-8a07-5b62ea06a7a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37096,DS-70d26a5d-a542-4f6e-9ff6-ca92d878bedf,DISK], DatanodeInfoWithStorage[127.0.0.1:46276,DS-9b4ba545-a2e1-424a-84ab-91f6810f2dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:43545,DS-8a480852-0ff3-45f5-bf3c-32ffd74b5221,DISK], DatanodeInfoWithStorage[127.0.0.1:45487,DS-fe7950ce-8908-47ab-9a38-19cbc41c4961,DISK], DatanodeInfoWithStorage[127.0.0.1:43017,DS-fa396919-c6c3-429f-abd7-33990bca3c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:38815,DS-70de1b33-9a57-4d4a-b1b4-c3f5962134b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34905,DS-917b31d1-c4ed-459b-8053-8fca168d9dc4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-205448462-172.17.0.10-1597383106766:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33627,DS-5923f917-3e34-4f3a-ac78-841319a2cd51,DISK], DatanodeInfoWithStorage[127.0.0.1:34221,DS-105a1cf1-9e58-489c-8de1-f4f09e07558b,DISK], DatanodeInfoWithStorage[127.0.0.1:35435,DS-8befae0a-05d7-4942-b226-f7257ffe4b05,DISK], DatanodeInfoWithStorage[127.0.0.1:43825,DS-ce398df3-d490-4098-a308-2986942c2419,DISK], DatanodeInfoWithStorage[127.0.0.1:39015,DS-7a69c81d-9e99-4a5c-a717-87781ea9ba0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37816,DS-b6ae9a64-8d07-4873-a490-99e4755e086f,DISK], DatanodeInfoWithStorage[127.0.0.1:39835,DS-86eb6e7f-4bc2-4506-9947-913c2adc4bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:46418,DS-acf372c4-e4de-48a2-95f5-cf8eacdcc596,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-205448462-172.17.0.10-1597383106766:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33627,DS-5923f917-3e34-4f3a-ac78-841319a2cd51,DISK], DatanodeInfoWithStorage[127.0.0.1:34221,DS-105a1cf1-9e58-489c-8de1-f4f09e07558b,DISK], DatanodeInfoWithStorage[127.0.0.1:35435,DS-8befae0a-05d7-4942-b226-f7257ffe4b05,DISK], DatanodeInfoWithStorage[127.0.0.1:43825,DS-ce398df3-d490-4098-a308-2986942c2419,DISK], DatanodeInfoWithStorage[127.0.0.1:39015,DS-7a69c81d-9e99-4a5c-a717-87781ea9ba0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37816,DS-b6ae9a64-8d07-4873-a490-99e4755e086f,DISK], DatanodeInfoWithStorage[127.0.0.1:39835,DS-86eb6e7f-4bc2-4506-9947-913c2adc4bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:46418,DS-acf372c4-e4de-48a2-95f5-cf8eacdcc596,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5401
