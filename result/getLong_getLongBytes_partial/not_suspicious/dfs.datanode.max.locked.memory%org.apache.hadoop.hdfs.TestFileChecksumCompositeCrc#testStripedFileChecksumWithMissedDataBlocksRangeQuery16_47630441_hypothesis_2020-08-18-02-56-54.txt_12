reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-486752485-172.17.0.5-1597719583331:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46612,DS-6611b0c4-2b55-4122-9249-6a63a0791220,DISK], DatanodeInfoWithStorage[127.0.0.1:46858,DS-a0002563-27cc-47e8-aa97-e543b051d646,DISK], DatanodeInfoWithStorage[127.0.0.1:33414,DS-b71b65ae-cee7-48cc-8536-3897640e8a53,DISK], DatanodeInfoWithStorage[127.0.0.1:44692,DS-5a8e7280-3bf9-4445-90b4-5b5421419578,DISK], DatanodeInfoWithStorage[127.0.0.1:38378,DS-e9199b7a-b69f-4661-bffd-1cfa81807a78,DISK], DatanodeInfoWithStorage[127.0.0.1:34201,DS-b5c6cfc2-98ea-4608-9dee-55c17f8ee883,DISK], DatanodeInfoWithStorage[127.0.0.1:35197,DS-76158957-07e8-40c9-a4fb-0223e574c27c,DISK], DatanodeInfoWithStorage[127.0.0.1:44385,DS-4fc0aced-0cce-41cb-a79a-f0c09a26acb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-486752485-172.17.0.5-1597719583331:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46612,DS-6611b0c4-2b55-4122-9249-6a63a0791220,DISK], DatanodeInfoWithStorage[127.0.0.1:46858,DS-a0002563-27cc-47e8-aa97-e543b051d646,DISK], DatanodeInfoWithStorage[127.0.0.1:33414,DS-b71b65ae-cee7-48cc-8536-3897640e8a53,DISK], DatanodeInfoWithStorage[127.0.0.1:44692,DS-5a8e7280-3bf9-4445-90b4-5b5421419578,DISK], DatanodeInfoWithStorage[127.0.0.1:38378,DS-e9199b7a-b69f-4661-bffd-1cfa81807a78,DISK], DatanodeInfoWithStorage[127.0.0.1:34201,DS-b5c6cfc2-98ea-4608-9dee-55c17f8ee883,DISK], DatanodeInfoWithStorage[127.0.0.1:35197,DS-76158957-07e8-40c9-a4fb-0223e574c27c,DISK], DatanodeInfoWithStorage[127.0.0.1:44385,DS-4fc0aced-0cce-41cb-a79a-f0c09a26acb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-160560842-172.17.0.5-1597719756043:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37100,DS-fec1fb13-a8e1-44ef-8cd4-48dd62849553,DISK], DatanodeInfoWithStorage[127.0.0.1:39757,DS-63000d61-49bf-43a8-9b2d-c806072091d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39482,DS-3bb522ea-ce60-41e5-b364-80499b5a5678,DISK], DatanodeInfoWithStorage[127.0.0.1:38670,DS-05948284-72b8-4d01-9387-9c29526cc8fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41809,DS-0cc6ac2d-12aa-441b-9db9-b15ad968f1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44205,DS-ce71a504-5588-46b1-918e-6114e56d3093,DISK], DatanodeInfoWithStorage[127.0.0.1:43744,DS-4b5b2893-3ee6-49f0-b1a6-48d109ce95fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43916,DS-a68f89d3-e3fe-46ee-8251-7c23c775918a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-160560842-172.17.0.5-1597719756043:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37100,DS-fec1fb13-a8e1-44ef-8cd4-48dd62849553,DISK], DatanodeInfoWithStorage[127.0.0.1:39757,DS-63000d61-49bf-43a8-9b2d-c806072091d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39482,DS-3bb522ea-ce60-41e5-b364-80499b5a5678,DISK], DatanodeInfoWithStorage[127.0.0.1:38670,DS-05948284-72b8-4d01-9387-9c29526cc8fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41809,DS-0cc6ac2d-12aa-441b-9db9-b15ad968f1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44205,DS-ce71a504-5588-46b1-918e-6114e56d3093,DISK], DatanodeInfoWithStorage[127.0.0.1:43744,DS-4b5b2893-3ee6-49f0-b1a6-48d109ce95fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43916,DS-a68f89d3-e3fe-46ee-8251-7c23c775918a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1423729416-172.17.0.5-1597719849103:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38302,DS-5d101dfb-1f55-4d4a-8bd6-434c2a553e77,DISK], DatanodeInfoWithStorage[127.0.0.1:42946,DS-49efa79d-3e94-41ff-afd4-8e632707de4d,DISK], DatanodeInfoWithStorage[127.0.0.1:44962,DS-c1d75ad5-0647-48fc-a5e5-108215aa6980,DISK], DatanodeInfoWithStorage[127.0.0.1:39725,DS-3fb8b0f1-08f7-4065-8658-f8db8e1b098a,DISK], DatanodeInfoWithStorage[127.0.0.1:40870,DS-521385de-61ac-4936-9592-ea76136ceda9,DISK], DatanodeInfoWithStorage[127.0.0.1:35263,DS-a07ee5eb-fb13-445e-a910-375b6a307399,DISK], DatanodeInfoWithStorage[127.0.0.1:46009,DS-5ad9be9e-fa3d-4c93-a261-5ac95abfe43b,DISK], DatanodeInfoWithStorage[127.0.0.1:37684,DS-ae8ab4d2-7412-4efd-a91a-1c84a0281fc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1423729416-172.17.0.5-1597719849103:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38302,DS-5d101dfb-1f55-4d4a-8bd6-434c2a553e77,DISK], DatanodeInfoWithStorage[127.0.0.1:42946,DS-49efa79d-3e94-41ff-afd4-8e632707de4d,DISK], DatanodeInfoWithStorage[127.0.0.1:44962,DS-c1d75ad5-0647-48fc-a5e5-108215aa6980,DISK], DatanodeInfoWithStorage[127.0.0.1:39725,DS-3fb8b0f1-08f7-4065-8658-f8db8e1b098a,DISK], DatanodeInfoWithStorage[127.0.0.1:40870,DS-521385de-61ac-4936-9592-ea76136ceda9,DISK], DatanodeInfoWithStorage[127.0.0.1:35263,DS-a07ee5eb-fb13-445e-a910-375b6a307399,DISK], DatanodeInfoWithStorage[127.0.0.1:46009,DS-5ad9be9e-fa3d-4c93-a261-5ac95abfe43b,DISK], DatanodeInfoWithStorage[127.0.0.1:37684,DS-ae8ab4d2-7412-4efd-a91a-1c84a0281fc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1548669232-172.17.0.5-1597720192478:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36546,DS-67c6b662-9235-4f26-9bd1-40888021bf55,DISK], DatanodeInfoWithStorage[127.0.0.1:42417,DS-52543bba-dfe8-4aca-8449-3d508d08b213,DISK], DatanodeInfoWithStorage[127.0.0.1:35288,DS-12d41563-79c0-4976-8cf4-94cbd389bcd6,DISK], DatanodeInfoWithStorage[127.0.0.1:41914,DS-fa191d17-414a-411a-8357-299fb60fa9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37959,DS-6d91df31-d861-4be2-a3f5-a0087d4b0882,DISK], DatanodeInfoWithStorage[127.0.0.1:34361,DS-19e62382-99a1-41e1-864c-9545a088efb5,DISK], DatanodeInfoWithStorage[127.0.0.1:38480,DS-db9a8c83-f679-4f9e-b942-324bb0dba962,DISK], DatanodeInfoWithStorage[127.0.0.1:42270,DS-c427d89b-851e-4de6-8b2f-69dfca94a5e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1548669232-172.17.0.5-1597720192478:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36546,DS-67c6b662-9235-4f26-9bd1-40888021bf55,DISK], DatanodeInfoWithStorage[127.0.0.1:42417,DS-52543bba-dfe8-4aca-8449-3d508d08b213,DISK], DatanodeInfoWithStorage[127.0.0.1:35288,DS-12d41563-79c0-4976-8cf4-94cbd389bcd6,DISK], DatanodeInfoWithStorage[127.0.0.1:41914,DS-fa191d17-414a-411a-8357-299fb60fa9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37959,DS-6d91df31-d861-4be2-a3f5-a0087d4b0882,DISK], DatanodeInfoWithStorage[127.0.0.1:34361,DS-19e62382-99a1-41e1-864c-9545a088efb5,DISK], DatanodeInfoWithStorage[127.0.0.1:38480,DS-db9a8c83-f679-4f9e-b942-324bb0dba962,DISK], DatanodeInfoWithStorage[127.0.0.1:42270,DS-c427d89b-851e-4de6-8b2f-69dfca94a5e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2067140887-172.17.0.5-1597720427042:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46173,DS-45e91332-d696-4cca-b8f1-4f185ed050ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35912,DS-85ff0099-b5f6-4f85-8e75-202bc4e9cec2,DISK], DatanodeInfoWithStorage[127.0.0.1:33466,DS-c850811c-c4d1-438d-8d26-e2543df08352,DISK], DatanodeInfoWithStorage[127.0.0.1:36005,DS-c3049b26-9859-4265-9bd0-7c4c536888a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42785,DS-c19747c1-91aa-4a77-acf1-5d3dab01ce57,DISK], DatanodeInfoWithStorage[127.0.0.1:36462,DS-313eb693-ae13-4822-9cd4-059c78c518c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44602,DS-bb6870f6-0d7a-4330-959c-2866a1257630,DISK], DatanodeInfoWithStorage[127.0.0.1:45268,DS-e998ef42-9819-47dc-887f-8dd5bf372f4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2067140887-172.17.0.5-1597720427042:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46173,DS-45e91332-d696-4cca-b8f1-4f185ed050ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35912,DS-85ff0099-b5f6-4f85-8e75-202bc4e9cec2,DISK], DatanodeInfoWithStorage[127.0.0.1:33466,DS-c850811c-c4d1-438d-8d26-e2543df08352,DISK], DatanodeInfoWithStorage[127.0.0.1:36005,DS-c3049b26-9859-4265-9bd0-7c4c536888a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42785,DS-c19747c1-91aa-4a77-acf1-5d3dab01ce57,DISK], DatanodeInfoWithStorage[127.0.0.1:36462,DS-313eb693-ae13-4822-9cd4-059c78c518c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44602,DS-bb6870f6-0d7a-4330-959c-2866a1257630,DISK], DatanodeInfoWithStorage[127.0.0.1:45268,DS-e998ef42-9819-47dc-887f-8dd5bf372f4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-127087920-172.17.0.5-1597720475953:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39960,DS-af8cb5ee-0dd5-47b9-bbb1-9528eef4577a,DISK], DatanodeInfoWithStorage[127.0.0.1:39422,DS-2683b0ed-fea7-47ad-a599-e67fe458fdc2,DISK], DatanodeInfoWithStorage[127.0.0.1:37470,DS-6933a3c1-9b6c-4b18-8be9-b964c72281bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46133,DS-05d03941-d79e-48f8-b234-e10fc43d086e,DISK], DatanodeInfoWithStorage[127.0.0.1:42258,DS-d97350d9-2a19-4fc0-853b-3391cccc30da,DISK], DatanodeInfoWithStorage[127.0.0.1:34741,DS-8ab5325f-e78e-4988-9be8-880f74f9d173,DISK], DatanodeInfoWithStorage[127.0.0.1:32981,DS-3bae910a-1793-43e6-9e2a-56cc2129c456,DISK], DatanodeInfoWithStorage[127.0.0.1:34334,DS-55f6634d-738c-46a5-a6c6-3ecf3ca91dc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-127087920-172.17.0.5-1597720475953:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39960,DS-af8cb5ee-0dd5-47b9-bbb1-9528eef4577a,DISK], DatanodeInfoWithStorage[127.0.0.1:39422,DS-2683b0ed-fea7-47ad-a599-e67fe458fdc2,DISK], DatanodeInfoWithStorage[127.0.0.1:37470,DS-6933a3c1-9b6c-4b18-8be9-b964c72281bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46133,DS-05d03941-d79e-48f8-b234-e10fc43d086e,DISK], DatanodeInfoWithStorage[127.0.0.1:42258,DS-d97350d9-2a19-4fc0-853b-3391cccc30da,DISK], DatanodeInfoWithStorage[127.0.0.1:34741,DS-8ab5325f-e78e-4988-9be8-880f74f9d173,DISK], DatanodeInfoWithStorage[127.0.0.1:32981,DS-3bae910a-1793-43e6-9e2a-56cc2129c456,DISK], DatanodeInfoWithStorage[127.0.0.1:34334,DS-55f6634d-738c-46a5-a6c6-3ecf3ca91dc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1843535869-172.17.0.5-1597720607245:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44857,DS-a4cfd044-5368-40a8-9dd1-32d2d4764b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:34555,DS-697dda90-0ccc-431d-b436-a5f04a179e19,DISK], DatanodeInfoWithStorage[127.0.0.1:42194,DS-3a00edac-158f-400f-ac00-88cd6f2a950f,DISK], DatanodeInfoWithStorage[127.0.0.1:36592,DS-a799419a-437b-474b-be8e-be2dc92635aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33972,DS-a9dbad3c-9a0d-4d6b-950e-4e10dd23d750,DISK], DatanodeInfoWithStorage[127.0.0.1:34804,DS-be79e8e0-866a-4d00-8e0b-c99a8ca20d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:34345,DS-90b1932d-0cf3-43d2-8507-15924f9231b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36050,DS-8a84e399-ac8d-45f8-8e18-97374f1cad4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1843535869-172.17.0.5-1597720607245:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44857,DS-a4cfd044-5368-40a8-9dd1-32d2d4764b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:34555,DS-697dda90-0ccc-431d-b436-a5f04a179e19,DISK], DatanodeInfoWithStorage[127.0.0.1:42194,DS-3a00edac-158f-400f-ac00-88cd6f2a950f,DISK], DatanodeInfoWithStorage[127.0.0.1:36592,DS-a799419a-437b-474b-be8e-be2dc92635aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33972,DS-a9dbad3c-9a0d-4d6b-950e-4e10dd23d750,DISK], DatanodeInfoWithStorage[127.0.0.1:34804,DS-be79e8e0-866a-4d00-8e0b-c99a8ca20d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:34345,DS-90b1932d-0cf3-43d2-8507-15924f9231b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36050,DS-8a84e399-ac8d-45f8-8e18-97374f1cad4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1119445358-172.17.0.5-1597720800293:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42094,DS-61e3f133-7e8d-4ef2-8b5a-bc8e6ae72bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:44261,DS-1b13d6ea-ec14-4016-8018-57617079a118,DISK], DatanodeInfoWithStorage[127.0.0.1:44575,DS-9b5c45fe-9e40-47f4-8060-6809ffe8c0bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36486,DS-6446117b-a3ce-4f00-bc78-ab388c6b7a37,DISK], DatanodeInfoWithStorage[127.0.0.1:46864,DS-2d1a6784-9ccf-4472-9b19-044e9d3137c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38694,DS-0d2b4aab-b103-4efa-85b0-0c100afd39f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36750,DS-41495bc8-6bb9-406c-a17c-63c85e29bd27,DISK], DatanodeInfoWithStorage[127.0.0.1:34546,DS-420c3ac5-93df-4fdd-b96e-8fe425d13147,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1119445358-172.17.0.5-1597720800293:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42094,DS-61e3f133-7e8d-4ef2-8b5a-bc8e6ae72bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:44261,DS-1b13d6ea-ec14-4016-8018-57617079a118,DISK], DatanodeInfoWithStorage[127.0.0.1:44575,DS-9b5c45fe-9e40-47f4-8060-6809ffe8c0bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36486,DS-6446117b-a3ce-4f00-bc78-ab388c6b7a37,DISK], DatanodeInfoWithStorage[127.0.0.1:46864,DS-2d1a6784-9ccf-4472-9b19-044e9d3137c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38694,DS-0d2b4aab-b103-4efa-85b0-0c100afd39f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36750,DS-41495bc8-6bb9-406c-a17c-63c85e29bd27,DISK], DatanodeInfoWithStorage[127.0.0.1:34546,DS-420c3ac5-93df-4fdd-b96e-8fe425d13147,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-212364627-172.17.0.5-1597721266541:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38748,DS-8a2e9d3a-09ef-438f-9346-c27130bc343d,DISK], DatanodeInfoWithStorage[127.0.0.1:34279,DS-9cb51b89-14f4-482d-8cc7-e925cfb4e653,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-4fdcf054-3c3a-4ac0-9cbc-64b4976f9eed,DISK], DatanodeInfoWithStorage[127.0.0.1:36599,DS-37f88ee3-5816-46a4-b5f2-b5fc7400c4bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41715,DS-a2bd0a97-cc0f-4071-ae1b-b1c6e75992de,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-5f15c145-65a2-4a8f-89cd-abf32eaacc89,DISK], DatanodeInfoWithStorage[127.0.0.1:43894,DS-cfc5b73e-0549-4166-bc7c-7afd33c58c03,DISK], DatanodeInfoWithStorage[127.0.0.1:37792,DS-a98f6d95-d401-4140-a550-8b3755ce6e38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-212364627-172.17.0.5-1597721266541:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38748,DS-8a2e9d3a-09ef-438f-9346-c27130bc343d,DISK], DatanodeInfoWithStorage[127.0.0.1:34279,DS-9cb51b89-14f4-482d-8cc7-e925cfb4e653,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-4fdcf054-3c3a-4ac0-9cbc-64b4976f9eed,DISK], DatanodeInfoWithStorage[127.0.0.1:36599,DS-37f88ee3-5816-46a4-b5f2-b5fc7400c4bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41715,DS-a2bd0a97-cc0f-4071-ae1b-b1c6e75992de,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-5f15c145-65a2-4a8f-89cd-abf32eaacc89,DISK], DatanodeInfoWithStorage[127.0.0.1:43894,DS-cfc5b73e-0549-4166-bc7c-7afd33c58c03,DISK], DatanodeInfoWithStorage[127.0.0.1:37792,DS-a98f6d95-d401-4140-a550-8b3755ce6e38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-486182462-172.17.0.5-1597721923003:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35109,DS-3ed0dc46-f9e4-4294-9a37-7e91a5fae8c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41463,DS-0e1fbf1b-b7e1-491b-b320-c1beee54b285,DISK], DatanodeInfoWithStorage[127.0.0.1:36166,DS-6df9525c-eee8-42ee-ac99-49fd597cd461,DISK], DatanodeInfoWithStorage[127.0.0.1:35858,DS-fcd2c62a-1dbb-4d47-b672-b4f0c9fc2e87,DISK], DatanodeInfoWithStorage[127.0.0.1:40170,DS-ed43e5d3-937a-47c5-ab2f-d4217ba323e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35246,DS-d0e80566-7275-46ff-bfae-917d2448d3fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42874,DS-efab6cc4-73a3-4b92-99b5-cf369b5cb5cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38121,DS-f18f5c96-aef4-47d3-960f-9d8dadd66848,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-486182462-172.17.0.5-1597721923003:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35109,DS-3ed0dc46-f9e4-4294-9a37-7e91a5fae8c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41463,DS-0e1fbf1b-b7e1-491b-b320-c1beee54b285,DISK], DatanodeInfoWithStorage[127.0.0.1:36166,DS-6df9525c-eee8-42ee-ac99-49fd597cd461,DISK], DatanodeInfoWithStorage[127.0.0.1:35858,DS-fcd2c62a-1dbb-4d47-b672-b4f0c9fc2e87,DISK], DatanodeInfoWithStorage[127.0.0.1:40170,DS-ed43e5d3-937a-47c5-ab2f-d4217ba323e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35246,DS-d0e80566-7275-46ff-bfae-917d2448d3fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42874,DS-efab6cc4-73a3-4b92-99b5-cf369b5cb5cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38121,DS-f18f5c96-aef4-47d3-960f-9d8dadd66848,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-795524137-172.17.0.5-1597723473302:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43817,DS-1c948e15-74b0-4667-ae69-176229de45c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36747,DS-a4ac4edb-7afd-4cdb-894c-1bcd1254440c,DISK], DatanodeInfoWithStorage[127.0.0.1:45652,DS-feb1df50-5e86-47e1-9e0b-d8e76466dc32,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-aebe6417-4ffa-4ae3-ab5f-8160ff403fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:39791,DS-766c8844-3a96-4c6c-a176-9ca8b3518715,DISK], DatanodeInfoWithStorage[127.0.0.1:34659,DS-b1b762c2-9ad5-48cf-aab9-36b98f557916,DISK], DatanodeInfoWithStorage[127.0.0.1:42037,DS-e53e34de-7d5d-422f-a359-2316bee8851f,DISK], DatanodeInfoWithStorage[127.0.0.1:39194,DS-6f601ff6-a657-4693-ad57-dc3aeb54a990,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-795524137-172.17.0.5-1597723473302:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43817,DS-1c948e15-74b0-4667-ae69-176229de45c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36747,DS-a4ac4edb-7afd-4cdb-894c-1bcd1254440c,DISK], DatanodeInfoWithStorage[127.0.0.1:45652,DS-feb1df50-5e86-47e1-9e0b-d8e76466dc32,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-aebe6417-4ffa-4ae3-ab5f-8160ff403fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:39791,DS-766c8844-3a96-4c6c-a176-9ca8b3518715,DISK], DatanodeInfoWithStorage[127.0.0.1:34659,DS-b1b762c2-9ad5-48cf-aab9-36b98f557916,DISK], DatanodeInfoWithStorage[127.0.0.1:42037,DS-e53e34de-7d5d-422f-a359-2316bee8851f,DISK], DatanodeInfoWithStorage[127.0.0.1:39194,DS-6f601ff6-a657-4693-ad57-dc3aeb54a990,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2082420733-172.17.0.5-1597723836926:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42773,DS-b653a7f5-b319-4fae-b292-11c6e2dceb83,DISK], DatanodeInfoWithStorage[127.0.0.1:44207,DS-538f4d05-b21f-4226-997f-9a4c58be3819,DISK], DatanodeInfoWithStorage[127.0.0.1:41481,DS-1b041283-30d8-412e-91a5-aded4043b719,DISK], DatanodeInfoWithStorage[127.0.0.1:43777,DS-885034df-048a-4b83-acd4-155c79e3b470,DISK], DatanodeInfoWithStorage[127.0.0.1:40483,DS-0a8e4132-37c2-4a77-9d74-e47c530ba3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36546,DS-74bec088-6684-400b-8b65-3abcac5c06a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35229,DS-33f0339d-5963-4f21-9667-f521465f5676,DISK], DatanodeInfoWithStorage[127.0.0.1:38768,DS-1c9aa23d-ab7f-4651-9aaf-b78a527df77c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2082420733-172.17.0.5-1597723836926:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42773,DS-b653a7f5-b319-4fae-b292-11c6e2dceb83,DISK], DatanodeInfoWithStorage[127.0.0.1:44207,DS-538f4d05-b21f-4226-997f-9a4c58be3819,DISK], DatanodeInfoWithStorage[127.0.0.1:41481,DS-1b041283-30d8-412e-91a5-aded4043b719,DISK], DatanodeInfoWithStorage[127.0.0.1:43777,DS-885034df-048a-4b83-acd4-155c79e3b470,DISK], DatanodeInfoWithStorage[127.0.0.1:40483,DS-0a8e4132-37c2-4a77-9d74-e47c530ba3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36546,DS-74bec088-6684-400b-8b65-3abcac5c06a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35229,DS-33f0339d-5963-4f21-9667-f521465f5676,DISK], DatanodeInfoWithStorage[127.0.0.1:38768,DS-1c9aa23d-ab7f-4651-9aaf-b78a527df77c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2123871250-172.17.0.5-1597724017564:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35064,DS-fc252cc8-e499-4902-bbf5-0da047e140fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43443,DS-cb90c3bd-12f2-448a-9f6a-8f84d1c398a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34619,DS-a8f7d9a1-1f93-406e-922b-bd38753af6cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43819,DS-9638542e-c492-4883-9d28-546a736f1703,DISK], DatanodeInfoWithStorage[127.0.0.1:44461,DS-13f4ae40-d763-4701-b7b0-bb36980ed8d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45480,DS-19fc1ed3-e030-4dec-a22e-268edc93f5fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35655,DS-42e7f5da-7695-4683-b02e-50a337391f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:40246,DS-41f12fd6-308a-42dd-b6d5-7f4af283eed4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2123871250-172.17.0.5-1597724017564:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35064,DS-fc252cc8-e499-4902-bbf5-0da047e140fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43443,DS-cb90c3bd-12f2-448a-9f6a-8f84d1c398a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34619,DS-a8f7d9a1-1f93-406e-922b-bd38753af6cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43819,DS-9638542e-c492-4883-9d28-546a736f1703,DISK], DatanodeInfoWithStorage[127.0.0.1:44461,DS-13f4ae40-d763-4701-b7b0-bb36980ed8d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45480,DS-19fc1ed3-e030-4dec-a22e-268edc93f5fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35655,DS-42e7f5da-7695-4683-b02e-50a337391f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:40246,DS-41f12fd6-308a-42dd-b6d5-7f4af283eed4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1365698963-172.17.0.5-1597724338860:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45268,DS-0b2c8265-dae0-4a53-bd12-fb5f3169a446,DISK], DatanodeInfoWithStorage[127.0.0.1:37722,DS-ce2e1660-0a76-42af-bd82-860b420d8862,DISK], DatanodeInfoWithStorage[127.0.0.1:40554,DS-27fe2f8f-0af1-4182-8bd3-2158db6ac6d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37313,DS-71eb0774-f675-4aeb-9348-e51185670234,DISK], DatanodeInfoWithStorage[127.0.0.1:37619,DS-5bff540c-8001-40d6-ad94-3b54bb201d15,DISK], DatanodeInfoWithStorage[127.0.0.1:45826,DS-e5686eb5-98dd-4568-897e-a05025fd7460,DISK], DatanodeInfoWithStorage[127.0.0.1:37980,DS-6f6226b8-34d1-4582-bc75-67dcedf7fec6,DISK], DatanodeInfoWithStorage[127.0.0.1:33001,DS-c1812367-2c1e-47e3-988a-4d916acfe66a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1365698963-172.17.0.5-1597724338860:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45268,DS-0b2c8265-dae0-4a53-bd12-fb5f3169a446,DISK], DatanodeInfoWithStorage[127.0.0.1:37722,DS-ce2e1660-0a76-42af-bd82-860b420d8862,DISK], DatanodeInfoWithStorage[127.0.0.1:40554,DS-27fe2f8f-0af1-4182-8bd3-2158db6ac6d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37313,DS-71eb0774-f675-4aeb-9348-e51185670234,DISK], DatanodeInfoWithStorage[127.0.0.1:37619,DS-5bff540c-8001-40d6-ad94-3b54bb201d15,DISK], DatanodeInfoWithStorage[127.0.0.1:45826,DS-e5686eb5-98dd-4568-897e-a05025fd7460,DISK], DatanodeInfoWithStorage[127.0.0.1:37980,DS-6f6226b8-34d1-4582-bc75-67dcedf7fec6,DISK], DatanodeInfoWithStorage[127.0.0.1:33001,DS-c1812367-2c1e-47e3-988a-4d916acfe66a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1397401080-172.17.0.5-1597724577899:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37186,DS-15dbe2b6-0f10-4519-be15-687664779b72,DISK], DatanodeInfoWithStorage[127.0.0.1:37837,DS-cc2fdee8-bf44-4c6c-b3d3-85532e357a87,DISK], DatanodeInfoWithStorage[127.0.0.1:40365,DS-0267e998-a572-498f-812f-4a84014bb0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40496,DS-287c9536-e659-461a-ad59-f6ef4e4c492e,DISK], DatanodeInfoWithStorage[127.0.0.1:38909,DS-12ac5cd2-cba3-4936-9f97-7ea0e5626f14,DISK], DatanodeInfoWithStorage[127.0.0.1:38178,DS-dd7a52ef-a414-4dea-88bb-80cd0c142257,DISK], DatanodeInfoWithStorage[127.0.0.1:43062,DS-2457b1f0-4825-4bab-a23d-5492c1d1d687,DISK], DatanodeInfoWithStorage[127.0.0.1:42620,DS-d19efcf2-7669-41e5-9f4c-04a076edba79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1397401080-172.17.0.5-1597724577899:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37186,DS-15dbe2b6-0f10-4519-be15-687664779b72,DISK], DatanodeInfoWithStorage[127.0.0.1:37837,DS-cc2fdee8-bf44-4c6c-b3d3-85532e357a87,DISK], DatanodeInfoWithStorage[127.0.0.1:40365,DS-0267e998-a572-498f-812f-4a84014bb0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40496,DS-287c9536-e659-461a-ad59-f6ef4e4c492e,DISK], DatanodeInfoWithStorage[127.0.0.1:38909,DS-12ac5cd2-cba3-4936-9f97-7ea0e5626f14,DISK], DatanodeInfoWithStorage[127.0.0.1:38178,DS-dd7a52ef-a414-4dea-88bb-80cd0c142257,DISK], DatanodeInfoWithStorage[127.0.0.1:43062,DS-2457b1f0-4825-4bab-a23d-5492c1d1d687,DISK], DatanodeInfoWithStorage[127.0.0.1:42620,DS-d19efcf2-7669-41e5-9f4c-04a076edba79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1063820218-172.17.0.5-1597724623547:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33907,DS-3f410222-e4ec-479a-9d7d-fb5056e8b299,DISK], DatanodeInfoWithStorage[127.0.0.1:39084,DS-8e89ba0a-9e20-467f-9e7b-4275c315f1ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39589,DS-2bff07c0-6d48-432b-be74-8e702d787e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:37216,DS-982ed74e-fc86-43db-b7ea-710d0edd5522,DISK], DatanodeInfoWithStorage[127.0.0.1:46041,DS-19bd5157-ad85-46e9-88c0-7515ff638f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44831,DS-798e7f5c-e62d-457c-933c-13cf81b2a6d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40944,DS-6c745451-b65d-4544-a3de-0fa7e4a20b68,DISK], DatanodeInfoWithStorage[127.0.0.1:36650,DS-f0b06e61-8be0-4031-b9e5-1a4fdd76d4fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1063820218-172.17.0.5-1597724623547:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33907,DS-3f410222-e4ec-479a-9d7d-fb5056e8b299,DISK], DatanodeInfoWithStorage[127.0.0.1:39084,DS-8e89ba0a-9e20-467f-9e7b-4275c315f1ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39589,DS-2bff07c0-6d48-432b-be74-8e702d787e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:37216,DS-982ed74e-fc86-43db-b7ea-710d0edd5522,DISK], DatanodeInfoWithStorage[127.0.0.1:46041,DS-19bd5157-ad85-46e9-88c0-7515ff638f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44831,DS-798e7f5c-e62d-457c-933c-13cf81b2a6d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40944,DS-6c745451-b65d-4544-a3de-0fa7e4a20b68,DISK], DatanodeInfoWithStorage[127.0.0.1:36650,DS-f0b06e61-8be0-4031-b9e5-1a4fdd76d4fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1767777215-172.17.0.5-1597725076798:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43188,DS-5f97191f-d9fb-4d2a-a55f-b4cbeab6944f,DISK], DatanodeInfoWithStorage[127.0.0.1:39577,DS-e1a6006c-3748-4097-8158-08e27e55dc6b,DISK], DatanodeInfoWithStorage[127.0.0.1:33731,DS-e3513f54-f7f2-45e0-a2d4-1975b88380c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46246,DS-89e1bbe7-3646-4b79-923f-9c67b020afa3,DISK], DatanodeInfoWithStorage[127.0.0.1:44684,DS-464b4f92-0346-495e-bf31-1048c25ff775,DISK], DatanodeInfoWithStorage[127.0.0.1:38648,DS-06f932f7-5e60-45f2-9ea8-262357022874,DISK], DatanodeInfoWithStorage[127.0.0.1:46116,DS-8fb59f62-5991-46da-8246-c4d58799ef50,DISK], DatanodeInfoWithStorage[127.0.0.1:36067,DS-321a93c6-8c17-4723-9c9a-2173d7339bc9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1767777215-172.17.0.5-1597725076798:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43188,DS-5f97191f-d9fb-4d2a-a55f-b4cbeab6944f,DISK], DatanodeInfoWithStorage[127.0.0.1:39577,DS-e1a6006c-3748-4097-8158-08e27e55dc6b,DISK], DatanodeInfoWithStorage[127.0.0.1:33731,DS-e3513f54-f7f2-45e0-a2d4-1975b88380c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46246,DS-89e1bbe7-3646-4b79-923f-9c67b020afa3,DISK], DatanodeInfoWithStorage[127.0.0.1:44684,DS-464b4f92-0346-495e-bf31-1048c25ff775,DISK], DatanodeInfoWithStorage[127.0.0.1:38648,DS-06f932f7-5e60-45f2-9ea8-262357022874,DISK], DatanodeInfoWithStorage[127.0.0.1:46116,DS-8fb59f62-5991-46da-8246-c4d58799ef50,DISK], DatanodeInfoWithStorage[127.0.0.1:36067,DS-321a93c6-8c17-4723-9c9a-2173d7339bc9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-49845827-172.17.0.5-1597725128979:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33782,DS-2b7084cf-925b-4b4f-9a21-d2e7473bebe8,DISK], DatanodeInfoWithStorage[127.0.0.1:36052,DS-875e2bdf-256d-4628-9a31-1a5c13369888,DISK], DatanodeInfoWithStorage[127.0.0.1:44844,DS-6a1063b7-d5d4-46d6-889b-ce673c2e4ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:36773,DS-52d40e5b-6d1b-401f-896d-ef5ec376644c,DISK], DatanodeInfoWithStorage[127.0.0.1:44847,DS-ee042f4e-7219-4738-85c7-6d98041f7756,DISK], DatanodeInfoWithStorage[127.0.0.1:34011,DS-00caa1c3-8ac9-4f1a-81d6-60ab5856c52f,DISK], DatanodeInfoWithStorage[127.0.0.1:41915,DS-c01f6941-3b4c-47f7-9a43-3d72eb564992,DISK], DatanodeInfoWithStorage[127.0.0.1:35086,DS-df5ba536-b12f-4b43-97ff-c764efa11889,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-49845827-172.17.0.5-1597725128979:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33782,DS-2b7084cf-925b-4b4f-9a21-d2e7473bebe8,DISK], DatanodeInfoWithStorage[127.0.0.1:36052,DS-875e2bdf-256d-4628-9a31-1a5c13369888,DISK], DatanodeInfoWithStorage[127.0.0.1:44844,DS-6a1063b7-d5d4-46d6-889b-ce673c2e4ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:36773,DS-52d40e5b-6d1b-401f-896d-ef5ec376644c,DISK], DatanodeInfoWithStorage[127.0.0.1:44847,DS-ee042f4e-7219-4738-85c7-6d98041f7756,DISK], DatanodeInfoWithStorage[127.0.0.1:34011,DS-00caa1c3-8ac9-4f1a-81d6-60ab5856c52f,DISK], DatanodeInfoWithStorage[127.0.0.1:41915,DS-c01f6941-3b4c-47f7-9a43-3d72eb564992,DISK], DatanodeInfoWithStorage[127.0.0.1:35086,DS-df5ba536-b12f-4b43-97ff-c764efa11889,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-517056959-172.17.0.5-1597725210904:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42717,DS-8f788773-658c-4c9a-a687-cc915acccd57,DISK], DatanodeInfoWithStorage[127.0.0.1:44056,DS-6c5d0ebc-fe5c-438b-9422-0ae42dd3557a,DISK], DatanodeInfoWithStorage[127.0.0.1:38979,DS-b9327394-4229-44a4-9e5d-3b45ffb5e6e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39464,DS-4a111df2-7bbc-4ef4-a74e-1f38efffd170,DISK], DatanodeInfoWithStorage[127.0.0.1:43581,DS-7d568f1b-c267-4bbb-8fb2-d86f5ddebdd6,DISK], DatanodeInfoWithStorage[127.0.0.1:36140,DS-9b169bfd-1b4d-408e-8a1d-2544dd182ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:39038,DS-ac999df6-cc33-4bb1-8fd0-2d89e1bc4ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:42261,DS-cfde4491-f91e-49f5-913d-43a93dc7212f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-517056959-172.17.0.5-1597725210904:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42717,DS-8f788773-658c-4c9a-a687-cc915acccd57,DISK], DatanodeInfoWithStorage[127.0.0.1:44056,DS-6c5d0ebc-fe5c-438b-9422-0ae42dd3557a,DISK], DatanodeInfoWithStorage[127.0.0.1:38979,DS-b9327394-4229-44a4-9e5d-3b45ffb5e6e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39464,DS-4a111df2-7bbc-4ef4-a74e-1f38efffd170,DISK], DatanodeInfoWithStorage[127.0.0.1:43581,DS-7d568f1b-c267-4bbb-8fb2-d86f5ddebdd6,DISK], DatanodeInfoWithStorage[127.0.0.1:36140,DS-9b169bfd-1b4d-408e-8a1d-2544dd182ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:39038,DS-ac999df6-cc33-4bb1-8fd0-2d89e1bc4ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:42261,DS-cfde4491-f91e-49f5-913d-43a93dc7212f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1112746721-172.17.0.5-1597725308966:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33720,DS-988ad4e2-91cd-4952-b024-3fc5d25e273b,DISK], DatanodeInfoWithStorage[127.0.0.1:35480,DS-fa88a48f-1a7d-4d53-98e8-0571b2f6b2e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35698,DS-b9bee046-a8a9-44cd-9ff8-c4cdebb59c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:42015,DS-4875624f-caeb-4b0b-b8cc-30666dbd9da3,DISK], DatanodeInfoWithStorage[127.0.0.1:41607,DS-36de65a9-5cd3-455a-b70e-78216f0d5975,DISK], DatanodeInfoWithStorage[127.0.0.1:44916,DS-63d29761-fd06-4b78-91d5-2ebf2ca8c69f,DISK], DatanodeInfoWithStorage[127.0.0.1:44117,DS-ca5adfd5-4055-400d-83a8-7c55964dbdb0,DISK], DatanodeInfoWithStorage[127.0.0.1:38329,DS-86d9c211-5c5c-4db5-9a90-feb53477979d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1112746721-172.17.0.5-1597725308966:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33720,DS-988ad4e2-91cd-4952-b024-3fc5d25e273b,DISK], DatanodeInfoWithStorage[127.0.0.1:35480,DS-fa88a48f-1a7d-4d53-98e8-0571b2f6b2e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35698,DS-b9bee046-a8a9-44cd-9ff8-c4cdebb59c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:42015,DS-4875624f-caeb-4b0b-b8cc-30666dbd9da3,DISK], DatanodeInfoWithStorage[127.0.0.1:41607,DS-36de65a9-5cd3-455a-b70e-78216f0d5975,DISK], DatanodeInfoWithStorage[127.0.0.1:44916,DS-63d29761-fd06-4b78-91d5-2ebf2ca8c69f,DISK], DatanodeInfoWithStorage[127.0.0.1:44117,DS-ca5adfd5-4055-400d-83a8-7c55964dbdb0,DISK], DatanodeInfoWithStorage[127.0.0.1:38329,DS-86d9c211-5c5c-4db5-9a90-feb53477979d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-796232108-172.17.0.5-1597725433065:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40798,DS-e8576d24-1b97-47f0-9436-7937cc1c989b,DISK], DatanodeInfoWithStorage[127.0.0.1:45090,DS-1cf20991-98b2-434f-87ca-5e0ebc77c715,DISK], DatanodeInfoWithStorage[127.0.0.1:45009,DS-fe119d21-f046-4274-aed7-b9f1692e7c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-23f62d1f-04c4-4190-9883-aca9c24e4502,DISK], DatanodeInfoWithStorage[127.0.0.1:42197,DS-33b7a50e-61fb-4d62-b6bc-744293874260,DISK], DatanodeInfoWithStorage[127.0.0.1:36709,DS-423759f5-3ed7-4d50-8b16-3ca945f3a6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34840,DS-6239e6d7-2180-4b7e-b383-317bec31ebff,DISK], DatanodeInfoWithStorage[127.0.0.1:39081,DS-e36527f4-05ae-4b4a-b0b0-d1f77d4f2552,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-796232108-172.17.0.5-1597725433065:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40798,DS-e8576d24-1b97-47f0-9436-7937cc1c989b,DISK], DatanodeInfoWithStorage[127.0.0.1:45090,DS-1cf20991-98b2-434f-87ca-5e0ebc77c715,DISK], DatanodeInfoWithStorage[127.0.0.1:45009,DS-fe119d21-f046-4274-aed7-b9f1692e7c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-23f62d1f-04c4-4190-9883-aca9c24e4502,DISK], DatanodeInfoWithStorage[127.0.0.1:42197,DS-33b7a50e-61fb-4d62-b6bc-744293874260,DISK], DatanodeInfoWithStorage[127.0.0.1:36709,DS-423759f5-3ed7-4d50-8b16-3ca945f3a6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34840,DS-6239e6d7-2180-4b7e-b383-317bec31ebff,DISK], DatanodeInfoWithStorage[127.0.0.1:39081,DS-e36527f4-05ae-4b4a-b0b0-d1f77d4f2552,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-510802652-172.17.0.5-1597725780208:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37981,DS-2d686091-e55c-4ee3-afa8-404c955fcc5e,DISK], DatanodeInfoWithStorage[127.0.0.1:46037,DS-974f0f2a-18c4-487f-aa8f-56a93d7b2adc,DISK], DatanodeInfoWithStorage[127.0.0.1:42780,DS-aab36618-6b64-40c8-893f-b573912dc8c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38059,DS-52a5a258-d7fc-490b-8e78-784fe88be561,DISK], DatanodeInfoWithStorage[127.0.0.1:41961,DS-9b5be9b2-1bef-4967-ba12-bf0f8dbe8d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38273,DS-4c7b0997-4e12-4684-aef0-404704d91a43,DISK], DatanodeInfoWithStorage[127.0.0.1:33511,DS-8afb6777-6b03-4ca5-bf9a-4d88e58d1300,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-981f8c52-07dc-487b-95e1-f481446d90cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-510802652-172.17.0.5-1597725780208:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37981,DS-2d686091-e55c-4ee3-afa8-404c955fcc5e,DISK], DatanodeInfoWithStorage[127.0.0.1:46037,DS-974f0f2a-18c4-487f-aa8f-56a93d7b2adc,DISK], DatanodeInfoWithStorage[127.0.0.1:42780,DS-aab36618-6b64-40c8-893f-b573912dc8c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38059,DS-52a5a258-d7fc-490b-8e78-784fe88be561,DISK], DatanodeInfoWithStorage[127.0.0.1:41961,DS-9b5be9b2-1bef-4967-ba12-bf0f8dbe8d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38273,DS-4c7b0997-4e12-4684-aef0-404704d91a43,DISK], DatanodeInfoWithStorage[127.0.0.1:33511,DS-8afb6777-6b03-4ca5-bf9a-4d88e58d1300,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-981f8c52-07dc-487b-95e1-f481446d90cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 6794
