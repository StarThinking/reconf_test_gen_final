reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 5000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 5000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1391460146-172.17.0.2-1597513226809:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34840,DS-88702f91-b2bd-46a2-b37f-4642ad3e9e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:37472,DS-b03bf217-a1d7-45d7-83f4-c461e0c7ea52,DISK], DatanodeInfoWithStorage[127.0.0.1:45894,DS-bb3d18bc-a51d-4d07-afaf-e6fb33b37f04,DISK], DatanodeInfoWithStorage[127.0.0.1:40837,DS-bf6a3a07-443e-47a3-9b56-f58255bbe047,DISK], DatanodeInfoWithStorage[127.0.0.1:45228,DS-26942925-f67d-40ca-9cea-e5761985e12b,DISK], DatanodeInfoWithStorage[127.0.0.1:40357,DS-b96cfdc7-f238-4642-a953-e232f8d47103,DISK], DatanodeInfoWithStorage[127.0.0.1:34794,DS-708a312d-2493-4c9d-a80a-7fd88b5cbda0,DISK], DatanodeInfoWithStorage[127.0.0.1:33320,DS-b1cfd09c-efef-4375-9cd9-e3a46d938594,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1391460146-172.17.0.2-1597513226809:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34840,DS-88702f91-b2bd-46a2-b37f-4642ad3e9e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:37472,DS-b03bf217-a1d7-45d7-83f4-c461e0c7ea52,DISK], DatanodeInfoWithStorage[127.0.0.1:45894,DS-bb3d18bc-a51d-4d07-afaf-e6fb33b37f04,DISK], DatanodeInfoWithStorage[127.0.0.1:40837,DS-bf6a3a07-443e-47a3-9b56-f58255bbe047,DISK], DatanodeInfoWithStorage[127.0.0.1:45228,DS-26942925-f67d-40ca-9cea-e5761985e12b,DISK], DatanodeInfoWithStorage[127.0.0.1:40357,DS-b96cfdc7-f238-4642-a953-e232f8d47103,DISK], DatanodeInfoWithStorage[127.0.0.1:34794,DS-708a312d-2493-4c9d-a80a-7fd88b5cbda0,DISK], DatanodeInfoWithStorage[127.0.0.1:33320,DS-b1cfd09c-efef-4375-9cd9-e3a46d938594,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 5000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-961824210-172.17.0.2-1597513793652:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41004,DS-319b4b21-04ee-47f0-86a7-7f91b0dfacbe,DISK], DatanodeInfoWithStorage[127.0.0.1:44225,DS-41224ad9-8f68-437d-b5c5-57c47a6f954e,DISK], DatanodeInfoWithStorage[127.0.0.1:40292,DS-921628c5-3398-45da-8886-2f6351b6f212,DISK], DatanodeInfoWithStorage[127.0.0.1:33949,DS-92bc4ae2-defb-4bbf-95a4-4f90e70d27fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46062,DS-9986cfd2-a180-4770-ade3-c245d9725fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:45710,DS-42cb32de-a1f5-4d6c-b84e-b0146219f130,DISK], DatanodeInfoWithStorage[127.0.0.1:35822,DS-c4402e06-92bc-4ac5-b892-cc2b76ed3480,DISK], DatanodeInfoWithStorage[127.0.0.1:39351,DS-92039b43-fb26-44b4-bdb0-2e0075deb2dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-961824210-172.17.0.2-1597513793652:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41004,DS-319b4b21-04ee-47f0-86a7-7f91b0dfacbe,DISK], DatanodeInfoWithStorage[127.0.0.1:44225,DS-41224ad9-8f68-437d-b5c5-57c47a6f954e,DISK], DatanodeInfoWithStorage[127.0.0.1:40292,DS-921628c5-3398-45da-8886-2f6351b6f212,DISK], DatanodeInfoWithStorage[127.0.0.1:33949,DS-92bc4ae2-defb-4bbf-95a4-4f90e70d27fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46062,DS-9986cfd2-a180-4770-ade3-c245d9725fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:45710,DS-42cb32de-a1f5-4d6c-b84e-b0146219f130,DISK], DatanodeInfoWithStorage[127.0.0.1:35822,DS-c4402e06-92bc-4ac5-b892-cc2b76ed3480,DISK], DatanodeInfoWithStorage[127.0.0.1:39351,DS-92039b43-fb26-44b4-bdb0-2e0075deb2dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 5000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-593968408-172.17.0.2-1597514166951:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32913,DS-0bf67dc4-01b4-4645-9035-c471b2f52aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-6f55f94e-0281-48a2-8220-467b12a1937c,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-017c9537-6ea0-4cd3-8388-e3fef5965586,DISK], DatanodeInfoWithStorage[127.0.0.1:37566,DS-40f91ee8-5e44-46b6-a316-892a710da786,DISK], DatanodeInfoWithStorage[127.0.0.1:35795,DS-be043e51-a37f-4204-8e71-4f8dfcc6280c,DISK], DatanodeInfoWithStorage[127.0.0.1:41732,DS-a2116bd9-6b76-4b74-8ab6-5747021ad9f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45295,DS-fdc7c6ee-1408-4f1f-b1b0-d1955f6e1c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43704,DS-8d27dfc4-e2aa-40a5-b7ed-98017b35239b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-593968408-172.17.0.2-1597514166951:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32913,DS-0bf67dc4-01b4-4645-9035-c471b2f52aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-6f55f94e-0281-48a2-8220-467b12a1937c,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-017c9537-6ea0-4cd3-8388-e3fef5965586,DISK], DatanodeInfoWithStorage[127.0.0.1:37566,DS-40f91ee8-5e44-46b6-a316-892a710da786,DISK], DatanodeInfoWithStorage[127.0.0.1:35795,DS-be043e51-a37f-4204-8e71-4f8dfcc6280c,DISK], DatanodeInfoWithStorage[127.0.0.1:41732,DS-a2116bd9-6b76-4b74-8ab6-5747021ad9f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45295,DS-fdc7c6ee-1408-4f1f-b1b0-d1955f6e1c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43704,DS-8d27dfc4-e2aa-40a5-b7ed-98017b35239b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 5000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1663074954-172.17.0.2-1597514422650:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41770,DS-703a9192-f0c7-46c5-adac-1d3011164f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42421,DS-0217c5fd-42aa-4b50-8ef9-d54e3f8d3a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34209,DS-b07ffbcd-d495-440b-ae10-6dbcd514828d,DISK], DatanodeInfoWithStorage[127.0.0.1:46806,DS-5980dbe1-592c-43af-82b6-656e4aff3736,DISK], DatanodeInfoWithStorage[127.0.0.1:42116,DS-64930798-eef3-4774-baab-aafb43b303de,DISK], DatanodeInfoWithStorage[127.0.0.1:35844,DS-300db6bf-f9b5-4b64-8c04-13097811dd35,DISK], DatanodeInfoWithStorage[127.0.0.1:46807,DS-8978ac80-223c-45db-b786-36f7420c9894,DISK], DatanodeInfoWithStorage[127.0.0.1:46477,DS-9e3aba9b-cb02-4b78-8958-a5974014ead7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1663074954-172.17.0.2-1597514422650:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41770,DS-703a9192-f0c7-46c5-adac-1d3011164f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42421,DS-0217c5fd-42aa-4b50-8ef9-d54e3f8d3a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34209,DS-b07ffbcd-d495-440b-ae10-6dbcd514828d,DISK], DatanodeInfoWithStorage[127.0.0.1:46806,DS-5980dbe1-592c-43af-82b6-656e4aff3736,DISK], DatanodeInfoWithStorage[127.0.0.1:42116,DS-64930798-eef3-4774-baab-aafb43b303de,DISK], DatanodeInfoWithStorage[127.0.0.1:35844,DS-300db6bf-f9b5-4b64-8c04-13097811dd35,DISK], DatanodeInfoWithStorage[127.0.0.1:46807,DS-8978ac80-223c-45db-b786-36f7420c9894,DISK], DatanodeInfoWithStorage[127.0.0.1:46477,DS-9e3aba9b-cb02-4b78-8958-a5974014ead7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 5000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1518397074-172.17.0.2-1597514674110:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36208,DS-53b443a4-635e-46c8-b380-0a3e17de06ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36023,DS-23659055-8991-4856-8e16-4c1dbfff2e85,DISK], DatanodeInfoWithStorage[127.0.0.1:39165,DS-9425b66c-36b3-4cca-bd75-437c91438849,DISK], DatanodeInfoWithStorage[127.0.0.1:44291,DS-d4184d58-09e1-46be-8b88-319766809f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:37587,DS-a230cd14-1cd8-408d-a114-8518aee9dbaa,DISK], DatanodeInfoWithStorage[127.0.0.1:38966,DS-f29ff6ce-1312-4986-88c7-854198c50ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:44994,DS-96375c63-a75d-48ab-9d54-f5437ee077a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33376,DS-f7bac5cd-c4f6-4d39-85e4-1ea8068ee128,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1518397074-172.17.0.2-1597514674110:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36208,DS-53b443a4-635e-46c8-b380-0a3e17de06ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36023,DS-23659055-8991-4856-8e16-4c1dbfff2e85,DISK], DatanodeInfoWithStorage[127.0.0.1:39165,DS-9425b66c-36b3-4cca-bd75-437c91438849,DISK], DatanodeInfoWithStorage[127.0.0.1:44291,DS-d4184d58-09e1-46be-8b88-319766809f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:37587,DS-a230cd14-1cd8-408d-a114-8518aee9dbaa,DISK], DatanodeInfoWithStorage[127.0.0.1:38966,DS-f29ff6ce-1312-4986-88c7-854198c50ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:44994,DS-96375c63-a75d-48ab-9d54-f5437ee077a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33376,DS-f7bac5cd-c4f6-4d39-85e4-1ea8068ee128,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 5000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-962816443-172.17.0.2-1597514816836:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43857,DS-f9ceeb43-96c7-41f4-83d0-333e2db67b31,DISK], DatanodeInfoWithStorage[127.0.0.1:42358,DS-ddc575bd-e79a-43ba-bb5b-3f7e22cddcba,DISK], DatanodeInfoWithStorage[127.0.0.1:34492,DS-712e166d-94fe-40bc-aca1-0241991ee71d,DISK], DatanodeInfoWithStorage[127.0.0.1:37500,DS-59c380c3-785c-42c1-9af7-e20957002e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:33710,DS-32701963-428c-4901-a3f8-804064261587,DISK], DatanodeInfoWithStorage[127.0.0.1:39706,DS-179ed2a7-d37b-4efc-90dd-dfb44191352f,DISK], DatanodeInfoWithStorage[127.0.0.1:42385,DS-08fab20f-2696-467d-94f0-c2946cdb581b,DISK], DatanodeInfoWithStorage[127.0.0.1:44714,DS-aa8059db-01b5-47f2-8ced-8526a7a7516c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-962816443-172.17.0.2-1597514816836:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43857,DS-f9ceeb43-96c7-41f4-83d0-333e2db67b31,DISK], DatanodeInfoWithStorage[127.0.0.1:42358,DS-ddc575bd-e79a-43ba-bb5b-3f7e22cddcba,DISK], DatanodeInfoWithStorage[127.0.0.1:34492,DS-712e166d-94fe-40bc-aca1-0241991ee71d,DISK], DatanodeInfoWithStorage[127.0.0.1:37500,DS-59c380c3-785c-42c1-9af7-e20957002e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:33710,DS-32701963-428c-4901-a3f8-804064261587,DISK], DatanodeInfoWithStorage[127.0.0.1:39706,DS-179ed2a7-d37b-4efc-90dd-dfb44191352f,DISK], DatanodeInfoWithStorage[127.0.0.1:42385,DS-08fab20f-2696-467d-94f0-c2946cdb581b,DISK], DatanodeInfoWithStorage[127.0.0.1:44714,DS-aa8059db-01b5-47f2-8ced-8526a7a7516c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 5000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-155592681-172.17.0.2-1597514854195:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40023,DS-4fe50b03-752f-4f5b-bc27-48a681c3f5a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42879,DS-27908dc6-f794-434e-bcfd-93b88b64579c,DISK], DatanodeInfoWithStorage[127.0.0.1:35176,DS-8c0ee505-852f-4706-8c96-5bcceae9f1f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39396,DS-bc4e6f51-a032-4e49-96f0-914cafe31682,DISK], DatanodeInfoWithStorage[127.0.0.1:38177,DS-5f85b886-767d-4d12-9037-d9507838f2a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34381,DS-78e309d8-4f54-4356-a5b6-9e2c4471155b,DISK], DatanodeInfoWithStorage[127.0.0.1:46320,DS-2d7922b5-2354-4841-ae36-00a3adc1c3a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43606,DS-a200b9e8-ec01-44fc-86ea-c11b4f09dfb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-155592681-172.17.0.2-1597514854195:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40023,DS-4fe50b03-752f-4f5b-bc27-48a681c3f5a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42879,DS-27908dc6-f794-434e-bcfd-93b88b64579c,DISK], DatanodeInfoWithStorage[127.0.0.1:35176,DS-8c0ee505-852f-4706-8c96-5bcceae9f1f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39396,DS-bc4e6f51-a032-4e49-96f0-914cafe31682,DISK], DatanodeInfoWithStorage[127.0.0.1:38177,DS-5f85b886-767d-4d12-9037-d9507838f2a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34381,DS-78e309d8-4f54-4356-a5b6-9e2c4471155b,DISK], DatanodeInfoWithStorage[127.0.0.1:46320,DS-2d7922b5-2354-4841-ae36-00a3adc1c3a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43606,DS-a200b9e8-ec01-44fc-86ea-c11b4f09dfb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 5000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-801664346-172.17.0.2-1597515151355:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34461,DS-7534b00d-cdd6-4257-806d-5228488bfba0,DISK], DatanodeInfoWithStorage[127.0.0.1:46216,DS-ec52d441-6c4e-45d7-ad88-41c572f48b30,DISK], DatanodeInfoWithStorage[127.0.0.1:40035,DS-ba45df16-bf75-4e6c-82dd-873f70bdf099,DISK], DatanodeInfoWithStorage[127.0.0.1:37408,DS-dd4a49ae-b736-48bb-b038-2c51571a5746,DISK], DatanodeInfoWithStorage[127.0.0.1:43640,DS-018c1a61-5eca-4b0e-802b-708ca6baa969,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-f7b2f96c-08da-4559-9616-5c24e46d9f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42883,DS-e7e4e78c-8206-4517-8b45-2a4c7ef73e91,DISK], DatanodeInfoWithStorage[127.0.0.1:42464,DS-f1e37250-617e-45de-a29e-09bb58adeb83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-801664346-172.17.0.2-1597515151355:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34461,DS-7534b00d-cdd6-4257-806d-5228488bfba0,DISK], DatanodeInfoWithStorage[127.0.0.1:46216,DS-ec52d441-6c4e-45d7-ad88-41c572f48b30,DISK], DatanodeInfoWithStorage[127.0.0.1:40035,DS-ba45df16-bf75-4e6c-82dd-873f70bdf099,DISK], DatanodeInfoWithStorage[127.0.0.1:37408,DS-dd4a49ae-b736-48bb-b038-2c51571a5746,DISK], DatanodeInfoWithStorage[127.0.0.1:43640,DS-018c1a61-5eca-4b0e-802b-708ca6baa969,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-f7b2f96c-08da-4559-9616-5c24e46d9f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42883,DS-e7e4e78c-8206-4517-8b45-2a4c7ef73e91,DISK], DatanodeInfoWithStorage[127.0.0.1:42464,DS-f1e37250-617e-45de-a29e-09bb58adeb83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 5000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-50054241-172.17.0.2-1597515372109:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32924,DS-7eb85ef1-7c58-4230-b4ef-e1bb46caedda,DISK], DatanodeInfoWithStorage[127.0.0.1:42360,DS-80b03d62-215f-4489-b9da-273326960e90,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-49adafc0-a63a-4a90-b8d7-ec58b3e9b5e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39689,DS-f13abf0b-fd04-4b2e-8129-9461f664d68e,DISK], DatanodeInfoWithStorage[127.0.0.1:37894,DS-6951db54-5751-4723-820e-1d12171cceba,DISK], DatanodeInfoWithStorage[127.0.0.1:45600,DS-90047bba-3e94-44c0-8927-f6a996e916cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36934,DS-bd0b6730-5d36-46e5-84f8-ea78f80a9a45,DISK], DatanodeInfoWithStorage[127.0.0.1:46052,DS-0da6c631-4e3b-4dde-96b7-c462732ee983,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-50054241-172.17.0.2-1597515372109:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32924,DS-7eb85ef1-7c58-4230-b4ef-e1bb46caedda,DISK], DatanodeInfoWithStorage[127.0.0.1:42360,DS-80b03d62-215f-4489-b9da-273326960e90,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-49adafc0-a63a-4a90-b8d7-ec58b3e9b5e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39689,DS-f13abf0b-fd04-4b2e-8129-9461f664d68e,DISK], DatanodeInfoWithStorage[127.0.0.1:37894,DS-6951db54-5751-4723-820e-1d12171cceba,DISK], DatanodeInfoWithStorage[127.0.0.1:45600,DS-90047bba-3e94-44c0-8927-f6a996e916cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36934,DS-bd0b6730-5d36-46e5-84f8-ea78f80a9a45,DISK], DatanodeInfoWithStorage[127.0.0.1:46052,DS-0da6c631-4e3b-4dde-96b7-c462732ee983,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 5000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1008853507-172.17.0.2-1597515661994:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35276,DS-f0f0069b-b4f5-4652-9357-26b817090bae,DISK], DatanodeInfoWithStorage[127.0.0.1:42130,DS-086208f5-6f14-43cc-8440-963b8bb59285,DISK], DatanodeInfoWithStorage[127.0.0.1:34947,DS-4ed11390-a520-4a12-bbfc-5f0a2fd40877,DISK], DatanodeInfoWithStorage[127.0.0.1:43760,DS-ed7bfbd4-6563-403c-9792-698898f37214,DISK], DatanodeInfoWithStorage[127.0.0.1:32972,DS-97f0d883-f3bc-4a51-abd6-8796d284367f,DISK], DatanodeInfoWithStorage[127.0.0.1:33275,DS-68feced0-b0f3-4326-9d8c-52589fc540b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35716,DS-511405b2-b1a5-4086-b151-db882007c100,DISK], DatanodeInfoWithStorage[127.0.0.1:42791,DS-a39b8e11-23aa-4ce2-8919-2cc5b393350c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1008853507-172.17.0.2-1597515661994:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35276,DS-f0f0069b-b4f5-4652-9357-26b817090bae,DISK], DatanodeInfoWithStorage[127.0.0.1:42130,DS-086208f5-6f14-43cc-8440-963b8bb59285,DISK], DatanodeInfoWithStorage[127.0.0.1:34947,DS-4ed11390-a520-4a12-bbfc-5f0a2fd40877,DISK], DatanodeInfoWithStorage[127.0.0.1:43760,DS-ed7bfbd4-6563-403c-9792-698898f37214,DISK], DatanodeInfoWithStorage[127.0.0.1:32972,DS-97f0d883-f3bc-4a51-abd6-8796d284367f,DISK], DatanodeInfoWithStorage[127.0.0.1:33275,DS-68feced0-b0f3-4326-9d8c-52589fc540b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35716,DS-511405b2-b1a5-4086-b151-db882007c100,DISK], DatanodeInfoWithStorage[127.0.0.1:42791,DS-a39b8e11-23aa-4ce2-8919-2cc5b393350c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 5000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1413135736-172.17.0.2-1597515891960:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46753,DS-1175d25a-982c-4a00-af36-8e3c7d021540,DISK], DatanodeInfoWithStorage[127.0.0.1:37652,DS-f6e76bec-43e3-4868-be57-dc89ff29f2f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45098,DS-cc4fab64-bf76-4cae-9604-8e622dc86d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:43776,DS-137b42e0-44db-490d-a22c-ccf4ef023f59,DISK], DatanodeInfoWithStorage[127.0.0.1:40914,DS-917345b2-584f-474f-810a-f6ad9c78becb,DISK], DatanodeInfoWithStorage[127.0.0.1:45592,DS-f3f5a515-c1a7-47b8-be6a-0a38ddc970f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43965,DS-f3f2410c-dd67-440e-9930-6dde56d7830c,DISK], DatanodeInfoWithStorage[127.0.0.1:43506,DS-2e457138-c460-4636-9749-4c0d8d61a53e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1413135736-172.17.0.2-1597515891960:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46753,DS-1175d25a-982c-4a00-af36-8e3c7d021540,DISK], DatanodeInfoWithStorage[127.0.0.1:37652,DS-f6e76bec-43e3-4868-be57-dc89ff29f2f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45098,DS-cc4fab64-bf76-4cae-9604-8e622dc86d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:43776,DS-137b42e0-44db-490d-a22c-ccf4ef023f59,DISK], DatanodeInfoWithStorage[127.0.0.1:40914,DS-917345b2-584f-474f-810a-f6ad9c78becb,DISK], DatanodeInfoWithStorage[127.0.0.1:45592,DS-f3f5a515-c1a7-47b8-be6a-0a38ddc970f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43965,DS-f3f2410c-dd67-440e-9930-6dde56d7830c,DISK], DatanodeInfoWithStorage[127.0.0.1:43506,DS-2e457138-c460-4636-9749-4c0d8d61a53e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 5000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-168378608-172.17.0.2-1597516006933:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42356,DS-7e7d07cc-e0fd-4c1d-bd4e-c42566d49a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40700,DS-ebc95bc7-384b-4ec7-aff4-ddb5fd3647e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44600,DS-6cab47df-8b85-4a2f-ac56-e910eb54df9e,DISK], DatanodeInfoWithStorage[127.0.0.1:33574,DS-6777be42-9304-4c8d-8c99-4e5711d4283b,DISK], DatanodeInfoWithStorage[127.0.0.1:36735,DS-69a71417-67f0-4d4c-9009-4f0d1a3f7786,DISK], DatanodeInfoWithStorage[127.0.0.1:44218,DS-f9977042-7e98-4dbc-8b8a-fb8287784571,DISK], DatanodeInfoWithStorage[127.0.0.1:40073,DS-7bb577c9-6255-4cd6-9bb4-7ccf22f07d01,DISK], DatanodeInfoWithStorage[127.0.0.1:36782,DS-84bb2fe7-6ab7-47cb-876e-67e4ea462667,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-168378608-172.17.0.2-1597516006933:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42356,DS-7e7d07cc-e0fd-4c1d-bd4e-c42566d49a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40700,DS-ebc95bc7-384b-4ec7-aff4-ddb5fd3647e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44600,DS-6cab47df-8b85-4a2f-ac56-e910eb54df9e,DISK], DatanodeInfoWithStorage[127.0.0.1:33574,DS-6777be42-9304-4c8d-8c99-4e5711d4283b,DISK], DatanodeInfoWithStorage[127.0.0.1:36735,DS-69a71417-67f0-4d4c-9009-4f0d1a3f7786,DISK], DatanodeInfoWithStorage[127.0.0.1:44218,DS-f9977042-7e98-4dbc-8b8a-fb8287784571,DISK], DatanodeInfoWithStorage[127.0.0.1:40073,DS-7bb577c9-6255-4cd6-9bb4-7ccf22f07d01,DISK], DatanodeInfoWithStorage[127.0.0.1:36782,DS-84bb2fe7-6ab7-47cb-876e-67e4ea462667,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 5000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-319781625-172.17.0.2-1597516128357:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37751,DS-993b8e7d-0f84-4e2b-b0d2-9ed0cbec73bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41670,DS-3e9538a0-acd7-4ae9-b9bd-7bbd25c728a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36206,DS-0f0a8c87-8286-41c0-90d3-c96455a8e116,DISK], DatanodeInfoWithStorage[127.0.0.1:41124,DS-15686ed1-8df7-4c64-bbc9-8688e3eca775,DISK], DatanodeInfoWithStorage[127.0.0.1:36188,DS-93a5fa54-8036-471b-984f-579560fe1170,DISK], DatanodeInfoWithStorage[127.0.0.1:34821,DS-66ab762e-d285-4e08-b585-9ed9b4d56307,DISK], DatanodeInfoWithStorage[127.0.0.1:34033,DS-8320f8de-428d-407d-90ca-4c174a072b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45680,DS-284c0f27-4eba-4ef9-b4ad-44dc5a34c2fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-319781625-172.17.0.2-1597516128357:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37751,DS-993b8e7d-0f84-4e2b-b0d2-9ed0cbec73bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41670,DS-3e9538a0-acd7-4ae9-b9bd-7bbd25c728a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36206,DS-0f0a8c87-8286-41c0-90d3-c96455a8e116,DISK], DatanodeInfoWithStorage[127.0.0.1:41124,DS-15686ed1-8df7-4c64-bbc9-8688e3eca775,DISK], DatanodeInfoWithStorage[127.0.0.1:36188,DS-93a5fa54-8036-471b-984f-579560fe1170,DISK], DatanodeInfoWithStorage[127.0.0.1:34821,DS-66ab762e-d285-4e08-b585-9ed9b4d56307,DISK], DatanodeInfoWithStorage[127.0.0.1:34033,DS-8320f8de-428d-407d-90ca-4c174a072b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45680,DS-284c0f27-4eba-4ef9-b4ad-44dc5a34c2fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 5000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1616425255-172.17.0.2-1597516740678:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36176,DS-8a0512c1-fe9a-4d26-a4b4-dc67941ac90a,DISK], DatanodeInfoWithStorage[127.0.0.1:36853,DS-99478d1c-baf2-470f-b308-202c0aa128db,DISK], DatanodeInfoWithStorage[127.0.0.1:34912,DS-52c665cd-88f1-4451-9ca9-89cd8b2b2423,DISK], DatanodeInfoWithStorage[127.0.0.1:46544,DS-76ab0e3a-1c82-491a-85d7-6f4d9da37ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:40425,DS-238661d0-bb4e-4556-9ff0-725d56a45948,DISK], DatanodeInfoWithStorage[127.0.0.1:34817,DS-94b924af-c488-413f-877b-a1fae6778e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:46639,DS-88e5b460-dd32-4e9d-976f-1aac258809a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39679,DS-73039c7f-0608-46e8-8c3e-890b3246816e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1616425255-172.17.0.2-1597516740678:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36176,DS-8a0512c1-fe9a-4d26-a4b4-dc67941ac90a,DISK], DatanodeInfoWithStorage[127.0.0.1:36853,DS-99478d1c-baf2-470f-b308-202c0aa128db,DISK], DatanodeInfoWithStorage[127.0.0.1:34912,DS-52c665cd-88f1-4451-9ca9-89cd8b2b2423,DISK], DatanodeInfoWithStorage[127.0.0.1:46544,DS-76ab0e3a-1c82-491a-85d7-6f4d9da37ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:40425,DS-238661d0-bb4e-4556-9ff0-725d56a45948,DISK], DatanodeInfoWithStorage[127.0.0.1:34817,DS-94b924af-c488-413f-877b-a1fae6778e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:46639,DS-88e5b460-dd32-4e9d-976f-1aac258809a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39679,DS-73039c7f-0608-46e8-8c3e-890b3246816e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 5000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-871459618-172.17.0.2-1597516811374:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45831,DS-ef805b2e-880f-4d11-9156-8b44e606da77,DISK], DatanodeInfoWithStorage[127.0.0.1:34703,DS-3721add7-bbb9-4a14-ba5d-ec8985e0ba34,DISK], DatanodeInfoWithStorage[127.0.0.1:43217,DS-0c7845a8-a421-4b51-a1eb-e7fb6a3f70c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44231,DS-24818b15-c28d-4607-ac80-6c0572bd7f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:45663,DS-5948603f-fca8-4fb2-ba59-cddb6000c154,DISK], DatanodeInfoWithStorage[127.0.0.1:35299,DS-201bb36c-501c-4cdf-b039-e7504f279c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43055,DS-8e7a3704-18e5-44c5-9856-0c8e24a68d88,DISK], DatanodeInfoWithStorage[127.0.0.1:43232,DS-7017a834-8b17-4909-a454-321fc724fd5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-871459618-172.17.0.2-1597516811374:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45831,DS-ef805b2e-880f-4d11-9156-8b44e606da77,DISK], DatanodeInfoWithStorage[127.0.0.1:34703,DS-3721add7-bbb9-4a14-ba5d-ec8985e0ba34,DISK], DatanodeInfoWithStorage[127.0.0.1:43217,DS-0c7845a8-a421-4b51-a1eb-e7fb6a3f70c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44231,DS-24818b15-c28d-4607-ac80-6c0572bd7f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:45663,DS-5948603f-fca8-4fb2-ba59-cddb6000c154,DISK], DatanodeInfoWithStorage[127.0.0.1:35299,DS-201bb36c-501c-4cdf-b039-e7504f279c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43055,DS-8e7a3704-18e5-44c5-9856-0c8e24a68d88,DISK], DatanodeInfoWithStorage[127.0.0.1:43232,DS-7017a834-8b17-4909-a454-321fc724fd5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 5000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-57031959-172.17.0.2-1597516955501:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41588,DS-bef046ae-a0b8-4629-8602-ce98c1e974aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34475,DS-a76453b0-89a9-418e-80e7-c473572eabbc,DISK], DatanodeInfoWithStorage[127.0.0.1:38807,DS-4f39d10c-f2e8-4dd4-9c74-5196589b9220,DISK], DatanodeInfoWithStorage[127.0.0.1:37219,DS-14639085-b16d-418d-85e8-231b3376ea1c,DISK], DatanodeInfoWithStorage[127.0.0.1:36728,DS-625398cb-d564-4eee-9dcb-67c372dd5a13,DISK], DatanodeInfoWithStorage[127.0.0.1:38368,DS-31e687fb-0383-4f77-b507-1f2fd293ef5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39075,DS-512ee660-39b7-4eb2-8b18-130300c5aae8,DISK], DatanodeInfoWithStorage[127.0.0.1:42549,DS-cc06db53-ddcb-4cd6-a5ea-bbc2c8346d48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-57031959-172.17.0.2-1597516955501:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41588,DS-bef046ae-a0b8-4629-8602-ce98c1e974aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34475,DS-a76453b0-89a9-418e-80e7-c473572eabbc,DISK], DatanodeInfoWithStorage[127.0.0.1:38807,DS-4f39d10c-f2e8-4dd4-9c74-5196589b9220,DISK], DatanodeInfoWithStorage[127.0.0.1:37219,DS-14639085-b16d-418d-85e8-231b3376ea1c,DISK], DatanodeInfoWithStorage[127.0.0.1:36728,DS-625398cb-d564-4eee-9dcb-67c372dd5a13,DISK], DatanodeInfoWithStorage[127.0.0.1:38368,DS-31e687fb-0383-4f77-b507-1f2fd293ef5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39075,DS-512ee660-39b7-4eb2-8b18-130300c5aae8,DISK], DatanodeInfoWithStorage[127.0.0.1:42549,DS-cc06db53-ddcb-4cd6-a5ea-bbc2c8346d48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 5000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2036605973-172.17.0.2-1597517108256:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39755,DS-fcedd487-73cb-4576-9902-34aebb801c65,DISK], DatanodeInfoWithStorage[127.0.0.1:44999,DS-60d8031a-8aa7-48b9-a18f-6231b33ef03f,DISK], DatanodeInfoWithStorage[127.0.0.1:34298,DS-c2b6bbb1-02bb-46d9-9163-d209418bd5c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42747,DS-e69da32b-7542-447b-a2b2-bb7d9e043e67,DISK], DatanodeInfoWithStorage[127.0.0.1:41028,DS-0237d6c6-e7ce-4c58-9d5a-c5a160cbc0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46037,DS-e1f1c9df-e963-4563-ad54-d115b2880208,DISK], DatanodeInfoWithStorage[127.0.0.1:42197,DS-0169ca1d-c95d-4bcc-92a1-1a65dccf9d57,DISK], DatanodeInfoWithStorage[127.0.0.1:43798,DS-7d73759a-d60b-4423-9af3-10b46d97ff9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2036605973-172.17.0.2-1597517108256:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39755,DS-fcedd487-73cb-4576-9902-34aebb801c65,DISK], DatanodeInfoWithStorage[127.0.0.1:44999,DS-60d8031a-8aa7-48b9-a18f-6231b33ef03f,DISK], DatanodeInfoWithStorage[127.0.0.1:34298,DS-c2b6bbb1-02bb-46d9-9163-d209418bd5c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42747,DS-e69da32b-7542-447b-a2b2-bb7d9e043e67,DISK], DatanodeInfoWithStorage[127.0.0.1:41028,DS-0237d6c6-e7ce-4c58-9d5a-c5a160cbc0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46037,DS-e1f1c9df-e963-4563-ad54-d115b2880208,DISK], DatanodeInfoWithStorage[127.0.0.1:42197,DS-0169ca1d-c95d-4bcc-92a1-1a65dccf9d57,DISK], DatanodeInfoWithStorage[127.0.0.1:43798,DS-7d73759a-d60b-4423-9af3-10b46d97ff9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 5000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-763015415-172.17.0.2-1597518040169:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44903,DS-67df4e3a-470d-4cdb-9031-f0723d5bbc54,DISK], DatanodeInfoWithStorage[127.0.0.1:44292,DS-0ace1e97-4545-440f-bca5-7472d885aa87,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-2fad7285-3e29-425f-8452-82039fb52a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:42393,DS-e72fae8c-c36f-4ee2-9e9e-73801811038a,DISK], DatanodeInfoWithStorage[127.0.0.1:40307,DS-055b6582-0133-4f71-9818-10cb3c77e084,DISK], DatanodeInfoWithStorage[127.0.0.1:43637,DS-f5c619d1-5a35-43e7-84bf-88b4ce96089a,DISK], DatanodeInfoWithStorage[127.0.0.1:41069,DS-36352f74-2dbf-4019-aeeb-aa5e205dcd0c,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-9e29f1f2-cc9c-415a-a390-dedce1951e83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-763015415-172.17.0.2-1597518040169:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44903,DS-67df4e3a-470d-4cdb-9031-f0723d5bbc54,DISK], DatanodeInfoWithStorage[127.0.0.1:44292,DS-0ace1e97-4545-440f-bca5-7472d885aa87,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-2fad7285-3e29-425f-8452-82039fb52a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:42393,DS-e72fae8c-c36f-4ee2-9e9e-73801811038a,DISK], DatanodeInfoWithStorage[127.0.0.1:40307,DS-055b6582-0133-4f71-9818-10cb3c77e084,DISK], DatanodeInfoWithStorage[127.0.0.1:43637,DS-f5c619d1-5a35-43e7-84bf-88b4ce96089a,DISK], DatanodeInfoWithStorage[127.0.0.1:41069,DS-36352f74-2dbf-4019-aeeb-aa5e205dcd0c,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-9e29f1f2-cc9c-415a-a390-dedce1951e83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 5000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-798888514-172.17.0.2-1597518216997:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35798,DS-2842d122-b364-45bb-a56f-a8ed5c517ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:44988,DS-aa230199-03ba-44b8-8474-b4da30517082,DISK], DatanodeInfoWithStorage[127.0.0.1:46829,DS-b8172881-8495-49d1-94b3-2e154cd93d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:46110,DS-d6e25535-968a-472a-92e3-4d68d2d5f616,DISK], DatanodeInfoWithStorage[127.0.0.1:43941,DS-cb28578e-e30d-408f-80c6-23366961eab4,DISK], DatanodeInfoWithStorage[127.0.0.1:35055,DS-e6e42ce7-a6ac-4571-8a89-8aca09f820ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36197,DS-3256ca24-91da-4da9-a291-a4459cd4f029,DISK], DatanodeInfoWithStorage[127.0.0.1:39803,DS-72512e8d-1f62-4ee7-be96-ec92b7ece292,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-798888514-172.17.0.2-1597518216997:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35798,DS-2842d122-b364-45bb-a56f-a8ed5c517ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:44988,DS-aa230199-03ba-44b8-8474-b4da30517082,DISK], DatanodeInfoWithStorage[127.0.0.1:46829,DS-b8172881-8495-49d1-94b3-2e154cd93d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:46110,DS-d6e25535-968a-472a-92e3-4d68d2d5f616,DISK], DatanodeInfoWithStorage[127.0.0.1:43941,DS-cb28578e-e30d-408f-80c6-23366961eab4,DISK], DatanodeInfoWithStorage[127.0.0.1:35055,DS-e6e42ce7-a6ac-4571-8a89-8aca09f820ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36197,DS-3256ca24-91da-4da9-a291-a4459cd4f029,DISK], DatanodeInfoWithStorage[127.0.0.1:39803,DS-72512e8d-1f62-4ee7-be96-ec92b7ece292,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 5000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-145755225-172.17.0.2-1597518287857:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37573,DS-b7722022-49a0-4b8e-a6a7-f9d76864a0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33514,DS-147fb4a7-2a29-4704-bbea-791abc461bac,DISK], DatanodeInfoWithStorage[127.0.0.1:34298,DS-4456426f-0b04-4c02-8c1e-654dfef19763,DISK], DatanodeInfoWithStorage[127.0.0.1:41154,DS-e8e6d71e-66df-4f73-b9f2-01df49c0c272,DISK], DatanodeInfoWithStorage[127.0.0.1:36059,DS-d7ec48be-4e7a-4248-986f-57b664454c82,DISK], DatanodeInfoWithStorage[127.0.0.1:36071,DS-054c3c2c-47ed-4a95-933a-ffaba170c1bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41798,DS-0e8d2e71-5e30-43a8-bffe-155063141ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:38806,DS-0c40089b-5521-4e2a-a3b5-126b46cb874e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-145755225-172.17.0.2-1597518287857:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37573,DS-b7722022-49a0-4b8e-a6a7-f9d76864a0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33514,DS-147fb4a7-2a29-4704-bbea-791abc461bac,DISK], DatanodeInfoWithStorage[127.0.0.1:34298,DS-4456426f-0b04-4c02-8c1e-654dfef19763,DISK], DatanodeInfoWithStorage[127.0.0.1:41154,DS-e8e6d71e-66df-4f73-b9f2-01df49c0c272,DISK], DatanodeInfoWithStorage[127.0.0.1:36059,DS-d7ec48be-4e7a-4248-986f-57b664454c82,DISK], DatanodeInfoWithStorage[127.0.0.1:36071,DS-054c3c2c-47ed-4a95-933a-ffaba170c1bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41798,DS-0e8d2e71-5e30-43a8-bffe-155063141ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:38806,DS-0c40089b-5521-4e2a-a3b5-126b46cb874e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 5000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1282012010-172.17.0.2-1597518393192:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40198,DS-0032ce9d-0334-4dca-b1c5-bb128be62bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:40241,DS-69eb3ccb-f33f-4019-b617-cc06949034ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41710,DS-5f626b57-9549-4eab-8c99-a0091ab422c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44057,DS-f470b9c8-5534-4326-ab33-87c90218ba07,DISK], DatanodeInfoWithStorage[127.0.0.1:42814,DS-3a086d18-9b3b-492e-b24d-9b1a5a6fe01b,DISK], DatanodeInfoWithStorage[127.0.0.1:42518,DS-ea6647a3-b94f-435f-8b22-9fe627b6873d,DISK], DatanodeInfoWithStorage[127.0.0.1:41736,DS-fe30fbd7-6a54-4439-a4e3-f5581088d009,DISK], DatanodeInfoWithStorage[127.0.0.1:40038,DS-3ea194b9-7907-48b2-bf80-420230abe6f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1282012010-172.17.0.2-1597518393192:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40198,DS-0032ce9d-0334-4dca-b1c5-bb128be62bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:40241,DS-69eb3ccb-f33f-4019-b617-cc06949034ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41710,DS-5f626b57-9549-4eab-8c99-a0091ab422c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44057,DS-f470b9c8-5534-4326-ab33-87c90218ba07,DISK], DatanodeInfoWithStorage[127.0.0.1:42814,DS-3a086d18-9b3b-492e-b24d-9b1a5a6fe01b,DISK], DatanodeInfoWithStorage[127.0.0.1:42518,DS-ea6647a3-b94f-435f-8b22-9fe627b6873d,DISK], DatanodeInfoWithStorage[127.0.0.1:41736,DS-fe30fbd7-6a54-4439-a4e3-f5581088d009,DISK], DatanodeInfoWithStorage[127.0.0.1:40038,DS-3ea194b9-7907-48b2-bf80-420230abe6f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5481
