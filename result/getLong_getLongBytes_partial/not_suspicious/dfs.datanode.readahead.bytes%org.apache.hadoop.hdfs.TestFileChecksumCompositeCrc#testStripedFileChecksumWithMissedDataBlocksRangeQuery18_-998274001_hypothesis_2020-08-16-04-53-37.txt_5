reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 8388608
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 8388608
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1290111010-172.17.0.17-1597553795928:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38678,DS-f594e1ae-aa5c-4bd4-9bf0-04bde2ee3dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:34165,DS-c45dc02e-e53a-4ab4-80c4-157a5536107b,DISK], DatanodeInfoWithStorage[127.0.0.1:37905,DS-09b84f4f-224c-464c-9f19-18ca98b0149e,DISK], DatanodeInfoWithStorage[127.0.0.1:38344,DS-968c9aca-7d3c-4cb9-9433-294c931f525a,DISK], DatanodeInfoWithStorage[127.0.0.1:37458,DS-6cae1616-72a6-4305-ac41-ab292c202acd,DISK], DatanodeInfoWithStorage[127.0.0.1:40241,DS-492473bf-c3be-4ef3-a80e-e68a096698c6,DISK], DatanodeInfoWithStorage[127.0.0.1:32853,DS-eac9bc52-d2c5-49e3-a499-fec5bf05eb15,DISK], DatanodeInfoWithStorage[127.0.0.1:44221,DS-6e3ea769-92b3-4f94-a5e8-22f08dd1fc26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1290111010-172.17.0.17-1597553795928:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38678,DS-f594e1ae-aa5c-4bd4-9bf0-04bde2ee3dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:34165,DS-c45dc02e-e53a-4ab4-80c4-157a5536107b,DISK], DatanodeInfoWithStorage[127.0.0.1:37905,DS-09b84f4f-224c-464c-9f19-18ca98b0149e,DISK], DatanodeInfoWithStorage[127.0.0.1:38344,DS-968c9aca-7d3c-4cb9-9433-294c931f525a,DISK], DatanodeInfoWithStorage[127.0.0.1:37458,DS-6cae1616-72a6-4305-ac41-ab292c202acd,DISK], DatanodeInfoWithStorage[127.0.0.1:40241,DS-492473bf-c3be-4ef3-a80e-e68a096698c6,DISK], DatanodeInfoWithStorage[127.0.0.1:32853,DS-eac9bc52-d2c5-49e3-a499-fec5bf05eb15,DISK], DatanodeInfoWithStorage[127.0.0.1:44221,DS-6e3ea769-92b3-4f94-a5e8-22f08dd1fc26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 8388608
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1624716227-172.17.0.17-1597553835127:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36836,DS-7506c427-95a3-437b-8f9c-3aa84956eeaa,DISK], DatanodeInfoWithStorage[127.0.0.1:33260,DS-924e1df4-ce98-4bef-90de-abb05ecbf124,DISK], DatanodeInfoWithStorage[127.0.0.1:36726,DS-1314f20d-6772-4925-8817-383ac63e8d39,DISK], DatanodeInfoWithStorage[127.0.0.1:33162,DS-e7a49ed1-cf0e-4208-aeec-cd8326aa6fab,DISK], DatanodeInfoWithStorage[127.0.0.1:38036,DS-f9b2fb0d-b46e-4be9-9924-271b247b0b02,DISK], DatanodeInfoWithStorage[127.0.0.1:43735,DS-af492fb2-2329-4cf1-8fae-4fbaf496f612,DISK], DatanodeInfoWithStorage[127.0.0.1:44611,DS-7398d549-40f2-46f8-a79f-24129392b97c,DISK], DatanodeInfoWithStorage[127.0.0.1:38573,DS-c110d0f7-d99e-453b-a16a-75991d7d9f2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1624716227-172.17.0.17-1597553835127:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36836,DS-7506c427-95a3-437b-8f9c-3aa84956eeaa,DISK], DatanodeInfoWithStorage[127.0.0.1:33260,DS-924e1df4-ce98-4bef-90de-abb05ecbf124,DISK], DatanodeInfoWithStorage[127.0.0.1:36726,DS-1314f20d-6772-4925-8817-383ac63e8d39,DISK], DatanodeInfoWithStorage[127.0.0.1:33162,DS-e7a49ed1-cf0e-4208-aeec-cd8326aa6fab,DISK], DatanodeInfoWithStorage[127.0.0.1:38036,DS-f9b2fb0d-b46e-4be9-9924-271b247b0b02,DISK], DatanodeInfoWithStorage[127.0.0.1:43735,DS-af492fb2-2329-4cf1-8fae-4fbaf496f612,DISK], DatanodeInfoWithStorage[127.0.0.1:44611,DS-7398d549-40f2-46f8-a79f-24129392b97c,DISK], DatanodeInfoWithStorage[127.0.0.1:38573,DS-c110d0f7-d99e-453b-a16a-75991d7d9f2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 8388608
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1266348333-172.17.0.17-1597554528578:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34678,DS-202e361b-059b-4f2b-b827-fe5fb7c7d0e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43394,DS-9adc1e74-87ca-40a9-a04d-df70f9256e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:39185,DS-39a1f61c-4039-441b-a2ed-2e16b63ef4e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41398,DS-a053c8c2-24e5-4ef1-b8aa-8a80c9b1c6aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42309,DS-5252af13-8637-4abc-9ab4-deba8531f4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37982,DS-f8d5bc7c-9469-4388-bbdb-776d7a4a8555,DISK], DatanodeInfoWithStorage[127.0.0.1:33225,DS-8d128732-e096-4eec-8d53-483b9e2e9db3,DISK], DatanodeInfoWithStorage[127.0.0.1:41077,DS-f374945d-f33f-41cc-af9f-5dbf8f724e2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1266348333-172.17.0.17-1597554528578:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34678,DS-202e361b-059b-4f2b-b827-fe5fb7c7d0e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43394,DS-9adc1e74-87ca-40a9-a04d-df70f9256e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:39185,DS-39a1f61c-4039-441b-a2ed-2e16b63ef4e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41398,DS-a053c8c2-24e5-4ef1-b8aa-8a80c9b1c6aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42309,DS-5252af13-8637-4abc-9ab4-deba8531f4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37982,DS-f8d5bc7c-9469-4388-bbdb-776d7a4a8555,DISK], DatanodeInfoWithStorage[127.0.0.1:33225,DS-8d128732-e096-4eec-8d53-483b9e2e9db3,DISK], DatanodeInfoWithStorage[127.0.0.1:41077,DS-f374945d-f33f-41cc-af9f-5dbf8f724e2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 8388608
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1959758759-172.17.0.17-1597554673370:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40420,DS-4b761b8c-363b-4af0-bc08-a165061338af,DISK], DatanodeInfoWithStorage[127.0.0.1:42659,DS-d869468f-f146-46a9-8c0e-9fdc2e7ac945,DISK], DatanodeInfoWithStorage[127.0.0.1:42229,DS-7cedfd59-3c94-4092-aba9-447a6655678d,DISK], DatanodeInfoWithStorage[127.0.0.1:33030,DS-de0d66a4-7bef-4fa3-b016-c86d707cd8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36242,DS-2e94a9d6-b62e-471f-9f3c-c4d51e838eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:37012,DS-5b0bb7bb-d76f-4948-ad30-0639aa919bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:44335,DS-00f4ddb4-b457-4f5c-a17b-1d70edca764e,DISK], DatanodeInfoWithStorage[127.0.0.1:44782,DS-ae1d5fed-f023-4a85-9180-878e9d58171d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1959758759-172.17.0.17-1597554673370:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40420,DS-4b761b8c-363b-4af0-bc08-a165061338af,DISK], DatanodeInfoWithStorage[127.0.0.1:42659,DS-d869468f-f146-46a9-8c0e-9fdc2e7ac945,DISK], DatanodeInfoWithStorage[127.0.0.1:42229,DS-7cedfd59-3c94-4092-aba9-447a6655678d,DISK], DatanodeInfoWithStorage[127.0.0.1:33030,DS-de0d66a4-7bef-4fa3-b016-c86d707cd8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36242,DS-2e94a9d6-b62e-471f-9f3c-c4d51e838eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:37012,DS-5b0bb7bb-d76f-4948-ad30-0639aa919bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:44335,DS-00f4ddb4-b457-4f5c-a17b-1d70edca764e,DISK], DatanodeInfoWithStorage[127.0.0.1:44782,DS-ae1d5fed-f023-4a85-9180-878e9d58171d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 8388608
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-581617282-172.17.0.17-1597555151299:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44350,DS-bc9475d5-c69e-4c13-a8aa-19916f126a62,DISK], DatanodeInfoWithStorage[127.0.0.1:46430,DS-66829340-2ebc-4cac-9708-845c14a17d90,DISK], DatanodeInfoWithStorage[127.0.0.1:44130,DS-3f80ac98-d8a7-441c-b537-dfad7654c637,DISK], DatanodeInfoWithStorage[127.0.0.1:44400,DS-22546c09-19f3-45fa-bbb8-2becf9fb0c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:36066,DS-f357c633-8acd-4106-8d76-37a691f9ab54,DISK], DatanodeInfoWithStorage[127.0.0.1:37117,DS-b6a23622-91d9-48a5-861f-7b8680caa34e,DISK], DatanodeInfoWithStorage[127.0.0.1:40154,DS-6b8f2a00-1091-4979-a741-d61d4f966d82,DISK], DatanodeInfoWithStorage[127.0.0.1:38548,DS-5d2827ce-d8a0-4e69-8f1d-10eca35a4be3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-581617282-172.17.0.17-1597555151299:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44350,DS-bc9475d5-c69e-4c13-a8aa-19916f126a62,DISK], DatanodeInfoWithStorage[127.0.0.1:46430,DS-66829340-2ebc-4cac-9708-845c14a17d90,DISK], DatanodeInfoWithStorage[127.0.0.1:44130,DS-3f80ac98-d8a7-441c-b537-dfad7654c637,DISK], DatanodeInfoWithStorage[127.0.0.1:44400,DS-22546c09-19f3-45fa-bbb8-2becf9fb0c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:36066,DS-f357c633-8acd-4106-8d76-37a691f9ab54,DISK], DatanodeInfoWithStorage[127.0.0.1:37117,DS-b6a23622-91d9-48a5-861f-7b8680caa34e,DISK], DatanodeInfoWithStorage[127.0.0.1:40154,DS-6b8f2a00-1091-4979-a741-d61d4f966d82,DISK], DatanodeInfoWithStorage[127.0.0.1:38548,DS-5d2827ce-d8a0-4e69-8f1d-10eca35a4be3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 8388608
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1531085915-172.17.0.17-1597555188639:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38325,DS-7f7d9635-0eeb-4787-956d-65f970eaf257,DISK], DatanodeInfoWithStorage[127.0.0.1:46615,DS-8f76c165-eead-4e3a-97f0-1b0e6630d03e,DISK], DatanodeInfoWithStorage[127.0.0.1:33769,DS-223667b4-313e-4da3-9e0f-1a73e21ecb87,DISK], DatanodeInfoWithStorage[127.0.0.1:38924,DS-508e9016-28ec-43c9-817a-941959683428,DISK], DatanodeInfoWithStorage[127.0.0.1:37193,DS-410796f1-11f1-4bb4-924d-52b9d8c09d88,DISK], DatanodeInfoWithStorage[127.0.0.1:44124,DS-c94c229d-2e44-44b7-a03d-874f9378ed9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37115,DS-811631e9-1c45-4993-98ab-8f27bee51fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:34587,DS-41c9d206-343e-4397-a6f4-c4f86b521cc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1531085915-172.17.0.17-1597555188639:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38325,DS-7f7d9635-0eeb-4787-956d-65f970eaf257,DISK], DatanodeInfoWithStorage[127.0.0.1:46615,DS-8f76c165-eead-4e3a-97f0-1b0e6630d03e,DISK], DatanodeInfoWithStorage[127.0.0.1:33769,DS-223667b4-313e-4da3-9e0f-1a73e21ecb87,DISK], DatanodeInfoWithStorage[127.0.0.1:38924,DS-508e9016-28ec-43c9-817a-941959683428,DISK], DatanodeInfoWithStorage[127.0.0.1:37193,DS-410796f1-11f1-4bb4-924d-52b9d8c09d88,DISK], DatanodeInfoWithStorage[127.0.0.1:44124,DS-c94c229d-2e44-44b7-a03d-874f9378ed9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37115,DS-811631e9-1c45-4993-98ab-8f27bee51fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:34587,DS-41c9d206-343e-4397-a6f4-c4f86b521cc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 8388608
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-209931880-172.17.0.17-1597555740362:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39704,DS-0b58a26f-1316-4a40-8146-5b23a27732cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39635,DS-6eddb06c-1d8c-401d-b6ba-37f84caf35fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39726,DS-d64672d9-2e73-491b-b2fd-3a0d26ba12ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45534,DS-daeadc06-012f-4c2c-871e-1ed33718ca5a,DISK], DatanodeInfoWithStorage[127.0.0.1:33546,DS-45e01404-2466-455e-afdd-800f98274b65,DISK], DatanodeInfoWithStorage[127.0.0.1:43399,DS-f95be00c-f4ae-4358-9e76-be7fee00547c,DISK], DatanodeInfoWithStorage[127.0.0.1:45789,DS-4162268e-985b-4d8d-ab81-177ff0800018,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-338acf8f-657c-4abf-8b55-7dffbc805fdb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-209931880-172.17.0.17-1597555740362:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39704,DS-0b58a26f-1316-4a40-8146-5b23a27732cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39635,DS-6eddb06c-1d8c-401d-b6ba-37f84caf35fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39726,DS-d64672d9-2e73-491b-b2fd-3a0d26ba12ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45534,DS-daeadc06-012f-4c2c-871e-1ed33718ca5a,DISK], DatanodeInfoWithStorage[127.0.0.1:33546,DS-45e01404-2466-455e-afdd-800f98274b65,DISK], DatanodeInfoWithStorage[127.0.0.1:43399,DS-f95be00c-f4ae-4358-9e76-be7fee00547c,DISK], DatanodeInfoWithStorage[127.0.0.1:45789,DS-4162268e-985b-4d8d-ab81-177ff0800018,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-338acf8f-657c-4abf-8b55-7dffbc805fdb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 8388608
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-362512478-172.17.0.17-1597555967031:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39532,DS-2a6b175b-6d73-4a16-a2bd-a118e218c151,DISK], DatanodeInfoWithStorage[127.0.0.1:34373,DS-ce11b419-884f-40b8-b98e-e9b4fc5b25e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40199,DS-d01ef820-21f0-4378-a3f9-b0120b5c876e,DISK], DatanodeInfoWithStorage[127.0.0.1:35453,DS-9394fa4a-0b71-4f2f-a980-058e545a9e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:46841,DS-cb5c880d-a990-4778-ae00-22cec98aeb1b,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-6456a0ea-0fdd-47e6-97b0-23039a62a8ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42218,DS-a1ed5539-5763-457e-a363-f0631027d80e,DISK], DatanodeInfoWithStorage[127.0.0.1:39219,DS-bdf49b92-b3ed-4898-8488-6fe832366905,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-362512478-172.17.0.17-1597555967031:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39532,DS-2a6b175b-6d73-4a16-a2bd-a118e218c151,DISK], DatanodeInfoWithStorage[127.0.0.1:34373,DS-ce11b419-884f-40b8-b98e-e9b4fc5b25e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40199,DS-d01ef820-21f0-4378-a3f9-b0120b5c876e,DISK], DatanodeInfoWithStorage[127.0.0.1:35453,DS-9394fa4a-0b71-4f2f-a980-058e545a9e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:46841,DS-cb5c880d-a990-4778-ae00-22cec98aeb1b,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-6456a0ea-0fdd-47e6-97b0-23039a62a8ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42218,DS-a1ed5539-5763-457e-a363-f0631027d80e,DISK], DatanodeInfoWithStorage[127.0.0.1:39219,DS-bdf49b92-b3ed-4898-8488-6fe832366905,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 8388608
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1542763324-172.17.0.17-1597556224067:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34261,DS-db6001c7-ecd0-4619-b927-421855b24de7,DISK], DatanodeInfoWithStorage[127.0.0.1:36140,DS-52aed4b3-dcf8-42ca-a552-8a1f0ddeb96d,DISK], DatanodeInfoWithStorage[127.0.0.1:38113,DS-0424d643-b027-4c25-8d5d-c6de6d75cd3b,DISK], DatanodeInfoWithStorage[127.0.0.1:36961,DS-2335f117-9739-4d93-ae52-ca7fcfc6e08e,DISK], DatanodeInfoWithStorage[127.0.0.1:38125,DS-40c81df0-17c7-45f6-8623-9132077c9ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:33398,DS-d9992dbb-e0b7-4ee3-8836-5d00db1715d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35245,DS-bfa3b2b0-7238-43d8-91f9-99f9b060daa9,DISK], DatanodeInfoWithStorage[127.0.0.1:39580,DS-52132e6a-ce8b-47f4-911d-8a47e21723bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1542763324-172.17.0.17-1597556224067:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34261,DS-db6001c7-ecd0-4619-b927-421855b24de7,DISK], DatanodeInfoWithStorage[127.0.0.1:36140,DS-52aed4b3-dcf8-42ca-a552-8a1f0ddeb96d,DISK], DatanodeInfoWithStorage[127.0.0.1:38113,DS-0424d643-b027-4c25-8d5d-c6de6d75cd3b,DISK], DatanodeInfoWithStorage[127.0.0.1:36961,DS-2335f117-9739-4d93-ae52-ca7fcfc6e08e,DISK], DatanodeInfoWithStorage[127.0.0.1:38125,DS-40c81df0-17c7-45f6-8623-9132077c9ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:33398,DS-d9992dbb-e0b7-4ee3-8836-5d00db1715d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35245,DS-bfa3b2b0-7238-43d8-91f9-99f9b060daa9,DISK], DatanodeInfoWithStorage[127.0.0.1:39580,DS-52132e6a-ce8b-47f4-911d-8a47e21723bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 8388608
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-464623620-172.17.0.17-1597556774611:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40318,DS-947c0a36-f976-4991-8111-e0a1cb962a56,DISK], DatanodeInfoWithStorage[127.0.0.1:37593,DS-a8d643c0-79ff-42d8-be48-51420d63954d,DISK], DatanodeInfoWithStorage[127.0.0.1:38116,DS-654ae788-2978-4091-ac70-839326053a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-1e27250d-ed0a-456a-9c90-4bd12808fbf9,DISK], DatanodeInfoWithStorage[127.0.0.1:46302,DS-1f252d65-5fd5-4f0a-a461-8ef5fc687a39,DISK], DatanodeInfoWithStorage[127.0.0.1:36831,DS-ff4244c7-d634-40b5-871d-0e8bcd1f38da,DISK], DatanodeInfoWithStorage[127.0.0.1:45593,DS-cc303b4a-8f11-449c-a41b-08a4b39d2b02,DISK], DatanodeInfoWithStorage[127.0.0.1:42880,DS-16027b58-c6dd-4c18-92f1-9089af11fc1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-464623620-172.17.0.17-1597556774611:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40318,DS-947c0a36-f976-4991-8111-e0a1cb962a56,DISK], DatanodeInfoWithStorage[127.0.0.1:37593,DS-a8d643c0-79ff-42d8-be48-51420d63954d,DISK], DatanodeInfoWithStorage[127.0.0.1:38116,DS-654ae788-2978-4091-ac70-839326053a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-1e27250d-ed0a-456a-9c90-4bd12808fbf9,DISK], DatanodeInfoWithStorage[127.0.0.1:46302,DS-1f252d65-5fd5-4f0a-a461-8ef5fc687a39,DISK], DatanodeInfoWithStorage[127.0.0.1:36831,DS-ff4244c7-d634-40b5-871d-0e8bcd1f38da,DISK], DatanodeInfoWithStorage[127.0.0.1:45593,DS-cc303b4a-8f11-449c-a41b-08a4b39d2b02,DISK], DatanodeInfoWithStorage[127.0.0.1:42880,DS-16027b58-c6dd-4c18-92f1-9089af11fc1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 8388608
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1451086594-172.17.0.17-1597556961053:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34358,DS-68ea6051-c7bd-4060-b7cb-fa94ff502245,DISK], DatanodeInfoWithStorage[127.0.0.1:42054,DS-9925ec62-d02a-4078-a7d8-b0eb5422f57b,DISK], DatanodeInfoWithStorage[127.0.0.1:36553,DS-c6d119b1-53ad-45bc-abb3-42060d9b077f,DISK], DatanodeInfoWithStorage[127.0.0.1:34307,DS-1d783cb3-a7ba-400a-a489-ab5315fa4392,DISK], DatanodeInfoWithStorage[127.0.0.1:35804,DS-4d6b7904-5b1b-4616-b1c4-7a1393f068c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46492,DS-49f75281-f53d-4bf2-b73a-f101f2954dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:33856,DS-442fb8f7-bbde-4190-90cd-cfeae773830a,DISK], DatanodeInfoWithStorage[127.0.0.1:42686,DS-ee0d9c92-9557-4111-bc9f-1575642b8bbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1451086594-172.17.0.17-1597556961053:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34358,DS-68ea6051-c7bd-4060-b7cb-fa94ff502245,DISK], DatanodeInfoWithStorage[127.0.0.1:42054,DS-9925ec62-d02a-4078-a7d8-b0eb5422f57b,DISK], DatanodeInfoWithStorage[127.0.0.1:36553,DS-c6d119b1-53ad-45bc-abb3-42060d9b077f,DISK], DatanodeInfoWithStorage[127.0.0.1:34307,DS-1d783cb3-a7ba-400a-a489-ab5315fa4392,DISK], DatanodeInfoWithStorage[127.0.0.1:35804,DS-4d6b7904-5b1b-4616-b1c4-7a1393f068c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46492,DS-49f75281-f53d-4bf2-b73a-f101f2954dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:33856,DS-442fb8f7-bbde-4190-90cd-cfeae773830a,DISK], DatanodeInfoWithStorage[127.0.0.1:42686,DS-ee0d9c92-9557-4111-bc9f-1575642b8bbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 8388608
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1939772498-172.17.0.17-1597557315496:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35295,DS-f7a638bd-929d-4f19-b47e-fb45c2017bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:35247,DS-4b9d1543-c774-4aaf-aef1-d239baff3015,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-6a0dbad7-46d2-4bef-9c32-bc3ee54c1932,DISK], DatanodeInfoWithStorage[127.0.0.1:39884,DS-d0c0d0f8-b008-422d-9a53-354d8e01229d,DISK], DatanodeInfoWithStorage[127.0.0.1:41300,DS-96f4959c-0471-409b-b37a-3fd43101ecec,DISK], DatanodeInfoWithStorage[127.0.0.1:34095,DS-68875c7f-8387-4778-9090-60593b97c755,DISK], DatanodeInfoWithStorage[127.0.0.1:42204,DS-faf7c2fe-ec36-4e42-a1ec-d73333046c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:41020,DS-ab10f36a-c644-4849-86b6-b3ad37c24357,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1939772498-172.17.0.17-1597557315496:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35295,DS-f7a638bd-929d-4f19-b47e-fb45c2017bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:35247,DS-4b9d1543-c774-4aaf-aef1-d239baff3015,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-6a0dbad7-46d2-4bef-9c32-bc3ee54c1932,DISK], DatanodeInfoWithStorage[127.0.0.1:39884,DS-d0c0d0f8-b008-422d-9a53-354d8e01229d,DISK], DatanodeInfoWithStorage[127.0.0.1:41300,DS-96f4959c-0471-409b-b37a-3fd43101ecec,DISK], DatanodeInfoWithStorage[127.0.0.1:34095,DS-68875c7f-8387-4778-9090-60593b97c755,DISK], DatanodeInfoWithStorage[127.0.0.1:42204,DS-faf7c2fe-ec36-4e42-a1ec-d73333046c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:41020,DS-ab10f36a-c644-4849-86b6-b3ad37c24357,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 8388608
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1239368796-172.17.0.17-1597557847134:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36103,DS-2684d4fe-6f73-44fe-8c24-59206b61b762,DISK], DatanodeInfoWithStorage[127.0.0.1:34287,DS-bbabfb6c-8469-42d4-bfb5-8edbd9f28864,DISK], DatanodeInfoWithStorage[127.0.0.1:38507,DS-8cdb5a3f-cdbd-49fd-8829-6886a1eb8188,DISK], DatanodeInfoWithStorage[127.0.0.1:43700,DS-b3871482-4d60-4d98-b174-1dde1f5ab5db,DISK], DatanodeInfoWithStorage[127.0.0.1:41158,DS-7abf1688-c496-4489-8081-d2ac51c8b19a,DISK], DatanodeInfoWithStorage[127.0.0.1:42497,DS-33612576-d874-4825-ac33-dbe36e0a783c,DISK], DatanodeInfoWithStorage[127.0.0.1:39118,DS-be23320c-b574-4aad-88b5-00d57b90c756,DISK], DatanodeInfoWithStorage[127.0.0.1:38573,DS-b9756c7f-9e6e-4c15-8f8f-82a25e5226dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1239368796-172.17.0.17-1597557847134:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36103,DS-2684d4fe-6f73-44fe-8c24-59206b61b762,DISK], DatanodeInfoWithStorage[127.0.0.1:34287,DS-bbabfb6c-8469-42d4-bfb5-8edbd9f28864,DISK], DatanodeInfoWithStorage[127.0.0.1:38507,DS-8cdb5a3f-cdbd-49fd-8829-6886a1eb8188,DISK], DatanodeInfoWithStorage[127.0.0.1:43700,DS-b3871482-4d60-4d98-b174-1dde1f5ab5db,DISK], DatanodeInfoWithStorage[127.0.0.1:41158,DS-7abf1688-c496-4489-8081-d2ac51c8b19a,DISK], DatanodeInfoWithStorage[127.0.0.1:42497,DS-33612576-d874-4825-ac33-dbe36e0a783c,DISK], DatanodeInfoWithStorage[127.0.0.1:39118,DS-be23320c-b574-4aad-88b5-00d57b90c756,DISK], DatanodeInfoWithStorage[127.0.0.1:38573,DS-b9756c7f-9e6e-4c15-8f8f-82a25e5226dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 8388608
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-688455020-172.17.0.17-1597558366037:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44724,DS-6ee8ed9b-7063-438d-8fb2-870b4c9bc9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45079,DS-97808b90-d861-4305-9ec1-82c2a59668e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43465,DS-bba1516b-ff00-4d87-92be-b1c9c38f4450,DISK], DatanodeInfoWithStorage[127.0.0.1:45939,DS-e67e93b5-c7b9-462e-a522-eb7badd55827,DISK], DatanodeInfoWithStorage[127.0.0.1:36922,DS-808a6b09-e4ec-43ea-a20a-dddc0176256c,DISK], DatanodeInfoWithStorage[127.0.0.1:34668,DS-42b5c94d-7803-49ec-b8ca-a2d8325bd390,DISK], DatanodeInfoWithStorage[127.0.0.1:36826,DS-52356e97-956d-4cd2-984d-f1cd460bdf7c,DISK], DatanodeInfoWithStorage[127.0.0.1:45480,DS-a5eb1431-0704-415d-8305-1bfb04c2426e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-688455020-172.17.0.17-1597558366037:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44724,DS-6ee8ed9b-7063-438d-8fb2-870b4c9bc9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45079,DS-97808b90-d861-4305-9ec1-82c2a59668e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43465,DS-bba1516b-ff00-4d87-92be-b1c9c38f4450,DISK], DatanodeInfoWithStorage[127.0.0.1:45939,DS-e67e93b5-c7b9-462e-a522-eb7badd55827,DISK], DatanodeInfoWithStorage[127.0.0.1:36922,DS-808a6b09-e4ec-43ea-a20a-dddc0176256c,DISK], DatanodeInfoWithStorage[127.0.0.1:34668,DS-42b5c94d-7803-49ec-b8ca-a2d8325bd390,DISK], DatanodeInfoWithStorage[127.0.0.1:36826,DS-52356e97-956d-4cd2-984d-f1cd460bdf7c,DISK], DatanodeInfoWithStorage[127.0.0.1:45480,DS-a5eb1431-0704-415d-8305-1bfb04c2426e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 8388608
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1290442563-172.17.0.17-1597558475195:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37130,DS-3257eb3c-e65c-4a7a-9d34-521049aea42c,DISK], DatanodeInfoWithStorage[127.0.0.1:38209,DS-5864b363-57ae-446f-a70a-e9b1db475492,DISK], DatanodeInfoWithStorage[127.0.0.1:43179,DS-9bcbd875-6945-4e26-99b8-af224c63b4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43978,DS-87b34b50-6d0b-4a08-a01f-f4ec3757802f,DISK], DatanodeInfoWithStorage[127.0.0.1:40209,DS-0dea7e2a-33ea-4aaf-bfa6-a33aaa426914,DISK], DatanodeInfoWithStorage[127.0.0.1:41206,DS-08d38bac-4c7a-4fc9-a7b0-ee0b9fb449c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34511,DS-53c00ba8-4bb8-4cfd-87bc-da9d45ab374b,DISK], DatanodeInfoWithStorage[127.0.0.1:35460,DS-5f040d40-656f-4ca4-bb13-4414c1ef669e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1290442563-172.17.0.17-1597558475195:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37130,DS-3257eb3c-e65c-4a7a-9d34-521049aea42c,DISK], DatanodeInfoWithStorage[127.0.0.1:38209,DS-5864b363-57ae-446f-a70a-e9b1db475492,DISK], DatanodeInfoWithStorage[127.0.0.1:43179,DS-9bcbd875-6945-4e26-99b8-af224c63b4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43978,DS-87b34b50-6d0b-4a08-a01f-f4ec3757802f,DISK], DatanodeInfoWithStorage[127.0.0.1:40209,DS-0dea7e2a-33ea-4aaf-bfa6-a33aaa426914,DISK], DatanodeInfoWithStorage[127.0.0.1:41206,DS-08d38bac-4c7a-4fc9-a7b0-ee0b9fb449c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34511,DS-53c00ba8-4bb8-4cfd-87bc-da9d45ab374b,DISK], DatanodeInfoWithStorage[127.0.0.1:35460,DS-5f040d40-656f-4ca4-bb13-4414c1ef669e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 8388608
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-246017719-172.17.0.17-1597558774495:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33850,DS-93db9839-6cc7-4f83-9a60-e277bd35e716,DISK], DatanodeInfoWithStorage[127.0.0.1:38707,DS-3173390f-c619-4ca9-ba6f-5f5f73869428,DISK], DatanodeInfoWithStorage[127.0.0.1:37616,DS-f8d955ec-2440-404c-8ff9-6bfebe165776,DISK], DatanodeInfoWithStorage[127.0.0.1:45425,DS-03e1c711-d2da-4a9a-8737-54f29c0fccdf,DISK], DatanodeInfoWithStorage[127.0.0.1:42066,DS-361364c3-6c78-4c32-8f48-6cf3e34af33e,DISK], DatanodeInfoWithStorage[127.0.0.1:35096,DS-91fb8dcf-be28-4e50-9b95-8420177548fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42619,DS-29c0527f-07b0-41da-bbc7-45c5dbe43c23,DISK], DatanodeInfoWithStorage[127.0.0.1:35149,DS-62d30535-56aa-4001-aa83-7cd5087a6544,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-246017719-172.17.0.17-1597558774495:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33850,DS-93db9839-6cc7-4f83-9a60-e277bd35e716,DISK], DatanodeInfoWithStorage[127.0.0.1:38707,DS-3173390f-c619-4ca9-ba6f-5f5f73869428,DISK], DatanodeInfoWithStorage[127.0.0.1:37616,DS-f8d955ec-2440-404c-8ff9-6bfebe165776,DISK], DatanodeInfoWithStorage[127.0.0.1:45425,DS-03e1c711-d2da-4a9a-8737-54f29c0fccdf,DISK], DatanodeInfoWithStorage[127.0.0.1:42066,DS-361364c3-6c78-4c32-8f48-6cf3e34af33e,DISK], DatanodeInfoWithStorage[127.0.0.1:35096,DS-91fb8dcf-be28-4e50-9b95-8420177548fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42619,DS-29c0527f-07b0-41da-bbc7-45c5dbe43c23,DISK], DatanodeInfoWithStorage[127.0.0.1:35149,DS-62d30535-56aa-4001-aa83-7cd5087a6544,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5556
