reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-87721864-172.17.0.13-1597561949627:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39987,DS-543de9f4-8c12-4929-8f1a-7e867e82e9a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37610,DS-3865f72b-7ad2-4cb0-8a43-eaef895950dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37911,DS-bd9576b5-ccf4-428a-9d01-b812aad87a03,DISK], DatanodeInfoWithStorage[127.0.0.1:38534,DS-534c068e-a061-401c-872d-7a0cdfa37566,DISK], DatanodeInfoWithStorage[127.0.0.1:33113,DS-1975c55c-c982-4a5b-8d34-33d7866ba5ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41472,DS-ed9db896-5ad4-48a7-a869-f50419b92664,DISK], DatanodeInfoWithStorage[127.0.0.1:40712,DS-3fe03d12-3311-473c-9c5c-bfb4ddece328,DISK], DatanodeInfoWithStorage[127.0.0.1:33405,DS-0c9fd824-16ec-425e-ab05-04f2d7ee98fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-87721864-172.17.0.13-1597561949627:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39987,DS-543de9f4-8c12-4929-8f1a-7e867e82e9a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37610,DS-3865f72b-7ad2-4cb0-8a43-eaef895950dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37911,DS-bd9576b5-ccf4-428a-9d01-b812aad87a03,DISK], DatanodeInfoWithStorage[127.0.0.1:38534,DS-534c068e-a061-401c-872d-7a0cdfa37566,DISK], DatanodeInfoWithStorage[127.0.0.1:33113,DS-1975c55c-c982-4a5b-8d34-33d7866ba5ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41472,DS-ed9db896-5ad4-48a7-a869-f50419b92664,DISK], DatanodeInfoWithStorage[127.0.0.1:40712,DS-3fe03d12-3311-473c-9c5c-bfb4ddece328,DISK], DatanodeInfoWithStorage[127.0.0.1:33405,DS-0c9fd824-16ec-425e-ab05-04f2d7ee98fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1404110973-172.17.0.13-1597562116406:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44849,DS-a93f85a0-5b45-4c77-95e1-9ef913012736,DISK], DatanodeInfoWithStorage[127.0.0.1:40850,DS-d07dbabb-def6-413c-bcf1-f839d087fb75,DISK], DatanodeInfoWithStorage[127.0.0.1:42153,DS-1a33e291-38f4-49ea-9076-e614fb4fc47d,DISK], DatanodeInfoWithStorage[127.0.0.1:39237,DS-5f029e8e-578c-4fc5-a3ca-22c821dcdbdf,DISK], DatanodeInfoWithStorage[127.0.0.1:46404,DS-4e5991c8-bae2-4090-86b1-c0d534a668fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46437,DS-f564829e-6eb8-4759-8743-3ae1a5abc6f8,DISK], DatanodeInfoWithStorage[127.0.0.1:32888,DS-627b558c-f8e2-4a11-a91b-e24dd9d4d40a,DISK], DatanodeInfoWithStorage[127.0.0.1:33248,DS-4ec67f53-c1be-4bc0-891c-dc4351edbb87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1404110973-172.17.0.13-1597562116406:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44849,DS-a93f85a0-5b45-4c77-95e1-9ef913012736,DISK], DatanodeInfoWithStorage[127.0.0.1:40850,DS-d07dbabb-def6-413c-bcf1-f839d087fb75,DISK], DatanodeInfoWithStorage[127.0.0.1:42153,DS-1a33e291-38f4-49ea-9076-e614fb4fc47d,DISK], DatanodeInfoWithStorage[127.0.0.1:39237,DS-5f029e8e-578c-4fc5-a3ca-22c821dcdbdf,DISK], DatanodeInfoWithStorage[127.0.0.1:46404,DS-4e5991c8-bae2-4090-86b1-c0d534a668fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46437,DS-f564829e-6eb8-4759-8743-3ae1a5abc6f8,DISK], DatanodeInfoWithStorage[127.0.0.1:32888,DS-627b558c-f8e2-4a11-a91b-e24dd9d4d40a,DISK], DatanodeInfoWithStorage[127.0.0.1:33248,DS-4ec67f53-c1be-4bc0-891c-dc4351edbb87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-519788679-172.17.0.13-1597562922915:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34688,DS-e285adcd-7a31-4e99-b6e2-afc5f4e0e3c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35492,DS-13d58971-11bb-473c-b62a-98253670921f,DISK], DatanodeInfoWithStorage[127.0.0.1:33154,DS-4f721298-275b-42e7-8e1c-db0a797fdc02,DISK], DatanodeInfoWithStorage[127.0.0.1:44645,DS-2703db1f-d3f1-416b-bbe2-2283e941159b,DISK], DatanodeInfoWithStorage[127.0.0.1:44548,DS-bb23c576-b6bd-44fc-8d28-e4d5fc036966,DISK], DatanodeInfoWithStorage[127.0.0.1:34587,DS-483228a0-de22-4396-b302-e76183ee88aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44163,DS-7e6065a1-f42d-4d0a-abf5-ae42f0b09e52,DISK], DatanodeInfoWithStorage[127.0.0.1:45481,DS-ec8bfbea-e7c0-42ab-a0b8-76d017ef9286,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-519788679-172.17.0.13-1597562922915:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34688,DS-e285adcd-7a31-4e99-b6e2-afc5f4e0e3c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35492,DS-13d58971-11bb-473c-b62a-98253670921f,DISK], DatanodeInfoWithStorage[127.0.0.1:33154,DS-4f721298-275b-42e7-8e1c-db0a797fdc02,DISK], DatanodeInfoWithStorage[127.0.0.1:44645,DS-2703db1f-d3f1-416b-bbe2-2283e941159b,DISK], DatanodeInfoWithStorage[127.0.0.1:44548,DS-bb23c576-b6bd-44fc-8d28-e4d5fc036966,DISK], DatanodeInfoWithStorage[127.0.0.1:34587,DS-483228a0-de22-4396-b302-e76183ee88aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44163,DS-7e6065a1-f42d-4d0a-abf5-ae42f0b09e52,DISK], DatanodeInfoWithStorage[127.0.0.1:45481,DS-ec8bfbea-e7c0-42ab-a0b8-76d017ef9286,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1040971090-172.17.0.13-1597563434885:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36080,DS-5ef10c0f-adcc-4014-929c-a290d8f33786,DISK], DatanodeInfoWithStorage[127.0.0.1:36321,DS-4b4ec955-1395-48a9-b636-9bae3afab056,DISK], DatanodeInfoWithStorage[127.0.0.1:34664,DS-722430f2-e954-45ae-9cf1-fb1ac1cc5160,DISK], DatanodeInfoWithStorage[127.0.0.1:46564,DS-56272120-1fea-4075-b822-1357515adad1,DISK], DatanodeInfoWithStorage[127.0.0.1:45378,DS-551005fa-78a4-4741-8125-511abe8b3b78,DISK], DatanodeInfoWithStorage[127.0.0.1:45365,DS-bbe5dc84-34bb-4257-adc2-2606b318e87d,DISK], DatanodeInfoWithStorage[127.0.0.1:46336,DS-d26a09af-2f90-4e36-b3ce-45d92f48e92d,DISK], DatanodeInfoWithStorage[127.0.0.1:34738,DS-a1a15746-a1f0-4439-9474-bc6796d1887c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1040971090-172.17.0.13-1597563434885:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36080,DS-5ef10c0f-adcc-4014-929c-a290d8f33786,DISK], DatanodeInfoWithStorage[127.0.0.1:36321,DS-4b4ec955-1395-48a9-b636-9bae3afab056,DISK], DatanodeInfoWithStorage[127.0.0.1:34664,DS-722430f2-e954-45ae-9cf1-fb1ac1cc5160,DISK], DatanodeInfoWithStorage[127.0.0.1:46564,DS-56272120-1fea-4075-b822-1357515adad1,DISK], DatanodeInfoWithStorage[127.0.0.1:45378,DS-551005fa-78a4-4741-8125-511abe8b3b78,DISK], DatanodeInfoWithStorage[127.0.0.1:45365,DS-bbe5dc84-34bb-4257-adc2-2606b318e87d,DISK], DatanodeInfoWithStorage[127.0.0.1:46336,DS-d26a09af-2f90-4e36-b3ce-45d92f48e92d,DISK], DatanodeInfoWithStorage[127.0.0.1:34738,DS-a1a15746-a1f0-4439-9474-bc6796d1887c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1343006882-172.17.0.13-1597563946997:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39865,DS-60a38e47-52cb-4c29-8d72-ccdaccfa69a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40758,DS-1984bb87-0113-4c6d-94ce-ce1b7fd2664d,DISK], DatanodeInfoWithStorage[127.0.0.1:41067,DS-3b604c75-fb72-4fc5-a996-163503e2dad6,DISK], DatanodeInfoWithStorage[127.0.0.1:34339,DS-4a526b07-58ae-4e62-adf7-3a13c915e711,DISK], DatanodeInfoWithStorage[127.0.0.1:38090,DS-8ff7fe92-e11d-4dc9-855d-f332e5c3e17e,DISK], DatanodeInfoWithStorage[127.0.0.1:36917,DS-08d8ab9c-dd85-45cb-a9d8-a3acd609622c,DISK], DatanodeInfoWithStorage[127.0.0.1:41880,DS-11b1b55e-6fe2-4c57-bca8-79a448109237,DISK], DatanodeInfoWithStorage[127.0.0.1:33380,DS-34d70261-e0b3-425e-a483-e6f6c501a69c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1343006882-172.17.0.13-1597563946997:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39865,DS-60a38e47-52cb-4c29-8d72-ccdaccfa69a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40758,DS-1984bb87-0113-4c6d-94ce-ce1b7fd2664d,DISK], DatanodeInfoWithStorage[127.0.0.1:41067,DS-3b604c75-fb72-4fc5-a996-163503e2dad6,DISK], DatanodeInfoWithStorage[127.0.0.1:34339,DS-4a526b07-58ae-4e62-adf7-3a13c915e711,DISK], DatanodeInfoWithStorage[127.0.0.1:38090,DS-8ff7fe92-e11d-4dc9-855d-f332e5c3e17e,DISK], DatanodeInfoWithStorage[127.0.0.1:36917,DS-08d8ab9c-dd85-45cb-a9d8-a3acd609622c,DISK], DatanodeInfoWithStorage[127.0.0.1:41880,DS-11b1b55e-6fe2-4c57-bca8-79a448109237,DISK], DatanodeInfoWithStorage[127.0.0.1:33380,DS-34d70261-e0b3-425e-a483-e6f6c501a69c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1142058608-172.17.0.13-1597564054678:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35364,DS-e6609d22-0990-448d-9fbc-2650f2ea9342,DISK], DatanodeInfoWithStorage[127.0.0.1:40557,DS-4dc9728f-e589-4075-917e-5bdd251c201a,DISK], DatanodeInfoWithStorage[127.0.0.1:34687,DS-1273c173-c866-4c56-9ee0-ebcc11b5b43a,DISK], DatanodeInfoWithStorage[127.0.0.1:36449,DS-cd82ab63-950a-4434-9563-5c8cc10a1cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:41946,DS-c3efb47c-fc1f-4a30-85ef-8662779e3174,DISK], DatanodeInfoWithStorage[127.0.0.1:34392,DS-f70f4e94-e3ef-46a4-abd8-3bb55ec04a73,DISK], DatanodeInfoWithStorage[127.0.0.1:33643,DS-e102c5f0-4d82-4219-85b9-15310e586727,DISK], DatanodeInfoWithStorage[127.0.0.1:37114,DS-439a6fde-b24f-4e6a-abb4-1fe3dc3f028e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1142058608-172.17.0.13-1597564054678:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35364,DS-e6609d22-0990-448d-9fbc-2650f2ea9342,DISK], DatanodeInfoWithStorage[127.0.0.1:40557,DS-4dc9728f-e589-4075-917e-5bdd251c201a,DISK], DatanodeInfoWithStorage[127.0.0.1:34687,DS-1273c173-c866-4c56-9ee0-ebcc11b5b43a,DISK], DatanodeInfoWithStorage[127.0.0.1:36449,DS-cd82ab63-950a-4434-9563-5c8cc10a1cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:41946,DS-c3efb47c-fc1f-4a30-85ef-8662779e3174,DISK], DatanodeInfoWithStorage[127.0.0.1:34392,DS-f70f4e94-e3ef-46a4-abd8-3bb55ec04a73,DISK], DatanodeInfoWithStorage[127.0.0.1:33643,DS-e102c5f0-4d82-4219-85b9-15310e586727,DISK], DatanodeInfoWithStorage[127.0.0.1:37114,DS-439a6fde-b24f-4e6a-abb4-1fe3dc3f028e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-950045742-172.17.0.13-1597564881579:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42002,DS-b01d222c-85f9-4a17-a496-4589ffd30c23,DISK], DatanodeInfoWithStorage[127.0.0.1:46016,DS-11b40080-d255-42d1-8365-6b7069ec69bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38276,DS-8ea01d67-8179-430a-a29f-1804a4894c72,DISK], DatanodeInfoWithStorage[127.0.0.1:44973,DS-16b84dd4-96ef-40be-bffd-d1cdcc248524,DISK], DatanodeInfoWithStorage[127.0.0.1:39561,DS-1079056f-d191-4b15-a387-f41159083324,DISK], DatanodeInfoWithStorage[127.0.0.1:34172,DS-617f3cb7-fa48-437b-8842-75ce4be84f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:34546,DS-d4902d8e-eb98-4636-8b2f-b2eb67a6f6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41516,DS-4e39660b-8b28-46a7-a369-6cceec73b0c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-950045742-172.17.0.13-1597564881579:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42002,DS-b01d222c-85f9-4a17-a496-4589ffd30c23,DISK], DatanodeInfoWithStorage[127.0.0.1:46016,DS-11b40080-d255-42d1-8365-6b7069ec69bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38276,DS-8ea01d67-8179-430a-a29f-1804a4894c72,DISK], DatanodeInfoWithStorage[127.0.0.1:44973,DS-16b84dd4-96ef-40be-bffd-d1cdcc248524,DISK], DatanodeInfoWithStorage[127.0.0.1:39561,DS-1079056f-d191-4b15-a387-f41159083324,DISK], DatanodeInfoWithStorage[127.0.0.1:34172,DS-617f3cb7-fa48-437b-8842-75ce4be84f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:34546,DS-d4902d8e-eb98-4636-8b2f-b2eb67a6f6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41516,DS-4e39660b-8b28-46a7-a369-6cceec73b0c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-213749398-172.17.0.13-1597565178230:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46030,DS-51491366-8f4f-46ac-a581-db8c39f9e588,DISK], DatanodeInfoWithStorage[127.0.0.1:42760,DS-ca651c77-c3e8-4ac8-8cd9-ccf62a2d050f,DISK], DatanodeInfoWithStorage[127.0.0.1:38105,DS-f1f95544-3487-4432-ac0c-0d0ff2d4dd43,DISK], DatanodeInfoWithStorage[127.0.0.1:36648,DS-f6890dc0-f0eb-4ba5-a213-f5be3424156f,DISK], DatanodeInfoWithStorage[127.0.0.1:38544,DS-22ac69a6-6484-46ba-99ba-4479813a9448,DISK], DatanodeInfoWithStorage[127.0.0.1:40619,DS-9ed5353e-b107-418c-b740-c07436efada5,DISK], DatanodeInfoWithStorage[127.0.0.1:35728,DS-5ecfdab2-e88f-4410-8400-af93ad1e161d,DISK], DatanodeInfoWithStorage[127.0.0.1:36472,DS-1152a72a-74ae-4514-815a-36f6b3b98030,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-213749398-172.17.0.13-1597565178230:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46030,DS-51491366-8f4f-46ac-a581-db8c39f9e588,DISK], DatanodeInfoWithStorage[127.0.0.1:42760,DS-ca651c77-c3e8-4ac8-8cd9-ccf62a2d050f,DISK], DatanodeInfoWithStorage[127.0.0.1:38105,DS-f1f95544-3487-4432-ac0c-0d0ff2d4dd43,DISK], DatanodeInfoWithStorage[127.0.0.1:36648,DS-f6890dc0-f0eb-4ba5-a213-f5be3424156f,DISK], DatanodeInfoWithStorage[127.0.0.1:38544,DS-22ac69a6-6484-46ba-99ba-4479813a9448,DISK], DatanodeInfoWithStorage[127.0.0.1:40619,DS-9ed5353e-b107-418c-b740-c07436efada5,DISK], DatanodeInfoWithStorage[127.0.0.1:35728,DS-5ecfdab2-e88f-4410-8400-af93ad1e161d,DISK], DatanodeInfoWithStorage[127.0.0.1:36472,DS-1152a72a-74ae-4514-815a-36f6b3b98030,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1100894646-172.17.0.13-1597565214511:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41020,DS-ed1dc51b-9fba-4249-8803-fab46568fd1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35818,DS-cfefdf3c-aea8-4912-954f-e274339fc0b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34652,DS-977f6978-2cbc-4457-9a56-aea150a123b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33428,DS-7e8a7368-1ade-4275-bac0-9de5ab7fa0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33506,DS-beb479ff-a27d-4e8d-9a58-1f6c386607d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35514,DS-21c44b00-7425-4f2f-9a20-3631750ca4ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38226,DS-637114c4-202e-4776-85d5-a8f03257f139,DISK], DatanodeInfoWithStorage[127.0.0.1:45702,DS-e40328c6-c32e-4b5e-9643-8ad6464613cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1100894646-172.17.0.13-1597565214511:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41020,DS-ed1dc51b-9fba-4249-8803-fab46568fd1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35818,DS-cfefdf3c-aea8-4912-954f-e274339fc0b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34652,DS-977f6978-2cbc-4457-9a56-aea150a123b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33428,DS-7e8a7368-1ade-4275-bac0-9de5ab7fa0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33506,DS-beb479ff-a27d-4e8d-9a58-1f6c386607d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35514,DS-21c44b00-7425-4f2f-9a20-3631750ca4ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38226,DS-637114c4-202e-4776-85d5-a8f03257f139,DISK], DatanodeInfoWithStorage[127.0.0.1:45702,DS-e40328c6-c32e-4b5e-9643-8ad6464613cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-510239433-172.17.0.13-1597565426978:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44305,DS-7bb3eaa9-6e1d-4ab3-954c-8aec9130af07,DISK], DatanodeInfoWithStorage[127.0.0.1:41444,DS-97c1330d-1c9a-4e91-beed-2726a0de03b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38754,DS-0e633a65-d796-406d-9aab-e4e841a1f5f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39428,DS-9ee59921-edc8-4d6c-9dba-cb09261a1872,DISK], DatanodeInfoWithStorage[127.0.0.1:38015,DS-52bfb286-0639-4bcd-841f-6ac1b2af1a35,DISK], DatanodeInfoWithStorage[127.0.0.1:44308,DS-dac88f32-43f9-4668-bc0f-6b6002aa1788,DISK], DatanodeInfoWithStorage[127.0.0.1:39147,DS-62a5323a-6971-4ff0-988f-747f2516742f,DISK], DatanodeInfoWithStorage[127.0.0.1:35758,DS-9d59cf95-0bf6-4c6f-887f-043356576539,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-510239433-172.17.0.13-1597565426978:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44305,DS-7bb3eaa9-6e1d-4ab3-954c-8aec9130af07,DISK], DatanodeInfoWithStorage[127.0.0.1:41444,DS-97c1330d-1c9a-4e91-beed-2726a0de03b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38754,DS-0e633a65-d796-406d-9aab-e4e841a1f5f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39428,DS-9ee59921-edc8-4d6c-9dba-cb09261a1872,DISK], DatanodeInfoWithStorage[127.0.0.1:38015,DS-52bfb286-0639-4bcd-841f-6ac1b2af1a35,DISK], DatanodeInfoWithStorage[127.0.0.1:44308,DS-dac88f32-43f9-4668-bc0f-6b6002aa1788,DISK], DatanodeInfoWithStorage[127.0.0.1:39147,DS-62a5323a-6971-4ff0-988f-747f2516742f,DISK], DatanodeInfoWithStorage[127.0.0.1:35758,DS-9d59cf95-0bf6-4c6f-887f-043356576539,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-690985839-172.17.0.13-1597565615168:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35374,DS-cf83162c-08d3-47fb-a2e1-44e4c8242d18,DISK], DatanodeInfoWithStorage[127.0.0.1:44229,DS-48d939c1-4ead-4290-b7df-1b42e3b4b13c,DISK], DatanodeInfoWithStorage[127.0.0.1:45224,DS-66325789-582d-4af7-9747-04b91509afc6,DISK], DatanodeInfoWithStorage[127.0.0.1:38596,DS-adbfdd05-617d-4d88-a98b-d57d524cfcbb,DISK], DatanodeInfoWithStorage[127.0.0.1:41147,DS-44027d35-3bfc-463e-874d-84f0b9fb5791,DISK], DatanodeInfoWithStorage[127.0.0.1:41687,DS-bb293f61-2e16-454a-8556-b7c0b9474e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:32988,DS-c62f03d0-7e2c-4bf8-82ab-ddbf97f4b60b,DISK], DatanodeInfoWithStorage[127.0.0.1:43852,DS-e8e830eb-3ce9-47d1-b46e-9f422f578c2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-690985839-172.17.0.13-1597565615168:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35374,DS-cf83162c-08d3-47fb-a2e1-44e4c8242d18,DISK], DatanodeInfoWithStorage[127.0.0.1:44229,DS-48d939c1-4ead-4290-b7df-1b42e3b4b13c,DISK], DatanodeInfoWithStorage[127.0.0.1:45224,DS-66325789-582d-4af7-9747-04b91509afc6,DISK], DatanodeInfoWithStorage[127.0.0.1:38596,DS-adbfdd05-617d-4d88-a98b-d57d524cfcbb,DISK], DatanodeInfoWithStorage[127.0.0.1:41147,DS-44027d35-3bfc-463e-874d-84f0b9fb5791,DISK], DatanodeInfoWithStorage[127.0.0.1:41687,DS-bb293f61-2e16-454a-8556-b7c0b9474e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:32988,DS-c62f03d0-7e2c-4bf8-82ab-ddbf97f4b60b,DISK], DatanodeInfoWithStorage[127.0.0.1:43852,DS-e8e830eb-3ce9-47d1-b46e-9f422f578c2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-486206481-172.17.0.13-1597565914889:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43247,DS-d10c32fc-9d10-49ff-9883-9ec8c8402278,DISK], DatanodeInfoWithStorage[127.0.0.1:33762,DS-0b94dc5f-6314-43d0-980a-de2207421876,DISK], DatanodeInfoWithStorage[127.0.0.1:37670,DS-6ee7ae41-7357-4425-8209-8050a85f2f77,DISK], DatanodeInfoWithStorage[127.0.0.1:44872,DS-b9d17deb-2c5b-4aef-ba03-b48862525fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:46739,DS-8ea8cb54-b7e3-4064-8f57-4d643519977d,DISK], DatanodeInfoWithStorage[127.0.0.1:42651,DS-8954973b-7399-4fdb-b012-7a85abd4505f,DISK], DatanodeInfoWithStorage[127.0.0.1:38676,DS-f6d85d6e-80db-4f35-80f3-1f8f74e9ee25,DISK], DatanodeInfoWithStorage[127.0.0.1:42298,DS-d341471b-b2e5-4d27-8679-80a2059326ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-486206481-172.17.0.13-1597565914889:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43247,DS-d10c32fc-9d10-49ff-9883-9ec8c8402278,DISK], DatanodeInfoWithStorage[127.0.0.1:33762,DS-0b94dc5f-6314-43d0-980a-de2207421876,DISK], DatanodeInfoWithStorage[127.0.0.1:37670,DS-6ee7ae41-7357-4425-8209-8050a85f2f77,DISK], DatanodeInfoWithStorage[127.0.0.1:44872,DS-b9d17deb-2c5b-4aef-ba03-b48862525fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:46739,DS-8ea8cb54-b7e3-4064-8f57-4d643519977d,DISK], DatanodeInfoWithStorage[127.0.0.1:42651,DS-8954973b-7399-4fdb-b012-7a85abd4505f,DISK], DatanodeInfoWithStorage[127.0.0.1:38676,DS-f6d85d6e-80db-4f35-80f3-1f8f74e9ee25,DISK], DatanodeInfoWithStorage[127.0.0.1:42298,DS-d341471b-b2e5-4d27-8679-80a2059326ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1740432450-172.17.0.13-1597565959246:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38857,DS-9074ae2a-5222-447b-a9fd-a3a0b3ec80a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36633,DS-5464c3c8-61c4-4e9f-ab4a-f10bd30f992e,DISK], DatanodeInfoWithStorage[127.0.0.1:45232,DS-7724cf07-abc8-4c8f-a8fd-4baa675bdd5d,DISK], DatanodeInfoWithStorage[127.0.0.1:45089,DS-d38e9b75-b8f2-4f5d-8b71-2d0c0af0bf89,DISK], DatanodeInfoWithStorage[127.0.0.1:41661,DS-cf4fc513-e028-4d63-b5ea-53f31ded63e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41333,DS-3bd038ee-6a09-4282-b458-bf38b3992bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:40031,DS-570161b1-af3c-47a5-bb85-e5920316d591,DISK], DatanodeInfoWithStorage[127.0.0.1:37867,DS-859cda49-7893-44b3-be6f-70e1465322df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1740432450-172.17.0.13-1597565959246:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38857,DS-9074ae2a-5222-447b-a9fd-a3a0b3ec80a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36633,DS-5464c3c8-61c4-4e9f-ab4a-f10bd30f992e,DISK], DatanodeInfoWithStorage[127.0.0.1:45232,DS-7724cf07-abc8-4c8f-a8fd-4baa675bdd5d,DISK], DatanodeInfoWithStorage[127.0.0.1:45089,DS-d38e9b75-b8f2-4f5d-8b71-2d0c0af0bf89,DISK], DatanodeInfoWithStorage[127.0.0.1:41661,DS-cf4fc513-e028-4d63-b5ea-53f31ded63e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41333,DS-3bd038ee-6a09-4282-b458-bf38b3992bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:40031,DS-570161b1-af3c-47a5-bb85-e5920316d591,DISK], DatanodeInfoWithStorage[127.0.0.1:37867,DS-859cda49-7893-44b3-be6f-70e1465322df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-269369683-172.17.0.13-1597565992100:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36832,DS-32912769-cf5f-4009-8046-0d40c165e2c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44813,DS-1b521a46-25af-4699-a5f6-86bd4c334e51,DISK], DatanodeInfoWithStorage[127.0.0.1:43764,DS-e7a0604b-36a1-4546-afef-5f59688e0899,DISK], DatanodeInfoWithStorage[127.0.0.1:42222,DS-34c94258-588a-411a-aeb3-2c34238b5ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:38414,DS-0d41d2fa-3fc9-481a-bf10-df1cf68c1ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:42195,DS-88a97871-81a4-4884-bd64-adde5944c6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44390,DS-5ab88b72-174d-49e8-8878-ed6aa5bf3308,DISK], DatanodeInfoWithStorage[127.0.0.1:40252,DS-9ab8b3e4-cdb3-4a7e-9958-3c484ebf5aa9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-269369683-172.17.0.13-1597565992100:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36832,DS-32912769-cf5f-4009-8046-0d40c165e2c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44813,DS-1b521a46-25af-4699-a5f6-86bd4c334e51,DISK], DatanodeInfoWithStorage[127.0.0.1:43764,DS-e7a0604b-36a1-4546-afef-5f59688e0899,DISK], DatanodeInfoWithStorage[127.0.0.1:42222,DS-34c94258-588a-411a-aeb3-2c34238b5ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:38414,DS-0d41d2fa-3fc9-481a-bf10-df1cf68c1ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:42195,DS-88a97871-81a4-4884-bd64-adde5944c6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44390,DS-5ab88b72-174d-49e8-8878-ed6aa5bf3308,DISK], DatanodeInfoWithStorage[127.0.0.1:40252,DS-9ab8b3e4-cdb3-4a7e-9958-3c484ebf5aa9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-549042912-172.17.0.13-1597566137815:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37514,DS-780aadb4-66b7-4416-b783-d6f11d51f00d,DISK], DatanodeInfoWithStorage[127.0.0.1:43862,DS-f0735c41-41e1-44db-8bf8-d888d0fce052,DISK], DatanodeInfoWithStorage[127.0.0.1:37089,DS-39250fb9-0093-4525-bde5-7e342c7a6f93,DISK], DatanodeInfoWithStorage[127.0.0.1:35825,DS-422b4dc3-6276-4e3a-90bb-3ce67e58eed6,DISK], DatanodeInfoWithStorage[127.0.0.1:35338,DS-055dbe25-f538-4d78-90be-a9ecc65f2741,DISK], DatanodeInfoWithStorage[127.0.0.1:33263,DS-876bcfac-5742-40f9-ba01-6e69f71382b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45298,DS-fd932459-0fe0-4ac0-a77c-396faf6be3d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36965,DS-a3f2256d-49c4-4c7e-88c3-7a0ec32c7fd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-549042912-172.17.0.13-1597566137815:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37514,DS-780aadb4-66b7-4416-b783-d6f11d51f00d,DISK], DatanodeInfoWithStorage[127.0.0.1:43862,DS-f0735c41-41e1-44db-8bf8-d888d0fce052,DISK], DatanodeInfoWithStorage[127.0.0.1:37089,DS-39250fb9-0093-4525-bde5-7e342c7a6f93,DISK], DatanodeInfoWithStorage[127.0.0.1:35825,DS-422b4dc3-6276-4e3a-90bb-3ce67e58eed6,DISK], DatanodeInfoWithStorage[127.0.0.1:35338,DS-055dbe25-f538-4d78-90be-a9ecc65f2741,DISK], DatanodeInfoWithStorage[127.0.0.1:33263,DS-876bcfac-5742-40f9-ba01-6e69f71382b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45298,DS-fd932459-0fe0-4ac0-a77c-396faf6be3d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36965,DS-a3f2256d-49c4-4c7e-88c3-7a0ec32c7fd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-462441517-172.17.0.13-1597566430432:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41041,DS-9c53a74c-a165-41ab-9427-bc835c31f778,DISK], DatanodeInfoWithStorage[127.0.0.1:43641,DS-4d9f7e15-0b3a-40ab-8edd-c1a3fb740585,DISK], DatanodeInfoWithStorage[127.0.0.1:43206,DS-ba2bc435-1d90-428b-9d6a-1b5dd8194f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:39995,DS-64d33944-3200-4154-9df5-ec7fa409eaaa,DISK], DatanodeInfoWithStorage[127.0.0.1:33520,DS-9c734375-434e-4f49-a860-99a7a5eaf5b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46480,DS-49096a63-ce1c-4e29-b773-68105882c616,DISK], DatanodeInfoWithStorage[127.0.0.1:36580,DS-92e722ae-06d1-4811-8dd9-8764a59254d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43161,DS-d76eb663-3fe8-4e89-a8a9-cf41d9e39e76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-462441517-172.17.0.13-1597566430432:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41041,DS-9c53a74c-a165-41ab-9427-bc835c31f778,DISK], DatanodeInfoWithStorage[127.0.0.1:43641,DS-4d9f7e15-0b3a-40ab-8edd-c1a3fb740585,DISK], DatanodeInfoWithStorage[127.0.0.1:43206,DS-ba2bc435-1d90-428b-9d6a-1b5dd8194f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:39995,DS-64d33944-3200-4154-9df5-ec7fa409eaaa,DISK], DatanodeInfoWithStorage[127.0.0.1:33520,DS-9c734375-434e-4f49-a860-99a7a5eaf5b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46480,DS-49096a63-ce1c-4e29-b773-68105882c616,DISK], DatanodeInfoWithStorage[127.0.0.1:36580,DS-92e722ae-06d1-4811-8dd9-8764a59254d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43161,DS-d76eb663-3fe8-4e89-a8a9-cf41d9e39e76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-422745712-172.17.0.13-1597567175240:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41892,DS-b656d0c1-d1af-4a09-b716-79b1131676e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34130,DS-b502ee98-d73f-4df4-98bc-da3551f0a626,DISK], DatanodeInfoWithStorage[127.0.0.1:34478,DS-60b473e7-e3a3-41fe-b12f-c73d9a0fb7b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34074,DS-1bc606e6-c2c5-4dcf-ba6f-62240e719873,DISK], DatanodeInfoWithStorage[127.0.0.1:41142,DS-e009f798-0e71-44e0-898d-717817ff9322,DISK], DatanodeInfoWithStorage[127.0.0.1:42329,DS-f572008c-45b0-4e07-8cbb-c66fb4b401a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38078,DS-de74786f-2a67-47aa-b2b4-c8d8ec9c9a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:40154,DS-7bbc01ec-4a19-4132-927b-dbde8e5856a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-422745712-172.17.0.13-1597567175240:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41892,DS-b656d0c1-d1af-4a09-b716-79b1131676e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34130,DS-b502ee98-d73f-4df4-98bc-da3551f0a626,DISK], DatanodeInfoWithStorage[127.0.0.1:34478,DS-60b473e7-e3a3-41fe-b12f-c73d9a0fb7b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34074,DS-1bc606e6-c2c5-4dcf-ba6f-62240e719873,DISK], DatanodeInfoWithStorage[127.0.0.1:41142,DS-e009f798-0e71-44e0-898d-717817ff9322,DISK], DatanodeInfoWithStorage[127.0.0.1:42329,DS-f572008c-45b0-4e07-8cbb-c66fb4b401a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38078,DS-de74786f-2a67-47aa-b2b4-c8d8ec9c9a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:40154,DS-7bbc01ec-4a19-4132-927b-dbde8e5856a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5452
