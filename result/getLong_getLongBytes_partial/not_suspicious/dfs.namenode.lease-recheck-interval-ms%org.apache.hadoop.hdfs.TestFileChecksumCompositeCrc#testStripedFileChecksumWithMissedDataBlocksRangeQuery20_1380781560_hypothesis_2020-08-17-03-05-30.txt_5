reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-953861316-172.17.0.7-1597633555250:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41027,DS-30164625-26de-4100-81e3-1296d708b089,DISK], DatanodeInfoWithStorage[127.0.0.1:42031,DS-cdeb8af4-b0fe-44a7-83f6-33a947caae71,DISK], DatanodeInfoWithStorage[127.0.0.1:37377,DS-ec9adb42-d496-4d41-b536-ef1e64c25cab,DISK], DatanodeInfoWithStorage[127.0.0.1:40760,DS-6288a098-4f26-4e3b-9d4b-81abc5692bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:38567,DS-26cee038-c4e6-4c1c-97bc-243b12a09196,DISK], DatanodeInfoWithStorage[127.0.0.1:36008,DS-d6267de8-2288-47d8-993b-cbea65d15e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:35513,DS-b31e9a34-ec10-4c22-9340-88e1fdad621e,DISK], DatanodeInfoWithStorage[127.0.0.1:41833,DS-9dbfe33a-966d-4f38-8392-ffdc461e6289,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-953861316-172.17.0.7-1597633555250:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41027,DS-30164625-26de-4100-81e3-1296d708b089,DISK], DatanodeInfoWithStorage[127.0.0.1:42031,DS-cdeb8af4-b0fe-44a7-83f6-33a947caae71,DISK], DatanodeInfoWithStorage[127.0.0.1:37377,DS-ec9adb42-d496-4d41-b536-ef1e64c25cab,DISK], DatanodeInfoWithStorage[127.0.0.1:40760,DS-6288a098-4f26-4e3b-9d4b-81abc5692bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:38567,DS-26cee038-c4e6-4c1c-97bc-243b12a09196,DISK], DatanodeInfoWithStorage[127.0.0.1:36008,DS-d6267de8-2288-47d8-993b-cbea65d15e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:35513,DS-b31e9a34-ec10-4c22-9340-88e1fdad621e,DISK], DatanodeInfoWithStorage[127.0.0.1:41833,DS-9dbfe33a-966d-4f38-8392-ffdc461e6289,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1162180202-172.17.0.7-1597633646043:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44936,DS-17d8dd8c-9987-4349-8a2b-fd5e41ac778f,DISK], DatanodeInfoWithStorage[127.0.0.1:37273,DS-60f53951-a2d1-44b5-93a7-f730023d9d39,DISK], DatanodeInfoWithStorage[127.0.0.1:40568,DS-414759bb-8233-4774-883b-4997986801e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46152,DS-81767f8a-6e4e-4613-bf3d-cd1be971db11,DISK], DatanodeInfoWithStorage[127.0.0.1:46189,DS-3771811b-2321-4c7c-8ca4-86e7b0df24a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34475,DS-b755a6c9-0ec9-44c8-8b2f-48bfd8244fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:37748,DS-bd30478f-e3c6-464c-83fb-5b73a5acbc33,DISK], DatanodeInfoWithStorage[127.0.0.1:46766,DS-fe569df3-f72b-43df-b82e-0ccbc4cae55c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1162180202-172.17.0.7-1597633646043:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44936,DS-17d8dd8c-9987-4349-8a2b-fd5e41ac778f,DISK], DatanodeInfoWithStorage[127.0.0.1:37273,DS-60f53951-a2d1-44b5-93a7-f730023d9d39,DISK], DatanodeInfoWithStorage[127.0.0.1:40568,DS-414759bb-8233-4774-883b-4997986801e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46152,DS-81767f8a-6e4e-4613-bf3d-cd1be971db11,DISK], DatanodeInfoWithStorage[127.0.0.1:46189,DS-3771811b-2321-4c7c-8ca4-86e7b0df24a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34475,DS-b755a6c9-0ec9-44c8-8b2f-48bfd8244fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:37748,DS-bd30478f-e3c6-464c-83fb-5b73a5acbc33,DISK], DatanodeInfoWithStorage[127.0.0.1:46766,DS-fe569df3-f72b-43df-b82e-0ccbc4cae55c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-381867425-172.17.0.7-1597633740859:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45662,DS-5c64438f-399a-490e-87f6-b718aaf92eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:35400,DS-2d2e566b-6d90-4e5c-84bf-74fe059df7b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34050,DS-687f3081-d06a-4b79-842a-03984703c71e,DISK], DatanodeInfoWithStorage[127.0.0.1:36979,DS-7c8a409b-1de8-4dbe-bad2-41cdd52463cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35386,DS-5161c661-bc48-428f-b094-e2b79c9d15dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35081,DS-b9b1e662-547c-46f0-94a2-8bff619c1467,DISK], DatanodeInfoWithStorage[127.0.0.1:39926,DS-6b7d67c4-94f2-4c22-80c5-68c03deed949,DISK], DatanodeInfoWithStorage[127.0.0.1:44184,DS-be840eca-32f8-42a5-8c27-01969684fce1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-381867425-172.17.0.7-1597633740859:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45662,DS-5c64438f-399a-490e-87f6-b718aaf92eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:35400,DS-2d2e566b-6d90-4e5c-84bf-74fe059df7b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34050,DS-687f3081-d06a-4b79-842a-03984703c71e,DISK], DatanodeInfoWithStorage[127.0.0.1:36979,DS-7c8a409b-1de8-4dbe-bad2-41cdd52463cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35386,DS-5161c661-bc48-428f-b094-e2b79c9d15dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35081,DS-b9b1e662-547c-46f0-94a2-8bff619c1467,DISK], DatanodeInfoWithStorage[127.0.0.1:39926,DS-6b7d67c4-94f2-4c22-80c5-68c03deed949,DISK], DatanodeInfoWithStorage[127.0.0.1:44184,DS-be840eca-32f8-42a5-8c27-01969684fce1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1232735668-172.17.0.7-1597634059513:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37386,DS-6613dc8c-4cbd-4e81-ab84-7c1ba2d3b697,DISK], DatanodeInfoWithStorage[127.0.0.1:45356,DS-089cbcf4-e9c1-4253-94ce-02fb69fcdd8c,DISK], DatanodeInfoWithStorage[127.0.0.1:42267,DS-cacb97cb-0170-4b94-8328-2dd610142d53,DISK], DatanodeInfoWithStorage[127.0.0.1:38623,DS-bf61f749-5dcc-46fd-a2dc-21a0543f90fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38479,DS-08cad6fc-6a17-46f7-8448-9b673267952b,DISK], DatanodeInfoWithStorage[127.0.0.1:42236,DS-cb4e5cfb-e41c-4205-a9c3-9a9bf16bf2f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39929,DS-ed03fd57-52b4-43ec-9e1a-f3d9f5f78466,DISK], DatanodeInfoWithStorage[127.0.0.1:39965,DS-7c13b5e4-6cca-4a13-a243-01bb6d4f59b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1232735668-172.17.0.7-1597634059513:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37386,DS-6613dc8c-4cbd-4e81-ab84-7c1ba2d3b697,DISK], DatanodeInfoWithStorage[127.0.0.1:45356,DS-089cbcf4-e9c1-4253-94ce-02fb69fcdd8c,DISK], DatanodeInfoWithStorage[127.0.0.1:42267,DS-cacb97cb-0170-4b94-8328-2dd610142d53,DISK], DatanodeInfoWithStorage[127.0.0.1:38623,DS-bf61f749-5dcc-46fd-a2dc-21a0543f90fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38479,DS-08cad6fc-6a17-46f7-8448-9b673267952b,DISK], DatanodeInfoWithStorage[127.0.0.1:42236,DS-cb4e5cfb-e41c-4205-a9c3-9a9bf16bf2f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39929,DS-ed03fd57-52b4-43ec-9e1a-f3d9f5f78466,DISK], DatanodeInfoWithStorage[127.0.0.1:39965,DS-7c13b5e4-6cca-4a13-a243-01bb6d4f59b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1612697329-172.17.0.7-1597634783560:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42905,DS-cddc9b78-5038-4e94-9493-e2d6323dccf0,DISK], DatanodeInfoWithStorage[127.0.0.1:43827,DS-908f5bc8-d05a-434d-a047-13e1fdecbf1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43027,DS-f9ba1799-3e0c-457c-819b-a0bd67be4ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:34293,DS-40185b3c-bde7-4c53-bda0-b1a3666b2ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:34159,DS-f0ec6b5f-21eb-4df6-8d57-9b6cad0654cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36337,DS-9479b1a0-758e-4e44-8085-5e7f0e30bdaa,DISK], DatanodeInfoWithStorage[127.0.0.1:40176,DS-8280028a-984b-476c-9b09-136432d727d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46503,DS-568f3058-26a9-4d00-b69c-013a37f4d1c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1612697329-172.17.0.7-1597634783560:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42905,DS-cddc9b78-5038-4e94-9493-e2d6323dccf0,DISK], DatanodeInfoWithStorage[127.0.0.1:43827,DS-908f5bc8-d05a-434d-a047-13e1fdecbf1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43027,DS-f9ba1799-3e0c-457c-819b-a0bd67be4ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:34293,DS-40185b3c-bde7-4c53-bda0-b1a3666b2ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:34159,DS-f0ec6b5f-21eb-4df6-8d57-9b6cad0654cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36337,DS-9479b1a0-758e-4e44-8085-5e7f0e30bdaa,DISK], DatanodeInfoWithStorage[127.0.0.1:40176,DS-8280028a-984b-476c-9b09-136432d727d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46503,DS-568f3058-26a9-4d00-b69c-013a37f4d1c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-874743352-172.17.0.7-1597634832400:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42816,DS-8836e0d0-e640-4ad6-9548-542cdcf299fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34871,DS-f14d41f6-4992-40ab-bc68-29512d2cfd96,DISK], DatanodeInfoWithStorage[127.0.0.1:39097,DS-6f3c06c6-4b8b-4595-a465-215272aac93f,DISK], DatanodeInfoWithStorage[127.0.0.1:40238,DS-9e0408ef-97de-4b7c-a389-fdd02f65bb4b,DISK], DatanodeInfoWithStorage[127.0.0.1:42649,DS-bdbbd6fd-6834-4c28-9f9c-a417f61782a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35086,DS-1d4e7011-391a-450f-8527-28d05e2174e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41129,DS-f66f00a6-1deb-4027-b7e7-02c32ca6f067,DISK], DatanodeInfoWithStorage[127.0.0.1:42590,DS-718f714c-b76d-430c-ab77-27028db322b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-874743352-172.17.0.7-1597634832400:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42816,DS-8836e0d0-e640-4ad6-9548-542cdcf299fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34871,DS-f14d41f6-4992-40ab-bc68-29512d2cfd96,DISK], DatanodeInfoWithStorage[127.0.0.1:39097,DS-6f3c06c6-4b8b-4595-a465-215272aac93f,DISK], DatanodeInfoWithStorage[127.0.0.1:40238,DS-9e0408ef-97de-4b7c-a389-fdd02f65bb4b,DISK], DatanodeInfoWithStorage[127.0.0.1:42649,DS-bdbbd6fd-6834-4c28-9f9c-a417f61782a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35086,DS-1d4e7011-391a-450f-8527-28d05e2174e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41129,DS-f66f00a6-1deb-4027-b7e7-02c32ca6f067,DISK], DatanodeInfoWithStorage[127.0.0.1:42590,DS-718f714c-b76d-430c-ab77-27028db322b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-628683602-172.17.0.7-1597635786653:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44095,DS-84835550-36b9-4741-bd0e-1383ae7fdbed,DISK], DatanodeInfoWithStorage[127.0.0.1:37510,DS-c0da40b7-71c5-46b2-aeba-e235c4cae1d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42250,DS-f363d260-7e01-446a-9eb3-e4dc6e9d92a5,DISK], DatanodeInfoWithStorage[127.0.0.1:32793,DS-f6ff019c-68a9-4e0c-bfd4-633bacdebc95,DISK], DatanodeInfoWithStorage[127.0.0.1:44153,DS-e7e96e36-3c0d-4cb0-9ddc-b04b82d15cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:37304,DS-61d22b54-320d-4b33-8d7b-5ba72e6b7ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:42696,DS-1362400c-979a-4d02-ad96-63b8ced7c5f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33721,DS-e9dfa9ef-3db9-4201-ae3d-44cdee7f4e44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-628683602-172.17.0.7-1597635786653:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44095,DS-84835550-36b9-4741-bd0e-1383ae7fdbed,DISK], DatanodeInfoWithStorage[127.0.0.1:37510,DS-c0da40b7-71c5-46b2-aeba-e235c4cae1d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42250,DS-f363d260-7e01-446a-9eb3-e4dc6e9d92a5,DISK], DatanodeInfoWithStorage[127.0.0.1:32793,DS-f6ff019c-68a9-4e0c-bfd4-633bacdebc95,DISK], DatanodeInfoWithStorage[127.0.0.1:44153,DS-e7e96e36-3c0d-4cb0-9ddc-b04b82d15cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:37304,DS-61d22b54-320d-4b33-8d7b-5ba72e6b7ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:42696,DS-1362400c-979a-4d02-ad96-63b8ced7c5f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33721,DS-e9dfa9ef-3db9-4201-ae3d-44cdee7f4e44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-812121096-172.17.0.7-1597636168002:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36930,DS-05e6d6e0-32e1-4d15-a442-d33efc3e3339,DISK], DatanodeInfoWithStorage[127.0.0.1:40887,DS-73a618e5-4d34-46ac-a109-11f5f6f29650,DISK], DatanodeInfoWithStorage[127.0.0.1:41481,DS-c3daa7f6-8611-4e65-82ce-f622e0154b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:46296,DS-4d2dfa6c-2dcc-439a-a3f2-672f0ae76923,DISK], DatanodeInfoWithStorage[127.0.0.1:42606,DS-b08145ff-6716-4609-930d-62e4d5047a67,DISK], DatanodeInfoWithStorage[127.0.0.1:34603,DS-b6f19556-fb1c-418f-ad98-342760aed0e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41510,DS-b4afc525-683a-4f17-bb20-00189c7590b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34273,DS-90d9060e-c565-4830-9a0d-c10ee74366a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-812121096-172.17.0.7-1597636168002:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36930,DS-05e6d6e0-32e1-4d15-a442-d33efc3e3339,DISK], DatanodeInfoWithStorage[127.0.0.1:40887,DS-73a618e5-4d34-46ac-a109-11f5f6f29650,DISK], DatanodeInfoWithStorage[127.0.0.1:41481,DS-c3daa7f6-8611-4e65-82ce-f622e0154b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:46296,DS-4d2dfa6c-2dcc-439a-a3f2-672f0ae76923,DISK], DatanodeInfoWithStorage[127.0.0.1:42606,DS-b08145ff-6716-4609-930d-62e4d5047a67,DISK], DatanodeInfoWithStorage[127.0.0.1:34603,DS-b6f19556-fb1c-418f-ad98-342760aed0e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41510,DS-b4afc525-683a-4f17-bb20-00189c7590b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34273,DS-90d9060e-c565-4830-9a0d-c10ee74366a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-491915489-172.17.0.7-1597637297972:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39689,DS-f0c03947-2fff-4fea-a1d2-cd602e49366c,DISK], DatanodeInfoWithStorage[127.0.0.1:32965,DS-76a0817a-b81e-4ba7-887f-1b5ec7a022cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33015,DS-6b47c331-46b0-4d9a-b1c3-a680e04fa7c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42178,DS-5be2a2db-aed9-487f-a73b-965cea6189ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33648,DS-0954f76e-d016-4ddb-a311-2ef45f743386,DISK], DatanodeInfoWithStorage[127.0.0.1:44892,DS-a5235067-73b8-4c87-a104-7a26f01204f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39136,DS-0e36d70a-8558-4359-803a-166f1da5ca6e,DISK], DatanodeInfoWithStorage[127.0.0.1:43913,DS-3d68c922-9965-4067-aaa1-68b07194e3e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-491915489-172.17.0.7-1597637297972:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39689,DS-f0c03947-2fff-4fea-a1d2-cd602e49366c,DISK], DatanodeInfoWithStorage[127.0.0.1:32965,DS-76a0817a-b81e-4ba7-887f-1b5ec7a022cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33015,DS-6b47c331-46b0-4d9a-b1c3-a680e04fa7c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42178,DS-5be2a2db-aed9-487f-a73b-965cea6189ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33648,DS-0954f76e-d016-4ddb-a311-2ef45f743386,DISK], DatanodeInfoWithStorage[127.0.0.1:44892,DS-a5235067-73b8-4c87-a104-7a26f01204f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39136,DS-0e36d70a-8558-4359-803a-166f1da5ca6e,DISK], DatanodeInfoWithStorage[127.0.0.1:43913,DS-3d68c922-9965-4067-aaa1-68b07194e3e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1155175972-172.17.0.7-1597638402159:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40390,DS-d2b86813-5f37-44c6-867b-c807a7fcfd9a,DISK], DatanodeInfoWithStorage[127.0.0.1:43233,DS-4b495260-7576-4cb1-84e8-f9b7f0c217c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33246,DS-2595287d-2ea8-4158-b7b6-fa2d8b4195c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44697,DS-e13d8b21-2d0a-416e-b6c8-7230fd08216a,DISK], DatanodeInfoWithStorage[127.0.0.1:41100,DS-aa0ac6b4-2a20-486e-86e3-7036f0d53957,DISK], DatanodeInfoWithStorage[127.0.0.1:33253,DS-0cc1db27-64e4-4ac8-b96a-9c195f953e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:40550,DS-e9dcf655-27cc-4eb8-a344-9cfd89137e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:34685,DS-7bad409c-2ee2-4191-99e9-6bee9dc5ff71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1155175972-172.17.0.7-1597638402159:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40390,DS-d2b86813-5f37-44c6-867b-c807a7fcfd9a,DISK], DatanodeInfoWithStorage[127.0.0.1:43233,DS-4b495260-7576-4cb1-84e8-f9b7f0c217c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33246,DS-2595287d-2ea8-4158-b7b6-fa2d8b4195c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44697,DS-e13d8b21-2d0a-416e-b6c8-7230fd08216a,DISK], DatanodeInfoWithStorage[127.0.0.1:41100,DS-aa0ac6b4-2a20-486e-86e3-7036f0d53957,DISK], DatanodeInfoWithStorage[127.0.0.1:33253,DS-0cc1db27-64e4-4ac8-b96a-9c195f953e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:40550,DS-e9dcf655-27cc-4eb8-a344-9cfd89137e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:34685,DS-7bad409c-2ee2-4191-99e9-6bee9dc5ff71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-863207500-172.17.0.7-1597638676808:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44338,DS-db5be12b-36a5-4cb2-9565-f9f35d306f90,DISK], DatanodeInfoWithStorage[127.0.0.1:42220,DS-d6d565b9-5d56-4a8f-a76e-bdfe00176314,DISK], DatanodeInfoWithStorage[127.0.0.1:46486,DS-4af3c28d-745b-4a6e-ba3b-c343b42a0b03,DISK], DatanodeInfoWithStorage[127.0.0.1:37172,DS-9842ed88-27cb-423b-84c2-9c8c0437dcb4,DISK], DatanodeInfoWithStorage[127.0.0.1:35068,DS-552a4ca2-fa06-45e6-8584-acd6d6df35f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39399,DS-d969c844-b7f5-49e0-8465-8ca481515c36,DISK], DatanodeInfoWithStorage[127.0.0.1:43645,DS-08faca0f-1c5e-44c6-9350-1e5bbcc12034,DISK], DatanodeInfoWithStorage[127.0.0.1:39468,DS-e899ef2e-94e4-41f6-b5ad-4b7dc6c9ad69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-863207500-172.17.0.7-1597638676808:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44338,DS-db5be12b-36a5-4cb2-9565-f9f35d306f90,DISK], DatanodeInfoWithStorage[127.0.0.1:42220,DS-d6d565b9-5d56-4a8f-a76e-bdfe00176314,DISK], DatanodeInfoWithStorage[127.0.0.1:46486,DS-4af3c28d-745b-4a6e-ba3b-c343b42a0b03,DISK], DatanodeInfoWithStorage[127.0.0.1:37172,DS-9842ed88-27cb-423b-84c2-9c8c0437dcb4,DISK], DatanodeInfoWithStorage[127.0.0.1:35068,DS-552a4ca2-fa06-45e6-8584-acd6d6df35f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39399,DS-d969c844-b7f5-49e0-8465-8ca481515c36,DISK], DatanodeInfoWithStorage[127.0.0.1:43645,DS-08faca0f-1c5e-44c6-9350-1e5bbcc12034,DISK], DatanodeInfoWithStorage[127.0.0.1:39468,DS-e899ef2e-94e4-41f6-b5ad-4b7dc6c9ad69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-694841995-172.17.0.7-1597638720621:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35624,DS-1cf0b799-914b-4386-9c8e-828fbc30d5aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42151,DS-dbc2a75f-a546-431f-93de-b780f2f933d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33049,DS-e1db6481-be7b-498e-a5f8-8537b2d5826c,DISK], DatanodeInfoWithStorage[127.0.0.1:41383,DS-8502bebd-f26a-48a4-8fe1-feec9ca30520,DISK], DatanodeInfoWithStorage[127.0.0.1:34953,DS-0896b7d9-254f-4855-893c-d31829199491,DISK], DatanodeInfoWithStorage[127.0.0.1:46656,DS-65048b2a-1d4a-4c77-9940-99024c98daf5,DISK], DatanodeInfoWithStorage[127.0.0.1:38935,DS-a8bf4897-982c-4bb9-a986-4cf3fb9ca4d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34738,DS-554198f1-2cca-4158-8fd4-10a1ac2a997d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-694841995-172.17.0.7-1597638720621:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35624,DS-1cf0b799-914b-4386-9c8e-828fbc30d5aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42151,DS-dbc2a75f-a546-431f-93de-b780f2f933d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33049,DS-e1db6481-be7b-498e-a5f8-8537b2d5826c,DISK], DatanodeInfoWithStorage[127.0.0.1:41383,DS-8502bebd-f26a-48a4-8fe1-feec9ca30520,DISK], DatanodeInfoWithStorage[127.0.0.1:34953,DS-0896b7d9-254f-4855-893c-d31829199491,DISK], DatanodeInfoWithStorage[127.0.0.1:46656,DS-65048b2a-1d4a-4c77-9940-99024c98daf5,DISK], DatanodeInfoWithStorage[127.0.0.1:38935,DS-a8bf4897-982c-4bb9-a986-4cf3fb9ca4d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34738,DS-554198f1-2cca-4158-8fd4-10a1ac2a997d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-532338451-172.17.0.7-1597639307470:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45062,DS-e2c4eef3-086f-494a-8411-2d817bf1f62a,DISK], DatanodeInfoWithStorage[127.0.0.1:46417,DS-f070f017-5423-467e-9948-63ca022b353a,DISK], DatanodeInfoWithStorage[127.0.0.1:36313,DS-6dca5f8e-0c1d-43de-b420-3314bfa36dad,DISK], DatanodeInfoWithStorage[127.0.0.1:40187,DS-c75fad37-f96c-407f-9a27-4379ea6e225c,DISK], DatanodeInfoWithStorage[127.0.0.1:36022,DS-ff9b549b-2526-4298-a334-0131bd8d7e84,DISK], DatanodeInfoWithStorage[127.0.0.1:42635,DS-352b6d26-534d-4a22-93ef-64f9a83893e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34260,DS-269f4e20-4b94-466a-8097-74d2b7f61977,DISK], DatanodeInfoWithStorage[127.0.0.1:35045,DS-c9181155-72ac-433d-97e7-5173d46285bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-532338451-172.17.0.7-1597639307470:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45062,DS-e2c4eef3-086f-494a-8411-2d817bf1f62a,DISK], DatanodeInfoWithStorage[127.0.0.1:46417,DS-f070f017-5423-467e-9948-63ca022b353a,DISK], DatanodeInfoWithStorage[127.0.0.1:36313,DS-6dca5f8e-0c1d-43de-b420-3314bfa36dad,DISK], DatanodeInfoWithStorage[127.0.0.1:40187,DS-c75fad37-f96c-407f-9a27-4379ea6e225c,DISK], DatanodeInfoWithStorage[127.0.0.1:36022,DS-ff9b549b-2526-4298-a334-0131bd8d7e84,DISK], DatanodeInfoWithStorage[127.0.0.1:42635,DS-352b6d26-534d-4a22-93ef-64f9a83893e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34260,DS-269f4e20-4b94-466a-8097-74d2b7f61977,DISK], DatanodeInfoWithStorage[127.0.0.1:35045,DS-c9181155-72ac-433d-97e7-5173d46285bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1030514912-172.17.0.7-1597639575454:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34659,DS-3137b5ed-901b-4f18-bf5b-48065a53a05f,DISK], DatanodeInfoWithStorage[127.0.0.1:44410,DS-235d523a-6fac-44d8-b192-cd0fbe4ddd87,DISK], DatanodeInfoWithStorage[127.0.0.1:35230,DS-37fc3a61-ca52-4946-82a2-f58c3391d2c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37203,DS-5a711cb0-9e71-44f3-98c5-f860c96dc09b,DISK], DatanodeInfoWithStorage[127.0.0.1:44735,DS-bffd58df-ad4a-4df3-a758-76bc2a51bf8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33268,DS-ede76a0f-7168-4e97-9bca-df7c9378e307,DISK], DatanodeInfoWithStorage[127.0.0.1:36685,DS-ea63b28e-9b25-4d48-be4a-81dbd6c39efc,DISK], DatanodeInfoWithStorage[127.0.0.1:39672,DS-39d538ec-21bb-4e1a-99b2-1412de3c4066,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1030514912-172.17.0.7-1597639575454:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34659,DS-3137b5ed-901b-4f18-bf5b-48065a53a05f,DISK], DatanodeInfoWithStorage[127.0.0.1:44410,DS-235d523a-6fac-44d8-b192-cd0fbe4ddd87,DISK], DatanodeInfoWithStorage[127.0.0.1:35230,DS-37fc3a61-ca52-4946-82a2-f58c3391d2c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37203,DS-5a711cb0-9e71-44f3-98c5-f860c96dc09b,DISK], DatanodeInfoWithStorage[127.0.0.1:44735,DS-bffd58df-ad4a-4df3-a758-76bc2a51bf8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33268,DS-ede76a0f-7168-4e97-9bca-df7c9378e307,DISK], DatanodeInfoWithStorage[127.0.0.1:36685,DS-ea63b28e-9b25-4d48-be4a-81dbd6c39efc,DISK], DatanodeInfoWithStorage[127.0.0.1:39672,DS-39d538ec-21bb-4e1a-99b2-1412de3c4066,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1556242595-172.17.0.7-1597639661247:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45887,DS-ff3637a1-e544-485f-8722-cbda71bf4469,DISK], DatanodeInfoWithStorage[127.0.0.1:33572,DS-134dd64e-949f-4e95-8f07-bba2030e8839,DISK], DatanodeInfoWithStorage[127.0.0.1:41193,DS-b2b19814-70b4-447d-876f-33b43127970e,DISK], DatanodeInfoWithStorage[127.0.0.1:33820,DS-8dc1e004-1597-4917-acfa-c732340e3009,DISK], DatanodeInfoWithStorage[127.0.0.1:36740,DS-fd0ee012-6852-46ad-85f7-d4ad2f896f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:43032,DS-fb98932e-2ebf-4e4e-baa1-5900ae7eb746,DISK], DatanodeInfoWithStorage[127.0.0.1:43004,DS-4705942c-669d-47d0-996d-ac67ad5675a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46217,DS-be4cfe51-da1b-4085-9462-a94b1e64ec96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1556242595-172.17.0.7-1597639661247:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45887,DS-ff3637a1-e544-485f-8722-cbda71bf4469,DISK], DatanodeInfoWithStorage[127.0.0.1:33572,DS-134dd64e-949f-4e95-8f07-bba2030e8839,DISK], DatanodeInfoWithStorage[127.0.0.1:41193,DS-b2b19814-70b4-447d-876f-33b43127970e,DISK], DatanodeInfoWithStorage[127.0.0.1:33820,DS-8dc1e004-1597-4917-acfa-c732340e3009,DISK], DatanodeInfoWithStorage[127.0.0.1:36740,DS-fd0ee012-6852-46ad-85f7-d4ad2f896f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:43032,DS-fb98932e-2ebf-4e4e-baa1-5900ae7eb746,DISK], DatanodeInfoWithStorage[127.0.0.1:43004,DS-4705942c-669d-47d0-996d-ac67ad5675a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46217,DS-be4cfe51-da1b-4085-9462-a94b1e64ec96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-635682882-172.17.0.7-1597639995257:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42296,DS-f1388b76-07d7-4274-bf4b-f3a6b80d017d,DISK], DatanodeInfoWithStorage[127.0.0.1:43348,DS-583115ad-192b-482b-ad1a-d3496ce898cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34739,DS-9281dec2-6549-4148-ae46-d08db5c4a9f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38478,DS-db405d9f-705f-4f61-bb6b-ee0fa9ad2ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:44641,DS-62b02a41-8c6e-4791-b4b0-dd45dbebbafc,DISK], DatanodeInfoWithStorage[127.0.0.1:36796,DS-da0238b5-4217-4f8f-9e21-95a9e95cfafb,DISK], DatanodeInfoWithStorage[127.0.0.1:33737,DS-d8ed96c7-f7dc-4282-acd5-b211d6392107,DISK], DatanodeInfoWithStorage[127.0.0.1:39981,DS-14fc92ff-2683-46c4-8617-054e04414053,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-635682882-172.17.0.7-1597639995257:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42296,DS-f1388b76-07d7-4274-bf4b-f3a6b80d017d,DISK], DatanodeInfoWithStorage[127.0.0.1:43348,DS-583115ad-192b-482b-ad1a-d3496ce898cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34739,DS-9281dec2-6549-4148-ae46-d08db5c4a9f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38478,DS-db405d9f-705f-4f61-bb6b-ee0fa9ad2ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:44641,DS-62b02a41-8c6e-4791-b4b0-dd45dbebbafc,DISK], DatanodeInfoWithStorage[127.0.0.1:36796,DS-da0238b5-4217-4f8f-9e21-95a9e95cfafb,DISK], DatanodeInfoWithStorage[127.0.0.1:33737,DS-d8ed96c7-f7dc-4282-acd5-b211d6392107,DISK], DatanodeInfoWithStorage[127.0.0.1:39981,DS-14fc92ff-2683-46c4-8617-054e04414053,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 6921
