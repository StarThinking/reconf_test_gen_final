reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-690223123-172.17.0.19-1597672183144:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36213,DS-1a3a8ec6-6c25-4987-bb0e-30cf1083b8b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35459,DS-303aced3-9d07-41e8-aaf8-ba9b5b6e0039,DISK], DatanodeInfoWithStorage[127.0.0.1:39202,DS-64c09f2b-5f57-463f-ab11-02005dccfcea,DISK], DatanodeInfoWithStorage[127.0.0.1:33598,DS-9d267147-7db0-44cb-98ce-0590f2eee6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46152,DS-6e221055-81b7-4e9b-b627-6e078445d052,DISK], DatanodeInfoWithStorage[127.0.0.1:39415,DS-3363ae06-7a0a-461e-813c-da27f84b0ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:38211,DS-dbe66fcc-588b-46e0-a32b-27a0c4d7feb2,DISK], DatanodeInfoWithStorage[127.0.0.1:45853,DS-c6f7fb42-1fe6-4429-952e-649444105a9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-690223123-172.17.0.19-1597672183144:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36213,DS-1a3a8ec6-6c25-4987-bb0e-30cf1083b8b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35459,DS-303aced3-9d07-41e8-aaf8-ba9b5b6e0039,DISK], DatanodeInfoWithStorage[127.0.0.1:39202,DS-64c09f2b-5f57-463f-ab11-02005dccfcea,DISK], DatanodeInfoWithStorage[127.0.0.1:33598,DS-9d267147-7db0-44cb-98ce-0590f2eee6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46152,DS-6e221055-81b7-4e9b-b627-6e078445d052,DISK], DatanodeInfoWithStorage[127.0.0.1:39415,DS-3363ae06-7a0a-461e-813c-da27f84b0ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:38211,DS-dbe66fcc-588b-46e0-a32b-27a0c4d7feb2,DISK], DatanodeInfoWithStorage[127.0.0.1:45853,DS-c6f7fb42-1fe6-4429-952e-649444105a9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1213871986-172.17.0.19-1597672790808:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41697,DS-b565cbe2-3cfd-40ee-adb9-d2c114fa60a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34125,DS-eedc0d22-c028-4ca2-ac62-fd34749fad9e,DISK], DatanodeInfoWithStorage[127.0.0.1:46446,DS-7fa5d5d5-ced7-4a8f-9740-740418e5e167,DISK], DatanodeInfoWithStorage[127.0.0.1:34907,DS-c09857eb-69b7-4452-adb4-8b1e7565219e,DISK], DatanodeInfoWithStorage[127.0.0.1:35029,DS-33fa51fd-03b5-4999-a25f-ed2686233029,DISK], DatanodeInfoWithStorage[127.0.0.1:38200,DS-7c85b0a0-506a-4d92-a045-8996f39dd963,DISK], DatanodeInfoWithStorage[127.0.0.1:33576,DS-b6dbe4d5-3b7a-471d-bf59-948aace4539a,DISK], DatanodeInfoWithStorage[127.0.0.1:40972,DS-946b76a1-595a-43ca-b16f-a27544a9439d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1213871986-172.17.0.19-1597672790808:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41697,DS-b565cbe2-3cfd-40ee-adb9-d2c114fa60a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34125,DS-eedc0d22-c028-4ca2-ac62-fd34749fad9e,DISK], DatanodeInfoWithStorage[127.0.0.1:46446,DS-7fa5d5d5-ced7-4a8f-9740-740418e5e167,DISK], DatanodeInfoWithStorage[127.0.0.1:34907,DS-c09857eb-69b7-4452-adb4-8b1e7565219e,DISK], DatanodeInfoWithStorage[127.0.0.1:35029,DS-33fa51fd-03b5-4999-a25f-ed2686233029,DISK], DatanodeInfoWithStorage[127.0.0.1:38200,DS-7c85b0a0-506a-4d92-a045-8996f39dd963,DISK], DatanodeInfoWithStorage[127.0.0.1:33576,DS-b6dbe4d5-3b7a-471d-bf59-948aace4539a,DISK], DatanodeInfoWithStorage[127.0.0.1:40972,DS-946b76a1-595a-43ca-b16f-a27544a9439d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1271103068-172.17.0.19-1597673698843:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35095,DS-6a19adab-4ed4-42a4-b296-cfdcf371a616,DISK], DatanodeInfoWithStorage[127.0.0.1:38765,DS-0cce3302-8b28-4a40-9f4d-7abe125b56e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38285,DS-27a0fa96-4f23-4aef-96ef-a090f769104b,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-2fca3b62-1239-4f24-af98-564241423233,DISK], DatanodeInfoWithStorage[127.0.0.1:39070,DS-9650ef9b-5d75-47ac-b031-a72080970a23,DISK], DatanodeInfoWithStorage[127.0.0.1:43816,DS-bcddec9e-1c9d-4f8f-a50b-7defc2820752,DISK], DatanodeInfoWithStorage[127.0.0.1:33506,DS-7480e734-0151-4fe3-b0b7-cae683fc623a,DISK], DatanodeInfoWithStorage[127.0.0.1:44414,DS-5a9ce081-7640-41f7-9e04-d8def2c2bfb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1271103068-172.17.0.19-1597673698843:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35095,DS-6a19adab-4ed4-42a4-b296-cfdcf371a616,DISK], DatanodeInfoWithStorage[127.0.0.1:38765,DS-0cce3302-8b28-4a40-9f4d-7abe125b56e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38285,DS-27a0fa96-4f23-4aef-96ef-a090f769104b,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-2fca3b62-1239-4f24-af98-564241423233,DISK], DatanodeInfoWithStorage[127.0.0.1:39070,DS-9650ef9b-5d75-47ac-b031-a72080970a23,DISK], DatanodeInfoWithStorage[127.0.0.1:43816,DS-bcddec9e-1c9d-4f8f-a50b-7defc2820752,DISK], DatanodeInfoWithStorage[127.0.0.1:33506,DS-7480e734-0151-4fe3-b0b7-cae683fc623a,DISK], DatanodeInfoWithStorage[127.0.0.1:44414,DS-5a9ce081-7640-41f7-9e04-d8def2c2bfb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1917886052-172.17.0.19-1597673895071:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45178,DS-2d7dd8f0-8f8a-47a2-8f90-5f7df6138573,DISK], DatanodeInfoWithStorage[127.0.0.1:39878,DS-a6898198-148e-45d3-baa8-b948f9af5165,DISK], DatanodeInfoWithStorage[127.0.0.1:41707,DS-07410dec-4b86-4aa5-aa89-47044d59534b,DISK], DatanodeInfoWithStorage[127.0.0.1:39972,DS-7421cc64-23d4-48c9-8672-040e9a406c34,DISK], DatanodeInfoWithStorage[127.0.0.1:37016,DS-93e1ab75-1e77-44d2-a15d-282ff45f2841,DISK], DatanodeInfoWithStorage[127.0.0.1:40981,DS-1a36d96b-2657-497d-a68f-e87d8d960526,DISK], DatanodeInfoWithStorage[127.0.0.1:45681,DS-a69548cc-868d-4b79-abef-1f0bebe92088,DISK], DatanodeInfoWithStorage[127.0.0.1:40096,DS-11fccc91-50b7-44eb-86a9-ba3adfb06f61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1917886052-172.17.0.19-1597673895071:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45178,DS-2d7dd8f0-8f8a-47a2-8f90-5f7df6138573,DISK], DatanodeInfoWithStorage[127.0.0.1:39878,DS-a6898198-148e-45d3-baa8-b948f9af5165,DISK], DatanodeInfoWithStorage[127.0.0.1:41707,DS-07410dec-4b86-4aa5-aa89-47044d59534b,DISK], DatanodeInfoWithStorage[127.0.0.1:39972,DS-7421cc64-23d4-48c9-8672-040e9a406c34,DISK], DatanodeInfoWithStorage[127.0.0.1:37016,DS-93e1ab75-1e77-44d2-a15d-282ff45f2841,DISK], DatanodeInfoWithStorage[127.0.0.1:40981,DS-1a36d96b-2657-497d-a68f-e87d8d960526,DISK], DatanodeInfoWithStorage[127.0.0.1:45681,DS-a69548cc-868d-4b79-abef-1f0bebe92088,DISK], DatanodeInfoWithStorage[127.0.0.1:40096,DS-11fccc91-50b7-44eb-86a9-ba3adfb06f61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-817731738-172.17.0.19-1597674584733:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38861,DS-ba72fb26-f169-4120-9174-22ef1d48a453,DISK], DatanodeInfoWithStorage[127.0.0.1:42058,DS-8b87fdcd-91e4-4011-a4fe-670e6d027bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:38037,DS-4573b95f-f7e0-4a0c-9100-d68696ddc152,DISK], DatanodeInfoWithStorage[127.0.0.1:33228,DS-954976c8-8f56-499d-ba0a-3bd7d9d3c0de,DISK], DatanodeInfoWithStorage[127.0.0.1:33471,DS-f2b4b133-1c08-4de9-9d5f-671702fc7507,DISK], DatanodeInfoWithStorage[127.0.0.1:45005,DS-5f11b3f3-beae-40fb-868c-ec312def347a,DISK], DatanodeInfoWithStorage[127.0.0.1:40573,DS-4e1bf49a-927b-4550-a72f-016a88d442c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44103,DS-f17e0193-74ac-4498-ac57-77f7919d8e7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-817731738-172.17.0.19-1597674584733:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38861,DS-ba72fb26-f169-4120-9174-22ef1d48a453,DISK], DatanodeInfoWithStorage[127.0.0.1:42058,DS-8b87fdcd-91e4-4011-a4fe-670e6d027bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:38037,DS-4573b95f-f7e0-4a0c-9100-d68696ddc152,DISK], DatanodeInfoWithStorage[127.0.0.1:33228,DS-954976c8-8f56-499d-ba0a-3bd7d9d3c0de,DISK], DatanodeInfoWithStorage[127.0.0.1:33471,DS-f2b4b133-1c08-4de9-9d5f-671702fc7507,DISK], DatanodeInfoWithStorage[127.0.0.1:45005,DS-5f11b3f3-beae-40fb-868c-ec312def347a,DISK], DatanodeInfoWithStorage[127.0.0.1:40573,DS-4e1bf49a-927b-4550-a72f-016a88d442c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44103,DS-f17e0193-74ac-4498-ac57-77f7919d8e7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1320486932-172.17.0.19-1597675055316:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46159,DS-0bd99a82-a1d3-43a6-a3c6-82a7fb0ec4ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33464,DS-cbc66aeb-1765-4c92-81e4-b12ca53e442b,DISK], DatanodeInfoWithStorage[127.0.0.1:42052,DS-cac92f0b-36b5-4c7c-a13b-780acec65f10,DISK], DatanodeInfoWithStorage[127.0.0.1:42638,DS-cb6396ee-39d9-440d-98c0-c8cc814c7b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:40690,DS-465cc61b-c335-4af7-bdfc-7147870dbac3,DISK], DatanodeInfoWithStorage[127.0.0.1:46409,DS-c290eb31-8ae2-4b4e-92d7-6049ede45b16,DISK], DatanodeInfoWithStorage[127.0.0.1:39566,DS-efdf617d-4e7c-481d-969a-2c9d1f6c95ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44689,DS-3abde627-4cb4-4afa-98ce-38b87e16d6db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1320486932-172.17.0.19-1597675055316:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46159,DS-0bd99a82-a1d3-43a6-a3c6-82a7fb0ec4ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33464,DS-cbc66aeb-1765-4c92-81e4-b12ca53e442b,DISK], DatanodeInfoWithStorage[127.0.0.1:42052,DS-cac92f0b-36b5-4c7c-a13b-780acec65f10,DISK], DatanodeInfoWithStorage[127.0.0.1:42638,DS-cb6396ee-39d9-440d-98c0-c8cc814c7b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:40690,DS-465cc61b-c335-4af7-bdfc-7147870dbac3,DISK], DatanodeInfoWithStorage[127.0.0.1:46409,DS-c290eb31-8ae2-4b4e-92d7-6049ede45b16,DISK], DatanodeInfoWithStorage[127.0.0.1:39566,DS-efdf617d-4e7c-481d-969a-2c9d1f6c95ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44689,DS-3abde627-4cb4-4afa-98ce-38b87e16d6db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1206256758-172.17.0.19-1597675229303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38574,DS-01c21858-379e-44c9-8e04-e4c17910d599,DISK], DatanodeInfoWithStorage[127.0.0.1:38603,DS-fa932484-4fd0-4a91-a97b-e226351f18e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41407,DS-65d64286-01ac-4215-858e-5d04fd320092,DISK], DatanodeInfoWithStorage[127.0.0.1:37246,DS-a4e03f40-f940-4fc1-bd93-e89be657241c,DISK], DatanodeInfoWithStorage[127.0.0.1:40205,DS-1393b4e9-f707-4f3b-b9f4-df09a2792095,DISK], DatanodeInfoWithStorage[127.0.0.1:37165,DS-e4d27846-92ea-41ee-aab3-0b91af87c60d,DISK], DatanodeInfoWithStorage[127.0.0.1:37557,DS-f5ebeb0b-7a0c-430e-8191-121e7c43681f,DISK], DatanodeInfoWithStorage[127.0.0.1:39624,DS-aeb86824-60ab-40cf-b076-f5537fec92f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1206256758-172.17.0.19-1597675229303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38574,DS-01c21858-379e-44c9-8e04-e4c17910d599,DISK], DatanodeInfoWithStorage[127.0.0.1:38603,DS-fa932484-4fd0-4a91-a97b-e226351f18e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41407,DS-65d64286-01ac-4215-858e-5d04fd320092,DISK], DatanodeInfoWithStorage[127.0.0.1:37246,DS-a4e03f40-f940-4fc1-bd93-e89be657241c,DISK], DatanodeInfoWithStorage[127.0.0.1:40205,DS-1393b4e9-f707-4f3b-b9f4-df09a2792095,DISK], DatanodeInfoWithStorage[127.0.0.1:37165,DS-e4d27846-92ea-41ee-aab3-0b91af87c60d,DISK], DatanodeInfoWithStorage[127.0.0.1:37557,DS-f5ebeb0b-7a0c-430e-8191-121e7c43681f,DISK], DatanodeInfoWithStorage[127.0.0.1:39624,DS-aeb86824-60ab-40cf-b076-f5537fec92f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1337251947-172.17.0.19-1597675322795:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36987,DS-03cdeaf8-19e3-4be5-9459-01dbfed10616,DISK], DatanodeInfoWithStorage[127.0.0.1:36231,DS-28396b4b-5a62-48eb-92e4-972356005bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:43443,DS-38fd3eb9-91a8-4bd0-af47-2634cac932fd,DISK], DatanodeInfoWithStorage[127.0.0.1:32901,DS-23b1f2f3-db7d-4db0-a1d0-9e4aa92bfbf9,DISK], DatanodeInfoWithStorage[127.0.0.1:44992,DS-2664ba6c-359c-4955-9f89-01731f178adb,DISK], DatanodeInfoWithStorage[127.0.0.1:46553,DS-f1736c19-2d25-4da2-8620-68b5937d65f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43796,DS-87fd6f68-1d05-42e7-b059-abe92fbc3a07,DISK], DatanodeInfoWithStorage[127.0.0.1:45097,DS-b2174e6a-7542-4032-963e-ddcaa879b98e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1337251947-172.17.0.19-1597675322795:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36987,DS-03cdeaf8-19e3-4be5-9459-01dbfed10616,DISK], DatanodeInfoWithStorage[127.0.0.1:36231,DS-28396b4b-5a62-48eb-92e4-972356005bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:43443,DS-38fd3eb9-91a8-4bd0-af47-2634cac932fd,DISK], DatanodeInfoWithStorage[127.0.0.1:32901,DS-23b1f2f3-db7d-4db0-a1d0-9e4aa92bfbf9,DISK], DatanodeInfoWithStorage[127.0.0.1:44992,DS-2664ba6c-359c-4955-9f89-01731f178adb,DISK], DatanodeInfoWithStorage[127.0.0.1:46553,DS-f1736c19-2d25-4da2-8620-68b5937d65f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43796,DS-87fd6f68-1d05-42e7-b059-abe92fbc3a07,DISK], DatanodeInfoWithStorage[127.0.0.1:45097,DS-b2174e6a-7542-4032-963e-ddcaa879b98e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-878280787-172.17.0.19-1597675769902:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34448,DS-2363d733-4ce5-4a3e-9c50-556e30d0fffe,DISK], DatanodeInfoWithStorage[127.0.0.1:36459,DS-bd8765ad-85fb-4776-9057-a980ca47e77f,DISK], DatanodeInfoWithStorage[127.0.0.1:34850,DS-f28d12f5-6dec-42ce-8b08-83137481bbbc,DISK], DatanodeInfoWithStorage[127.0.0.1:42829,DS-68dacb84-8523-4941-9734-6590decd5794,DISK], DatanodeInfoWithStorage[127.0.0.1:37361,DS-65c69894-2a2f-409c-aec6-d3072b138431,DISK], DatanodeInfoWithStorage[127.0.0.1:39260,DS-6f69dde8-e264-40bf-8fa1-b3fe43694d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38276,DS-b1e5901b-95c5-4723-813e-305438543ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:43973,DS-7d4592cb-199b-468f-889e-eff842576a1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-878280787-172.17.0.19-1597675769902:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34448,DS-2363d733-4ce5-4a3e-9c50-556e30d0fffe,DISK], DatanodeInfoWithStorage[127.0.0.1:36459,DS-bd8765ad-85fb-4776-9057-a980ca47e77f,DISK], DatanodeInfoWithStorage[127.0.0.1:34850,DS-f28d12f5-6dec-42ce-8b08-83137481bbbc,DISK], DatanodeInfoWithStorage[127.0.0.1:42829,DS-68dacb84-8523-4941-9734-6590decd5794,DISK], DatanodeInfoWithStorage[127.0.0.1:37361,DS-65c69894-2a2f-409c-aec6-d3072b138431,DISK], DatanodeInfoWithStorage[127.0.0.1:39260,DS-6f69dde8-e264-40bf-8fa1-b3fe43694d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38276,DS-b1e5901b-95c5-4723-813e-305438543ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:43973,DS-7d4592cb-199b-468f-889e-eff842576a1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2014420799-172.17.0.19-1597676437909:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38061,DS-d2a53fd7-6f80-44be-bec2-5115a9fb8e24,DISK], DatanodeInfoWithStorage[127.0.0.1:33818,DS-2602e4d7-7d2d-434c-8680-42d9dc0b1b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:33004,DS-e90ded69-7903-4a8f-85db-3b569c8bd873,DISK], DatanodeInfoWithStorage[127.0.0.1:37235,DS-51861005-7551-4d0d-af01-d7114f641e58,DISK], DatanodeInfoWithStorage[127.0.0.1:36710,DS-2d840fa5-06fc-44b1-b6f1-f331a2a07156,DISK], DatanodeInfoWithStorage[127.0.0.1:37257,DS-cc86654d-00b7-498c-8dde-0975dca2e48b,DISK], DatanodeInfoWithStorage[127.0.0.1:35331,DS-fbcd2d37-b746-4d3c-a1b3-e80eb2e5ec5c,DISK], DatanodeInfoWithStorage[127.0.0.1:45501,DS-91afdcd3-d022-4c52-870e-3c6a7f2ca2fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2014420799-172.17.0.19-1597676437909:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38061,DS-d2a53fd7-6f80-44be-bec2-5115a9fb8e24,DISK], DatanodeInfoWithStorage[127.0.0.1:33818,DS-2602e4d7-7d2d-434c-8680-42d9dc0b1b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:33004,DS-e90ded69-7903-4a8f-85db-3b569c8bd873,DISK], DatanodeInfoWithStorage[127.0.0.1:37235,DS-51861005-7551-4d0d-af01-d7114f641e58,DISK], DatanodeInfoWithStorage[127.0.0.1:36710,DS-2d840fa5-06fc-44b1-b6f1-f331a2a07156,DISK], DatanodeInfoWithStorage[127.0.0.1:37257,DS-cc86654d-00b7-498c-8dde-0975dca2e48b,DISK], DatanodeInfoWithStorage[127.0.0.1:35331,DS-fbcd2d37-b746-4d3c-a1b3-e80eb2e5ec5c,DISK], DatanodeInfoWithStorage[127.0.0.1:45501,DS-91afdcd3-d022-4c52-870e-3c6a7f2ca2fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2057596755-172.17.0.19-1597676646794:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41974,DS-e1f40901-a97b-4410-93b7-6e037e0ffac5,DISK], DatanodeInfoWithStorage[127.0.0.1:43597,DS-3442053a-d9fe-49c2-aeaa-ffb217e03636,DISK], DatanodeInfoWithStorage[127.0.0.1:44873,DS-62e904a7-8605-41fd-8bbc-dc39a056bd6f,DISK], DatanodeInfoWithStorage[127.0.0.1:37885,DS-8b22d3e3-d3cd-456a-b7f2-821fe1bab6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43797,DS-67f55689-d048-4920-8904-5f7df6c0719a,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-ddb9bfbc-784f-4425-9901-31341b4ea9db,DISK], DatanodeInfoWithStorage[127.0.0.1:43577,DS-b653dd7e-03a2-4f49-a8e1-684f579a7963,DISK], DatanodeInfoWithStorage[127.0.0.1:41344,DS-ec86fafb-ea7f-4e9d-9d85-8e90066c0304,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2057596755-172.17.0.19-1597676646794:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41974,DS-e1f40901-a97b-4410-93b7-6e037e0ffac5,DISK], DatanodeInfoWithStorage[127.0.0.1:43597,DS-3442053a-d9fe-49c2-aeaa-ffb217e03636,DISK], DatanodeInfoWithStorage[127.0.0.1:44873,DS-62e904a7-8605-41fd-8bbc-dc39a056bd6f,DISK], DatanodeInfoWithStorage[127.0.0.1:37885,DS-8b22d3e3-d3cd-456a-b7f2-821fe1bab6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43797,DS-67f55689-d048-4920-8904-5f7df6c0719a,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-ddb9bfbc-784f-4425-9901-31341b4ea9db,DISK], DatanodeInfoWithStorage[127.0.0.1:43577,DS-b653dd7e-03a2-4f49-a8e1-684f579a7963,DISK], DatanodeInfoWithStorage[127.0.0.1:41344,DS-ec86fafb-ea7f-4e9d-9d85-8e90066c0304,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-335066831-172.17.0.19-1597676687337:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43993,DS-6f352a9b-01f4-49a2-89dd-3495f856f22e,DISK], DatanodeInfoWithStorage[127.0.0.1:42518,DS-b2a5cfbd-ee09-48b3-8dd2-ec6b1e16ee4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38815,DS-cc62218a-3649-4d63-a4f6-7c49fb0c915b,DISK], DatanodeInfoWithStorage[127.0.0.1:34982,DS-e9c59515-ff7b-4a68-9689-6e0f70895012,DISK], DatanodeInfoWithStorage[127.0.0.1:45297,DS-7709b670-7b5f-4efe-b084-8e7c0ef9be90,DISK], DatanodeInfoWithStorage[127.0.0.1:45800,DS-5373fb88-ba60-42e4-9afc-809a91251df5,DISK], DatanodeInfoWithStorage[127.0.0.1:45406,DS-3e6a00cf-02b9-4843-aeca-00dfa13b1e0b,DISK], DatanodeInfoWithStorage[127.0.0.1:43524,DS-180dad73-290b-4112-919d-1e2359d8f79b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-335066831-172.17.0.19-1597676687337:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43993,DS-6f352a9b-01f4-49a2-89dd-3495f856f22e,DISK], DatanodeInfoWithStorage[127.0.0.1:42518,DS-b2a5cfbd-ee09-48b3-8dd2-ec6b1e16ee4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38815,DS-cc62218a-3649-4d63-a4f6-7c49fb0c915b,DISK], DatanodeInfoWithStorage[127.0.0.1:34982,DS-e9c59515-ff7b-4a68-9689-6e0f70895012,DISK], DatanodeInfoWithStorage[127.0.0.1:45297,DS-7709b670-7b5f-4efe-b084-8e7c0ef9be90,DISK], DatanodeInfoWithStorage[127.0.0.1:45800,DS-5373fb88-ba60-42e4-9afc-809a91251df5,DISK], DatanodeInfoWithStorage[127.0.0.1:45406,DS-3e6a00cf-02b9-4843-aeca-00dfa13b1e0b,DISK], DatanodeInfoWithStorage[127.0.0.1:43524,DS-180dad73-290b-4112-919d-1e2359d8f79b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-367836135-172.17.0.19-1597676977795:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43554,DS-b45993a3-b877-4f98-86c0-53e73d1f0324,DISK], DatanodeInfoWithStorage[127.0.0.1:41886,DS-b93099bb-943c-4083-b447-17effef21f97,DISK], DatanodeInfoWithStorage[127.0.0.1:33850,DS-decd3cf7-6632-44ac-a683-1066ef817ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:39046,DS-d8e648ea-82ff-4aff-aa05-13a5afd2df1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44808,DS-057f2bc8-089c-4b6a-8ea7-d67179b5999c,DISK], DatanodeInfoWithStorage[127.0.0.1:36438,DS-184a75e4-629b-4be2-b96b-cee641a35838,DISK], DatanodeInfoWithStorage[127.0.0.1:37887,DS-e4b72614-2bdd-4228-8355-de1b962df482,DISK], DatanodeInfoWithStorage[127.0.0.1:42401,DS-168fcdcd-2e6d-4b75-bc83-1ff15f4c2a9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-367836135-172.17.0.19-1597676977795:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43554,DS-b45993a3-b877-4f98-86c0-53e73d1f0324,DISK], DatanodeInfoWithStorage[127.0.0.1:41886,DS-b93099bb-943c-4083-b447-17effef21f97,DISK], DatanodeInfoWithStorage[127.0.0.1:33850,DS-decd3cf7-6632-44ac-a683-1066ef817ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:39046,DS-d8e648ea-82ff-4aff-aa05-13a5afd2df1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44808,DS-057f2bc8-089c-4b6a-8ea7-d67179b5999c,DISK], DatanodeInfoWithStorage[127.0.0.1:36438,DS-184a75e4-629b-4be2-b96b-cee641a35838,DISK], DatanodeInfoWithStorage[127.0.0.1:37887,DS-e4b72614-2bdd-4228-8355-de1b962df482,DISK], DatanodeInfoWithStorage[127.0.0.1:42401,DS-168fcdcd-2e6d-4b75-bc83-1ff15f4c2a9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1454757844-172.17.0.19-1597677186307:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38250,DS-75b50f0c-a6ea-4e06-b861-2c6dd3af087e,DISK], DatanodeInfoWithStorage[127.0.0.1:36336,DS-bbb87b1c-3b8f-4740-8193-239bcb6b5e85,DISK], DatanodeInfoWithStorage[127.0.0.1:40879,DS-ed7af6ab-3bcb-4fd6-9458-f85aa9020f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44644,DS-b9e30ab7-8327-4fb7-8564-6199f17c3ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:40692,DS-8f20341c-deb4-43b9-882a-fe400727824b,DISK], DatanodeInfoWithStorage[127.0.0.1:45204,DS-7ca2c33c-8389-434e-a55d-02d2bee5f580,DISK], DatanodeInfoWithStorage[127.0.0.1:35517,DS-277942a3-203d-482b-9e0d-3016c1c65331,DISK], DatanodeInfoWithStorage[127.0.0.1:37346,DS-071f9073-039c-4f65-aec0-cbb2cf55a360,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1454757844-172.17.0.19-1597677186307:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38250,DS-75b50f0c-a6ea-4e06-b861-2c6dd3af087e,DISK], DatanodeInfoWithStorage[127.0.0.1:36336,DS-bbb87b1c-3b8f-4740-8193-239bcb6b5e85,DISK], DatanodeInfoWithStorage[127.0.0.1:40879,DS-ed7af6ab-3bcb-4fd6-9458-f85aa9020f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44644,DS-b9e30ab7-8327-4fb7-8564-6199f17c3ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:40692,DS-8f20341c-deb4-43b9-882a-fe400727824b,DISK], DatanodeInfoWithStorage[127.0.0.1:45204,DS-7ca2c33c-8389-434e-a55d-02d2bee5f580,DISK], DatanodeInfoWithStorage[127.0.0.1:35517,DS-277942a3-203d-482b-9e0d-3016c1c65331,DISK], DatanodeInfoWithStorage[127.0.0.1:37346,DS-071f9073-039c-4f65-aec0-cbb2cf55a360,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-304285434-172.17.0.19-1597677878887:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36123,DS-3c5f7c71-f501-4cfc-8f00-1f94987677be,DISK], DatanodeInfoWithStorage[127.0.0.1:34830,DS-7c5c30f6-84fc-4f2d-8e7f-3987bd01b7d8,DISK], DatanodeInfoWithStorage[127.0.0.1:32780,DS-1683e8cb-56f1-48aa-815f-d4d321b94485,DISK], DatanodeInfoWithStorage[127.0.0.1:37346,DS-f5d16bd6-0a58-4fe4-9691-aa08f67f52f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36798,DS-06274376-d61b-4bc4-ba24-46c931f86915,DISK], DatanodeInfoWithStorage[127.0.0.1:33927,DS-3703b005-e063-46a7-a96a-f3be747610bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37700,DS-5eab58c6-110d-4d01-b32c-647922d2a9e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44709,DS-6f0ebc7c-5bf2-4fc7-8814-8d1780883f56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-304285434-172.17.0.19-1597677878887:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36123,DS-3c5f7c71-f501-4cfc-8f00-1f94987677be,DISK], DatanodeInfoWithStorage[127.0.0.1:34830,DS-7c5c30f6-84fc-4f2d-8e7f-3987bd01b7d8,DISK], DatanodeInfoWithStorage[127.0.0.1:32780,DS-1683e8cb-56f1-48aa-815f-d4d321b94485,DISK], DatanodeInfoWithStorage[127.0.0.1:37346,DS-f5d16bd6-0a58-4fe4-9691-aa08f67f52f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36798,DS-06274376-d61b-4bc4-ba24-46c931f86915,DISK], DatanodeInfoWithStorage[127.0.0.1:33927,DS-3703b005-e063-46a7-a96a-f3be747610bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37700,DS-5eab58c6-110d-4d01-b32c-647922d2a9e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44709,DS-6f0ebc7c-5bf2-4fc7-8814-8d1780883f56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2027426431-172.17.0.19-1597678739600:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43418,DS-e488ffb9-4058-431c-90e0-d65fca805dac,DISK], DatanodeInfoWithStorage[127.0.0.1:45500,DS-3eed2902-f058-48bc-91cf-d2d17c464de1,DISK], DatanodeInfoWithStorage[127.0.0.1:43461,DS-7b244154-cba2-4c7d-8944-f8bf7435ac76,DISK], DatanodeInfoWithStorage[127.0.0.1:36022,DS-0be1af39-a7c7-4c72-bfd2-64fd20913147,DISK], DatanodeInfoWithStorage[127.0.0.1:39742,DS-28eb5c80-78ac-452b-b0be-34cb8869a257,DISK], DatanodeInfoWithStorage[127.0.0.1:39977,DS-ba526aa8-7563-4b58-a6d4-03b0ecaefe20,DISK], DatanodeInfoWithStorage[127.0.0.1:42350,DS-d20f228d-4088-4670-8e5d-16a3d706d22b,DISK], DatanodeInfoWithStorage[127.0.0.1:32894,DS-5a127f2f-955f-49fe-8c25-46b98fb35556,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2027426431-172.17.0.19-1597678739600:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43418,DS-e488ffb9-4058-431c-90e0-d65fca805dac,DISK], DatanodeInfoWithStorage[127.0.0.1:45500,DS-3eed2902-f058-48bc-91cf-d2d17c464de1,DISK], DatanodeInfoWithStorage[127.0.0.1:43461,DS-7b244154-cba2-4c7d-8944-f8bf7435ac76,DISK], DatanodeInfoWithStorage[127.0.0.1:36022,DS-0be1af39-a7c7-4c72-bfd2-64fd20913147,DISK], DatanodeInfoWithStorage[127.0.0.1:39742,DS-28eb5c80-78ac-452b-b0be-34cb8869a257,DISK], DatanodeInfoWithStorage[127.0.0.1:39977,DS-ba526aa8-7563-4b58-a6d4-03b0ecaefe20,DISK], DatanodeInfoWithStorage[127.0.0.1:42350,DS-d20f228d-4088-4670-8e5d-16a3d706d22b,DISK], DatanodeInfoWithStorage[127.0.0.1:32894,DS-5a127f2f-955f-49fe-8c25-46b98fb35556,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1580998836-172.17.0.19-1597678996458:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43444,DS-8b708004-6f18-4033-9d66-c132adbe3a22,DISK], DatanodeInfoWithStorage[127.0.0.1:36956,DS-e155c080-0ce2-403f-aa2a-93c90be6f7d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46414,DS-92dd51f3-22cc-4325-9ef0-10e42c00675c,DISK], DatanodeInfoWithStorage[127.0.0.1:37585,DS-4f58d687-d091-4392-b23e-2c3e9ae8d900,DISK], DatanodeInfoWithStorage[127.0.0.1:46843,DS-b56f1fd0-ee9e-4906-a756-63ee82c58fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:35421,DS-e4c94675-b483-4b0a-a631-7280636ede05,DISK], DatanodeInfoWithStorage[127.0.0.1:35673,DS-c3e4fa32-db9b-46ec-89f0-235d5f2d8c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33791,DS-a950c187-5573-4f6f-a375-3fe0312139e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1580998836-172.17.0.19-1597678996458:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43444,DS-8b708004-6f18-4033-9d66-c132adbe3a22,DISK], DatanodeInfoWithStorage[127.0.0.1:36956,DS-e155c080-0ce2-403f-aa2a-93c90be6f7d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46414,DS-92dd51f3-22cc-4325-9ef0-10e42c00675c,DISK], DatanodeInfoWithStorage[127.0.0.1:37585,DS-4f58d687-d091-4392-b23e-2c3e9ae8d900,DISK], DatanodeInfoWithStorage[127.0.0.1:46843,DS-b56f1fd0-ee9e-4906-a756-63ee82c58fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:35421,DS-e4c94675-b483-4b0a-a631-7280636ede05,DISK], DatanodeInfoWithStorage[127.0.0.1:35673,DS-c3e4fa32-db9b-46ec-89f0-235d5f2d8c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33791,DS-a950c187-5573-4f6f-a375-3fe0312139e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 7388
