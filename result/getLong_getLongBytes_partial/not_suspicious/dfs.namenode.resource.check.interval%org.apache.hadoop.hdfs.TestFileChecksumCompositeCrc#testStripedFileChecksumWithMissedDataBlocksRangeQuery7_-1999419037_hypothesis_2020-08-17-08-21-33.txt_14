reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-733252603-172.17.0.16-1597652616205:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40077,DS-385514ed-d997-47e1-974e-cb8547a5528b,DISK], DatanodeInfoWithStorage[127.0.0.1:33411,DS-7225e228-3688-4af9-9f61-eb899f401554,DISK], DatanodeInfoWithStorage[127.0.0.1:37040,DS-5e62171e-be6e-463d-b5de-a3da5cb3599b,DISK], DatanodeInfoWithStorage[127.0.0.1:39022,DS-fdba259b-4ce4-406b-a632-1475462d55bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40199,DS-a5344816-9e54-48f9-9dd0-a44ea2402fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:34658,DS-9ce3a90a-fac1-42a0-b7f6-8e3b9ef25af2,DISK], DatanodeInfoWithStorage[127.0.0.1:43794,DS-88f6b110-d705-44ef-a228-d923a97bc15e,DISK], DatanodeInfoWithStorage[127.0.0.1:43610,DS-1eb30ab3-986e-4c6a-a181-0d331f5be4c2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-733252603-172.17.0.16-1597652616205:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40077,DS-385514ed-d997-47e1-974e-cb8547a5528b,DISK], DatanodeInfoWithStorage[127.0.0.1:33411,DS-7225e228-3688-4af9-9f61-eb899f401554,DISK], DatanodeInfoWithStorage[127.0.0.1:37040,DS-5e62171e-be6e-463d-b5de-a3da5cb3599b,DISK], DatanodeInfoWithStorage[127.0.0.1:39022,DS-fdba259b-4ce4-406b-a632-1475462d55bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40199,DS-a5344816-9e54-48f9-9dd0-a44ea2402fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:34658,DS-9ce3a90a-fac1-42a0-b7f6-8e3b9ef25af2,DISK], DatanodeInfoWithStorage[127.0.0.1:43794,DS-88f6b110-d705-44ef-a228-d923a97bc15e,DISK], DatanodeInfoWithStorage[127.0.0.1:43610,DS-1eb30ab3-986e-4c6a-a181-0d331f5be4c2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1713404070-172.17.0.16-1597652653293:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38403,DS-ea6cae5b-cb8c-4093-9130-dcd88c256eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:35223,DS-91e48f2a-2518-476e-8e9c-48a4dea454a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36151,DS-f644f40b-33c9-4be3-8a7a-80a86e300ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:35645,DS-4a15cfa6-b106-4bb3-b0fa-8a028fc84967,DISK], DatanodeInfoWithStorage[127.0.0.1:35758,DS-3a835246-653f-427e-a3b7-0f2f97378faf,DISK], DatanodeInfoWithStorage[127.0.0.1:33282,DS-3e19b6ba-a249-4a5e-9afd-7ddccdde32d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37919,DS-6a7965e6-fff2-40df-b27c-898f8ab51f24,DISK], DatanodeInfoWithStorage[127.0.0.1:33035,DS-6c8ff367-fa27-4ce3-bdef-e1d634909571,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1713404070-172.17.0.16-1597652653293:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38403,DS-ea6cae5b-cb8c-4093-9130-dcd88c256eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:35223,DS-91e48f2a-2518-476e-8e9c-48a4dea454a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36151,DS-f644f40b-33c9-4be3-8a7a-80a86e300ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:35645,DS-4a15cfa6-b106-4bb3-b0fa-8a028fc84967,DISK], DatanodeInfoWithStorage[127.0.0.1:35758,DS-3a835246-653f-427e-a3b7-0f2f97378faf,DISK], DatanodeInfoWithStorage[127.0.0.1:33282,DS-3e19b6ba-a249-4a5e-9afd-7ddccdde32d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37919,DS-6a7965e6-fff2-40df-b27c-898f8ab51f24,DISK], DatanodeInfoWithStorage[127.0.0.1:33035,DS-6c8ff367-fa27-4ce3-bdef-e1d634909571,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-632674311-172.17.0.16-1597652691485:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45009,DS-c8e3c2b3-2d5c-425f-954e-9b91d6508abd,DISK], DatanodeInfoWithStorage[127.0.0.1:43763,DS-732f0d0b-a880-467b-8ff3-32deb4f89b97,DISK], DatanodeInfoWithStorage[127.0.0.1:35023,DS-204aaa1a-4ce7-4165-ac43-9d3af482f55e,DISK], DatanodeInfoWithStorage[127.0.0.1:35771,DS-02a5d869-c807-4fe1-a633-f5dab761f608,DISK], DatanodeInfoWithStorage[127.0.0.1:46828,DS-f6208550-6f44-4a7a-b601-23b9afea701a,DISK], DatanodeInfoWithStorage[127.0.0.1:43140,DS-b02042e3-7442-43d9-ab7a-d2ad11919ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:45934,DS-034a906c-ed82-48d1-b0b0-5e001a9a6d53,DISK], DatanodeInfoWithStorage[127.0.0.1:44128,DS-331f4106-aa88-47d7-841e-197b25cc22f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-632674311-172.17.0.16-1597652691485:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45009,DS-c8e3c2b3-2d5c-425f-954e-9b91d6508abd,DISK], DatanodeInfoWithStorage[127.0.0.1:43763,DS-732f0d0b-a880-467b-8ff3-32deb4f89b97,DISK], DatanodeInfoWithStorage[127.0.0.1:35023,DS-204aaa1a-4ce7-4165-ac43-9d3af482f55e,DISK], DatanodeInfoWithStorage[127.0.0.1:35771,DS-02a5d869-c807-4fe1-a633-f5dab761f608,DISK], DatanodeInfoWithStorage[127.0.0.1:46828,DS-f6208550-6f44-4a7a-b601-23b9afea701a,DISK], DatanodeInfoWithStorage[127.0.0.1:43140,DS-b02042e3-7442-43d9-ab7a-d2ad11919ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:45934,DS-034a906c-ed82-48d1-b0b0-5e001a9a6d53,DISK], DatanodeInfoWithStorage[127.0.0.1:44128,DS-331f4106-aa88-47d7-841e-197b25cc22f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1498253761-172.17.0.16-1597652875974:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43698,DS-7308fda3-9edd-4187-b8a2-cfc0099e0399,DISK], DatanodeInfoWithStorage[127.0.0.1:42704,DS-764b6452-1356-466f-bb29-0212d3c9e4e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36075,DS-cf5d1069-d703-48de-8fd9-fa9e7ebb301f,DISK], DatanodeInfoWithStorage[127.0.0.1:45578,DS-e8707f72-d992-412c-b36f-1fa7c456b645,DISK], DatanodeInfoWithStorage[127.0.0.1:43491,DS-ac23ebbe-c5b8-406d-9969-c4d6fe4255ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37532,DS-2f430b81-ffe0-4ebe-b3b6-1909ef2f22b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37636,DS-4a0ea2d5-f051-442d-aab5-d4911a0fef36,DISK], DatanodeInfoWithStorage[127.0.0.1:33140,DS-a9fc12b8-c20c-4bd4-9153-3541e1a58c61,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1498253761-172.17.0.16-1597652875974:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43698,DS-7308fda3-9edd-4187-b8a2-cfc0099e0399,DISK], DatanodeInfoWithStorage[127.0.0.1:42704,DS-764b6452-1356-466f-bb29-0212d3c9e4e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36075,DS-cf5d1069-d703-48de-8fd9-fa9e7ebb301f,DISK], DatanodeInfoWithStorage[127.0.0.1:45578,DS-e8707f72-d992-412c-b36f-1fa7c456b645,DISK], DatanodeInfoWithStorage[127.0.0.1:43491,DS-ac23ebbe-c5b8-406d-9969-c4d6fe4255ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37532,DS-2f430b81-ffe0-4ebe-b3b6-1909ef2f22b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37636,DS-4a0ea2d5-f051-442d-aab5-d4911a0fef36,DISK], DatanodeInfoWithStorage[127.0.0.1:33140,DS-a9fc12b8-c20c-4bd4-9153-3541e1a58c61,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1281408643-172.17.0.16-1597653176405:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43210,DS-a2bb167e-f0be-4ee9-bb15-27ffc1bd2a66,DISK], DatanodeInfoWithStorage[127.0.0.1:35456,DS-008df90e-0338-42c6-9157-2404b63bed5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45539,DS-7a9f513c-ad44-4fc9-a1bc-e1a41ed73c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:37734,DS-9ddca94c-c7e1-44c2-b01d-7639d211fd5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34810,DS-3d7f2468-d45b-4b69-9575-88df85faa0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39261,DS-587a92f7-e53b-4d69-84e7-ddaea5f1beb3,DISK], DatanodeInfoWithStorage[127.0.0.1:40152,DS-df79c274-897d-4b56-8126-e28a23ebf95b,DISK], DatanodeInfoWithStorage[127.0.0.1:32990,DS-5737a6e2-28f4-400c-b71d-8c07fcdfa43c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1281408643-172.17.0.16-1597653176405:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43210,DS-a2bb167e-f0be-4ee9-bb15-27ffc1bd2a66,DISK], DatanodeInfoWithStorage[127.0.0.1:35456,DS-008df90e-0338-42c6-9157-2404b63bed5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45539,DS-7a9f513c-ad44-4fc9-a1bc-e1a41ed73c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:37734,DS-9ddca94c-c7e1-44c2-b01d-7639d211fd5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34810,DS-3d7f2468-d45b-4b69-9575-88df85faa0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39261,DS-587a92f7-e53b-4d69-84e7-ddaea5f1beb3,DISK], DatanodeInfoWithStorage[127.0.0.1:40152,DS-df79c274-897d-4b56-8126-e28a23ebf95b,DISK], DatanodeInfoWithStorage[127.0.0.1:32990,DS-5737a6e2-28f4-400c-b71d-8c07fcdfa43c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1087668612-172.17.0.16-1597653212229:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42027,DS-01f83903-c70e-4d4d-921e-82cb8f4f5dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:34475,DS-7662fcf1-2a4f-4310-ab8e-c89a4df4ce5f,DISK], DatanodeInfoWithStorage[127.0.0.1:44057,DS-a7109705-3f69-4f1b-985c-4f27fd158507,DISK], DatanodeInfoWithStorage[127.0.0.1:43186,DS-e9798cb3-1d91-4141-ab17-8414ba5cfb8a,DISK], DatanodeInfoWithStorage[127.0.0.1:36131,DS-4a03a6e7-e17a-450b-8fdf-ebcd2924b541,DISK], DatanodeInfoWithStorage[127.0.0.1:40212,DS-5c03d82b-b5a6-4af4-bbd5-794d336e3b42,DISK], DatanodeInfoWithStorage[127.0.0.1:37840,DS-aabc2011-5015-423f-8394-20d0816eee10,DISK], DatanodeInfoWithStorage[127.0.0.1:36557,DS-7fef4cd2-504d-4b0c-89f9-65fd2a7a9223,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1087668612-172.17.0.16-1597653212229:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42027,DS-01f83903-c70e-4d4d-921e-82cb8f4f5dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:34475,DS-7662fcf1-2a4f-4310-ab8e-c89a4df4ce5f,DISK], DatanodeInfoWithStorage[127.0.0.1:44057,DS-a7109705-3f69-4f1b-985c-4f27fd158507,DISK], DatanodeInfoWithStorage[127.0.0.1:43186,DS-e9798cb3-1d91-4141-ab17-8414ba5cfb8a,DISK], DatanodeInfoWithStorage[127.0.0.1:36131,DS-4a03a6e7-e17a-450b-8fdf-ebcd2924b541,DISK], DatanodeInfoWithStorage[127.0.0.1:40212,DS-5c03d82b-b5a6-4af4-bbd5-794d336e3b42,DISK], DatanodeInfoWithStorage[127.0.0.1:37840,DS-aabc2011-5015-423f-8394-20d0816eee10,DISK], DatanodeInfoWithStorage[127.0.0.1:36557,DS-7fef4cd2-504d-4b0c-89f9-65fd2a7a9223,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-849423872-172.17.0.16-1597653252506:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40290,DS-aafdd46c-b1ff-462d-ae4c-1e055d32a27f,DISK], DatanodeInfoWithStorage[127.0.0.1:37238,DS-234180e4-763c-4d1d-ade3-ff754a44069a,DISK], DatanodeInfoWithStorage[127.0.0.1:43610,DS-cb465a83-5453-4902-b0fa-20bf274a79f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44875,DS-3198ac34-b875-4d12-a9ea-3fbf1c5b758c,DISK], DatanodeInfoWithStorage[127.0.0.1:43076,DS-9c7d20b4-0de1-4bbc-9474-b6901ae74b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41172,DS-b20739d3-9b7d-4152-98ca-3eaf217e65be,DISK], DatanodeInfoWithStorage[127.0.0.1:42956,DS-1429415d-9043-4d72-8c72-7cd148687a86,DISK], DatanodeInfoWithStorage[127.0.0.1:42368,DS-0c57b14b-f634-4b9c-b53f-60cf566010fc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-849423872-172.17.0.16-1597653252506:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40290,DS-aafdd46c-b1ff-462d-ae4c-1e055d32a27f,DISK], DatanodeInfoWithStorage[127.0.0.1:37238,DS-234180e4-763c-4d1d-ade3-ff754a44069a,DISK], DatanodeInfoWithStorage[127.0.0.1:43610,DS-cb465a83-5453-4902-b0fa-20bf274a79f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44875,DS-3198ac34-b875-4d12-a9ea-3fbf1c5b758c,DISK], DatanodeInfoWithStorage[127.0.0.1:43076,DS-9c7d20b4-0de1-4bbc-9474-b6901ae74b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41172,DS-b20739d3-9b7d-4152-98ca-3eaf217e65be,DISK], DatanodeInfoWithStorage[127.0.0.1:42956,DS-1429415d-9043-4d72-8c72-7cd148687a86,DISK], DatanodeInfoWithStorage[127.0.0.1:42368,DS-0c57b14b-f634-4b9c-b53f-60cf566010fc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-428554520-172.17.0.16-1597653358638:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37202,DS-76899305-64c4-40eb-802b-9b9e5ee7ccc7,DISK], DatanodeInfoWithStorage[127.0.0.1:36868,DS-5938c5a1-79f8-46b5-9b6d-a85a60e3f27f,DISK], DatanodeInfoWithStorage[127.0.0.1:44441,DS-8e980ed9-c15f-46cf-ba92-3d102ff6d986,DISK], DatanodeInfoWithStorage[127.0.0.1:39675,DS-c616be95-efb7-4e0f-9dd3-c3e9b992fba3,DISK], DatanodeInfoWithStorage[127.0.0.1:34834,DS-8db1ce2b-aeb0-4683-ba77-b9db46224be7,DISK], DatanodeInfoWithStorage[127.0.0.1:35050,DS-60f3132f-0c7d-4672-a6c5-e7737f5d93ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37788,DS-1274ead1-fe11-426e-a5dd-3bc695082338,DISK], DatanodeInfoWithStorage[127.0.0.1:41622,DS-95047728-1bc2-4f62-9386-0e4841010778,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-428554520-172.17.0.16-1597653358638:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37202,DS-76899305-64c4-40eb-802b-9b9e5ee7ccc7,DISK], DatanodeInfoWithStorage[127.0.0.1:36868,DS-5938c5a1-79f8-46b5-9b6d-a85a60e3f27f,DISK], DatanodeInfoWithStorage[127.0.0.1:44441,DS-8e980ed9-c15f-46cf-ba92-3d102ff6d986,DISK], DatanodeInfoWithStorage[127.0.0.1:39675,DS-c616be95-efb7-4e0f-9dd3-c3e9b992fba3,DISK], DatanodeInfoWithStorage[127.0.0.1:34834,DS-8db1ce2b-aeb0-4683-ba77-b9db46224be7,DISK], DatanodeInfoWithStorage[127.0.0.1:35050,DS-60f3132f-0c7d-4672-a6c5-e7737f5d93ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37788,DS-1274ead1-fe11-426e-a5dd-3bc695082338,DISK], DatanodeInfoWithStorage[127.0.0.1:41622,DS-95047728-1bc2-4f62-9386-0e4841010778,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-251171173-172.17.0.16-1597653457579:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38821,DS-64a15737-b0cf-47b4-a640-d333ab33040a,DISK], DatanodeInfoWithStorage[127.0.0.1:45802,DS-604ff061-c28c-4419-927e-583960ad6c52,DISK], DatanodeInfoWithStorage[127.0.0.1:43663,DS-8319e2e0-6f8c-4412-8958-aed1667d6a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45605,DS-22e84e42-80c3-4ba5-a8f8-caa625f2be6a,DISK], DatanodeInfoWithStorage[127.0.0.1:42984,DS-9a7949a4-1449-4d8d-92c7-bf94820b8ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:41570,DS-3e661e69-ebcc-4fbf-8ddc-614f2c95d993,DISK], DatanodeInfoWithStorage[127.0.0.1:41080,DS-863dfb03-13ec-43e2-bfec-ea9ef172ef58,DISK], DatanodeInfoWithStorage[127.0.0.1:33044,DS-ca8c2b03-9156-4029-9972-b253570dd736,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-251171173-172.17.0.16-1597653457579:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38821,DS-64a15737-b0cf-47b4-a640-d333ab33040a,DISK], DatanodeInfoWithStorage[127.0.0.1:45802,DS-604ff061-c28c-4419-927e-583960ad6c52,DISK], DatanodeInfoWithStorage[127.0.0.1:43663,DS-8319e2e0-6f8c-4412-8958-aed1667d6a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45605,DS-22e84e42-80c3-4ba5-a8f8-caa625f2be6a,DISK], DatanodeInfoWithStorage[127.0.0.1:42984,DS-9a7949a4-1449-4d8d-92c7-bf94820b8ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:41570,DS-3e661e69-ebcc-4fbf-8ddc-614f2c95d993,DISK], DatanodeInfoWithStorage[127.0.0.1:41080,DS-863dfb03-13ec-43e2-bfec-ea9ef172ef58,DISK], DatanodeInfoWithStorage[127.0.0.1:33044,DS-ca8c2b03-9156-4029-9972-b253570dd736,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-234194141-172.17.0.16-1597653483104:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41918,DS-13a3f9aa-88ac-4e59-a0db-755b154f4b02,DISK], DatanodeInfoWithStorage[127.0.0.1:38393,DS-b810303c-9527-4831-8b9e-6a93a2c1b114,DISK], DatanodeInfoWithStorage[127.0.0.1:39475,DS-53fc77a1-cfa5-4fae-ab43-7e1a99d4ca32,DISK], DatanodeInfoWithStorage[127.0.0.1:35000,DS-6c74f5a1-861e-41b8-addc-341178b04003,DISK], DatanodeInfoWithStorage[127.0.0.1:46470,DS-6baa10fa-1ba4-47bc-9d14-e80fbd801c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:33085,DS-0800fa34-c171-4760-8aaa-89cbe03c8c51,DISK], DatanodeInfoWithStorage[127.0.0.1:33424,DS-88d6eca5-9322-4a61-b655-c79e15ea580d,DISK], DatanodeInfoWithStorage[127.0.0.1:38037,DS-33cccfc5-03ce-4426-a477-685fd0e32559,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-234194141-172.17.0.16-1597653483104:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41918,DS-13a3f9aa-88ac-4e59-a0db-755b154f4b02,DISK], DatanodeInfoWithStorage[127.0.0.1:38393,DS-b810303c-9527-4831-8b9e-6a93a2c1b114,DISK], DatanodeInfoWithStorage[127.0.0.1:39475,DS-53fc77a1-cfa5-4fae-ab43-7e1a99d4ca32,DISK], DatanodeInfoWithStorage[127.0.0.1:35000,DS-6c74f5a1-861e-41b8-addc-341178b04003,DISK], DatanodeInfoWithStorage[127.0.0.1:46470,DS-6baa10fa-1ba4-47bc-9d14-e80fbd801c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:33085,DS-0800fa34-c171-4760-8aaa-89cbe03c8c51,DISK], DatanodeInfoWithStorage[127.0.0.1:33424,DS-88d6eca5-9322-4a61-b655-c79e15ea580d,DISK], DatanodeInfoWithStorage[127.0.0.1:38037,DS-33cccfc5-03ce-4426-a477-685fd0e32559,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1891605438-172.17.0.16-1597653747753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36123,DS-823d76d4-9e94-4d3c-a843-e7f5740d85bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33782,DS-7ae2b46d-2ff5-4611-af55-c5c008e4d873,DISK], DatanodeInfoWithStorage[127.0.0.1:39415,DS-1b099ffb-6e95-48f7-ab8d-c8bab61b1ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:36659,DS-69734aa1-04cb-4788-833a-db613fdaaaf2,DISK], DatanodeInfoWithStorage[127.0.0.1:40039,DS-3e4ff988-5294-45b8-9fb6-212f06f1b105,DISK], DatanodeInfoWithStorage[127.0.0.1:45313,DS-1db93b0c-2f1d-46cd-a9b4-e8b64f0e6517,DISK], DatanodeInfoWithStorage[127.0.0.1:34655,DS-13cb7c6f-fc0c-403b-a17e-99e62d391ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:38847,DS-10daedaa-d124-443a-a350-0d5737e0f4c4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1891605438-172.17.0.16-1597653747753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36123,DS-823d76d4-9e94-4d3c-a843-e7f5740d85bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33782,DS-7ae2b46d-2ff5-4611-af55-c5c008e4d873,DISK], DatanodeInfoWithStorage[127.0.0.1:39415,DS-1b099ffb-6e95-48f7-ab8d-c8bab61b1ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:36659,DS-69734aa1-04cb-4788-833a-db613fdaaaf2,DISK], DatanodeInfoWithStorage[127.0.0.1:40039,DS-3e4ff988-5294-45b8-9fb6-212f06f1b105,DISK], DatanodeInfoWithStorage[127.0.0.1:45313,DS-1db93b0c-2f1d-46cd-a9b4-e8b64f0e6517,DISK], DatanodeInfoWithStorage[127.0.0.1:34655,DS-13cb7c6f-fc0c-403b-a17e-99e62d391ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:38847,DS-10daedaa-d124-443a-a350-0d5737e0f4c4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-775746888-172.17.0.16-1597653859919:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40724,DS-a3d17dc4-7bd0-47c2-ba19-255963e47a66,DISK], DatanodeInfoWithStorage[127.0.0.1:43569,DS-5ae9bca7-4cc4-4cc7-95a3-cc41cc3dcd2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43982,DS-eba1d958-efa5-4e6a-a785-cf1953b0e8f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41377,DS-235276fb-c373-4d88-927e-1ae781a64f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41822,DS-bc816215-1c5c-4e87-9fd5-b1ceca5ce320,DISK], DatanodeInfoWithStorage[127.0.0.1:43354,DS-d1306de2-41ff-40ca-8dbb-9c5ec107ba98,DISK], DatanodeInfoWithStorage[127.0.0.1:42553,DS-19291a9a-51f5-40ae-993f-0263966d5c10,DISK], DatanodeInfoWithStorage[127.0.0.1:39691,DS-2bfeb135-8874-476d-87f7-e38d06bb60e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-775746888-172.17.0.16-1597653859919:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40724,DS-a3d17dc4-7bd0-47c2-ba19-255963e47a66,DISK], DatanodeInfoWithStorage[127.0.0.1:43569,DS-5ae9bca7-4cc4-4cc7-95a3-cc41cc3dcd2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43982,DS-eba1d958-efa5-4e6a-a785-cf1953b0e8f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41377,DS-235276fb-c373-4d88-927e-1ae781a64f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41822,DS-bc816215-1c5c-4e87-9fd5-b1ceca5ce320,DISK], DatanodeInfoWithStorage[127.0.0.1:43354,DS-d1306de2-41ff-40ca-8dbb-9c5ec107ba98,DISK], DatanodeInfoWithStorage[127.0.0.1:42553,DS-19291a9a-51f5-40ae-993f-0263966d5c10,DISK], DatanodeInfoWithStorage[127.0.0.1:39691,DS-2bfeb135-8874-476d-87f7-e38d06bb60e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1575628540-172.17.0.16-1597654208930:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34037,DS-51c9cdfe-9ed1-41f2-8385-12bf02cfe304,DISK], DatanodeInfoWithStorage[127.0.0.1:34735,DS-fd679658-18d1-4929-8f97-60cf3f953428,DISK], DatanodeInfoWithStorage[127.0.0.1:41736,DS-ce186bd4-a9d9-4188-ad44-17b2550acf6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44386,DS-794a3868-2f95-4bd7-a610-90752fea520f,DISK], DatanodeInfoWithStorage[127.0.0.1:36437,DS-19c62277-95e9-4880-8801-5d66e50f70f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40632,DS-7deedc3d-3bf8-4bec-af68-0b85c2cdf84c,DISK], DatanodeInfoWithStorage[127.0.0.1:44324,DS-f1ce7459-87b2-4a24-b35b-5fcfb6296294,DISK], DatanodeInfoWithStorage[127.0.0.1:46342,DS-e64f5db4-a773-48cc-87b3-49e8f575df21,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1575628540-172.17.0.16-1597654208930:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34037,DS-51c9cdfe-9ed1-41f2-8385-12bf02cfe304,DISK], DatanodeInfoWithStorage[127.0.0.1:34735,DS-fd679658-18d1-4929-8f97-60cf3f953428,DISK], DatanodeInfoWithStorage[127.0.0.1:41736,DS-ce186bd4-a9d9-4188-ad44-17b2550acf6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44386,DS-794a3868-2f95-4bd7-a610-90752fea520f,DISK], DatanodeInfoWithStorage[127.0.0.1:36437,DS-19c62277-95e9-4880-8801-5d66e50f70f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40632,DS-7deedc3d-3bf8-4bec-af68-0b85c2cdf84c,DISK], DatanodeInfoWithStorage[127.0.0.1:44324,DS-f1ce7459-87b2-4a24-b35b-5fcfb6296294,DISK], DatanodeInfoWithStorage[127.0.0.1:46342,DS-e64f5db4-a773-48cc-87b3-49e8f575df21,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-232339347-172.17.0.16-1597654417255:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44822,DS-e67e34a9-357b-42e5-974e-46e3fdf3ab93,DISK], DatanodeInfoWithStorage[127.0.0.1:43333,DS-e9d2858a-81e1-48ee-a690-b9b13539fa2e,DISK], DatanodeInfoWithStorage[127.0.0.1:35101,DS-0c22f35f-34b0-46f7-8c69-2df92db7e1a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38554,DS-d578b713-d591-4dcd-9e5d-7f90e092cc4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46709,DS-091157aa-d33f-45ad-8bbf-dcd680167f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:44208,DS-fe10dacb-0ac2-4f44-8c32-82d6228683ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41156,DS-46f1aabb-4fe5-467e-af65-7209d6afce5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45493,DS-d7fede6b-9864-4707-bdd3-e3924a6bb59f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-232339347-172.17.0.16-1597654417255:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44822,DS-e67e34a9-357b-42e5-974e-46e3fdf3ab93,DISK], DatanodeInfoWithStorage[127.0.0.1:43333,DS-e9d2858a-81e1-48ee-a690-b9b13539fa2e,DISK], DatanodeInfoWithStorage[127.0.0.1:35101,DS-0c22f35f-34b0-46f7-8c69-2df92db7e1a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38554,DS-d578b713-d591-4dcd-9e5d-7f90e092cc4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46709,DS-091157aa-d33f-45ad-8bbf-dcd680167f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:44208,DS-fe10dacb-0ac2-4f44-8c32-82d6228683ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41156,DS-46f1aabb-4fe5-467e-af65-7209d6afce5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45493,DS-d7fede6b-9864-4707-bdd3-e3924a6bb59f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-175635441-172.17.0.16-1597654908848:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46475,DS-2159a316-29c1-40bf-8d30-8370daba4723,DISK], DatanodeInfoWithStorage[127.0.0.1:35243,DS-025a6dfa-53f0-45f5-a02d-9f38bc8eb3c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37013,DS-486c5ae8-a64a-4425-873c-976f0cad5170,DISK], DatanodeInfoWithStorage[127.0.0.1:42029,DS-1e39b893-74c1-4cfb-9507-7e3f94d6ceca,DISK], DatanodeInfoWithStorage[127.0.0.1:38060,DS-b781c544-216f-45d9-9c5d-10b8dc35dce9,DISK], DatanodeInfoWithStorage[127.0.0.1:33403,DS-40d41cfa-e362-47c9-99eb-0d8f3c24dfc7,DISK], DatanodeInfoWithStorage[127.0.0.1:38653,DS-5e6047c1-c6a0-4bd8-99ed-782330e9974d,DISK], DatanodeInfoWithStorage[127.0.0.1:36072,DS-46e735ef-cdca-4fdf-b29b-2e9f25986152,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-175635441-172.17.0.16-1597654908848:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46475,DS-2159a316-29c1-40bf-8d30-8370daba4723,DISK], DatanodeInfoWithStorage[127.0.0.1:35243,DS-025a6dfa-53f0-45f5-a02d-9f38bc8eb3c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37013,DS-486c5ae8-a64a-4425-873c-976f0cad5170,DISK], DatanodeInfoWithStorage[127.0.0.1:42029,DS-1e39b893-74c1-4cfb-9507-7e3f94d6ceca,DISK], DatanodeInfoWithStorage[127.0.0.1:38060,DS-b781c544-216f-45d9-9c5d-10b8dc35dce9,DISK], DatanodeInfoWithStorage[127.0.0.1:33403,DS-40d41cfa-e362-47c9-99eb-0d8f3c24dfc7,DISK], DatanodeInfoWithStorage[127.0.0.1:38653,DS-5e6047c1-c6a0-4bd8-99ed-782330e9974d,DISK], DatanodeInfoWithStorage[127.0.0.1:36072,DS-46e735ef-cdca-4fdf-b29b-2e9f25986152,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-566311644-172.17.0.16-1597654946372:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40246,DS-5fcb57b2-a690-47d7-a0ae-8287162ccef1,DISK], DatanodeInfoWithStorage[127.0.0.1:43174,DS-bdd67110-e5fb-406e-8e1a-b8cc8f2b414c,DISK], DatanodeInfoWithStorage[127.0.0.1:43741,DS-6c818c9d-7df9-423d-b643-4fdd03404e90,DISK], DatanodeInfoWithStorage[127.0.0.1:33834,DS-77d6db46-2b2f-4d27-829a-63804a0f23fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35323,DS-f9f375f6-86c5-402d-a470-1a955111ac04,DISK], DatanodeInfoWithStorage[127.0.0.1:44071,DS-00790c1c-17f8-4c73-9f2a-f33523871287,DISK], DatanodeInfoWithStorage[127.0.0.1:41758,DS-2081fe5b-4676-4cd7-8097-9f482e2e855c,DISK], DatanodeInfoWithStorage[127.0.0.1:46277,DS-9190306f-8f8a-46d1-869d-3326cf7695ab,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-566311644-172.17.0.16-1597654946372:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40246,DS-5fcb57b2-a690-47d7-a0ae-8287162ccef1,DISK], DatanodeInfoWithStorage[127.0.0.1:43174,DS-bdd67110-e5fb-406e-8e1a-b8cc8f2b414c,DISK], DatanodeInfoWithStorage[127.0.0.1:43741,DS-6c818c9d-7df9-423d-b643-4fdd03404e90,DISK], DatanodeInfoWithStorage[127.0.0.1:33834,DS-77d6db46-2b2f-4d27-829a-63804a0f23fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35323,DS-f9f375f6-86c5-402d-a470-1a955111ac04,DISK], DatanodeInfoWithStorage[127.0.0.1:44071,DS-00790c1c-17f8-4c73-9f2a-f33523871287,DISK], DatanodeInfoWithStorage[127.0.0.1:41758,DS-2081fe5b-4676-4cd7-8097-9f482e2e855c,DISK], DatanodeInfoWithStorage[127.0.0.1:46277,DS-9190306f-8f8a-46d1-869d-3326cf7695ab,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-637350301-172.17.0.16-1597655061879:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35418,DS-1a46e532-28b0-4297-9fc3-a6fa4eaf5294,DISK], DatanodeInfoWithStorage[127.0.0.1:37597,DS-4e2bf524-5c54-4309-a13c-4c5b3a7b7774,DISK], DatanodeInfoWithStorage[127.0.0.1:38417,DS-87eba738-ebb6-4644-ab79-3b21925729a9,DISK], DatanodeInfoWithStorage[127.0.0.1:32770,DS-a7bc882b-b7a4-4eae-86a8-84859847d54f,DISK], DatanodeInfoWithStorage[127.0.0.1:33460,DS-6357c5d4-d55d-491f-8771-4bfc172898f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36490,DS-f776ea85-038f-4e6e-90f9-d8c0312e37c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36726,DS-801725c6-6dda-4a26-aed5-a6373753899a,DISK], DatanodeInfoWithStorage[127.0.0.1:41361,DS-4ccfd3c0-4abc-4a03-91b0-32afbda1fea9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-637350301-172.17.0.16-1597655061879:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35418,DS-1a46e532-28b0-4297-9fc3-a6fa4eaf5294,DISK], DatanodeInfoWithStorage[127.0.0.1:37597,DS-4e2bf524-5c54-4309-a13c-4c5b3a7b7774,DISK], DatanodeInfoWithStorage[127.0.0.1:38417,DS-87eba738-ebb6-4644-ab79-3b21925729a9,DISK], DatanodeInfoWithStorage[127.0.0.1:32770,DS-a7bc882b-b7a4-4eae-86a8-84859847d54f,DISK], DatanodeInfoWithStorage[127.0.0.1:33460,DS-6357c5d4-d55d-491f-8771-4bfc172898f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36490,DS-f776ea85-038f-4e6e-90f9-d8c0312e37c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36726,DS-801725c6-6dda-4a26-aed5-a6373753899a,DISK], DatanodeInfoWithStorage[127.0.0.1:41361,DS-4ccfd3c0-4abc-4a03-91b0-32afbda1fea9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1242161678-172.17.0.16-1597655195810:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40381,DS-993257ec-13e8-4cd3-8df3-5ac5b31d2321,DISK], DatanodeInfoWithStorage[127.0.0.1:37419,DS-d8fd4414-2ac2-46e2-8f1f-e00e6542eefc,DISK], DatanodeInfoWithStorage[127.0.0.1:44462,DS-f43e05f1-61e9-4177-87d8-a9f9937c4e39,DISK], DatanodeInfoWithStorage[127.0.0.1:45079,DS-90266aa7-5d24-4498-8b9c-41a41e72d964,DISK], DatanodeInfoWithStorage[127.0.0.1:37884,DS-b540fd88-8730-4414-8428-aa6472291a10,DISK], DatanodeInfoWithStorage[127.0.0.1:45535,DS-838a69b0-4ee2-4baf-83cc-d28650549e36,DISK], DatanodeInfoWithStorage[127.0.0.1:39533,DS-5a8623bb-ceb8-4571-abb2-5cc4cea4b343,DISK], DatanodeInfoWithStorage[127.0.0.1:43085,DS-25903aff-e1d0-494b-a405-5dafbc877a0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1242161678-172.17.0.16-1597655195810:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40381,DS-993257ec-13e8-4cd3-8df3-5ac5b31d2321,DISK], DatanodeInfoWithStorage[127.0.0.1:37419,DS-d8fd4414-2ac2-46e2-8f1f-e00e6542eefc,DISK], DatanodeInfoWithStorage[127.0.0.1:44462,DS-f43e05f1-61e9-4177-87d8-a9f9937c4e39,DISK], DatanodeInfoWithStorage[127.0.0.1:45079,DS-90266aa7-5d24-4498-8b9c-41a41e72d964,DISK], DatanodeInfoWithStorage[127.0.0.1:37884,DS-b540fd88-8730-4414-8428-aa6472291a10,DISK], DatanodeInfoWithStorage[127.0.0.1:45535,DS-838a69b0-4ee2-4baf-83cc-d28650549e36,DISK], DatanodeInfoWithStorage[127.0.0.1:39533,DS-5a8623bb-ceb8-4571-abb2-5cc4cea4b343,DISK], DatanodeInfoWithStorage[127.0.0.1:43085,DS-25903aff-e1d0-494b-a405-5dafbc877a0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-896037305-172.17.0.16-1597655317394:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41293,DS-4f1fce62-d414-4a5b-b21b-1fa9cf8dcf85,DISK], DatanodeInfoWithStorage[127.0.0.1:41802,DS-50ba7939-51c2-4c64-bb39-39d1c636e658,DISK], DatanodeInfoWithStorage[127.0.0.1:39847,DS-a10496a7-23bb-49d0-ac60-9d437d30ff39,DISK], DatanodeInfoWithStorage[127.0.0.1:34181,DS-6dc56001-0a50-4f3e-b3fc-5c09f0b39348,DISK], DatanodeInfoWithStorage[127.0.0.1:40589,DS-1cfc2a7b-417a-444b-99f5-7d12c422fae5,DISK], DatanodeInfoWithStorage[127.0.0.1:46215,DS-cf97a01d-a57c-464f-b1c8-2b91e9fd923e,DISK], DatanodeInfoWithStorage[127.0.0.1:43693,DS-86417d33-49db-4d92-ad88-a3bdbba99c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:46426,DS-87cbfac9-a688-4659-9fe1-99030ebd3c37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-896037305-172.17.0.16-1597655317394:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41293,DS-4f1fce62-d414-4a5b-b21b-1fa9cf8dcf85,DISK], DatanodeInfoWithStorage[127.0.0.1:41802,DS-50ba7939-51c2-4c64-bb39-39d1c636e658,DISK], DatanodeInfoWithStorage[127.0.0.1:39847,DS-a10496a7-23bb-49d0-ac60-9d437d30ff39,DISK], DatanodeInfoWithStorage[127.0.0.1:34181,DS-6dc56001-0a50-4f3e-b3fc-5c09f0b39348,DISK], DatanodeInfoWithStorage[127.0.0.1:40589,DS-1cfc2a7b-417a-444b-99f5-7d12c422fae5,DISK], DatanodeInfoWithStorage[127.0.0.1:46215,DS-cf97a01d-a57c-464f-b1c8-2b91e9fd923e,DISK], DatanodeInfoWithStorage[127.0.0.1:43693,DS-86417d33-49db-4d92-ad88-a3bdbba99c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:46426,DS-87cbfac9-a688-4659-9fe1-99030ebd3c37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-138278973-172.17.0.16-1597655470835:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40699,DS-a4f03168-5464-44df-8ff9-35880589d02e,DISK], DatanodeInfoWithStorage[127.0.0.1:43897,DS-c735db94-b8c3-49a5-b334-37ca39410774,DISK], DatanodeInfoWithStorage[127.0.0.1:35693,DS-9d869fd9-5a51-46ec-be90-c66bf218eac6,DISK], DatanodeInfoWithStorage[127.0.0.1:46871,DS-db2cf8a8-5560-4db6-ab58-21e9e7509668,DISK], DatanodeInfoWithStorage[127.0.0.1:43628,DS-fa2629b1-e03f-4b05-9ba2-b400971bb6c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38098,DS-8c2c3f30-486f-4ffc-850c-d459920dec41,DISK], DatanodeInfoWithStorage[127.0.0.1:45912,DS-0234e770-9505-46c8-b31c-9fca096a3508,DISK], DatanodeInfoWithStorage[127.0.0.1:36626,DS-e857b5f8-29c3-4b0e-b377-724dda1a6bda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-138278973-172.17.0.16-1597655470835:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40699,DS-a4f03168-5464-44df-8ff9-35880589d02e,DISK], DatanodeInfoWithStorage[127.0.0.1:43897,DS-c735db94-b8c3-49a5-b334-37ca39410774,DISK], DatanodeInfoWithStorage[127.0.0.1:35693,DS-9d869fd9-5a51-46ec-be90-c66bf218eac6,DISK], DatanodeInfoWithStorage[127.0.0.1:46871,DS-db2cf8a8-5560-4db6-ab58-21e9e7509668,DISK], DatanodeInfoWithStorage[127.0.0.1:43628,DS-fa2629b1-e03f-4b05-9ba2-b400971bb6c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38098,DS-8c2c3f30-486f-4ffc-850c-d459920dec41,DISK], DatanodeInfoWithStorage[127.0.0.1:45912,DS-0234e770-9505-46c8-b31c-9fca096a3508,DISK], DatanodeInfoWithStorage[127.0.0.1:36626,DS-e857b5f8-29c3-4b0e-b377-724dda1a6bda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-799874951-172.17.0.16-1597655713894:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37684,DS-a83858c8-0798-4361-a7b8-4d3faed4b618,DISK], DatanodeInfoWithStorage[127.0.0.1:33592,DS-edfb30bc-28c1-437a-b436-3b65eda136ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33703,DS-ec92215a-8d55-4ee9-b0f2-f99797ed06af,DISK], DatanodeInfoWithStorage[127.0.0.1:38680,DS-71a07224-be7a-448a-8f43-9ccd73142765,DISK], DatanodeInfoWithStorage[127.0.0.1:33380,DS-28f85f51-999a-47c5-814b-54cd2ae1c163,DISK], DatanodeInfoWithStorage[127.0.0.1:43616,DS-ae53cd97-d8b1-42c5-8921-b70eaa70c047,DISK], DatanodeInfoWithStorage[127.0.0.1:44856,DS-35104cc0-d9c6-4fbd-ab88-9877e489aaf4,DISK], DatanodeInfoWithStorage[127.0.0.1:34837,DS-f63e1133-8c99-46b0-9723-cdb2bc7a58ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-799874951-172.17.0.16-1597655713894:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37684,DS-a83858c8-0798-4361-a7b8-4d3faed4b618,DISK], DatanodeInfoWithStorage[127.0.0.1:33592,DS-edfb30bc-28c1-437a-b436-3b65eda136ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33703,DS-ec92215a-8d55-4ee9-b0f2-f99797ed06af,DISK], DatanodeInfoWithStorage[127.0.0.1:38680,DS-71a07224-be7a-448a-8f43-9ccd73142765,DISK], DatanodeInfoWithStorage[127.0.0.1:33380,DS-28f85f51-999a-47c5-814b-54cd2ae1c163,DISK], DatanodeInfoWithStorage[127.0.0.1:43616,DS-ae53cd97-d8b1-42c5-8921-b70eaa70c047,DISK], DatanodeInfoWithStorage[127.0.0.1:44856,DS-35104cc0-d9c6-4fbd-ab88-9877e489aaf4,DISK], DatanodeInfoWithStorage[127.0.0.1:34837,DS-f63e1133-8c99-46b0-9723-cdb2bc7a58ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1651982231-172.17.0.16-1597655756693:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46414,DS-e4339751-9658-47c9-a90c-a6cc9f469219,DISK], DatanodeInfoWithStorage[127.0.0.1:44319,DS-35c0d800-bbbf-44f2-96a8-45969784c1fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41273,DS-0e99e9de-22d4-4589-a772-fb04f38018cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43270,DS-73a20706-251d-41fb-8366-91c00be132a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45345,DS-79ce3357-a6a7-4e1d-aad5-97e0b856803f,DISK], DatanodeInfoWithStorage[127.0.0.1:39008,DS-787c18dc-81d1-4473-98da-64d0381b9ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:46027,DS-86286813-892f-4128-ac7b-db6c905f570a,DISK], DatanodeInfoWithStorage[127.0.0.1:40603,DS-d9ed2ae7-7f0c-4c88-83ee-8fe74efeb932,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1651982231-172.17.0.16-1597655756693:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46414,DS-e4339751-9658-47c9-a90c-a6cc9f469219,DISK], DatanodeInfoWithStorage[127.0.0.1:44319,DS-35c0d800-bbbf-44f2-96a8-45969784c1fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41273,DS-0e99e9de-22d4-4589-a772-fb04f38018cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43270,DS-73a20706-251d-41fb-8366-91c00be132a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45345,DS-79ce3357-a6a7-4e1d-aad5-97e0b856803f,DISK], DatanodeInfoWithStorage[127.0.0.1:39008,DS-787c18dc-81d1-4473-98da-64d0381b9ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:46027,DS-86286813-892f-4128-ac7b-db6c905f570a,DISK], DatanodeInfoWithStorage[127.0.0.1:40603,DS-d9ed2ae7-7f0c-4c88-83ee-8fe74efeb932,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1038356410-172.17.0.16-1597655837774:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35276,DS-ff5ccf3f-268c-4675-bda6-9f086f2cdd38,DISK], DatanodeInfoWithStorage[127.0.0.1:39451,DS-da13a4b4-e805-4115-8f6f-80877f4e6a81,DISK], DatanodeInfoWithStorage[127.0.0.1:44970,DS-92159d14-df2a-4426-b4ae-5037c71d4309,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-72113b48-f4d9-4989-8ad9-b9df1e2cfa2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43128,DS-19013e5f-42d7-4889-a4f4-6949c74639cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34810,DS-2804a037-7816-49fe-9ad3-1bd506b6ad2d,DISK], DatanodeInfoWithStorage[127.0.0.1:41706,DS-6289436b-33e5-4f36-8ba2-f5aa95aadc8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37889,DS-cfa165f3-d6a4-4c59-9bfc-d7c650c1a7d9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1038356410-172.17.0.16-1597655837774:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35276,DS-ff5ccf3f-268c-4675-bda6-9f086f2cdd38,DISK], DatanodeInfoWithStorage[127.0.0.1:39451,DS-da13a4b4-e805-4115-8f6f-80877f4e6a81,DISK], DatanodeInfoWithStorage[127.0.0.1:44970,DS-92159d14-df2a-4426-b4ae-5037c71d4309,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-72113b48-f4d9-4989-8ad9-b9df1e2cfa2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43128,DS-19013e5f-42d7-4889-a4f4-6949c74639cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34810,DS-2804a037-7816-49fe-9ad3-1bd506b6ad2d,DISK], DatanodeInfoWithStorage[127.0.0.1:41706,DS-6289436b-33e5-4f36-8ba2-f5aa95aadc8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37889,DS-cfa165f3-d6a4-4c59-9bfc-d7c650c1a7d9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2137972434-172.17.0.16-1597655960492:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45217,DS-caa023d8-458e-4640-ad85-69a794b6ee99,DISK], DatanodeInfoWithStorage[127.0.0.1:45294,DS-c547d62d-0008-43eb-a900-b68dfe0d6d18,DISK], DatanodeInfoWithStorage[127.0.0.1:37504,DS-b018bd89-feb3-4f4a-b1b2-c3a2a0a1bb00,DISK], DatanodeInfoWithStorage[127.0.0.1:44668,DS-85ac1edd-d597-4be4-8adc-72784a86d616,DISK], DatanodeInfoWithStorage[127.0.0.1:41835,DS-dd0d04d2-f226-430f-a543-449e54222599,DISK], DatanodeInfoWithStorage[127.0.0.1:43115,DS-3e41f508-ce18-4c5d-aeb3-72ba3124c1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43484,DS-4efd6966-0d29-4989-9667-1e38ad029b64,DISK], DatanodeInfoWithStorage[127.0.0.1:35008,DS-db26a0fd-410c-4042-9ad9-8e8a6434c5bb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2137972434-172.17.0.16-1597655960492:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45217,DS-caa023d8-458e-4640-ad85-69a794b6ee99,DISK], DatanodeInfoWithStorage[127.0.0.1:45294,DS-c547d62d-0008-43eb-a900-b68dfe0d6d18,DISK], DatanodeInfoWithStorage[127.0.0.1:37504,DS-b018bd89-feb3-4f4a-b1b2-c3a2a0a1bb00,DISK], DatanodeInfoWithStorage[127.0.0.1:44668,DS-85ac1edd-d597-4be4-8adc-72784a86d616,DISK], DatanodeInfoWithStorage[127.0.0.1:41835,DS-dd0d04d2-f226-430f-a543-449e54222599,DISK], DatanodeInfoWithStorage[127.0.0.1:43115,DS-3e41f508-ce18-4c5d-aeb3-72ba3124c1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43484,DS-4efd6966-0d29-4989-9667-1e38ad029b64,DISK], DatanodeInfoWithStorage[127.0.0.1:35008,DS-db26a0fd-410c-4042-9ad9-8e8a6434c5bb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-202676748-172.17.0.16-1597656033710:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44470,DS-aec5c21a-d119-4855-8245-59ee12b46cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:34779,DS-afea4e73-b3ba-481a-8ff3-05bff4b1706f,DISK], DatanodeInfoWithStorage[127.0.0.1:45529,DS-5a68e15d-33f9-4b4b-b4ab-a2bc271b3392,DISK], DatanodeInfoWithStorage[127.0.0.1:41375,DS-d9292483-52dc-45c3-b6f6-ab0beb982dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:44798,DS-2590ede4-60ac-4548-88ac-9d3192070175,DISK], DatanodeInfoWithStorage[127.0.0.1:44157,DS-468e87df-74fc-4e40-9ffd-a00643a55784,DISK], DatanodeInfoWithStorage[127.0.0.1:38243,DS-7ce99ba8-04f9-4606-93ab-eb36d7e0126d,DISK], DatanodeInfoWithStorage[127.0.0.1:34312,DS-e925cb22-9bbd-48d7-bb3f-a3aa9ee41eaa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-202676748-172.17.0.16-1597656033710:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44470,DS-aec5c21a-d119-4855-8245-59ee12b46cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:34779,DS-afea4e73-b3ba-481a-8ff3-05bff4b1706f,DISK], DatanodeInfoWithStorage[127.0.0.1:45529,DS-5a68e15d-33f9-4b4b-b4ab-a2bc271b3392,DISK], DatanodeInfoWithStorage[127.0.0.1:41375,DS-d9292483-52dc-45c3-b6f6-ab0beb982dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:44798,DS-2590ede4-60ac-4548-88ac-9d3192070175,DISK], DatanodeInfoWithStorage[127.0.0.1:44157,DS-468e87df-74fc-4e40-9ffd-a00643a55784,DISK], DatanodeInfoWithStorage[127.0.0.1:38243,DS-7ce99ba8-04f9-4606-93ab-eb36d7e0126d,DISK], DatanodeInfoWithStorage[127.0.0.1:34312,DS-e925cb22-9bbd-48d7-bb3f-a3aa9ee41eaa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-928834990-172.17.0.16-1597656331558:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41308,DS-bd92007a-d6d4-4dcb-97eb-8ff04764850c,DISK], DatanodeInfoWithStorage[127.0.0.1:35002,DS-b6fa38bb-891a-4142-bf18-79226786229a,DISK], DatanodeInfoWithStorage[127.0.0.1:40589,DS-9cb084c1-4494-4c7e-8a99-534141137490,DISK], DatanodeInfoWithStorage[127.0.0.1:36372,DS-3c25264e-d2f1-4bbb-8587-2c0ce0a9fb3b,DISK], DatanodeInfoWithStorage[127.0.0.1:41640,DS-56df0cc5-9b75-4f8f-9077-5727b4395a24,DISK], DatanodeInfoWithStorage[127.0.0.1:45942,DS-e3b4658d-61a8-4165-9fbc-427a75e152d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45154,DS-814cfad0-7866-4c94-9712-5f2cf3696d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:41625,DS-040842b3-67a6-4523-b75a-cf4e2a3efdc7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-928834990-172.17.0.16-1597656331558:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41308,DS-bd92007a-d6d4-4dcb-97eb-8ff04764850c,DISK], DatanodeInfoWithStorage[127.0.0.1:35002,DS-b6fa38bb-891a-4142-bf18-79226786229a,DISK], DatanodeInfoWithStorage[127.0.0.1:40589,DS-9cb084c1-4494-4c7e-8a99-534141137490,DISK], DatanodeInfoWithStorage[127.0.0.1:36372,DS-3c25264e-d2f1-4bbb-8587-2c0ce0a9fb3b,DISK], DatanodeInfoWithStorage[127.0.0.1:41640,DS-56df0cc5-9b75-4f8f-9077-5727b4395a24,DISK], DatanodeInfoWithStorage[127.0.0.1:45942,DS-e3b4658d-61a8-4165-9fbc-427a75e152d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45154,DS-814cfad0-7866-4c94-9712-5f2cf3696d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:41625,DS-040842b3-67a6-4523-b75a-cf4e2a3efdc7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2142248193-172.17.0.16-1597656552578:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33963,DS-3d1591d9-efe6-479d-9a93-9667ccee45a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46714,DS-553d3fe9-8ea3-4b6b-ae6d-e44e251cbd77,DISK], DatanodeInfoWithStorage[127.0.0.1:33472,DS-aa5460bb-1de6-4443-84a1-61e41572a8cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42725,DS-97fbd6f7-c4a7-45f7-9026-c6dce61b28fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46212,DS-168c6889-87d0-4cd7-ac9b-1480cf64e72a,DISK], DatanodeInfoWithStorage[127.0.0.1:43584,DS-ece4b363-4512-411d-9a6f-a8d2cde75e89,DISK], DatanodeInfoWithStorage[127.0.0.1:34315,DS-6b2ec302-511f-4268-b5e5-32f9d26c0302,DISK], DatanodeInfoWithStorage[127.0.0.1:36879,DS-8c55550c-757a-4553-8bbc-7a3dd4ba9e32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2142248193-172.17.0.16-1597656552578:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33963,DS-3d1591d9-efe6-479d-9a93-9667ccee45a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46714,DS-553d3fe9-8ea3-4b6b-ae6d-e44e251cbd77,DISK], DatanodeInfoWithStorage[127.0.0.1:33472,DS-aa5460bb-1de6-4443-84a1-61e41572a8cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42725,DS-97fbd6f7-c4a7-45f7-9026-c6dce61b28fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46212,DS-168c6889-87d0-4cd7-ac9b-1480cf64e72a,DISK], DatanodeInfoWithStorage[127.0.0.1:43584,DS-ece4b363-4512-411d-9a6f-a8d2cde75e89,DISK], DatanodeInfoWithStorage[127.0.0.1:34315,DS-6b2ec302-511f-4268-b5e5-32f9d26c0302,DISK], DatanodeInfoWithStorage[127.0.0.1:36879,DS-8c55550c-757a-4553-8bbc-7a3dd4ba9e32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1983928676-172.17.0.16-1597656585910:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45853,DS-1b49feb8-8236-4205-adbe-c6def9f48d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:46595,DS-c9b6cbbc-734f-40bb-a986-4f7f77fbab37,DISK], DatanodeInfoWithStorage[127.0.0.1:42915,DS-1e0b1d9b-1f52-4dac-9eaa-786c2bcda8f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35328,DS-41b33f75-e3d0-4393-a00f-0d98ba8930ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43759,DS-542472ee-9c62-43f6-9c59-da070a1c6a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:34535,DS-d8991a99-8ddd-442a-84ed-97eee3eef6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37463,DS-c99524bf-7b84-48ff-ab9b-74dbcfd95ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:38544,DS-4caaa01c-62ea-48b1-b514-0be4bd99f2c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1983928676-172.17.0.16-1597656585910:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45853,DS-1b49feb8-8236-4205-adbe-c6def9f48d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:46595,DS-c9b6cbbc-734f-40bb-a986-4f7f77fbab37,DISK], DatanodeInfoWithStorage[127.0.0.1:42915,DS-1e0b1d9b-1f52-4dac-9eaa-786c2bcda8f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35328,DS-41b33f75-e3d0-4393-a00f-0d98ba8930ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43759,DS-542472ee-9c62-43f6-9c59-da070a1c6a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:34535,DS-d8991a99-8ddd-442a-84ed-97eee3eef6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37463,DS-c99524bf-7b84-48ff-ab9b-74dbcfd95ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:38544,DS-4caaa01c-62ea-48b1-b514-0be4bd99f2c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1818866036-172.17.0.16-1597656630954:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35478,DS-1194c6a2-d334-4925-837e-c666648f7f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44544,DS-33c28e1d-4dcf-4258-a4f7-5b3a39027514,DISK], DatanodeInfoWithStorage[127.0.0.1:36399,DS-63bb4c12-0ff8-4619-9642-3dd8b3339a53,DISK], DatanodeInfoWithStorage[127.0.0.1:41470,DS-2458f6db-10b5-424a-a800-e8a60e445ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:38523,DS-387ad7be-e828-4c9e-816b-c585a57e2f99,DISK], DatanodeInfoWithStorage[127.0.0.1:34864,DS-c0171d9a-3901-4a5b-ac4b-8a46d1c6afdd,DISK], DatanodeInfoWithStorage[127.0.0.1:38600,DS-2972853a-ac6c-4f39-943b-7d0847109c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:36535,DS-09e82086-862b-4942-a069-f58b38daae37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1818866036-172.17.0.16-1597656630954:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35478,DS-1194c6a2-d334-4925-837e-c666648f7f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44544,DS-33c28e1d-4dcf-4258-a4f7-5b3a39027514,DISK], DatanodeInfoWithStorage[127.0.0.1:36399,DS-63bb4c12-0ff8-4619-9642-3dd8b3339a53,DISK], DatanodeInfoWithStorage[127.0.0.1:41470,DS-2458f6db-10b5-424a-a800-e8a60e445ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:38523,DS-387ad7be-e828-4c9e-816b-c585a57e2f99,DISK], DatanodeInfoWithStorage[127.0.0.1:34864,DS-c0171d9a-3901-4a5b-ac4b-8a46d1c6afdd,DISK], DatanodeInfoWithStorage[127.0.0.1:38600,DS-2972853a-ac6c-4f39-943b-7d0847109c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:36535,DS-09e82086-862b-4942-a069-f58b38daae37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1855877452-172.17.0.16-1597656696493:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36899,DS-0d8a8200-9694-460d-80a3-4012940fbd00,DISK], DatanodeInfoWithStorage[127.0.0.1:41106,DS-7c263228-c945-445b-9c42-42168d7d5df2,DISK], DatanodeInfoWithStorage[127.0.0.1:35340,DS-7a71566f-f157-45e0-a483-cca291e7b7d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46088,DS-5afc6cc0-3010-4552-9d86-b7cd8f91fb70,DISK], DatanodeInfoWithStorage[127.0.0.1:41116,DS-7dd90f53-35df-4b2d-922b-51837df28320,DISK], DatanodeInfoWithStorage[127.0.0.1:38361,DS-9c48259b-9d7c-4fc9-bd1f-e3a4e5fa0a77,DISK], DatanodeInfoWithStorage[127.0.0.1:33445,DS-fa723cf8-431d-4fa8-8164-11479b076dba,DISK], DatanodeInfoWithStorage[127.0.0.1:40819,DS-3740bcf4-f7e6-4ae7-b481-e187d32eaa91,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1855877452-172.17.0.16-1597656696493:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36899,DS-0d8a8200-9694-460d-80a3-4012940fbd00,DISK], DatanodeInfoWithStorage[127.0.0.1:41106,DS-7c263228-c945-445b-9c42-42168d7d5df2,DISK], DatanodeInfoWithStorage[127.0.0.1:35340,DS-7a71566f-f157-45e0-a483-cca291e7b7d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46088,DS-5afc6cc0-3010-4552-9d86-b7cd8f91fb70,DISK], DatanodeInfoWithStorage[127.0.0.1:41116,DS-7dd90f53-35df-4b2d-922b-51837df28320,DISK], DatanodeInfoWithStorage[127.0.0.1:38361,DS-9c48259b-9d7c-4fc9-bd1f-e3a4e5fa0a77,DISK], DatanodeInfoWithStorage[127.0.0.1:33445,DS-fa723cf8-431d-4fa8-8164-11479b076dba,DISK], DatanodeInfoWithStorage[127.0.0.1:40819,DS-3740bcf4-f7e6-4ae7-b481-e187d32eaa91,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-683412446-172.17.0.16-1597656771906:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41653,DS-82586d9a-655b-4fd7-a3da-e30619d62d95,DISK], DatanodeInfoWithStorage[127.0.0.1:33495,DS-377f7064-257c-4d16-9bc3-aa8da1041a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:43908,DS-13563aa8-ec7a-49e0-ae0b-270facabecde,DISK], DatanodeInfoWithStorage[127.0.0.1:44931,DS-255c3206-80a6-4c72-945c-02aaf3812517,DISK], DatanodeInfoWithStorage[127.0.0.1:33570,DS-4ef9170f-e517-4c0f-a7ae-67c7ec2c2585,DISK], DatanodeInfoWithStorage[127.0.0.1:43425,DS-db511ede-2e84-44b7-84c8-5054bb10f0ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39702,DS-9bcd038c-049c-461d-877d-30a3ec359f75,DISK], DatanodeInfoWithStorage[127.0.0.1:36209,DS-d6ac2676-9358-4f1b-8585-f0b62a61e799,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-683412446-172.17.0.16-1597656771906:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41653,DS-82586d9a-655b-4fd7-a3da-e30619d62d95,DISK], DatanodeInfoWithStorage[127.0.0.1:33495,DS-377f7064-257c-4d16-9bc3-aa8da1041a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:43908,DS-13563aa8-ec7a-49e0-ae0b-270facabecde,DISK], DatanodeInfoWithStorage[127.0.0.1:44931,DS-255c3206-80a6-4c72-945c-02aaf3812517,DISK], DatanodeInfoWithStorage[127.0.0.1:33570,DS-4ef9170f-e517-4c0f-a7ae-67c7ec2c2585,DISK], DatanodeInfoWithStorage[127.0.0.1:43425,DS-db511ede-2e84-44b7-84c8-5054bb10f0ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39702,DS-9bcd038c-049c-461d-877d-30a3ec359f75,DISK], DatanodeInfoWithStorage[127.0.0.1:36209,DS-d6ac2676-9358-4f1b-8585-f0b62a61e799,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1495885267-172.17.0.16-1597656812374:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45339,DS-19a327ae-e965-4fd3-89bb-c46d9e6437c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34408,DS-2f969c29-c2cc-41e0-9836-f74e5a843b35,DISK], DatanodeInfoWithStorage[127.0.0.1:44290,DS-402762a3-f050-4760-859a-4d26915807b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44516,DS-d9d0bc44-b77f-4860-819d-0f252b23cbd6,DISK], DatanodeInfoWithStorage[127.0.0.1:46388,DS-8b04a005-5369-4cc7-ba66-500f585eb7f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37451,DS-b88fa755-2344-4528-8992-f4eef7b75ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:38091,DS-9832b4eb-2e8c-4eb5-a02a-319ed4860609,DISK], DatanodeInfoWithStorage[127.0.0.1:35145,DS-1fc68639-7f77-4a18-a5a3-edfb0484eb20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1495885267-172.17.0.16-1597656812374:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45339,DS-19a327ae-e965-4fd3-89bb-c46d9e6437c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34408,DS-2f969c29-c2cc-41e0-9836-f74e5a843b35,DISK], DatanodeInfoWithStorage[127.0.0.1:44290,DS-402762a3-f050-4760-859a-4d26915807b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44516,DS-d9d0bc44-b77f-4860-819d-0f252b23cbd6,DISK], DatanodeInfoWithStorage[127.0.0.1:46388,DS-8b04a005-5369-4cc7-ba66-500f585eb7f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37451,DS-b88fa755-2344-4528-8992-f4eef7b75ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:38091,DS-9832b4eb-2e8c-4eb5-a02a-319ed4860609,DISK], DatanodeInfoWithStorage[127.0.0.1:35145,DS-1fc68639-7f77-4a18-a5a3-edfb0484eb20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1308199216-172.17.0.16-1597657056936:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36382,DS-481590af-be62-4056-946c-1a159a223c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:44520,DS-edc9867f-1751-4719-a299-85693eba58b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33294,DS-ae919bf8-3228-4002-b979-f14148bb1325,DISK], DatanodeInfoWithStorage[127.0.0.1:34470,DS-0e0fc729-303f-4cd1-ad34-3ba6acf2195f,DISK], DatanodeInfoWithStorage[127.0.0.1:33268,DS-be9d895e-b7fe-4700-8c37-06c9e2112227,DISK], DatanodeInfoWithStorage[127.0.0.1:46050,DS-60f5ba12-6b0f-436e-b8e0-dac3dfb94e85,DISK], DatanodeInfoWithStorage[127.0.0.1:39852,DS-4c8efd11-ac53-4a37-be45-7f9cee583f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:40687,DS-44ae0b1f-ba09-4812-8aa4-ea6234b27e2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1308199216-172.17.0.16-1597657056936:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36382,DS-481590af-be62-4056-946c-1a159a223c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:44520,DS-edc9867f-1751-4719-a299-85693eba58b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33294,DS-ae919bf8-3228-4002-b979-f14148bb1325,DISK], DatanodeInfoWithStorage[127.0.0.1:34470,DS-0e0fc729-303f-4cd1-ad34-3ba6acf2195f,DISK], DatanodeInfoWithStorage[127.0.0.1:33268,DS-be9d895e-b7fe-4700-8c37-06c9e2112227,DISK], DatanodeInfoWithStorage[127.0.0.1:46050,DS-60f5ba12-6b0f-436e-b8e0-dac3dfb94e85,DISK], DatanodeInfoWithStorage[127.0.0.1:39852,DS-4c8efd11-ac53-4a37-be45-7f9cee583f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:40687,DS-44ae0b1f-ba09-4812-8aa4-ea6234b27e2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-786844777-172.17.0.16-1597657137711:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45204,DS-67116838-1d37-4802-b8fb-56c1f92ff2df,DISK], DatanodeInfoWithStorage[127.0.0.1:38938,DS-1b010a09-dd48-4d57-ab90-e164ab00ee5a,DISK], DatanodeInfoWithStorage[127.0.0.1:34202,DS-db5c85a9-0fbb-469b-9776-688ffff5dc70,DISK], DatanodeInfoWithStorage[127.0.0.1:39992,DS-0234e09f-874a-4e99-99aa-ca70cc9803ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44928,DS-ba4e5931-0403-4c02-a25f-4a3492ef808e,DISK], DatanodeInfoWithStorage[127.0.0.1:43611,DS-d078fdde-ad9f-4771-b085-4b0efe659fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:33706,DS-d65dd627-3c19-4e24-82d3-4ff4a024bd76,DISK], DatanodeInfoWithStorage[127.0.0.1:42009,DS-c39198fd-1fcc-439a-894a-7433ccadda51,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-786844777-172.17.0.16-1597657137711:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45204,DS-67116838-1d37-4802-b8fb-56c1f92ff2df,DISK], DatanodeInfoWithStorage[127.0.0.1:38938,DS-1b010a09-dd48-4d57-ab90-e164ab00ee5a,DISK], DatanodeInfoWithStorage[127.0.0.1:34202,DS-db5c85a9-0fbb-469b-9776-688ffff5dc70,DISK], DatanodeInfoWithStorage[127.0.0.1:39992,DS-0234e09f-874a-4e99-99aa-ca70cc9803ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44928,DS-ba4e5931-0403-4c02-a25f-4a3492ef808e,DISK], DatanodeInfoWithStorage[127.0.0.1:43611,DS-d078fdde-ad9f-4771-b085-4b0efe659fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:33706,DS-d65dd627-3c19-4e24-82d3-4ff4a024bd76,DISK], DatanodeInfoWithStorage[127.0.0.1:42009,DS-c39198fd-1fcc-439a-894a-7433ccadda51,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2070818858-172.17.0.16-1597657368178:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34921,DS-f38accf7-fd13-4644-95fc-313c1966aa0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43103,DS-fbe1d6a6-1524-4890-b919-71d7f38fc4f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44047,DS-15abc05a-680a-48ad-97db-d207e440587b,DISK], DatanodeInfoWithStorage[127.0.0.1:36521,DS-e91add55-36c4-4a22-817e-e300e80f94cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45013,DS-406ef362-c320-42b1-b28a-661f436101cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39365,DS-976326a7-d659-4003-8b05-c9855c46b4b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38913,DS-17c32ffb-b8b3-4eef-979b-b9eb5dca3e76,DISK], DatanodeInfoWithStorage[127.0.0.1:32949,DS-490a9f11-4aa6-499f-98a1-1af1dda8d13d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2070818858-172.17.0.16-1597657368178:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34921,DS-f38accf7-fd13-4644-95fc-313c1966aa0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43103,DS-fbe1d6a6-1524-4890-b919-71d7f38fc4f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44047,DS-15abc05a-680a-48ad-97db-d207e440587b,DISK], DatanodeInfoWithStorage[127.0.0.1:36521,DS-e91add55-36c4-4a22-817e-e300e80f94cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45013,DS-406ef362-c320-42b1-b28a-661f436101cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39365,DS-976326a7-d659-4003-8b05-c9855c46b4b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38913,DS-17c32ffb-b8b3-4eef-979b-b9eb5dca3e76,DISK], DatanodeInfoWithStorage[127.0.0.1:32949,DS-490a9f11-4aa6-499f-98a1-1af1dda8d13d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1081152913-172.17.0.16-1597657405623:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35015,DS-e32f81fb-00c6-4c13-9cf9-758dceb7d149,DISK], DatanodeInfoWithStorage[127.0.0.1:33468,DS-d71ea0dd-b345-49be-954d-509e099ac7f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44069,DS-76a3e941-b59f-48d1-8cce-ca84545ba944,DISK], DatanodeInfoWithStorage[127.0.0.1:45397,DS-55848643-1f84-47a5-8104-8cb2530a99f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35883,DS-35590e7b-9ea6-4c14-81df-fdff57b4068e,DISK], DatanodeInfoWithStorage[127.0.0.1:37749,DS-d04d8915-94f0-4df6-8b72-e8a676e3e7fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42040,DS-a3fbc057-6b8b-4b9e-b6d6-80cf9b3d60c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40845,DS-c75f4858-b7d5-4bda-80ac-58502a0002a9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1081152913-172.17.0.16-1597657405623:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35015,DS-e32f81fb-00c6-4c13-9cf9-758dceb7d149,DISK], DatanodeInfoWithStorage[127.0.0.1:33468,DS-d71ea0dd-b345-49be-954d-509e099ac7f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44069,DS-76a3e941-b59f-48d1-8cce-ca84545ba944,DISK], DatanodeInfoWithStorage[127.0.0.1:45397,DS-55848643-1f84-47a5-8104-8cb2530a99f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35883,DS-35590e7b-9ea6-4c14-81df-fdff57b4068e,DISK], DatanodeInfoWithStorage[127.0.0.1:37749,DS-d04d8915-94f0-4df6-8b72-e8a676e3e7fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42040,DS-a3fbc057-6b8b-4b9e-b6d6-80cf9b3d60c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40845,DS-c75f4858-b7d5-4bda-80ac-58502a0002a9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1039060118-172.17.0.16-1597657747699:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40788,DS-cb6af17e-1ac0-4969-a82b-0ed3856a6315,DISK], DatanodeInfoWithStorage[127.0.0.1:33980,DS-99915993-592a-4c06-9ecc-ebfcf96df34a,DISK], DatanodeInfoWithStorage[127.0.0.1:33335,DS-53639c33-b0be-43fb-9069-667fdd54d5b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41044,DS-c8415ba3-f6bd-48d1-b2f3-68ba02545192,DISK], DatanodeInfoWithStorage[127.0.0.1:46352,DS-ad074694-8773-408c-9d12-8d062af44f86,DISK], DatanodeInfoWithStorage[127.0.0.1:45906,DS-a5ab8273-0933-4458-8bb1-c0bd435d2a17,DISK], DatanodeInfoWithStorage[127.0.0.1:34559,DS-bfcec54b-5abe-4d10-9022-a7d5fc0f8cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:38204,DS-d10ea279-b726-413d-b0de-e316c1a00cd0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1039060118-172.17.0.16-1597657747699:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40788,DS-cb6af17e-1ac0-4969-a82b-0ed3856a6315,DISK], DatanodeInfoWithStorage[127.0.0.1:33980,DS-99915993-592a-4c06-9ecc-ebfcf96df34a,DISK], DatanodeInfoWithStorage[127.0.0.1:33335,DS-53639c33-b0be-43fb-9069-667fdd54d5b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41044,DS-c8415ba3-f6bd-48d1-b2f3-68ba02545192,DISK], DatanodeInfoWithStorage[127.0.0.1:46352,DS-ad074694-8773-408c-9d12-8d062af44f86,DISK], DatanodeInfoWithStorage[127.0.0.1:45906,DS-a5ab8273-0933-4458-8bb1-c0bd435d2a17,DISK], DatanodeInfoWithStorage[127.0.0.1:34559,DS-bfcec54b-5abe-4d10-9022-a7d5fc0f8cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:38204,DS-d10ea279-b726-413d-b0de-e316c1a00cd0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-636701204-172.17.0.16-1597657785553:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45788,DS-6e3c9985-b9d7-4bfc-8813-37edfa2108ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40051,DS-a4e69d73-a18f-4eb6-bde6-3c8aafdce425,DISK], DatanodeInfoWithStorage[127.0.0.1:39942,DS-963e41ee-3d27-4f3f-a5dd-04d757931615,DISK], DatanodeInfoWithStorage[127.0.0.1:44485,DS-855a444a-34e1-466e-8622-65477c35564e,DISK], DatanodeInfoWithStorage[127.0.0.1:40037,DS-4f735904-221c-4973-8f39-621d264a901b,DISK], DatanodeInfoWithStorage[127.0.0.1:37433,DS-5ae9a832-89a4-42df-aa6c-04bc9f339a10,DISK], DatanodeInfoWithStorage[127.0.0.1:37765,DS-d5eb18b4-7efe-491c-a848-03b3d1d012c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33783,DS-81bab6c5-d5ff-42c8-85be-d380ed8b98c4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-636701204-172.17.0.16-1597657785553:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45788,DS-6e3c9985-b9d7-4bfc-8813-37edfa2108ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40051,DS-a4e69d73-a18f-4eb6-bde6-3c8aafdce425,DISK], DatanodeInfoWithStorage[127.0.0.1:39942,DS-963e41ee-3d27-4f3f-a5dd-04d757931615,DISK], DatanodeInfoWithStorage[127.0.0.1:44485,DS-855a444a-34e1-466e-8622-65477c35564e,DISK], DatanodeInfoWithStorage[127.0.0.1:40037,DS-4f735904-221c-4973-8f39-621d264a901b,DISK], DatanodeInfoWithStorage[127.0.0.1:37433,DS-5ae9a832-89a4-42df-aa6c-04bc9f339a10,DISK], DatanodeInfoWithStorage[127.0.0.1:37765,DS-d5eb18b4-7efe-491c-a848-03b3d1d012c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33783,DS-81bab6c5-d5ff-42c8-85be-d380ed8b98c4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 16 out of 50
v1v1v2v2 failed with probability 19 out of 50
result: false positive !!!
Total execution time in seconds : 5595
