reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1312410710-172.17.0.16-1597659793877:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43762,DS-670b6ec1-0008-441a-8f9f-f29295dfa78c,DISK], DatanodeInfoWithStorage[127.0.0.1:34858,DS-5f6d1833-aec5-4965-a0d7-1ef005088ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:36088,DS-1ef520a8-0dc3-4ec1-929c-623de90c60b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35922,DS-17e8ae44-f110-4a2d-aa86-69a3117591a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46463,DS-26ae2ac2-7926-467a-b102-e6fff0cd9325,DISK], DatanodeInfoWithStorage[127.0.0.1:40490,DS-d19606fc-7a8e-4fa7-b2a6-7e19c0f4c515,DISK], DatanodeInfoWithStorage[127.0.0.1:45043,DS-0222374f-3e5a-4c4c-a78a-d6a92943b0b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44680,DS-106f739b-9023-43f2-b4ef-91ec9ca1e589,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1312410710-172.17.0.16-1597659793877:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43762,DS-670b6ec1-0008-441a-8f9f-f29295dfa78c,DISK], DatanodeInfoWithStorage[127.0.0.1:34858,DS-5f6d1833-aec5-4965-a0d7-1ef005088ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:36088,DS-1ef520a8-0dc3-4ec1-929c-623de90c60b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35922,DS-17e8ae44-f110-4a2d-aa86-69a3117591a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46463,DS-26ae2ac2-7926-467a-b102-e6fff0cd9325,DISK], DatanodeInfoWithStorage[127.0.0.1:40490,DS-d19606fc-7a8e-4fa7-b2a6-7e19c0f4c515,DISK], DatanodeInfoWithStorage[127.0.0.1:45043,DS-0222374f-3e5a-4c4c-a78a-d6a92943b0b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44680,DS-106f739b-9023-43f2-b4ef-91ec9ca1e589,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1708597789-172.17.0.16-1597660059387:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39406,DS-57d5df5d-1e49-4748-b43a-e0300a0ba436,DISK], DatanodeInfoWithStorage[127.0.0.1:40949,DS-dfec7ab3-4053-4389-9296-6b74f9b77ed4,DISK], DatanodeInfoWithStorage[127.0.0.1:37562,DS-0536a0eb-dd6c-42b2-be29-bcca1ff08af1,DISK], DatanodeInfoWithStorage[127.0.0.1:44585,DS-9b96a934-fff9-4628-bdf9-4370dee72be9,DISK], DatanodeInfoWithStorage[127.0.0.1:36353,DS-522c1c65-91a4-4d20-9fc7-8ece066af628,DISK], DatanodeInfoWithStorage[127.0.0.1:33896,DS-d3aea723-b202-4ad9-b0b0-fb80ff4c0316,DISK], DatanodeInfoWithStorage[127.0.0.1:41066,DS-50fa8d11-1842-44c9-86e4-a695cc151577,DISK], DatanodeInfoWithStorage[127.0.0.1:37203,DS-ddc36edc-87ae-4206-af76-b60ac8555468,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1708597789-172.17.0.16-1597660059387:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39406,DS-57d5df5d-1e49-4748-b43a-e0300a0ba436,DISK], DatanodeInfoWithStorage[127.0.0.1:40949,DS-dfec7ab3-4053-4389-9296-6b74f9b77ed4,DISK], DatanodeInfoWithStorage[127.0.0.1:37562,DS-0536a0eb-dd6c-42b2-be29-bcca1ff08af1,DISK], DatanodeInfoWithStorage[127.0.0.1:44585,DS-9b96a934-fff9-4628-bdf9-4370dee72be9,DISK], DatanodeInfoWithStorage[127.0.0.1:36353,DS-522c1c65-91a4-4d20-9fc7-8ece066af628,DISK], DatanodeInfoWithStorage[127.0.0.1:33896,DS-d3aea723-b202-4ad9-b0b0-fb80ff4c0316,DISK], DatanodeInfoWithStorage[127.0.0.1:41066,DS-50fa8d11-1842-44c9-86e4-a695cc151577,DISK], DatanodeInfoWithStorage[127.0.0.1:37203,DS-ddc36edc-87ae-4206-af76-b60ac8555468,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-316192132-172.17.0.16-1597660137014:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38127,DS-52f02408-6a0e-4f0e-8829-0ed7d60e3ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:33017,DS-5832fd67-03d7-4db0-b6be-963bbe56b081,DISK], DatanodeInfoWithStorage[127.0.0.1:39903,DS-eabc2b1b-cb47-4187-b1c7-5750a32a32bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41720,DS-806ae55c-67cb-47ae-b5b9-db8ffba374f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45885,DS-9402ae77-2967-4d03-bbc8-d32ac740f64a,DISK], DatanodeInfoWithStorage[127.0.0.1:33402,DS-d8c5dbd2-1a4d-4221-865f-542ec12d1379,DISK], DatanodeInfoWithStorage[127.0.0.1:36879,DS-2d5baafe-67c2-433e-9e77-1580f74fe2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36017,DS-c26997fb-0e19-4fcd-b43b-cad8fa8a8970,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-316192132-172.17.0.16-1597660137014:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38127,DS-52f02408-6a0e-4f0e-8829-0ed7d60e3ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:33017,DS-5832fd67-03d7-4db0-b6be-963bbe56b081,DISK], DatanodeInfoWithStorage[127.0.0.1:39903,DS-eabc2b1b-cb47-4187-b1c7-5750a32a32bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41720,DS-806ae55c-67cb-47ae-b5b9-db8ffba374f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45885,DS-9402ae77-2967-4d03-bbc8-d32ac740f64a,DISK], DatanodeInfoWithStorage[127.0.0.1:33402,DS-d8c5dbd2-1a4d-4221-865f-542ec12d1379,DISK], DatanodeInfoWithStorage[127.0.0.1:36879,DS-2d5baafe-67c2-433e-9e77-1580f74fe2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36017,DS-c26997fb-0e19-4fcd-b43b-cad8fa8a8970,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-583600748-172.17.0.16-1597660348612:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35562,DS-3f6757dc-614d-416b-bf82-5f0a56733be6,DISK], DatanodeInfoWithStorage[127.0.0.1:45751,DS-8e86b472-5c87-4d97-b114-eb79f5699623,DISK], DatanodeInfoWithStorage[127.0.0.1:38435,DS-a2add743-4411-467e-b8aa-2053c618bfab,DISK], DatanodeInfoWithStorage[127.0.0.1:34661,DS-a6d9d0fd-f2a9-4a0d-8a9e-1a0736553df8,DISK], DatanodeInfoWithStorage[127.0.0.1:33141,DS-b8c60710-4b95-4c71-97e7-2bc56ebf866e,DISK], DatanodeInfoWithStorage[127.0.0.1:43487,DS-8b1650cf-f664-413a-9188-9eb62afc8675,DISK], DatanodeInfoWithStorage[127.0.0.1:46683,DS-1b73de58-0341-4710-a863-8d7ccce95f85,DISK], DatanodeInfoWithStorage[127.0.0.1:34501,DS-79aee216-d96a-47b1-ae59-98c544753325,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-583600748-172.17.0.16-1597660348612:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35562,DS-3f6757dc-614d-416b-bf82-5f0a56733be6,DISK], DatanodeInfoWithStorage[127.0.0.1:45751,DS-8e86b472-5c87-4d97-b114-eb79f5699623,DISK], DatanodeInfoWithStorage[127.0.0.1:38435,DS-a2add743-4411-467e-b8aa-2053c618bfab,DISK], DatanodeInfoWithStorage[127.0.0.1:34661,DS-a6d9d0fd-f2a9-4a0d-8a9e-1a0736553df8,DISK], DatanodeInfoWithStorage[127.0.0.1:33141,DS-b8c60710-4b95-4c71-97e7-2bc56ebf866e,DISK], DatanodeInfoWithStorage[127.0.0.1:43487,DS-8b1650cf-f664-413a-9188-9eb62afc8675,DISK], DatanodeInfoWithStorage[127.0.0.1:46683,DS-1b73de58-0341-4710-a863-8d7ccce95f85,DISK], DatanodeInfoWithStorage[127.0.0.1:34501,DS-79aee216-d96a-47b1-ae59-98c544753325,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1196521945-172.17.0.16-1597660750624:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43367,DS-36c94a99-69fe-4bb9-ab1a-9a5ad51fac34,DISK], DatanodeInfoWithStorage[127.0.0.1:35100,DS-2413de3d-c687-47a5-aaf4-7647fa81e396,DISK], DatanodeInfoWithStorage[127.0.0.1:40446,DS-8f8813e9-4655-4e74-92f4-052a0b8ce56e,DISK], DatanodeInfoWithStorage[127.0.0.1:41296,DS-dacd7c45-b5cf-4786-9183-224cde2befc5,DISK], DatanodeInfoWithStorage[127.0.0.1:44979,DS-994b54db-c36a-498d-b68f-ea41b742169b,DISK], DatanodeInfoWithStorage[127.0.0.1:33381,DS-b5a74d4a-9b78-438b-bdeb-22157a8eff44,DISK], DatanodeInfoWithStorage[127.0.0.1:43261,DS-bf5f5018-19c5-420a-9a9d-a70bfc74bb10,DISK], DatanodeInfoWithStorage[127.0.0.1:35438,DS-b48483fb-1b71-4c41-9c09-68cde8b4c3a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1196521945-172.17.0.16-1597660750624:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43367,DS-36c94a99-69fe-4bb9-ab1a-9a5ad51fac34,DISK], DatanodeInfoWithStorage[127.0.0.1:35100,DS-2413de3d-c687-47a5-aaf4-7647fa81e396,DISK], DatanodeInfoWithStorage[127.0.0.1:40446,DS-8f8813e9-4655-4e74-92f4-052a0b8ce56e,DISK], DatanodeInfoWithStorage[127.0.0.1:41296,DS-dacd7c45-b5cf-4786-9183-224cde2befc5,DISK], DatanodeInfoWithStorage[127.0.0.1:44979,DS-994b54db-c36a-498d-b68f-ea41b742169b,DISK], DatanodeInfoWithStorage[127.0.0.1:33381,DS-b5a74d4a-9b78-438b-bdeb-22157a8eff44,DISK], DatanodeInfoWithStorage[127.0.0.1:43261,DS-bf5f5018-19c5-420a-9a9d-a70bfc74bb10,DISK], DatanodeInfoWithStorage[127.0.0.1:35438,DS-b48483fb-1b71-4c41-9c09-68cde8b4c3a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-664831486-172.17.0.16-1597661518988:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39826,DS-1c59449c-f7b4-4a19-afa5-effe1b28d6fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43729,DS-0c637883-e68a-472e-87d7-4c74c5722877,DISK], DatanodeInfoWithStorage[127.0.0.1:37720,DS-da2b7606-bb06-46e2-9a0b-80eef6ccd2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44196,DS-76607f01-1fa5-477a-8cef-138f59c3663c,DISK], DatanodeInfoWithStorage[127.0.0.1:36155,DS-ac339fd6-62f6-459e-9752-89c9a3b6f81b,DISK], DatanodeInfoWithStorage[127.0.0.1:38777,DS-f7909aea-9617-4ece-bfe2-129329ca90a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34884,DS-b4601abd-fecb-4f39-bae9-a3167b8e38f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43091,DS-f5ef900b-a633-4657-9ee9-3372a933d55c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-664831486-172.17.0.16-1597661518988:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39826,DS-1c59449c-f7b4-4a19-afa5-effe1b28d6fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43729,DS-0c637883-e68a-472e-87d7-4c74c5722877,DISK], DatanodeInfoWithStorage[127.0.0.1:37720,DS-da2b7606-bb06-46e2-9a0b-80eef6ccd2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44196,DS-76607f01-1fa5-477a-8cef-138f59c3663c,DISK], DatanodeInfoWithStorage[127.0.0.1:36155,DS-ac339fd6-62f6-459e-9752-89c9a3b6f81b,DISK], DatanodeInfoWithStorage[127.0.0.1:38777,DS-f7909aea-9617-4ece-bfe2-129329ca90a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34884,DS-b4601abd-fecb-4f39-bae9-a3167b8e38f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43091,DS-f5ef900b-a633-4657-9ee9-3372a933d55c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-539042447-172.17.0.16-1597661773240:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40308,DS-59134f28-1d03-4c0f-beca-bddad93cf94a,DISK], DatanodeInfoWithStorage[127.0.0.1:32795,DS-a530b990-08a3-4995-9a94-132373c752cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37247,DS-d78b9bdf-87d6-4c2d-ac01-032ac9a77c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:44443,DS-a1cd8433-2ae7-4efc-93c5-ac8830e15593,DISK], DatanodeInfoWithStorage[127.0.0.1:37215,DS-f05e7330-2287-4443-9628-ecd862a718be,DISK], DatanodeInfoWithStorage[127.0.0.1:39087,DS-1931be09-d52b-4de9-bae9-21ddbdfd5734,DISK], DatanodeInfoWithStorage[127.0.0.1:36999,DS-3c318b75-7dde-408c-8444-1508510d26e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41864,DS-6d35efc3-b15f-4dce-b850-6dbd190ee5d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-539042447-172.17.0.16-1597661773240:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40308,DS-59134f28-1d03-4c0f-beca-bddad93cf94a,DISK], DatanodeInfoWithStorage[127.0.0.1:32795,DS-a530b990-08a3-4995-9a94-132373c752cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37247,DS-d78b9bdf-87d6-4c2d-ac01-032ac9a77c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:44443,DS-a1cd8433-2ae7-4efc-93c5-ac8830e15593,DISK], DatanodeInfoWithStorage[127.0.0.1:37215,DS-f05e7330-2287-4443-9628-ecd862a718be,DISK], DatanodeInfoWithStorage[127.0.0.1:39087,DS-1931be09-d52b-4de9-bae9-21ddbdfd5734,DISK], DatanodeInfoWithStorage[127.0.0.1:36999,DS-3c318b75-7dde-408c-8444-1508510d26e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41864,DS-6d35efc3-b15f-4dce-b850-6dbd190ee5d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-630703577-172.17.0.16-1597662021515:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36891,DS-992dce2f-70f3-44ad-b4d2-4edf34518731,DISK], DatanodeInfoWithStorage[127.0.0.1:36738,DS-e8238b63-08c7-4708-aa62-73b812280cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:44114,DS-88b16bdb-462f-4ff4-8d99-40b659aa2f38,DISK], DatanodeInfoWithStorage[127.0.0.1:43945,DS-287851db-ad9c-4c79-a08f-fb287d7e6a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:37451,DS-9c20cd8c-dc25-4c53-93f6-4fae61b53ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:44875,DS-2bea6f59-570d-44ef-bc7b-85431d1dcf47,DISK], DatanodeInfoWithStorage[127.0.0.1:43853,DS-69ab71c9-4ba1-483b-862d-5e03800af0e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42146,DS-4506fc2b-f2e8-4a13-8183-1d63b35a38be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-630703577-172.17.0.16-1597662021515:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36891,DS-992dce2f-70f3-44ad-b4d2-4edf34518731,DISK], DatanodeInfoWithStorage[127.0.0.1:36738,DS-e8238b63-08c7-4708-aa62-73b812280cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:44114,DS-88b16bdb-462f-4ff4-8d99-40b659aa2f38,DISK], DatanodeInfoWithStorage[127.0.0.1:43945,DS-287851db-ad9c-4c79-a08f-fb287d7e6a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:37451,DS-9c20cd8c-dc25-4c53-93f6-4fae61b53ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:44875,DS-2bea6f59-570d-44ef-bc7b-85431d1dcf47,DISK], DatanodeInfoWithStorage[127.0.0.1:43853,DS-69ab71c9-4ba1-483b-862d-5e03800af0e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42146,DS-4506fc2b-f2e8-4a13-8183-1d63b35a38be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-278184188-172.17.0.16-1597662708408:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36712,DS-75147743-6976-48a1-9344-63548660c6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46055,DS-a0f85a33-955c-474f-94af-5d171d775ced,DISK], DatanodeInfoWithStorage[127.0.0.1:40838,DS-246abedd-db5b-43f4-a410-39da1205d3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39689,DS-4121ce3e-a17f-4d62-9eb7-0002eb70eff3,DISK], DatanodeInfoWithStorage[127.0.0.1:41158,DS-2d018915-325a-47d1-87ee-e376e6a73092,DISK], DatanodeInfoWithStorage[127.0.0.1:33027,DS-205a88f1-44b3-4853-988a-a7ee79447a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43659,DS-b2dd0d77-7fca-463f-802d-7a25fe861b70,DISK], DatanodeInfoWithStorage[127.0.0.1:39265,DS-6943cc40-aa67-46b0-9783-faa271c77df3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-278184188-172.17.0.16-1597662708408:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36712,DS-75147743-6976-48a1-9344-63548660c6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46055,DS-a0f85a33-955c-474f-94af-5d171d775ced,DISK], DatanodeInfoWithStorage[127.0.0.1:40838,DS-246abedd-db5b-43f4-a410-39da1205d3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39689,DS-4121ce3e-a17f-4d62-9eb7-0002eb70eff3,DISK], DatanodeInfoWithStorage[127.0.0.1:41158,DS-2d018915-325a-47d1-87ee-e376e6a73092,DISK], DatanodeInfoWithStorage[127.0.0.1:33027,DS-205a88f1-44b3-4853-988a-a7ee79447a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43659,DS-b2dd0d77-7fca-463f-802d-7a25fe861b70,DISK], DatanodeInfoWithStorage[127.0.0.1:39265,DS-6943cc40-aa67-46b0-9783-faa271c77df3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1632759078-172.17.0.16-1597662852147:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46296,DS-e6c10f11-74e4-4f09-a614-8af9dc51e43b,DISK], DatanodeInfoWithStorage[127.0.0.1:45041,DS-2b94c6ae-d2c9-4c79-9520-94ac96682e06,DISK], DatanodeInfoWithStorage[127.0.0.1:37713,DS-e94bb192-0543-496c-aff1-fa2d3e432cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:46767,DS-6ac80323-b3f4-4a4d-8a59-84951a916ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:33783,DS-821394a0-9500-4f25-b6a8-ebd736d3b041,DISK], DatanodeInfoWithStorage[127.0.0.1:35424,DS-2a420f7d-0d8c-4966-8191-a0d70cb18d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:42549,DS-e5aae155-5b97-4b91-8a97-c65a5d6a4be9,DISK], DatanodeInfoWithStorage[127.0.0.1:34987,DS-5ff7e2c1-4e95-494f-ae91-c2a1a9d527cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1632759078-172.17.0.16-1597662852147:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46296,DS-e6c10f11-74e4-4f09-a614-8af9dc51e43b,DISK], DatanodeInfoWithStorage[127.0.0.1:45041,DS-2b94c6ae-d2c9-4c79-9520-94ac96682e06,DISK], DatanodeInfoWithStorage[127.0.0.1:37713,DS-e94bb192-0543-496c-aff1-fa2d3e432cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:46767,DS-6ac80323-b3f4-4a4d-8a59-84951a916ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:33783,DS-821394a0-9500-4f25-b6a8-ebd736d3b041,DISK], DatanodeInfoWithStorage[127.0.0.1:35424,DS-2a420f7d-0d8c-4966-8191-a0d70cb18d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:42549,DS-e5aae155-5b97-4b91-8a97-c65a5d6a4be9,DISK], DatanodeInfoWithStorage[127.0.0.1:34987,DS-5ff7e2c1-4e95-494f-ae91-c2a1a9d527cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1194001804-172.17.0.16-1597663227869:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37894,DS-0f37f571-fce0-447d-bb61-31066e7eb2bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45187,DS-b0de2974-645a-4040-a217-58d5ffbcc21f,DISK], DatanodeInfoWithStorage[127.0.0.1:45662,DS-0c78685c-637b-4343-b8cd-7815f08b4691,DISK], DatanodeInfoWithStorage[127.0.0.1:42054,DS-a719e23f-c85f-4da4-96fb-fb81175165bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40633,DS-55f37ee6-6df9-4c80-ba04-89f6b832317d,DISK], DatanodeInfoWithStorage[127.0.0.1:43888,DS-c66cb4ed-239a-4dc2-80dc-823cfe1aea65,DISK], DatanodeInfoWithStorage[127.0.0.1:39866,DS-ce132835-f2c3-4acb-abd1-89e35b625481,DISK], DatanodeInfoWithStorage[127.0.0.1:34752,DS-e680774b-d168-4d35-897d-31782d7fab2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1194001804-172.17.0.16-1597663227869:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37894,DS-0f37f571-fce0-447d-bb61-31066e7eb2bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45187,DS-b0de2974-645a-4040-a217-58d5ffbcc21f,DISK], DatanodeInfoWithStorage[127.0.0.1:45662,DS-0c78685c-637b-4343-b8cd-7815f08b4691,DISK], DatanodeInfoWithStorage[127.0.0.1:42054,DS-a719e23f-c85f-4da4-96fb-fb81175165bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40633,DS-55f37ee6-6df9-4c80-ba04-89f6b832317d,DISK], DatanodeInfoWithStorage[127.0.0.1:43888,DS-c66cb4ed-239a-4dc2-80dc-823cfe1aea65,DISK], DatanodeInfoWithStorage[127.0.0.1:39866,DS-ce132835-f2c3-4acb-abd1-89e35b625481,DISK], DatanodeInfoWithStorage[127.0.0.1:34752,DS-e680774b-d168-4d35-897d-31782d7fab2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1651659589-172.17.0.16-1597663482245:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37971,DS-86db1f47-9f78-4a4b-acc9-ee303c1acb29,DISK], DatanodeInfoWithStorage[127.0.0.1:34766,DS-72269e6d-2dd4-4023-97b8-76b60289220c,DISK], DatanodeInfoWithStorage[127.0.0.1:46337,DS-405e3e1d-eb98-4a19-9725-9f58a436507a,DISK], DatanodeInfoWithStorage[127.0.0.1:43520,DS-f77a1ab8-34cd-4baa-b0ac-d3b4d0340468,DISK], DatanodeInfoWithStorage[127.0.0.1:34610,DS-8fb09ba1-54bb-4501-aab0-dadc0505d2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33030,DS-b3cb0eee-8010-4a01-bf56-3dae376ea371,DISK], DatanodeInfoWithStorage[127.0.0.1:44547,DS-93108a4a-f345-4a16-a83c-63dde095f520,DISK], DatanodeInfoWithStorage[127.0.0.1:35456,DS-e7a02857-b2c3-4e29-b70e-545f18f1ce4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1651659589-172.17.0.16-1597663482245:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37971,DS-86db1f47-9f78-4a4b-acc9-ee303c1acb29,DISK], DatanodeInfoWithStorage[127.0.0.1:34766,DS-72269e6d-2dd4-4023-97b8-76b60289220c,DISK], DatanodeInfoWithStorage[127.0.0.1:46337,DS-405e3e1d-eb98-4a19-9725-9f58a436507a,DISK], DatanodeInfoWithStorage[127.0.0.1:43520,DS-f77a1ab8-34cd-4baa-b0ac-d3b4d0340468,DISK], DatanodeInfoWithStorage[127.0.0.1:34610,DS-8fb09ba1-54bb-4501-aab0-dadc0505d2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33030,DS-b3cb0eee-8010-4a01-bf56-3dae376ea371,DISK], DatanodeInfoWithStorage[127.0.0.1:44547,DS-93108a4a-f345-4a16-a83c-63dde095f520,DISK], DatanodeInfoWithStorage[127.0.0.1:35456,DS-e7a02857-b2c3-4e29-b70e-545f18f1ce4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1019563904-172.17.0.16-1597663975067:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42583,DS-2b94de3a-43bb-4db2-8183-37ae85e2b53f,DISK], DatanodeInfoWithStorage[127.0.0.1:35101,DS-8ad7ddda-26dd-4e2d-8017-657b48545a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:37566,DS-6c220213-97ad-44e3-b6b3-74e027b41394,DISK], DatanodeInfoWithStorage[127.0.0.1:34072,DS-c54a6093-05ab-45a5-b04f-a9b060f891bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39076,DS-9a995697-ee01-40bd-8012-3c64fff4fd73,DISK], DatanodeInfoWithStorage[127.0.0.1:43218,DS-61fbb75f-991a-4913-abf7-cc55e3c39421,DISK], DatanodeInfoWithStorage[127.0.0.1:36512,DS-43838f84-9cd0-4147-a519-fafb25829e31,DISK], DatanodeInfoWithStorage[127.0.0.1:40247,DS-08ec8fe8-4b25-4c49-adfc-daabac0793e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1019563904-172.17.0.16-1597663975067:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42583,DS-2b94de3a-43bb-4db2-8183-37ae85e2b53f,DISK], DatanodeInfoWithStorage[127.0.0.1:35101,DS-8ad7ddda-26dd-4e2d-8017-657b48545a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:37566,DS-6c220213-97ad-44e3-b6b3-74e027b41394,DISK], DatanodeInfoWithStorage[127.0.0.1:34072,DS-c54a6093-05ab-45a5-b04f-a9b060f891bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39076,DS-9a995697-ee01-40bd-8012-3c64fff4fd73,DISK], DatanodeInfoWithStorage[127.0.0.1:43218,DS-61fbb75f-991a-4913-abf7-cc55e3c39421,DISK], DatanodeInfoWithStorage[127.0.0.1:36512,DS-43838f84-9cd0-4147-a519-fafb25829e31,DISK], DatanodeInfoWithStorage[127.0.0.1:40247,DS-08ec8fe8-4b25-4c49-adfc-daabac0793e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5516
