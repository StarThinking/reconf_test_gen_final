reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2014216925-172.17.0.8-1597651086023:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37478,DS-69f0d631-24f7-4585-b40d-b2a12ed4bd48,DISK], DatanodeInfoWithStorage[127.0.0.1:42109,DS-02c4795a-727a-4ee3-bf30-30245dc6d9a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44531,DS-4bb8bca2-c928-44fe-9444-dcc62bb12754,DISK], DatanodeInfoWithStorage[127.0.0.1:41503,DS-a1447481-eeeb-4423-8fbd-466c8c7b5d93,DISK], DatanodeInfoWithStorage[127.0.0.1:36039,DS-c2aed1c9-eef2-4871-9279-d2e442fb803d,DISK], DatanodeInfoWithStorage[127.0.0.1:37260,DS-da13b2bc-5302-4c1a-8e71-e96f448bd797,DISK], DatanodeInfoWithStorage[127.0.0.1:38318,DS-ab68ed6e-7447-415b-8d00-fee9ec580e92,DISK], DatanodeInfoWithStorage[127.0.0.1:43311,DS-b0442d22-96ca-4058-bd12-430028a2517f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2014216925-172.17.0.8-1597651086023:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37478,DS-69f0d631-24f7-4585-b40d-b2a12ed4bd48,DISK], DatanodeInfoWithStorage[127.0.0.1:42109,DS-02c4795a-727a-4ee3-bf30-30245dc6d9a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44531,DS-4bb8bca2-c928-44fe-9444-dcc62bb12754,DISK], DatanodeInfoWithStorage[127.0.0.1:41503,DS-a1447481-eeeb-4423-8fbd-466c8c7b5d93,DISK], DatanodeInfoWithStorage[127.0.0.1:36039,DS-c2aed1c9-eef2-4871-9279-d2e442fb803d,DISK], DatanodeInfoWithStorage[127.0.0.1:37260,DS-da13b2bc-5302-4c1a-8e71-e96f448bd797,DISK], DatanodeInfoWithStorage[127.0.0.1:38318,DS-ab68ed6e-7447-415b-8d00-fee9ec580e92,DISK], DatanodeInfoWithStorage[127.0.0.1:43311,DS-b0442d22-96ca-4058-bd12-430028a2517f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-844723426-172.17.0.8-1597651220672:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44249,DS-dfe8d4ba-5b0f-433b-8321-4eb9bf687890,DISK], DatanodeInfoWithStorage[127.0.0.1:33758,DS-e5f6bcc8-3324-404a-a648-12eb8adb6c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:39884,DS-45aa44d1-62d2-479e-94ab-e63f64f5df83,DISK], DatanodeInfoWithStorage[127.0.0.1:34324,DS-dceec08c-14cd-4235-b498-4f14e5e53cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:39672,DS-79a35a08-e8a1-4b03-ac57-aa45312d2003,DISK], DatanodeInfoWithStorage[127.0.0.1:35188,DS-975dea85-679a-436e-adde-4d5148ee3322,DISK], DatanodeInfoWithStorage[127.0.0.1:35945,DS-570d7e7c-b519-460d-b388-9b7675a790a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36747,DS-904d7c3d-bfb2-4562-9312-158e8f32d1a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-844723426-172.17.0.8-1597651220672:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44249,DS-dfe8d4ba-5b0f-433b-8321-4eb9bf687890,DISK], DatanodeInfoWithStorage[127.0.0.1:33758,DS-e5f6bcc8-3324-404a-a648-12eb8adb6c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:39884,DS-45aa44d1-62d2-479e-94ab-e63f64f5df83,DISK], DatanodeInfoWithStorage[127.0.0.1:34324,DS-dceec08c-14cd-4235-b498-4f14e5e53cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:39672,DS-79a35a08-e8a1-4b03-ac57-aa45312d2003,DISK], DatanodeInfoWithStorage[127.0.0.1:35188,DS-975dea85-679a-436e-adde-4d5148ee3322,DISK], DatanodeInfoWithStorage[127.0.0.1:35945,DS-570d7e7c-b519-460d-b388-9b7675a790a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36747,DS-904d7c3d-bfb2-4562-9312-158e8f32d1a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-742016263-172.17.0.8-1597651298573:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36431,DS-9c078296-b15c-4530-acb7-d6a15cbdcbea,DISK], DatanodeInfoWithStorage[127.0.0.1:45288,DS-cb295722-0c6f-40e2-870e-907ce082b481,DISK], DatanodeInfoWithStorage[127.0.0.1:40192,DS-5417a134-d0f2-408d-9068-81ae48be789c,DISK], DatanodeInfoWithStorage[127.0.0.1:42983,DS-850a8a6e-8429-48c0-ad3b-154ad1e4d1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43310,DS-1a6395dc-6612-45c4-a8ab-2daeab5f377a,DISK], DatanodeInfoWithStorage[127.0.0.1:45446,DS-d64e21c0-3f87-442f-92e8-b737d2b57b82,DISK], DatanodeInfoWithStorage[127.0.0.1:33297,DS-c1ddaa3c-b2a4-4f6f-86df-7ec7e07a6c16,DISK], DatanodeInfoWithStorage[127.0.0.1:44125,DS-ad67f54a-014d-49e1-a469-a1de583ab4c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-742016263-172.17.0.8-1597651298573:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36431,DS-9c078296-b15c-4530-acb7-d6a15cbdcbea,DISK], DatanodeInfoWithStorage[127.0.0.1:45288,DS-cb295722-0c6f-40e2-870e-907ce082b481,DISK], DatanodeInfoWithStorage[127.0.0.1:40192,DS-5417a134-d0f2-408d-9068-81ae48be789c,DISK], DatanodeInfoWithStorage[127.0.0.1:42983,DS-850a8a6e-8429-48c0-ad3b-154ad1e4d1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43310,DS-1a6395dc-6612-45c4-a8ab-2daeab5f377a,DISK], DatanodeInfoWithStorage[127.0.0.1:45446,DS-d64e21c0-3f87-442f-92e8-b737d2b57b82,DISK], DatanodeInfoWithStorage[127.0.0.1:33297,DS-c1ddaa3c-b2a4-4f6f-86df-7ec7e07a6c16,DISK], DatanodeInfoWithStorage[127.0.0.1:44125,DS-ad67f54a-014d-49e1-a469-a1de583ab4c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1115643591-172.17.0.8-1597651367860:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45373,DS-1d492434-0e31-492d-ac00-08804b710b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:46788,DS-7804c864-31e5-41f6-b084-e48eb6ad6ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:34259,DS-22412700-ccb8-4b28-bcbf-655d9b3d6e87,DISK], DatanodeInfoWithStorage[127.0.0.1:43549,DS-2d4c1fa8-318b-48be-8f45-783d32aa3a60,DISK], DatanodeInfoWithStorage[127.0.0.1:33117,DS-deb30e30-3e68-4684-ad3c-4ed7fcf4a7a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40527,DS-d00fa68c-a89e-4c0a-b80a-fecd5676d4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38113,DS-2d911ec5-2e1d-42eb-a179-2fd2cfd35448,DISK], DatanodeInfoWithStorage[127.0.0.1:35641,DS-5f9891d0-ac05-438b-bf07-bc70a24dd610,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1115643591-172.17.0.8-1597651367860:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45373,DS-1d492434-0e31-492d-ac00-08804b710b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:46788,DS-7804c864-31e5-41f6-b084-e48eb6ad6ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:34259,DS-22412700-ccb8-4b28-bcbf-655d9b3d6e87,DISK], DatanodeInfoWithStorage[127.0.0.1:43549,DS-2d4c1fa8-318b-48be-8f45-783d32aa3a60,DISK], DatanodeInfoWithStorage[127.0.0.1:33117,DS-deb30e30-3e68-4684-ad3c-4ed7fcf4a7a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40527,DS-d00fa68c-a89e-4c0a-b80a-fecd5676d4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38113,DS-2d911ec5-2e1d-42eb-a179-2fd2cfd35448,DISK], DatanodeInfoWithStorage[127.0.0.1:35641,DS-5f9891d0-ac05-438b-bf07-bc70a24dd610,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-417254483-172.17.0.8-1597651730746:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39114,DS-cf9eec89-1416-4017-a221-f565db12e77b,DISK], DatanodeInfoWithStorage[127.0.0.1:46367,DS-d0e1b403-6818-4dbf-9e76-f94a5d308711,DISK], DatanodeInfoWithStorage[127.0.0.1:33629,DS-94c9e0d8-3c56-4b76-9949-c497cdf68769,DISK], DatanodeInfoWithStorage[127.0.0.1:38559,DS-35a3fa40-c4bb-42c5-8da0-3f28da299e50,DISK], DatanodeInfoWithStorage[127.0.0.1:43294,DS-9e7539aa-d30e-4e01-988b-aaf82561caf0,DISK], DatanodeInfoWithStorage[127.0.0.1:40775,DS-4c9d8a9a-9f1f-4f0a-994d-696b7b451e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43806,DS-5c49baa4-7f83-4173-a809-8fac6c78d314,DISK], DatanodeInfoWithStorage[127.0.0.1:45885,DS-cbbab791-7443-4751-8b0a-cd7ecd6955b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-417254483-172.17.0.8-1597651730746:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39114,DS-cf9eec89-1416-4017-a221-f565db12e77b,DISK], DatanodeInfoWithStorage[127.0.0.1:46367,DS-d0e1b403-6818-4dbf-9e76-f94a5d308711,DISK], DatanodeInfoWithStorage[127.0.0.1:33629,DS-94c9e0d8-3c56-4b76-9949-c497cdf68769,DISK], DatanodeInfoWithStorage[127.0.0.1:38559,DS-35a3fa40-c4bb-42c5-8da0-3f28da299e50,DISK], DatanodeInfoWithStorage[127.0.0.1:43294,DS-9e7539aa-d30e-4e01-988b-aaf82561caf0,DISK], DatanodeInfoWithStorage[127.0.0.1:40775,DS-4c9d8a9a-9f1f-4f0a-994d-696b7b451e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43806,DS-5c49baa4-7f83-4173-a809-8fac6c78d314,DISK], DatanodeInfoWithStorage[127.0.0.1:45885,DS-cbbab791-7443-4751-8b0a-cd7ecd6955b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1242722428-172.17.0.8-1597651907994:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37715,DS-840bffd1-40f4-4077-ab6c-df068e6694fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39913,DS-a232ae05-360b-4f12-a9b1-35dd943476ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41356,DS-d941679b-cbb6-475b-a575-9d405966de66,DISK], DatanodeInfoWithStorage[127.0.0.1:39134,DS-ddc9e5eb-4a56-4cdc-9a8b-95cf8c1f1469,DISK], DatanodeInfoWithStorage[127.0.0.1:33436,DS-9254a8c2-fe84-4e5b-bac6-97919ac1b9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38196,DS-fdaf92a2-3f9d-48ab-aed7-59f92efd28dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46513,DS-8b6a59dd-9393-4725-bc7e-5dcd42a09727,DISK], DatanodeInfoWithStorage[127.0.0.1:41069,DS-0f9f513c-5a66-4956-8165-4cfe271651a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1242722428-172.17.0.8-1597651907994:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37715,DS-840bffd1-40f4-4077-ab6c-df068e6694fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39913,DS-a232ae05-360b-4f12-a9b1-35dd943476ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41356,DS-d941679b-cbb6-475b-a575-9d405966de66,DISK], DatanodeInfoWithStorage[127.0.0.1:39134,DS-ddc9e5eb-4a56-4cdc-9a8b-95cf8c1f1469,DISK], DatanodeInfoWithStorage[127.0.0.1:33436,DS-9254a8c2-fe84-4e5b-bac6-97919ac1b9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38196,DS-fdaf92a2-3f9d-48ab-aed7-59f92efd28dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46513,DS-8b6a59dd-9393-4725-bc7e-5dcd42a09727,DISK], DatanodeInfoWithStorage[127.0.0.1:41069,DS-0f9f513c-5a66-4956-8165-4cfe271651a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-823749474-172.17.0.8-1597652118402:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42600,DS-175a20d4-bedb-45ae-8c43-4e08f86a531d,DISK], DatanodeInfoWithStorage[127.0.0.1:39181,DS-71acb2d0-c07f-45ee-9bd9-09543c6afe04,DISK], DatanodeInfoWithStorage[127.0.0.1:41369,DS-503a7ad1-31e2-4ba4-b16a-be653eab6ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:41035,DS-0a50e93b-856e-451b-94d4-5c50bb182b50,DISK], DatanodeInfoWithStorage[127.0.0.1:33223,DS-c982d771-b68d-4ef5-a562-184864553130,DISK], DatanodeInfoWithStorage[127.0.0.1:43377,DS-0e486c28-f1a5-4ab6-8236-78c191f3bec6,DISK], DatanodeInfoWithStorage[127.0.0.1:33053,DS-3d863e56-3a34-4f6f-9d3f-bc7d58973b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:36043,DS-711da9d4-de42-4183-95f6-e659802d4f87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-823749474-172.17.0.8-1597652118402:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42600,DS-175a20d4-bedb-45ae-8c43-4e08f86a531d,DISK], DatanodeInfoWithStorage[127.0.0.1:39181,DS-71acb2d0-c07f-45ee-9bd9-09543c6afe04,DISK], DatanodeInfoWithStorage[127.0.0.1:41369,DS-503a7ad1-31e2-4ba4-b16a-be653eab6ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:41035,DS-0a50e93b-856e-451b-94d4-5c50bb182b50,DISK], DatanodeInfoWithStorage[127.0.0.1:33223,DS-c982d771-b68d-4ef5-a562-184864553130,DISK], DatanodeInfoWithStorage[127.0.0.1:43377,DS-0e486c28-f1a5-4ab6-8236-78c191f3bec6,DISK], DatanodeInfoWithStorage[127.0.0.1:33053,DS-3d863e56-3a34-4f6f-9d3f-bc7d58973b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:36043,DS-711da9d4-de42-4183-95f6-e659802d4f87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-223637300-172.17.0.8-1597652363431:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36497,DS-49b6602a-62ff-4251-a250-e3610f946119,DISK], DatanodeInfoWithStorage[127.0.0.1:43052,DS-068373ff-9188-42ce-9a00-c79a0a292d97,DISK], DatanodeInfoWithStorage[127.0.0.1:34729,DS-81b70df7-23c7-4bd7-a11e-145cb5335f91,DISK], DatanodeInfoWithStorage[127.0.0.1:34221,DS-db4e429f-6ca2-48e8-aa66-baa68d85f3a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34129,DS-4aed0f73-7bad-4d5a-bb8f-07d59cc45280,DISK], DatanodeInfoWithStorage[127.0.0.1:46826,DS-8f96d87b-2707-4071-b9b1-5f6b3b3da339,DISK], DatanodeInfoWithStorage[127.0.0.1:39206,DS-0c29561d-404f-460f-947b-ff1ab9f7dc52,DISK], DatanodeInfoWithStorage[127.0.0.1:37255,DS-04354085-2493-4694-b30f-9f2287a333f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-223637300-172.17.0.8-1597652363431:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36497,DS-49b6602a-62ff-4251-a250-e3610f946119,DISK], DatanodeInfoWithStorage[127.0.0.1:43052,DS-068373ff-9188-42ce-9a00-c79a0a292d97,DISK], DatanodeInfoWithStorage[127.0.0.1:34729,DS-81b70df7-23c7-4bd7-a11e-145cb5335f91,DISK], DatanodeInfoWithStorage[127.0.0.1:34221,DS-db4e429f-6ca2-48e8-aa66-baa68d85f3a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34129,DS-4aed0f73-7bad-4d5a-bb8f-07d59cc45280,DISK], DatanodeInfoWithStorage[127.0.0.1:46826,DS-8f96d87b-2707-4071-b9b1-5f6b3b3da339,DISK], DatanodeInfoWithStorage[127.0.0.1:39206,DS-0c29561d-404f-460f-947b-ff1ab9f7dc52,DISK], DatanodeInfoWithStorage[127.0.0.1:37255,DS-04354085-2493-4694-b30f-9f2287a333f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1717908812-172.17.0.8-1597652466412:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36189,DS-e2ee2345-7052-4a56-ac10-e267f17484c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35663,DS-b4f5d17d-ed05-4206-8e77-3bf68fb36281,DISK], DatanodeInfoWithStorage[127.0.0.1:38540,DS-83c8ebed-be65-43dc-b5fb-fc14f6822f20,DISK], DatanodeInfoWithStorage[127.0.0.1:45812,DS-a09aa097-4aad-4902-8368-746ee0626bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:39468,DS-29a8855d-ec1c-4f8b-a0cc-56ea67d584d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43375,DS-9ebf0f14-9941-40b0-8952-71791f64ee43,DISK], DatanodeInfoWithStorage[127.0.0.1:34393,DS-b888a88e-1473-4ec1-961f-ecf28d4415cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45565,DS-5b561cb0-d823-4c46-8fe6-fc65bffe2e79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1717908812-172.17.0.8-1597652466412:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36189,DS-e2ee2345-7052-4a56-ac10-e267f17484c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35663,DS-b4f5d17d-ed05-4206-8e77-3bf68fb36281,DISK], DatanodeInfoWithStorage[127.0.0.1:38540,DS-83c8ebed-be65-43dc-b5fb-fc14f6822f20,DISK], DatanodeInfoWithStorage[127.0.0.1:45812,DS-a09aa097-4aad-4902-8368-746ee0626bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:39468,DS-29a8855d-ec1c-4f8b-a0cc-56ea67d584d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43375,DS-9ebf0f14-9941-40b0-8952-71791f64ee43,DISK], DatanodeInfoWithStorage[127.0.0.1:34393,DS-b888a88e-1473-4ec1-961f-ecf28d4415cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45565,DS-5b561cb0-d823-4c46-8fe6-fc65bffe2e79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-730176667-172.17.0.8-1597653107701:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40428,DS-a9c09e4c-806b-44ff-af9f-a8d931e73932,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-dc67060f-7668-4762-bbcb-f2eb8df8a442,DISK], DatanodeInfoWithStorage[127.0.0.1:38953,DS-61ba5f0f-ee13-4f98-ad9d-cb104ff8af46,DISK], DatanodeInfoWithStorage[127.0.0.1:36754,DS-7074c67c-d90d-4e3a-85e1-2b67b484dfa1,DISK], DatanodeInfoWithStorage[127.0.0.1:44164,DS-d4c3179a-479f-46f1-a536-2bc755cf52ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35708,DS-f0994ff0-0631-4434-81b0-1682dcdbbcca,DISK], DatanodeInfoWithStorage[127.0.0.1:34751,DS-3f55c79a-15b2-4fac-a972-1c284d5595dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37507,DS-fdc69270-52d8-4c1a-aaa2-f5f89e33426f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-730176667-172.17.0.8-1597653107701:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40428,DS-a9c09e4c-806b-44ff-af9f-a8d931e73932,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-dc67060f-7668-4762-bbcb-f2eb8df8a442,DISK], DatanodeInfoWithStorage[127.0.0.1:38953,DS-61ba5f0f-ee13-4f98-ad9d-cb104ff8af46,DISK], DatanodeInfoWithStorage[127.0.0.1:36754,DS-7074c67c-d90d-4e3a-85e1-2b67b484dfa1,DISK], DatanodeInfoWithStorage[127.0.0.1:44164,DS-d4c3179a-479f-46f1-a536-2bc755cf52ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35708,DS-f0994ff0-0631-4434-81b0-1682dcdbbcca,DISK], DatanodeInfoWithStorage[127.0.0.1:34751,DS-3f55c79a-15b2-4fac-a972-1c284d5595dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37507,DS-fdc69270-52d8-4c1a-aaa2-f5f89e33426f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-631663859-172.17.0.8-1597653443069:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42382,DS-e20d4d45-4bf8-446e-a9fa-578025b5cbd0,DISK], DatanodeInfoWithStorage[127.0.0.1:36485,DS-6044f9bd-acac-45ef-9109-cd48c088f386,DISK], DatanodeInfoWithStorage[127.0.0.1:39865,DS-581dd3c2-1a02-4d83-b0a7-38d191b8e859,DISK], DatanodeInfoWithStorage[127.0.0.1:34767,DS-45fc0472-cc14-44fb-8b2a-c1f40977c836,DISK], DatanodeInfoWithStorage[127.0.0.1:46101,DS-e717839c-f7da-4f55-ba64-b17a2d1ff7f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42491,DS-1d67c104-57df-45b0-a2cb-2ef113239968,DISK], DatanodeInfoWithStorage[127.0.0.1:42564,DS-80773967-7f6c-44f9-a10f-18249eab401e,DISK], DatanodeInfoWithStorage[127.0.0.1:43869,DS-7670ad5d-80ce-415c-a70c-588ef114c268,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-631663859-172.17.0.8-1597653443069:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42382,DS-e20d4d45-4bf8-446e-a9fa-578025b5cbd0,DISK], DatanodeInfoWithStorage[127.0.0.1:36485,DS-6044f9bd-acac-45ef-9109-cd48c088f386,DISK], DatanodeInfoWithStorage[127.0.0.1:39865,DS-581dd3c2-1a02-4d83-b0a7-38d191b8e859,DISK], DatanodeInfoWithStorage[127.0.0.1:34767,DS-45fc0472-cc14-44fb-8b2a-c1f40977c836,DISK], DatanodeInfoWithStorage[127.0.0.1:46101,DS-e717839c-f7da-4f55-ba64-b17a2d1ff7f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42491,DS-1d67c104-57df-45b0-a2cb-2ef113239968,DISK], DatanodeInfoWithStorage[127.0.0.1:42564,DS-80773967-7f6c-44f9-a10f-18249eab401e,DISK], DatanodeInfoWithStorage[127.0.0.1:43869,DS-7670ad5d-80ce-415c-a70c-588ef114c268,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-989454807-172.17.0.8-1597653598471:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44707,DS-885024af-7463-43ef-97e0-8f7a3e0d9880,DISK], DatanodeInfoWithStorage[127.0.0.1:35946,DS-a3682382-2a9d-4df5-b37c-c08a37fd1d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:40764,DS-dd79ae75-4643-4378-ab7d-93812c3b4f51,DISK], DatanodeInfoWithStorage[127.0.0.1:34711,DS-4d7de00c-e8a2-4297-a0f1-7db5e66a3ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:38704,DS-34c47763-b925-4adf-834f-3961b6609d93,DISK], DatanodeInfoWithStorage[127.0.0.1:41422,DS-e29b0db0-46ee-4000-aab2-99d5b8423a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35729,DS-ab0390fb-3b74-4fe1-a9ae-e39e00dd44d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37709,DS-353656d5-484d-4f6f-96a7-acd24a8ce5ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-989454807-172.17.0.8-1597653598471:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44707,DS-885024af-7463-43ef-97e0-8f7a3e0d9880,DISK], DatanodeInfoWithStorage[127.0.0.1:35946,DS-a3682382-2a9d-4df5-b37c-c08a37fd1d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:40764,DS-dd79ae75-4643-4378-ab7d-93812c3b4f51,DISK], DatanodeInfoWithStorage[127.0.0.1:34711,DS-4d7de00c-e8a2-4297-a0f1-7db5e66a3ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:38704,DS-34c47763-b925-4adf-834f-3961b6609d93,DISK], DatanodeInfoWithStorage[127.0.0.1:41422,DS-e29b0db0-46ee-4000-aab2-99d5b8423a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35729,DS-ab0390fb-3b74-4fe1-a9ae-e39e00dd44d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37709,DS-353656d5-484d-4f6f-96a7-acd24a8ce5ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1434032451-172.17.0.8-1597653971772:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39757,DS-baf5f528-8f5b-4b3e-a80a-19426fcfddac,DISK], DatanodeInfoWithStorage[127.0.0.1:46281,DS-8d9c2c94-423a-4578-815f-89e95d767a80,DISK], DatanodeInfoWithStorage[127.0.0.1:44342,DS-ec5bdf5d-0bbd-4494-a71e-7a8a350871f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34727,DS-a370401b-41ec-4386-934a-c1ef8f1a6d67,DISK], DatanodeInfoWithStorage[127.0.0.1:45593,DS-0beef506-2a8b-4cea-b639-7b3a71729df9,DISK], DatanodeInfoWithStorage[127.0.0.1:41068,DS-f4447abe-2617-4686-bacd-e26f03f3f61a,DISK], DatanodeInfoWithStorage[127.0.0.1:34373,DS-f22c84f6-3dd9-4284-a0ad-67653a10049d,DISK], DatanodeInfoWithStorage[127.0.0.1:41931,DS-6b6a9a34-8253-4feb-b741-aba2d182aa46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1434032451-172.17.0.8-1597653971772:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39757,DS-baf5f528-8f5b-4b3e-a80a-19426fcfddac,DISK], DatanodeInfoWithStorage[127.0.0.1:46281,DS-8d9c2c94-423a-4578-815f-89e95d767a80,DISK], DatanodeInfoWithStorage[127.0.0.1:44342,DS-ec5bdf5d-0bbd-4494-a71e-7a8a350871f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34727,DS-a370401b-41ec-4386-934a-c1ef8f1a6d67,DISK], DatanodeInfoWithStorage[127.0.0.1:45593,DS-0beef506-2a8b-4cea-b639-7b3a71729df9,DISK], DatanodeInfoWithStorage[127.0.0.1:41068,DS-f4447abe-2617-4686-bacd-e26f03f3f61a,DISK], DatanodeInfoWithStorage[127.0.0.1:34373,DS-f22c84f6-3dd9-4284-a0ad-67653a10049d,DISK], DatanodeInfoWithStorage[127.0.0.1:41931,DS-6b6a9a34-8253-4feb-b741-aba2d182aa46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2132284844-172.17.0.8-1597654519405:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36703,DS-c2d33ca7-f5fb-4fe6-94c2-4f48715c34fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33814,DS-e5f47807-4f23-46a8-8e36-0c653da7a432,DISK], DatanodeInfoWithStorage[127.0.0.1:37310,DS-2b1f629d-8410-4f87-92d1-c4b9a1e70ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:36702,DS-289fa285-3cff-40e5-a831-ffee3485f02b,DISK], DatanodeInfoWithStorage[127.0.0.1:42138,DS-ae59606d-d6b3-482b-8194-7eaeac71d847,DISK], DatanodeInfoWithStorage[127.0.0.1:37232,DS-e957e64c-42ee-4a6e-8b29-6722c91b0755,DISK], DatanodeInfoWithStorage[127.0.0.1:34303,DS-db607d4e-45bc-4e02-9f71-3de5416d6108,DISK], DatanodeInfoWithStorage[127.0.0.1:43616,DS-f427d9e5-d761-4ab3-bf44-4ca695f44bfb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2132284844-172.17.0.8-1597654519405:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36703,DS-c2d33ca7-f5fb-4fe6-94c2-4f48715c34fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33814,DS-e5f47807-4f23-46a8-8e36-0c653da7a432,DISK], DatanodeInfoWithStorage[127.0.0.1:37310,DS-2b1f629d-8410-4f87-92d1-c4b9a1e70ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:36702,DS-289fa285-3cff-40e5-a831-ffee3485f02b,DISK], DatanodeInfoWithStorage[127.0.0.1:42138,DS-ae59606d-d6b3-482b-8194-7eaeac71d847,DISK], DatanodeInfoWithStorage[127.0.0.1:37232,DS-e957e64c-42ee-4a6e-8b29-6722c91b0755,DISK], DatanodeInfoWithStorage[127.0.0.1:34303,DS-db607d4e-45bc-4e02-9f71-3de5416d6108,DISK], DatanodeInfoWithStorage[127.0.0.1:43616,DS-f427d9e5-d761-4ab3-bf44-4ca695f44bfb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-520725360-172.17.0.8-1597654987459:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41548,DS-61e3cd37-7d59-41ce-8ca1-befc6c501b97,DISK], DatanodeInfoWithStorage[127.0.0.1:42054,DS-b02b9967-d61c-4497-9492-eac422aa4af2,DISK], DatanodeInfoWithStorage[127.0.0.1:46729,DS-ac825431-6174-4ef2-98fb-5988818b31ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37203,DS-11b5eed4-4d2d-425d-a4ee-57b3e8b142f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38159,DS-1d80e021-5013-48fa-bca8-a5ee60f21822,DISK], DatanodeInfoWithStorage[127.0.0.1:45092,DS-a12ba384-69c3-45b1-9d87-1aabc538b5c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39468,DS-42dfe793-0c60-45ec-b7fc-e976cdac5420,DISK], DatanodeInfoWithStorage[127.0.0.1:35989,DS-b7469177-8830-4a89-be9b-a262f477c9c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-520725360-172.17.0.8-1597654987459:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41548,DS-61e3cd37-7d59-41ce-8ca1-befc6c501b97,DISK], DatanodeInfoWithStorage[127.0.0.1:42054,DS-b02b9967-d61c-4497-9492-eac422aa4af2,DISK], DatanodeInfoWithStorage[127.0.0.1:46729,DS-ac825431-6174-4ef2-98fb-5988818b31ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37203,DS-11b5eed4-4d2d-425d-a4ee-57b3e8b142f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38159,DS-1d80e021-5013-48fa-bca8-a5ee60f21822,DISK], DatanodeInfoWithStorage[127.0.0.1:45092,DS-a12ba384-69c3-45b1-9d87-1aabc538b5c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39468,DS-42dfe793-0c60-45ec-b7fc-e976cdac5420,DISK], DatanodeInfoWithStorage[127.0.0.1:35989,DS-b7469177-8830-4a89-be9b-a262f477c9c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1475571198-172.17.0.8-1597655131201:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37311,DS-23d6101b-6e43-4149-8ac0-983c14e9fd11,DISK], DatanodeInfoWithStorage[127.0.0.1:32776,DS-3675feba-c020-4b2f-9e15-ca54d8a557a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38783,DS-35e31e4e-8c7d-4bdc-8d42-88de2bc4d124,DISK], DatanodeInfoWithStorage[127.0.0.1:33093,DS-d6bbebfa-0782-4ef5-b226-f630def377e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38254,DS-ee7c2ad3-09d3-4d0a-bd2a-ca17f8331459,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-566e9b21-7ac1-4ef0-90e1-bfd37a53cf22,DISK], DatanodeInfoWithStorage[127.0.0.1:46535,DS-7a44e089-6cc8-404a-a925-9633cb8c05d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42965,DS-c7cad964-2b99-4d2c-8311-ac822ab54bd2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1475571198-172.17.0.8-1597655131201:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37311,DS-23d6101b-6e43-4149-8ac0-983c14e9fd11,DISK], DatanodeInfoWithStorage[127.0.0.1:32776,DS-3675feba-c020-4b2f-9e15-ca54d8a557a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38783,DS-35e31e4e-8c7d-4bdc-8d42-88de2bc4d124,DISK], DatanodeInfoWithStorage[127.0.0.1:33093,DS-d6bbebfa-0782-4ef5-b226-f630def377e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38254,DS-ee7c2ad3-09d3-4d0a-bd2a-ca17f8331459,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-566e9b21-7ac1-4ef0-90e1-bfd37a53cf22,DISK], DatanodeInfoWithStorage[127.0.0.1:46535,DS-7a44e089-6cc8-404a-a925-9633cb8c05d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42965,DS-c7cad964-2b99-4d2c-8311-ac822ab54bd2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-937372845-172.17.0.8-1597655264363:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46325,DS-4af72809-1a27-468b-97b0-0f3f0c2309fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40642,DS-53062d9a-fa01-4b99-b129-4760336c0668,DISK], DatanodeInfoWithStorage[127.0.0.1:42095,DS-eec870c4-e278-4e58-9f31-f1539982a5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38434,DS-af78447a-f334-423a-bfb0-a3985a63ad1b,DISK], DatanodeInfoWithStorage[127.0.0.1:36996,DS-c5f8d17e-97b0-43f0-b70c-6bed207c841f,DISK], DatanodeInfoWithStorage[127.0.0.1:46162,DS-c673c71a-ac86-4afb-8243-d4f60ba24d14,DISK], DatanodeInfoWithStorage[127.0.0.1:33228,DS-fa60e66a-e719-4333-aa18-cf72df6ab60f,DISK], DatanodeInfoWithStorage[127.0.0.1:44499,DS-3cb1bb1b-997a-449e-9847-dd41d0dd8ab2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-937372845-172.17.0.8-1597655264363:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46325,DS-4af72809-1a27-468b-97b0-0f3f0c2309fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40642,DS-53062d9a-fa01-4b99-b129-4760336c0668,DISK], DatanodeInfoWithStorage[127.0.0.1:42095,DS-eec870c4-e278-4e58-9f31-f1539982a5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38434,DS-af78447a-f334-423a-bfb0-a3985a63ad1b,DISK], DatanodeInfoWithStorage[127.0.0.1:36996,DS-c5f8d17e-97b0-43f0-b70c-6bed207c841f,DISK], DatanodeInfoWithStorage[127.0.0.1:46162,DS-c673c71a-ac86-4afb-8243-d4f60ba24d14,DISK], DatanodeInfoWithStorage[127.0.0.1:33228,DS-fa60e66a-e719-4333-aa18-cf72df6ab60f,DISK], DatanodeInfoWithStorage[127.0.0.1:44499,DS-3cb1bb1b-997a-449e-9847-dd41d0dd8ab2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-949978702-172.17.0.8-1597655484897:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38762,DS-a1434557-c275-4f72-ba94-88a201fa34f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34789,DS-cd8f7684-7df9-4617-a892-62353060218a,DISK], DatanodeInfoWithStorage[127.0.0.1:44947,DS-98815524-bdd0-47a2-8b70-2d6189af0a45,DISK], DatanodeInfoWithStorage[127.0.0.1:42480,DS-5a6d584d-9459-45f6-8b13-7a06880651e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43867,DS-8e4dde50-a0c5-43a7-8b69-cf2d3f0f5f08,DISK], DatanodeInfoWithStorage[127.0.0.1:38406,DS-b13469d4-9180-4c86-828a-eb7018f9ad76,DISK], DatanodeInfoWithStorage[127.0.0.1:37444,DS-833dd82c-b4fe-4945-b733-44a794c1a365,DISK], DatanodeInfoWithStorage[127.0.0.1:40866,DS-2f8b95cb-cdf5-4002-a074-1a6ee1169ea3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-949978702-172.17.0.8-1597655484897:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38762,DS-a1434557-c275-4f72-ba94-88a201fa34f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34789,DS-cd8f7684-7df9-4617-a892-62353060218a,DISK], DatanodeInfoWithStorage[127.0.0.1:44947,DS-98815524-bdd0-47a2-8b70-2d6189af0a45,DISK], DatanodeInfoWithStorage[127.0.0.1:42480,DS-5a6d584d-9459-45f6-8b13-7a06880651e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43867,DS-8e4dde50-a0c5-43a7-8b69-cf2d3f0f5f08,DISK], DatanodeInfoWithStorage[127.0.0.1:38406,DS-b13469d4-9180-4c86-828a-eb7018f9ad76,DISK], DatanodeInfoWithStorage[127.0.0.1:37444,DS-833dd82c-b4fe-4945-b733-44a794c1a365,DISK], DatanodeInfoWithStorage[127.0.0.1:40866,DS-2f8b95cb-cdf5-4002-a074-1a6ee1169ea3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1175344176-172.17.0.8-1597655658194:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44778,DS-03b4525b-876d-4e57-9776-7c2989bbadcf,DISK], DatanodeInfoWithStorage[127.0.0.1:46170,DS-a50c0f09-b9f3-4c36-aa4a-04103e8e9a74,DISK], DatanodeInfoWithStorage[127.0.0.1:32962,DS-2a1da488-0427-4d05-9c2e-24b47bf9fa5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35558,DS-e9561e86-2c24-4dbc-b66d-29b64cfaffaf,DISK], DatanodeInfoWithStorage[127.0.0.1:39339,DS-f6a1dd93-5237-4143-967f-bc381db2c08a,DISK], DatanodeInfoWithStorage[127.0.0.1:36860,DS-2a160ba4-81af-45f3-9682-3888e58239c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42276,DS-f617804d-8902-457a-ab7f-96853e458724,DISK], DatanodeInfoWithStorage[127.0.0.1:42110,DS-761cfa2d-5a43-4da7-be69-0c40b64dbd12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1175344176-172.17.0.8-1597655658194:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44778,DS-03b4525b-876d-4e57-9776-7c2989bbadcf,DISK], DatanodeInfoWithStorage[127.0.0.1:46170,DS-a50c0f09-b9f3-4c36-aa4a-04103e8e9a74,DISK], DatanodeInfoWithStorage[127.0.0.1:32962,DS-2a1da488-0427-4d05-9c2e-24b47bf9fa5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35558,DS-e9561e86-2c24-4dbc-b66d-29b64cfaffaf,DISK], DatanodeInfoWithStorage[127.0.0.1:39339,DS-f6a1dd93-5237-4143-967f-bc381db2c08a,DISK], DatanodeInfoWithStorage[127.0.0.1:36860,DS-2a160ba4-81af-45f3-9682-3888e58239c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42276,DS-f617804d-8902-457a-ab7f-96853e458724,DISK], DatanodeInfoWithStorage[127.0.0.1:42110,DS-761cfa2d-5a43-4da7-be69-0c40b64dbd12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: might be true error
Total execution time in seconds : 5215
