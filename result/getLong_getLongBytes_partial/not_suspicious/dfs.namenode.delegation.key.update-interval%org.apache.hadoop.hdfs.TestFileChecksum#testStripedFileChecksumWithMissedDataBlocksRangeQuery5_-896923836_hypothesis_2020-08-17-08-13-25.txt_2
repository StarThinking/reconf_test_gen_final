reconf_parameter: dfs.namenode.delegation.key.update-interval
component: hdfs:NameNode
v1: 10
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.key.update-interval
component: hdfs:NameNode
v1: 10
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-940065032-172.17.0.10-1597652675779:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39172,DS-07aae4fa-f041-4c30-ab52-e168f415e791,DISK], DatanodeInfoWithStorage[127.0.0.1:34166,DS-1d9b027e-724b-4694-bd68-279ca8650548,DISK], DatanodeInfoWithStorage[127.0.0.1:35415,DS-b52d186e-ac60-4f35-ad58-ac71cf27ba86,DISK], DatanodeInfoWithStorage[127.0.0.1:44516,DS-798cc884-4691-4c6c-9e3b-62ec1c8f42f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36468,DS-44a356a3-e4cc-4602-8091-48fb3ad81072,DISK], DatanodeInfoWithStorage[127.0.0.1:45827,DS-759bb42c-c037-4109-b470-085eea2eef14,DISK], DatanodeInfoWithStorage[127.0.0.1:35685,DS-c5c77b92-6be8-4801-b58c-6b42d0c89d30,DISK], DatanodeInfoWithStorage[127.0.0.1:34508,DS-8190c6bb-60df-4ada-aec1-9209708fb6c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-940065032-172.17.0.10-1597652675779:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39172,DS-07aae4fa-f041-4c30-ab52-e168f415e791,DISK], DatanodeInfoWithStorage[127.0.0.1:34166,DS-1d9b027e-724b-4694-bd68-279ca8650548,DISK], DatanodeInfoWithStorage[127.0.0.1:35415,DS-b52d186e-ac60-4f35-ad58-ac71cf27ba86,DISK], DatanodeInfoWithStorage[127.0.0.1:44516,DS-798cc884-4691-4c6c-9e3b-62ec1c8f42f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36468,DS-44a356a3-e4cc-4602-8091-48fb3ad81072,DISK], DatanodeInfoWithStorage[127.0.0.1:45827,DS-759bb42c-c037-4109-b470-085eea2eef14,DISK], DatanodeInfoWithStorage[127.0.0.1:35685,DS-c5c77b92-6be8-4801-b58c-6b42d0c89d30,DISK], DatanodeInfoWithStorage[127.0.0.1:34508,DS-8190c6bb-60df-4ada-aec1-9209708fb6c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.key.update-interval
component: hdfs:NameNode
v1: 10
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-244312891-172.17.0.10-1597652709041:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40441,DS-0aa654c1-de71-43d2-b26a-12f5b4fda9e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36496,DS-fb36c90f-01c6-4169-8f69-06c0d01bfa45,DISK], DatanodeInfoWithStorage[127.0.0.1:46340,DS-e5a4ce71-2944-4fc5-a198-9a57038b7356,DISK], DatanodeInfoWithStorage[127.0.0.1:36398,DS-96d255c1-7f98-41b1-89a6-02925b354278,DISK], DatanodeInfoWithStorage[127.0.0.1:45104,DS-d622b117-4866-4c06-914a-cb9ae6efdfe6,DISK], DatanodeInfoWithStorage[127.0.0.1:42246,DS-4dd37f0c-598e-4b7f-b39a-1ef61c7f37a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41410,DS-da196388-334b-4f75-b085-9a5ffb357c65,DISK], DatanodeInfoWithStorage[127.0.0.1:38676,DS-fbd97a51-0c31-4d94-9f59-b316399e335b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-244312891-172.17.0.10-1597652709041:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40441,DS-0aa654c1-de71-43d2-b26a-12f5b4fda9e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36496,DS-fb36c90f-01c6-4169-8f69-06c0d01bfa45,DISK], DatanodeInfoWithStorage[127.0.0.1:46340,DS-e5a4ce71-2944-4fc5-a198-9a57038b7356,DISK], DatanodeInfoWithStorage[127.0.0.1:36398,DS-96d255c1-7f98-41b1-89a6-02925b354278,DISK], DatanodeInfoWithStorage[127.0.0.1:45104,DS-d622b117-4866-4c06-914a-cb9ae6efdfe6,DISK], DatanodeInfoWithStorage[127.0.0.1:42246,DS-4dd37f0c-598e-4b7f-b39a-1ef61c7f37a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41410,DS-da196388-334b-4f75-b085-9a5ffb357c65,DISK], DatanodeInfoWithStorage[127.0.0.1:38676,DS-fbd97a51-0c31-4d94-9f59-b316399e335b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.key.update-interval
component: hdfs:NameNode
v1: 10
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1310011451-172.17.0.10-1597653445373:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45564,DS-fca9b29d-1651-4f0a-b718-e2996211340b,DISK], DatanodeInfoWithStorage[127.0.0.1:40941,DS-a0901407-ae0a-44f1-a118-6bcd152fe998,DISK], DatanodeInfoWithStorage[127.0.0.1:46042,DS-416854fd-48fd-4f5a-94c0-c8d8a92a7bae,DISK], DatanodeInfoWithStorage[127.0.0.1:34214,DS-2cfaf05c-fd63-4299-9d69-2b6a918982c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41650,DS-1e44ff78-caa6-492a-a6ec-39a3b4c61102,DISK], DatanodeInfoWithStorage[127.0.0.1:36472,DS-a13ab7cb-660f-492d-aa5b-9107b023b2bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39234,DS-d56d5ea9-705d-48a8-adae-016a7a410e11,DISK], DatanodeInfoWithStorage[127.0.0.1:33968,DS-c2ddaa87-bc14-4e07-a95a-541b75999056,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1310011451-172.17.0.10-1597653445373:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45564,DS-fca9b29d-1651-4f0a-b718-e2996211340b,DISK], DatanodeInfoWithStorage[127.0.0.1:40941,DS-a0901407-ae0a-44f1-a118-6bcd152fe998,DISK], DatanodeInfoWithStorage[127.0.0.1:46042,DS-416854fd-48fd-4f5a-94c0-c8d8a92a7bae,DISK], DatanodeInfoWithStorage[127.0.0.1:34214,DS-2cfaf05c-fd63-4299-9d69-2b6a918982c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41650,DS-1e44ff78-caa6-492a-a6ec-39a3b4c61102,DISK], DatanodeInfoWithStorage[127.0.0.1:36472,DS-a13ab7cb-660f-492d-aa5b-9107b023b2bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39234,DS-d56d5ea9-705d-48a8-adae-016a7a410e11,DISK], DatanodeInfoWithStorage[127.0.0.1:33968,DS-c2ddaa87-bc14-4e07-a95a-541b75999056,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.key.update-interval
component: hdfs:NameNode
v1: 10
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2112866320-172.17.0.10-1597653666953:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45997,DS-93b26b38-7825-4cb1-8918-2106043d69d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46007,DS-5ac31337-79f3-47fd-8a72-e0eb0c15ffe4,DISK], DatanodeInfoWithStorage[127.0.0.1:46452,DS-81b56b04-f271-42b8-8bf9-88a760bc7f59,DISK], DatanodeInfoWithStorage[127.0.0.1:38577,DS-03ee068c-375e-41ec-a273-b58aec874eef,DISK], DatanodeInfoWithStorage[127.0.0.1:40683,DS-11161844-9281-457e-95dc-d1935eae4fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:42401,DS-14254ff4-0bad-407d-aa5e-95b3a702cfd4,DISK], DatanodeInfoWithStorage[127.0.0.1:39063,DS-c1a8a87d-b6a6-4f06-8a0c-68e062f380db,DISK], DatanodeInfoWithStorage[127.0.0.1:45176,DS-c7642aff-a0d7-4a3f-9be9-6396af9a972d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2112866320-172.17.0.10-1597653666953:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45997,DS-93b26b38-7825-4cb1-8918-2106043d69d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46007,DS-5ac31337-79f3-47fd-8a72-e0eb0c15ffe4,DISK], DatanodeInfoWithStorage[127.0.0.1:46452,DS-81b56b04-f271-42b8-8bf9-88a760bc7f59,DISK], DatanodeInfoWithStorage[127.0.0.1:38577,DS-03ee068c-375e-41ec-a273-b58aec874eef,DISK], DatanodeInfoWithStorage[127.0.0.1:40683,DS-11161844-9281-457e-95dc-d1935eae4fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:42401,DS-14254ff4-0bad-407d-aa5e-95b3a702cfd4,DISK], DatanodeInfoWithStorage[127.0.0.1:39063,DS-c1a8a87d-b6a6-4f06-8a0c-68e062f380db,DISK], DatanodeInfoWithStorage[127.0.0.1:45176,DS-c7642aff-a0d7-4a3f-9be9-6396af9a972d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.key.update-interval
component: hdfs:NameNode
v1: 10
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-321762042-172.17.0.10-1597653822317:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41480,DS-71b63a4d-c4c1-47bf-b72a-c8ca268d119a,DISK], DatanodeInfoWithStorage[127.0.0.1:44504,DS-9e658f81-baf3-48ad-8722-2b1a26bac47f,DISK], DatanodeInfoWithStorage[127.0.0.1:40859,DS-84e0d3a1-1daf-4c18-a3b4-9a13332d3a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:41651,DS-bdee8538-6c10-4b8b-9813-b3ddb6736c51,DISK], DatanodeInfoWithStorage[127.0.0.1:46291,DS-07318d85-a65e-4d83-b27c-fe70bcd80b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43685,DS-28b8154a-ceb9-4833-bf0d-dea542760fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:45617,DS-b1b687e9-93cb-4d48-9125-8800e1ce8324,DISK], DatanodeInfoWithStorage[127.0.0.1:33839,DS-c870c043-3197-4f53-8893-b5cf7e7dfa99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-321762042-172.17.0.10-1597653822317:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41480,DS-71b63a4d-c4c1-47bf-b72a-c8ca268d119a,DISK], DatanodeInfoWithStorage[127.0.0.1:44504,DS-9e658f81-baf3-48ad-8722-2b1a26bac47f,DISK], DatanodeInfoWithStorage[127.0.0.1:40859,DS-84e0d3a1-1daf-4c18-a3b4-9a13332d3a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:41651,DS-bdee8538-6c10-4b8b-9813-b3ddb6736c51,DISK], DatanodeInfoWithStorage[127.0.0.1:46291,DS-07318d85-a65e-4d83-b27c-fe70bcd80b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43685,DS-28b8154a-ceb9-4833-bf0d-dea542760fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:45617,DS-b1b687e9-93cb-4d48-9125-8800e1ce8324,DISK], DatanodeInfoWithStorage[127.0.0.1:33839,DS-c870c043-3197-4f53-8893-b5cf7e7dfa99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.key.update-interval
component: hdfs:NameNode
v1: 10
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-391801726-172.17.0.10-1597653867131:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34758,DS-e6fcc4a7-d19a-472b-bdce-544a1a4d2efe,DISK], DatanodeInfoWithStorage[127.0.0.1:33305,DS-dd1c64b2-cea7-4e1c-a5cc-1f21f0fb8277,DISK], DatanodeInfoWithStorage[127.0.0.1:37568,DS-2cf3133f-c67c-4fce-bc0d-5061d9cfc5bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43050,DS-a38d85ea-578e-413a-a49b-969438712b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:35593,DS-b6f82743-ec26-4d34-a60a-39613e757177,DISK], DatanodeInfoWithStorage[127.0.0.1:39965,DS-ee625be9-e60d-4ba3-8654-ed79b9d293f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46077,DS-6ab7b5fc-49a3-406e-98ae-18c8b6e63be2,DISK], DatanodeInfoWithStorage[127.0.0.1:43066,DS-c60ea53c-6fcd-46cd-a4b9-0de4d1f9b456,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-391801726-172.17.0.10-1597653867131:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34758,DS-e6fcc4a7-d19a-472b-bdce-544a1a4d2efe,DISK], DatanodeInfoWithStorage[127.0.0.1:33305,DS-dd1c64b2-cea7-4e1c-a5cc-1f21f0fb8277,DISK], DatanodeInfoWithStorage[127.0.0.1:37568,DS-2cf3133f-c67c-4fce-bc0d-5061d9cfc5bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43050,DS-a38d85ea-578e-413a-a49b-969438712b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:35593,DS-b6f82743-ec26-4d34-a60a-39613e757177,DISK], DatanodeInfoWithStorage[127.0.0.1:39965,DS-ee625be9-e60d-4ba3-8654-ed79b9d293f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46077,DS-6ab7b5fc-49a3-406e-98ae-18c8b6e63be2,DISK], DatanodeInfoWithStorage[127.0.0.1:43066,DS-c60ea53c-6fcd-46cd-a4b9-0de4d1f9b456,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.key.update-interval
component: hdfs:NameNode
v1: 10
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-393916931-172.17.0.10-1597654082510:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35919,DS-77be525f-e193-454a-944f-8ca9de73332d,DISK], DatanodeInfoWithStorage[127.0.0.1:44090,DS-ac8e3966-5688-4a77-95e3-52d652370abe,DISK], DatanodeInfoWithStorage[127.0.0.1:35981,DS-b0919312-3597-4a53-8970-e7d4c57b880c,DISK], DatanodeInfoWithStorage[127.0.0.1:40083,DS-d6414e55-8a68-4419-b645-44d04565e47d,DISK], DatanodeInfoWithStorage[127.0.0.1:45638,DS-d896b12f-597b-40cb-bebb-0e9a02f4da48,DISK], DatanodeInfoWithStorage[127.0.0.1:38507,DS-6724360c-2460-49a0-b767-a8af5552e4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35215,DS-f214afe6-a433-4920-ad13-4a6d169ced03,DISK], DatanodeInfoWithStorage[127.0.0.1:46019,DS-98254e0c-1678-4bfb-881a-712ac43f3bc7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-393916931-172.17.0.10-1597654082510:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35919,DS-77be525f-e193-454a-944f-8ca9de73332d,DISK], DatanodeInfoWithStorage[127.0.0.1:44090,DS-ac8e3966-5688-4a77-95e3-52d652370abe,DISK], DatanodeInfoWithStorage[127.0.0.1:35981,DS-b0919312-3597-4a53-8970-e7d4c57b880c,DISK], DatanodeInfoWithStorage[127.0.0.1:40083,DS-d6414e55-8a68-4419-b645-44d04565e47d,DISK], DatanodeInfoWithStorage[127.0.0.1:45638,DS-d896b12f-597b-40cb-bebb-0e9a02f4da48,DISK], DatanodeInfoWithStorage[127.0.0.1:38507,DS-6724360c-2460-49a0-b767-a8af5552e4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35215,DS-f214afe6-a433-4920-ad13-4a6d169ced03,DISK], DatanodeInfoWithStorage[127.0.0.1:46019,DS-98254e0c-1678-4bfb-881a-712ac43f3bc7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.key.update-interval
component: hdfs:NameNode
v1: 10
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-3482811-172.17.0.10-1597654339063:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36716,DS-4919fb8c-9e24-4788-a0e6-8f849d7d23ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42437,DS-56de1907-17ba-4028-8250-40cdc30df6e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37651,DS-af3fa80d-a3dd-495d-a7aa-aa468ee793f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43832,DS-9ee19af3-1538-4012-b4f2-2bff789d5c33,DISK], DatanodeInfoWithStorage[127.0.0.1:39360,DS-73ede3ff-9b11-4d41-8c70-ba0657c68572,DISK], DatanodeInfoWithStorage[127.0.0.1:33690,DS-8f58b072-0335-447a-85d9-2a43535e8bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:40694,DS-3c88a1bf-13f8-4edb-9226-dcc8215d764d,DISK], DatanodeInfoWithStorage[127.0.0.1:43220,DS-9a5b1ca8-a8e9-485e-985c-9f8954568a0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-3482811-172.17.0.10-1597654339063:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36716,DS-4919fb8c-9e24-4788-a0e6-8f849d7d23ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42437,DS-56de1907-17ba-4028-8250-40cdc30df6e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37651,DS-af3fa80d-a3dd-495d-a7aa-aa468ee793f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43832,DS-9ee19af3-1538-4012-b4f2-2bff789d5c33,DISK], DatanodeInfoWithStorage[127.0.0.1:39360,DS-73ede3ff-9b11-4d41-8c70-ba0657c68572,DISK], DatanodeInfoWithStorage[127.0.0.1:33690,DS-8f58b072-0335-447a-85d9-2a43535e8bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:40694,DS-3c88a1bf-13f8-4edb-9226-dcc8215d764d,DISK], DatanodeInfoWithStorage[127.0.0.1:43220,DS-9a5b1ca8-a8e9-485e-985c-9f8954568a0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.key.update-interval
component: hdfs:NameNode
v1: 10
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1466173372-172.17.0.10-1597654787389:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43840,DS-c166f91c-0930-48f4-a779-3d64c2049851,DISK], DatanodeInfoWithStorage[127.0.0.1:46112,DS-a345b5ca-b058-40c9-ac66-7ae11383f4fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39385,DS-2a7c3d04-27b6-4978-874d-15ac37a3a582,DISK], DatanodeInfoWithStorage[127.0.0.1:38034,DS-21a0b646-466b-4d41-bd81-47c105bb02d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41196,DS-9a937eb2-5df1-4c97-ac1c-149dde969bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:34628,DS-09d5e402-9ccf-45c1-b322-b8f578b63b33,DISK], DatanodeInfoWithStorage[127.0.0.1:37780,DS-b8547598-962a-44dd-b829-5a42cbe5785e,DISK], DatanodeInfoWithStorage[127.0.0.1:35022,DS-3a778ae5-7eec-4251-9f83-de923315767e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1466173372-172.17.0.10-1597654787389:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43840,DS-c166f91c-0930-48f4-a779-3d64c2049851,DISK], DatanodeInfoWithStorage[127.0.0.1:46112,DS-a345b5ca-b058-40c9-ac66-7ae11383f4fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39385,DS-2a7c3d04-27b6-4978-874d-15ac37a3a582,DISK], DatanodeInfoWithStorage[127.0.0.1:38034,DS-21a0b646-466b-4d41-bd81-47c105bb02d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41196,DS-9a937eb2-5df1-4c97-ac1c-149dde969bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:34628,DS-09d5e402-9ccf-45c1-b322-b8f578b63b33,DISK], DatanodeInfoWithStorage[127.0.0.1:37780,DS-b8547598-962a-44dd-b829-5a42cbe5785e,DISK], DatanodeInfoWithStorage[127.0.0.1:35022,DS-3a778ae5-7eec-4251-9f83-de923315767e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.key.update-interval
component: hdfs:NameNode
v1: 10
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2110114862-172.17.0.10-1597654860119:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42787,DS-bc63abb8-696e-4e54-adf2-64a5a9393352,DISK], DatanodeInfoWithStorage[127.0.0.1:40810,DS-fab4df29-4923-4020-a341-614163e4f27f,DISK], DatanodeInfoWithStorage[127.0.0.1:35694,DS-888da695-e0c7-4dfd-9d97-ca5a9fb63fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:44983,DS-71697541-478c-4c84-bc7c-d57d11a4ac72,DISK], DatanodeInfoWithStorage[127.0.0.1:41247,DS-06681417-f6e0-446a-9033-2bd72d692157,DISK], DatanodeInfoWithStorage[127.0.0.1:32839,DS-05c311ba-7ea9-45e1-b1e6-bfcaf2842df0,DISK], DatanodeInfoWithStorage[127.0.0.1:37789,DS-a8a95f84-6742-445d-aff0-50dd525fcc5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38927,DS-4dfc99bd-822b-452d-9f24-d2537a32c982,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2110114862-172.17.0.10-1597654860119:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42787,DS-bc63abb8-696e-4e54-adf2-64a5a9393352,DISK], DatanodeInfoWithStorage[127.0.0.1:40810,DS-fab4df29-4923-4020-a341-614163e4f27f,DISK], DatanodeInfoWithStorage[127.0.0.1:35694,DS-888da695-e0c7-4dfd-9d97-ca5a9fb63fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:44983,DS-71697541-478c-4c84-bc7c-d57d11a4ac72,DISK], DatanodeInfoWithStorage[127.0.0.1:41247,DS-06681417-f6e0-446a-9033-2bd72d692157,DISK], DatanodeInfoWithStorage[127.0.0.1:32839,DS-05c311ba-7ea9-45e1-b1e6-bfcaf2842df0,DISK], DatanodeInfoWithStorage[127.0.0.1:37789,DS-a8a95f84-6742-445d-aff0-50dd525fcc5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38927,DS-4dfc99bd-822b-452d-9f24-d2537a32c982,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.key.update-interval
component: hdfs:NameNode
v1: 10
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-7203222-172.17.0.10-1597655310487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43352,DS-042b6bdc-5971-410f-b735-6b5fc240770f,DISK], DatanodeInfoWithStorage[127.0.0.1:34069,DS-581ad109-ec27-4b62-af14-6991ac1bc954,DISK], DatanodeInfoWithStorage[127.0.0.1:32842,DS-9accda00-03a6-44fa-9c6a-f4ebe6857b17,DISK], DatanodeInfoWithStorage[127.0.0.1:38779,DS-1497d754-88e4-4025-a0cc-8927f64df41a,DISK], DatanodeInfoWithStorage[127.0.0.1:45629,DS-65193bc1-dffa-42ef-8529-1a094b0d70c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42433,DS-e3379d1b-63d2-4492-a711-5617be05dd43,DISK], DatanodeInfoWithStorage[127.0.0.1:33943,DS-134c8905-463f-4818-bfd6-7cc9dd639bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:42017,DS-55b7b9e1-adeb-4d68-9fd8-2786dd15d8b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-7203222-172.17.0.10-1597655310487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43352,DS-042b6bdc-5971-410f-b735-6b5fc240770f,DISK], DatanodeInfoWithStorage[127.0.0.1:34069,DS-581ad109-ec27-4b62-af14-6991ac1bc954,DISK], DatanodeInfoWithStorage[127.0.0.1:32842,DS-9accda00-03a6-44fa-9c6a-f4ebe6857b17,DISK], DatanodeInfoWithStorage[127.0.0.1:38779,DS-1497d754-88e4-4025-a0cc-8927f64df41a,DISK], DatanodeInfoWithStorage[127.0.0.1:45629,DS-65193bc1-dffa-42ef-8529-1a094b0d70c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42433,DS-e3379d1b-63d2-4492-a711-5617be05dd43,DISK], DatanodeInfoWithStorage[127.0.0.1:33943,DS-134c8905-463f-4818-bfd6-7cc9dd639bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:42017,DS-55b7b9e1-adeb-4d68-9fd8-2786dd15d8b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.key.update-interval
component: hdfs:NameNode
v1: 10
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-246825651-172.17.0.10-1597655578875:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38890,DS-9b3bca17-a289-4067-beb8-f95fcf0d1cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:46454,DS-2ec2a750-d186-45d9-9c7c-5db9ebdd33db,DISK], DatanodeInfoWithStorage[127.0.0.1:40760,DS-c111ce17-a1e9-4ac7-871b-21c03b0ac779,DISK], DatanodeInfoWithStorage[127.0.0.1:42502,DS-cb5253aa-42cf-4d95-bae3-73b615ef33a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46370,DS-291eadbd-1a9e-4a0c-97d9-b55fbba14e14,DISK], DatanodeInfoWithStorage[127.0.0.1:33400,DS-39539773-4b3c-44af-a4c5-6332c5ee415b,DISK], DatanodeInfoWithStorage[127.0.0.1:38380,DS-51c1a621-fd66-4386-acde-d6b9ad85b25b,DISK], DatanodeInfoWithStorage[127.0.0.1:45548,DS-cf4e305a-2565-40ab-96aa-165e196701ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-246825651-172.17.0.10-1597655578875:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38890,DS-9b3bca17-a289-4067-beb8-f95fcf0d1cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:46454,DS-2ec2a750-d186-45d9-9c7c-5db9ebdd33db,DISK], DatanodeInfoWithStorage[127.0.0.1:40760,DS-c111ce17-a1e9-4ac7-871b-21c03b0ac779,DISK], DatanodeInfoWithStorage[127.0.0.1:42502,DS-cb5253aa-42cf-4d95-bae3-73b615ef33a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46370,DS-291eadbd-1a9e-4a0c-97d9-b55fbba14e14,DISK], DatanodeInfoWithStorage[127.0.0.1:33400,DS-39539773-4b3c-44af-a4c5-6332c5ee415b,DISK], DatanodeInfoWithStorage[127.0.0.1:38380,DS-51c1a621-fd66-4386-acde-d6b9ad85b25b,DISK], DatanodeInfoWithStorage[127.0.0.1:45548,DS-cf4e305a-2565-40ab-96aa-165e196701ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.key.update-interval
component: hdfs:NameNode
v1: 10
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-563745518-172.17.0.10-1597655621943:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39513,DS-7373651b-e1bc-465c-9b7a-e55b92e60c57,DISK], DatanodeInfoWithStorage[127.0.0.1:40394,DS-56e981b4-c390-48e1-81df-2486061f077d,DISK], DatanodeInfoWithStorage[127.0.0.1:33451,DS-41f6d9fe-c52c-440d-afb4-24a50680d132,DISK], DatanodeInfoWithStorage[127.0.0.1:32778,DS-df31e7fe-fb2a-4490-a16a-5ebca7fa3104,DISK], DatanodeInfoWithStorage[127.0.0.1:46488,DS-967cc2e0-3dd7-472a-be0f-ec69b289baa3,DISK], DatanodeInfoWithStorage[127.0.0.1:39881,DS-2f2c5aff-412a-45be-8f1e-4a16de375e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38383,DS-24626b27-109c-48da-beaa-5bc0545e042d,DISK], DatanodeInfoWithStorage[127.0.0.1:34765,DS-03d0d552-03ae-43a2-bcb3-44bc8e585f15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-563745518-172.17.0.10-1597655621943:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39513,DS-7373651b-e1bc-465c-9b7a-e55b92e60c57,DISK], DatanodeInfoWithStorage[127.0.0.1:40394,DS-56e981b4-c390-48e1-81df-2486061f077d,DISK], DatanodeInfoWithStorage[127.0.0.1:33451,DS-41f6d9fe-c52c-440d-afb4-24a50680d132,DISK], DatanodeInfoWithStorage[127.0.0.1:32778,DS-df31e7fe-fb2a-4490-a16a-5ebca7fa3104,DISK], DatanodeInfoWithStorage[127.0.0.1:46488,DS-967cc2e0-3dd7-472a-be0f-ec69b289baa3,DISK], DatanodeInfoWithStorage[127.0.0.1:39881,DS-2f2c5aff-412a-45be-8f1e-4a16de375e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38383,DS-24626b27-109c-48da-beaa-5bc0545e042d,DISK], DatanodeInfoWithStorage[127.0.0.1:34765,DS-03d0d552-03ae-43a2-bcb3-44bc8e585f15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.key.update-interval
component: hdfs:NameNode
v1: 10
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-245203578-172.17.0.10-1597655690203:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42671,DS-cb8b8dc7-6455-44d7-8ef2-17ddae91e22a,DISK], DatanodeInfoWithStorage[127.0.0.1:34501,DS-2d6f3d99-2b86-465f-a0cb-6dc4a66f9625,DISK], DatanodeInfoWithStorage[127.0.0.1:33528,DS-e9fdc09b-a4d4-46d7-9564-4b9f378d8b62,DISK], DatanodeInfoWithStorage[127.0.0.1:44948,DS-9689c9e3-fef6-45c4-aed0-7571c0bf652b,DISK], DatanodeInfoWithStorage[127.0.0.1:33987,DS-ffe211aa-2b06-4685-b24c-8c27b14a1aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:33926,DS-6dccab1b-ddb0-40c0-8fb4-6d99279513cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33226,DS-09d8db5c-c30a-4438-a32b-004a52c57d57,DISK], DatanodeInfoWithStorage[127.0.0.1:39222,DS-3261da1e-7b52-4fc2-8895-ce66566ea27c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-245203578-172.17.0.10-1597655690203:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42671,DS-cb8b8dc7-6455-44d7-8ef2-17ddae91e22a,DISK], DatanodeInfoWithStorage[127.0.0.1:34501,DS-2d6f3d99-2b86-465f-a0cb-6dc4a66f9625,DISK], DatanodeInfoWithStorage[127.0.0.1:33528,DS-e9fdc09b-a4d4-46d7-9564-4b9f378d8b62,DISK], DatanodeInfoWithStorage[127.0.0.1:44948,DS-9689c9e3-fef6-45c4-aed0-7571c0bf652b,DISK], DatanodeInfoWithStorage[127.0.0.1:33987,DS-ffe211aa-2b06-4685-b24c-8c27b14a1aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:33926,DS-6dccab1b-ddb0-40c0-8fb4-6d99279513cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33226,DS-09d8db5c-c30a-4438-a32b-004a52c57d57,DISK], DatanodeInfoWithStorage[127.0.0.1:39222,DS-3261da1e-7b52-4fc2-8895-ce66566ea27c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.key.update-interval
component: hdfs:NameNode
v1: 10
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1726830503-172.17.0.10-1597655810998:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44759,DS-e4db0f25-40e3-46f0-a549-5d09545b0cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:40378,DS-6ef99e1e-369c-4f89-af55-e0d54c5698d0,DISK], DatanodeInfoWithStorage[127.0.0.1:32930,DS-32edd38a-6725-4802-ad07-01b8d9d609bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-f8a06ee6-391e-4e98-9a08-436bb8e14de7,DISK], DatanodeInfoWithStorage[127.0.0.1:37417,DS-0e21dcab-03e0-43ae-b1ec-9970ad3f6540,DISK], DatanodeInfoWithStorage[127.0.0.1:37152,DS-52b9f78a-66a2-4210-8415-4b0a9f847017,DISK], DatanodeInfoWithStorage[127.0.0.1:34785,DS-c06ab906-f594-48dc-8465-dc8e39f0b2cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-5df0cf9b-226a-4c11-8eda-a09cfd408086,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1726830503-172.17.0.10-1597655810998:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44759,DS-e4db0f25-40e3-46f0-a549-5d09545b0cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:40378,DS-6ef99e1e-369c-4f89-af55-e0d54c5698d0,DISK], DatanodeInfoWithStorage[127.0.0.1:32930,DS-32edd38a-6725-4802-ad07-01b8d9d609bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-f8a06ee6-391e-4e98-9a08-436bb8e14de7,DISK], DatanodeInfoWithStorage[127.0.0.1:37417,DS-0e21dcab-03e0-43ae-b1ec-9970ad3f6540,DISK], DatanodeInfoWithStorage[127.0.0.1:37152,DS-52b9f78a-66a2-4210-8415-4b0a9f847017,DISK], DatanodeInfoWithStorage[127.0.0.1:34785,DS-c06ab906-f594-48dc-8465-dc8e39f0b2cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-5df0cf9b-226a-4c11-8eda-a09cfd408086,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.key.update-interval
component: hdfs:NameNode
v1: 10
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1548324074-172.17.0.10-1597655894480:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46300,DS-9a5bd615-9af5-40ed-ac0d-2c14b5b1b759,DISK], DatanodeInfoWithStorage[127.0.0.1:46489,DS-c7240b0e-b4cf-4281-9124-a502983bcada,DISK], DatanodeInfoWithStorage[127.0.0.1:33793,DS-cced2019-896d-4df9-b88d-082b277d50bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40406,DS-fce8a892-15b3-4a51-9a3c-b56b3d3a1996,DISK], DatanodeInfoWithStorage[127.0.0.1:34643,DS-3769a0ad-bf46-4626-a9c1-e2a9f9adac54,DISK], DatanodeInfoWithStorage[127.0.0.1:35625,DS-58894de7-0952-4eb5-b0db-7f6e0f724764,DISK], DatanodeInfoWithStorage[127.0.0.1:46418,DS-ae2d7d18-52ec-4ebc-9cf7-ebcab987e40f,DISK], DatanodeInfoWithStorage[127.0.0.1:43638,DS-0bf510f8-78ed-467c-b062-f0f82fc21e5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1548324074-172.17.0.10-1597655894480:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46300,DS-9a5bd615-9af5-40ed-ac0d-2c14b5b1b759,DISK], DatanodeInfoWithStorage[127.0.0.1:46489,DS-c7240b0e-b4cf-4281-9124-a502983bcada,DISK], DatanodeInfoWithStorage[127.0.0.1:33793,DS-cced2019-896d-4df9-b88d-082b277d50bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40406,DS-fce8a892-15b3-4a51-9a3c-b56b3d3a1996,DISK], DatanodeInfoWithStorage[127.0.0.1:34643,DS-3769a0ad-bf46-4626-a9c1-e2a9f9adac54,DISK], DatanodeInfoWithStorage[127.0.0.1:35625,DS-58894de7-0952-4eb5-b0db-7f6e0f724764,DISK], DatanodeInfoWithStorage[127.0.0.1:46418,DS-ae2d7d18-52ec-4ebc-9cf7-ebcab987e40f,DISK], DatanodeInfoWithStorage[127.0.0.1:43638,DS-0bf510f8-78ed-467c-b062-f0f82fc21e5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.key.update-interval
component: hdfs:NameNode
v1: 10
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1430759689-172.17.0.10-1597656930761:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41003,DS-ff197e48-b9cf-46cf-9d12-a2c695a46026,DISK], DatanodeInfoWithStorage[127.0.0.1:37433,DS-d64112a0-6393-4625-a204-968307045f75,DISK], DatanodeInfoWithStorage[127.0.0.1:32785,DS-813ff72b-0def-4797-9096-498f5d7c5ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:34032,DS-e90a5a4c-725a-4f54-b92e-18d1173e3595,DISK], DatanodeInfoWithStorage[127.0.0.1:41339,DS-2ce8d386-0bda-49fc-9cef-61b54f50cbc8,DISK], DatanodeInfoWithStorage[127.0.0.1:46168,DS-7ab37d00-e2ee-449c-9337-b0f4708e7467,DISK], DatanodeInfoWithStorage[127.0.0.1:41764,DS-21a68381-b654-42cf-a275-65e0d191c368,DISK], DatanodeInfoWithStorage[127.0.0.1:41313,DS-7027f6b8-ec43-497e-b3a2-59a11a88d3c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1430759689-172.17.0.10-1597656930761:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41003,DS-ff197e48-b9cf-46cf-9d12-a2c695a46026,DISK], DatanodeInfoWithStorage[127.0.0.1:37433,DS-d64112a0-6393-4625-a204-968307045f75,DISK], DatanodeInfoWithStorage[127.0.0.1:32785,DS-813ff72b-0def-4797-9096-498f5d7c5ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:34032,DS-e90a5a4c-725a-4f54-b92e-18d1173e3595,DISK], DatanodeInfoWithStorage[127.0.0.1:41339,DS-2ce8d386-0bda-49fc-9cef-61b54f50cbc8,DISK], DatanodeInfoWithStorage[127.0.0.1:46168,DS-7ab37d00-e2ee-449c-9337-b0f4708e7467,DISK], DatanodeInfoWithStorage[127.0.0.1:41764,DS-21a68381-b654-42cf-a275-65e0d191c368,DISK], DatanodeInfoWithStorage[127.0.0.1:41313,DS-7027f6b8-ec43-497e-b3a2-59a11a88d3c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.key.update-interval
component: hdfs:NameNode
v1: 10
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-978821870-172.17.0.10-1597657210806:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43429,DS-848dd9c9-eec4-4153-b66b-a086cd3c79f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35258,DS-958e3abf-66e6-4a7c-97e5-2b9e16b83917,DISK], DatanodeInfoWithStorage[127.0.0.1:38835,DS-88eb2818-da8c-45d8-903d-9731552760f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39213,DS-6863b7cf-a27d-4f34-a4e1-4e11e2bad4a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45061,DS-2e353c88-d95c-48bf-bc15-2c776fbf4cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:39260,DS-03322a57-8e72-4f5a-844c-603b6f40b2b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36601,DS-3509dd40-dccc-4f6f-8510-f43d5bbec185,DISK], DatanodeInfoWithStorage[127.0.0.1:38364,DS-79690758-5a69-4149-a052-799ac6feff57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-978821870-172.17.0.10-1597657210806:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43429,DS-848dd9c9-eec4-4153-b66b-a086cd3c79f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35258,DS-958e3abf-66e6-4a7c-97e5-2b9e16b83917,DISK], DatanodeInfoWithStorage[127.0.0.1:38835,DS-88eb2818-da8c-45d8-903d-9731552760f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39213,DS-6863b7cf-a27d-4f34-a4e1-4e11e2bad4a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45061,DS-2e353c88-d95c-48bf-bc15-2c776fbf4cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:39260,DS-03322a57-8e72-4f5a-844c-603b6f40b2b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36601,DS-3509dd40-dccc-4f6f-8510-f43d5bbec185,DISK], DatanodeInfoWithStorage[127.0.0.1:38364,DS-79690758-5a69-4149-a052-799ac6feff57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.key.update-interval
component: hdfs:NameNode
v1: 10
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1618213427-172.17.0.10-1597657399354:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43168,DS-ee2aa9c4-9984-499e-b3b4-c49d4b925420,DISK], DatanodeInfoWithStorage[127.0.0.1:45279,DS-5ec218fa-e741-41f1-9aa5-48556efc76f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37958,DS-b1e2b392-d085-446f-b485-ce33e4f4574c,DISK], DatanodeInfoWithStorage[127.0.0.1:41405,DS-deadc2ea-3860-4477-b3e0-054b8ca7788d,DISK], DatanodeInfoWithStorage[127.0.0.1:42166,DS-0a31a8d3-7f38-4a45-9c8f-373a82e4ce4b,DISK], DatanodeInfoWithStorage[127.0.0.1:34220,DS-b7089c39-9b80-436a-9778-cd525478af56,DISK], DatanodeInfoWithStorage[127.0.0.1:37392,DS-f5050046-4042-40af-bdf6-a0e3edfa8899,DISK], DatanodeInfoWithStorage[127.0.0.1:34618,DS-6c8f239f-0f2e-46e5-9e3f-709340aa6f7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1618213427-172.17.0.10-1597657399354:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43168,DS-ee2aa9c4-9984-499e-b3b4-c49d4b925420,DISK], DatanodeInfoWithStorage[127.0.0.1:45279,DS-5ec218fa-e741-41f1-9aa5-48556efc76f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37958,DS-b1e2b392-d085-446f-b485-ce33e4f4574c,DISK], DatanodeInfoWithStorage[127.0.0.1:41405,DS-deadc2ea-3860-4477-b3e0-054b8ca7788d,DISK], DatanodeInfoWithStorage[127.0.0.1:42166,DS-0a31a8d3-7f38-4a45-9c8f-373a82e4ce4b,DISK], DatanodeInfoWithStorage[127.0.0.1:34220,DS-b7089c39-9b80-436a-9778-cd525478af56,DISK], DatanodeInfoWithStorage[127.0.0.1:37392,DS-f5050046-4042-40af-bdf6-a0e3edfa8899,DISK], DatanodeInfoWithStorage[127.0.0.1:34618,DS-6c8f239f-0f2e-46e5-9e3f-709340aa6f7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 16 out of 50
result: false positive !!!
Total execution time in seconds : 5702
