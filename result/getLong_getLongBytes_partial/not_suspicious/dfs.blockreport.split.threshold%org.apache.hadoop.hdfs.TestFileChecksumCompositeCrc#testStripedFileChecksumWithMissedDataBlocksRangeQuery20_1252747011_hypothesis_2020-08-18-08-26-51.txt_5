reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-532176350-172.17.0.20-1597739453348:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41323,DS-03202fae-9955-4887-9b77-c0be8a89c1ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40517,DS-c0ea1b88-0a31-4763-b77a-6fb7eb04584f,DISK], DatanodeInfoWithStorage[127.0.0.1:38923,DS-e3de70b6-8e9f-4ffb-8449-d4d3a38786a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33320,DS-2039a363-6d4d-4330-bc31-dc89d82edd9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45080,DS-7a870395-d557-436a-b437-ec8db48359bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40804,DS-e9ca1a55-8fc9-4f0e-af59-a722848f9266,DISK], DatanodeInfoWithStorage[127.0.0.1:42837,DS-6c526a2d-7526-4b46-a418-69c1922e0c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43805,DS-dc307693-976a-4407-8a19-a251c664eb17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-532176350-172.17.0.20-1597739453348:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41323,DS-03202fae-9955-4887-9b77-c0be8a89c1ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40517,DS-c0ea1b88-0a31-4763-b77a-6fb7eb04584f,DISK], DatanodeInfoWithStorage[127.0.0.1:38923,DS-e3de70b6-8e9f-4ffb-8449-d4d3a38786a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33320,DS-2039a363-6d4d-4330-bc31-dc89d82edd9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45080,DS-7a870395-d557-436a-b437-ec8db48359bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40804,DS-e9ca1a55-8fc9-4f0e-af59-a722848f9266,DISK], DatanodeInfoWithStorage[127.0.0.1:42837,DS-6c526a2d-7526-4b46-a418-69c1922e0c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43805,DS-dc307693-976a-4407-8a19-a251c664eb17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1810140371-172.17.0.20-1597739631603:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40925,DS-69ccfb10-6ab0-46f1-aad7-0b3ad63892df,DISK], DatanodeInfoWithStorage[127.0.0.1:36781,DS-5d5859cc-2386-4efd-a076-40b735cbf4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-ddec5f79-0735-4c8e-8903-9a4e7d070dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:36953,DS-69c5cbd0-8a01-41a9-95c9-b600422d6670,DISK], DatanodeInfoWithStorage[127.0.0.1:46739,DS-d52e0991-fbfe-46bb-877d-9c9f1f5ee7f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35145,DS-00e92435-98fd-482f-9943-1a1afa44ac38,DISK], DatanodeInfoWithStorage[127.0.0.1:41134,DS-b143f701-0764-4794-a2fa-74e59d4ccd0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40220,DS-fb99ac56-8d8e-4dcd-9eab-1d2e735472c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1810140371-172.17.0.20-1597739631603:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40925,DS-69ccfb10-6ab0-46f1-aad7-0b3ad63892df,DISK], DatanodeInfoWithStorage[127.0.0.1:36781,DS-5d5859cc-2386-4efd-a076-40b735cbf4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-ddec5f79-0735-4c8e-8903-9a4e7d070dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:36953,DS-69c5cbd0-8a01-41a9-95c9-b600422d6670,DISK], DatanodeInfoWithStorage[127.0.0.1:46739,DS-d52e0991-fbfe-46bb-877d-9c9f1f5ee7f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35145,DS-00e92435-98fd-482f-9943-1a1afa44ac38,DISK], DatanodeInfoWithStorage[127.0.0.1:41134,DS-b143f701-0764-4794-a2fa-74e59d4ccd0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40220,DS-fb99ac56-8d8e-4dcd-9eab-1d2e735472c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2129672922-172.17.0.20-1597739728332:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34634,DS-9c80a8eb-1529-4c90-8263-d1a413378cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:34066,DS-8cc8c10f-d9c7-45e7-bb0a-cf8df499a338,DISK], DatanodeInfoWithStorage[127.0.0.1:34941,DS-ed446a03-cfe3-49fa-8746-7361c0249a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40668,DS-8042c170-82bc-4259-b1eb-beeda557a59e,DISK], DatanodeInfoWithStorage[127.0.0.1:44683,DS-8174f690-5000-4fc1-a1a3-0a2ad3b6cbfb,DISK], DatanodeInfoWithStorage[127.0.0.1:33194,DS-ca38f431-e5b0-4fd1-b664-de4fa525721e,DISK], DatanodeInfoWithStorage[127.0.0.1:37593,DS-79773ee9-e385-487e-9e63-ee291d3450fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40532,DS-a9d4a33b-01a9-4853-96dc-95deae118658,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2129672922-172.17.0.20-1597739728332:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34634,DS-9c80a8eb-1529-4c90-8263-d1a413378cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:34066,DS-8cc8c10f-d9c7-45e7-bb0a-cf8df499a338,DISK], DatanodeInfoWithStorage[127.0.0.1:34941,DS-ed446a03-cfe3-49fa-8746-7361c0249a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40668,DS-8042c170-82bc-4259-b1eb-beeda557a59e,DISK], DatanodeInfoWithStorage[127.0.0.1:44683,DS-8174f690-5000-4fc1-a1a3-0a2ad3b6cbfb,DISK], DatanodeInfoWithStorage[127.0.0.1:33194,DS-ca38f431-e5b0-4fd1-b664-de4fa525721e,DISK], DatanodeInfoWithStorage[127.0.0.1:37593,DS-79773ee9-e385-487e-9e63-ee291d3450fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40532,DS-a9d4a33b-01a9-4853-96dc-95deae118658,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-366335707-172.17.0.20-1597740087080:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37952,DS-2b1df256-bcbc-4614-9da6-bc9f6b17715b,DISK], DatanodeInfoWithStorage[127.0.0.1:46305,DS-e4aff2b2-064a-4996-ab7d-fa065ae278ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37698,DS-24366da4-b35f-4b58-9e8e-dd80aa921ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:33966,DS-25d68c1a-bf1e-404b-aabd-adcbbc340535,DISK], DatanodeInfoWithStorage[127.0.0.1:35292,DS-00d493f5-6e21-4752-8e05-935b793ada43,DISK], DatanodeInfoWithStorage[127.0.0.1:41200,DS-c462f112-3563-4014-bf0a-ae01b6ff13a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37567,DS-c3ff8e84-3330-42e6-8afb-69bec9632d36,DISK], DatanodeInfoWithStorage[127.0.0.1:35260,DS-352da7f1-efdc-4999-b1df-7f7e37118bc9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-366335707-172.17.0.20-1597740087080:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37952,DS-2b1df256-bcbc-4614-9da6-bc9f6b17715b,DISK], DatanodeInfoWithStorage[127.0.0.1:46305,DS-e4aff2b2-064a-4996-ab7d-fa065ae278ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37698,DS-24366da4-b35f-4b58-9e8e-dd80aa921ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:33966,DS-25d68c1a-bf1e-404b-aabd-adcbbc340535,DISK], DatanodeInfoWithStorage[127.0.0.1:35292,DS-00d493f5-6e21-4752-8e05-935b793ada43,DISK], DatanodeInfoWithStorage[127.0.0.1:41200,DS-c462f112-3563-4014-bf0a-ae01b6ff13a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37567,DS-c3ff8e84-3330-42e6-8afb-69bec9632d36,DISK], DatanodeInfoWithStorage[127.0.0.1:35260,DS-352da7f1-efdc-4999-b1df-7f7e37118bc9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2079091666-172.17.0.20-1597740937577:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35442,DS-e1867c0e-0467-49d0-a022-80c5e1463587,DISK], DatanodeInfoWithStorage[127.0.0.1:37305,DS-684feedd-8022-4f44-a2f1-89f44cacc5fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43575,DS-ba49a2a2-257e-4b82-85a7-803acface99e,DISK], DatanodeInfoWithStorage[127.0.0.1:33767,DS-1632500d-9e6a-4650-adca-f12e153b0299,DISK], DatanodeInfoWithStorage[127.0.0.1:39273,DS-300f9ed9-2f8b-4279-92f4-64385a5fa57e,DISK], DatanodeInfoWithStorage[127.0.0.1:34561,DS-c687f755-1905-42d6-ac46-6adbf31c63e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-d4eebc93-b545-46c4-bc1b-05517ee4eeea,DISK], DatanodeInfoWithStorage[127.0.0.1:44165,DS-df07fc6a-f46d-4d73-8883-dd953817e0fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2079091666-172.17.0.20-1597740937577:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35442,DS-e1867c0e-0467-49d0-a022-80c5e1463587,DISK], DatanodeInfoWithStorage[127.0.0.1:37305,DS-684feedd-8022-4f44-a2f1-89f44cacc5fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43575,DS-ba49a2a2-257e-4b82-85a7-803acface99e,DISK], DatanodeInfoWithStorage[127.0.0.1:33767,DS-1632500d-9e6a-4650-adca-f12e153b0299,DISK], DatanodeInfoWithStorage[127.0.0.1:39273,DS-300f9ed9-2f8b-4279-92f4-64385a5fa57e,DISK], DatanodeInfoWithStorage[127.0.0.1:34561,DS-c687f755-1905-42d6-ac46-6adbf31c63e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-d4eebc93-b545-46c4-bc1b-05517ee4eeea,DISK], DatanodeInfoWithStorage[127.0.0.1:44165,DS-df07fc6a-f46d-4d73-8883-dd953817e0fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-213857591-172.17.0.20-1597741104401:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35419,DS-f37ef19b-e76e-4407-9ceb-ad2b4d38c82c,DISK], DatanodeInfoWithStorage[127.0.0.1:41626,DS-30eb0398-5196-4259-8095-f35f0e68cc64,DISK], DatanodeInfoWithStorage[127.0.0.1:32906,DS-93a28735-1818-4f47-999f-0a95cf1f40eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40904,DS-64a1470f-4d67-4370-bae1-ef9e94a1514d,DISK], DatanodeInfoWithStorage[127.0.0.1:41263,DS-f39dcc77-4d9d-472b-a820-faccb46cae8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33602,DS-1c43da97-f733-4370-a5e4-5d4382b6804e,DISK], DatanodeInfoWithStorage[127.0.0.1:39550,DS-3e8b207a-5ace-4562-b1b9-7182c23bf060,DISK], DatanodeInfoWithStorage[127.0.0.1:34164,DS-c10b5474-3245-4eed-a0d9-1c4ef7af0caf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-213857591-172.17.0.20-1597741104401:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35419,DS-f37ef19b-e76e-4407-9ceb-ad2b4d38c82c,DISK], DatanodeInfoWithStorage[127.0.0.1:41626,DS-30eb0398-5196-4259-8095-f35f0e68cc64,DISK], DatanodeInfoWithStorage[127.0.0.1:32906,DS-93a28735-1818-4f47-999f-0a95cf1f40eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40904,DS-64a1470f-4d67-4370-bae1-ef9e94a1514d,DISK], DatanodeInfoWithStorage[127.0.0.1:41263,DS-f39dcc77-4d9d-472b-a820-faccb46cae8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33602,DS-1c43da97-f733-4370-a5e4-5d4382b6804e,DISK], DatanodeInfoWithStorage[127.0.0.1:39550,DS-3e8b207a-5ace-4562-b1b9-7182c23bf060,DISK], DatanodeInfoWithStorage[127.0.0.1:34164,DS-c10b5474-3245-4eed-a0d9-1c4ef7af0caf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2019815834-172.17.0.20-1597741459513:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32855,DS-11edecd9-f39e-4c6b-9316-387e19707c34,DISK], DatanodeInfoWithStorage[127.0.0.1:45888,DS-b6ccbc83-4507-4a19-a3ce-a999d70a5802,DISK], DatanodeInfoWithStorage[127.0.0.1:33044,DS-cdfaa84c-84ed-425c-a026-dcecbbffd954,DISK], DatanodeInfoWithStorage[127.0.0.1:45944,DS-3131d226-8603-47d4-985b-6cd00350ae74,DISK], DatanodeInfoWithStorage[127.0.0.1:40583,DS-1f67ffb9-14ac-4d71-aa28-3a4ace46eede,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-6de51ef9-2e2a-4ba5-aa44-531a62278340,DISK], DatanodeInfoWithStorage[127.0.0.1:36336,DS-b863fe4f-9fef-43d5-b182-7f53a001258c,DISK], DatanodeInfoWithStorage[127.0.0.1:46678,DS-733bd703-a95e-45ff-871c-b87ff1815406,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2019815834-172.17.0.20-1597741459513:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32855,DS-11edecd9-f39e-4c6b-9316-387e19707c34,DISK], DatanodeInfoWithStorage[127.0.0.1:45888,DS-b6ccbc83-4507-4a19-a3ce-a999d70a5802,DISK], DatanodeInfoWithStorage[127.0.0.1:33044,DS-cdfaa84c-84ed-425c-a026-dcecbbffd954,DISK], DatanodeInfoWithStorage[127.0.0.1:45944,DS-3131d226-8603-47d4-985b-6cd00350ae74,DISK], DatanodeInfoWithStorage[127.0.0.1:40583,DS-1f67ffb9-14ac-4d71-aa28-3a4ace46eede,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-6de51ef9-2e2a-4ba5-aa44-531a62278340,DISK], DatanodeInfoWithStorage[127.0.0.1:36336,DS-b863fe4f-9fef-43d5-b182-7f53a001258c,DISK], DatanodeInfoWithStorage[127.0.0.1:46678,DS-733bd703-a95e-45ff-871c-b87ff1815406,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-29382801-172.17.0.20-1597741521224:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35796,DS-31903567-013a-4e2d-921b-2d3d18ab81f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34370,DS-4653eead-cfac-4820-a399-66616120f05c,DISK], DatanodeInfoWithStorage[127.0.0.1:34544,DS-845bd3e3-2624-4c99-8d5d-df1dae8ff05b,DISK], DatanodeInfoWithStorage[127.0.0.1:39158,DS-8b7d7aad-485f-4b36-a864-30a80fb595db,DISK], DatanodeInfoWithStorage[127.0.0.1:38199,DS-2d3fc7b0-46ed-4061-b395-8309dc7b8eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:35241,DS-77762234-4104-4901-a065-152572ee0aae,DISK], DatanodeInfoWithStorage[127.0.0.1:43586,DS-935f2c82-23e5-48e1-81e2-107782d7389c,DISK], DatanodeInfoWithStorage[127.0.0.1:34675,DS-6f8265a6-ea36-41de-8564-606a0087eaff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-29382801-172.17.0.20-1597741521224:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35796,DS-31903567-013a-4e2d-921b-2d3d18ab81f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34370,DS-4653eead-cfac-4820-a399-66616120f05c,DISK], DatanodeInfoWithStorage[127.0.0.1:34544,DS-845bd3e3-2624-4c99-8d5d-df1dae8ff05b,DISK], DatanodeInfoWithStorage[127.0.0.1:39158,DS-8b7d7aad-485f-4b36-a864-30a80fb595db,DISK], DatanodeInfoWithStorage[127.0.0.1:38199,DS-2d3fc7b0-46ed-4061-b395-8309dc7b8eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:35241,DS-77762234-4104-4901-a065-152572ee0aae,DISK], DatanodeInfoWithStorage[127.0.0.1:43586,DS-935f2c82-23e5-48e1-81e2-107782d7389c,DISK], DatanodeInfoWithStorage[127.0.0.1:34675,DS-6f8265a6-ea36-41de-8564-606a0087eaff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1592207002-172.17.0.20-1597741673507:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39958,DS-6890d3d2-ba4a-429f-a198-f8526c28fff6,DISK], DatanodeInfoWithStorage[127.0.0.1:35002,DS-d48875fe-0729-4407-995e-22e147c40615,DISK], DatanodeInfoWithStorage[127.0.0.1:41776,DS-de000d53-322f-4b1d-b936-c277a85fc3a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34131,DS-4e7f3d25-440a-4668-8333-a4bc90cca8a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33068,DS-f42ea583-e7b4-4703-8147-98e2805f6b47,DISK], DatanodeInfoWithStorage[127.0.0.1:34851,DS-e0a2dee9-dd79-4045-9d36-0e907c49a729,DISK], DatanodeInfoWithStorage[127.0.0.1:46113,DS-c9e68020-e102-43c4-81e8-99db3d799d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40850,DS-ce3431a0-147c-4270-b865-5b1ae1746a86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1592207002-172.17.0.20-1597741673507:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39958,DS-6890d3d2-ba4a-429f-a198-f8526c28fff6,DISK], DatanodeInfoWithStorage[127.0.0.1:35002,DS-d48875fe-0729-4407-995e-22e147c40615,DISK], DatanodeInfoWithStorage[127.0.0.1:41776,DS-de000d53-322f-4b1d-b936-c277a85fc3a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34131,DS-4e7f3d25-440a-4668-8333-a4bc90cca8a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33068,DS-f42ea583-e7b4-4703-8147-98e2805f6b47,DISK], DatanodeInfoWithStorage[127.0.0.1:34851,DS-e0a2dee9-dd79-4045-9d36-0e907c49a729,DISK], DatanodeInfoWithStorage[127.0.0.1:46113,DS-c9e68020-e102-43c4-81e8-99db3d799d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40850,DS-ce3431a0-147c-4270-b865-5b1ae1746a86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-496840880-172.17.0.20-1597741787354:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46384,DS-ea499a07-a6d0-4379-8a03-af828753873d,DISK], DatanodeInfoWithStorage[127.0.0.1:35204,DS-ea38fadb-dbe6-415e-92ac-703ad48a0c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:35912,DS-a2be3b41-f543-4b84-be15-134837775604,DISK], DatanodeInfoWithStorage[127.0.0.1:45473,DS-0c2b8441-7862-4299-9d33-f0e284dc0173,DISK], DatanodeInfoWithStorage[127.0.0.1:42708,DS-6dcf2d0c-a02f-45a0-9407-1638ef1e3867,DISK], DatanodeInfoWithStorage[127.0.0.1:40433,DS-9c01b6cc-20d4-4b2a-a057-249cfe584fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:39352,DS-b62649b1-c751-4f22-917f-87a763a5b27e,DISK], DatanodeInfoWithStorage[127.0.0.1:36846,DS-e283327d-e3a5-4eed-b6ec-a231a8f2d1b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-496840880-172.17.0.20-1597741787354:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46384,DS-ea499a07-a6d0-4379-8a03-af828753873d,DISK], DatanodeInfoWithStorage[127.0.0.1:35204,DS-ea38fadb-dbe6-415e-92ac-703ad48a0c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:35912,DS-a2be3b41-f543-4b84-be15-134837775604,DISK], DatanodeInfoWithStorage[127.0.0.1:45473,DS-0c2b8441-7862-4299-9d33-f0e284dc0173,DISK], DatanodeInfoWithStorage[127.0.0.1:42708,DS-6dcf2d0c-a02f-45a0-9407-1638ef1e3867,DISK], DatanodeInfoWithStorage[127.0.0.1:40433,DS-9c01b6cc-20d4-4b2a-a057-249cfe584fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:39352,DS-b62649b1-c751-4f22-917f-87a763a5b27e,DISK], DatanodeInfoWithStorage[127.0.0.1:36846,DS-e283327d-e3a5-4eed-b6ec-a231a8f2d1b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1954269719-172.17.0.20-1597742204705:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44245,DS-b652f570-0c68-42e8-895c-db3c8bdfa610,DISK], DatanodeInfoWithStorage[127.0.0.1:36997,DS-cca2ea2b-137b-4c68-8695-f5ac9fa82c95,DISK], DatanodeInfoWithStorage[127.0.0.1:38845,DS-fc4378a2-adb7-4ca3-9492-5cd4dbb1b5b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35028,DS-911b4d17-7982-4fd3-93d8-1b252e95423c,DISK], DatanodeInfoWithStorage[127.0.0.1:39211,DS-85a6f92f-fb4e-46c0-b7fe-5cfd6d56e7b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43556,DS-8f03421c-2cec-4f3b-81aa-a1b756bf6918,DISK], DatanodeInfoWithStorage[127.0.0.1:36697,DS-b1efb273-afbf-4938-9119-374b7b9ebbc4,DISK], DatanodeInfoWithStorage[127.0.0.1:39654,DS-b9269cbb-5765-42a8-8b72-fd6e51ac83e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1954269719-172.17.0.20-1597742204705:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44245,DS-b652f570-0c68-42e8-895c-db3c8bdfa610,DISK], DatanodeInfoWithStorage[127.0.0.1:36997,DS-cca2ea2b-137b-4c68-8695-f5ac9fa82c95,DISK], DatanodeInfoWithStorage[127.0.0.1:38845,DS-fc4378a2-adb7-4ca3-9492-5cd4dbb1b5b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35028,DS-911b4d17-7982-4fd3-93d8-1b252e95423c,DISK], DatanodeInfoWithStorage[127.0.0.1:39211,DS-85a6f92f-fb4e-46c0-b7fe-5cfd6d56e7b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43556,DS-8f03421c-2cec-4f3b-81aa-a1b756bf6918,DISK], DatanodeInfoWithStorage[127.0.0.1:36697,DS-b1efb273-afbf-4938-9119-374b7b9ebbc4,DISK], DatanodeInfoWithStorage[127.0.0.1:39654,DS-b9269cbb-5765-42a8-8b72-fd6e51ac83e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-898447469-172.17.0.20-1597742272034:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41397,DS-fbbd3434-7882-48c7-833c-46d6b95508c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45130,DS-22cbfff6-41f6-40ba-8a92-90eed024eb0e,DISK], DatanodeInfoWithStorage[127.0.0.1:40349,DS-2045bfe5-7a58-4e40-801b-5412d9edfcf4,DISK], DatanodeInfoWithStorage[127.0.0.1:43720,DS-c396000c-ed07-4240-8bdd-27e868a3ccee,DISK], DatanodeInfoWithStorage[127.0.0.1:42612,DS-b5752537-e041-441a-8fec-ffdeb5883e62,DISK], DatanodeInfoWithStorage[127.0.0.1:42217,DS-11f7c5a2-b0f4-4cb6-a17a-3267084c5e38,DISK], DatanodeInfoWithStorage[127.0.0.1:39663,DS-98395812-8ab0-4d65-9ab8-eafce58a2748,DISK], DatanodeInfoWithStorage[127.0.0.1:33898,DS-5eadea3b-bd3e-4163-8a19-51af5c08aab5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-898447469-172.17.0.20-1597742272034:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41397,DS-fbbd3434-7882-48c7-833c-46d6b95508c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45130,DS-22cbfff6-41f6-40ba-8a92-90eed024eb0e,DISK], DatanodeInfoWithStorage[127.0.0.1:40349,DS-2045bfe5-7a58-4e40-801b-5412d9edfcf4,DISK], DatanodeInfoWithStorage[127.0.0.1:43720,DS-c396000c-ed07-4240-8bdd-27e868a3ccee,DISK], DatanodeInfoWithStorage[127.0.0.1:42612,DS-b5752537-e041-441a-8fec-ffdeb5883e62,DISK], DatanodeInfoWithStorage[127.0.0.1:42217,DS-11f7c5a2-b0f4-4cb6-a17a-3267084c5e38,DISK], DatanodeInfoWithStorage[127.0.0.1:39663,DS-98395812-8ab0-4d65-9ab8-eafce58a2748,DISK], DatanodeInfoWithStorage[127.0.0.1:33898,DS-5eadea3b-bd3e-4163-8a19-51af5c08aab5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2078820760-172.17.0.20-1597742349566:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41754,DS-c1386fdf-f2ea-464a-9546-14bf6a0fca4d,DISK], DatanodeInfoWithStorage[127.0.0.1:39438,DS-f0675ffc-149e-46a7-941b-629006e2a3d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36070,DS-762de363-e2ca-4dc3-b85a-61c341e0f32a,DISK], DatanodeInfoWithStorage[127.0.0.1:33296,DS-952ec5ad-9a2a-4a07-8646-178fedd6c018,DISK], DatanodeInfoWithStorage[127.0.0.1:45305,DS-3d5b6f52-5cbe-44c5-8100-6275ddfa956d,DISK], DatanodeInfoWithStorage[127.0.0.1:42312,DS-8ccd388a-dedd-46a4-8bae-c42e0b59ae4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35626,DS-9d1d099a-f89d-4a89-9964-e5fb941db8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40631,DS-bdd89251-c286-4bae-a834-b83453aef786,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2078820760-172.17.0.20-1597742349566:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41754,DS-c1386fdf-f2ea-464a-9546-14bf6a0fca4d,DISK], DatanodeInfoWithStorage[127.0.0.1:39438,DS-f0675ffc-149e-46a7-941b-629006e2a3d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36070,DS-762de363-e2ca-4dc3-b85a-61c341e0f32a,DISK], DatanodeInfoWithStorage[127.0.0.1:33296,DS-952ec5ad-9a2a-4a07-8646-178fedd6c018,DISK], DatanodeInfoWithStorage[127.0.0.1:45305,DS-3d5b6f52-5cbe-44c5-8100-6275ddfa956d,DISK], DatanodeInfoWithStorage[127.0.0.1:42312,DS-8ccd388a-dedd-46a4-8bae-c42e0b59ae4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35626,DS-9d1d099a-f89d-4a89-9964-e5fb941db8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40631,DS-bdd89251-c286-4bae-a834-b83453aef786,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1594837976-172.17.0.20-1597742386225:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45994,DS-7df27639-3aa3-449f-a9c0-92b1f5c2bd86,DISK], DatanodeInfoWithStorage[127.0.0.1:41611,DS-d6e60feb-7489-496b-92b3-9627c7fcd773,DISK], DatanodeInfoWithStorage[127.0.0.1:39764,DS-cf89a3fb-8e13-476b-804a-6a1cbf792c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:45974,DS-2d9fbd7e-f123-4cc8-a215-3f49e4bedc5a,DISK], DatanodeInfoWithStorage[127.0.0.1:43813,DS-ccf9d967-37ca-40fa-8972-1d00ce6cde23,DISK], DatanodeInfoWithStorage[127.0.0.1:40044,DS-a9321e97-eabc-41bf-8848-f6a025292b70,DISK], DatanodeInfoWithStorage[127.0.0.1:45692,DS-6de08048-5e8d-4ed5-be30-8d2e723af9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40830,DS-22cee218-84c5-42d5-bb4d-939716c9187a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1594837976-172.17.0.20-1597742386225:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45994,DS-7df27639-3aa3-449f-a9c0-92b1f5c2bd86,DISK], DatanodeInfoWithStorage[127.0.0.1:41611,DS-d6e60feb-7489-496b-92b3-9627c7fcd773,DISK], DatanodeInfoWithStorage[127.0.0.1:39764,DS-cf89a3fb-8e13-476b-804a-6a1cbf792c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:45974,DS-2d9fbd7e-f123-4cc8-a215-3f49e4bedc5a,DISK], DatanodeInfoWithStorage[127.0.0.1:43813,DS-ccf9d967-37ca-40fa-8972-1d00ce6cde23,DISK], DatanodeInfoWithStorage[127.0.0.1:40044,DS-a9321e97-eabc-41bf-8848-f6a025292b70,DISK], DatanodeInfoWithStorage[127.0.0.1:45692,DS-6de08048-5e8d-4ed5-be30-8d2e723af9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40830,DS-22cee218-84c5-42d5-bb4d-939716c9187a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-171985836-172.17.0.20-1597742554487:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45833,DS-54990b07-8743-492c-9f92-f81aa3019073,DISK], DatanodeInfoWithStorage[127.0.0.1:40239,DS-63002928-5e66-458a-8efa-3ca4a8269787,DISK], DatanodeInfoWithStorage[127.0.0.1:35448,DS-29aaa4be-d24e-4898-8850-a8e3531aa9cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36217,DS-d41b75bf-6ca4-4934-ac62-b775bf0111c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45796,DS-0fa2d9d9-2abc-4768-8a6c-10c7133ab0a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34506,DS-4551c734-5637-4983-8f20-01d5e8a997fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38550,DS-bd3da756-bc2f-4b97-a871-e1012a1b0fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:34771,DS-9a7b384b-e2e2-4020-ba97-80c8a86bf521,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-171985836-172.17.0.20-1597742554487:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45833,DS-54990b07-8743-492c-9f92-f81aa3019073,DISK], DatanodeInfoWithStorage[127.0.0.1:40239,DS-63002928-5e66-458a-8efa-3ca4a8269787,DISK], DatanodeInfoWithStorage[127.0.0.1:35448,DS-29aaa4be-d24e-4898-8850-a8e3531aa9cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36217,DS-d41b75bf-6ca4-4934-ac62-b775bf0111c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45796,DS-0fa2d9d9-2abc-4768-8a6c-10c7133ab0a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34506,DS-4551c734-5637-4983-8f20-01d5e8a997fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38550,DS-bd3da756-bc2f-4b97-a871-e1012a1b0fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:34771,DS-9a7b384b-e2e2-4020-ba97-80c8a86bf521,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1205329190-172.17.0.20-1597743095956:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38981,DS-ac878b97-ce07-4dae-afea-f4a241eed2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37419,DS-bffd9128-1bc1-48ac-b3b3-6a01324e91ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34540,DS-8c14ec00-c8ca-4ca6-a7b0-69474c04a5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46469,DS-f3e2440a-6b30-4a6d-871b-ccab9f991153,DISK], DatanodeInfoWithStorage[127.0.0.1:43718,DS-d5096130-b56a-4af9-abf3-448869e6d621,DISK], DatanodeInfoWithStorage[127.0.0.1:43095,DS-4e388685-7cba-4cf5-a281-a156c14e795d,DISK], DatanodeInfoWithStorage[127.0.0.1:46583,DS-0ebc69f7-693f-4c84-81c1-b98ece7300d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42482,DS-8088f512-1302-4e66-ad06-5ce1e7ac97f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1205329190-172.17.0.20-1597743095956:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38981,DS-ac878b97-ce07-4dae-afea-f4a241eed2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37419,DS-bffd9128-1bc1-48ac-b3b3-6a01324e91ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34540,DS-8c14ec00-c8ca-4ca6-a7b0-69474c04a5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46469,DS-f3e2440a-6b30-4a6d-871b-ccab9f991153,DISK], DatanodeInfoWithStorage[127.0.0.1:43718,DS-d5096130-b56a-4af9-abf3-448869e6d621,DISK], DatanodeInfoWithStorage[127.0.0.1:43095,DS-4e388685-7cba-4cf5-a281-a156c14e795d,DISK], DatanodeInfoWithStorage[127.0.0.1:46583,DS-0ebc69f7-693f-4c84-81c1-b98ece7300d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42482,DS-8088f512-1302-4e66-ad06-5ce1e7ac97f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-113307912-172.17.0.20-1597744036185:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42969,DS-717fa210-17ed-4130-92b3-6e75db22f4c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44153,DS-a44145f3-53fd-4c63-9dc3-6ee639229727,DISK], DatanodeInfoWithStorage[127.0.0.1:44248,DS-19254463-9d63-47ea-87c9-14ee8071e5d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33790,DS-a401b7e6-f7fb-443a-a69c-dba94aec2d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45543,DS-58703881-812a-438a-bc26-20dd619db806,DISK], DatanodeInfoWithStorage[127.0.0.1:38636,DS-5c6f61de-9b6e-4b35-8794-1d692e2a3072,DISK], DatanodeInfoWithStorage[127.0.0.1:44255,DS-5c736027-0e15-4c9b-bba4-1f509985f2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39036,DS-78a63e3d-130b-4ac8-8399-33c508208a24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-113307912-172.17.0.20-1597744036185:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42969,DS-717fa210-17ed-4130-92b3-6e75db22f4c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44153,DS-a44145f3-53fd-4c63-9dc3-6ee639229727,DISK], DatanodeInfoWithStorage[127.0.0.1:44248,DS-19254463-9d63-47ea-87c9-14ee8071e5d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33790,DS-a401b7e6-f7fb-443a-a69c-dba94aec2d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45543,DS-58703881-812a-438a-bc26-20dd619db806,DISK], DatanodeInfoWithStorage[127.0.0.1:38636,DS-5c6f61de-9b6e-4b35-8794-1d692e2a3072,DISK], DatanodeInfoWithStorage[127.0.0.1:44255,DS-5c736027-0e15-4c9b-bba4-1f509985f2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39036,DS-78a63e3d-130b-4ac8-8399-33c508208a24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1461048678-172.17.0.20-1597744474041:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45943,DS-8e7676b4-bd7c-4ea5-9122-e78c4907bf19,DISK], DatanodeInfoWithStorage[127.0.0.1:33477,DS-7f1ec213-7673-4136-926b-3ff518b6f4e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34261,DS-78489f0e-9855-49a4-beda-5d262e4f72ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36710,DS-42c53550-4563-4f2d-9aa0-dccdce32d088,DISK], DatanodeInfoWithStorage[127.0.0.1:42868,DS-3980a2f5-22ec-4d28-b170-013c8a7e6f82,DISK], DatanodeInfoWithStorage[127.0.0.1:41029,DS-662c2b69-2cad-44f7-9052-b27749da62c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40820,DS-ad272863-3266-4b8d-bf0c-c4a47b966691,DISK], DatanodeInfoWithStorage[127.0.0.1:41960,DS-e7d7ff9c-2c2b-43a9-bd27-4de410f843e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1461048678-172.17.0.20-1597744474041:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45943,DS-8e7676b4-bd7c-4ea5-9122-e78c4907bf19,DISK], DatanodeInfoWithStorage[127.0.0.1:33477,DS-7f1ec213-7673-4136-926b-3ff518b6f4e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34261,DS-78489f0e-9855-49a4-beda-5d262e4f72ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36710,DS-42c53550-4563-4f2d-9aa0-dccdce32d088,DISK], DatanodeInfoWithStorage[127.0.0.1:42868,DS-3980a2f5-22ec-4d28-b170-013c8a7e6f82,DISK], DatanodeInfoWithStorage[127.0.0.1:41029,DS-662c2b69-2cad-44f7-9052-b27749da62c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40820,DS-ad272863-3266-4b8d-bf0c-c4a47b966691,DISK], DatanodeInfoWithStorage[127.0.0.1:41960,DS-e7d7ff9c-2c2b-43a9-bd27-4de410f843e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5390
