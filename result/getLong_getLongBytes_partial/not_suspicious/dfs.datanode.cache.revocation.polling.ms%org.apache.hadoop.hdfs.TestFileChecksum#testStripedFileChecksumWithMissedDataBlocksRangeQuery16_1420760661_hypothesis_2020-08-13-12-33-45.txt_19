reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-247005433-172.17.0.21-1597322323968:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36088,DS-35b26466-0d4f-43a4-a7e2-c2f17a79c265,DISK], DatanodeInfoWithStorage[127.0.0.1:33333,DS-cc66f6ad-d7a3-46e2-8827-cf8760b5aa24,DISK], DatanodeInfoWithStorage[127.0.0.1:42048,DS-2bdeb5d0-cdef-4092-bbd4-106cd63c3d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:34478,DS-7281f7df-95bf-4347-a067-bb25b96a384a,DISK], DatanodeInfoWithStorage[127.0.0.1:43839,DS-89e271da-7511-4922-8aaf-9e056421754b,DISK], DatanodeInfoWithStorage[127.0.0.1:41023,DS-a3b3618c-c8d1-4be6-8c05-83609d998519,DISK], DatanodeInfoWithStorage[127.0.0.1:36876,DS-1ddb5477-11cf-45e5-9606-00e84b798001,DISK], DatanodeInfoWithStorage[127.0.0.1:38646,DS-e5b995f0-e0a4-476b-9a50-3907abf9597d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-247005433-172.17.0.21-1597322323968:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36088,DS-35b26466-0d4f-43a4-a7e2-c2f17a79c265,DISK], DatanodeInfoWithStorage[127.0.0.1:33333,DS-cc66f6ad-d7a3-46e2-8827-cf8760b5aa24,DISK], DatanodeInfoWithStorage[127.0.0.1:42048,DS-2bdeb5d0-cdef-4092-bbd4-106cd63c3d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:34478,DS-7281f7df-95bf-4347-a067-bb25b96a384a,DISK], DatanodeInfoWithStorage[127.0.0.1:43839,DS-89e271da-7511-4922-8aaf-9e056421754b,DISK], DatanodeInfoWithStorage[127.0.0.1:41023,DS-a3b3618c-c8d1-4be6-8c05-83609d998519,DISK], DatanodeInfoWithStorage[127.0.0.1:36876,DS-1ddb5477-11cf-45e5-9606-00e84b798001,DISK], DatanodeInfoWithStorage[127.0.0.1:38646,DS-e5b995f0-e0a4-476b-9a50-3907abf9597d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2096814963-172.17.0.21-1597322907193:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41004,DS-fb151f49-a00b-4b26-a398-031d567120e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42696,DS-67e7f80a-90ab-4c0b-9e54-6460d2947746,DISK], DatanodeInfoWithStorage[127.0.0.1:44250,DS-c8b9fa24-442f-4a79-a95b-08f165b9cb58,DISK], DatanodeInfoWithStorage[127.0.0.1:39795,DS-243e1346-e5ac-4731-9d72-50af67c5af40,DISK], DatanodeInfoWithStorage[127.0.0.1:35407,DS-60ce646d-21e7-412e-bba9-807763a67432,DISK], DatanodeInfoWithStorage[127.0.0.1:33658,DS-9cc47f98-f1c9-47b3-b3cd-4585955860ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34643,DS-9c6d94b2-1af7-4341-b747-4c3fa29b899b,DISK], DatanodeInfoWithStorage[127.0.0.1:35540,DS-bb0ef937-2ae6-489b-bf72-7f750e0ef382,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2096814963-172.17.0.21-1597322907193:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41004,DS-fb151f49-a00b-4b26-a398-031d567120e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42696,DS-67e7f80a-90ab-4c0b-9e54-6460d2947746,DISK], DatanodeInfoWithStorage[127.0.0.1:44250,DS-c8b9fa24-442f-4a79-a95b-08f165b9cb58,DISK], DatanodeInfoWithStorage[127.0.0.1:39795,DS-243e1346-e5ac-4731-9d72-50af67c5af40,DISK], DatanodeInfoWithStorage[127.0.0.1:35407,DS-60ce646d-21e7-412e-bba9-807763a67432,DISK], DatanodeInfoWithStorage[127.0.0.1:33658,DS-9cc47f98-f1c9-47b3-b3cd-4585955860ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34643,DS-9c6d94b2-1af7-4341-b747-4c3fa29b899b,DISK], DatanodeInfoWithStorage[127.0.0.1:35540,DS-bb0ef937-2ae6-489b-bf72-7f750e0ef382,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1776524033-172.17.0.21-1597323207354:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46458,DS-e78ea01a-bddd-4c52-b7f2-79d343aacd38,DISK], DatanodeInfoWithStorage[127.0.0.1:33819,DS-a0b3d4b7-a8fb-4d2e-889e-a123fc681ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:35581,DS-1f0736f8-ef9a-4634-8314-bb23bfaae687,DISK], DatanodeInfoWithStorage[127.0.0.1:39097,DS-8196909f-25c4-4130-9168-f715e9fb74c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44830,DS-0f8a7caf-5eb3-4384-9765-8e8b9eceb616,DISK], DatanodeInfoWithStorage[127.0.0.1:44047,DS-ae07b5c9-426f-4064-b206-6bd4c1d12dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:41461,DS-f03c61be-18fd-409e-9335-fd6569eff6dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33165,DS-009e47ad-6cd0-4f1e-9bf4-37596c13e356,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1776524033-172.17.0.21-1597323207354:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46458,DS-e78ea01a-bddd-4c52-b7f2-79d343aacd38,DISK], DatanodeInfoWithStorage[127.0.0.1:33819,DS-a0b3d4b7-a8fb-4d2e-889e-a123fc681ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:35581,DS-1f0736f8-ef9a-4634-8314-bb23bfaae687,DISK], DatanodeInfoWithStorage[127.0.0.1:39097,DS-8196909f-25c4-4130-9168-f715e9fb74c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44830,DS-0f8a7caf-5eb3-4384-9765-8e8b9eceb616,DISK], DatanodeInfoWithStorage[127.0.0.1:44047,DS-ae07b5c9-426f-4064-b206-6bd4c1d12dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:41461,DS-f03c61be-18fd-409e-9335-fd6569eff6dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33165,DS-009e47ad-6cd0-4f1e-9bf4-37596c13e356,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-534676973-172.17.0.21-1597323743149:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39928,DS-80315768-c0fe-4cb5-a5b7-8ba199c0387a,DISK], DatanodeInfoWithStorage[127.0.0.1:39138,DS-983e03d2-c7fb-4e30-9351-5962ca567434,DISK], DatanodeInfoWithStorage[127.0.0.1:34263,DS-78c2962c-ecf0-45be-81a0-e5b2136bcc78,DISK], DatanodeInfoWithStorage[127.0.0.1:37583,DS-e4dae460-b688-4160-99fe-494334cd9f66,DISK], DatanodeInfoWithStorage[127.0.0.1:43999,DS-a6bece82-fcf6-4208-a95b-14f201046ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:42072,DS-ed5613d7-a6cd-4905-aae7-432ff6733c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44443,DS-c3e013e8-6652-4102-bc1c-adc222652472,DISK], DatanodeInfoWithStorage[127.0.0.1:40830,DS-ceaceb6e-f7b3-4144-9533-4bdde91c7312,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-534676973-172.17.0.21-1597323743149:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39928,DS-80315768-c0fe-4cb5-a5b7-8ba199c0387a,DISK], DatanodeInfoWithStorage[127.0.0.1:39138,DS-983e03d2-c7fb-4e30-9351-5962ca567434,DISK], DatanodeInfoWithStorage[127.0.0.1:34263,DS-78c2962c-ecf0-45be-81a0-e5b2136bcc78,DISK], DatanodeInfoWithStorage[127.0.0.1:37583,DS-e4dae460-b688-4160-99fe-494334cd9f66,DISK], DatanodeInfoWithStorage[127.0.0.1:43999,DS-a6bece82-fcf6-4208-a95b-14f201046ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:42072,DS-ed5613d7-a6cd-4905-aae7-432ff6733c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44443,DS-c3e013e8-6652-4102-bc1c-adc222652472,DISK], DatanodeInfoWithStorage[127.0.0.1:40830,DS-ceaceb6e-f7b3-4144-9533-4bdde91c7312,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1364057647-172.17.0.21-1597324291162:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44097,DS-2c6a9c5b-f248-4ce1-9268-4eb8550e4a11,DISK], DatanodeInfoWithStorage[127.0.0.1:34339,DS-a00c1f47-6cd4-40a3-a3f9-82427f705dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:45149,DS-501c7de2-cfe0-481c-9d85-c17c3e4517f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40726,DS-cb09bcab-6945-4c83-a906-c6a09ac5c37b,DISK], DatanodeInfoWithStorage[127.0.0.1:38384,DS-6533930e-a42c-4354-9f58-d62a5234a8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38004,DS-227e09f8-4405-43b9-814c-2e2a5f6a87ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40113,DS-848a2bf2-426f-4235-85df-c4436cde7317,DISK], DatanodeInfoWithStorage[127.0.0.1:43792,DS-e92e87b6-17fd-41a1-93ea-8822d8a4e72a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1364057647-172.17.0.21-1597324291162:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44097,DS-2c6a9c5b-f248-4ce1-9268-4eb8550e4a11,DISK], DatanodeInfoWithStorage[127.0.0.1:34339,DS-a00c1f47-6cd4-40a3-a3f9-82427f705dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:45149,DS-501c7de2-cfe0-481c-9d85-c17c3e4517f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40726,DS-cb09bcab-6945-4c83-a906-c6a09ac5c37b,DISK], DatanodeInfoWithStorage[127.0.0.1:38384,DS-6533930e-a42c-4354-9f58-d62a5234a8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38004,DS-227e09f8-4405-43b9-814c-2e2a5f6a87ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40113,DS-848a2bf2-426f-4235-85df-c4436cde7317,DISK], DatanodeInfoWithStorage[127.0.0.1:43792,DS-e92e87b6-17fd-41a1-93ea-8822d8a4e72a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-672198890-172.17.0.21-1597324749278:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37805,DS-5fcaab08-d698-457d-950f-db2c31a014b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46363,DS-6ee40e71-1d73-4569-a68f-32f0a161bea5,DISK], DatanodeInfoWithStorage[127.0.0.1:41934,DS-e53740b7-d88f-4c69-8a9a-08e2d1496e94,DISK], DatanodeInfoWithStorage[127.0.0.1:33799,DS-35a70929-f2c5-4bc4-aa05-60ea624d850f,DISK], DatanodeInfoWithStorage[127.0.0.1:43257,DS-04aeda16-ed95-4dbd-8049-1b284badac37,DISK], DatanodeInfoWithStorage[127.0.0.1:37198,DS-0e2afbfb-35c9-428d-860a-47017c7bdf84,DISK], DatanodeInfoWithStorage[127.0.0.1:41321,DS-f8a27f0a-a2eb-4dc1-877c-e20be2de8fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:35595,DS-395b6187-ce9f-4248-80e5-bdc41ce490fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-672198890-172.17.0.21-1597324749278:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37805,DS-5fcaab08-d698-457d-950f-db2c31a014b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46363,DS-6ee40e71-1d73-4569-a68f-32f0a161bea5,DISK], DatanodeInfoWithStorage[127.0.0.1:41934,DS-e53740b7-d88f-4c69-8a9a-08e2d1496e94,DISK], DatanodeInfoWithStorage[127.0.0.1:33799,DS-35a70929-f2c5-4bc4-aa05-60ea624d850f,DISK], DatanodeInfoWithStorage[127.0.0.1:43257,DS-04aeda16-ed95-4dbd-8049-1b284badac37,DISK], DatanodeInfoWithStorage[127.0.0.1:37198,DS-0e2afbfb-35c9-428d-860a-47017c7bdf84,DISK], DatanodeInfoWithStorage[127.0.0.1:41321,DS-f8a27f0a-a2eb-4dc1-877c-e20be2de8fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:35595,DS-395b6187-ce9f-4248-80e5-bdc41ce490fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1452627702-172.17.0.21-1597325018159:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42992,DS-f2289ee7-c04b-4f07-879c-b9f8aa4c2236,DISK], DatanodeInfoWithStorage[127.0.0.1:44185,DS-e53742da-bba0-4a9f-aae8-3006ab2e7b56,DISK], DatanodeInfoWithStorage[127.0.0.1:35969,DS-f282a3d0-5ad8-4562-95e0-0ad61b831c22,DISK], DatanodeInfoWithStorage[127.0.0.1:37517,DS-73ee090d-6355-4276-a7f3-299079aa91af,DISK], DatanodeInfoWithStorage[127.0.0.1:38354,DS-221af358-e139-4b09-b611-a95ff5c6e1be,DISK], DatanodeInfoWithStorage[127.0.0.1:35568,DS-379f235a-3791-4751-8781-ffb197aa4529,DISK], DatanodeInfoWithStorage[127.0.0.1:33942,DS-87a3f9d0-bfc5-4789-b600-c4c6a50b0c63,DISK], DatanodeInfoWithStorage[127.0.0.1:36381,DS-a819359c-b919-430a-92a6-c682f0921cac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1452627702-172.17.0.21-1597325018159:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42992,DS-f2289ee7-c04b-4f07-879c-b9f8aa4c2236,DISK], DatanodeInfoWithStorage[127.0.0.1:44185,DS-e53742da-bba0-4a9f-aae8-3006ab2e7b56,DISK], DatanodeInfoWithStorage[127.0.0.1:35969,DS-f282a3d0-5ad8-4562-95e0-0ad61b831c22,DISK], DatanodeInfoWithStorage[127.0.0.1:37517,DS-73ee090d-6355-4276-a7f3-299079aa91af,DISK], DatanodeInfoWithStorage[127.0.0.1:38354,DS-221af358-e139-4b09-b611-a95ff5c6e1be,DISK], DatanodeInfoWithStorage[127.0.0.1:35568,DS-379f235a-3791-4751-8781-ffb197aa4529,DISK], DatanodeInfoWithStorage[127.0.0.1:33942,DS-87a3f9d0-bfc5-4789-b600-c4c6a50b0c63,DISK], DatanodeInfoWithStorage[127.0.0.1:36381,DS-a819359c-b919-430a-92a6-c682f0921cac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1848102737-172.17.0.21-1597325827680:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44143,DS-8e63acbe-2cd9-4977-8f9f-edeed101c557,DISK], DatanodeInfoWithStorage[127.0.0.1:45970,DS-c5b6a9a7-ae9c-4413-b217-8041672fed56,DISK], DatanodeInfoWithStorage[127.0.0.1:35324,DS-c563d728-5166-4b40-95f1-5231e3c3e10a,DISK], DatanodeInfoWithStorage[127.0.0.1:39190,DS-0579de6f-234b-4e4e-887f-865cb673ac42,DISK], DatanodeInfoWithStorage[127.0.0.1:46757,DS-273ff202-d81a-4022-b60e-d88c809ad236,DISK], DatanodeInfoWithStorage[127.0.0.1:39140,DS-d92da0ce-643d-4858-b1f3-2f320d269b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:43896,DS-4bcd79b2-77c3-411a-9702-487464d081a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38942,DS-be46f341-dfab-4589-9575-7ce65921c3a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1848102737-172.17.0.21-1597325827680:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44143,DS-8e63acbe-2cd9-4977-8f9f-edeed101c557,DISK], DatanodeInfoWithStorage[127.0.0.1:45970,DS-c5b6a9a7-ae9c-4413-b217-8041672fed56,DISK], DatanodeInfoWithStorage[127.0.0.1:35324,DS-c563d728-5166-4b40-95f1-5231e3c3e10a,DISK], DatanodeInfoWithStorage[127.0.0.1:39190,DS-0579de6f-234b-4e4e-887f-865cb673ac42,DISK], DatanodeInfoWithStorage[127.0.0.1:46757,DS-273ff202-d81a-4022-b60e-d88c809ad236,DISK], DatanodeInfoWithStorage[127.0.0.1:39140,DS-d92da0ce-643d-4858-b1f3-2f320d269b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:43896,DS-4bcd79b2-77c3-411a-9702-487464d081a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38942,DS-be46f341-dfab-4589-9575-7ce65921c3a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-912984487-172.17.0.21-1597327173201:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39091,DS-efbd82b6-2f55-494b-b8ee-8c38671eed8c,DISK], DatanodeInfoWithStorage[127.0.0.1:38641,DS-349895f8-da0d-4b00-9fec-67570fb2f01f,DISK], DatanodeInfoWithStorage[127.0.0.1:39195,DS-29d0cb36-18e7-4a53-aaac-b3c65f71e132,DISK], DatanodeInfoWithStorage[127.0.0.1:44548,DS-bb6ad97b-fbce-41f3-b557-d660b6d58309,DISK], DatanodeInfoWithStorage[127.0.0.1:37758,DS-533c001a-2aa2-42f7-95db-6d79df90c14d,DISK], DatanodeInfoWithStorage[127.0.0.1:32980,DS-1d6130a6-27ab-4d49-ab80-aae542b5e5c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34368,DS-707f8ce2-647d-4232-b955-166e06aef725,DISK], DatanodeInfoWithStorage[127.0.0.1:43703,DS-2592a66e-bacc-4281-be40-bf3464e23f44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-912984487-172.17.0.21-1597327173201:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39091,DS-efbd82b6-2f55-494b-b8ee-8c38671eed8c,DISK], DatanodeInfoWithStorage[127.0.0.1:38641,DS-349895f8-da0d-4b00-9fec-67570fb2f01f,DISK], DatanodeInfoWithStorage[127.0.0.1:39195,DS-29d0cb36-18e7-4a53-aaac-b3c65f71e132,DISK], DatanodeInfoWithStorage[127.0.0.1:44548,DS-bb6ad97b-fbce-41f3-b557-d660b6d58309,DISK], DatanodeInfoWithStorage[127.0.0.1:37758,DS-533c001a-2aa2-42f7-95db-6d79df90c14d,DISK], DatanodeInfoWithStorage[127.0.0.1:32980,DS-1d6130a6-27ab-4d49-ab80-aae542b5e5c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34368,DS-707f8ce2-647d-4232-b955-166e06aef725,DISK], DatanodeInfoWithStorage[127.0.0.1:43703,DS-2592a66e-bacc-4281-be40-bf3464e23f44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1911914363-172.17.0.21-1597327795604:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43350,DS-df1af36c-9abf-4c30-89b9-da996a4ef4fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41047,DS-9d22ac40-da28-4541-929c-e4497ba2e580,DISK], DatanodeInfoWithStorage[127.0.0.1:36336,DS-024ba2ae-6f9d-4d6e-8089-98403e46f74f,DISK], DatanodeInfoWithStorage[127.0.0.1:34398,DS-79c16c32-c948-492c-a14d-bc059ee45e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:34991,DS-198aafcc-e8d4-4cd2-bbbb-c5816f511d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40448,DS-1d902da2-f3d9-4634-a03e-c302227441cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39349,DS-85bf4fac-918f-466a-83f9-9ca141bc270e,DISK], DatanodeInfoWithStorage[127.0.0.1:39319,DS-57154606-de27-4e8f-b9d0-d7c8d1dfe01c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1911914363-172.17.0.21-1597327795604:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43350,DS-df1af36c-9abf-4c30-89b9-da996a4ef4fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41047,DS-9d22ac40-da28-4541-929c-e4497ba2e580,DISK], DatanodeInfoWithStorage[127.0.0.1:36336,DS-024ba2ae-6f9d-4d6e-8089-98403e46f74f,DISK], DatanodeInfoWithStorage[127.0.0.1:34398,DS-79c16c32-c948-492c-a14d-bc059ee45e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:34991,DS-198aafcc-e8d4-4cd2-bbbb-c5816f511d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40448,DS-1d902da2-f3d9-4634-a03e-c302227441cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39349,DS-85bf4fac-918f-466a-83f9-9ca141bc270e,DISK], DatanodeInfoWithStorage[127.0.0.1:39319,DS-57154606-de27-4e8f-b9d0-d7c8d1dfe01c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-787864386-172.17.0.21-1597327999474:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35427,DS-74947e10-7ee9-4e9e-abf4-007607288fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:41836,DS-fa3dc184-a0a3-48da-9a39-fbf0dfef817e,DISK], DatanodeInfoWithStorage[127.0.0.1:33319,DS-30ec52e4-c31e-4850-b11e-daa261a6c059,DISK], DatanodeInfoWithStorage[127.0.0.1:37345,DS-ab2ceba1-47fb-4d9d-b6ce-3164851fd761,DISK], DatanodeInfoWithStorage[127.0.0.1:37951,DS-0adc870b-e499-4045-b0a2-5aa4bbf16cca,DISK], DatanodeInfoWithStorage[127.0.0.1:44687,DS-e1564d93-df77-44a1-be02-7f15acafc7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34227,DS-76985292-eb96-4bf8-a3db-edd6f416c1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41068,DS-ca24c0d6-2e29-421c-ae9a-d3d92a4a9443,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-787864386-172.17.0.21-1597327999474:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35427,DS-74947e10-7ee9-4e9e-abf4-007607288fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:41836,DS-fa3dc184-a0a3-48da-9a39-fbf0dfef817e,DISK], DatanodeInfoWithStorage[127.0.0.1:33319,DS-30ec52e4-c31e-4850-b11e-daa261a6c059,DISK], DatanodeInfoWithStorage[127.0.0.1:37345,DS-ab2ceba1-47fb-4d9d-b6ce-3164851fd761,DISK], DatanodeInfoWithStorage[127.0.0.1:37951,DS-0adc870b-e499-4045-b0a2-5aa4bbf16cca,DISK], DatanodeInfoWithStorage[127.0.0.1:44687,DS-e1564d93-df77-44a1-be02-7f15acafc7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34227,DS-76985292-eb96-4bf8-a3db-edd6f416c1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41068,DS-ca24c0d6-2e29-421c-ae9a-d3d92a4a9443,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1528332015-172.17.0.21-1597328457440:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35997,DS-6d644338-9bf1-42ab-a193-117894ebb9d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43138,DS-30c673ad-90f6-48dd-ae1d-3d70158aaa70,DISK], DatanodeInfoWithStorage[127.0.0.1:41264,DS-c7062736-ecb1-4100-841c-a42991ac70a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33600,DS-8023b000-8ff2-48e6-82c9-c423c089dbaa,DISK], DatanodeInfoWithStorage[127.0.0.1:42049,DS-e49647a0-039f-4c59-8095-5fa149f111b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46722,DS-a9b68608-7a40-4a71-b015-cdc6536fdb0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37850,DS-7351c60d-858c-483d-971c-c3b2d39b3cae,DISK], DatanodeInfoWithStorage[127.0.0.1:36914,DS-1f9f5cee-5ea3-4339-bea7-a91462373425,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1528332015-172.17.0.21-1597328457440:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35997,DS-6d644338-9bf1-42ab-a193-117894ebb9d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43138,DS-30c673ad-90f6-48dd-ae1d-3d70158aaa70,DISK], DatanodeInfoWithStorage[127.0.0.1:41264,DS-c7062736-ecb1-4100-841c-a42991ac70a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33600,DS-8023b000-8ff2-48e6-82c9-c423c089dbaa,DISK], DatanodeInfoWithStorage[127.0.0.1:42049,DS-e49647a0-039f-4c59-8095-5fa149f111b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46722,DS-a9b68608-7a40-4a71-b015-cdc6536fdb0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37850,DS-7351c60d-858c-483d-971c-c3b2d39b3cae,DISK], DatanodeInfoWithStorage[127.0.0.1:36914,DS-1f9f5cee-5ea3-4339-bea7-a91462373425,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1057156942-172.17.0.21-1597328507404:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36644,DS-079f74dd-fd61-428e-aa5c-a11b4098b501,DISK], DatanodeInfoWithStorage[127.0.0.1:44156,DS-78f2e676-9064-4269-8827-8d2ad9261b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:46613,DS-60813116-7ee4-4fcf-b3b4-ab4c8092658c,DISK], DatanodeInfoWithStorage[127.0.0.1:41085,DS-6cff5946-83cb-4c3e-abd9-97dae22782f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44189,DS-3d042ee1-f53f-422e-8ba1-5b36abba6627,DISK], DatanodeInfoWithStorage[127.0.0.1:41872,DS-1a28b261-ca88-42b6-bf23-6d40c7ad21fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44064,DS-c33901a4-f83b-4a6c-ac2e-ee506062f155,DISK], DatanodeInfoWithStorage[127.0.0.1:44405,DS-e75424e4-fe88-4df7-ae76-7de285acdb42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1057156942-172.17.0.21-1597328507404:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36644,DS-079f74dd-fd61-428e-aa5c-a11b4098b501,DISK], DatanodeInfoWithStorage[127.0.0.1:44156,DS-78f2e676-9064-4269-8827-8d2ad9261b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:46613,DS-60813116-7ee4-4fcf-b3b4-ab4c8092658c,DISK], DatanodeInfoWithStorage[127.0.0.1:41085,DS-6cff5946-83cb-4c3e-abd9-97dae22782f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44189,DS-3d042ee1-f53f-422e-8ba1-5b36abba6627,DISK], DatanodeInfoWithStorage[127.0.0.1:41872,DS-1a28b261-ca88-42b6-bf23-6d40c7ad21fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44064,DS-c33901a4-f83b-4a6c-ac2e-ee506062f155,DISK], DatanodeInfoWithStorage[127.0.0.1:44405,DS-e75424e4-fe88-4df7-ae76-7de285acdb42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-856224790-172.17.0.21-1597328591380:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36264,DS-dc5cd3f5-e141-4b89-aa9d-361331f7b51e,DISK], DatanodeInfoWithStorage[127.0.0.1:39342,DS-b17bd7e2-a329-4ba3-ae7b-d0f20e9dba89,DISK], DatanodeInfoWithStorage[127.0.0.1:40422,DS-2b380860-338c-4464-bdf2-a8abc1fb606e,DISK], DatanodeInfoWithStorage[127.0.0.1:37199,DS-3bd5baad-f187-49ba-9036-1337a6fe73c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38212,DS-646ab443-cee0-45ad-abbc-37fb5cab0217,DISK], DatanodeInfoWithStorage[127.0.0.1:34294,DS-9d227264-87f3-4edf-8843-17d17334286c,DISK], DatanodeInfoWithStorage[127.0.0.1:44751,DS-61c4c8a4-8f22-44d8-b135-0b5b779325eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46075,DS-40773558-8162-49fa-9f54-b636d34e07e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-856224790-172.17.0.21-1597328591380:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36264,DS-dc5cd3f5-e141-4b89-aa9d-361331f7b51e,DISK], DatanodeInfoWithStorage[127.0.0.1:39342,DS-b17bd7e2-a329-4ba3-ae7b-d0f20e9dba89,DISK], DatanodeInfoWithStorage[127.0.0.1:40422,DS-2b380860-338c-4464-bdf2-a8abc1fb606e,DISK], DatanodeInfoWithStorage[127.0.0.1:37199,DS-3bd5baad-f187-49ba-9036-1337a6fe73c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38212,DS-646ab443-cee0-45ad-abbc-37fb5cab0217,DISK], DatanodeInfoWithStorage[127.0.0.1:34294,DS-9d227264-87f3-4edf-8843-17d17334286c,DISK], DatanodeInfoWithStorage[127.0.0.1:44751,DS-61c4c8a4-8f22-44d8-b135-0b5b779325eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46075,DS-40773558-8162-49fa-9f54-b636d34e07e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-859797854-172.17.0.21-1597328742921:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33329,DS-f78e8872-bfd6-4bb2-b4b3-7a15ee919489,DISK], DatanodeInfoWithStorage[127.0.0.1:43543,DS-32b0bc0d-aa62-4494-b212-ebe1ccab5e97,DISK], DatanodeInfoWithStorage[127.0.0.1:39448,DS-d00974e3-53b9-46fc-bcbd-24954315ca72,DISK], DatanodeInfoWithStorage[127.0.0.1:44258,DS-e901f203-e39a-41f6-b287-68a983989c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36493,DS-64bc082e-8135-41da-bfc6-7755d8b606f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41886,DS-a215443f-11e6-44fe-be55-7071763b6a05,DISK], DatanodeInfoWithStorage[127.0.0.1:44178,DS-88ab2d25-4580-4d32-a05e-56a45d11409b,DISK], DatanodeInfoWithStorage[127.0.0.1:41691,DS-c04cc9a1-1749-417c-9342-d20e14d477c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-859797854-172.17.0.21-1597328742921:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33329,DS-f78e8872-bfd6-4bb2-b4b3-7a15ee919489,DISK], DatanodeInfoWithStorage[127.0.0.1:43543,DS-32b0bc0d-aa62-4494-b212-ebe1ccab5e97,DISK], DatanodeInfoWithStorage[127.0.0.1:39448,DS-d00974e3-53b9-46fc-bcbd-24954315ca72,DISK], DatanodeInfoWithStorage[127.0.0.1:44258,DS-e901f203-e39a-41f6-b287-68a983989c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36493,DS-64bc082e-8135-41da-bfc6-7755d8b606f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41886,DS-a215443f-11e6-44fe-be55-7071763b6a05,DISK], DatanodeInfoWithStorage[127.0.0.1:44178,DS-88ab2d25-4580-4d32-a05e-56a45d11409b,DISK], DatanodeInfoWithStorage[127.0.0.1:41691,DS-c04cc9a1-1749-417c-9342-d20e14d477c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1382087378-172.17.0.21-1597328825380:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42941,DS-5c110db7-66e6-4d99-987e-e4ff7ee02906,DISK], DatanodeInfoWithStorage[127.0.0.1:35711,DS-4682c047-cc41-4447-aca6-b27e6ca43831,DISK], DatanodeInfoWithStorage[127.0.0.1:33259,DS-b83102ad-e5a4-45a7-b0e7-b512c8787da2,DISK], DatanodeInfoWithStorage[127.0.0.1:43736,DS-da16e497-9dc8-47e2-a9b0-c96711585952,DISK], DatanodeInfoWithStorage[127.0.0.1:42265,DS-75c95a6f-8bdb-47e7-9dca-d22acdfd01f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40049,DS-1bc42497-00d0-45d6-8c68-294e0fcd2898,DISK], DatanodeInfoWithStorage[127.0.0.1:40795,DS-d1e53895-f8af-4e68-90eb-f7d6c026bca2,DISK], DatanodeInfoWithStorage[127.0.0.1:43865,DS-8056db55-3198-4222-b199-16728f4f5d6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1382087378-172.17.0.21-1597328825380:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42941,DS-5c110db7-66e6-4d99-987e-e4ff7ee02906,DISK], DatanodeInfoWithStorage[127.0.0.1:35711,DS-4682c047-cc41-4447-aca6-b27e6ca43831,DISK], DatanodeInfoWithStorage[127.0.0.1:33259,DS-b83102ad-e5a4-45a7-b0e7-b512c8787da2,DISK], DatanodeInfoWithStorage[127.0.0.1:43736,DS-da16e497-9dc8-47e2-a9b0-c96711585952,DISK], DatanodeInfoWithStorage[127.0.0.1:42265,DS-75c95a6f-8bdb-47e7-9dca-d22acdfd01f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40049,DS-1bc42497-00d0-45d6-8c68-294e0fcd2898,DISK], DatanodeInfoWithStorage[127.0.0.1:40795,DS-d1e53895-f8af-4e68-90eb-f7d6c026bca2,DISK], DatanodeInfoWithStorage[127.0.0.1:43865,DS-8056db55-3198-4222-b199-16728f4f5d6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 6954
