reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1030947387-172.17.0.21-1597566010185:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35338,DS-fcb1ebef-df6e-4b60-8340-c86e64f8997a,DISK], DatanodeInfoWithStorage[127.0.0.1:44176,DS-0bde3b1f-775c-48f9-80e2-083745b59719,DISK], DatanodeInfoWithStorage[127.0.0.1:43197,DS-ee5d5fa1-5a4e-461b-8d27-1c817498e4d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36029,DS-7dfc42a1-e361-461d-971c-47489651645e,DISK], DatanodeInfoWithStorage[127.0.0.1:33871,DS-0eed94ab-eba9-44e7-b7bf-0a56fa4ab21c,DISK], DatanodeInfoWithStorage[127.0.0.1:36857,DS-4af4764f-f71d-4412-92e5-93a0f2e339a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40492,DS-f8145874-c3d8-4cdf-973e-17cb0b18a08b,DISK], DatanodeInfoWithStorage[127.0.0.1:33456,DS-d9a71066-fb58-481d-9f35-c698b4818c02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1030947387-172.17.0.21-1597566010185:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35338,DS-fcb1ebef-df6e-4b60-8340-c86e64f8997a,DISK], DatanodeInfoWithStorage[127.0.0.1:44176,DS-0bde3b1f-775c-48f9-80e2-083745b59719,DISK], DatanodeInfoWithStorage[127.0.0.1:43197,DS-ee5d5fa1-5a4e-461b-8d27-1c817498e4d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36029,DS-7dfc42a1-e361-461d-971c-47489651645e,DISK], DatanodeInfoWithStorage[127.0.0.1:33871,DS-0eed94ab-eba9-44e7-b7bf-0a56fa4ab21c,DISK], DatanodeInfoWithStorage[127.0.0.1:36857,DS-4af4764f-f71d-4412-92e5-93a0f2e339a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40492,DS-f8145874-c3d8-4cdf-973e-17cb0b18a08b,DISK], DatanodeInfoWithStorage[127.0.0.1:33456,DS-d9a71066-fb58-481d-9f35-c698b4818c02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2108134261-172.17.0.21-1597566286954:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38169,DS-4bc57aa7-97ef-44c7-8c1a-3daf8d803185,DISK], DatanodeInfoWithStorage[127.0.0.1:43533,DS-10e2c63b-39dd-4e17-a91f-26541ea887b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43799,DS-ce88381b-7e3e-4e94-b7a1-4992beba81fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33208,DS-e295f20d-a366-4d0d-a2bc-0bcc672cf2e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41352,DS-c78276b5-2ec1-43f7-a68d-d030b79a1948,DISK], DatanodeInfoWithStorage[127.0.0.1:40080,DS-6aff2287-f9c5-4942-a9b7-74cd024762cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35721,DS-8fe4aac1-833c-429e-8642-2d7659fdfb47,DISK], DatanodeInfoWithStorage[127.0.0.1:40474,DS-1810ec57-9e30-4950-b0e2-31ba616bd351,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2108134261-172.17.0.21-1597566286954:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38169,DS-4bc57aa7-97ef-44c7-8c1a-3daf8d803185,DISK], DatanodeInfoWithStorage[127.0.0.1:43533,DS-10e2c63b-39dd-4e17-a91f-26541ea887b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43799,DS-ce88381b-7e3e-4e94-b7a1-4992beba81fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33208,DS-e295f20d-a366-4d0d-a2bc-0bcc672cf2e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41352,DS-c78276b5-2ec1-43f7-a68d-d030b79a1948,DISK], DatanodeInfoWithStorage[127.0.0.1:40080,DS-6aff2287-f9c5-4942-a9b7-74cd024762cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35721,DS-8fe4aac1-833c-429e-8642-2d7659fdfb47,DISK], DatanodeInfoWithStorage[127.0.0.1:40474,DS-1810ec57-9e30-4950-b0e2-31ba616bd351,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1846024685-172.17.0.21-1597568127542:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42343,DS-b12d8a4f-a730-4ab7-8036-4e1fb78ddc12,DISK], DatanodeInfoWithStorage[127.0.0.1:38442,DS-bab69205-23aa-45e2-aea5-c615801428fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46016,DS-3ad375af-41c9-4b1b-8a0c-2a9e128aaf28,DISK], DatanodeInfoWithStorage[127.0.0.1:36917,DS-8e3d6c21-1490-4794-83ca-08e7f4b357fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38790,DS-95e05aed-c9c4-47a4-9009-356169eb1050,DISK], DatanodeInfoWithStorage[127.0.0.1:39791,DS-e616e711-22d1-4c57-8ded-bd1e491b58ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39337,DS-cf928ce0-9945-40d6-a5c9-ea530403ce60,DISK], DatanodeInfoWithStorage[127.0.0.1:37169,DS-8b3cf9c3-3a0a-406b-a47f-555cd3b8311b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1846024685-172.17.0.21-1597568127542:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42343,DS-b12d8a4f-a730-4ab7-8036-4e1fb78ddc12,DISK], DatanodeInfoWithStorage[127.0.0.1:38442,DS-bab69205-23aa-45e2-aea5-c615801428fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46016,DS-3ad375af-41c9-4b1b-8a0c-2a9e128aaf28,DISK], DatanodeInfoWithStorage[127.0.0.1:36917,DS-8e3d6c21-1490-4794-83ca-08e7f4b357fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38790,DS-95e05aed-c9c4-47a4-9009-356169eb1050,DISK], DatanodeInfoWithStorage[127.0.0.1:39791,DS-e616e711-22d1-4c57-8ded-bd1e491b58ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39337,DS-cf928ce0-9945-40d6-a5c9-ea530403ce60,DISK], DatanodeInfoWithStorage[127.0.0.1:37169,DS-8b3cf9c3-3a0a-406b-a47f-555cd3b8311b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1749803237-172.17.0.21-1597568318345:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40531,DS-84c53835-252d-4628-8aa4-d01512e053b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40618,DS-4ed6874b-baad-4524-bcd7-25e6d56326d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44589,DS-2dfa3c0b-047f-4e9d-a59f-1ba78a99794e,DISK], DatanodeInfoWithStorage[127.0.0.1:42171,DS-02c65d3f-b142-4abb-807a-c97fec80a978,DISK], DatanodeInfoWithStorage[127.0.0.1:46497,DS-55b028c3-3530-4db2-ae8f-e79c6af74fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:33296,DS-e09dfec1-0b86-4534-9260-80a5a988b278,DISK], DatanodeInfoWithStorage[127.0.0.1:35510,DS-c8b7ebc6-f849-4fb2-8487-b8a83588152a,DISK], DatanodeInfoWithStorage[127.0.0.1:42444,DS-e6964020-22df-47a0-b5f0-ca9555eca47e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1749803237-172.17.0.21-1597568318345:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40531,DS-84c53835-252d-4628-8aa4-d01512e053b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40618,DS-4ed6874b-baad-4524-bcd7-25e6d56326d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44589,DS-2dfa3c0b-047f-4e9d-a59f-1ba78a99794e,DISK], DatanodeInfoWithStorage[127.0.0.1:42171,DS-02c65d3f-b142-4abb-807a-c97fec80a978,DISK], DatanodeInfoWithStorage[127.0.0.1:46497,DS-55b028c3-3530-4db2-ae8f-e79c6af74fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:33296,DS-e09dfec1-0b86-4534-9260-80a5a988b278,DISK], DatanodeInfoWithStorage[127.0.0.1:35510,DS-c8b7ebc6-f849-4fb2-8487-b8a83588152a,DISK], DatanodeInfoWithStorage[127.0.0.1:42444,DS-e6964020-22df-47a0-b5f0-ca9555eca47e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1077733824-172.17.0.21-1597568622093:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37073,DS-f4cc8caa-121f-469c-a1f3-f4b9d54d0c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:43722,DS-2c69080a-ddf5-4664-8d7b-78e64b43bcee,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-3dd03be7-c1c9-4dd5-be19-06b86967f8f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34514,DS-32eee2d0-cbd9-44a6-b929-cca6aac47ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:42034,DS-68577058-a922-4c73-816c-5aafae09320b,DISK], DatanodeInfoWithStorage[127.0.0.1:37674,DS-b3c171f6-9bcb-499d-a61f-d23fea56e82d,DISK], DatanodeInfoWithStorage[127.0.0.1:33004,DS-569a124b-47c5-417d-9a4c-d80d810255a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35680,DS-bd4893a5-45da-48b5-9259-fded1b0d63df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1077733824-172.17.0.21-1597568622093:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37073,DS-f4cc8caa-121f-469c-a1f3-f4b9d54d0c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:43722,DS-2c69080a-ddf5-4664-8d7b-78e64b43bcee,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-3dd03be7-c1c9-4dd5-be19-06b86967f8f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34514,DS-32eee2d0-cbd9-44a6-b929-cca6aac47ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:42034,DS-68577058-a922-4c73-816c-5aafae09320b,DISK], DatanodeInfoWithStorage[127.0.0.1:37674,DS-b3c171f6-9bcb-499d-a61f-d23fea56e82d,DISK], DatanodeInfoWithStorage[127.0.0.1:33004,DS-569a124b-47c5-417d-9a4c-d80d810255a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35680,DS-bd4893a5-45da-48b5-9259-fded1b0d63df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-669004871-172.17.0.21-1597569464938:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43653,DS-bb0f2ca8-0744-474b-a7f2-6e533c65934e,DISK], DatanodeInfoWithStorage[127.0.0.1:45088,DS-d53debc2-488e-481d-b37f-1fe2c698edc1,DISK], DatanodeInfoWithStorage[127.0.0.1:38605,DS-6e2b7168-f1ff-41a7-b9fb-258b64a59626,DISK], DatanodeInfoWithStorage[127.0.0.1:45899,DS-e8877102-2932-4386-9b32-59cda2733299,DISK], DatanodeInfoWithStorage[127.0.0.1:41567,DS-df48f89a-bb64-44f3-846c-b964377f47f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46057,DS-5ba9f51a-8499-40df-8141-4c3f6980f9dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46763,DS-9c3d1315-57af-45ed-8563-35ebf88fd240,DISK], DatanodeInfoWithStorage[127.0.0.1:37695,DS-1eb7838a-400f-471d-8c49-984a62803c81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-669004871-172.17.0.21-1597569464938:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43653,DS-bb0f2ca8-0744-474b-a7f2-6e533c65934e,DISK], DatanodeInfoWithStorage[127.0.0.1:45088,DS-d53debc2-488e-481d-b37f-1fe2c698edc1,DISK], DatanodeInfoWithStorage[127.0.0.1:38605,DS-6e2b7168-f1ff-41a7-b9fb-258b64a59626,DISK], DatanodeInfoWithStorage[127.0.0.1:45899,DS-e8877102-2932-4386-9b32-59cda2733299,DISK], DatanodeInfoWithStorage[127.0.0.1:41567,DS-df48f89a-bb64-44f3-846c-b964377f47f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46057,DS-5ba9f51a-8499-40df-8141-4c3f6980f9dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46763,DS-9c3d1315-57af-45ed-8563-35ebf88fd240,DISK], DatanodeInfoWithStorage[127.0.0.1:37695,DS-1eb7838a-400f-471d-8c49-984a62803c81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1406232992-172.17.0.21-1597569778396:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40466,DS-42e973b4-0cd1-4241-802f-0e9d4d9b8a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33294,DS-d6f81958-e4c3-4e8c-bb1c-31bb0ab55c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:42560,DS-b5d76090-79f4-44e4-b9ed-6cdcd3a7ab16,DISK], DatanodeInfoWithStorage[127.0.0.1:37921,DS-a6d5ff32-d021-4ae7-b037-ad61ad1c04e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46030,DS-cdba6e64-beb2-4271-8b1c-a5cdb0ad1571,DISK], DatanodeInfoWithStorage[127.0.0.1:39494,DS-9a232e7a-ee3c-4d2a-b461-e846f85d1828,DISK], DatanodeInfoWithStorage[127.0.0.1:42496,DS-19bd79ed-7fb2-4b83-84b2-b1f52f5d92ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34201,DS-b0bff72d-38bb-43f1-a51a-eebc8fa73a3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1406232992-172.17.0.21-1597569778396:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40466,DS-42e973b4-0cd1-4241-802f-0e9d4d9b8a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33294,DS-d6f81958-e4c3-4e8c-bb1c-31bb0ab55c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:42560,DS-b5d76090-79f4-44e4-b9ed-6cdcd3a7ab16,DISK], DatanodeInfoWithStorage[127.0.0.1:37921,DS-a6d5ff32-d021-4ae7-b037-ad61ad1c04e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46030,DS-cdba6e64-beb2-4271-8b1c-a5cdb0ad1571,DISK], DatanodeInfoWithStorage[127.0.0.1:39494,DS-9a232e7a-ee3c-4d2a-b461-e846f85d1828,DISK], DatanodeInfoWithStorage[127.0.0.1:42496,DS-19bd79ed-7fb2-4b83-84b2-b1f52f5d92ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34201,DS-b0bff72d-38bb-43f1-a51a-eebc8fa73a3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-512057840-172.17.0.21-1597569930622:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46625,DS-6f67e05b-2d9a-4f60-b862-2ce07605adc6,DISK], DatanodeInfoWithStorage[127.0.0.1:43356,DS-3d817228-c594-45a7-918b-ca518fc85649,DISK], DatanodeInfoWithStorage[127.0.0.1:33950,DS-b6d4bcfa-e571-4809-96cf-58759c0f984d,DISK], DatanodeInfoWithStorage[127.0.0.1:35360,DS-ce7f7833-fbfe-4749-90a1-952c64808d90,DISK], DatanodeInfoWithStorage[127.0.0.1:35297,DS-1fb9e4b1-a04c-45ea-942b-7514cdbc4865,DISK], DatanodeInfoWithStorage[127.0.0.1:39939,DS-3d1fd6f0-643a-4e4b-9417-5267f3c1a868,DISK], DatanodeInfoWithStorage[127.0.0.1:43610,DS-3ddb42c2-1048-4e04-9b07-b6e1727dc565,DISK], DatanodeInfoWithStorage[127.0.0.1:40448,DS-37566f61-2c51-4b8b-818e-7ebb16dba628,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-512057840-172.17.0.21-1597569930622:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46625,DS-6f67e05b-2d9a-4f60-b862-2ce07605adc6,DISK], DatanodeInfoWithStorage[127.0.0.1:43356,DS-3d817228-c594-45a7-918b-ca518fc85649,DISK], DatanodeInfoWithStorage[127.0.0.1:33950,DS-b6d4bcfa-e571-4809-96cf-58759c0f984d,DISK], DatanodeInfoWithStorage[127.0.0.1:35360,DS-ce7f7833-fbfe-4749-90a1-952c64808d90,DISK], DatanodeInfoWithStorage[127.0.0.1:35297,DS-1fb9e4b1-a04c-45ea-942b-7514cdbc4865,DISK], DatanodeInfoWithStorage[127.0.0.1:39939,DS-3d1fd6f0-643a-4e4b-9417-5267f3c1a868,DISK], DatanodeInfoWithStorage[127.0.0.1:43610,DS-3ddb42c2-1048-4e04-9b07-b6e1727dc565,DISK], DatanodeInfoWithStorage[127.0.0.1:40448,DS-37566f61-2c51-4b8b-818e-7ebb16dba628,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1926265587-172.17.0.21-1597570033484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37508,DS-7f76ff02-d236-4c59-84a9-a1eb0c1c2484,DISK], DatanodeInfoWithStorage[127.0.0.1:36114,DS-7c0b1be6-39d8-4108-af3a-ff95377945d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33651,DS-691d9cfd-874b-4fa8-bf06-1cfa638b1ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:33704,DS-0316ea35-1e84-4508-816a-c361b4f00486,DISK], DatanodeInfoWithStorage[127.0.0.1:42437,DS-61c043b1-2fb6-42bd-8a3c-20dd7fa7660d,DISK], DatanodeInfoWithStorage[127.0.0.1:42975,DS-392563e4-8502-45b5-b67a-7f6421264b60,DISK], DatanodeInfoWithStorage[127.0.0.1:34635,DS-8b881812-b025-45ab-9e78-3264e773ed87,DISK], DatanodeInfoWithStorage[127.0.0.1:33793,DS-9e9a792e-b89d-491e-a340-8e1e1c380716,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1926265587-172.17.0.21-1597570033484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37508,DS-7f76ff02-d236-4c59-84a9-a1eb0c1c2484,DISK], DatanodeInfoWithStorage[127.0.0.1:36114,DS-7c0b1be6-39d8-4108-af3a-ff95377945d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33651,DS-691d9cfd-874b-4fa8-bf06-1cfa638b1ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:33704,DS-0316ea35-1e84-4508-816a-c361b4f00486,DISK], DatanodeInfoWithStorage[127.0.0.1:42437,DS-61c043b1-2fb6-42bd-8a3c-20dd7fa7660d,DISK], DatanodeInfoWithStorage[127.0.0.1:42975,DS-392563e4-8502-45b5-b67a-7f6421264b60,DISK], DatanodeInfoWithStorage[127.0.0.1:34635,DS-8b881812-b025-45ab-9e78-3264e773ed87,DISK], DatanodeInfoWithStorage[127.0.0.1:33793,DS-9e9a792e-b89d-491e-a340-8e1e1c380716,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1696081756-172.17.0.21-1597570109382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40562,DS-c67ddbb0-06aa-4db2-ade0-f76aca00389a,DISK], DatanodeInfoWithStorage[127.0.0.1:38701,DS-094b5ce8-2c37-4ffd-81af-eb070f82208d,DISK], DatanodeInfoWithStorage[127.0.0.1:45352,DS-a797baa0-a847-434b-bebd-eabeb83f879e,DISK], DatanodeInfoWithStorage[127.0.0.1:41243,DS-6cd9d4e3-ab87-4431-9574-c266402b2f64,DISK], DatanodeInfoWithStorage[127.0.0.1:38068,DS-b76266a0-a5c8-45cd-83e9-de71abb977db,DISK], DatanodeInfoWithStorage[127.0.0.1:38594,DS-c700f061-0304-4cb4-8ebd-f720500657d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38055,DS-eceb5c42-ac97-4f37-8388-9f7623dcf579,DISK], DatanodeInfoWithStorage[127.0.0.1:36015,DS-9ceb80c8-c7ae-43f7-98a4-102c111c7a81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1696081756-172.17.0.21-1597570109382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40562,DS-c67ddbb0-06aa-4db2-ade0-f76aca00389a,DISK], DatanodeInfoWithStorage[127.0.0.1:38701,DS-094b5ce8-2c37-4ffd-81af-eb070f82208d,DISK], DatanodeInfoWithStorage[127.0.0.1:45352,DS-a797baa0-a847-434b-bebd-eabeb83f879e,DISK], DatanodeInfoWithStorage[127.0.0.1:41243,DS-6cd9d4e3-ab87-4431-9574-c266402b2f64,DISK], DatanodeInfoWithStorage[127.0.0.1:38068,DS-b76266a0-a5c8-45cd-83e9-de71abb977db,DISK], DatanodeInfoWithStorage[127.0.0.1:38594,DS-c700f061-0304-4cb4-8ebd-f720500657d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38055,DS-eceb5c42-ac97-4f37-8388-9f7623dcf579,DISK], DatanodeInfoWithStorage[127.0.0.1:36015,DS-9ceb80c8-c7ae-43f7-98a4-102c111c7a81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-866263918-172.17.0.21-1597570768256:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45190,DS-1d08f48a-7802-459b-b3a7-98fec529ee3f,DISK], DatanodeInfoWithStorage[127.0.0.1:44540,DS-fb5b8825-2a03-480e-869c-fa8db39e71c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38518,DS-497e2ac4-3554-479e-8e0e-3c41fee74e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:36315,DS-5d69b4b2-16d9-47d2-8873-d36e90a37eac,DISK], DatanodeInfoWithStorage[127.0.0.1:33663,DS-c0d2e3d7-869d-4a55-bd54-4b6bdfe6bc0c,DISK], DatanodeInfoWithStorage[127.0.0.1:34916,DS-08a298a8-8bf9-4a6d-bf1d-1ad7a1b9e233,DISK], DatanodeInfoWithStorage[127.0.0.1:42044,DS-151ee26a-a359-455b-9566-1ccd8445ddd9,DISK], DatanodeInfoWithStorage[127.0.0.1:39631,DS-0a82408d-3b13-46c8-ba3d-d9e29507b4f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-866263918-172.17.0.21-1597570768256:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45190,DS-1d08f48a-7802-459b-b3a7-98fec529ee3f,DISK], DatanodeInfoWithStorage[127.0.0.1:44540,DS-fb5b8825-2a03-480e-869c-fa8db39e71c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38518,DS-497e2ac4-3554-479e-8e0e-3c41fee74e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:36315,DS-5d69b4b2-16d9-47d2-8873-d36e90a37eac,DISK], DatanodeInfoWithStorage[127.0.0.1:33663,DS-c0d2e3d7-869d-4a55-bd54-4b6bdfe6bc0c,DISK], DatanodeInfoWithStorage[127.0.0.1:34916,DS-08a298a8-8bf9-4a6d-bf1d-1ad7a1b9e233,DISK], DatanodeInfoWithStorage[127.0.0.1:42044,DS-151ee26a-a359-455b-9566-1ccd8445ddd9,DISK], DatanodeInfoWithStorage[127.0.0.1:39631,DS-0a82408d-3b13-46c8-ba3d-d9e29507b4f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-853774029-172.17.0.21-1597570845387:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34474,DS-dd0018d7-449e-4a80-aa43-a828fa13e71e,DISK], DatanodeInfoWithStorage[127.0.0.1:35691,DS-1e1ca8e7-26f9-4045-b719-123d47775798,DISK], DatanodeInfoWithStorage[127.0.0.1:45918,DS-eaf1613a-9ccb-4289-a33a-c050ddfa491d,DISK], DatanodeInfoWithStorage[127.0.0.1:42099,DS-4cbd1ac9-72a3-4a78-92c5-b6994497a3a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38669,DS-ed224a23-beae-4b58-86a9-04b8c78ab047,DISK], DatanodeInfoWithStorage[127.0.0.1:42331,DS-b083c1a0-c7e5-492e-b862-3fdfee241719,DISK], DatanodeInfoWithStorage[127.0.0.1:37233,DS-fa1cf5be-8542-406d-9e55-97419209b80a,DISK], DatanodeInfoWithStorage[127.0.0.1:44857,DS-1d1f1b4f-171c-47d9-860e-6b013e9a1730,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-853774029-172.17.0.21-1597570845387:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34474,DS-dd0018d7-449e-4a80-aa43-a828fa13e71e,DISK], DatanodeInfoWithStorage[127.0.0.1:35691,DS-1e1ca8e7-26f9-4045-b719-123d47775798,DISK], DatanodeInfoWithStorage[127.0.0.1:45918,DS-eaf1613a-9ccb-4289-a33a-c050ddfa491d,DISK], DatanodeInfoWithStorage[127.0.0.1:42099,DS-4cbd1ac9-72a3-4a78-92c5-b6994497a3a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38669,DS-ed224a23-beae-4b58-86a9-04b8c78ab047,DISK], DatanodeInfoWithStorage[127.0.0.1:42331,DS-b083c1a0-c7e5-492e-b862-3fdfee241719,DISK], DatanodeInfoWithStorage[127.0.0.1:37233,DS-fa1cf5be-8542-406d-9e55-97419209b80a,DISK], DatanodeInfoWithStorage[127.0.0.1:44857,DS-1d1f1b4f-171c-47d9-860e-6b013e9a1730,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5552
