reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 4
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 4
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1285866009-172.17.0.14-1597653479058:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34895,DS-7186d1ba-238d-4184-b5da-8f320ac69355,DISK], DatanodeInfoWithStorage[127.0.0.1:42068,DS-f973cbee-0aee-4089-b89e-4457184626e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35137,DS-71f3695d-7360-4c6f-843c-01039cc48e47,DISK], DatanodeInfoWithStorage[127.0.0.1:43846,DS-6a747319-2007-41b7-b057-71886d7c1b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45768,DS-23574423-d3f6-455e-b4b9-2fe542802154,DISK], DatanodeInfoWithStorage[127.0.0.1:37148,DS-a7860876-ae7a-4886-bbe2-778eff4c024c,DISK], DatanodeInfoWithStorage[127.0.0.1:37680,DS-6f9241d1-60f4-4272-bd71-0db90f7272ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36340,DS-8282db5e-a6ed-48a9-8747-7d0ff5c56ff3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1285866009-172.17.0.14-1597653479058:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34895,DS-7186d1ba-238d-4184-b5da-8f320ac69355,DISK], DatanodeInfoWithStorage[127.0.0.1:42068,DS-f973cbee-0aee-4089-b89e-4457184626e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35137,DS-71f3695d-7360-4c6f-843c-01039cc48e47,DISK], DatanodeInfoWithStorage[127.0.0.1:43846,DS-6a747319-2007-41b7-b057-71886d7c1b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45768,DS-23574423-d3f6-455e-b4b9-2fe542802154,DISK], DatanodeInfoWithStorage[127.0.0.1:37148,DS-a7860876-ae7a-4886-bbe2-778eff4c024c,DISK], DatanodeInfoWithStorage[127.0.0.1:37680,DS-6f9241d1-60f4-4272-bd71-0db90f7272ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36340,DS-8282db5e-a6ed-48a9-8747-7d0ff5c56ff3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 4
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-806991008-172.17.0.14-1597653626338:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34567,DS-2824e9e7-a270-43fb-9d46-12076d496fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:37363,DS-e47515af-a464-438a-8225-50e4871c97d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37217,DS-3dd0faf6-2a63-43e8-b69d-458c003815ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43497,DS-9c832d58-a132-4b55-9b17-396e480dbdc6,DISK], DatanodeInfoWithStorage[127.0.0.1:44656,DS-0d25f98d-cb32-4f94-9846-780525d5cfaf,DISK], DatanodeInfoWithStorage[127.0.0.1:37085,DS-a4e62467-46b8-49da-a653-1c0451306d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:33530,DS-b218bd85-4eae-4fdc-9624-4c15e67048f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41906,DS-8fc6f20e-a8de-479f-b0ec-72b15fda12fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-806991008-172.17.0.14-1597653626338:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34567,DS-2824e9e7-a270-43fb-9d46-12076d496fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:37363,DS-e47515af-a464-438a-8225-50e4871c97d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37217,DS-3dd0faf6-2a63-43e8-b69d-458c003815ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43497,DS-9c832d58-a132-4b55-9b17-396e480dbdc6,DISK], DatanodeInfoWithStorage[127.0.0.1:44656,DS-0d25f98d-cb32-4f94-9846-780525d5cfaf,DISK], DatanodeInfoWithStorage[127.0.0.1:37085,DS-a4e62467-46b8-49da-a653-1c0451306d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:33530,DS-b218bd85-4eae-4fdc-9624-4c15e67048f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41906,DS-8fc6f20e-a8de-479f-b0ec-72b15fda12fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 4
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-586704897-172.17.0.14-1597654048086:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39539,DS-cd0899b4-eed4-463b-b3ca-a1bf373d64d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34836,DS-69dd06f4-4688-4e91-9ac5-8382f1df9c62,DISK], DatanodeInfoWithStorage[127.0.0.1:39171,DS-a95f2041-2ece-44a5-a021-88f3c8898fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:34175,DS-c9e5d189-5e28-4b78-ad92-114cd8e12d18,DISK], DatanodeInfoWithStorage[127.0.0.1:36317,DS-c3d26ea6-d86d-4315-9454-e11efbb3af2d,DISK], DatanodeInfoWithStorage[127.0.0.1:37481,DS-d8a14668-f2d9-492d-b9e4-6fb658f7ac4b,DISK], DatanodeInfoWithStorage[127.0.0.1:40127,DS-a1124684-e0f8-4099-9e18-97e8b3b1de3a,DISK], DatanodeInfoWithStorage[127.0.0.1:37379,DS-136dcefc-dc4b-4636-abd6-38705a5b42ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-586704897-172.17.0.14-1597654048086:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39539,DS-cd0899b4-eed4-463b-b3ca-a1bf373d64d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34836,DS-69dd06f4-4688-4e91-9ac5-8382f1df9c62,DISK], DatanodeInfoWithStorage[127.0.0.1:39171,DS-a95f2041-2ece-44a5-a021-88f3c8898fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:34175,DS-c9e5d189-5e28-4b78-ad92-114cd8e12d18,DISK], DatanodeInfoWithStorage[127.0.0.1:36317,DS-c3d26ea6-d86d-4315-9454-e11efbb3af2d,DISK], DatanodeInfoWithStorage[127.0.0.1:37481,DS-d8a14668-f2d9-492d-b9e4-6fb658f7ac4b,DISK], DatanodeInfoWithStorage[127.0.0.1:40127,DS-a1124684-e0f8-4099-9e18-97e8b3b1de3a,DISK], DatanodeInfoWithStorage[127.0.0.1:37379,DS-136dcefc-dc4b-4636-abd6-38705a5b42ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 4
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-649249728-172.17.0.14-1597654247999:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46215,DS-d5fde02c-9c58-47ce-80d3-d403448fd038,DISK], DatanodeInfoWithStorage[127.0.0.1:41296,DS-a31998a5-6da2-44a7-9796-ace3393a257a,DISK], DatanodeInfoWithStorage[127.0.0.1:46474,DS-ca13ec82-24d4-4cdd-a1f8-7c23ec2cbe19,DISK], DatanodeInfoWithStorage[127.0.0.1:42521,DS-e36927c0-b9d5-4f57-9507-0d8159e42ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:39471,DS-821a0f60-bc14-4332-b186-df0dfc1ec96f,DISK], DatanodeInfoWithStorage[127.0.0.1:46628,DS-4cc980f8-4dba-4663-9903-29407b803014,DISK], DatanodeInfoWithStorage[127.0.0.1:33958,DS-fa6f9d32-b991-4398-acfe-2d2ecdd94bca,DISK], DatanodeInfoWithStorage[127.0.0.1:45474,DS-9b367bec-53a4-445e-a4e4-8c3e826b4768,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-649249728-172.17.0.14-1597654247999:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46215,DS-d5fde02c-9c58-47ce-80d3-d403448fd038,DISK], DatanodeInfoWithStorage[127.0.0.1:41296,DS-a31998a5-6da2-44a7-9796-ace3393a257a,DISK], DatanodeInfoWithStorage[127.0.0.1:46474,DS-ca13ec82-24d4-4cdd-a1f8-7c23ec2cbe19,DISK], DatanodeInfoWithStorage[127.0.0.1:42521,DS-e36927c0-b9d5-4f57-9507-0d8159e42ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:39471,DS-821a0f60-bc14-4332-b186-df0dfc1ec96f,DISK], DatanodeInfoWithStorage[127.0.0.1:46628,DS-4cc980f8-4dba-4663-9903-29407b803014,DISK], DatanodeInfoWithStorage[127.0.0.1:33958,DS-fa6f9d32-b991-4398-acfe-2d2ecdd94bca,DISK], DatanodeInfoWithStorage[127.0.0.1:45474,DS-9b367bec-53a4-445e-a4e4-8c3e826b4768,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 4
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-744594675-172.17.0.14-1597655131457:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33830,DS-525b5b73-e9f3-42ce-8dd4-8a2c97a1fdbe,DISK], DatanodeInfoWithStorage[127.0.0.1:38967,DS-2629526e-6a68-47a6-aad6-6c4a83d83220,DISK], DatanodeInfoWithStorage[127.0.0.1:34752,DS-594e012d-ad40-4401-8ab6-08a6c40aa7af,DISK], DatanodeInfoWithStorage[127.0.0.1:38040,DS-966fdeee-5cb2-4766-88cf-77b44297a6bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44356,DS-17bd71e9-d83b-424b-9e1d-eb5249fcedda,DISK], DatanodeInfoWithStorage[127.0.0.1:44064,DS-ace63c8b-5152-4731-9a6f-5a02032d0e19,DISK], DatanodeInfoWithStorage[127.0.0.1:39769,DS-cccc63f2-1675-4b49-9777-126d412e8ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:33262,DS-565eb1b4-7623-4124-b633-256b12550255,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-744594675-172.17.0.14-1597655131457:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33830,DS-525b5b73-e9f3-42ce-8dd4-8a2c97a1fdbe,DISK], DatanodeInfoWithStorage[127.0.0.1:38967,DS-2629526e-6a68-47a6-aad6-6c4a83d83220,DISK], DatanodeInfoWithStorage[127.0.0.1:34752,DS-594e012d-ad40-4401-8ab6-08a6c40aa7af,DISK], DatanodeInfoWithStorage[127.0.0.1:38040,DS-966fdeee-5cb2-4766-88cf-77b44297a6bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44356,DS-17bd71e9-d83b-424b-9e1d-eb5249fcedda,DISK], DatanodeInfoWithStorage[127.0.0.1:44064,DS-ace63c8b-5152-4731-9a6f-5a02032d0e19,DISK], DatanodeInfoWithStorage[127.0.0.1:39769,DS-cccc63f2-1675-4b49-9777-126d412e8ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:33262,DS-565eb1b4-7623-4124-b633-256b12550255,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 4
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1545375779-172.17.0.14-1597656094174:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33462,DS-1be4eb12-2b62-4885-a0b7-13fb823d21b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33290,DS-b588de55-5e82-4add-a98b-2adf67ddbeb8,DISK], DatanodeInfoWithStorage[127.0.0.1:33745,DS-3162be57-7163-4105-8a43-9840e5995084,DISK], DatanodeInfoWithStorage[127.0.0.1:38173,DS-3703095c-2071-4909-9cd4-1c1f99e5b5ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41776,DS-054e78f0-f022-4b2c-967d-a37405b5d058,DISK], DatanodeInfoWithStorage[127.0.0.1:43090,DS-6f388c9c-fd0e-46c9-97b9-4f3c79c3c0be,DISK], DatanodeInfoWithStorage[127.0.0.1:32932,DS-45ecde43-9e2e-477c-bda1-1b8714b586df,DISK], DatanodeInfoWithStorage[127.0.0.1:44467,DS-7a98869f-e6fe-4f72-bd36-e1570db075b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1545375779-172.17.0.14-1597656094174:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33462,DS-1be4eb12-2b62-4885-a0b7-13fb823d21b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33290,DS-b588de55-5e82-4add-a98b-2adf67ddbeb8,DISK], DatanodeInfoWithStorage[127.0.0.1:33745,DS-3162be57-7163-4105-8a43-9840e5995084,DISK], DatanodeInfoWithStorage[127.0.0.1:38173,DS-3703095c-2071-4909-9cd4-1c1f99e5b5ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41776,DS-054e78f0-f022-4b2c-967d-a37405b5d058,DISK], DatanodeInfoWithStorage[127.0.0.1:43090,DS-6f388c9c-fd0e-46c9-97b9-4f3c79c3c0be,DISK], DatanodeInfoWithStorage[127.0.0.1:32932,DS-45ecde43-9e2e-477c-bda1-1b8714b586df,DISK], DatanodeInfoWithStorage[127.0.0.1:44467,DS-7a98869f-e6fe-4f72-bd36-e1570db075b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 4
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1438823569-172.17.0.14-1597656347338:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44286,DS-16e293da-4549-467a-89d4-223d0774386d,DISK], DatanodeInfoWithStorage[127.0.0.1:44383,DS-5292bb09-75a7-4352-83ec-00c38da476a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38525,DS-90207710-372a-4a1e-a65d-3ed459e0981b,DISK], DatanodeInfoWithStorage[127.0.0.1:36998,DS-972703f7-ad00-4f7c-a250-a01571d71b27,DISK], DatanodeInfoWithStorage[127.0.0.1:35149,DS-0ab10066-247a-4b18-badb-e8d947612f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:34575,DS-857ecfff-64f5-4f78-b9d0-8c2bc942489d,DISK], DatanodeInfoWithStorage[127.0.0.1:35401,DS-a42818d0-9e00-4e89-b990-4b6c89b1f730,DISK], DatanodeInfoWithStorage[127.0.0.1:35826,DS-c3941dbf-08fd-4a59-959d-83a65145f13b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1438823569-172.17.0.14-1597656347338:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44286,DS-16e293da-4549-467a-89d4-223d0774386d,DISK], DatanodeInfoWithStorage[127.0.0.1:44383,DS-5292bb09-75a7-4352-83ec-00c38da476a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38525,DS-90207710-372a-4a1e-a65d-3ed459e0981b,DISK], DatanodeInfoWithStorage[127.0.0.1:36998,DS-972703f7-ad00-4f7c-a250-a01571d71b27,DISK], DatanodeInfoWithStorage[127.0.0.1:35149,DS-0ab10066-247a-4b18-badb-e8d947612f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:34575,DS-857ecfff-64f5-4f78-b9d0-8c2bc942489d,DISK], DatanodeInfoWithStorage[127.0.0.1:35401,DS-a42818d0-9e00-4e89-b990-4b6c89b1f730,DISK], DatanodeInfoWithStorage[127.0.0.1:35826,DS-c3941dbf-08fd-4a59-959d-83a65145f13b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 4
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1779681677-172.17.0.14-1597656875940:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44518,DS-8c7c7866-2365-4770-acbc-8a1740886252,DISK], DatanodeInfoWithStorage[127.0.0.1:37199,DS-125ff519-6f23-44ea-bb24-9d368d1399e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34671,DS-4fd529d5-7ff6-4230-9d70-f4f0bf13a1c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37305,DS-3f6b2ddb-442b-4891-a8ed-250342d6c7ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45294,DS-fb6dbda2-30be-4d38-ab9b-66f4e5d7c7f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37764,DS-ae4558f9-6f18-4193-a1da-103c43c32a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45541,DS-d2616d84-5db4-451e-a221-af14caba3935,DISK], DatanodeInfoWithStorage[127.0.0.1:45519,DS-bebc4052-0a1b-4b00-b53b-73433c5f2fb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1779681677-172.17.0.14-1597656875940:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44518,DS-8c7c7866-2365-4770-acbc-8a1740886252,DISK], DatanodeInfoWithStorage[127.0.0.1:37199,DS-125ff519-6f23-44ea-bb24-9d368d1399e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34671,DS-4fd529d5-7ff6-4230-9d70-f4f0bf13a1c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37305,DS-3f6b2ddb-442b-4891-a8ed-250342d6c7ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45294,DS-fb6dbda2-30be-4d38-ab9b-66f4e5d7c7f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37764,DS-ae4558f9-6f18-4193-a1da-103c43c32a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45541,DS-d2616d84-5db4-451e-a221-af14caba3935,DISK], DatanodeInfoWithStorage[127.0.0.1:45519,DS-bebc4052-0a1b-4b00-b53b-73433c5f2fb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 4
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-340309883-172.17.0.14-1597657238414:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46813,DS-e9fa6894-6fca-427e-81e3-48af11126bae,DISK], DatanodeInfoWithStorage[127.0.0.1:46464,DS-40b4925b-55cf-44b5-a0a1-71408dd16295,DISK], DatanodeInfoWithStorage[127.0.0.1:39885,DS-494a9db5-a222-43fb-8a96-a1ff41254e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42549,DS-1fda6682-a9ef-40d4-b764-3d66b760bd4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45102,DS-2ea1e559-d09a-4f22-b6ef-e7621a736360,DISK], DatanodeInfoWithStorage[127.0.0.1:40385,DS-cefc383e-1390-4589-8052-dcfe29edee7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38331,DS-e1eaea59-dfb7-474a-989f-fb514b60d3a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43941,DS-1762e467-9751-4440-a647-5b6a5349080c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-340309883-172.17.0.14-1597657238414:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46813,DS-e9fa6894-6fca-427e-81e3-48af11126bae,DISK], DatanodeInfoWithStorage[127.0.0.1:46464,DS-40b4925b-55cf-44b5-a0a1-71408dd16295,DISK], DatanodeInfoWithStorage[127.0.0.1:39885,DS-494a9db5-a222-43fb-8a96-a1ff41254e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42549,DS-1fda6682-a9ef-40d4-b764-3d66b760bd4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45102,DS-2ea1e559-d09a-4f22-b6ef-e7621a736360,DISK], DatanodeInfoWithStorage[127.0.0.1:40385,DS-cefc383e-1390-4589-8052-dcfe29edee7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38331,DS-e1eaea59-dfb7-474a-989f-fb514b60d3a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43941,DS-1762e467-9751-4440-a647-5b6a5349080c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 4
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-293531288-172.17.0.14-1597657264155:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36967,DS-456d62ad-f187-41df-9f86-c53ec4f6bb97,DISK], DatanodeInfoWithStorage[127.0.0.1:39908,DS-88ac4242-0e02-417a-adb3-23e787b2a15d,DISK], DatanodeInfoWithStorage[127.0.0.1:36646,DS-7e29958c-eca6-4ef2-8c41-43cb04cd449c,DISK], DatanodeInfoWithStorage[127.0.0.1:38802,DS-b8c18352-aa38-4b8e-b1a7-ba0716ffa814,DISK], DatanodeInfoWithStorage[127.0.0.1:42451,DS-abcf5d90-0127-4f20-b72b-a7500efc2745,DISK], DatanodeInfoWithStorage[127.0.0.1:37343,DS-dea27323-162f-4337-95b5-aa3e5a557e22,DISK], DatanodeInfoWithStorage[127.0.0.1:35338,DS-6201ea5a-e1c0-48a5-bd53-2aac3cb3da65,DISK], DatanodeInfoWithStorage[127.0.0.1:36480,DS-1f2f997b-924c-464e-a285-fa7d09fa9c8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-293531288-172.17.0.14-1597657264155:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36967,DS-456d62ad-f187-41df-9f86-c53ec4f6bb97,DISK], DatanodeInfoWithStorage[127.0.0.1:39908,DS-88ac4242-0e02-417a-adb3-23e787b2a15d,DISK], DatanodeInfoWithStorage[127.0.0.1:36646,DS-7e29958c-eca6-4ef2-8c41-43cb04cd449c,DISK], DatanodeInfoWithStorage[127.0.0.1:38802,DS-b8c18352-aa38-4b8e-b1a7-ba0716ffa814,DISK], DatanodeInfoWithStorage[127.0.0.1:42451,DS-abcf5d90-0127-4f20-b72b-a7500efc2745,DISK], DatanodeInfoWithStorage[127.0.0.1:37343,DS-dea27323-162f-4337-95b5-aa3e5a557e22,DISK], DatanodeInfoWithStorage[127.0.0.1:35338,DS-6201ea5a-e1c0-48a5-bd53-2aac3cb3da65,DISK], DatanodeInfoWithStorage[127.0.0.1:36480,DS-1f2f997b-924c-464e-a285-fa7d09fa9c8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 4
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-836488918-172.17.0.14-1597657364646:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33671,DS-291f523c-1b8f-4e0b-9dda-13f687f2b1ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42430,DS-f113f031-af96-47bd-9577-e02583747911,DISK], DatanodeInfoWithStorage[127.0.0.1:42574,DS-9ec99dad-5fff-44dc-acd4-2678c29f0420,DISK], DatanodeInfoWithStorage[127.0.0.1:36605,DS-d1dfcf49-f3e9-4fde-80f7-124fddf5b161,DISK], DatanodeInfoWithStorage[127.0.0.1:45847,DS-17aa9f2f-4ce2-407e-a058-f344ff5dcad8,DISK], DatanodeInfoWithStorage[127.0.0.1:43144,DS-eadfb3fd-9267-4c83-b51a-51386c8cefa4,DISK], DatanodeInfoWithStorage[127.0.0.1:44218,DS-ee5d42f1-041e-433a-8907-61aa57de214f,DISK], DatanodeInfoWithStorage[127.0.0.1:41117,DS-2fe5b038-be17-4d31-a18b-b0fa52b41c76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-836488918-172.17.0.14-1597657364646:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33671,DS-291f523c-1b8f-4e0b-9dda-13f687f2b1ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42430,DS-f113f031-af96-47bd-9577-e02583747911,DISK], DatanodeInfoWithStorage[127.0.0.1:42574,DS-9ec99dad-5fff-44dc-acd4-2678c29f0420,DISK], DatanodeInfoWithStorage[127.0.0.1:36605,DS-d1dfcf49-f3e9-4fde-80f7-124fddf5b161,DISK], DatanodeInfoWithStorage[127.0.0.1:45847,DS-17aa9f2f-4ce2-407e-a058-f344ff5dcad8,DISK], DatanodeInfoWithStorage[127.0.0.1:43144,DS-eadfb3fd-9267-4c83-b51a-51386c8cefa4,DISK], DatanodeInfoWithStorage[127.0.0.1:44218,DS-ee5d42f1-041e-433a-8907-61aa57de214f,DISK], DatanodeInfoWithStorage[127.0.0.1:41117,DS-2fe5b038-be17-4d31-a18b-b0fa52b41c76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 4
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-600427570-172.17.0.14-1597657491730:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40547,DS-c4b8ba3b-7332-48a2-8019-5211fca3242f,DISK], DatanodeInfoWithStorage[127.0.0.1:37620,DS-9060792e-e39f-449e-8e9b-0853dea40323,DISK], DatanodeInfoWithStorage[127.0.0.1:42428,DS-0d6c4b36-9e9b-4855-b39f-5bdef3500533,DISK], DatanodeInfoWithStorage[127.0.0.1:34145,DS-c57b7302-b20a-417c-aa11-17eb03895f25,DISK], DatanodeInfoWithStorage[127.0.0.1:39655,DS-e9ebe75f-5571-49d5-996a-79f9a75cf5ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38307,DS-46bc0635-e8cb-496a-a458-f9d1fb0f71f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38811,DS-9ed36d94-5318-4faf-abae-8d5bbc50f9a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46385,DS-3f681db1-22a0-4eb1-8f43-467c46a1c73f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-600427570-172.17.0.14-1597657491730:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40547,DS-c4b8ba3b-7332-48a2-8019-5211fca3242f,DISK], DatanodeInfoWithStorage[127.0.0.1:37620,DS-9060792e-e39f-449e-8e9b-0853dea40323,DISK], DatanodeInfoWithStorage[127.0.0.1:42428,DS-0d6c4b36-9e9b-4855-b39f-5bdef3500533,DISK], DatanodeInfoWithStorage[127.0.0.1:34145,DS-c57b7302-b20a-417c-aa11-17eb03895f25,DISK], DatanodeInfoWithStorage[127.0.0.1:39655,DS-e9ebe75f-5571-49d5-996a-79f9a75cf5ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38307,DS-46bc0635-e8cb-496a-a458-f9d1fb0f71f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38811,DS-9ed36d94-5318-4faf-abae-8d5bbc50f9a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46385,DS-3f681db1-22a0-4eb1-8f43-467c46a1c73f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 4
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-212244353-172.17.0.14-1597657523721:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35808,DS-961ad708-11a4-4ae3-b8cd-7085117e5e45,DISK], DatanodeInfoWithStorage[127.0.0.1:40575,DS-10879947-ca6f-4509-8532-9bdca38f0a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:35023,DS-bf0bf5b4-5006-4c55-8130-697f6c67743e,DISK], DatanodeInfoWithStorage[127.0.0.1:34204,DS-644e12eb-4f34-45e4-aab7-2338486c03b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33137,DS-3292d641-29bf-44a5-9400-bfd9e8aa63f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45700,DS-dbc6b916-14c6-4e07-9f8a-ed4c105d1d05,DISK], DatanodeInfoWithStorage[127.0.0.1:33569,DS-8ff1aa28-90b5-42e4-bd10-ce384f21be22,DISK], DatanodeInfoWithStorage[127.0.0.1:46651,DS-31596942-6009-45c4-b8fc-3c048f5b149e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-212244353-172.17.0.14-1597657523721:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35808,DS-961ad708-11a4-4ae3-b8cd-7085117e5e45,DISK], DatanodeInfoWithStorage[127.0.0.1:40575,DS-10879947-ca6f-4509-8532-9bdca38f0a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:35023,DS-bf0bf5b4-5006-4c55-8130-697f6c67743e,DISK], DatanodeInfoWithStorage[127.0.0.1:34204,DS-644e12eb-4f34-45e4-aab7-2338486c03b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33137,DS-3292d641-29bf-44a5-9400-bfd9e8aa63f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45700,DS-dbc6b916-14c6-4e07-9f8a-ed4c105d1d05,DISK], DatanodeInfoWithStorage[127.0.0.1:33569,DS-8ff1aa28-90b5-42e4-bd10-ce384f21be22,DISK], DatanodeInfoWithStorage[127.0.0.1:46651,DS-31596942-6009-45c4-b8fc-3c048f5b149e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 4
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2106063806-172.17.0.14-1597657698465:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37442,DS-5f1a4bd5-ef91-4b9a-ba62-6fe5d744650b,DISK], DatanodeInfoWithStorage[127.0.0.1:40223,DS-59e6952d-707f-48f4-9a39-a2791fb24480,DISK], DatanodeInfoWithStorage[127.0.0.1:33499,DS-ce931b7d-d571-4658-9843-7af70d541c90,DISK], DatanodeInfoWithStorage[127.0.0.1:41376,DS-9d66c8be-32bf-4c41-a7de-841b515fba03,DISK], DatanodeInfoWithStorage[127.0.0.1:40276,DS-10f08d41-61d4-41a4-b5c9-fd9cdfd2e193,DISK], DatanodeInfoWithStorage[127.0.0.1:35510,DS-ef051c34-9adf-4b09-abaf-6a2a6bfcf938,DISK], DatanodeInfoWithStorage[127.0.0.1:44669,DS-d8bfd37d-2328-41da-bfba-73c429a5bba0,DISK], DatanodeInfoWithStorage[127.0.0.1:42993,DS-baa98956-685c-4a26-a421-5f0729674f2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2106063806-172.17.0.14-1597657698465:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37442,DS-5f1a4bd5-ef91-4b9a-ba62-6fe5d744650b,DISK], DatanodeInfoWithStorage[127.0.0.1:40223,DS-59e6952d-707f-48f4-9a39-a2791fb24480,DISK], DatanodeInfoWithStorage[127.0.0.1:33499,DS-ce931b7d-d571-4658-9843-7af70d541c90,DISK], DatanodeInfoWithStorage[127.0.0.1:41376,DS-9d66c8be-32bf-4c41-a7de-841b515fba03,DISK], DatanodeInfoWithStorage[127.0.0.1:40276,DS-10f08d41-61d4-41a4-b5c9-fd9cdfd2e193,DISK], DatanodeInfoWithStorage[127.0.0.1:35510,DS-ef051c34-9adf-4b09-abaf-6a2a6bfcf938,DISK], DatanodeInfoWithStorage[127.0.0.1:44669,DS-d8bfd37d-2328-41da-bfba-73c429a5bba0,DISK], DatanodeInfoWithStorage[127.0.0.1:42993,DS-baa98956-685c-4a26-a421-5f0729674f2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 4
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2076462277-172.17.0.14-1597657762795:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37404,DS-0c92964d-76ac-4ae5-8ce2-9a1a0539ba86,DISK], DatanodeInfoWithStorage[127.0.0.1:39251,DS-e541fc5c-66ea-4e9a-b004-881a1d66d522,DISK], DatanodeInfoWithStorage[127.0.0.1:39122,DS-81403d86-3c3b-4274-a227-5f211484f910,DISK], DatanodeInfoWithStorage[127.0.0.1:34213,DS-2f79e96f-8306-49d5-a5a9-429dafeebd6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34355,DS-7ad0ecd0-fd9b-4659-8b8d-acb6fe6bf37d,DISK], DatanodeInfoWithStorage[127.0.0.1:45940,DS-214c3bee-9796-481f-9a2b-bb3cd264057e,DISK], DatanodeInfoWithStorage[127.0.0.1:41434,DS-e015cc75-b9fb-408b-b4e3-1b44e8f3e104,DISK], DatanodeInfoWithStorage[127.0.0.1:36188,DS-a8228244-3eb1-42e3-afbc-7d70fa4d83d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2076462277-172.17.0.14-1597657762795:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37404,DS-0c92964d-76ac-4ae5-8ce2-9a1a0539ba86,DISK], DatanodeInfoWithStorage[127.0.0.1:39251,DS-e541fc5c-66ea-4e9a-b004-881a1d66d522,DISK], DatanodeInfoWithStorage[127.0.0.1:39122,DS-81403d86-3c3b-4274-a227-5f211484f910,DISK], DatanodeInfoWithStorage[127.0.0.1:34213,DS-2f79e96f-8306-49d5-a5a9-429dafeebd6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34355,DS-7ad0ecd0-fd9b-4659-8b8d-acb6fe6bf37d,DISK], DatanodeInfoWithStorage[127.0.0.1:45940,DS-214c3bee-9796-481f-9a2b-bb3cd264057e,DISK], DatanodeInfoWithStorage[127.0.0.1:41434,DS-e015cc75-b9fb-408b-b4e3-1b44e8f3e104,DISK], DatanodeInfoWithStorage[127.0.0.1:36188,DS-a8228244-3eb1-42e3-afbc-7d70fa4d83d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 4
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2019620355-172.17.0.14-1597657906715:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38464,DS-08f69a96-2968-46ce-88e0-117cf647ed79,DISK], DatanodeInfoWithStorage[127.0.0.1:37840,DS-f0bfa5eb-a82e-4211-a50e-0df32e8b6bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:43982,DS-64fffcc3-1b7a-4b76-859f-a78b9af94942,DISK], DatanodeInfoWithStorage[127.0.0.1:39577,DS-391c892c-318a-4f96-844a-6dfc20a51085,DISK], DatanodeInfoWithStorage[127.0.0.1:46380,DS-3c1b027e-ee97-4bc5-bf99-7850df64741d,DISK], DatanodeInfoWithStorage[127.0.0.1:42309,DS-eedde472-c754-4977-94a7-1cfca82e7176,DISK], DatanodeInfoWithStorage[127.0.0.1:41712,DS-f8407a38-10fd-472d-a1b2-3c826e5362c4,DISK], DatanodeInfoWithStorage[127.0.0.1:32998,DS-7ab707a1-b86e-40b5-b2e9-51e1017a723f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2019620355-172.17.0.14-1597657906715:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38464,DS-08f69a96-2968-46ce-88e0-117cf647ed79,DISK], DatanodeInfoWithStorage[127.0.0.1:37840,DS-f0bfa5eb-a82e-4211-a50e-0df32e8b6bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:43982,DS-64fffcc3-1b7a-4b76-859f-a78b9af94942,DISK], DatanodeInfoWithStorage[127.0.0.1:39577,DS-391c892c-318a-4f96-844a-6dfc20a51085,DISK], DatanodeInfoWithStorage[127.0.0.1:46380,DS-3c1b027e-ee97-4bc5-bf99-7850df64741d,DISK], DatanodeInfoWithStorage[127.0.0.1:42309,DS-eedde472-c754-4977-94a7-1cfca82e7176,DISK], DatanodeInfoWithStorage[127.0.0.1:41712,DS-f8407a38-10fd-472d-a1b2-3c826e5362c4,DISK], DatanodeInfoWithStorage[127.0.0.1:32998,DS-7ab707a1-b86e-40b5-b2e9-51e1017a723f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 4
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1467087588-172.17.0.14-1597658096214:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39857,DS-cc8e9b8d-0905-4e5d-991e-8120cc6f280b,DISK], DatanodeInfoWithStorage[127.0.0.1:40748,DS-b26ae494-98d9-4bfc-8663-a3a939f9f089,DISK], DatanodeInfoWithStorage[127.0.0.1:42826,DS-7bbc1e10-2153-4cc4-b992-dd2fdf081d64,DISK], DatanodeInfoWithStorage[127.0.0.1:45929,DS-d7db0e44-4ddf-4d6e-8cee-90459d31e73a,DISK], DatanodeInfoWithStorage[127.0.0.1:35821,DS-90e7bbae-a1e6-40df-b0b7-75d9ea36b062,DISK], DatanodeInfoWithStorage[127.0.0.1:34149,DS-c0f0efa6-6167-4439-a1f3-9c30da917ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:33614,DS-6f7f7f46-faad-4b2c-914f-bf8f9325b422,DISK], DatanodeInfoWithStorage[127.0.0.1:37624,DS-8ed05053-a50d-4c3b-ac4f-cf69dbbc4502,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1467087588-172.17.0.14-1597658096214:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39857,DS-cc8e9b8d-0905-4e5d-991e-8120cc6f280b,DISK], DatanodeInfoWithStorage[127.0.0.1:40748,DS-b26ae494-98d9-4bfc-8663-a3a939f9f089,DISK], DatanodeInfoWithStorage[127.0.0.1:42826,DS-7bbc1e10-2153-4cc4-b992-dd2fdf081d64,DISK], DatanodeInfoWithStorage[127.0.0.1:45929,DS-d7db0e44-4ddf-4d6e-8cee-90459d31e73a,DISK], DatanodeInfoWithStorage[127.0.0.1:35821,DS-90e7bbae-a1e6-40df-b0b7-75d9ea36b062,DISK], DatanodeInfoWithStorage[127.0.0.1:34149,DS-c0f0efa6-6167-4439-a1f3-9c30da917ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:33614,DS-6f7f7f46-faad-4b2c-914f-bf8f9325b422,DISK], DatanodeInfoWithStorage[127.0.0.1:37624,DS-8ed05053-a50d-4c3b-ac4f-cf69dbbc4502,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: might be true error
Total execution time in seconds : 5343
