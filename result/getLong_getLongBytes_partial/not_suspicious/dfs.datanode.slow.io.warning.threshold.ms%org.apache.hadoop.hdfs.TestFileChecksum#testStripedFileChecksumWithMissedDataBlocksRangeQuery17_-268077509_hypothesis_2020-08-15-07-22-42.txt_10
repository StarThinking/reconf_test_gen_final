reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1065336536-172.17.0.16-1597476368427:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36754,DS-f8aa6528-195f-45bb-96b6-318d9259256b,DISK], DatanodeInfoWithStorage[127.0.0.1:44571,DS-4f06efeb-5a52-4dfd-9acd-1728cc848073,DISK], DatanodeInfoWithStorage[127.0.0.1:34686,DS-0c393d2a-82db-425e-9b9e-93cef09ced07,DISK], DatanodeInfoWithStorage[127.0.0.1:39830,DS-aba8e268-b27b-45be-a4bc-dcab18f00eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:40673,DS-e1114a6f-b710-4776-a7b0-aaa2ac5a4a79,DISK], DatanodeInfoWithStorage[127.0.0.1:40514,DS-92e3e739-093e-467d-8003-0535ea4ba667,DISK], DatanodeInfoWithStorage[127.0.0.1:44246,DS-d561d07c-d458-4613-bd4d-f5032cb9c1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34988,DS-2e919c33-dc24-41dc-b45f-226dbd9ea59f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1065336536-172.17.0.16-1597476368427:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36754,DS-f8aa6528-195f-45bb-96b6-318d9259256b,DISK], DatanodeInfoWithStorage[127.0.0.1:44571,DS-4f06efeb-5a52-4dfd-9acd-1728cc848073,DISK], DatanodeInfoWithStorage[127.0.0.1:34686,DS-0c393d2a-82db-425e-9b9e-93cef09ced07,DISK], DatanodeInfoWithStorage[127.0.0.1:39830,DS-aba8e268-b27b-45be-a4bc-dcab18f00eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:40673,DS-e1114a6f-b710-4776-a7b0-aaa2ac5a4a79,DISK], DatanodeInfoWithStorage[127.0.0.1:40514,DS-92e3e739-093e-467d-8003-0535ea4ba667,DISK], DatanodeInfoWithStorage[127.0.0.1:44246,DS-d561d07c-d458-4613-bd4d-f5032cb9c1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34988,DS-2e919c33-dc24-41dc-b45f-226dbd9ea59f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1940594291-172.17.0.16-1597476810970:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36676,DS-af777890-0b0c-4d44-b493-15b552803017,DISK], DatanodeInfoWithStorage[127.0.0.1:34687,DS-9295c45d-1fbd-457b-9672-b7735e050ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:38302,DS-31ad29ab-1df5-421f-a028-d70f748478ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43941,DS-1ecce5be-86b9-4ea5-98bf-bd62a4ee3107,DISK], DatanodeInfoWithStorage[127.0.0.1:36628,DS-9940f48d-65ad-4664-85dd-f059ae14771f,DISK], DatanodeInfoWithStorage[127.0.0.1:36146,DS-b6ba3638-1679-439e-bb05-0d70a394c818,DISK], DatanodeInfoWithStorage[127.0.0.1:38129,DS-dc0b6b02-71e1-4a20-a6de-3deca726ef23,DISK], DatanodeInfoWithStorage[127.0.0.1:43194,DS-667c3fe6-2d62-4161-93af-a70e9107821a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1940594291-172.17.0.16-1597476810970:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36676,DS-af777890-0b0c-4d44-b493-15b552803017,DISK], DatanodeInfoWithStorage[127.0.0.1:34687,DS-9295c45d-1fbd-457b-9672-b7735e050ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:38302,DS-31ad29ab-1df5-421f-a028-d70f748478ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43941,DS-1ecce5be-86b9-4ea5-98bf-bd62a4ee3107,DISK], DatanodeInfoWithStorage[127.0.0.1:36628,DS-9940f48d-65ad-4664-85dd-f059ae14771f,DISK], DatanodeInfoWithStorage[127.0.0.1:36146,DS-b6ba3638-1679-439e-bb05-0d70a394c818,DISK], DatanodeInfoWithStorage[127.0.0.1:38129,DS-dc0b6b02-71e1-4a20-a6de-3deca726ef23,DISK], DatanodeInfoWithStorage[127.0.0.1:43194,DS-667c3fe6-2d62-4161-93af-a70e9107821a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2014281258-172.17.0.16-1597477030770:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37734,DS-f929e4c2-9ffa-46c2-bb47-13faac1accc8,DISK], DatanodeInfoWithStorage[127.0.0.1:36333,DS-7ac80be8-99dd-4690-a723-d19af6e1e154,DISK], DatanodeInfoWithStorage[127.0.0.1:43782,DS-38793bf7-267d-4399-b88e-eb2c47a587d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34461,DS-c02e7b42-26c0-43f3-9cd1-da3f03652617,DISK], DatanodeInfoWithStorage[127.0.0.1:45730,DS-ed82fe9f-dad7-488a-bb60-516516a5f60e,DISK], DatanodeInfoWithStorage[127.0.0.1:35549,DS-a0e1a7b3-53bc-441e-a4d6-cc37afbc9425,DISK], DatanodeInfoWithStorage[127.0.0.1:43253,DS-d2f0ac76-3e44-4346-9b67-7a73cd478a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42390,DS-d545a78c-782f-4f6e-99e0-f35e5effdea7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2014281258-172.17.0.16-1597477030770:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37734,DS-f929e4c2-9ffa-46c2-bb47-13faac1accc8,DISK], DatanodeInfoWithStorage[127.0.0.1:36333,DS-7ac80be8-99dd-4690-a723-d19af6e1e154,DISK], DatanodeInfoWithStorage[127.0.0.1:43782,DS-38793bf7-267d-4399-b88e-eb2c47a587d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34461,DS-c02e7b42-26c0-43f3-9cd1-da3f03652617,DISK], DatanodeInfoWithStorage[127.0.0.1:45730,DS-ed82fe9f-dad7-488a-bb60-516516a5f60e,DISK], DatanodeInfoWithStorage[127.0.0.1:35549,DS-a0e1a7b3-53bc-441e-a4d6-cc37afbc9425,DISK], DatanodeInfoWithStorage[127.0.0.1:43253,DS-d2f0ac76-3e44-4346-9b67-7a73cd478a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42390,DS-d545a78c-782f-4f6e-99e0-f35e5effdea7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1629625481-172.17.0.16-1597477172894:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40782,DS-42e025ff-ada7-4668-9df3-4e01e941276c,DISK], DatanodeInfoWithStorage[127.0.0.1:38100,DS-62fe2bad-806b-4e38-8f0b-c5c430418994,DISK], DatanodeInfoWithStorage[127.0.0.1:36849,DS-e6f39fc2-7289-442a-90e2-5246d28bd07a,DISK], DatanodeInfoWithStorage[127.0.0.1:39840,DS-fecd8860-2e90-4a64-a44a-12e341488a84,DISK], DatanodeInfoWithStorage[127.0.0.1:38951,DS-056e7bdd-665e-4a14-9ca5-8d7a5c0de8d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34352,DS-83027ce5-80cb-4463-bf68-0660efb8685a,DISK], DatanodeInfoWithStorage[127.0.0.1:33000,DS-6c64089e-83e4-481f-a33a-ea75d51873a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35704,DS-945bfc41-e9ac-43b2-af08-426837245bc9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1629625481-172.17.0.16-1597477172894:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40782,DS-42e025ff-ada7-4668-9df3-4e01e941276c,DISK], DatanodeInfoWithStorage[127.0.0.1:38100,DS-62fe2bad-806b-4e38-8f0b-c5c430418994,DISK], DatanodeInfoWithStorage[127.0.0.1:36849,DS-e6f39fc2-7289-442a-90e2-5246d28bd07a,DISK], DatanodeInfoWithStorage[127.0.0.1:39840,DS-fecd8860-2e90-4a64-a44a-12e341488a84,DISK], DatanodeInfoWithStorage[127.0.0.1:38951,DS-056e7bdd-665e-4a14-9ca5-8d7a5c0de8d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34352,DS-83027ce5-80cb-4463-bf68-0660efb8685a,DISK], DatanodeInfoWithStorage[127.0.0.1:33000,DS-6c64089e-83e4-481f-a33a-ea75d51873a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35704,DS-945bfc41-e9ac-43b2-af08-426837245bc9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1695953957-172.17.0.16-1597477512765:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42485,DS-ae9d9955-2f73-492a-83da-cf4e1eeac7c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35586,DS-b14084be-e8ea-422a-bfd4-c83c5bbb089e,DISK], DatanodeInfoWithStorage[127.0.0.1:37828,DS-4873d31d-9e51-452a-b821-2aeb45ef978d,DISK], DatanodeInfoWithStorage[127.0.0.1:37813,DS-74a22416-97bc-4ec6-9a7d-f2da1f36918a,DISK], DatanodeInfoWithStorage[127.0.0.1:45167,DS-2a6d83fc-3371-4444-99df-d4a7d69cab72,DISK], DatanodeInfoWithStorage[127.0.0.1:38076,DS-a35f5038-4371-4cfb-8234-5d650838c5b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37135,DS-d912d734-d40e-42e6-8352-d4b15c2ece95,DISK], DatanodeInfoWithStorage[127.0.0.1:37965,DS-a25ceb02-a93c-44b0-82bf-adc7dd2005fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1695953957-172.17.0.16-1597477512765:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42485,DS-ae9d9955-2f73-492a-83da-cf4e1eeac7c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35586,DS-b14084be-e8ea-422a-bfd4-c83c5bbb089e,DISK], DatanodeInfoWithStorage[127.0.0.1:37828,DS-4873d31d-9e51-452a-b821-2aeb45ef978d,DISK], DatanodeInfoWithStorage[127.0.0.1:37813,DS-74a22416-97bc-4ec6-9a7d-f2da1f36918a,DISK], DatanodeInfoWithStorage[127.0.0.1:45167,DS-2a6d83fc-3371-4444-99df-d4a7d69cab72,DISK], DatanodeInfoWithStorage[127.0.0.1:38076,DS-a35f5038-4371-4cfb-8234-5d650838c5b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37135,DS-d912d734-d40e-42e6-8352-d4b15c2ece95,DISK], DatanodeInfoWithStorage[127.0.0.1:37965,DS-a25ceb02-a93c-44b0-82bf-adc7dd2005fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1841732077-172.17.0.16-1597477579639:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35386,DS-131a253a-1255-443e-b048-cbd2b1c0b05e,DISK], DatanodeInfoWithStorage[127.0.0.1:33313,DS-3c7a6723-13b3-4e45-b21f-5b2dd1828a45,DISK], DatanodeInfoWithStorage[127.0.0.1:35665,DS-6cb4b2bb-e57c-4aa4-8f60-675ae55d68eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43733,DS-e9cbb792-79f9-4a8a-a85b-702d103c2796,DISK], DatanodeInfoWithStorage[127.0.0.1:37301,DS-ee3632b2-33a6-4603-bd61-7b1070dcc5d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33575,DS-53a65e9b-6141-4e11-820e-59a12fa1e0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45640,DS-7b671e69-0150-419e-ab48-6ce58016a150,DISK], DatanodeInfoWithStorage[127.0.0.1:44699,DS-ffbd244d-73da-4fad-8e2a-09ed19b9e68c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1841732077-172.17.0.16-1597477579639:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35386,DS-131a253a-1255-443e-b048-cbd2b1c0b05e,DISK], DatanodeInfoWithStorage[127.0.0.1:33313,DS-3c7a6723-13b3-4e45-b21f-5b2dd1828a45,DISK], DatanodeInfoWithStorage[127.0.0.1:35665,DS-6cb4b2bb-e57c-4aa4-8f60-675ae55d68eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43733,DS-e9cbb792-79f9-4a8a-a85b-702d103c2796,DISK], DatanodeInfoWithStorage[127.0.0.1:37301,DS-ee3632b2-33a6-4603-bd61-7b1070dcc5d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33575,DS-53a65e9b-6141-4e11-820e-59a12fa1e0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45640,DS-7b671e69-0150-419e-ab48-6ce58016a150,DISK], DatanodeInfoWithStorage[127.0.0.1:44699,DS-ffbd244d-73da-4fad-8e2a-09ed19b9e68c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1938264128-172.17.0.16-1597477862436:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44180,DS-6d6d072d-4c2c-4509-a90e-4b27f78dd785,DISK], DatanodeInfoWithStorage[127.0.0.1:39911,DS-cdfc595d-71f7-4e9c-9081-d06b93412eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:38525,DS-afb84575-92f6-420c-a1f9-4c685b28d68e,DISK], DatanodeInfoWithStorage[127.0.0.1:38799,DS-f675245a-64ce-4ae1-b6e5-8e1f75ed6cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:46749,DS-2c2b183f-bb40-4a5a-91a7-95fbb87c3b05,DISK], DatanodeInfoWithStorage[127.0.0.1:46269,DS-97b79958-0b51-44ee-ab03-4f5dc119fdca,DISK], DatanodeInfoWithStorage[127.0.0.1:41271,DS-9be7c6f7-1045-413c-92c4-f41326fd967e,DISK], DatanodeInfoWithStorage[127.0.0.1:41798,DS-7a18080f-da76-4ff1-be0f-9f713873c798,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1938264128-172.17.0.16-1597477862436:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44180,DS-6d6d072d-4c2c-4509-a90e-4b27f78dd785,DISK], DatanodeInfoWithStorage[127.0.0.1:39911,DS-cdfc595d-71f7-4e9c-9081-d06b93412eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:38525,DS-afb84575-92f6-420c-a1f9-4c685b28d68e,DISK], DatanodeInfoWithStorage[127.0.0.1:38799,DS-f675245a-64ce-4ae1-b6e5-8e1f75ed6cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:46749,DS-2c2b183f-bb40-4a5a-91a7-95fbb87c3b05,DISK], DatanodeInfoWithStorage[127.0.0.1:46269,DS-97b79958-0b51-44ee-ab03-4f5dc119fdca,DISK], DatanodeInfoWithStorage[127.0.0.1:41271,DS-9be7c6f7-1045-413c-92c4-f41326fd967e,DISK], DatanodeInfoWithStorage[127.0.0.1:41798,DS-7a18080f-da76-4ff1-be0f-9f713873c798,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-386879801-172.17.0.16-1597478014552:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40691,DS-26da4b81-7ddc-4867-99cc-c3e15255c736,DISK], DatanodeInfoWithStorage[127.0.0.1:43239,DS-f611e299-1447-4c7a-aeb5-13f7071c9411,DISK], DatanodeInfoWithStorage[127.0.0.1:36511,DS-4abe337c-da8b-4636-80b8-ec3acf2d8ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:35904,DS-10ed2ab5-ffb1-4187-b4fe-9d54051ed780,DISK], DatanodeInfoWithStorage[127.0.0.1:33247,DS-9dc2ec2e-e4cb-4507-8623-f8eef3f9e673,DISK], DatanodeInfoWithStorage[127.0.0.1:35371,DS-df660435-859a-49b9-8bb6-a3c14622f8b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40061,DS-6bfcad22-22c9-4d8a-a678-95f6a0b0ee99,DISK], DatanodeInfoWithStorage[127.0.0.1:40180,DS-2f8e67ef-980b-476a-89b3-6fb65ea52195,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-386879801-172.17.0.16-1597478014552:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40691,DS-26da4b81-7ddc-4867-99cc-c3e15255c736,DISK], DatanodeInfoWithStorage[127.0.0.1:43239,DS-f611e299-1447-4c7a-aeb5-13f7071c9411,DISK], DatanodeInfoWithStorage[127.0.0.1:36511,DS-4abe337c-da8b-4636-80b8-ec3acf2d8ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:35904,DS-10ed2ab5-ffb1-4187-b4fe-9d54051ed780,DISK], DatanodeInfoWithStorage[127.0.0.1:33247,DS-9dc2ec2e-e4cb-4507-8623-f8eef3f9e673,DISK], DatanodeInfoWithStorage[127.0.0.1:35371,DS-df660435-859a-49b9-8bb6-a3c14622f8b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40061,DS-6bfcad22-22c9-4d8a-a678-95f6a0b0ee99,DISK], DatanodeInfoWithStorage[127.0.0.1:40180,DS-2f8e67ef-980b-476a-89b3-6fb65ea52195,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2054180787-172.17.0.16-1597478324275:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42888,DS-655cf6d0-18cf-4ce0-9e8f-8087e893528d,DISK], DatanodeInfoWithStorage[127.0.0.1:42664,DS-e6393ef8-6f9e-45fc-a74d-42adfacf28dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39218,DS-6bd8a2f6-0cf0-4698-9677-081f31df3fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:36485,DS-8de297cc-50a9-4eef-a96a-b3c080841f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:37514,DS-288b112c-4f3a-4b58-93bf-6f30ca2b0cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:40107,DS-cbcc2b7f-1192-42ae-a159-0c83375137ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37945,DS-d63b8051-9041-4a24-a0e8-755664b34740,DISK], DatanodeInfoWithStorage[127.0.0.1:36146,DS-ee808092-d9e2-4c01-b2e4-e9f3f954f363,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2054180787-172.17.0.16-1597478324275:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42888,DS-655cf6d0-18cf-4ce0-9e8f-8087e893528d,DISK], DatanodeInfoWithStorage[127.0.0.1:42664,DS-e6393ef8-6f9e-45fc-a74d-42adfacf28dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39218,DS-6bd8a2f6-0cf0-4698-9677-081f31df3fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:36485,DS-8de297cc-50a9-4eef-a96a-b3c080841f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:37514,DS-288b112c-4f3a-4b58-93bf-6f30ca2b0cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:40107,DS-cbcc2b7f-1192-42ae-a159-0c83375137ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37945,DS-d63b8051-9041-4a24-a0e8-755664b34740,DISK], DatanodeInfoWithStorage[127.0.0.1:36146,DS-ee808092-d9e2-4c01-b2e4-e9f3f954f363,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1849023649-172.17.0.16-1597478918900:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44337,DS-22fa6ba8-6761-4279-89f7-677e8521fda7,DISK], DatanodeInfoWithStorage[127.0.0.1:46548,DS-fd9b3e37-2adc-401c-a2f4-26a05f337e92,DISK], DatanodeInfoWithStorage[127.0.0.1:46136,DS-d3ea4094-71f3-4c1e-9526-a32d9f79fbc2,DISK], DatanodeInfoWithStorage[127.0.0.1:40556,DS-d15c1b23-9d65-42f2-a60f-9bc660f051a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43916,DS-73d7de86-38a5-42fb-94c1-667e177130b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41146,DS-91593d4f-0218-4e29-b349-13069ed430e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46723,DS-05c667df-77f6-4510-9b04-4728d7ec6ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:33127,DS-4bdb865b-7ac1-4f58-8b69-3794a785e647,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1849023649-172.17.0.16-1597478918900:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44337,DS-22fa6ba8-6761-4279-89f7-677e8521fda7,DISK], DatanodeInfoWithStorage[127.0.0.1:46548,DS-fd9b3e37-2adc-401c-a2f4-26a05f337e92,DISK], DatanodeInfoWithStorage[127.0.0.1:46136,DS-d3ea4094-71f3-4c1e-9526-a32d9f79fbc2,DISK], DatanodeInfoWithStorage[127.0.0.1:40556,DS-d15c1b23-9d65-42f2-a60f-9bc660f051a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43916,DS-73d7de86-38a5-42fb-94c1-667e177130b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41146,DS-91593d4f-0218-4e29-b349-13069ed430e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46723,DS-05c667df-77f6-4510-9b04-4728d7ec6ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:33127,DS-4bdb865b-7ac1-4f58-8b69-3794a785e647,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1785743149-172.17.0.16-1597479248269:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36334,DS-35e2a98b-1edf-4423-a58d-838a439825b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43054,DS-864194b2-5357-418d-8359-5bf4e88abcb7,DISK], DatanodeInfoWithStorage[127.0.0.1:41762,DS-5c6dfc73-bf13-41d9-a0c3-dcd78725673d,DISK], DatanodeInfoWithStorage[127.0.0.1:46655,DS-4ed789d9-1172-4f9b-b449-fae87e9eb589,DISK], DatanodeInfoWithStorage[127.0.0.1:38310,DS-753747e7-2a85-4385-a948-2e8936aebcf8,DISK], DatanodeInfoWithStorage[127.0.0.1:44233,DS-2b573ade-6416-47a1-8362-3f1f8cffae3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42742,DS-6f717487-4cb4-4e95-82e2-07ee2c698ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:36020,DS-d5d3913a-af5c-4b6d-8d54-ce836b4316c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1785743149-172.17.0.16-1597479248269:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36334,DS-35e2a98b-1edf-4423-a58d-838a439825b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43054,DS-864194b2-5357-418d-8359-5bf4e88abcb7,DISK], DatanodeInfoWithStorage[127.0.0.1:41762,DS-5c6dfc73-bf13-41d9-a0c3-dcd78725673d,DISK], DatanodeInfoWithStorage[127.0.0.1:46655,DS-4ed789d9-1172-4f9b-b449-fae87e9eb589,DISK], DatanodeInfoWithStorage[127.0.0.1:38310,DS-753747e7-2a85-4385-a948-2e8936aebcf8,DISK], DatanodeInfoWithStorage[127.0.0.1:44233,DS-2b573ade-6416-47a1-8362-3f1f8cffae3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42742,DS-6f717487-4cb4-4e95-82e2-07ee2c698ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:36020,DS-d5d3913a-af5c-4b6d-8d54-ce836b4316c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1142131740-172.17.0.16-1597479324107:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46378,DS-a7f69a13-9ea1-4e50-be3a-a7931b15809c,DISK], DatanodeInfoWithStorage[127.0.0.1:33294,DS-28ffc27a-9dd1-4791-804f-abf553d110a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40008,DS-7ffe2e11-641c-41df-97d0-9660983c8501,DISK], DatanodeInfoWithStorage[127.0.0.1:33134,DS-26759562-54d1-45db-bcac-4cb4c10808ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42388,DS-65697f72-7b39-4651-9c37-cb4b1a39f526,DISK], DatanodeInfoWithStorage[127.0.0.1:46605,DS-792200d2-bc02-4db3-a217-e3fc38cb4f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:42797,DS-b61874a2-aafc-4b24-98ae-53db2c3f92a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37698,DS-6335dfeb-2d0b-4633-918f-9666f433478c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1142131740-172.17.0.16-1597479324107:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46378,DS-a7f69a13-9ea1-4e50-be3a-a7931b15809c,DISK], DatanodeInfoWithStorage[127.0.0.1:33294,DS-28ffc27a-9dd1-4791-804f-abf553d110a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40008,DS-7ffe2e11-641c-41df-97d0-9660983c8501,DISK], DatanodeInfoWithStorage[127.0.0.1:33134,DS-26759562-54d1-45db-bcac-4cb4c10808ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42388,DS-65697f72-7b39-4651-9c37-cb4b1a39f526,DISK], DatanodeInfoWithStorage[127.0.0.1:46605,DS-792200d2-bc02-4db3-a217-e3fc38cb4f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:42797,DS-b61874a2-aafc-4b24-98ae-53db2c3f92a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37698,DS-6335dfeb-2d0b-4633-918f-9666f433478c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-575838417-172.17.0.16-1597479358308:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42323,DS-d1697e03-7871-40a2-bc34-6282a65bbc6a,DISK], DatanodeInfoWithStorage[127.0.0.1:40167,DS-dc98ed5d-acb7-41db-854d-fbd490b7d2f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35667,DS-314d3ed9-ac34-41d5-a203-616f2ac2d7cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44570,DS-518e02ab-de32-4117-95c0-73604c2dc77c,DISK], DatanodeInfoWithStorage[127.0.0.1:37981,DS-ea4bd988-244a-416e-a3c8-4a341ea2458f,DISK], DatanodeInfoWithStorage[127.0.0.1:38555,DS-5df8cc07-1880-44bc-9df2-3fc4aadf48f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44468,DS-3ebbbe10-daeb-4938-81af-31b03c1f6875,DISK], DatanodeInfoWithStorage[127.0.0.1:33587,DS-fa817d21-5443-4668-a659-3d1711f070dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-575838417-172.17.0.16-1597479358308:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42323,DS-d1697e03-7871-40a2-bc34-6282a65bbc6a,DISK], DatanodeInfoWithStorage[127.0.0.1:40167,DS-dc98ed5d-acb7-41db-854d-fbd490b7d2f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35667,DS-314d3ed9-ac34-41d5-a203-616f2ac2d7cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44570,DS-518e02ab-de32-4117-95c0-73604c2dc77c,DISK], DatanodeInfoWithStorage[127.0.0.1:37981,DS-ea4bd988-244a-416e-a3c8-4a341ea2458f,DISK], DatanodeInfoWithStorage[127.0.0.1:38555,DS-5df8cc07-1880-44bc-9df2-3fc4aadf48f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44468,DS-3ebbbe10-daeb-4938-81af-31b03c1f6875,DISK], DatanodeInfoWithStorage[127.0.0.1:33587,DS-fa817d21-5443-4668-a659-3d1711f070dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1785992928-172.17.0.16-1597479462215:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33740,DS-11f2cd94-b6f2-4df0-a8f3-e1ff63b60fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:33608,DS-9d55113d-5136-4cb6-a0de-2208f681ebf9,DISK], DatanodeInfoWithStorage[127.0.0.1:41488,DS-2b58987f-38b6-434c-8edc-73b1cb681c68,DISK], DatanodeInfoWithStorage[127.0.0.1:46524,DS-327f1288-d085-452d-9035-a55dfde014e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45437,DS-e567a89b-a00d-4f15-b2fd-53140bde7df2,DISK], DatanodeInfoWithStorage[127.0.0.1:43358,DS-65c686f3-9d0a-417e-a445-88f6da6960a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35369,DS-8d4b770b-86d1-43ae-b535-9e65533f4cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:40631,DS-fd8d7b37-a4df-4072-be18-17a57eb3537e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1785992928-172.17.0.16-1597479462215:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33740,DS-11f2cd94-b6f2-4df0-a8f3-e1ff63b60fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:33608,DS-9d55113d-5136-4cb6-a0de-2208f681ebf9,DISK], DatanodeInfoWithStorage[127.0.0.1:41488,DS-2b58987f-38b6-434c-8edc-73b1cb681c68,DISK], DatanodeInfoWithStorage[127.0.0.1:46524,DS-327f1288-d085-452d-9035-a55dfde014e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45437,DS-e567a89b-a00d-4f15-b2fd-53140bde7df2,DISK], DatanodeInfoWithStorage[127.0.0.1:43358,DS-65c686f3-9d0a-417e-a445-88f6da6960a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35369,DS-8d4b770b-86d1-43ae-b535-9e65533f4cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:40631,DS-fd8d7b37-a4df-4072-be18-17a57eb3537e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1136029178-172.17.0.16-1597479860754:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42635,DS-4cd4a65e-9e5d-4245-b715-3b73d76172f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46260,DS-0fcbc666-cdbf-4925-a2f8-bcfc876fa126,DISK], DatanodeInfoWithStorage[127.0.0.1:39259,DS-1730ed54-8062-4df4-b0fb-98bbd4b0e79b,DISK], DatanodeInfoWithStorage[127.0.0.1:40801,DS-380a702f-7d72-474e-a520-75389bd1197c,DISK], DatanodeInfoWithStorage[127.0.0.1:37301,DS-ada7bb49-2719-4bc7-916a-82887f2c2336,DISK], DatanodeInfoWithStorage[127.0.0.1:44192,DS-6e98303d-688b-47ae-8ef7-2962c8c764ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46389,DS-4ea4b7db-dd99-4069-809a-dfdd81ce7b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:37643,DS-dea456d5-ebe3-4059-bb4f-3ffbb9e023af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1136029178-172.17.0.16-1597479860754:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42635,DS-4cd4a65e-9e5d-4245-b715-3b73d76172f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46260,DS-0fcbc666-cdbf-4925-a2f8-bcfc876fa126,DISK], DatanodeInfoWithStorage[127.0.0.1:39259,DS-1730ed54-8062-4df4-b0fb-98bbd4b0e79b,DISK], DatanodeInfoWithStorage[127.0.0.1:40801,DS-380a702f-7d72-474e-a520-75389bd1197c,DISK], DatanodeInfoWithStorage[127.0.0.1:37301,DS-ada7bb49-2719-4bc7-916a-82887f2c2336,DISK], DatanodeInfoWithStorage[127.0.0.1:44192,DS-6e98303d-688b-47ae-8ef7-2962c8c764ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46389,DS-4ea4b7db-dd99-4069-809a-dfdd81ce7b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:37643,DS-dea456d5-ebe3-4059-bb4f-3ffbb9e023af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-282207486-172.17.0.16-1597480049881:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37181,DS-e57eee68-52a0-4934-88c7-706aebda0ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:45160,DS-f7c2ee58-31ab-494c-84b3-20e5b43add76,DISK], DatanodeInfoWithStorage[127.0.0.1:44467,DS-7a65d6ec-6645-4b6b-bbf3-c76ef47de560,DISK], DatanodeInfoWithStorage[127.0.0.1:35944,DS-b26f33b2-8e4e-4935-a8cf-91a79980ad41,DISK], DatanodeInfoWithStorage[127.0.0.1:46251,DS-cacd8032-f9bc-4102-93ca-4bc69c798a89,DISK], DatanodeInfoWithStorage[127.0.0.1:33640,DS-4cca59a0-248e-4e7e-8bdf-e335c7c05687,DISK], DatanodeInfoWithStorage[127.0.0.1:44534,DS-c1cfc6b4-fdd0-488a-8c95-30c563af6979,DISK], DatanodeInfoWithStorage[127.0.0.1:40005,DS-ff54d309-43b6-4fa1-b45e-59b752e50ce3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-282207486-172.17.0.16-1597480049881:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37181,DS-e57eee68-52a0-4934-88c7-706aebda0ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:45160,DS-f7c2ee58-31ab-494c-84b3-20e5b43add76,DISK], DatanodeInfoWithStorage[127.0.0.1:44467,DS-7a65d6ec-6645-4b6b-bbf3-c76ef47de560,DISK], DatanodeInfoWithStorage[127.0.0.1:35944,DS-b26f33b2-8e4e-4935-a8cf-91a79980ad41,DISK], DatanodeInfoWithStorage[127.0.0.1:46251,DS-cacd8032-f9bc-4102-93ca-4bc69c798a89,DISK], DatanodeInfoWithStorage[127.0.0.1:33640,DS-4cca59a0-248e-4e7e-8bdf-e335c7c05687,DISK], DatanodeInfoWithStorage[127.0.0.1:44534,DS-c1cfc6b4-fdd0-488a-8c95-30c563af6979,DISK], DatanodeInfoWithStorage[127.0.0.1:40005,DS-ff54d309-43b6-4fa1-b45e-59b752e50ce3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1303344298-172.17.0.16-1597480162492:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40403,DS-606f77e9-f4e0-45af-9361-21d2161d03fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39314,DS-f5190791-e081-49d8-9d1f-8b29595c9074,DISK], DatanodeInfoWithStorage[127.0.0.1:39699,DS-0df7090c-ce20-4a6f-91cc-3004333c22f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34471,DS-fc184b5f-672e-4b70-9f8d-10be894bc9c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41444,DS-19b0eb72-5433-40da-a173-50880c943772,DISK], DatanodeInfoWithStorage[127.0.0.1:40493,DS-833d5b9f-55b4-46f8-84fc-4b2fedb2e0c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44617,DS-0062ce91-4b8b-4217-ba98-0ae8fd9f02b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42309,DS-63513def-1ed3-4d60-b1bb-8053def0f05c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1303344298-172.17.0.16-1597480162492:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40403,DS-606f77e9-f4e0-45af-9361-21d2161d03fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39314,DS-f5190791-e081-49d8-9d1f-8b29595c9074,DISK], DatanodeInfoWithStorage[127.0.0.1:39699,DS-0df7090c-ce20-4a6f-91cc-3004333c22f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34471,DS-fc184b5f-672e-4b70-9f8d-10be894bc9c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41444,DS-19b0eb72-5433-40da-a173-50880c943772,DISK], DatanodeInfoWithStorage[127.0.0.1:40493,DS-833d5b9f-55b4-46f8-84fc-4b2fedb2e0c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44617,DS-0062ce91-4b8b-4217-ba98-0ae8fd9f02b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42309,DS-63513def-1ed3-4d60-b1bb-8053def0f05c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-595138598-172.17.0.16-1597480262779:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35881,DS-66f20ec0-ab41-4a63-a8ec-5e9a3d712559,DISK], DatanodeInfoWithStorage[127.0.0.1:35944,DS-51f35bdb-9a8c-4b49-afaa-ebd5f2f4017a,DISK], DatanodeInfoWithStorage[127.0.0.1:41202,DS-2efff412-a1fc-4df2-8dce-f653373356ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41211,DS-5d5e4472-cb8e-433f-a41c-7b5b115bebe6,DISK], DatanodeInfoWithStorage[127.0.0.1:35107,DS-bf69f37e-f6f7-4ae3-b2a5-592207201e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:42781,DS-d909b0f6-47a7-4cf0-bfbf-367d437ba472,DISK], DatanodeInfoWithStorage[127.0.0.1:38345,DS-39d6cce1-a866-428b-8e3e-ca47bd952963,DISK], DatanodeInfoWithStorage[127.0.0.1:43075,DS-f6b44d5f-a154-4cba-8e14-0f9e06d4a5e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-595138598-172.17.0.16-1597480262779:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35881,DS-66f20ec0-ab41-4a63-a8ec-5e9a3d712559,DISK], DatanodeInfoWithStorage[127.0.0.1:35944,DS-51f35bdb-9a8c-4b49-afaa-ebd5f2f4017a,DISK], DatanodeInfoWithStorage[127.0.0.1:41202,DS-2efff412-a1fc-4df2-8dce-f653373356ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41211,DS-5d5e4472-cb8e-433f-a41c-7b5b115bebe6,DISK], DatanodeInfoWithStorage[127.0.0.1:35107,DS-bf69f37e-f6f7-4ae3-b2a5-592207201e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:42781,DS-d909b0f6-47a7-4cf0-bfbf-367d437ba472,DISK], DatanodeInfoWithStorage[127.0.0.1:38345,DS-39d6cce1-a866-428b-8e3e-ca47bd952963,DISK], DatanodeInfoWithStorage[127.0.0.1:43075,DS-f6b44d5f-a154-4cba-8e14-0f9e06d4a5e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-621251497-172.17.0.16-1597480703157:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40429,DS-68f6e860-511d-46e4-b690-897712940619,DISK], DatanodeInfoWithStorage[127.0.0.1:37180,DS-df07e434-4d47-4aaa-8397-02acadb96074,DISK], DatanodeInfoWithStorage[127.0.0.1:44405,DS-e72c58ff-644b-4fcf-8a62-ff739a4950b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37928,DS-0336b9d4-fd38-4509-80ca-9cb3ce87d96a,DISK], DatanodeInfoWithStorage[127.0.0.1:36133,DS-8666472d-8f86-43f3-907e-3d9499b1fb5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44918,DS-60b66191-ebcc-4af8-9c6d-4ba9de47af8e,DISK], DatanodeInfoWithStorage[127.0.0.1:32995,DS-8bd7ea87-222f-4786-b4dd-228d2c3a52ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44354,DS-51269ae7-6311-4650-8f4f-e729e0a5e7f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-621251497-172.17.0.16-1597480703157:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40429,DS-68f6e860-511d-46e4-b690-897712940619,DISK], DatanodeInfoWithStorage[127.0.0.1:37180,DS-df07e434-4d47-4aaa-8397-02acadb96074,DISK], DatanodeInfoWithStorage[127.0.0.1:44405,DS-e72c58ff-644b-4fcf-8a62-ff739a4950b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37928,DS-0336b9d4-fd38-4509-80ca-9cb3ce87d96a,DISK], DatanodeInfoWithStorage[127.0.0.1:36133,DS-8666472d-8f86-43f3-907e-3d9499b1fb5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44918,DS-60b66191-ebcc-4af8-9c6d-4ba9de47af8e,DISK], DatanodeInfoWithStorage[127.0.0.1:32995,DS-8bd7ea87-222f-4786-b4dd-228d2c3a52ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44354,DS-51269ae7-6311-4650-8f4f-e729e0a5e7f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-132137767-172.17.0.16-1597480999387:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36960,DS-c8417c32-0b84-430e-bc5c-cd708d851e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40471,DS-08ca169f-c128-4275-8782-85478fc8d5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39955,DS-6008d065-d683-43b1-a7b1-bfce7adf764d,DISK], DatanodeInfoWithStorage[127.0.0.1:39468,DS-eae86a5e-10ae-4f82-b2f5-a6f099456a17,DISK], DatanodeInfoWithStorage[127.0.0.1:40351,DS-67db504f-d82d-4e36-90eb-d570123f4a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:41876,DS-f0be7e28-1d45-4e1c-ae46-2456264fecff,DISK], DatanodeInfoWithStorage[127.0.0.1:34463,DS-5e6397c5-90bc-4405-a184-567680d11092,DISK], DatanodeInfoWithStorage[127.0.0.1:34984,DS-f234b71f-26ed-4b18-a606-73953b0a447b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-132137767-172.17.0.16-1597480999387:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36960,DS-c8417c32-0b84-430e-bc5c-cd708d851e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40471,DS-08ca169f-c128-4275-8782-85478fc8d5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39955,DS-6008d065-d683-43b1-a7b1-bfce7adf764d,DISK], DatanodeInfoWithStorage[127.0.0.1:39468,DS-eae86a5e-10ae-4f82-b2f5-a6f099456a17,DISK], DatanodeInfoWithStorage[127.0.0.1:40351,DS-67db504f-d82d-4e36-90eb-d570123f4a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:41876,DS-f0be7e28-1d45-4e1c-ae46-2456264fecff,DISK], DatanodeInfoWithStorage[127.0.0.1:34463,DS-5e6397c5-90bc-4405-a184-567680d11092,DISK], DatanodeInfoWithStorage[127.0.0.1:34984,DS-f234b71f-26ed-4b18-a606-73953b0a447b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1555032485-172.17.0.16-1597481272642:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39817,DS-21003608-21b1-4256-ad99-e86e11ccfda6,DISK], DatanodeInfoWithStorage[127.0.0.1:36670,DS-e6ec05e9-3d89-4048-91cc-70f01a2ff5f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37263,DS-7be90b0f-6f9d-430c-818b-5c4ac804cd30,DISK], DatanodeInfoWithStorage[127.0.0.1:40414,DS-0077e76c-d61f-428f-a7be-de673074c5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41608,DS-1af6f4fc-9bcd-4e0e-b06d-523bdc6126a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42115,DS-3bff1739-e323-4f28-86a6-afcbac574cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:39418,DS-ebdabcad-9ce4-48f2-b5d9-7993179c5b80,DISK], DatanodeInfoWithStorage[127.0.0.1:36700,DS-465edac9-e39d-48a9-9cd2-c22bea41306b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1555032485-172.17.0.16-1597481272642:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39817,DS-21003608-21b1-4256-ad99-e86e11ccfda6,DISK], DatanodeInfoWithStorage[127.0.0.1:36670,DS-e6ec05e9-3d89-4048-91cc-70f01a2ff5f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37263,DS-7be90b0f-6f9d-430c-818b-5c4ac804cd30,DISK], DatanodeInfoWithStorage[127.0.0.1:40414,DS-0077e76c-d61f-428f-a7be-de673074c5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41608,DS-1af6f4fc-9bcd-4e0e-b06d-523bdc6126a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42115,DS-3bff1739-e323-4f28-86a6-afcbac574cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:39418,DS-ebdabcad-9ce4-48f2-b5d9-7993179c5b80,DISK], DatanodeInfoWithStorage[127.0.0.1:36700,DS-465edac9-e39d-48a9-9cd2-c22bea41306b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5480
