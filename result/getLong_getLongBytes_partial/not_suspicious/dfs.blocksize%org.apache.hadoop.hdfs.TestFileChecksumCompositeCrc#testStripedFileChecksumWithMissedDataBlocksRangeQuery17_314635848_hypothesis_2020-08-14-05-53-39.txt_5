reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 536870912
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 536870912
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1847993941-172.17.0.19-1597384597411:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45829,DS-02f6c0a8-f998-453e-bcc9-3b14f06dd0df,DISK], DatanodeInfoWithStorage[127.0.0.1:35736,DS-b77e2c35-28ea-476c-9c8b-da39ab9aa68c,DISK], DatanodeInfoWithStorage[127.0.0.1:36710,DS-8c70f520-fcc0-4b8e-9c61-6e55604c87cd,DISK], DatanodeInfoWithStorage[127.0.0.1:32889,DS-d172c72f-3eea-4819-962f-48f9210add9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38510,DS-01f22266-ca62-46cb-a0b3-88874cb4bbc7,DISK], DatanodeInfoWithStorage[127.0.0.1:35627,DS-57f071e4-f637-48e3-a98f-b3205aa0f701,DISK], DatanodeInfoWithStorage[127.0.0.1:44017,DS-a1e5c0c5-f0df-480a-94aa-480687acc83a,DISK], DatanodeInfoWithStorage[127.0.0.1:39757,DS-46aa10a6-3f9b-489f-ace2-2860dcb5db2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1847993941-172.17.0.19-1597384597411:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45829,DS-02f6c0a8-f998-453e-bcc9-3b14f06dd0df,DISK], DatanodeInfoWithStorage[127.0.0.1:35736,DS-b77e2c35-28ea-476c-9c8b-da39ab9aa68c,DISK], DatanodeInfoWithStorage[127.0.0.1:36710,DS-8c70f520-fcc0-4b8e-9c61-6e55604c87cd,DISK], DatanodeInfoWithStorage[127.0.0.1:32889,DS-d172c72f-3eea-4819-962f-48f9210add9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38510,DS-01f22266-ca62-46cb-a0b3-88874cb4bbc7,DISK], DatanodeInfoWithStorage[127.0.0.1:35627,DS-57f071e4-f637-48e3-a98f-b3205aa0f701,DISK], DatanodeInfoWithStorage[127.0.0.1:44017,DS-a1e5c0c5-f0df-480a-94aa-480687acc83a,DISK], DatanodeInfoWithStorage[127.0.0.1:39757,DS-46aa10a6-3f9b-489f-ace2-2860dcb5db2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 536870912
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2033604824-172.17.0.19-1597384629309:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40363,DS-4a287fa3-f577-402b-950a-87d7e8a79c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:40558,DS-885f1775-6f0b-4399-8543-2fb633f2b560,DISK], DatanodeInfoWithStorage[127.0.0.1:40981,DS-a8512c3c-a476-4d73-8826-74de14d0687c,DISK], DatanodeInfoWithStorage[127.0.0.1:35917,DS-5e2ad4fa-c5f5-4809-a04a-7033e0f753ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40963,DS-60c09d4d-5c4c-4250-bf75-67316eb54950,DISK], DatanodeInfoWithStorage[127.0.0.1:34051,DS-ceefa042-b947-416f-9ec7-ff081468caec,DISK], DatanodeInfoWithStorage[127.0.0.1:39165,DS-69be9fd2-63ff-4dee-96c0-a2b6fcf29197,DISK], DatanodeInfoWithStorage[127.0.0.1:33825,DS-7d962374-dffa-44d3-8cc9-6f0cb20c64ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2033604824-172.17.0.19-1597384629309:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40363,DS-4a287fa3-f577-402b-950a-87d7e8a79c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:40558,DS-885f1775-6f0b-4399-8543-2fb633f2b560,DISK], DatanodeInfoWithStorage[127.0.0.1:40981,DS-a8512c3c-a476-4d73-8826-74de14d0687c,DISK], DatanodeInfoWithStorage[127.0.0.1:35917,DS-5e2ad4fa-c5f5-4809-a04a-7033e0f753ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40963,DS-60c09d4d-5c4c-4250-bf75-67316eb54950,DISK], DatanodeInfoWithStorage[127.0.0.1:34051,DS-ceefa042-b947-416f-9ec7-ff081468caec,DISK], DatanodeInfoWithStorage[127.0.0.1:39165,DS-69be9fd2-63ff-4dee-96c0-a2b6fcf29197,DISK], DatanodeInfoWithStorage[127.0.0.1:33825,DS-7d962374-dffa-44d3-8cc9-6f0cb20c64ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 536870912
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-999069164-172.17.0.19-1597385151627:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40637,DS-868201bb-8b3b-494e-bd62-ff67fe6de812,DISK], DatanodeInfoWithStorage[127.0.0.1:44628,DS-3f4cd49d-b975-44be-b82a-4c8b88b9924a,DISK], DatanodeInfoWithStorage[127.0.0.1:43543,DS-6b8e4e00-ea02-4e58-82b1-d588a8be1012,DISK], DatanodeInfoWithStorage[127.0.0.1:39980,DS-3b6bae3c-32b8-498e-b821-b63789394eec,DISK], DatanodeInfoWithStorage[127.0.0.1:40742,DS-230a7935-234a-4944-922b-5edb26a508fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36081,DS-f43eb43e-2541-4e46-9bec-9d39d845ab58,DISK], DatanodeInfoWithStorage[127.0.0.1:38346,DS-151d027e-f8bd-42bb-8273-de32e28d4249,DISK], DatanodeInfoWithStorage[127.0.0.1:36030,DS-8ee54926-0d22-4687-b1e8-83ee7f27c8dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-999069164-172.17.0.19-1597385151627:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40637,DS-868201bb-8b3b-494e-bd62-ff67fe6de812,DISK], DatanodeInfoWithStorage[127.0.0.1:44628,DS-3f4cd49d-b975-44be-b82a-4c8b88b9924a,DISK], DatanodeInfoWithStorage[127.0.0.1:43543,DS-6b8e4e00-ea02-4e58-82b1-d588a8be1012,DISK], DatanodeInfoWithStorage[127.0.0.1:39980,DS-3b6bae3c-32b8-498e-b821-b63789394eec,DISK], DatanodeInfoWithStorage[127.0.0.1:40742,DS-230a7935-234a-4944-922b-5edb26a508fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36081,DS-f43eb43e-2541-4e46-9bec-9d39d845ab58,DISK], DatanodeInfoWithStorage[127.0.0.1:38346,DS-151d027e-f8bd-42bb-8273-de32e28d4249,DISK], DatanodeInfoWithStorage[127.0.0.1:36030,DS-8ee54926-0d22-4687-b1e8-83ee7f27c8dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 536870912
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-564039087-172.17.0.19-1597385799812:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37336,DS-541cbc82-d289-4ab5-b54c-40aa96b51026,DISK], DatanodeInfoWithStorage[127.0.0.1:46812,DS-f3c56ea2-4fda-49b0-b04a-d202bb0f5009,DISK], DatanodeInfoWithStorage[127.0.0.1:46675,DS-0d753344-3985-485c-8bc9-78af9e4480bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35024,DS-f6f9a2a4-c133-4bed-bd45-dae48611b7a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38996,DS-f4afbbf2-4a6f-4790-887b-a0d0071daedc,DISK], DatanodeInfoWithStorage[127.0.0.1:39972,DS-9bfd264a-8d79-471c-8d66-3873ed6a3f83,DISK], DatanodeInfoWithStorage[127.0.0.1:39069,DS-33523ed8-9e5f-4879-9728-5cf60de282a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35201,DS-1fd0959e-62c4-4c8e-9e82-2d750df1a40f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-564039087-172.17.0.19-1597385799812:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37336,DS-541cbc82-d289-4ab5-b54c-40aa96b51026,DISK], DatanodeInfoWithStorage[127.0.0.1:46812,DS-f3c56ea2-4fda-49b0-b04a-d202bb0f5009,DISK], DatanodeInfoWithStorage[127.0.0.1:46675,DS-0d753344-3985-485c-8bc9-78af9e4480bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35024,DS-f6f9a2a4-c133-4bed-bd45-dae48611b7a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38996,DS-f4afbbf2-4a6f-4790-887b-a0d0071daedc,DISK], DatanodeInfoWithStorage[127.0.0.1:39972,DS-9bfd264a-8d79-471c-8d66-3873ed6a3f83,DISK], DatanodeInfoWithStorage[127.0.0.1:39069,DS-33523ed8-9e5f-4879-9728-5cf60de282a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35201,DS-1fd0959e-62c4-4c8e-9e82-2d750df1a40f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 536870912
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2061596070-172.17.0.19-1597386365801:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36161,DS-9dff782d-7c13-42a0-969d-ded77bf78ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:40431,DS-b8c027b8-a70a-4678-9ca3-aa96532656a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40206,DS-30402954-8bac-4141-b307-fc827ad85ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:44966,DS-443f0ec7-a34c-471d-a286-46f74bd48dae,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-14b1fef4-81e2-4dab-9c6c-0643ea484aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:35196,DS-43416b94-d24f-4691-b4ff-25e439516dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:38365,DS-289e46f4-c480-4be9-99cd-632f109604f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45905,DS-0091a03b-e53e-42fc-a4ad-cfd63a17b9ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2061596070-172.17.0.19-1597386365801:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36161,DS-9dff782d-7c13-42a0-969d-ded77bf78ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:40431,DS-b8c027b8-a70a-4678-9ca3-aa96532656a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40206,DS-30402954-8bac-4141-b307-fc827ad85ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:44966,DS-443f0ec7-a34c-471d-a286-46f74bd48dae,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-14b1fef4-81e2-4dab-9c6c-0643ea484aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:35196,DS-43416b94-d24f-4691-b4ff-25e439516dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:38365,DS-289e46f4-c480-4be9-99cd-632f109604f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45905,DS-0091a03b-e53e-42fc-a4ad-cfd63a17b9ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 536870912
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-571774278-172.17.0.19-1597387880182:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33780,DS-0b519aff-70f1-45ee-879d-c09e2cab6cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:44552,DS-eb4db738-a0d4-4c54-81ef-e5fbc36b627d,DISK], DatanodeInfoWithStorage[127.0.0.1:35706,DS-5d7d2416-4dd9-4894-87e2-e2e16c380bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:40528,DS-0c1e4c84-8419-467f-9c22-f291a2005ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:38791,DS-ecefa1b7-4a2c-447d-bf48-6d514cdabdb5,DISK], DatanodeInfoWithStorage[127.0.0.1:37893,DS-945ce583-58ee-4aec-bc6b-6de67808caf9,DISK], DatanodeInfoWithStorage[127.0.0.1:39793,DS-67629675-7618-4fad-966b-27872b5eb690,DISK], DatanodeInfoWithStorage[127.0.0.1:33589,DS-b60c17a9-4868-44ec-a6bb-786acce5c1e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-571774278-172.17.0.19-1597387880182:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33780,DS-0b519aff-70f1-45ee-879d-c09e2cab6cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:44552,DS-eb4db738-a0d4-4c54-81ef-e5fbc36b627d,DISK], DatanodeInfoWithStorage[127.0.0.1:35706,DS-5d7d2416-4dd9-4894-87e2-e2e16c380bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:40528,DS-0c1e4c84-8419-467f-9c22-f291a2005ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:38791,DS-ecefa1b7-4a2c-447d-bf48-6d514cdabdb5,DISK], DatanodeInfoWithStorage[127.0.0.1:37893,DS-945ce583-58ee-4aec-bc6b-6de67808caf9,DISK], DatanodeInfoWithStorage[127.0.0.1:39793,DS-67629675-7618-4fad-966b-27872b5eb690,DISK], DatanodeInfoWithStorage[127.0.0.1:33589,DS-b60c17a9-4868-44ec-a6bb-786acce5c1e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 536870912
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-107666271-172.17.0.19-1597388170698:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40228,DS-d1d7491a-f3c8-48a9-a75c-bd19ad747933,DISK], DatanodeInfoWithStorage[127.0.0.1:40107,DS-77efe545-7771-4189-9a9a-89a009cf1c71,DISK], DatanodeInfoWithStorage[127.0.0.1:46606,DS-772f98d1-de8b-48ed-8cd8-c500b1456c34,DISK], DatanodeInfoWithStorage[127.0.0.1:38491,DS-c4d22605-6c3e-49b3-955e-0316a44bbc30,DISK], DatanodeInfoWithStorage[127.0.0.1:43386,DS-fefca7ab-ef98-4f0d-ad6b-a668b6cfbf16,DISK], DatanodeInfoWithStorage[127.0.0.1:45862,DS-54a7209b-3dcd-4372-b2af-6d4b9f0475d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43516,DS-c8aa2048-310d-45aa-bb84-1be663899cca,DISK], DatanodeInfoWithStorage[127.0.0.1:33731,DS-f58aa395-ca7b-474f-9c6f-9df80fc654a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-107666271-172.17.0.19-1597388170698:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40228,DS-d1d7491a-f3c8-48a9-a75c-bd19ad747933,DISK], DatanodeInfoWithStorage[127.0.0.1:40107,DS-77efe545-7771-4189-9a9a-89a009cf1c71,DISK], DatanodeInfoWithStorage[127.0.0.1:46606,DS-772f98d1-de8b-48ed-8cd8-c500b1456c34,DISK], DatanodeInfoWithStorage[127.0.0.1:38491,DS-c4d22605-6c3e-49b3-955e-0316a44bbc30,DISK], DatanodeInfoWithStorage[127.0.0.1:43386,DS-fefca7ab-ef98-4f0d-ad6b-a668b6cfbf16,DISK], DatanodeInfoWithStorage[127.0.0.1:45862,DS-54a7209b-3dcd-4372-b2af-6d4b9f0475d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43516,DS-c8aa2048-310d-45aa-bb84-1be663899cca,DISK], DatanodeInfoWithStorage[127.0.0.1:33731,DS-f58aa395-ca7b-474f-9c6f-9df80fc654a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 536870912
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-334245194-172.17.0.19-1597388309348:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40353,DS-db0d591b-05d7-4ab5-aef9-6232abc61a41,DISK], DatanodeInfoWithStorage[127.0.0.1:42459,DS-e4160aad-bd46-4407-93b0-170b5850ee8d,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-386bd8a8-f3b7-437f-8c1b-78ad7b591035,DISK], DatanodeInfoWithStorage[127.0.0.1:39123,DS-06a69fa8-6011-4697-9ebe-808b53f10a18,DISK], DatanodeInfoWithStorage[127.0.0.1:46347,DS-4ef172dc-9247-4966-b904-d1e621025980,DISK], DatanodeInfoWithStorage[127.0.0.1:46825,DS-cf1a4e77-dbaa-422d-8bf6-33a824ff58f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37889,DS-2c948c08-101e-44bf-bf39-6d7f035597e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33762,DS-0ad59e4a-6cd3-4a6c-ad79-30cbf057393d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-334245194-172.17.0.19-1597388309348:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40353,DS-db0d591b-05d7-4ab5-aef9-6232abc61a41,DISK], DatanodeInfoWithStorage[127.0.0.1:42459,DS-e4160aad-bd46-4407-93b0-170b5850ee8d,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-386bd8a8-f3b7-437f-8c1b-78ad7b591035,DISK], DatanodeInfoWithStorage[127.0.0.1:39123,DS-06a69fa8-6011-4697-9ebe-808b53f10a18,DISK], DatanodeInfoWithStorage[127.0.0.1:46347,DS-4ef172dc-9247-4966-b904-d1e621025980,DISK], DatanodeInfoWithStorage[127.0.0.1:46825,DS-cf1a4e77-dbaa-422d-8bf6-33a824ff58f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37889,DS-2c948c08-101e-44bf-bf39-6d7f035597e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33762,DS-0ad59e4a-6cd3-4a6c-ad79-30cbf057393d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 536870912
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-351196853-172.17.0.19-1597388520207:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43584,DS-8b24c6dc-bd46-4d76-8890-c45edbddb31f,DISK], DatanodeInfoWithStorage[127.0.0.1:41067,DS-ef00f12a-abe9-4ba7-bf39-c72d20750d56,DISK], DatanodeInfoWithStorage[127.0.0.1:46340,DS-c60f459d-9646-4c47-af19-6d04ff1d7c92,DISK], DatanodeInfoWithStorage[127.0.0.1:32891,DS-aaa7d949-233e-4c47-81f0-aa151c72032b,DISK], DatanodeInfoWithStorage[127.0.0.1:34567,DS-666410e2-bbf2-4c41-9abf-c1b1cd443f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:38590,DS-8470efb8-d5cf-4a18-9b9d-e7478415ecad,DISK], DatanodeInfoWithStorage[127.0.0.1:43499,DS-1c59a045-0ce1-495f-9576-00784b4daa24,DISK], DatanodeInfoWithStorage[127.0.0.1:46235,DS-97584358-6025-4f08-8707-9571432ffa24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-351196853-172.17.0.19-1597388520207:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43584,DS-8b24c6dc-bd46-4d76-8890-c45edbddb31f,DISK], DatanodeInfoWithStorage[127.0.0.1:41067,DS-ef00f12a-abe9-4ba7-bf39-c72d20750d56,DISK], DatanodeInfoWithStorage[127.0.0.1:46340,DS-c60f459d-9646-4c47-af19-6d04ff1d7c92,DISK], DatanodeInfoWithStorage[127.0.0.1:32891,DS-aaa7d949-233e-4c47-81f0-aa151c72032b,DISK], DatanodeInfoWithStorage[127.0.0.1:34567,DS-666410e2-bbf2-4c41-9abf-c1b1cd443f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:38590,DS-8470efb8-d5cf-4a18-9b9d-e7478415ecad,DISK], DatanodeInfoWithStorage[127.0.0.1:43499,DS-1c59a045-0ce1-495f-9576-00784b4daa24,DISK], DatanodeInfoWithStorage[127.0.0.1:46235,DS-97584358-6025-4f08-8707-9571432ffa24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 536870912
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-719671088-172.17.0.19-1597388591897:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37520,DS-4b91685a-f70f-476a-a753-6a896644bd82,DISK], DatanodeInfoWithStorage[127.0.0.1:41150,DS-8577daec-016d-4a98-a17f-2c585a12180d,DISK], DatanodeInfoWithStorage[127.0.0.1:33954,DS-db6e4bd3-43f5-422a-8786-58d77ba4f6e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43441,DS-04b5f2ba-cfd2-4358-8ae0-369bec981ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:45054,DS-23828709-da7a-433e-9593-fc683607e618,DISK], DatanodeInfoWithStorage[127.0.0.1:36191,DS-d6e27745-77b6-4c24-b029-f2297619d753,DISK], DatanodeInfoWithStorage[127.0.0.1:44344,DS-48b13f4d-617d-4e72-a931-0911bbd38e98,DISK], DatanodeInfoWithStorage[127.0.0.1:38534,DS-7ff40dd6-3153-497f-b03e-738b54dc3165,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-719671088-172.17.0.19-1597388591897:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37520,DS-4b91685a-f70f-476a-a753-6a896644bd82,DISK], DatanodeInfoWithStorage[127.0.0.1:41150,DS-8577daec-016d-4a98-a17f-2c585a12180d,DISK], DatanodeInfoWithStorage[127.0.0.1:33954,DS-db6e4bd3-43f5-422a-8786-58d77ba4f6e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43441,DS-04b5f2ba-cfd2-4358-8ae0-369bec981ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:45054,DS-23828709-da7a-433e-9593-fc683607e618,DISK], DatanodeInfoWithStorage[127.0.0.1:36191,DS-d6e27745-77b6-4c24-b029-f2297619d753,DISK], DatanodeInfoWithStorage[127.0.0.1:44344,DS-48b13f4d-617d-4e72-a931-0911bbd38e98,DISK], DatanodeInfoWithStorage[127.0.0.1:38534,DS-7ff40dd6-3153-497f-b03e-738b54dc3165,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 536870912
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-642492551-172.17.0.19-1597388922841:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40898,DS-41e40bde-ef4c-4036-9bb6-001c887c7d05,DISK], DatanodeInfoWithStorage[127.0.0.1:46484,DS-8c8a50c1-0e3e-40c3-9551-6fa63ee9f2bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39898,DS-c9fb6f8b-afd2-4bec-b584-57ad81e82f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36048,DS-d68aa0cc-13e8-4381-954a-856bf5e9f6d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37523,DS-4bf1c56e-935a-4655-9068-65b64845a15c,DISK], DatanodeInfoWithStorage[127.0.0.1:32828,DS-34e51cb6-96ae-44bd-a6d4-44e2c2505708,DISK], DatanodeInfoWithStorage[127.0.0.1:38030,DS-b5956d74-6e53-42c4-bd7f-e7d0cb99d390,DISK], DatanodeInfoWithStorage[127.0.0.1:38504,DS-8d7aadca-4de3-4eab-baca-60f2df1e026d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-642492551-172.17.0.19-1597388922841:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40898,DS-41e40bde-ef4c-4036-9bb6-001c887c7d05,DISK], DatanodeInfoWithStorage[127.0.0.1:46484,DS-8c8a50c1-0e3e-40c3-9551-6fa63ee9f2bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39898,DS-c9fb6f8b-afd2-4bec-b584-57ad81e82f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36048,DS-d68aa0cc-13e8-4381-954a-856bf5e9f6d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37523,DS-4bf1c56e-935a-4655-9068-65b64845a15c,DISK], DatanodeInfoWithStorage[127.0.0.1:32828,DS-34e51cb6-96ae-44bd-a6d4-44e2c2505708,DISK], DatanodeInfoWithStorage[127.0.0.1:38030,DS-b5956d74-6e53-42c4-bd7f-e7d0cb99d390,DISK], DatanodeInfoWithStorage[127.0.0.1:38504,DS-8d7aadca-4de3-4eab-baca-60f2df1e026d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 536870912
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-598548531-172.17.0.19-1597389060876:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41601,DS-b721ef4c-580a-44c2-beaa-4e9531baa95c,DISK], DatanodeInfoWithStorage[127.0.0.1:45711,DS-f03a2c36-0e53-45dd-8c6d-50bb857e1e69,DISK], DatanodeInfoWithStorage[127.0.0.1:42806,DS-ded9cac8-c43d-4b4a-9e7f-6dcaacbaf51c,DISK], DatanodeInfoWithStorage[127.0.0.1:33217,DS-2762b115-101e-411d-8724-920338e5d7be,DISK], DatanodeInfoWithStorage[127.0.0.1:41877,DS-7b82f877-bbe4-4926-acf0-b7bfd8502e15,DISK], DatanodeInfoWithStorage[127.0.0.1:42396,DS-52d7ec0d-15db-45ac-b8f6-6b6df76484af,DISK], DatanodeInfoWithStorage[127.0.0.1:45821,DS-f2c14a5f-954e-4da1-8a8e-53408b0f32e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36147,DS-d04a4e97-b7b9-4ef2-b754-5503d16fd6ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-598548531-172.17.0.19-1597389060876:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41601,DS-b721ef4c-580a-44c2-beaa-4e9531baa95c,DISK], DatanodeInfoWithStorage[127.0.0.1:45711,DS-f03a2c36-0e53-45dd-8c6d-50bb857e1e69,DISK], DatanodeInfoWithStorage[127.0.0.1:42806,DS-ded9cac8-c43d-4b4a-9e7f-6dcaacbaf51c,DISK], DatanodeInfoWithStorage[127.0.0.1:33217,DS-2762b115-101e-411d-8724-920338e5d7be,DISK], DatanodeInfoWithStorage[127.0.0.1:41877,DS-7b82f877-bbe4-4926-acf0-b7bfd8502e15,DISK], DatanodeInfoWithStorage[127.0.0.1:42396,DS-52d7ec0d-15db-45ac-b8f6-6b6df76484af,DISK], DatanodeInfoWithStorage[127.0.0.1:45821,DS-f2c14a5f-954e-4da1-8a8e-53408b0f32e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36147,DS-d04a4e97-b7b9-4ef2-b754-5503d16fd6ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 536870912
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-970175342-172.17.0.19-1597389383751:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45458,DS-b7e7f1c5-1e17-4887-bc00-e044d5131c14,DISK], DatanodeInfoWithStorage[127.0.0.1:46526,DS-36cedc86-1fb7-480c-aafd-07122655eba7,DISK], DatanodeInfoWithStorage[127.0.0.1:36694,DS-682addb0-efd3-43ac-b638-b02c413be690,DISK], DatanodeInfoWithStorage[127.0.0.1:42666,DS-fb49feb3-3927-438b-95ad-921a7dc14063,DISK], DatanodeInfoWithStorage[127.0.0.1:37859,DS-5b2ae334-e618-432d-b9ca-47c4a626e734,DISK], DatanodeInfoWithStorage[127.0.0.1:36690,DS-77217dfb-9028-4778-908a-0fec6350101f,DISK], DatanodeInfoWithStorage[127.0.0.1:43203,DS-66c6ebfc-42df-4309-8c05-5fd73f3e8364,DISK], DatanodeInfoWithStorage[127.0.0.1:39045,DS-496a47df-26a5-4d0f-be86-c51f12f5a343,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-970175342-172.17.0.19-1597389383751:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45458,DS-b7e7f1c5-1e17-4887-bc00-e044d5131c14,DISK], DatanodeInfoWithStorage[127.0.0.1:46526,DS-36cedc86-1fb7-480c-aafd-07122655eba7,DISK], DatanodeInfoWithStorage[127.0.0.1:36694,DS-682addb0-efd3-43ac-b638-b02c413be690,DISK], DatanodeInfoWithStorage[127.0.0.1:42666,DS-fb49feb3-3927-438b-95ad-921a7dc14063,DISK], DatanodeInfoWithStorage[127.0.0.1:37859,DS-5b2ae334-e618-432d-b9ca-47c4a626e734,DISK], DatanodeInfoWithStorage[127.0.0.1:36690,DS-77217dfb-9028-4778-908a-0fec6350101f,DISK], DatanodeInfoWithStorage[127.0.0.1:43203,DS-66c6ebfc-42df-4309-8c05-5fd73f3e8364,DISK], DatanodeInfoWithStorage[127.0.0.1:39045,DS-496a47df-26a5-4d0f-be86-c51f12f5a343,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5478
