reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 18
v2: 1800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 18
v2: 1800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1546722577-172.17.0.17-1597467418335:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39650,DS-9d0a3828-13c3-41d8-a659-f8d2af533bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:45861,DS-a177cf33-a221-4bfc-a38e-66245d23f30c,DISK], DatanodeInfoWithStorage[127.0.0.1:41741,DS-3ccee260-1727-4ccc-9d26-0c239fe521dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33907,DS-e5b48d54-a74f-4325-b50d-98a0f7e04e00,DISK], DatanodeInfoWithStorage[127.0.0.1:36454,DS-4ebfd8c5-466a-4ace-947b-8774b28df2b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39959,DS-57327da3-7d7a-4042-a742-f57eee9ffd79,DISK], DatanodeInfoWithStorage[127.0.0.1:35163,DS-286b39d4-1806-444d-82d0-a92766a54375,DISK], DatanodeInfoWithStorage[127.0.0.1:40953,DS-565bf579-d666-47fa-bd88-1fe28584005a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1546722577-172.17.0.17-1597467418335:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39650,DS-9d0a3828-13c3-41d8-a659-f8d2af533bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:45861,DS-a177cf33-a221-4bfc-a38e-66245d23f30c,DISK], DatanodeInfoWithStorage[127.0.0.1:41741,DS-3ccee260-1727-4ccc-9d26-0c239fe521dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33907,DS-e5b48d54-a74f-4325-b50d-98a0f7e04e00,DISK], DatanodeInfoWithStorage[127.0.0.1:36454,DS-4ebfd8c5-466a-4ace-947b-8774b28df2b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39959,DS-57327da3-7d7a-4042-a742-f57eee9ffd79,DISK], DatanodeInfoWithStorage[127.0.0.1:35163,DS-286b39d4-1806-444d-82d0-a92766a54375,DISK], DatanodeInfoWithStorage[127.0.0.1:40953,DS-565bf579-d666-47fa-bd88-1fe28584005a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 18
v2: 1800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1842319363-172.17.0.17-1597467807379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37029,DS-b43a17f9-2106-4f23-9251-043248dfff5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39177,DS-6f6fb095-ae04-4622-86ef-e7c9860884ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35053,DS-81821b3b-b976-41e3-9f28-f50190db5e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:38579,DS-eb6d0d74-b9d5-4e82-886a-036f031f7ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:41548,DS-293084b5-402f-40ab-af8a-b8b3373839e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34151,DS-bf99c9ee-179c-403a-92c3-b191af9ba7a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-e4610598-1438-44ef-9781-c9e66b5287ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34007,DS-1c103f00-8660-4d5c-b4f5-8cc2d94dc60a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1842319363-172.17.0.17-1597467807379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37029,DS-b43a17f9-2106-4f23-9251-043248dfff5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39177,DS-6f6fb095-ae04-4622-86ef-e7c9860884ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35053,DS-81821b3b-b976-41e3-9f28-f50190db5e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:38579,DS-eb6d0d74-b9d5-4e82-886a-036f031f7ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:41548,DS-293084b5-402f-40ab-af8a-b8b3373839e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34151,DS-bf99c9ee-179c-403a-92c3-b191af9ba7a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-e4610598-1438-44ef-9781-c9e66b5287ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34007,DS-1c103f00-8660-4d5c-b4f5-8cc2d94dc60a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 18
v2: 1800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2088998627-172.17.0.17-1597468316849:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38938,DS-2fa811ea-ca70-43c7-9ea6-d8b79e7decb1,DISK], DatanodeInfoWithStorage[127.0.0.1:36525,DS-84abe149-9835-45a8-b01e-865f5d555b31,DISK], DatanodeInfoWithStorage[127.0.0.1:40982,DS-18c742bc-82b1-4bec-b6c0-4544bbfe425e,DISK], DatanodeInfoWithStorage[127.0.0.1:46112,DS-cb71b61e-076e-4eba-ab2b-353b872a3f13,DISK], DatanodeInfoWithStorage[127.0.0.1:45803,DS-4bcbf066-f057-4fb4-9340-5926f54af093,DISK], DatanodeInfoWithStorage[127.0.0.1:46321,DS-3b219638-c77f-4b78-a7ba-8103a5d8181d,DISK], DatanodeInfoWithStorage[127.0.0.1:39025,DS-bb072bed-1f76-4050-8489-54546d38f52f,DISK], DatanodeInfoWithStorage[127.0.0.1:34408,DS-43a9bafe-b716-456e-99a0-0257002f73db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2088998627-172.17.0.17-1597468316849:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38938,DS-2fa811ea-ca70-43c7-9ea6-d8b79e7decb1,DISK], DatanodeInfoWithStorage[127.0.0.1:36525,DS-84abe149-9835-45a8-b01e-865f5d555b31,DISK], DatanodeInfoWithStorage[127.0.0.1:40982,DS-18c742bc-82b1-4bec-b6c0-4544bbfe425e,DISK], DatanodeInfoWithStorage[127.0.0.1:46112,DS-cb71b61e-076e-4eba-ab2b-353b872a3f13,DISK], DatanodeInfoWithStorage[127.0.0.1:45803,DS-4bcbf066-f057-4fb4-9340-5926f54af093,DISK], DatanodeInfoWithStorage[127.0.0.1:46321,DS-3b219638-c77f-4b78-a7ba-8103a5d8181d,DISK], DatanodeInfoWithStorage[127.0.0.1:39025,DS-bb072bed-1f76-4050-8489-54546d38f52f,DISK], DatanodeInfoWithStorage[127.0.0.1:34408,DS-43a9bafe-b716-456e-99a0-0257002f73db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 18
v2: 1800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1267371623-172.17.0.17-1597468655303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46860,DS-06bcbe32-d402-461e-9422-8cf6ff42e263,DISK], DatanodeInfoWithStorage[127.0.0.1:44433,DS-c1d8eeef-cb86-45c4-91d1-853656d5ef94,DISK], DatanodeInfoWithStorage[127.0.0.1:46756,DS-957cedad-637d-4f96-aa56-3ff78d9f7d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:40433,DS-33329a4f-0e9a-442f-87e1-3abd0abe6c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:44324,DS-c44f26c0-e0a8-4396-b090-3d28bd089baa,DISK], DatanodeInfoWithStorage[127.0.0.1:33595,DS-b2d8d3c4-b53e-48cc-a907-849faae4c4a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39977,DS-2b6427b5-10ec-41ee-8cb3-6a8e2ce5984a,DISK], DatanodeInfoWithStorage[127.0.0.1:35113,DS-0d1ef1d9-189f-4703-89ee-5f3abfe22eea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1267371623-172.17.0.17-1597468655303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46860,DS-06bcbe32-d402-461e-9422-8cf6ff42e263,DISK], DatanodeInfoWithStorage[127.0.0.1:44433,DS-c1d8eeef-cb86-45c4-91d1-853656d5ef94,DISK], DatanodeInfoWithStorage[127.0.0.1:46756,DS-957cedad-637d-4f96-aa56-3ff78d9f7d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:40433,DS-33329a4f-0e9a-442f-87e1-3abd0abe6c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:44324,DS-c44f26c0-e0a8-4396-b090-3d28bd089baa,DISK], DatanodeInfoWithStorage[127.0.0.1:33595,DS-b2d8d3c4-b53e-48cc-a907-849faae4c4a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39977,DS-2b6427b5-10ec-41ee-8cb3-6a8e2ce5984a,DISK], DatanodeInfoWithStorage[127.0.0.1:35113,DS-0d1ef1d9-189f-4703-89ee-5f3abfe22eea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 18
v2: 1800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1836949518-172.17.0.17-1597468722245:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42209,DS-851e63d5-9a38-4d6d-8bf8-0529262e3710,DISK], DatanodeInfoWithStorage[127.0.0.1:40682,DS-b512e0de-03ca-4bea-a17e-1948fb736cda,DISK], DatanodeInfoWithStorage[127.0.0.1:35776,DS-fb7681f9-1206-48da-87e6-bddab75969c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36713,DS-f3c64158-4a55-4dd4-9e8e-6752684f157b,DISK], DatanodeInfoWithStorage[127.0.0.1:38858,DS-8a98b041-8fb8-46ed-af4e-16d745403917,DISK], DatanodeInfoWithStorage[127.0.0.1:40966,DS-177e0f57-4813-4628-8dd4-3f693196edec,DISK], DatanodeInfoWithStorage[127.0.0.1:36806,DS-b1492811-8dfb-42ce-9147-777e685a2c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:44080,DS-7183c576-d61d-4901-b18c-b316d5457a27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1836949518-172.17.0.17-1597468722245:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42209,DS-851e63d5-9a38-4d6d-8bf8-0529262e3710,DISK], DatanodeInfoWithStorage[127.0.0.1:40682,DS-b512e0de-03ca-4bea-a17e-1948fb736cda,DISK], DatanodeInfoWithStorage[127.0.0.1:35776,DS-fb7681f9-1206-48da-87e6-bddab75969c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36713,DS-f3c64158-4a55-4dd4-9e8e-6752684f157b,DISK], DatanodeInfoWithStorage[127.0.0.1:38858,DS-8a98b041-8fb8-46ed-af4e-16d745403917,DISK], DatanodeInfoWithStorage[127.0.0.1:40966,DS-177e0f57-4813-4628-8dd4-3f693196edec,DISK], DatanodeInfoWithStorage[127.0.0.1:36806,DS-b1492811-8dfb-42ce-9147-777e685a2c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:44080,DS-7183c576-d61d-4901-b18c-b316d5457a27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 18
v2: 1800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1611375455-172.17.0.17-1597468995731:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35847,DS-9e85bd8a-aaba-4ef6-8050-3ac260dcd9a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36418,DS-34c63fb3-e236-431a-b415-1d33f04d137d,DISK], DatanodeInfoWithStorage[127.0.0.1:36576,DS-8c485054-87d6-4cbd-b78f-63991a09ce14,DISK], DatanodeInfoWithStorage[127.0.0.1:44250,DS-48a25e8d-7f36-4263-b5e9-533a16d1e884,DISK], DatanodeInfoWithStorage[127.0.0.1:37999,DS-65d3a63a-ae68-4082-8826-a9bf95751187,DISK], DatanodeInfoWithStorage[127.0.0.1:44960,DS-f83b27c6-d005-44ad-8a96-71686041e6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40957,DS-2aa6a2e8-afc6-4e69-9006-ad65c2751315,DISK], DatanodeInfoWithStorage[127.0.0.1:39755,DS-61bb84c1-6cca-4ed8-a9c4-808a385f02d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1611375455-172.17.0.17-1597468995731:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35847,DS-9e85bd8a-aaba-4ef6-8050-3ac260dcd9a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36418,DS-34c63fb3-e236-431a-b415-1d33f04d137d,DISK], DatanodeInfoWithStorage[127.0.0.1:36576,DS-8c485054-87d6-4cbd-b78f-63991a09ce14,DISK], DatanodeInfoWithStorage[127.0.0.1:44250,DS-48a25e8d-7f36-4263-b5e9-533a16d1e884,DISK], DatanodeInfoWithStorage[127.0.0.1:37999,DS-65d3a63a-ae68-4082-8826-a9bf95751187,DISK], DatanodeInfoWithStorage[127.0.0.1:44960,DS-f83b27c6-d005-44ad-8a96-71686041e6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40957,DS-2aa6a2e8-afc6-4e69-9006-ad65c2751315,DISK], DatanodeInfoWithStorage[127.0.0.1:39755,DS-61bb84c1-6cca-4ed8-a9c4-808a385f02d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 18
v2: 1800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2010141321-172.17.0.17-1597469630274:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35204,DS-ee58e18f-2c50-45b9-9848-1af1964feb4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35638,DS-43530e70-0723-4c18-b38c-1f500dbb4fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:36997,DS-dd8b6806-6501-4d1d-a683-a085886efbcd,DISK], DatanodeInfoWithStorage[127.0.0.1:37022,DS-6b53a5d2-6dad-4315-aea6-640877b09c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:33867,DS-5bd4c9e9-9287-411d-8333-9ae048a959dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38364,DS-30f041d9-03a8-493a-9255-24e3625b8ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:39701,DS-5bb49ddb-7d90-4cbd-bb16-18e639fad5cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44644,DS-fc0b50e7-e75f-4b19-85be-30d7d2ed2faa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2010141321-172.17.0.17-1597469630274:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35204,DS-ee58e18f-2c50-45b9-9848-1af1964feb4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35638,DS-43530e70-0723-4c18-b38c-1f500dbb4fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:36997,DS-dd8b6806-6501-4d1d-a683-a085886efbcd,DISK], DatanodeInfoWithStorage[127.0.0.1:37022,DS-6b53a5d2-6dad-4315-aea6-640877b09c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:33867,DS-5bd4c9e9-9287-411d-8333-9ae048a959dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38364,DS-30f041d9-03a8-493a-9255-24e3625b8ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:39701,DS-5bb49ddb-7d90-4cbd-bb16-18e639fad5cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44644,DS-fc0b50e7-e75f-4b19-85be-30d7d2ed2faa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 18
v2: 1800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1949153829-172.17.0.17-1597469984115:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41203,DS-b47c2c03-978e-4139-a62c-705c327d1ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:40065,DS-506b5eb6-3e46-467d-abd9-eae406bd16af,DISK], DatanodeInfoWithStorage[127.0.0.1:45551,DS-c76413f5-75f7-44d4-bc35-f9444f139f95,DISK], DatanodeInfoWithStorage[127.0.0.1:38495,DS-4e508007-d722-493c-ad85-7cec433d32d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38255,DS-5d677c53-e49c-4ad2-901e-7a7c713e323e,DISK], DatanodeInfoWithStorage[127.0.0.1:40264,DS-dc263916-f967-4fb7-b616-5d50d9b51eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:35706,DS-18a1d239-ef85-435f-920b-515a10287a32,DISK], DatanodeInfoWithStorage[127.0.0.1:43779,DS-b47710f7-26dd-42fa-8491-c62ab5c4c55a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1949153829-172.17.0.17-1597469984115:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41203,DS-b47c2c03-978e-4139-a62c-705c327d1ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:40065,DS-506b5eb6-3e46-467d-abd9-eae406bd16af,DISK], DatanodeInfoWithStorage[127.0.0.1:45551,DS-c76413f5-75f7-44d4-bc35-f9444f139f95,DISK], DatanodeInfoWithStorage[127.0.0.1:38495,DS-4e508007-d722-493c-ad85-7cec433d32d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38255,DS-5d677c53-e49c-4ad2-901e-7a7c713e323e,DISK], DatanodeInfoWithStorage[127.0.0.1:40264,DS-dc263916-f967-4fb7-b616-5d50d9b51eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:35706,DS-18a1d239-ef85-435f-920b-515a10287a32,DISK], DatanodeInfoWithStorage[127.0.0.1:43779,DS-b47710f7-26dd-42fa-8491-c62ab5c4c55a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 18
v2: 1800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-648146143-172.17.0.17-1597470062361:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33293,DS-04dba2f1-6a06-4105-a504-da521ac92c67,DISK], DatanodeInfoWithStorage[127.0.0.1:37799,DS-8366e778-53c9-48ff-8d24-a506c5c479c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36120,DS-9707558a-72b2-45b4-b959-693f5627af19,DISK], DatanodeInfoWithStorage[127.0.0.1:35162,DS-822edff0-b8a8-4370-b3c7-e7edbf0581fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42815,DS-5d5b3e9e-2cf0-45f0-9cf7-8891deeb16b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45282,DS-08d99620-7a98-425d-9bd1-f4e9f7ae1dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:39183,DS-5db119e8-686a-4be2-98cb-7a965d914f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:41572,DS-c54970d4-9b35-481e-9e82-06fbe4092838,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-648146143-172.17.0.17-1597470062361:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33293,DS-04dba2f1-6a06-4105-a504-da521ac92c67,DISK], DatanodeInfoWithStorage[127.0.0.1:37799,DS-8366e778-53c9-48ff-8d24-a506c5c479c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36120,DS-9707558a-72b2-45b4-b959-693f5627af19,DISK], DatanodeInfoWithStorage[127.0.0.1:35162,DS-822edff0-b8a8-4370-b3c7-e7edbf0581fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42815,DS-5d5b3e9e-2cf0-45f0-9cf7-8891deeb16b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45282,DS-08d99620-7a98-425d-9bd1-f4e9f7ae1dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:39183,DS-5db119e8-686a-4be2-98cb-7a965d914f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:41572,DS-c54970d4-9b35-481e-9e82-06fbe4092838,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 18
v2: 1800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1241368730-172.17.0.17-1597470519811:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40072,DS-f1df3506-f8f3-4edf-a9b0-44c3d40345da,DISK], DatanodeInfoWithStorage[127.0.0.1:42530,DS-cdab33f1-9dcb-45ec-a1fc-e3041e403b11,DISK], DatanodeInfoWithStorage[127.0.0.1:35678,DS-80198349-b84e-4538-8741-367de600f62c,DISK], DatanodeInfoWithStorage[127.0.0.1:35633,DS-f70bb72e-7657-42be-9a53-a0e190b45b14,DISK], DatanodeInfoWithStorage[127.0.0.1:41367,DS-9ba5ac0a-ad42-4614-8f87-bbd6fb3d9341,DISK], DatanodeInfoWithStorage[127.0.0.1:41153,DS-5cc987b4-0e92-410f-b0f7-9b8aefa9c9f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33651,DS-f3951c74-51ed-4b9e-87b5-c96bc41effe4,DISK], DatanodeInfoWithStorage[127.0.0.1:46260,DS-5ab85086-3fee-43ba-9009-2d9c6a3016b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1241368730-172.17.0.17-1597470519811:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40072,DS-f1df3506-f8f3-4edf-a9b0-44c3d40345da,DISK], DatanodeInfoWithStorage[127.0.0.1:42530,DS-cdab33f1-9dcb-45ec-a1fc-e3041e403b11,DISK], DatanodeInfoWithStorage[127.0.0.1:35678,DS-80198349-b84e-4538-8741-367de600f62c,DISK], DatanodeInfoWithStorage[127.0.0.1:35633,DS-f70bb72e-7657-42be-9a53-a0e190b45b14,DISK], DatanodeInfoWithStorage[127.0.0.1:41367,DS-9ba5ac0a-ad42-4614-8f87-bbd6fb3d9341,DISK], DatanodeInfoWithStorage[127.0.0.1:41153,DS-5cc987b4-0e92-410f-b0f7-9b8aefa9c9f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33651,DS-f3951c74-51ed-4b9e-87b5-c96bc41effe4,DISK], DatanodeInfoWithStorage[127.0.0.1:46260,DS-5ab85086-3fee-43ba-9009-2d9c6a3016b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 18
v2: 1800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-457414855-172.17.0.17-1597471026243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40496,DS-705cef66-856e-4910-b9a9-ffd13b00d565,DISK], DatanodeInfoWithStorage[127.0.0.1:36304,DS-54c4419f-8618-4a85-82ce-7371347f2c36,DISK], DatanodeInfoWithStorage[127.0.0.1:46754,DS-36f17bf2-2173-4331-a04b-69e56a6703ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33604,DS-95f30e6e-e2d3-4869-a9d0-3de566b8875b,DISK], DatanodeInfoWithStorage[127.0.0.1:46168,DS-3804fbf6-5897-471f-9a37-cd949a37044f,DISK], DatanodeInfoWithStorage[127.0.0.1:34598,DS-b283ab2d-849c-4a0c-8368-41205f544737,DISK], DatanodeInfoWithStorage[127.0.0.1:44502,DS-f6010047-cbd7-43a5-83bc-21032bb50625,DISK], DatanodeInfoWithStorage[127.0.0.1:37423,DS-473cc811-e40a-49a4-8155-13f58c1877b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-457414855-172.17.0.17-1597471026243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40496,DS-705cef66-856e-4910-b9a9-ffd13b00d565,DISK], DatanodeInfoWithStorage[127.0.0.1:36304,DS-54c4419f-8618-4a85-82ce-7371347f2c36,DISK], DatanodeInfoWithStorage[127.0.0.1:46754,DS-36f17bf2-2173-4331-a04b-69e56a6703ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33604,DS-95f30e6e-e2d3-4869-a9d0-3de566b8875b,DISK], DatanodeInfoWithStorage[127.0.0.1:46168,DS-3804fbf6-5897-471f-9a37-cd949a37044f,DISK], DatanodeInfoWithStorage[127.0.0.1:34598,DS-b283ab2d-849c-4a0c-8368-41205f544737,DISK], DatanodeInfoWithStorage[127.0.0.1:44502,DS-f6010047-cbd7-43a5-83bc-21032bb50625,DISK], DatanodeInfoWithStorage[127.0.0.1:37423,DS-473cc811-e40a-49a4-8155-13f58c1877b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 18
v2: 1800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1638685817-172.17.0.17-1597471062775:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34441,DS-2893c08f-228f-48fd-a7e6-0b800d481e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43040,DS-440566a1-53d1-4235-b077-395c31a26513,DISK], DatanodeInfoWithStorage[127.0.0.1:38346,DS-dcfe7fa8-caa9-40bb-acd5-c1d4cdc4cc66,DISK], DatanodeInfoWithStorage[127.0.0.1:36962,DS-aa011b83-24ad-4fbd-8201-155acb226f9d,DISK], DatanodeInfoWithStorage[127.0.0.1:40409,DS-8ed7b124-8e40-40b1-9eea-3696acc3b058,DISK], DatanodeInfoWithStorage[127.0.0.1:33815,DS-fc915fd8-fb32-4969-849b-55fd58f088da,DISK], DatanodeInfoWithStorage[127.0.0.1:41590,DS-4a4b9b45-6d7c-4dcf-b1a6-ed3bda856255,DISK], DatanodeInfoWithStorage[127.0.0.1:39691,DS-cc7d16e8-2677-4009-aa4b-f3eb7a03c6a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1638685817-172.17.0.17-1597471062775:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34441,DS-2893c08f-228f-48fd-a7e6-0b800d481e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43040,DS-440566a1-53d1-4235-b077-395c31a26513,DISK], DatanodeInfoWithStorage[127.0.0.1:38346,DS-dcfe7fa8-caa9-40bb-acd5-c1d4cdc4cc66,DISK], DatanodeInfoWithStorage[127.0.0.1:36962,DS-aa011b83-24ad-4fbd-8201-155acb226f9d,DISK], DatanodeInfoWithStorage[127.0.0.1:40409,DS-8ed7b124-8e40-40b1-9eea-3696acc3b058,DISK], DatanodeInfoWithStorage[127.0.0.1:33815,DS-fc915fd8-fb32-4969-849b-55fd58f088da,DISK], DatanodeInfoWithStorage[127.0.0.1:41590,DS-4a4b9b45-6d7c-4dcf-b1a6-ed3bda856255,DISK], DatanodeInfoWithStorage[127.0.0.1:39691,DS-cc7d16e8-2677-4009-aa4b-f3eb7a03c6a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 18
v2: 1800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-354639017-172.17.0.17-1597471253187:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46718,DS-a4febe01-e2d4-4f9e-82e9-c641341483dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45099,DS-406e56bc-8d02-42c7-9315-3abd899a3307,DISK], DatanodeInfoWithStorage[127.0.0.1:44884,DS-80660f92-1438-4563-a80f-e6133614bcf3,DISK], DatanodeInfoWithStorage[127.0.0.1:36717,DS-c6575d4d-7408-4e6b-93d5-7cbd9d1c6770,DISK], DatanodeInfoWithStorage[127.0.0.1:45277,DS-a6593db6-3cc0-41b9-b3c6-3341feb4bd24,DISK], DatanodeInfoWithStorage[127.0.0.1:34790,DS-1c3b9ffd-d519-4946-bf7f-2e44e952250c,DISK], DatanodeInfoWithStorage[127.0.0.1:35257,DS-6d8aefc8-f991-4ae0-919e-b2465ab9d0f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37804,DS-37c8b26f-4529-46f0-a25f-3eccdcd9ce32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-354639017-172.17.0.17-1597471253187:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46718,DS-a4febe01-e2d4-4f9e-82e9-c641341483dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45099,DS-406e56bc-8d02-42c7-9315-3abd899a3307,DISK], DatanodeInfoWithStorage[127.0.0.1:44884,DS-80660f92-1438-4563-a80f-e6133614bcf3,DISK], DatanodeInfoWithStorage[127.0.0.1:36717,DS-c6575d4d-7408-4e6b-93d5-7cbd9d1c6770,DISK], DatanodeInfoWithStorage[127.0.0.1:45277,DS-a6593db6-3cc0-41b9-b3c6-3341feb4bd24,DISK], DatanodeInfoWithStorage[127.0.0.1:34790,DS-1c3b9ffd-d519-4946-bf7f-2e44e952250c,DISK], DatanodeInfoWithStorage[127.0.0.1:35257,DS-6d8aefc8-f991-4ae0-919e-b2465ab9d0f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37804,DS-37c8b26f-4529-46f0-a25f-3eccdcd9ce32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 18
v2: 1800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-643427482-172.17.0.17-1597471377792:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40862,DS-b493b3be-a277-4357-acfe-334c5eadaf6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42985,DS-f780c3b0-aced-4f9f-bec4-53dfa4145590,DISK], DatanodeInfoWithStorage[127.0.0.1:33564,DS-cdcc38d8-3c5e-4099-9107-4fc1b5340fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:44958,DS-2d026ccb-d0e9-4e10-a5dd-8fe65985f887,DISK], DatanodeInfoWithStorage[127.0.0.1:35886,DS-738629f0-eaf2-4d5c-a9f9-eba5768de89d,DISK], DatanodeInfoWithStorage[127.0.0.1:40645,DS-c21c7fb4-88b7-47ed-bbda-6ea56b37942d,DISK], DatanodeInfoWithStorage[127.0.0.1:44342,DS-31c34099-25c8-4680-9be2-53d4099bd930,DISK], DatanodeInfoWithStorage[127.0.0.1:41851,DS-8993c082-d089-4a30-88b0-93ebcc4ccbc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-643427482-172.17.0.17-1597471377792:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40862,DS-b493b3be-a277-4357-acfe-334c5eadaf6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42985,DS-f780c3b0-aced-4f9f-bec4-53dfa4145590,DISK], DatanodeInfoWithStorage[127.0.0.1:33564,DS-cdcc38d8-3c5e-4099-9107-4fc1b5340fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:44958,DS-2d026ccb-d0e9-4e10-a5dd-8fe65985f887,DISK], DatanodeInfoWithStorage[127.0.0.1:35886,DS-738629f0-eaf2-4d5c-a9f9-eba5768de89d,DISK], DatanodeInfoWithStorage[127.0.0.1:40645,DS-c21c7fb4-88b7-47ed-bbda-6ea56b37942d,DISK], DatanodeInfoWithStorage[127.0.0.1:44342,DS-31c34099-25c8-4680-9be2-53d4099bd930,DISK], DatanodeInfoWithStorage[127.0.0.1:41851,DS-8993c082-d089-4a30-88b0-93ebcc4ccbc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 18
v2: 1800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1029867777-172.17.0.17-1597471919816:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41785,DS-98d5227d-dc7f-43da-be83-656f20888878,DISK], DatanodeInfoWithStorage[127.0.0.1:44448,DS-6418de67-bd5f-4d59-98f6-277f307aaabb,DISK], DatanodeInfoWithStorage[127.0.0.1:36759,DS-271ed9e2-4235-4d4f-a5d4-aac9894f0b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:40806,DS-fce96734-fe1b-4b96-9221-1790f1bf7d14,DISK], DatanodeInfoWithStorage[127.0.0.1:35376,DS-b35d5da2-93cd-43e3-9df0-9455ebd6fed8,DISK], DatanodeInfoWithStorage[127.0.0.1:38025,DS-f44d2730-ea70-4dcd-be0b-7be74f2d4c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39207,DS-ed4f3fa4-8ff8-4e00-9661-14a5aee9136b,DISK], DatanodeInfoWithStorage[127.0.0.1:43807,DS-90897203-b53a-4968-b163-054e49777588,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1029867777-172.17.0.17-1597471919816:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41785,DS-98d5227d-dc7f-43da-be83-656f20888878,DISK], DatanodeInfoWithStorage[127.0.0.1:44448,DS-6418de67-bd5f-4d59-98f6-277f307aaabb,DISK], DatanodeInfoWithStorage[127.0.0.1:36759,DS-271ed9e2-4235-4d4f-a5d4-aac9894f0b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:40806,DS-fce96734-fe1b-4b96-9221-1790f1bf7d14,DISK], DatanodeInfoWithStorage[127.0.0.1:35376,DS-b35d5da2-93cd-43e3-9df0-9455ebd6fed8,DISK], DatanodeInfoWithStorage[127.0.0.1:38025,DS-f44d2730-ea70-4dcd-be0b-7be74f2d4c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39207,DS-ed4f3fa4-8ff8-4e00-9661-14a5aee9136b,DISK], DatanodeInfoWithStorage[127.0.0.1:43807,DS-90897203-b53a-4968-b163-054e49777588,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 18
v2: 1800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-37871851-172.17.0.17-1597472186490:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44094,DS-55a7c823-2e8e-4480-9509-df2a77093a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42335,DS-46401863-9293-4ab6-b102-82134b51d3cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35196,DS-ba84b836-94e0-4ff5-a47e-6793afc396b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35958,DS-6861ed0c-d97b-4ef3-81bb-4a5cbd7688d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44081,DS-fb86eb6e-f6ab-49fc-939d-70a4d5fee26e,DISK], DatanodeInfoWithStorage[127.0.0.1:37755,DS-f72d379d-c51a-44e4-bcb6-7bba6a43d79e,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-5e8ad8c6-01d6-4f4e-ab62-cf39a21829fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40152,DS-298e1129-c2a4-4a46-a561-3259fb0168b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-37871851-172.17.0.17-1597472186490:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44094,DS-55a7c823-2e8e-4480-9509-df2a77093a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42335,DS-46401863-9293-4ab6-b102-82134b51d3cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35196,DS-ba84b836-94e0-4ff5-a47e-6793afc396b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35958,DS-6861ed0c-d97b-4ef3-81bb-4a5cbd7688d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44081,DS-fb86eb6e-f6ab-49fc-939d-70a4d5fee26e,DISK], DatanodeInfoWithStorage[127.0.0.1:37755,DS-f72d379d-c51a-44e4-bcb6-7bba6a43d79e,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-5e8ad8c6-01d6-4f4e-ab62-cf39a21829fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40152,DS-298e1129-c2a4-4a46-a561-3259fb0168b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 18
v2: 1800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-292018280-172.17.0.17-1597472550874:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36499,DS-9e35e197-7282-4cc2-a432-76f20db4fd7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38301,DS-3cbb9a54-7acf-4cd5-aaa2-2dbb3b3e364f,DISK], DatanodeInfoWithStorage[127.0.0.1:34377,DS-474ccdc1-1447-4ad1-8450-b73ee024711a,DISK], DatanodeInfoWithStorage[127.0.0.1:35753,DS-e7072144-6d63-4660-b6dc-66808a2b920d,DISK], DatanodeInfoWithStorage[127.0.0.1:37218,DS-6a34f01a-fa2b-4006-bb33-685fa2813f86,DISK], DatanodeInfoWithStorage[127.0.0.1:38158,DS-43753a13-96cb-47c2-bc45-5028e96e721a,DISK], DatanodeInfoWithStorage[127.0.0.1:34467,DS-165860eb-b725-42f1-b874-b987c07a74df,DISK], DatanodeInfoWithStorage[127.0.0.1:41779,DS-91144ee7-0cab-496f-8c4e-1b3a1980df6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-292018280-172.17.0.17-1597472550874:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36499,DS-9e35e197-7282-4cc2-a432-76f20db4fd7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38301,DS-3cbb9a54-7acf-4cd5-aaa2-2dbb3b3e364f,DISK], DatanodeInfoWithStorage[127.0.0.1:34377,DS-474ccdc1-1447-4ad1-8450-b73ee024711a,DISK], DatanodeInfoWithStorage[127.0.0.1:35753,DS-e7072144-6d63-4660-b6dc-66808a2b920d,DISK], DatanodeInfoWithStorage[127.0.0.1:37218,DS-6a34f01a-fa2b-4006-bb33-685fa2813f86,DISK], DatanodeInfoWithStorage[127.0.0.1:38158,DS-43753a13-96cb-47c2-bc45-5028e96e721a,DISK], DatanodeInfoWithStorage[127.0.0.1:34467,DS-165860eb-b725-42f1-b874-b987c07a74df,DISK], DatanodeInfoWithStorage[127.0.0.1:41779,DS-91144ee7-0cab-496f-8c4e-1b3a1980df6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5715
