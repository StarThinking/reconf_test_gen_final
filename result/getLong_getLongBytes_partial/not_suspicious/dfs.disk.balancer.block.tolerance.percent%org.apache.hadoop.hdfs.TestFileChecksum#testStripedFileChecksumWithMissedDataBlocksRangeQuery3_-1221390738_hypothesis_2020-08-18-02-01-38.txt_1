reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 50
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 50
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1542392178-172.17.0.11-1597717896040:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43215,DS-3c7cbccc-4ea4-4e67-91d1-2165f8c327d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37290,DS-cc1872eb-d0e2-41e9-9219-b4f268ab96ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40047,DS-af820031-41ff-4a59-be39-02d4674f6c73,DISK], DatanodeInfoWithStorage[127.0.0.1:44333,DS-c5ab9fa1-7cd5-4ea7-be70-2d5771e6e536,DISK], DatanodeInfoWithStorage[127.0.0.1:36053,DS-b0222048-9a52-45eb-8232-8b575cd31760,DISK], DatanodeInfoWithStorage[127.0.0.1:40739,DS-ad6ea881-433c-48d5-b456-5950c06644c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37872,DS-0467b48c-db74-4244-97ba-db3da358613d,DISK], DatanodeInfoWithStorage[127.0.0.1:35864,DS-d10d8ec3-e641-4609-b638-925b3f2f36ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1542392178-172.17.0.11-1597717896040:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43215,DS-3c7cbccc-4ea4-4e67-91d1-2165f8c327d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37290,DS-cc1872eb-d0e2-41e9-9219-b4f268ab96ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40047,DS-af820031-41ff-4a59-be39-02d4674f6c73,DISK], DatanodeInfoWithStorage[127.0.0.1:44333,DS-c5ab9fa1-7cd5-4ea7-be70-2d5771e6e536,DISK], DatanodeInfoWithStorage[127.0.0.1:36053,DS-b0222048-9a52-45eb-8232-8b575cd31760,DISK], DatanodeInfoWithStorage[127.0.0.1:40739,DS-ad6ea881-433c-48d5-b456-5950c06644c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37872,DS-0467b48c-db74-4244-97ba-db3da358613d,DISK], DatanodeInfoWithStorage[127.0.0.1:35864,DS-d10d8ec3-e641-4609-b638-925b3f2f36ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 50
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1930244988-172.17.0.11-1597718214146:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38914,DS-3c8d4535-1e86-4221-a5e7-2399d91560ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33344,DS-59494ab8-1719-4fbc-ae7d-76c60ef7dcb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42012,DS-867beb35-f33c-4b06-9916-86b971d60cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:44757,DS-e6eea948-f3fa-499f-8798-fb3c02d5ca27,DISK], DatanodeInfoWithStorage[127.0.0.1:46311,DS-bc021f4a-8eb3-402e-8cf6-54707bdafad4,DISK], DatanodeInfoWithStorage[127.0.0.1:43465,DS-a3feac86-665b-4cf9-839b-23cfbfae9c18,DISK], DatanodeInfoWithStorage[127.0.0.1:46462,DS-0abb77a3-bf23-4813-ad76-b9846c4c3c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:39721,DS-7667f567-347e-4906-8cf7-e881bc1f155f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1930244988-172.17.0.11-1597718214146:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38914,DS-3c8d4535-1e86-4221-a5e7-2399d91560ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33344,DS-59494ab8-1719-4fbc-ae7d-76c60ef7dcb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42012,DS-867beb35-f33c-4b06-9916-86b971d60cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:44757,DS-e6eea948-f3fa-499f-8798-fb3c02d5ca27,DISK], DatanodeInfoWithStorage[127.0.0.1:46311,DS-bc021f4a-8eb3-402e-8cf6-54707bdafad4,DISK], DatanodeInfoWithStorage[127.0.0.1:43465,DS-a3feac86-665b-4cf9-839b-23cfbfae9c18,DISK], DatanodeInfoWithStorage[127.0.0.1:46462,DS-0abb77a3-bf23-4813-ad76-b9846c4c3c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:39721,DS-7667f567-347e-4906-8cf7-e881bc1f155f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 50
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-765116255-172.17.0.11-1597718903477:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44011,DS-70db4f03-5ae7-4390-9f0b-b820602f8fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:45877,DS-fbb4f40c-20ca-4542-aed0-270b7135e900,DISK], DatanodeInfoWithStorage[127.0.0.1:36646,DS-2318be51-18e7-44f1-9f9d-136411fec9dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35238,DS-eac8062d-e5f4-4778-b057-5f190b4e258a,DISK], DatanodeInfoWithStorage[127.0.0.1:39673,DS-db0db2f8-1452-4158-a9bd-6344f0bab9eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41230,DS-0300e653-cf37-49db-a622-08d935a0ade1,DISK], DatanodeInfoWithStorage[127.0.0.1:39318,DS-6c9cd425-3b18-4e33-8885-485bdcdb6013,DISK], DatanodeInfoWithStorage[127.0.0.1:38323,DS-7a6a521c-27c3-4734-a8b0-0a7c6d40a194,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-765116255-172.17.0.11-1597718903477:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44011,DS-70db4f03-5ae7-4390-9f0b-b820602f8fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:45877,DS-fbb4f40c-20ca-4542-aed0-270b7135e900,DISK], DatanodeInfoWithStorage[127.0.0.1:36646,DS-2318be51-18e7-44f1-9f9d-136411fec9dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35238,DS-eac8062d-e5f4-4778-b057-5f190b4e258a,DISK], DatanodeInfoWithStorage[127.0.0.1:39673,DS-db0db2f8-1452-4158-a9bd-6344f0bab9eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41230,DS-0300e653-cf37-49db-a622-08d935a0ade1,DISK], DatanodeInfoWithStorage[127.0.0.1:39318,DS-6c9cd425-3b18-4e33-8885-485bdcdb6013,DISK], DatanodeInfoWithStorage[127.0.0.1:38323,DS-7a6a521c-27c3-4734-a8b0-0a7c6d40a194,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 50
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-585124391-172.17.0.11-1597719673374:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42425,DS-3d0c4254-e2f5-4598-9b0f-255916ab8f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:43375,DS-3e6fcb31-9fe6-4b08-b514-c7b70652a93a,DISK], DatanodeInfoWithStorage[127.0.0.1:36747,DS-b6d90e50-8b8d-442a-9835-820c876d73a4,DISK], DatanodeInfoWithStorage[127.0.0.1:32826,DS-00c9de3b-ef99-4831-b872-ef263ab10574,DISK], DatanodeInfoWithStorage[127.0.0.1:43425,DS-83830af9-878d-4163-b137-36ca554f726b,DISK], DatanodeInfoWithStorage[127.0.0.1:35899,DS-ca81e8b1-5c20-46eb-bb38-c8ad7a5d44d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45634,DS-15ae8192-1dc4-465d-b434-6f53420959c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37389,DS-1ccbdc72-3175-4e21-8c94-dd5d24f44562,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-585124391-172.17.0.11-1597719673374:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42425,DS-3d0c4254-e2f5-4598-9b0f-255916ab8f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:43375,DS-3e6fcb31-9fe6-4b08-b514-c7b70652a93a,DISK], DatanodeInfoWithStorage[127.0.0.1:36747,DS-b6d90e50-8b8d-442a-9835-820c876d73a4,DISK], DatanodeInfoWithStorage[127.0.0.1:32826,DS-00c9de3b-ef99-4831-b872-ef263ab10574,DISK], DatanodeInfoWithStorage[127.0.0.1:43425,DS-83830af9-878d-4163-b137-36ca554f726b,DISK], DatanodeInfoWithStorage[127.0.0.1:35899,DS-ca81e8b1-5c20-46eb-bb38-c8ad7a5d44d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45634,DS-15ae8192-1dc4-465d-b434-6f53420959c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37389,DS-1ccbdc72-3175-4e21-8c94-dd5d24f44562,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 50
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1836754989-172.17.0.11-1597719786637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41799,DS-cb3f38f7-aec7-49a6-8ed0-bb845e51b98b,DISK], DatanodeInfoWithStorage[127.0.0.1:40101,DS-48ebc807-c0c3-4846-84a3-98e4d450c8f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43318,DS-b965077f-a7d8-4be9-81e9-1918341fe02b,DISK], DatanodeInfoWithStorage[127.0.0.1:45284,DS-5cf5ecdf-f9eb-494a-a8a9-1dc82959c8d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34423,DS-10b56924-0490-4b9a-b74e-85cc8c10f39c,DISK], DatanodeInfoWithStorage[127.0.0.1:33532,DS-f65ef8e8-f2c6-480a-94af-f5e14d55731f,DISK], DatanodeInfoWithStorage[127.0.0.1:45879,DS-df17421f-5889-4253-af2c-36fa107f6849,DISK], DatanodeInfoWithStorage[127.0.0.1:43159,DS-c3e7d3b4-c423-4314-9256-21359a29f085,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1836754989-172.17.0.11-1597719786637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41799,DS-cb3f38f7-aec7-49a6-8ed0-bb845e51b98b,DISK], DatanodeInfoWithStorage[127.0.0.1:40101,DS-48ebc807-c0c3-4846-84a3-98e4d450c8f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43318,DS-b965077f-a7d8-4be9-81e9-1918341fe02b,DISK], DatanodeInfoWithStorage[127.0.0.1:45284,DS-5cf5ecdf-f9eb-494a-a8a9-1dc82959c8d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34423,DS-10b56924-0490-4b9a-b74e-85cc8c10f39c,DISK], DatanodeInfoWithStorage[127.0.0.1:33532,DS-f65ef8e8-f2c6-480a-94af-f5e14d55731f,DISK], DatanodeInfoWithStorage[127.0.0.1:45879,DS-df17421f-5889-4253-af2c-36fa107f6849,DISK], DatanodeInfoWithStorage[127.0.0.1:43159,DS-c3e7d3b4-c423-4314-9256-21359a29f085,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 50
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-358762995-172.17.0.11-1597719957604:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46830,DS-0cff05bf-bdba-4f96-901d-9642d2895ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:46478,DS-4258ec7a-b9f4-4b8e-80e1-8b96a0e70e03,DISK], DatanodeInfoWithStorage[127.0.0.1:46633,DS-f1aa0ba0-b7f1-45cd-9ca1-9cf6bd4c6d16,DISK], DatanodeInfoWithStorage[127.0.0.1:34816,DS-ba52407e-ad73-4e48-bd69-44f9dd8b830a,DISK], DatanodeInfoWithStorage[127.0.0.1:33158,DS-bdd69c15-9d0e-47e7-8e22-c36e3a43daa3,DISK], DatanodeInfoWithStorage[127.0.0.1:33401,DS-d7598694-7c2d-46bf-8bb4-130a137fe0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34811,DS-49bd1773-3c88-4463-8381-2bd2c19e5255,DISK], DatanodeInfoWithStorage[127.0.0.1:32790,DS-cef83242-3ec2-490e-a062-aad604ce6a9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-358762995-172.17.0.11-1597719957604:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46830,DS-0cff05bf-bdba-4f96-901d-9642d2895ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:46478,DS-4258ec7a-b9f4-4b8e-80e1-8b96a0e70e03,DISK], DatanodeInfoWithStorage[127.0.0.1:46633,DS-f1aa0ba0-b7f1-45cd-9ca1-9cf6bd4c6d16,DISK], DatanodeInfoWithStorage[127.0.0.1:34816,DS-ba52407e-ad73-4e48-bd69-44f9dd8b830a,DISK], DatanodeInfoWithStorage[127.0.0.1:33158,DS-bdd69c15-9d0e-47e7-8e22-c36e3a43daa3,DISK], DatanodeInfoWithStorage[127.0.0.1:33401,DS-d7598694-7c2d-46bf-8bb4-130a137fe0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34811,DS-49bd1773-3c88-4463-8381-2bd2c19e5255,DISK], DatanodeInfoWithStorage[127.0.0.1:32790,DS-cef83242-3ec2-490e-a062-aad604ce6a9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 50
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-792282118-172.17.0.11-1597720055675:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42456,DS-887c922e-113d-4b01-bcce-f63536edc521,DISK], DatanodeInfoWithStorage[127.0.0.1:36970,DS-981b6c84-72b7-423a-9e4b-3c28f55b2e43,DISK], DatanodeInfoWithStorage[127.0.0.1:39529,DS-d34cbabc-1b8a-404b-b382-543cc479c8da,DISK], DatanodeInfoWithStorage[127.0.0.1:41113,DS-0ba53ae0-ce6d-4060-971a-7f843d6da51b,DISK], DatanodeInfoWithStorage[127.0.0.1:32796,DS-72858083-0753-46ed-b3b9-06f5c457e920,DISK], DatanodeInfoWithStorage[127.0.0.1:45125,DS-dad191f2-1257-4c63-a35c-d30a81d0380b,DISK], DatanodeInfoWithStorage[127.0.0.1:41038,DS-ad3d4f80-a7f8-4322-801d-31e7ac305ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:42419,DS-2285cf29-c1a0-40de-a3ba-ae7859f2a8d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-792282118-172.17.0.11-1597720055675:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42456,DS-887c922e-113d-4b01-bcce-f63536edc521,DISK], DatanodeInfoWithStorage[127.0.0.1:36970,DS-981b6c84-72b7-423a-9e4b-3c28f55b2e43,DISK], DatanodeInfoWithStorage[127.0.0.1:39529,DS-d34cbabc-1b8a-404b-b382-543cc479c8da,DISK], DatanodeInfoWithStorage[127.0.0.1:41113,DS-0ba53ae0-ce6d-4060-971a-7f843d6da51b,DISK], DatanodeInfoWithStorage[127.0.0.1:32796,DS-72858083-0753-46ed-b3b9-06f5c457e920,DISK], DatanodeInfoWithStorage[127.0.0.1:45125,DS-dad191f2-1257-4c63-a35c-d30a81d0380b,DISK], DatanodeInfoWithStorage[127.0.0.1:41038,DS-ad3d4f80-a7f8-4322-801d-31e7ac305ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:42419,DS-2285cf29-c1a0-40de-a3ba-ae7859f2a8d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 50
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1592219509-172.17.0.11-1597720130631:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45692,DS-75460f2b-022a-4136-b8cd-2a704bb6f98f,DISK], DatanodeInfoWithStorage[127.0.0.1:44259,DS-a23a2eef-526d-481c-9eb3-57c316837ece,DISK], DatanodeInfoWithStorage[127.0.0.1:42787,DS-53bb669c-8ade-416b-a817-463b3a03b396,DISK], DatanodeInfoWithStorage[127.0.0.1:33329,DS-56c0b05a-6ca0-4d36-9fdc-7269b569b9b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43308,DS-327cd3a4-841f-498b-b5a4-32f2b8a370df,DISK], DatanodeInfoWithStorage[127.0.0.1:43342,DS-50c6109c-c672-4c45-ac85-eb134989e995,DISK], DatanodeInfoWithStorage[127.0.0.1:43878,DS-7f75c98d-85cf-4514-a579-edb7ca3a822c,DISK], DatanodeInfoWithStorage[127.0.0.1:36317,DS-1f532868-ea91-4cc0-9ce1-a0c76c13df70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1592219509-172.17.0.11-1597720130631:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45692,DS-75460f2b-022a-4136-b8cd-2a704bb6f98f,DISK], DatanodeInfoWithStorage[127.0.0.1:44259,DS-a23a2eef-526d-481c-9eb3-57c316837ece,DISK], DatanodeInfoWithStorage[127.0.0.1:42787,DS-53bb669c-8ade-416b-a817-463b3a03b396,DISK], DatanodeInfoWithStorage[127.0.0.1:33329,DS-56c0b05a-6ca0-4d36-9fdc-7269b569b9b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43308,DS-327cd3a4-841f-498b-b5a4-32f2b8a370df,DISK], DatanodeInfoWithStorage[127.0.0.1:43342,DS-50c6109c-c672-4c45-ac85-eb134989e995,DISK], DatanodeInfoWithStorage[127.0.0.1:43878,DS-7f75c98d-85cf-4514-a579-edb7ca3a822c,DISK], DatanodeInfoWithStorage[127.0.0.1:36317,DS-1f532868-ea91-4cc0-9ce1-a0c76c13df70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 50
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-547432468-172.17.0.11-1597720567415:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42293,DS-94b4219a-a4c9-4f21-affb-5e0a53ed4ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:46685,DS-504f3da2-1e27-440b-bce0-a4335f4e6326,DISK], DatanodeInfoWithStorage[127.0.0.1:43745,DS-12b2201e-81a8-4551-967a-f5457ff44b94,DISK], DatanodeInfoWithStorage[127.0.0.1:43958,DS-aee02183-bea1-4af9-8bf3-0b1ebc1b9acd,DISK], DatanodeInfoWithStorage[127.0.0.1:43918,DS-502bb1c0-f132-406e-872e-7e99547ff60a,DISK], DatanodeInfoWithStorage[127.0.0.1:38029,DS-375a3e01-175e-4a7d-aeeb-389763ea6ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:38587,DS-14997c4c-e207-4d39-a83f-467a1ef7222d,DISK], DatanodeInfoWithStorage[127.0.0.1:42412,DS-e5e1ff62-abc0-4eea-8448-4b156576a7b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-547432468-172.17.0.11-1597720567415:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42293,DS-94b4219a-a4c9-4f21-affb-5e0a53ed4ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:46685,DS-504f3da2-1e27-440b-bce0-a4335f4e6326,DISK], DatanodeInfoWithStorage[127.0.0.1:43745,DS-12b2201e-81a8-4551-967a-f5457ff44b94,DISK], DatanodeInfoWithStorage[127.0.0.1:43958,DS-aee02183-bea1-4af9-8bf3-0b1ebc1b9acd,DISK], DatanodeInfoWithStorage[127.0.0.1:43918,DS-502bb1c0-f132-406e-872e-7e99547ff60a,DISK], DatanodeInfoWithStorage[127.0.0.1:38029,DS-375a3e01-175e-4a7d-aeeb-389763ea6ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:38587,DS-14997c4c-e207-4d39-a83f-467a1ef7222d,DISK], DatanodeInfoWithStorage[127.0.0.1:42412,DS-e5e1ff62-abc0-4eea-8448-4b156576a7b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 50
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-956625396-172.17.0.11-1597720604988:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33969,DS-836bd779-2466-466e-93f8-b42d6cde52c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33888,DS-20999b1c-199a-4ff1-ada2-4275e0636a37,DISK], DatanodeInfoWithStorage[127.0.0.1:32857,DS-354a8851-a70a-49fe-a61a-00aea8ff727b,DISK], DatanodeInfoWithStorage[127.0.0.1:34010,DS-955d53b0-070a-4cdc-ba14-581e073275fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43343,DS-2c5a6eb0-8d8a-4736-a4ad-d6bdef191193,DISK], DatanodeInfoWithStorage[127.0.0.1:36445,DS-166a927d-5736-4077-bf18-db65d809c285,DISK], DatanodeInfoWithStorage[127.0.0.1:39853,DS-8b9113bf-bafc-47f5-9911-ca3deb5a6b41,DISK], DatanodeInfoWithStorage[127.0.0.1:42531,DS-9ae7b1fc-fd9d-46e3-8ea7-ba2fc8095f60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-956625396-172.17.0.11-1597720604988:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33969,DS-836bd779-2466-466e-93f8-b42d6cde52c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33888,DS-20999b1c-199a-4ff1-ada2-4275e0636a37,DISK], DatanodeInfoWithStorage[127.0.0.1:32857,DS-354a8851-a70a-49fe-a61a-00aea8ff727b,DISK], DatanodeInfoWithStorage[127.0.0.1:34010,DS-955d53b0-070a-4cdc-ba14-581e073275fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43343,DS-2c5a6eb0-8d8a-4736-a4ad-d6bdef191193,DISK], DatanodeInfoWithStorage[127.0.0.1:36445,DS-166a927d-5736-4077-bf18-db65d809c285,DISK], DatanodeInfoWithStorage[127.0.0.1:39853,DS-8b9113bf-bafc-47f5-9911-ca3deb5a6b41,DISK], DatanodeInfoWithStorage[127.0.0.1:42531,DS-9ae7b1fc-fd9d-46e3-8ea7-ba2fc8095f60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 50
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1358577824-172.17.0.11-1597720674445:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36420,DS-8340f5ad-1568-4dfb-976b-d44988b45554,DISK], DatanodeInfoWithStorage[127.0.0.1:46537,DS-e614de3b-6c4c-48da-89d2-32f394953433,DISK], DatanodeInfoWithStorage[127.0.0.1:42305,DS-0c6b0110-b0e3-48ed-a166-5f21b7586265,DISK], DatanodeInfoWithStorage[127.0.0.1:43361,DS-08954980-02fb-4c4a-a1a1-16021378cfee,DISK], DatanodeInfoWithStorage[127.0.0.1:45297,DS-a9779bc4-3043-49f2-8225-9857f6dd4ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:41407,DS-b89032f9-6d76-4561-9dce-b4a4b121a069,DISK], DatanodeInfoWithStorage[127.0.0.1:45532,DS-32a1697a-79ec-4714-a7a1-599c6ac3a448,DISK], DatanodeInfoWithStorage[127.0.0.1:37765,DS-b9a6299c-7e70-4437-acfa-d31c1fb6ebcd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1358577824-172.17.0.11-1597720674445:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36420,DS-8340f5ad-1568-4dfb-976b-d44988b45554,DISK], DatanodeInfoWithStorage[127.0.0.1:46537,DS-e614de3b-6c4c-48da-89d2-32f394953433,DISK], DatanodeInfoWithStorage[127.0.0.1:42305,DS-0c6b0110-b0e3-48ed-a166-5f21b7586265,DISK], DatanodeInfoWithStorage[127.0.0.1:43361,DS-08954980-02fb-4c4a-a1a1-16021378cfee,DISK], DatanodeInfoWithStorage[127.0.0.1:45297,DS-a9779bc4-3043-49f2-8225-9857f6dd4ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:41407,DS-b89032f9-6d76-4561-9dce-b4a4b121a069,DISK], DatanodeInfoWithStorage[127.0.0.1:45532,DS-32a1697a-79ec-4714-a7a1-599c6ac3a448,DISK], DatanodeInfoWithStorage[127.0.0.1:37765,DS-b9a6299c-7e70-4437-acfa-d31c1fb6ebcd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 50
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-521432609-172.17.0.11-1597720754795:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38834,DS-b4bf522a-2be9-44cc-980e-11fcbe2462a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42485,DS-aaac52c4-53ed-4a33-83f3-598c4c331a24,DISK], DatanodeInfoWithStorage[127.0.0.1:33619,DS-fd1d8d2b-301a-43c6-a3a7-bdc5e1e93163,DISK], DatanodeInfoWithStorage[127.0.0.1:43052,DS-c1ff45dc-280c-4b65-b228-97484763df6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39314,DS-37d78809-0085-460a-af8d-0425685722ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35672,DS-c8e79790-adb7-404f-a042-be87cbf5f349,DISK], DatanodeInfoWithStorage[127.0.0.1:39707,DS-1b1f30fc-c6f8-4208-82c6-398a92163cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:33460,DS-0a79c8f1-8024-49ad-82a8-2513a59c8eb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-521432609-172.17.0.11-1597720754795:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38834,DS-b4bf522a-2be9-44cc-980e-11fcbe2462a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42485,DS-aaac52c4-53ed-4a33-83f3-598c4c331a24,DISK], DatanodeInfoWithStorage[127.0.0.1:33619,DS-fd1d8d2b-301a-43c6-a3a7-bdc5e1e93163,DISK], DatanodeInfoWithStorage[127.0.0.1:43052,DS-c1ff45dc-280c-4b65-b228-97484763df6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39314,DS-37d78809-0085-460a-af8d-0425685722ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35672,DS-c8e79790-adb7-404f-a042-be87cbf5f349,DISK], DatanodeInfoWithStorage[127.0.0.1:39707,DS-1b1f30fc-c6f8-4208-82c6-398a92163cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:33460,DS-0a79c8f1-8024-49ad-82a8-2513a59c8eb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 50
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-345747061-172.17.0.11-1597721006156:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38289,DS-66c0879f-d612-4b90-ab77-2c0f222e17fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46081,DS-11ac5976-3ebb-4bdb-ac1b-d75a42a89007,DISK], DatanodeInfoWithStorage[127.0.0.1:42647,DS-c80f928d-e343-41b4-a0ee-d0a53dc8fe9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44887,DS-8609fa61-3871-4fe2-add4-511be1913f50,DISK], DatanodeInfoWithStorage[127.0.0.1:33808,DS-84c84596-ccb1-46b6-89c1-a401253a63c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42615,DS-d0e9bd08-4ed9-48d8-9a0b-8db9fad13ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:36021,DS-bbe54ac6-1a5e-47e6-b7f8-917ef430ca5b,DISK], DatanodeInfoWithStorage[127.0.0.1:46308,DS-8e31b3c8-a4d9-4afa-a7ed-bfdf54692f3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-345747061-172.17.0.11-1597721006156:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38289,DS-66c0879f-d612-4b90-ab77-2c0f222e17fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46081,DS-11ac5976-3ebb-4bdb-ac1b-d75a42a89007,DISK], DatanodeInfoWithStorage[127.0.0.1:42647,DS-c80f928d-e343-41b4-a0ee-d0a53dc8fe9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44887,DS-8609fa61-3871-4fe2-add4-511be1913f50,DISK], DatanodeInfoWithStorage[127.0.0.1:33808,DS-84c84596-ccb1-46b6-89c1-a401253a63c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42615,DS-d0e9bd08-4ed9-48d8-9a0b-8db9fad13ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:36021,DS-bbe54ac6-1a5e-47e6-b7f8-917ef430ca5b,DISK], DatanodeInfoWithStorage[127.0.0.1:46308,DS-8e31b3c8-a4d9-4afa-a7ed-bfdf54692f3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5353
