reconf_parameter: dfs.namenode.accesstime.precision
component: hdfs:NameNode
v1: 36
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.accesstime.precision
component: hdfs:NameNode
v1: 36
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1602666982-172.17.0.3-1597467709851:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38756,DS-60710cd1-3d1d-443a-83e3-b69aa0d281d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44702,DS-85b8aac6-b2e0-4b00-9a7b-20be7e4f5bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:39728,DS-895af844-f500-4bca-87ea-cc0c373538b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43326,DS-d4a38db4-4be2-4db1-8c01-0c5053cc2b71,DISK], DatanodeInfoWithStorage[127.0.0.1:46152,DS-ae3cb709-378e-4bc4-bb26-05d98495e926,DISK], DatanodeInfoWithStorage[127.0.0.1:35358,DS-0ff2152e-c093-4fd5-a97d-343a62c647be,DISK], DatanodeInfoWithStorage[127.0.0.1:46851,DS-377c4bad-8c4c-4558-8633-5cbf17a80bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:42906,DS-d148a9aa-5e65-4d51-895b-c81c080e6fee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1602666982-172.17.0.3-1597467709851:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38756,DS-60710cd1-3d1d-443a-83e3-b69aa0d281d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44702,DS-85b8aac6-b2e0-4b00-9a7b-20be7e4f5bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:39728,DS-895af844-f500-4bca-87ea-cc0c373538b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43326,DS-d4a38db4-4be2-4db1-8c01-0c5053cc2b71,DISK], DatanodeInfoWithStorage[127.0.0.1:46152,DS-ae3cb709-378e-4bc4-bb26-05d98495e926,DISK], DatanodeInfoWithStorage[127.0.0.1:35358,DS-0ff2152e-c093-4fd5-a97d-343a62c647be,DISK], DatanodeInfoWithStorage[127.0.0.1:46851,DS-377c4bad-8c4c-4558-8633-5cbf17a80bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:42906,DS-d148a9aa-5e65-4d51-895b-c81c080e6fee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.accesstime.precision
component: hdfs:NameNode
v1: 36
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1401245129-172.17.0.3-1597467895786:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41888,DS-ccfbd543-f790-4c36-888d-496291f423eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40547,DS-9ea5bc70-3e05-45a8-ad30-fe1c3f43e143,DISK], DatanodeInfoWithStorage[127.0.0.1:37049,DS-01514c58-b6be-441d-8356-6b2c7554d720,DISK], DatanodeInfoWithStorage[127.0.0.1:34573,DS-0c6383c9-c53c-4c0e-9d8e-b677ebaafb69,DISK], DatanodeInfoWithStorage[127.0.0.1:45603,DS-38518756-3085-4ca4-b979-5093f09d715e,DISK], DatanodeInfoWithStorage[127.0.0.1:39535,DS-2889a378-ac73-4edd-a755-d1d55f6b322f,DISK], DatanodeInfoWithStorage[127.0.0.1:40715,DS-b95cd3bf-d50e-47fc-95a4-1460a10544d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43706,DS-401c7ac0-4816-4f09-826c-a0415f3863d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1401245129-172.17.0.3-1597467895786:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41888,DS-ccfbd543-f790-4c36-888d-496291f423eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40547,DS-9ea5bc70-3e05-45a8-ad30-fe1c3f43e143,DISK], DatanodeInfoWithStorage[127.0.0.1:37049,DS-01514c58-b6be-441d-8356-6b2c7554d720,DISK], DatanodeInfoWithStorage[127.0.0.1:34573,DS-0c6383c9-c53c-4c0e-9d8e-b677ebaafb69,DISK], DatanodeInfoWithStorage[127.0.0.1:45603,DS-38518756-3085-4ca4-b979-5093f09d715e,DISK], DatanodeInfoWithStorage[127.0.0.1:39535,DS-2889a378-ac73-4edd-a755-d1d55f6b322f,DISK], DatanodeInfoWithStorage[127.0.0.1:40715,DS-b95cd3bf-d50e-47fc-95a4-1460a10544d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43706,DS-401c7ac0-4816-4f09-826c-a0415f3863d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.accesstime.precision
component: hdfs:NameNode
v1: 36
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1607388609-172.17.0.3-1597467931017:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32824,DS-00f8c5d6-99b9-4345-9366-f34036c19d64,DISK], DatanodeInfoWithStorage[127.0.0.1:45101,DS-9d8630db-fd0d-4607-a8d7-b8e77c3ba9e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33230,DS-ec038d09-d411-4696-b7c7-58585c95f512,DISK], DatanodeInfoWithStorage[127.0.0.1:35936,DS-20e5ef0a-d78b-4de7-9269-e44e405c52fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40101,DS-b8567fdb-8bec-494e-963b-faa8506a7850,DISK], DatanodeInfoWithStorage[127.0.0.1:43120,DS-65226045-22a6-4ec4-8e37-81c4f12bca9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38568,DS-e15eb2ca-0352-442e-a7a9-4af897150668,DISK], DatanodeInfoWithStorage[127.0.0.1:45628,DS-19e5de54-c266-4bda-b840-dd714a954c97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1607388609-172.17.0.3-1597467931017:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32824,DS-00f8c5d6-99b9-4345-9366-f34036c19d64,DISK], DatanodeInfoWithStorage[127.0.0.1:45101,DS-9d8630db-fd0d-4607-a8d7-b8e77c3ba9e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33230,DS-ec038d09-d411-4696-b7c7-58585c95f512,DISK], DatanodeInfoWithStorage[127.0.0.1:35936,DS-20e5ef0a-d78b-4de7-9269-e44e405c52fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40101,DS-b8567fdb-8bec-494e-963b-faa8506a7850,DISK], DatanodeInfoWithStorage[127.0.0.1:43120,DS-65226045-22a6-4ec4-8e37-81c4f12bca9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38568,DS-e15eb2ca-0352-442e-a7a9-4af897150668,DISK], DatanodeInfoWithStorage[127.0.0.1:45628,DS-19e5de54-c266-4bda-b840-dd714a954c97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.accesstime.precision
component: hdfs:NameNode
v1: 36
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1728295098-172.17.0.3-1597468926838:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38692,DS-1705b26e-cd0c-451f-9206-254182a396c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43588,DS-a85ea52b-5c08-4668-9af3-08ada41aba03,DISK], DatanodeInfoWithStorage[127.0.0.1:44152,DS-40ce2b24-d773-4c30-a88c-5d1839d1ebf3,DISK], DatanodeInfoWithStorage[127.0.0.1:45905,DS-c1e1bc5c-5fe8-4853-b5aa-483f96171345,DISK], DatanodeInfoWithStorage[127.0.0.1:39572,DS-5bbe0f03-90c5-4896-bf48-e9c6586a3d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:37704,DS-545687c6-cf93-4cd3-a4b8-363bb9354240,DISK], DatanodeInfoWithStorage[127.0.0.1:35247,DS-535c71cd-9dfc-4a6b-ad5d-6af71363a811,DISK], DatanodeInfoWithStorage[127.0.0.1:46204,DS-593e07df-57f9-4eff-ac78-b5fe1b997f71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1728295098-172.17.0.3-1597468926838:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38692,DS-1705b26e-cd0c-451f-9206-254182a396c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43588,DS-a85ea52b-5c08-4668-9af3-08ada41aba03,DISK], DatanodeInfoWithStorage[127.0.0.1:44152,DS-40ce2b24-d773-4c30-a88c-5d1839d1ebf3,DISK], DatanodeInfoWithStorage[127.0.0.1:45905,DS-c1e1bc5c-5fe8-4853-b5aa-483f96171345,DISK], DatanodeInfoWithStorage[127.0.0.1:39572,DS-5bbe0f03-90c5-4896-bf48-e9c6586a3d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:37704,DS-545687c6-cf93-4cd3-a4b8-363bb9354240,DISK], DatanodeInfoWithStorage[127.0.0.1:35247,DS-535c71cd-9dfc-4a6b-ad5d-6af71363a811,DISK], DatanodeInfoWithStorage[127.0.0.1:46204,DS-593e07df-57f9-4eff-ac78-b5fe1b997f71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.accesstime.precision
component: hdfs:NameNode
v1: 36
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1122595132-172.17.0.3-1597469030715:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36844,DS-47fa4925-73c2-4197-9456-ee80d614d38a,DISK], DatanodeInfoWithStorage[127.0.0.1:44637,DS-603365e1-4be6-4dd6-acaf-b4c07b9a1400,DISK], DatanodeInfoWithStorage[127.0.0.1:35189,DS-efa2fe15-705d-4c59-aafb-61b7e55d1a88,DISK], DatanodeInfoWithStorage[127.0.0.1:33228,DS-ef3e5db8-94e8-40ff-b3eb-0a571d22290c,DISK], DatanodeInfoWithStorage[127.0.0.1:34399,DS-f5884803-015e-4373-9281-1e2de3de4335,DISK], DatanodeInfoWithStorage[127.0.0.1:42859,DS-77144260-9140-4be9-9f2f-dcd46bfdbbfd,DISK], DatanodeInfoWithStorage[127.0.0.1:39058,DS-48571cdd-897d-482c-b82f-566e4b0bb755,DISK], DatanodeInfoWithStorage[127.0.0.1:35830,DS-4c24ea70-9b33-46e5-9074-3de360481859,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1122595132-172.17.0.3-1597469030715:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36844,DS-47fa4925-73c2-4197-9456-ee80d614d38a,DISK], DatanodeInfoWithStorage[127.0.0.1:44637,DS-603365e1-4be6-4dd6-acaf-b4c07b9a1400,DISK], DatanodeInfoWithStorage[127.0.0.1:35189,DS-efa2fe15-705d-4c59-aafb-61b7e55d1a88,DISK], DatanodeInfoWithStorage[127.0.0.1:33228,DS-ef3e5db8-94e8-40ff-b3eb-0a571d22290c,DISK], DatanodeInfoWithStorage[127.0.0.1:34399,DS-f5884803-015e-4373-9281-1e2de3de4335,DISK], DatanodeInfoWithStorage[127.0.0.1:42859,DS-77144260-9140-4be9-9f2f-dcd46bfdbbfd,DISK], DatanodeInfoWithStorage[127.0.0.1:39058,DS-48571cdd-897d-482c-b82f-566e4b0bb755,DISK], DatanodeInfoWithStorage[127.0.0.1:35830,DS-4c24ea70-9b33-46e5-9074-3de360481859,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.accesstime.precision
component: hdfs:NameNode
v1: 36
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2007620124-172.17.0.3-1597469247346:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46126,DS-535a3819-50a9-4af6-90a4-e05b1e90c8de,DISK], DatanodeInfoWithStorage[127.0.0.1:46587,DS-8cf444af-0661-4d37-a785-443b0cb655c7,DISK], DatanodeInfoWithStorage[127.0.0.1:32901,DS-c7566ba1-221d-4321-b5e8-f2e4231f807f,DISK], DatanodeInfoWithStorage[127.0.0.1:42952,DS-3a5502a5-69a3-4c5a-b846-c832bed9abe1,DISK], DatanodeInfoWithStorage[127.0.0.1:44480,DS-d39d8dff-e632-42aa-b353-85ecc050de94,DISK], DatanodeInfoWithStorage[127.0.0.1:36162,DS-22d15647-aac1-4a65-992c-b3bec8458a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:36963,DS-58c43c78-a282-4778-8ace-b6e417095f09,DISK], DatanodeInfoWithStorage[127.0.0.1:37054,DS-5daaffcc-e653-49a4-97e9-b20eb4f21005,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2007620124-172.17.0.3-1597469247346:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46126,DS-535a3819-50a9-4af6-90a4-e05b1e90c8de,DISK], DatanodeInfoWithStorage[127.0.0.1:46587,DS-8cf444af-0661-4d37-a785-443b0cb655c7,DISK], DatanodeInfoWithStorage[127.0.0.1:32901,DS-c7566ba1-221d-4321-b5e8-f2e4231f807f,DISK], DatanodeInfoWithStorage[127.0.0.1:42952,DS-3a5502a5-69a3-4c5a-b846-c832bed9abe1,DISK], DatanodeInfoWithStorage[127.0.0.1:44480,DS-d39d8dff-e632-42aa-b353-85ecc050de94,DISK], DatanodeInfoWithStorage[127.0.0.1:36162,DS-22d15647-aac1-4a65-992c-b3bec8458a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:36963,DS-58c43c78-a282-4778-8ace-b6e417095f09,DISK], DatanodeInfoWithStorage[127.0.0.1:37054,DS-5daaffcc-e653-49a4-97e9-b20eb4f21005,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.accesstime.precision
component: hdfs:NameNode
v1: 36
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1067309365-172.17.0.3-1597469540744:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33654,DS-f1e84634-9a03-490e-a1bc-67d179968fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:45855,DS-ae81c2eb-6cf5-4ab0-896d-3d025555e9d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37088,DS-f98a0944-440c-4912-8ea3-78b0c07062fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42916,DS-8ea2981c-67ea-4773-8fb8-4c68117472d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45902,DS-6795d620-da51-4e0e-8e3f-f2b0b68e6ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:34126,DS-8d6be66c-5bbe-4d18-ba9b-3b209acae5af,DISK], DatanodeInfoWithStorage[127.0.0.1:33876,DS-2751ac1b-ea8b-4345-bfc6-5af8804cd380,DISK], DatanodeInfoWithStorage[127.0.0.1:34152,DS-2036a509-7ed0-4cfe-92ca-5a48fa579e3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1067309365-172.17.0.3-1597469540744:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33654,DS-f1e84634-9a03-490e-a1bc-67d179968fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:45855,DS-ae81c2eb-6cf5-4ab0-896d-3d025555e9d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37088,DS-f98a0944-440c-4912-8ea3-78b0c07062fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42916,DS-8ea2981c-67ea-4773-8fb8-4c68117472d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45902,DS-6795d620-da51-4e0e-8e3f-f2b0b68e6ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:34126,DS-8d6be66c-5bbe-4d18-ba9b-3b209acae5af,DISK], DatanodeInfoWithStorage[127.0.0.1:33876,DS-2751ac1b-ea8b-4345-bfc6-5af8804cd380,DISK], DatanodeInfoWithStorage[127.0.0.1:34152,DS-2036a509-7ed0-4cfe-92ca-5a48fa579e3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.accesstime.precision
component: hdfs:NameNode
v1: 36
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-392695383-172.17.0.3-1597469882490:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43521,DS-b323f56c-a94e-4482-a561-79ebb7851654,DISK], DatanodeInfoWithStorage[127.0.0.1:42143,DS-6dbb7d84-dfc6-4c99-9f1e-62c293935b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:38544,DS-0fdf85c5-b6f2-4e52-adea-6b89d1d9355e,DISK], DatanodeInfoWithStorage[127.0.0.1:36364,DS-65a7bb4a-730d-459f-9bd8-41078aa590c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41661,DS-f8ff4fb0-1d13-417a-af0b-403c0a20052f,DISK], DatanodeInfoWithStorage[127.0.0.1:43913,DS-bd1eb0e2-86c1-474e-ae79-febaea0ba76e,DISK], DatanodeInfoWithStorage[127.0.0.1:36997,DS-9e490cc4-fc2f-4f85-a94a-745fa0570307,DISK], DatanodeInfoWithStorage[127.0.0.1:36050,DS-31faea40-4adb-4a24-b9fe-59b9b3eccbde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-392695383-172.17.0.3-1597469882490:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43521,DS-b323f56c-a94e-4482-a561-79ebb7851654,DISK], DatanodeInfoWithStorage[127.0.0.1:42143,DS-6dbb7d84-dfc6-4c99-9f1e-62c293935b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:38544,DS-0fdf85c5-b6f2-4e52-adea-6b89d1d9355e,DISK], DatanodeInfoWithStorage[127.0.0.1:36364,DS-65a7bb4a-730d-459f-9bd8-41078aa590c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41661,DS-f8ff4fb0-1d13-417a-af0b-403c0a20052f,DISK], DatanodeInfoWithStorage[127.0.0.1:43913,DS-bd1eb0e2-86c1-474e-ae79-febaea0ba76e,DISK], DatanodeInfoWithStorage[127.0.0.1:36997,DS-9e490cc4-fc2f-4f85-a94a-745fa0570307,DISK], DatanodeInfoWithStorage[127.0.0.1:36050,DS-31faea40-4adb-4a24-b9fe-59b9b3eccbde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.accesstime.precision
component: hdfs:NameNode
v1: 36
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1419353754-172.17.0.3-1597470021586:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33153,DS-dc9c9251-9fe0-43b3-9e6d-c2cc1063d964,DISK], DatanodeInfoWithStorage[127.0.0.1:38555,DS-af3131e9-5f66-4ad6-a34b-558a631ca48d,DISK], DatanodeInfoWithStorage[127.0.0.1:44859,DS-4f075ddd-f785-4688-909e-ed958370fc8e,DISK], DatanodeInfoWithStorage[127.0.0.1:46833,DS-e6757f2d-990d-45f8-af48-4a7ace8262ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42892,DS-b8be8a03-26c5-4e2c-8a51-e16bc1c2b234,DISK], DatanodeInfoWithStorage[127.0.0.1:40565,DS-633b28d3-6b91-4a2e-8b0b-c1c7d6e607c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39606,DS-3f0cde82-2421-43c8-9cf3-f9c0d0939081,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-f6b9c971-2525-4a17-affd-226402c73689,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1419353754-172.17.0.3-1597470021586:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33153,DS-dc9c9251-9fe0-43b3-9e6d-c2cc1063d964,DISK], DatanodeInfoWithStorage[127.0.0.1:38555,DS-af3131e9-5f66-4ad6-a34b-558a631ca48d,DISK], DatanodeInfoWithStorage[127.0.0.1:44859,DS-4f075ddd-f785-4688-909e-ed958370fc8e,DISK], DatanodeInfoWithStorage[127.0.0.1:46833,DS-e6757f2d-990d-45f8-af48-4a7ace8262ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42892,DS-b8be8a03-26c5-4e2c-8a51-e16bc1c2b234,DISK], DatanodeInfoWithStorage[127.0.0.1:40565,DS-633b28d3-6b91-4a2e-8b0b-c1c7d6e607c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39606,DS-3f0cde82-2421-43c8-9cf3-f9c0d0939081,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-f6b9c971-2525-4a17-affd-226402c73689,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.accesstime.precision
component: hdfs:NameNode
v1: 36
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-72448875-172.17.0.3-1597470363964:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39057,DS-3e19bec5-d558-4f99-ba51-685834b33772,DISK], DatanodeInfoWithStorage[127.0.0.1:39985,DS-0fc1f1d7-898a-452d-9441-c6fbc600e798,DISK], DatanodeInfoWithStorage[127.0.0.1:35765,DS-15caafe3-86fc-4b19-b6dc-f2150899fcda,DISK], DatanodeInfoWithStorage[127.0.0.1:38951,DS-eaa6de73-72e1-4ef3-a356-26be1b644d07,DISK], DatanodeInfoWithStorage[127.0.0.1:36393,DS-1c23ebc6-4eef-43a6-8b3e-34bbcbf1b39c,DISK], DatanodeInfoWithStorage[127.0.0.1:46673,DS-163cf345-bace-47f2-88f6-72aee044be82,DISK], DatanodeInfoWithStorage[127.0.0.1:35471,DS-86b87469-84b0-4822-b054-30235ca7971f,DISK], DatanodeInfoWithStorage[127.0.0.1:40091,DS-1c92709d-a630-4f99-b6f9-fc9db782ba9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-72448875-172.17.0.3-1597470363964:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39057,DS-3e19bec5-d558-4f99-ba51-685834b33772,DISK], DatanodeInfoWithStorage[127.0.0.1:39985,DS-0fc1f1d7-898a-452d-9441-c6fbc600e798,DISK], DatanodeInfoWithStorage[127.0.0.1:35765,DS-15caafe3-86fc-4b19-b6dc-f2150899fcda,DISK], DatanodeInfoWithStorage[127.0.0.1:38951,DS-eaa6de73-72e1-4ef3-a356-26be1b644d07,DISK], DatanodeInfoWithStorage[127.0.0.1:36393,DS-1c23ebc6-4eef-43a6-8b3e-34bbcbf1b39c,DISK], DatanodeInfoWithStorage[127.0.0.1:46673,DS-163cf345-bace-47f2-88f6-72aee044be82,DISK], DatanodeInfoWithStorage[127.0.0.1:35471,DS-86b87469-84b0-4822-b054-30235ca7971f,DISK], DatanodeInfoWithStorage[127.0.0.1:40091,DS-1c92709d-a630-4f99-b6f9-fc9db782ba9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.accesstime.precision
component: hdfs:NameNode
v1: 36
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1131232785-172.17.0.3-1597470404637:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34823,DS-4cdaf177-ff51-4ca3-8c7b-6c4b026546c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37874,DS-ca551b12-41d6-4bd5-a6e8-71e411192a97,DISK], DatanodeInfoWithStorage[127.0.0.1:40486,DS-955ea604-6622-485e-9a5c-b071722a9976,DISK], DatanodeInfoWithStorage[127.0.0.1:46361,DS-f2dd3717-7f8e-42b5-88cc-173c6c61e084,DISK], DatanodeInfoWithStorage[127.0.0.1:34822,DS-121f607e-16ea-4835-bfb0-d88f1ae95e24,DISK], DatanodeInfoWithStorage[127.0.0.1:34161,DS-f986d9d7-b26c-4121-aea4-b9391aa5483d,DISK], DatanodeInfoWithStorage[127.0.0.1:33714,DS-6573eee9-d457-49c0-8e69-f03efd0dcdf5,DISK], DatanodeInfoWithStorage[127.0.0.1:40766,DS-3294434d-9175-4f22-ad10-eec37db70d5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1131232785-172.17.0.3-1597470404637:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34823,DS-4cdaf177-ff51-4ca3-8c7b-6c4b026546c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37874,DS-ca551b12-41d6-4bd5-a6e8-71e411192a97,DISK], DatanodeInfoWithStorage[127.0.0.1:40486,DS-955ea604-6622-485e-9a5c-b071722a9976,DISK], DatanodeInfoWithStorage[127.0.0.1:46361,DS-f2dd3717-7f8e-42b5-88cc-173c6c61e084,DISK], DatanodeInfoWithStorage[127.0.0.1:34822,DS-121f607e-16ea-4835-bfb0-d88f1ae95e24,DISK], DatanodeInfoWithStorage[127.0.0.1:34161,DS-f986d9d7-b26c-4121-aea4-b9391aa5483d,DISK], DatanodeInfoWithStorage[127.0.0.1:33714,DS-6573eee9-d457-49c0-8e69-f03efd0dcdf5,DISK], DatanodeInfoWithStorage[127.0.0.1:40766,DS-3294434d-9175-4f22-ad10-eec37db70d5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.accesstime.precision
component: hdfs:NameNode
v1: 36
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-645833430-172.17.0.3-1597470444306:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41511,DS-f4ac5d0e-435a-4820-95bd-0e8d1e203141,DISK], DatanodeInfoWithStorage[127.0.0.1:36922,DS-96e4d4a8-ca71-4b2d-9329-c3688e9264da,DISK], DatanodeInfoWithStorage[127.0.0.1:39964,DS-657e0078-0c0b-4faf-9afd-f9761a8fdc3f,DISK], DatanodeInfoWithStorage[127.0.0.1:35213,DS-000e48bc-7f5b-4bd2-8c84-42c8bdc5d2a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33471,DS-28082745-bd0a-4d74-a2b5-113c99430084,DISK], DatanodeInfoWithStorage[127.0.0.1:45930,DS-c00c7c79-1410-4e1f-86a5-0e32fdf89e58,DISK], DatanodeInfoWithStorage[127.0.0.1:35826,DS-bb146052-b605-4ddb-b3ab-b35aa1941683,DISK], DatanodeInfoWithStorage[127.0.0.1:38118,DS-760d17cd-03b3-468a-ac0f-e7c83b026378,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-645833430-172.17.0.3-1597470444306:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41511,DS-f4ac5d0e-435a-4820-95bd-0e8d1e203141,DISK], DatanodeInfoWithStorage[127.0.0.1:36922,DS-96e4d4a8-ca71-4b2d-9329-c3688e9264da,DISK], DatanodeInfoWithStorage[127.0.0.1:39964,DS-657e0078-0c0b-4faf-9afd-f9761a8fdc3f,DISK], DatanodeInfoWithStorage[127.0.0.1:35213,DS-000e48bc-7f5b-4bd2-8c84-42c8bdc5d2a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33471,DS-28082745-bd0a-4d74-a2b5-113c99430084,DISK], DatanodeInfoWithStorage[127.0.0.1:45930,DS-c00c7c79-1410-4e1f-86a5-0e32fdf89e58,DISK], DatanodeInfoWithStorage[127.0.0.1:35826,DS-bb146052-b605-4ddb-b3ab-b35aa1941683,DISK], DatanodeInfoWithStorage[127.0.0.1:38118,DS-760d17cd-03b3-468a-ac0f-e7c83b026378,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.accesstime.precision
component: hdfs:NameNode
v1: 36
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-889030591-172.17.0.3-1597470672339:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42579,DS-68d90af7-aada-42c6-b942-b3c78fd8bba6,DISK], DatanodeInfoWithStorage[127.0.0.1:38303,DS-584e3175-e3e7-4bc7-abaa-5c8d04dc8576,DISK], DatanodeInfoWithStorage[127.0.0.1:36054,DS-528f603e-02db-452d-8e1c-0bc53aeb80a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40801,DS-52d29c66-089c-4993-b680-b3d792646328,DISK], DatanodeInfoWithStorage[127.0.0.1:32776,DS-f8197f35-6479-4091-b0ea-41a4f26c603b,DISK], DatanodeInfoWithStorage[127.0.0.1:37960,DS-89ac21b3-e54f-4610-9bba-541097d7aa6f,DISK], DatanodeInfoWithStorage[127.0.0.1:42439,DS-e1eada67-931f-4582-acb7-f53aeff0df5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45611,DS-bd267f3b-c460-4bf5-8359-2659e5dff2be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-889030591-172.17.0.3-1597470672339:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42579,DS-68d90af7-aada-42c6-b942-b3c78fd8bba6,DISK], DatanodeInfoWithStorage[127.0.0.1:38303,DS-584e3175-e3e7-4bc7-abaa-5c8d04dc8576,DISK], DatanodeInfoWithStorage[127.0.0.1:36054,DS-528f603e-02db-452d-8e1c-0bc53aeb80a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40801,DS-52d29c66-089c-4993-b680-b3d792646328,DISK], DatanodeInfoWithStorage[127.0.0.1:32776,DS-f8197f35-6479-4091-b0ea-41a4f26c603b,DISK], DatanodeInfoWithStorage[127.0.0.1:37960,DS-89ac21b3-e54f-4610-9bba-541097d7aa6f,DISK], DatanodeInfoWithStorage[127.0.0.1:42439,DS-e1eada67-931f-4582-acb7-f53aeff0df5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45611,DS-bd267f3b-c460-4bf5-8359-2659e5dff2be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.accesstime.precision
component: hdfs:NameNode
v1: 36
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1142500977-172.17.0.3-1597471328694:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33970,DS-24763742-685a-4a87-8f1f-88579aff6d06,DISK], DatanodeInfoWithStorage[127.0.0.1:36935,DS-6f429dd3-97f7-4ad9-b8f9-5624fdbf2d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33156,DS-91c3d089-8a5e-4741-ae36-4d159a8d31f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45178,DS-197fa109-0f34-46b1-8881-874288a026b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40121,DS-aad0bd28-cd31-4f2d-8256-34a9eda76a15,DISK], DatanodeInfoWithStorage[127.0.0.1:35029,DS-ebf6077b-2f2a-4e4e-bd42-d277dedc6551,DISK], DatanodeInfoWithStorage[127.0.0.1:37609,DS-b99f2213-d31b-4cb4-8def-2f8eef396945,DISK], DatanodeInfoWithStorage[127.0.0.1:36516,DS-07a3cb43-bfdd-4a27-8afb-4a2e5220f654,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1142500977-172.17.0.3-1597471328694:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33970,DS-24763742-685a-4a87-8f1f-88579aff6d06,DISK], DatanodeInfoWithStorage[127.0.0.1:36935,DS-6f429dd3-97f7-4ad9-b8f9-5624fdbf2d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33156,DS-91c3d089-8a5e-4741-ae36-4d159a8d31f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45178,DS-197fa109-0f34-46b1-8881-874288a026b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40121,DS-aad0bd28-cd31-4f2d-8256-34a9eda76a15,DISK], DatanodeInfoWithStorage[127.0.0.1:35029,DS-ebf6077b-2f2a-4e4e-bd42-d277dedc6551,DISK], DatanodeInfoWithStorage[127.0.0.1:37609,DS-b99f2213-d31b-4cb4-8def-2f8eef396945,DISK], DatanodeInfoWithStorage[127.0.0.1:36516,DS-07a3cb43-bfdd-4a27-8afb-4a2e5220f654,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.accesstime.precision
component: hdfs:NameNode
v1: 36
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-393677815-172.17.0.3-1597471891985:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41333,DS-41ad9e93-8acc-4966-a4bb-c6d08f4795da,DISK], DatanodeInfoWithStorage[127.0.0.1:41026,DS-db62f4ee-7829-4f91-a4ba-2e3cefda5f59,DISK], DatanodeInfoWithStorage[127.0.0.1:35339,DS-1fda0ab6-6256-4e7e-968f-8634c24f1833,DISK], DatanodeInfoWithStorage[127.0.0.1:34641,DS-e7b31653-7dda-4ed1-9791-aa6f99570206,DISK], DatanodeInfoWithStorage[127.0.0.1:40320,DS-3b1adc3b-5837-4c0b-8d6d-08446463c06c,DISK], DatanodeInfoWithStorage[127.0.0.1:45864,DS-5d98d2b8-10d6-404e-9f46-8a144eb55ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:33013,DS-94bce60c-d459-4dee-8430-8cdcdd546533,DISK], DatanodeInfoWithStorage[127.0.0.1:40257,DS-94e833af-e638-4b50-8354-0e877e9a3883,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-393677815-172.17.0.3-1597471891985:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41333,DS-41ad9e93-8acc-4966-a4bb-c6d08f4795da,DISK], DatanodeInfoWithStorage[127.0.0.1:41026,DS-db62f4ee-7829-4f91-a4ba-2e3cefda5f59,DISK], DatanodeInfoWithStorage[127.0.0.1:35339,DS-1fda0ab6-6256-4e7e-968f-8634c24f1833,DISK], DatanodeInfoWithStorage[127.0.0.1:34641,DS-e7b31653-7dda-4ed1-9791-aa6f99570206,DISK], DatanodeInfoWithStorage[127.0.0.1:40320,DS-3b1adc3b-5837-4c0b-8d6d-08446463c06c,DISK], DatanodeInfoWithStorage[127.0.0.1:45864,DS-5d98d2b8-10d6-404e-9f46-8a144eb55ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:33013,DS-94bce60c-d459-4dee-8430-8cdcdd546533,DISK], DatanodeInfoWithStorage[127.0.0.1:40257,DS-94e833af-e638-4b50-8354-0e877e9a3883,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.accesstime.precision
component: hdfs:NameNode
v1: 36
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1387255922-172.17.0.3-1597472508247:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42830,DS-5453bce8-bb78-4ef4-9543-37fc9d862c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:38987,DS-791e26f4-1161-4999-a8be-c27b8cbf6617,DISK], DatanodeInfoWithStorage[127.0.0.1:34256,DS-67166f26-3469-4f65-a026-d1b468ec34b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40453,DS-3f36a252-c481-41b0-970d-2e2c101be766,DISK], DatanodeInfoWithStorage[127.0.0.1:41869,DS-8652ec6c-1032-45e2-a6be-73b983f3fbb5,DISK], DatanodeInfoWithStorage[127.0.0.1:41736,DS-5af41522-cd4d-47a6-ae65-a7ba35c8f614,DISK], DatanodeInfoWithStorage[127.0.0.1:36207,DS-291db9ea-f5db-4f5a-8717-4cb7e858e182,DISK], DatanodeInfoWithStorage[127.0.0.1:33327,DS-fe883b88-3e63-46aa-b62f-4b55869f757b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1387255922-172.17.0.3-1597472508247:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42830,DS-5453bce8-bb78-4ef4-9543-37fc9d862c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:38987,DS-791e26f4-1161-4999-a8be-c27b8cbf6617,DISK], DatanodeInfoWithStorage[127.0.0.1:34256,DS-67166f26-3469-4f65-a026-d1b468ec34b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40453,DS-3f36a252-c481-41b0-970d-2e2c101be766,DISK], DatanodeInfoWithStorage[127.0.0.1:41869,DS-8652ec6c-1032-45e2-a6be-73b983f3fbb5,DISK], DatanodeInfoWithStorage[127.0.0.1:41736,DS-5af41522-cd4d-47a6-ae65-a7ba35c8f614,DISK], DatanodeInfoWithStorage[127.0.0.1:36207,DS-291db9ea-f5db-4f5a-8717-4cb7e858e182,DISK], DatanodeInfoWithStorage[127.0.0.1:33327,DS-fe883b88-3e63-46aa-b62f-4b55869f757b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.accesstime.precision
component: hdfs:NameNode
v1: 36
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-871081236-172.17.0.3-1597472707135:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45795,DS-26f40317-86d4-4852-85c4-086639d3e0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45664,DS-37662c6e-2d1c-4037-b8ec-0cdbb0fbd5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34152,DS-7a4be4c2-5c76-498e-a924-19cd4d8aa095,DISK], DatanodeInfoWithStorage[127.0.0.1:44386,DS-4fcbced2-c428-43c8-ba5b-1a515a8e002f,DISK], DatanodeInfoWithStorage[127.0.0.1:37428,DS-f2b8b056-5b17-4e3f-b0b3-94967cb3482e,DISK], DatanodeInfoWithStorage[127.0.0.1:40214,DS-c21c4c7d-776b-4f4d-b34b-542495790a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:36077,DS-6837c189-2c3b-4a3f-bb74-0bb18d7959c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41815,DS-4e228477-2bcb-4822-88a0-60c2899767f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-871081236-172.17.0.3-1597472707135:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45795,DS-26f40317-86d4-4852-85c4-086639d3e0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45664,DS-37662c6e-2d1c-4037-b8ec-0cdbb0fbd5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34152,DS-7a4be4c2-5c76-498e-a924-19cd4d8aa095,DISK], DatanodeInfoWithStorage[127.0.0.1:44386,DS-4fcbced2-c428-43c8-ba5b-1a515a8e002f,DISK], DatanodeInfoWithStorage[127.0.0.1:37428,DS-f2b8b056-5b17-4e3f-b0b3-94967cb3482e,DISK], DatanodeInfoWithStorage[127.0.0.1:40214,DS-c21c4c7d-776b-4f4d-b34b-542495790a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:36077,DS-6837c189-2c3b-4a3f-bb74-0bb18d7959c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41815,DS-4e228477-2bcb-4822-88a0-60c2899767f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.accesstime.precision
component: hdfs:NameNode
v1: 36
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-220836142-172.17.0.3-1597473089145:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38952,DS-be661a2d-29e9-4fce-abfd-38a62646debb,DISK], DatanodeInfoWithStorage[127.0.0.1:37914,DS-6ff04942-922c-4b2c-84ee-9f887fc975e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41062,DS-aa98b5b0-2bd9-425a-8bdf-667abc0c90c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46018,DS-d005e033-2f50-4bde-b214-78bf6c65f3f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42541,DS-e3f06424-644a-4a40-912d-d9fc82edea0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37905,DS-9afc7ab5-c7ea-4a2b-8fd8-c734554c816e,DISK], DatanodeInfoWithStorage[127.0.0.1:40735,DS-3dd952ff-3093-4b75-af7d-d92ff05eb18f,DISK], DatanodeInfoWithStorage[127.0.0.1:43487,DS-3443687b-c68d-40c6-bce8-8397f0193290,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-220836142-172.17.0.3-1597473089145:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38952,DS-be661a2d-29e9-4fce-abfd-38a62646debb,DISK], DatanodeInfoWithStorage[127.0.0.1:37914,DS-6ff04942-922c-4b2c-84ee-9f887fc975e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41062,DS-aa98b5b0-2bd9-425a-8bdf-667abc0c90c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46018,DS-d005e033-2f50-4bde-b214-78bf6c65f3f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42541,DS-e3f06424-644a-4a40-912d-d9fc82edea0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37905,DS-9afc7ab5-c7ea-4a2b-8fd8-c734554c816e,DISK], DatanodeInfoWithStorage[127.0.0.1:40735,DS-3dd952ff-3093-4b75-af7d-d92ff05eb18f,DISK], DatanodeInfoWithStorage[127.0.0.1:43487,DS-3443687b-c68d-40c6-bce8-8397f0193290,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5564
