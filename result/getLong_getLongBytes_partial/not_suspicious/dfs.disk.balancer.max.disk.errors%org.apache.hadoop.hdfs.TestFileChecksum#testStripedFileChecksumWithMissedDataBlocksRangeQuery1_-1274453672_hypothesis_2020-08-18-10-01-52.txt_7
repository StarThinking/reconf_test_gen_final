reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-413479419-172.17.0.21-1597745157820:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43596,DS-72a67f49-6822-4e45-a22a-0e6ccf07104a,DISK], DatanodeInfoWithStorage[127.0.0.1:33802,DS-64be3d03-6a37-4aee-b203-2f6f722e04b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43246,DS-bf2666c4-dded-4b8a-8919-dca2d2bde9c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44527,DS-01c72f8d-5cbe-4da6-8811-cf423c226e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35177,DS-3de1db77-358d-4557-b335-caefdea1c299,DISK], DatanodeInfoWithStorage[127.0.0.1:46664,DS-49a6b042-f400-4237-bdab-2f8359968252,DISK], DatanodeInfoWithStorage[127.0.0.1:44644,DS-603b2ebf-9fb6-40f4-a174-87d58159bc9c,DISK], DatanodeInfoWithStorage[127.0.0.1:38871,DS-5944a6d7-f1a4-42ff-ba4c-8bea9852b651,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-413479419-172.17.0.21-1597745157820:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43596,DS-72a67f49-6822-4e45-a22a-0e6ccf07104a,DISK], DatanodeInfoWithStorage[127.0.0.1:33802,DS-64be3d03-6a37-4aee-b203-2f6f722e04b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43246,DS-bf2666c4-dded-4b8a-8919-dca2d2bde9c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44527,DS-01c72f8d-5cbe-4da6-8811-cf423c226e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35177,DS-3de1db77-358d-4557-b335-caefdea1c299,DISK], DatanodeInfoWithStorage[127.0.0.1:46664,DS-49a6b042-f400-4237-bdab-2f8359968252,DISK], DatanodeInfoWithStorage[127.0.0.1:44644,DS-603b2ebf-9fb6-40f4-a174-87d58159bc9c,DISK], DatanodeInfoWithStorage[127.0.0.1:38871,DS-5944a6d7-f1a4-42ff-ba4c-8bea9852b651,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-223408707-172.17.0.21-1597745233075:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39460,DS-bb46a363-cf36-4680-830b-2033fe7bc687,DISK], DatanodeInfoWithStorage[127.0.0.1:40439,DS-0b2f5356-be7d-48a1-ba85-9c1cad86b7ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44282,DS-f4b698bc-56f2-4413-bdfa-9689b33b69be,DISK], DatanodeInfoWithStorage[127.0.0.1:37041,DS-33ce5f5e-0fdd-4715-8051-357099f2970e,DISK], DatanodeInfoWithStorage[127.0.0.1:37377,DS-692d28cd-cc73-4416-abf1-1ff651fa27b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34948,DS-fc02ff2c-1055-40c0-bbac-fb89294ae4ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35184,DS-0c09d51f-2a67-4e83-95fc-d0da9e943391,DISK], DatanodeInfoWithStorage[127.0.0.1:32930,DS-f711ab69-32eb-466f-8f5f-db12cf3bf258,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-223408707-172.17.0.21-1597745233075:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39460,DS-bb46a363-cf36-4680-830b-2033fe7bc687,DISK], DatanodeInfoWithStorage[127.0.0.1:40439,DS-0b2f5356-be7d-48a1-ba85-9c1cad86b7ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44282,DS-f4b698bc-56f2-4413-bdfa-9689b33b69be,DISK], DatanodeInfoWithStorage[127.0.0.1:37041,DS-33ce5f5e-0fdd-4715-8051-357099f2970e,DISK], DatanodeInfoWithStorage[127.0.0.1:37377,DS-692d28cd-cc73-4416-abf1-1ff651fa27b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34948,DS-fc02ff2c-1055-40c0-bbac-fb89294ae4ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35184,DS-0c09d51f-2a67-4e83-95fc-d0da9e943391,DISK], DatanodeInfoWithStorage[127.0.0.1:32930,DS-f711ab69-32eb-466f-8f5f-db12cf3bf258,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-535019403-172.17.0.21-1597745273179:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41647,DS-2aa40fa5-bbb5-47ce-add7-1a95a9a099aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40654,DS-36f62c07-43c3-496d-9c84-3da1c90d47d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46619,DS-60f225a4-ee08-4c3f-8827-7487be750693,DISK], DatanodeInfoWithStorage[127.0.0.1:39815,DS-ba389ac6-0e53-4ee0-b7db-a4a68e77ebfd,DISK], DatanodeInfoWithStorage[127.0.0.1:42107,DS-f024514d-41a9-4e23-9f60-9db69b81e0b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37975,DS-55aa9eae-96ca-44d5-9e68-80bef7417836,DISK], DatanodeInfoWithStorage[127.0.0.1:40104,DS-4513f9d8-853e-476a-8232-01d683ec3bde,DISK], DatanodeInfoWithStorage[127.0.0.1:43678,DS-c8f14fbb-e5bc-42b2-9144-3e01b70b7ee1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-535019403-172.17.0.21-1597745273179:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41647,DS-2aa40fa5-bbb5-47ce-add7-1a95a9a099aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40654,DS-36f62c07-43c3-496d-9c84-3da1c90d47d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46619,DS-60f225a4-ee08-4c3f-8827-7487be750693,DISK], DatanodeInfoWithStorage[127.0.0.1:39815,DS-ba389ac6-0e53-4ee0-b7db-a4a68e77ebfd,DISK], DatanodeInfoWithStorage[127.0.0.1:42107,DS-f024514d-41a9-4e23-9f60-9db69b81e0b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37975,DS-55aa9eae-96ca-44d5-9e68-80bef7417836,DISK], DatanodeInfoWithStorage[127.0.0.1:40104,DS-4513f9d8-853e-476a-8232-01d683ec3bde,DISK], DatanodeInfoWithStorage[127.0.0.1:43678,DS-c8f14fbb-e5bc-42b2-9144-3e01b70b7ee1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1804454066-172.17.0.21-1597745355621:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34728,DS-296b69ce-5520-4588-996d-2d4cb847a202,DISK], DatanodeInfoWithStorage[127.0.0.1:42380,DS-7ea292e1-9fde-4df2-9a61-f622e9138b49,DISK], DatanodeInfoWithStorage[127.0.0.1:36319,DS-668514ff-ddad-46c2-bc16-94df2fd111bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45528,DS-c8ce0e49-5e79-42a1-b47d-701deef390e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-046c530b-1976-4592-8100-bd95e3e6cbb4,DISK], DatanodeInfoWithStorage[127.0.0.1:43264,DS-f4059261-6602-4064-b56b-aab083211fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:36699,DS-67b0b18b-b49c-4dd1-9f8f-a9d6c1fc5c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:38571,DS-b29a6894-cb23-48bb-9c67-a632196c8dfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1804454066-172.17.0.21-1597745355621:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34728,DS-296b69ce-5520-4588-996d-2d4cb847a202,DISK], DatanodeInfoWithStorage[127.0.0.1:42380,DS-7ea292e1-9fde-4df2-9a61-f622e9138b49,DISK], DatanodeInfoWithStorage[127.0.0.1:36319,DS-668514ff-ddad-46c2-bc16-94df2fd111bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45528,DS-c8ce0e49-5e79-42a1-b47d-701deef390e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-046c530b-1976-4592-8100-bd95e3e6cbb4,DISK], DatanodeInfoWithStorage[127.0.0.1:43264,DS-f4059261-6602-4064-b56b-aab083211fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:36699,DS-67b0b18b-b49c-4dd1-9f8f-a9d6c1fc5c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:38571,DS-b29a6894-cb23-48bb-9c67-a632196c8dfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1984662214-172.17.0.21-1597745428206:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40653,DS-08971b33-867a-4f80-967a-e0d2f9613034,DISK], DatanodeInfoWithStorage[127.0.0.1:42954,DS-89c3252c-f8c4-4352-88e7-5c11f1325096,DISK], DatanodeInfoWithStorage[127.0.0.1:37628,DS-098ce63f-8a24-4516-b2c6-800ccb7be165,DISK], DatanodeInfoWithStorage[127.0.0.1:45348,DS-94f975a2-1049-440b-9acd-6fa5b83a4c62,DISK], DatanodeInfoWithStorage[127.0.0.1:34649,DS-3aec4807-8fb3-45a4-8048-4d492e610306,DISK], DatanodeInfoWithStorage[127.0.0.1:38801,DS-ed57a64b-a26c-49ad-924e-5afbba910f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40543,DS-8ee0c026-6c9e-4982-9225-77554dcfb34c,DISK], DatanodeInfoWithStorage[127.0.0.1:35603,DS-4f670137-9ec6-46b8-939f-a1326a3552ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1984662214-172.17.0.21-1597745428206:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40653,DS-08971b33-867a-4f80-967a-e0d2f9613034,DISK], DatanodeInfoWithStorage[127.0.0.1:42954,DS-89c3252c-f8c4-4352-88e7-5c11f1325096,DISK], DatanodeInfoWithStorage[127.0.0.1:37628,DS-098ce63f-8a24-4516-b2c6-800ccb7be165,DISK], DatanodeInfoWithStorage[127.0.0.1:45348,DS-94f975a2-1049-440b-9acd-6fa5b83a4c62,DISK], DatanodeInfoWithStorage[127.0.0.1:34649,DS-3aec4807-8fb3-45a4-8048-4d492e610306,DISK], DatanodeInfoWithStorage[127.0.0.1:38801,DS-ed57a64b-a26c-49ad-924e-5afbba910f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40543,DS-8ee0c026-6c9e-4982-9225-77554dcfb34c,DISK], DatanodeInfoWithStorage[127.0.0.1:35603,DS-4f670137-9ec6-46b8-939f-a1326a3552ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2021635442-172.17.0.21-1597745548295:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41076,DS-6b34fff5-9cde-4420-b6b3-00bda5f0b80f,DISK], DatanodeInfoWithStorage[127.0.0.1:43495,DS-234dc485-e999-41f7-b3cc-ff2a53c1fa10,DISK], DatanodeInfoWithStorage[127.0.0.1:35909,DS-07dd5b76-fd18-4bcb-9339-e486451895e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38592,DS-8251a7f8-e62f-4e51-9a12-96e56f3a54f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44743,DS-46e52134-1550-443f-9ccb-2beb7a1515be,DISK], DatanodeInfoWithStorage[127.0.0.1:39279,DS-3533736e-aee2-4685-95c0-bdf671a0fb95,DISK], DatanodeInfoWithStorage[127.0.0.1:36246,DS-1a1ca890-394e-4f61-ba14-d83380b343a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44769,DS-10e134a1-ec30-42e9-8919-cef5258632a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2021635442-172.17.0.21-1597745548295:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41076,DS-6b34fff5-9cde-4420-b6b3-00bda5f0b80f,DISK], DatanodeInfoWithStorage[127.0.0.1:43495,DS-234dc485-e999-41f7-b3cc-ff2a53c1fa10,DISK], DatanodeInfoWithStorage[127.0.0.1:35909,DS-07dd5b76-fd18-4bcb-9339-e486451895e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38592,DS-8251a7f8-e62f-4e51-9a12-96e56f3a54f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44743,DS-46e52134-1550-443f-9ccb-2beb7a1515be,DISK], DatanodeInfoWithStorage[127.0.0.1:39279,DS-3533736e-aee2-4685-95c0-bdf671a0fb95,DISK], DatanodeInfoWithStorage[127.0.0.1:36246,DS-1a1ca890-394e-4f61-ba14-d83380b343a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44769,DS-10e134a1-ec30-42e9-8919-cef5258632a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1117267210-172.17.0.21-1597745893288:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45619,DS-595f6744-cb18-4f05-b3b4-c3306d5a35ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39189,DS-43a76437-1dcb-4d0b-9ac6-485f727b0a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42381,DS-7d1e4b29-0eaa-4e11-9a60-af3e20fc4983,DISK], DatanodeInfoWithStorage[127.0.0.1:36763,DS-de9cd8d5-67bd-4103-87c2-598b98fbc6c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37289,DS-787f2f1c-e504-45bf-acc8-a1938a199592,DISK], DatanodeInfoWithStorage[127.0.0.1:35222,DS-f4dcdda7-d135-4cc8-b39a-7aaceec8cd5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45586,DS-1537771f-06e1-49e1-9da2-761ce697ad31,DISK], DatanodeInfoWithStorage[127.0.0.1:37200,DS-5dd966be-6a46-4264-9ba0-bb62c9409559,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1117267210-172.17.0.21-1597745893288:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45619,DS-595f6744-cb18-4f05-b3b4-c3306d5a35ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39189,DS-43a76437-1dcb-4d0b-9ac6-485f727b0a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42381,DS-7d1e4b29-0eaa-4e11-9a60-af3e20fc4983,DISK], DatanodeInfoWithStorage[127.0.0.1:36763,DS-de9cd8d5-67bd-4103-87c2-598b98fbc6c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37289,DS-787f2f1c-e504-45bf-acc8-a1938a199592,DISK], DatanodeInfoWithStorage[127.0.0.1:35222,DS-f4dcdda7-d135-4cc8-b39a-7aaceec8cd5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45586,DS-1537771f-06e1-49e1-9da2-761ce697ad31,DISK], DatanodeInfoWithStorage[127.0.0.1:37200,DS-5dd966be-6a46-4264-9ba0-bb62c9409559,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1419220785-172.17.0.21-1597746042479:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33860,DS-2a96f027-1154-461f-bc13-b8c8657feeff,DISK], DatanodeInfoWithStorage[127.0.0.1:44080,DS-b3ddca8d-a805-4635-b4d8-9c3a4885061a,DISK], DatanodeInfoWithStorage[127.0.0.1:37002,DS-4370edec-069b-4073-af44-0392c68fcab2,DISK], DatanodeInfoWithStorage[127.0.0.1:45430,DS-050f8daa-1f9c-4c31-b4a7-15b433ed9457,DISK], DatanodeInfoWithStorage[127.0.0.1:46201,DS-e9c9dd84-0ded-41f5-ae48-763eb326296c,DISK], DatanodeInfoWithStorage[127.0.0.1:45945,DS-cfe97752-8331-45fb-b395-fea53f2b54cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34096,DS-dbf8db80-94fc-479f-9f04-b4dc8c1e4cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:45260,DS-abd5af1b-0c7f-4cea-bf3d-2bc7e052869a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1419220785-172.17.0.21-1597746042479:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33860,DS-2a96f027-1154-461f-bc13-b8c8657feeff,DISK], DatanodeInfoWithStorage[127.0.0.1:44080,DS-b3ddca8d-a805-4635-b4d8-9c3a4885061a,DISK], DatanodeInfoWithStorage[127.0.0.1:37002,DS-4370edec-069b-4073-af44-0392c68fcab2,DISK], DatanodeInfoWithStorage[127.0.0.1:45430,DS-050f8daa-1f9c-4c31-b4a7-15b433ed9457,DISK], DatanodeInfoWithStorage[127.0.0.1:46201,DS-e9c9dd84-0ded-41f5-ae48-763eb326296c,DISK], DatanodeInfoWithStorage[127.0.0.1:45945,DS-cfe97752-8331-45fb-b395-fea53f2b54cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34096,DS-dbf8db80-94fc-479f-9f04-b4dc8c1e4cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:45260,DS-abd5af1b-0c7f-4cea-bf3d-2bc7e052869a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-31891196-172.17.0.21-1597746241362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41322,DS-c9a87862-513f-43e2-bcd1-bf5fc04bac1e,DISK], DatanodeInfoWithStorage[127.0.0.1:34185,DS-5904c078-05ce-4d15-8a45-fdd7346dc077,DISK], DatanodeInfoWithStorage[127.0.0.1:42615,DS-2efe1b50-5aee-4739-b83c-54cbdc947fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:39499,DS-76305430-02ad-4cf7-a609-5b1015f7b4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46384,DS-c9de3f3c-ca7c-45c6-974b-3239cd32446c,DISK], DatanodeInfoWithStorage[127.0.0.1:45424,DS-66e40adc-4147-45e7-937e-fba914eca00b,DISK], DatanodeInfoWithStorage[127.0.0.1:33988,DS-86bb6bd0-5830-4a19-a195-d92de1167c72,DISK], DatanodeInfoWithStorage[127.0.0.1:45494,DS-1dc10d1d-2dc2-4967-90a2-e9ca4c0d402b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-31891196-172.17.0.21-1597746241362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41322,DS-c9a87862-513f-43e2-bcd1-bf5fc04bac1e,DISK], DatanodeInfoWithStorage[127.0.0.1:34185,DS-5904c078-05ce-4d15-8a45-fdd7346dc077,DISK], DatanodeInfoWithStorage[127.0.0.1:42615,DS-2efe1b50-5aee-4739-b83c-54cbdc947fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:39499,DS-76305430-02ad-4cf7-a609-5b1015f7b4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46384,DS-c9de3f3c-ca7c-45c6-974b-3239cd32446c,DISK], DatanodeInfoWithStorage[127.0.0.1:45424,DS-66e40adc-4147-45e7-937e-fba914eca00b,DISK], DatanodeInfoWithStorage[127.0.0.1:33988,DS-86bb6bd0-5830-4a19-a195-d92de1167c72,DISK], DatanodeInfoWithStorage[127.0.0.1:45494,DS-1dc10d1d-2dc2-4967-90a2-e9ca4c0d402b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-469918425-172.17.0.21-1597746314873:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37265,DS-d5bd2046-a4b2-462a-819d-aacb8b4a8046,DISK], DatanodeInfoWithStorage[127.0.0.1:39423,DS-6dbcd7c0-470e-4377-a3d2-3f901298d034,DISK], DatanodeInfoWithStorage[127.0.0.1:35076,DS-ed9f6aa2-7346-4074-a802-cc64b08ea144,DISK], DatanodeInfoWithStorage[127.0.0.1:38224,DS-e4985ecb-e077-4921-adb2-f334885c73d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36897,DS-e734b02b-a200-4c24-aeee-b62fbbc93d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:44563,DS-6175fe4f-9d95-45ea-a757-a2e71c5bb160,DISK], DatanodeInfoWithStorage[127.0.0.1:35994,DS-9dd0c6f4-55f4-4759-97fd-d35969fbbe88,DISK], DatanodeInfoWithStorage[127.0.0.1:42269,DS-e5d249d6-b941-4274-a13d-5194d307c44f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-469918425-172.17.0.21-1597746314873:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37265,DS-d5bd2046-a4b2-462a-819d-aacb8b4a8046,DISK], DatanodeInfoWithStorage[127.0.0.1:39423,DS-6dbcd7c0-470e-4377-a3d2-3f901298d034,DISK], DatanodeInfoWithStorage[127.0.0.1:35076,DS-ed9f6aa2-7346-4074-a802-cc64b08ea144,DISK], DatanodeInfoWithStorage[127.0.0.1:38224,DS-e4985ecb-e077-4921-adb2-f334885c73d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36897,DS-e734b02b-a200-4c24-aeee-b62fbbc93d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:44563,DS-6175fe4f-9d95-45ea-a757-a2e71c5bb160,DISK], DatanodeInfoWithStorage[127.0.0.1:35994,DS-9dd0c6f4-55f4-4759-97fd-d35969fbbe88,DISK], DatanodeInfoWithStorage[127.0.0.1:42269,DS-e5d249d6-b941-4274-a13d-5194d307c44f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-986447529-172.17.0.21-1597746354254:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39861,DS-ddd40ff8-2fb8-4093-bdf3-c857edf31bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:35825,DS-021e7bf4-c597-43b7-82d2-608bf034000d,DISK], DatanodeInfoWithStorage[127.0.0.1:43215,DS-cabd705f-2af6-4d30-8612-1853094a2245,DISK], DatanodeInfoWithStorage[127.0.0.1:37801,DS-df3ec518-3710-4ecb-8a59-b4cfa4ddeab0,DISK], DatanodeInfoWithStorage[127.0.0.1:33439,DS-c8e806f2-7c19-4ee6-a649-60b579fa9b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45236,DS-ed4ab223-61ff-4ccc-ad40-51dc73a3eb9c,DISK], DatanodeInfoWithStorage[127.0.0.1:36862,DS-e20f2168-f08d-4555-bfe0-8b43b72ae076,DISK], DatanodeInfoWithStorage[127.0.0.1:38691,DS-078d6bad-fb39-4a21-98ce-a355bc3bbf09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-986447529-172.17.0.21-1597746354254:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39861,DS-ddd40ff8-2fb8-4093-bdf3-c857edf31bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:35825,DS-021e7bf4-c597-43b7-82d2-608bf034000d,DISK], DatanodeInfoWithStorage[127.0.0.1:43215,DS-cabd705f-2af6-4d30-8612-1853094a2245,DISK], DatanodeInfoWithStorage[127.0.0.1:37801,DS-df3ec518-3710-4ecb-8a59-b4cfa4ddeab0,DISK], DatanodeInfoWithStorage[127.0.0.1:33439,DS-c8e806f2-7c19-4ee6-a649-60b579fa9b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45236,DS-ed4ab223-61ff-4ccc-ad40-51dc73a3eb9c,DISK], DatanodeInfoWithStorage[127.0.0.1:36862,DS-e20f2168-f08d-4555-bfe0-8b43b72ae076,DISK], DatanodeInfoWithStorage[127.0.0.1:38691,DS-078d6bad-fb39-4a21-98ce-a355bc3bbf09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2019855631-172.17.0.21-1597746825593:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37936,DS-6f028885-ec6f-4fae-9b12-bae9634c2bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-e8ca7937-c2f3-4058-9ab0-63c9460ca72d,DISK], DatanodeInfoWithStorage[127.0.0.1:37665,DS-ca0c77e4-6654-4d37-9c89-ab4868899dda,DISK], DatanodeInfoWithStorage[127.0.0.1:38468,DS-d3ea1194-0cfc-4c4f-a013-39ef13ed1fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:42944,DS-4d7184b3-ca96-492c-a6e1-72f8cc9a3c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:33679,DS-0e80e34c-8f66-4d10-9080-5d42ad4bdf88,DISK], DatanodeInfoWithStorage[127.0.0.1:46017,DS-51053738-8001-4d8a-9d14-c79bb47f6e97,DISK], DatanodeInfoWithStorage[127.0.0.1:39934,DS-cabb84ab-38b5-496d-a92d-2c7fbfb55559,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2019855631-172.17.0.21-1597746825593:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37936,DS-6f028885-ec6f-4fae-9b12-bae9634c2bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-e8ca7937-c2f3-4058-9ab0-63c9460ca72d,DISK], DatanodeInfoWithStorage[127.0.0.1:37665,DS-ca0c77e4-6654-4d37-9c89-ab4868899dda,DISK], DatanodeInfoWithStorage[127.0.0.1:38468,DS-d3ea1194-0cfc-4c4f-a013-39ef13ed1fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:42944,DS-4d7184b3-ca96-492c-a6e1-72f8cc9a3c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:33679,DS-0e80e34c-8f66-4d10-9080-5d42ad4bdf88,DISK], DatanodeInfoWithStorage[127.0.0.1:46017,DS-51053738-8001-4d8a-9d14-c79bb47f6e97,DISK], DatanodeInfoWithStorage[127.0.0.1:39934,DS-cabb84ab-38b5-496d-a92d-2c7fbfb55559,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-801827296-172.17.0.21-1597747005273:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45581,DS-c8cdae7d-3077-4093-b0f4-0e0d0f69f7bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45954,DS-f92fa3df-f348-4d0c-b919-48c7a8c37a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42782,DS-6d4a6953-c89e-4521-b4e3-6b1049a5c33f,DISK], DatanodeInfoWithStorage[127.0.0.1:34127,DS-95b3a4d4-f783-4f8a-b8ff-bc0e955e2537,DISK], DatanodeInfoWithStorage[127.0.0.1:37227,DS-9ddfc72e-0ab1-48f0-b835-2246262b30dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33112,DS-c2c9706c-00c6-407c-b041-5ecf13d36abd,DISK], DatanodeInfoWithStorage[127.0.0.1:44917,DS-679a6ff4-969d-4d51-8407-abcf0fd81b43,DISK], DatanodeInfoWithStorage[127.0.0.1:43457,DS-91d2cea2-045c-428a-957d-eda65da32d22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-801827296-172.17.0.21-1597747005273:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45581,DS-c8cdae7d-3077-4093-b0f4-0e0d0f69f7bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45954,DS-f92fa3df-f348-4d0c-b919-48c7a8c37a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42782,DS-6d4a6953-c89e-4521-b4e3-6b1049a5c33f,DISK], DatanodeInfoWithStorage[127.0.0.1:34127,DS-95b3a4d4-f783-4f8a-b8ff-bc0e955e2537,DISK], DatanodeInfoWithStorage[127.0.0.1:37227,DS-9ddfc72e-0ab1-48f0-b835-2246262b30dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33112,DS-c2c9706c-00c6-407c-b041-5ecf13d36abd,DISK], DatanodeInfoWithStorage[127.0.0.1:44917,DS-679a6ff4-969d-4d51-8407-abcf0fd81b43,DISK], DatanodeInfoWithStorage[127.0.0.1:43457,DS-91d2cea2-045c-428a-957d-eda65da32d22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-863493840-172.17.0.21-1597747379551:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40575,DS-21e064aa-b346-4db7-baed-71cc467d0607,DISK], DatanodeInfoWithStorage[127.0.0.1:40667,DS-221085af-503d-4df7-be05-abba7e1e3858,DISK], DatanodeInfoWithStorage[127.0.0.1:33656,DS-b8dc3e7b-92d7-40f2-a24f-83342b1bfdfb,DISK], DatanodeInfoWithStorage[127.0.0.1:37396,DS-409165f4-ea09-4193-b175-ea176b3d3c69,DISK], DatanodeInfoWithStorage[127.0.0.1:34647,DS-7d99c9c6-5c2c-4340-8da9-47c86c7079d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39485,DS-a5c6c952-04bc-4413-820e-8ae6e386a346,DISK], DatanodeInfoWithStorage[127.0.0.1:39657,DS-d0a8c512-6a48-48c3-b2e2-bdd7955a50fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36226,DS-f90e5d20-c0c0-46db-b052-180eb4e9fdc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-863493840-172.17.0.21-1597747379551:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40575,DS-21e064aa-b346-4db7-baed-71cc467d0607,DISK], DatanodeInfoWithStorage[127.0.0.1:40667,DS-221085af-503d-4df7-be05-abba7e1e3858,DISK], DatanodeInfoWithStorage[127.0.0.1:33656,DS-b8dc3e7b-92d7-40f2-a24f-83342b1bfdfb,DISK], DatanodeInfoWithStorage[127.0.0.1:37396,DS-409165f4-ea09-4193-b175-ea176b3d3c69,DISK], DatanodeInfoWithStorage[127.0.0.1:34647,DS-7d99c9c6-5c2c-4340-8da9-47c86c7079d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39485,DS-a5c6c952-04bc-4413-820e-8ae6e386a346,DISK], DatanodeInfoWithStorage[127.0.0.1:39657,DS-d0a8c512-6a48-48c3-b2e2-bdd7955a50fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36226,DS-f90e5d20-c0c0-46db-b052-180eb4e9fdc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1877547726-172.17.0.21-1597747897843:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39091,DS-942c7126-4b4c-4bc2-ad41-5d7760b7895f,DISK], DatanodeInfoWithStorage[127.0.0.1:39714,DS-a912c6d8-d1c7-4a37-9c05-a355e00d0e63,DISK], DatanodeInfoWithStorage[127.0.0.1:38858,DS-746232e0-d9d6-4dec-b93c-8c86bdb2fda8,DISK], DatanodeInfoWithStorage[127.0.0.1:33157,DS-2375d450-d5d4-4915-8f3d-3d76461b506a,DISK], DatanodeInfoWithStorage[127.0.0.1:41692,DS-3817b761-b05c-4205-b13a-f144fba8791d,DISK], DatanodeInfoWithStorage[127.0.0.1:41144,DS-63c7b274-a89d-4e08-9f04-3014b4fdeb21,DISK], DatanodeInfoWithStorage[127.0.0.1:43750,DS-6ca5d450-174e-46b5-bfb5-d5085b3556f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38226,DS-f2b395b4-35dd-432c-8b08-a1fd3149130e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1877547726-172.17.0.21-1597747897843:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39091,DS-942c7126-4b4c-4bc2-ad41-5d7760b7895f,DISK], DatanodeInfoWithStorage[127.0.0.1:39714,DS-a912c6d8-d1c7-4a37-9c05-a355e00d0e63,DISK], DatanodeInfoWithStorage[127.0.0.1:38858,DS-746232e0-d9d6-4dec-b93c-8c86bdb2fda8,DISK], DatanodeInfoWithStorage[127.0.0.1:33157,DS-2375d450-d5d4-4915-8f3d-3d76461b506a,DISK], DatanodeInfoWithStorage[127.0.0.1:41692,DS-3817b761-b05c-4205-b13a-f144fba8791d,DISK], DatanodeInfoWithStorage[127.0.0.1:41144,DS-63c7b274-a89d-4e08-9f04-3014b4fdeb21,DISK], DatanodeInfoWithStorage[127.0.0.1:43750,DS-6ca5d450-174e-46b5-bfb5-d5085b3556f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38226,DS-f2b395b4-35dd-432c-8b08-a1fd3149130e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-825129234-172.17.0.21-1597747941470:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44774,DS-9eebcd79-91ef-4049-b24a-b0d6c0ce7406,DISK], DatanodeInfoWithStorage[127.0.0.1:33581,DS-a63f31c7-8fd0-4666-a583-bbb85deb6c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:44248,DS-6e9e44a0-3c38-4b68-85a7-37e338c8f41f,DISK], DatanodeInfoWithStorage[127.0.0.1:35131,DS-ebb84a65-7bbe-457c-82d1-935658d83a18,DISK], DatanodeInfoWithStorage[127.0.0.1:36300,DS-ad7a946b-81ec-436a-87ba-b752d834b20e,DISK], DatanodeInfoWithStorage[127.0.0.1:33374,DS-8bcb7d5f-2923-4d9a-b579-2c80a7de46c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44498,DS-4d53c7d4-dba2-4c24-99f4-e187eb1008b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36277,DS-c51ad968-5705-413a-8f62-2d6270cc7f97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-825129234-172.17.0.21-1597747941470:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44774,DS-9eebcd79-91ef-4049-b24a-b0d6c0ce7406,DISK], DatanodeInfoWithStorage[127.0.0.1:33581,DS-a63f31c7-8fd0-4666-a583-bbb85deb6c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:44248,DS-6e9e44a0-3c38-4b68-85a7-37e338c8f41f,DISK], DatanodeInfoWithStorage[127.0.0.1:35131,DS-ebb84a65-7bbe-457c-82d1-935658d83a18,DISK], DatanodeInfoWithStorage[127.0.0.1:36300,DS-ad7a946b-81ec-436a-87ba-b752d834b20e,DISK], DatanodeInfoWithStorage[127.0.0.1:33374,DS-8bcb7d5f-2923-4d9a-b579-2c80a7de46c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44498,DS-4d53c7d4-dba2-4c24-99f4-e187eb1008b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36277,DS-c51ad968-5705-413a-8f62-2d6270cc7f97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1817631872-172.17.0.21-1597748133197:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36496,DS-5281c701-939f-40c7-9780-75eed7cbe4fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41072,DS-4b784778-5bb5-492c-a907-3990d466ba0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46265,DS-d34cc856-de1a-416c-adf9-3935ed1eb570,DISK], DatanodeInfoWithStorage[127.0.0.1:41734,DS-2dc3e970-5fe8-46fd-b9d8-3454d1c8d6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35111,DS-276c80aa-39d3-4e46-9933-5c2fbfd24eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:37753,DS-56ec1e4b-71a8-4720-b6e6-6b107b8a61e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40044,DS-125a96c3-eff0-41a5-acad-8f051c54b614,DISK], DatanodeInfoWithStorage[127.0.0.1:42190,DS-3dec28f3-816c-48ca-9c5d-ae8ab7db9e12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1817631872-172.17.0.21-1597748133197:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36496,DS-5281c701-939f-40c7-9780-75eed7cbe4fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41072,DS-4b784778-5bb5-492c-a907-3990d466ba0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46265,DS-d34cc856-de1a-416c-adf9-3935ed1eb570,DISK], DatanodeInfoWithStorage[127.0.0.1:41734,DS-2dc3e970-5fe8-46fd-b9d8-3454d1c8d6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35111,DS-276c80aa-39d3-4e46-9933-5c2fbfd24eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:37753,DS-56ec1e4b-71a8-4720-b6e6-6b107b8a61e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40044,DS-125a96c3-eff0-41a5-acad-8f051c54b614,DISK], DatanodeInfoWithStorage[127.0.0.1:42190,DS-3dec28f3-816c-48ca-9c5d-ae8ab7db9e12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-839279587-172.17.0.21-1597748246730:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42540,DS-0e218cec-5800-427a-ad21-990b2c4b8d42,DISK], DatanodeInfoWithStorage[127.0.0.1:33914,DS-72dee6ba-e802-432f-a21d-b3741d186178,DISK], DatanodeInfoWithStorage[127.0.0.1:38905,DS-c283a937-a527-4c6f-93ef-ada3c86ea116,DISK], DatanodeInfoWithStorage[127.0.0.1:39310,DS-e44d35d2-40f7-493f-9485-c1b9d42ca32f,DISK], DatanodeInfoWithStorage[127.0.0.1:42009,DS-540a1ce0-229d-410e-908e-f43010e03c05,DISK], DatanodeInfoWithStorage[127.0.0.1:42439,DS-48d9255b-7bac-41bc-91cd-f1819949ff64,DISK], DatanodeInfoWithStorage[127.0.0.1:42229,DS-637b2b8b-afec-43b6-b5dd-fb600585bc4b,DISK], DatanodeInfoWithStorage[127.0.0.1:32795,DS-ba101ab4-53a8-42fa-b343-5c1450ed945a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-839279587-172.17.0.21-1597748246730:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42540,DS-0e218cec-5800-427a-ad21-990b2c4b8d42,DISK], DatanodeInfoWithStorage[127.0.0.1:33914,DS-72dee6ba-e802-432f-a21d-b3741d186178,DISK], DatanodeInfoWithStorage[127.0.0.1:38905,DS-c283a937-a527-4c6f-93ef-ada3c86ea116,DISK], DatanodeInfoWithStorage[127.0.0.1:39310,DS-e44d35d2-40f7-493f-9485-c1b9d42ca32f,DISK], DatanodeInfoWithStorage[127.0.0.1:42009,DS-540a1ce0-229d-410e-908e-f43010e03c05,DISK], DatanodeInfoWithStorage[127.0.0.1:42439,DS-48d9255b-7bac-41bc-91cd-f1819949ff64,DISK], DatanodeInfoWithStorage[127.0.0.1:42229,DS-637b2b8b-afec-43b6-b5dd-fb600585bc4b,DISK], DatanodeInfoWithStorage[127.0.0.1:32795,DS-ba101ab4-53a8-42fa-b343-5c1450ed945a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-837586163-172.17.0.21-1597748889247:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45656,DS-d2c815ff-11b3-423e-98a0-68c4ad53ff67,DISK], DatanodeInfoWithStorage[127.0.0.1:42883,DS-1b7dc2b3-c6d3-4087-b6ac-c0bdaa8fe506,DISK], DatanodeInfoWithStorage[127.0.0.1:39445,DS-e938bc3b-411d-4b34-9c26-704cf859f37d,DISK], DatanodeInfoWithStorage[127.0.0.1:39426,DS-3cfb214f-c5c4-4d5d-887a-d09a10d2bb3a,DISK], DatanodeInfoWithStorage[127.0.0.1:35556,DS-b28a859e-e3e0-4198-a66c-3260614fa67e,DISK], DatanodeInfoWithStorage[127.0.0.1:36805,DS-02f6142a-3e29-44e3-918d-72225adc9499,DISK], DatanodeInfoWithStorage[127.0.0.1:43546,DS-3a3b8638-0c3a-4319-888d-7828754c0bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:33855,DS-a3f4ea27-0ede-4f8b-95ed-c89049cb6ca8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-837586163-172.17.0.21-1597748889247:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45656,DS-d2c815ff-11b3-423e-98a0-68c4ad53ff67,DISK], DatanodeInfoWithStorage[127.0.0.1:42883,DS-1b7dc2b3-c6d3-4087-b6ac-c0bdaa8fe506,DISK], DatanodeInfoWithStorage[127.0.0.1:39445,DS-e938bc3b-411d-4b34-9c26-704cf859f37d,DISK], DatanodeInfoWithStorage[127.0.0.1:39426,DS-3cfb214f-c5c4-4d5d-887a-d09a10d2bb3a,DISK], DatanodeInfoWithStorage[127.0.0.1:35556,DS-b28a859e-e3e0-4198-a66c-3260614fa67e,DISK], DatanodeInfoWithStorage[127.0.0.1:36805,DS-02f6142a-3e29-44e3-918d-72225adc9499,DISK], DatanodeInfoWithStorage[127.0.0.1:43546,DS-3a3b8638-0c3a-4319-888d-7828754c0bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:33855,DS-a3f4ea27-0ede-4f8b-95ed-c89049cb6ca8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1387104653-172.17.0.21-1597748997786:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42925,DS-8cd3735a-cd77-465e-9b93-82ff78d1d838,DISK], DatanodeInfoWithStorage[127.0.0.1:33763,DS-1fcd50fa-c680-48cd-8008-a340aaada62d,DISK], DatanodeInfoWithStorage[127.0.0.1:45600,DS-e84b2bbd-323f-4176-9309-7e8e6e70cf28,DISK], DatanodeInfoWithStorage[127.0.0.1:34740,DS-0e694746-b8be-4f7a-a600-15e4c372576f,DISK], DatanodeInfoWithStorage[127.0.0.1:41461,DS-4fbda1e7-6ef4-48d2-9f6d-ede5e49c8559,DISK], DatanodeInfoWithStorage[127.0.0.1:43436,DS-549cf99a-b05b-4442-a1da-4556c3ba09f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41170,DS-7d943113-7136-48e8-b456-4ed9554b0736,DISK], DatanodeInfoWithStorage[127.0.0.1:42676,DS-5726129d-d81c-42c9-b843-8142941b429e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1387104653-172.17.0.21-1597748997786:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42925,DS-8cd3735a-cd77-465e-9b93-82ff78d1d838,DISK], DatanodeInfoWithStorage[127.0.0.1:33763,DS-1fcd50fa-c680-48cd-8008-a340aaada62d,DISK], DatanodeInfoWithStorage[127.0.0.1:45600,DS-e84b2bbd-323f-4176-9309-7e8e6e70cf28,DISK], DatanodeInfoWithStorage[127.0.0.1:34740,DS-0e694746-b8be-4f7a-a600-15e4c372576f,DISK], DatanodeInfoWithStorage[127.0.0.1:41461,DS-4fbda1e7-6ef4-48d2-9f6d-ede5e49c8559,DISK], DatanodeInfoWithStorage[127.0.0.1:43436,DS-549cf99a-b05b-4442-a1da-4556c3ba09f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41170,DS-7d943113-7136-48e8-b456-4ed9554b0736,DISK], DatanodeInfoWithStorage[127.0.0.1:42676,DS-5726129d-d81c-42c9-b843-8142941b429e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1974533517-172.17.0.21-1597749076506:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39456,DS-29a0f703-09c2-4c6c-8d66-4e810f7e70f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37468,DS-7d0c8a44-c635-4d96-b8b3-dd25ef1e99c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37107,DS-cea60f33-b93c-4d13-9a20-91435c78b80a,DISK], DatanodeInfoWithStorage[127.0.0.1:43976,DS-bd5b5ebd-f06f-4047-9990-1858b96ce85e,DISK], DatanodeInfoWithStorage[127.0.0.1:40844,DS-51f99001-7cca-4e80-a493-3f01777b0768,DISK], DatanodeInfoWithStorage[127.0.0.1:36611,DS-285826fc-df3a-4103-86b2-a1949b0e9f94,DISK], DatanodeInfoWithStorage[127.0.0.1:41911,DS-b609a82e-c786-482e-bda9-4590060ed300,DISK], DatanodeInfoWithStorage[127.0.0.1:44644,DS-5dcb2540-b908-435f-901e-c96cd31fbc34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1974533517-172.17.0.21-1597749076506:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39456,DS-29a0f703-09c2-4c6c-8d66-4e810f7e70f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37468,DS-7d0c8a44-c635-4d96-b8b3-dd25ef1e99c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37107,DS-cea60f33-b93c-4d13-9a20-91435c78b80a,DISK], DatanodeInfoWithStorage[127.0.0.1:43976,DS-bd5b5ebd-f06f-4047-9990-1858b96ce85e,DISK], DatanodeInfoWithStorage[127.0.0.1:40844,DS-51f99001-7cca-4e80-a493-3f01777b0768,DISK], DatanodeInfoWithStorage[127.0.0.1:36611,DS-285826fc-df3a-4103-86b2-a1949b0e9f94,DISK], DatanodeInfoWithStorage[127.0.0.1:41911,DS-b609a82e-c786-482e-bda9-4590060ed300,DISK], DatanodeInfoWithStorage[127.0.0.1:44644,DS-5dcb2540-b908-435f-901e-c96cd31fbc34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-23921969-172.17.0.21-1597749190737:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38010,DS-8dba114d-7bcd-4448-a05f-1efda9b803e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44495,DS-2e1520a9-32f1-4f6c-818f-fc96f33f097f,DISK], DatanodeInfoWithStorage[127.0.0.1:40589,DS-c8758c01-0c02-48a0-be7a-864b55a58afc,DISK], DatanodeInfoWithStorage[127.0.0.1:36777,DS-edb904ed-7c97-43ca-913f-fbd2867d3ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:39044,DS-f2b36f49-1240-465b-96df-d02e0f25ea84,DISK], DatanodeInfoWithStorage[127.0.0.1:34388,DS-8c6a574a-7714-4071-82e9-25f21ef7125a,DISK], DatanodeInfoWithStorage[127.0.0.1:43989,DS-5f2eb9ae-b1cd-468f-afe2-b7ac718de21b,DISK], DatanodeInfoWithStorage[127.0.0.1:42729,DS-675e994c-180b-4bfb-80db-6cf7b365d5a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-23921969-172.17.0.21-1597749190737:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38010,DS-8dba114d-7bcd-4448-a05f-1efda9b803e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44495,DS-2e1520a9-32f1-4f6c-818f-fc96f33f097f,DISK], DatanodeInfoWithStorage[127.0.0.1:40589,DS-c8758c01-0c02-48a0-be7a-864b55a58afc,DISK], DatanodeInfoWithStorage[127.0.0.1:36777,DS-edb904ed-7c97-43ca-913f-fbd2867d3ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:39044,DS-f2b36f49-1240-465b-96df-d02e0f25ea84,DISK], DatanodeInfoWithStorage[127.0.0.1:34388,DS-8c6a574a-7714-4071-82e9-25f21ef7125a,DISK], DatanodeInfoWithStorage[127.0.0.1:43989,DS-5f2eb9ae-b1cd-468f-afe2-b7ac718de21b,DISK], DatanodeInfoWithStorage[127.0.0.1:42729,DS-675e994c-180b-4bfb-80db-6cf7b365d5a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-550290506-172.17.0.21-1597749497651:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44095,DS-a3801b10-eacc-4b90-9d91-b087ca3d33e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35448,DS-2505365c-9022-4e86-8c87-47eacc8ac274,DISK], DatanodeInfoWithStorage[127.0.0.1:45083,DS-44138503-bad3-467c-b271-00a058edfdff,DISK], DatanodeInfoWithStorage[127.0.0.1:42837,DS-f04235ee-f761-4006-94ca-84df1ba65737,DISK], DatanodeInfoWithStorage[127.0.0.1:35283,DS-ebed59bf-6ac2-4d70-8034-44eb331f567f,DISK], DatanodeInfoWithStorage[127.0.0.1:37007,DS-1e104ac1-dd2b-476c-8fdb-1b4f90d4a759,DISK], DatanodeInfoWithStorage[127.0.0.1:36873,DS-b9214d3b-338e-46ef-8aca-5432bd1da7d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46822,DS-0337e556-0f2b-4d29-b430-dd85ed6fdb3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-550290506-172.17.0.21-1597749497651:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44095,DS-a3801b10-eacc-4b90-9d91-b087ca3d33e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35448,DS-2505365c-9022-4e86-8c87-47eacc8ac274,DISK], DatanodeInfoWithStorage[127.0.0.1:45083,DS-44138503-bad3-467c-b271-00a058edfdff,DISK], DatanodeInfoWithStorage[127.0.0.1:42837,DS-f04235ee-f761-4006-94ca-84df1ba65737,DISK], DatanodeInfoWithStorage[127.0.0.1:35283,DS-ebed59bf-6ac2-4d70-8034-44eb331f567f,DISK], DatanodeInfoWithStorage[127.0.0.1:37007,DS-1e104ac1-dd2b-476c-8fdb-1b4f90d4a759,DISK], DatanodeInfoWithStorage[127.0.0.1:36873,DS-b9214d3b-338e-46ef-8aca-5432bd1da7d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46822,DS-0337e556-0f2b-4d29-b430-dd85ed6fdb3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1572148452-172.17.0.21-1597749652998:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40315,DS-c4d2c47a-b26f-4190-827e-89ab0b03cae6,DISK], DatanodeInfoWithStorage[127.0.0.1:40284,DS-d72e29a8-08b3-430f-be01-398118aafdfb,DISK], DatanodeInfoWithStorage[127.0.0.1:40550,DS-5f2339ee-7c4c-45b9-ab91-894cdbf86514,DISK], DatanodeInfoWithStorage[127.0.0.1:33979,DS-0bf4faee-dc12-4a38-b2a2-4b16193e74a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37059,DS-76155354-efb3-46bf-96d0-ffbbbd9b20a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40849,DS-65e782e0-3043-4346-8b6b-eb7a21a4c21f,DISK], DatanodeInfoWithStorage[127.0.0.1:41051,DS-e42e8924-1f47-4bb6-90a6-b82327ac4e96,DISK], DatanodeInfoWithStorage[127.0.0.1:42240,DS-00174f7b-678e-44fc-a67b-bbc00e1c8831,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1572148452-172.17.0.21-1597749652998:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40315,DS-c4d2c47a-b26f-4190-827e-89ab0b03cae6,DISK], DatanodeInfoWithStorage[127.0.0.1:40284,DS-d72e29a8-08b3-430f-be01-398118aafdfb,DISK], DatanodeInfoWithStorage[127.0.0.1:40550,DS-5f2339ee-7c4c-45b9-ab91-894cdbf86514,DISK], DatanodeInfoWithStorage[127.0.0.1:33979,DS-0bf4faee-dc12-4a38-b2a2-4b16193e74a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37059,DS-76155354-efb3-46bf-96d0-ffbbbd9b20a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40849,DS-65e782e0-3043-4346-8b6b-eb7a21a4c21f,DISK], DatanodeInfoWithStorage[127.0.0.1:41051,DS-e42e8924-1f47-4bb6-90a6-b82327ac4e96,DISK], DatanodeInfoWithStorage[127.0.0.1:42240,DS-00174f7b-678e-44fc-a67b-bbc00e1c8831,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1380730989-172.17.0.21-1597749727031:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45015,DS-3198c7dc-6ce0-446b-b51e-fcfeeafb2035,DISK], DatanodeInfoWithStorage[127.0.0.1:34232,DS-b1c7de42-54ff-4a4a-a066-4d6e9dacb50d,DISK], DatanodeInfoWithStorage[127.0.0.1:40222,DS-2c1d25dd-0b0d-45de-b35c-e8125cad7f27,DISK], DatanodeInfoWithStorage[127.0.0.1:39461,DS-b988190b-e6ac-4f0e-8cd1-3ef809098070,DISK], DatanodeInfoWithStorage[127.0.0.1:44482,DS-73fb0850-a5ca-47a0-a3f5-b9f895e1ab7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44256,DS-ab2cc807-3692-47bc-8160-8266e732c845,DISK], DatanodeInfoWithStorage[127.0.0.1:32985,DS-1c0cb16f-d8d7-4d67-b319-80431ac78692,DISK], DatanodeInfoWithStorage[127.0.0.1:38281,DS-a067260e-f558-4045-98e7-857e096b60ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1380730989-172.17.0.21-1597749727031:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45015,DS-3198c7dc-6ce0-446b-b51e-fcfeeafb2035,DISK], DatanodeInfoWithStorage[127.0.0.1:34232,DS-b1c7de42-54ff-4a4a-a066-4d6e9dacb50d,DISK], DatanodeInfoWithStorage[127.0.0.1:40222,DS-2c1d25dd-0b0d-45de-b35c-e8125cad7f27,DISK], DatanodeInfoWithStorage[127.0.0.1:39461,DS-b988190b-e6ac-4f0e-8cd1-3ef809098070,DISK], DatanodeInfoWithStorage[127.0.0.1:44482,DS-73fb0850-a5ca-47a0-a3f5-b9f895e1ab7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44256,DS-ab2cc807-3692-47bc-8160-8266e732c845,DISK], DatanodeInfoWithStorage[127.0.0.1:32985,DS-1c0cb16f-d8d7-4d67-b319-80431ac78692,DISK], DatanodeInfoWithStorage[127.0.0.1:38281,DS-a067260e-f558-4045-98e7-857e096b60ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-160368624-172.17.0.21-1597750424811:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39247,DS-f89178b5-5506-4bd7-80f6-f26115140c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41236,DS-eafbbd2b-6485-4299-8704-596c8c7688dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37813,DS-1aac6aa6-0e71-4c71-9aa3-7c27d1ad4da6,DISK], DatanodeInfoWithStorage[127.0.0.1:34853,DS-f3380074-49e3-45d4-984d-e305a0f8805d,DISK], DatanodeInfoWithStorage[127.0.0.1:45783,DS-10cd8fe5-af3e-484e-9f5a-65d87dd8cfad,DISK], DatanodeInfoWithStorage[127.0.0.1:33647,DS-47c2ecf3-b320-4866-9832-e2155c1e4354,DISK], DatanodeInfoWithStorage[127.0.0.1:37926,DS-8be200a9-feba-450f-aedd-cfcc0c1bfdb7,DISK], DatanodeInfoWithStorage[127.0.0.1:34339,DS-31b73f60-74e3-411f-91ec-0185c5648634,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-160368624-172.17.0.21-1597750424811:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39247,DS-f89178b5-5506-4bd7-80f6-f26115140c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41236,DS-eafbbd2b-6485-4299-8704-596c8c7688dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37813,DS-1aac6aa6-0e71-4c71-9aa3-7c27d1ad4da6,DISK], DatanodeInfoWithStorage[127.0.0.1:34853,DS-f3380074-49e3-45d4-984d-e305a0f8805d,DISK], DatanodeInfoWithStorage[127.0.0.1:45783,DS-10cd8fe5-af3e-484e-9f5a-65d87dd8cfad,DISK], DatanodeInfoWithStorage[127.0.0.1:33647,DS-47c2ecf3-b320-4866-9832-e2155c1e4354,DISK], DatanodeInfoWithStorage[127.0.0.1:37926,DS-8be200a9-feba-450f-aedd-cfcc0c1bfdb7,DISK], DatanodeInfoWithStorage[127.0.0.1:34339,DS-31b73f60-74e3-411f-91ec-0185c5648634,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 17 out of 50
result: false positive !!!
Total execution time in seconds : 5691
