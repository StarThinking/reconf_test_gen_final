reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 1048576
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 1048576
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-74948874-172.17.0.6-1597742408963:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43125,DS-fa2ae9fa-801a-4ffc-a914-c1140c786e70,DISK], DatanodeInfoWithStorage[127.0.0.1:39301,DS-e691f330-409a-4bea-83a7-d64f627df649,DISK], DatanodeInfoWithStorage[127.0.0.1:41928,DS-d2747fcd-c456-48e9-a973-6c6645a0bde4,DISK], DatanodeInfoWithStorage[127.0.0.1:36861,DS-e32938de-52cd-41a4-8dc8-e625aeb9bd07,DISK], DatanodeInfoWithStorage[127.0.0.1:37658,DS-ec1fb21e-9d5f-4663-b3b0-499089bbeb48,DISK], DatanodeInfoWithStorage[127.0.0.1:46017,DS-fa2bb9c3-67db-4dd5-a960-a6fe9449b211,DISK], DatanodeInfoWithStorage[127.0.0.1:40934,DS-cef23776-45cc-47e0-90e7-013f222638c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45468,DS-6bf39cd1-e521-4eda-856f-bb825faecc5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-74948874-172.17.0.6-1597742408963:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43125,DS-fa2ae9fa-801a-4ffc-a914-c1140c786e70,DISK], DatanodeInfoWithStorage[127.0.0.1:39301,DS-e691f330-409a-4bea-83a7-d64f627df649,DISK], DatanodeInfoWithStorage[127.0.0.1:41928,DS-d2747fcd-c456-48e9-a973-6c6645a0bde4,DISK], DatanodeInfoWithStorage[127.0.0.1:36861,DS-e32938de-52cd-41a4-8dc8-e625aeb9bd07,DISK], DatanodeInfoWithStorage[127.0.0.1:37658,DS-ec1fb21e-9d5f-4663-b3b0-499089bbeb48,DISK], DatanodeInfoWithStorage[127.0.0.1:46017,DS-fa2bb9c3-67db-4dd5-a960-a6fe9449b211,DISK], DatanodeInfoWithStorage[127.0.0.1:40934,DS-cef23776-45cc-47e0-90e7-013f222638c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45468,DS-6bf39cd1-e521-4eda-856f-bb825faecc5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 1048576
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-277491098-172.17.0.6-1597743004010:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33465,DS-02cd944f-a4a0-4ada-af73-dfe6a383d566,DISK], DatanodeInfoWithStorage[127.0.0.1:39765,DS-6acbd0bc-aec6-4f8e-85db-866da006d319,DISK], DatanodeInfoWithStorage[127.0.0.1:36430,DS-58efe081-6c9a-485b-93bc-26a0af42e55e,DISK], DatanodeInfoWithStorage[127.0.0.1:44921,DS-b185f7ae-5406-475c-9a91-7ae91c1afe75,DISK], DatanodeInfoWithStorage[127.0.0.1:43969,DS-b0dc1676-7725-4fec-be9f-8810c757092c,DISK], DatanodeInfoWithStorage[127.0.0.1:44201,DS-ab7dff5f-83c4-4aae-8bfb-b474a96ed205,DISK], DatanodeInfoWithStorage[127.0.0.1:44357,DS-72031d3d-3542-469f-afa7-cdff7b583be3,DISK], DatanodeInfoWithStorage[127.0.0.1:46083,DS-77cf0a03-db24-4f16-a1b3-dd938b505015,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-277491098-172.17.0.6-1597743004010:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33465,DS-02cd944f-a4a0-4ada-af73-dfe6a383d566,DISK], DatanodeInfoWithStorage[127.0.0.1:39765,DS-6acbd0bc-aec6-4f8e-85db-866da006d319,DISK], DatanodeInfoWithStorage[127.0.0.1:36430,DS-58efe081-6c9a-485b-93bc-26a0af42e55e,DISK], DatanodeInfoWithStorage[127.0.0.1:44921,DS-b185f7ae-5406-475c-9a91-7ae91c1afe75,DISK], DatanodeInfoWithStorage[127.0.0.1:43969,DS-b0dc1676-7725-4fec-be9f-8810c757092c,DISK], DatanodeInfoWithStorage[127.0.0.1:44201,DS-ab7dff5f-83c4-4aae-8bfb-b474a96ed205,DISK], DatanodeInfoWithStorage[127.0.0.1:44357,DS-72031d3d-3542-469f-afa7-cdff7b583be3,DISK], DatanodeInfoWithStorage[127.0.0.1:46083,DS-77cf0a03-db24-4f16-a1b3-dd938b505015,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 1048576
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1027711830-172.17.0.6-1597743342460:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33920,DS-fdb59fb9-c9fc-4e3a-98e0-fb8b1b292e87,DISK], DatanodeInfoWithStorage[127.0.0.1:45546,DS-0cc31249-7ec5-4097-8c8a-d47534bb7e48,DISK], DatanodeInfoWithStorage[127.0.0.1:39070,DS-faae1e9b-1386-4146-9983-c39fce367318,DISK], DatanodeInfoWithStorage[127.0.0.1:43466,DS-c71cdb81-dcd1-4e1a-b94d-8db6a43df2f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34018,DS-af6e45c6-8c64-4ec5-beec-9aa21721aab9,DISK], DatanodeInfoWithStorage[127.0.0.1:44332,DS-57a31d96-890d-4ef4-bc89-520e5ae7a644,DISK], DatanodeInfoWithStorage[127.0.0.1:45335,DS-8e1ef97b-2cd2-44d4-bb40-662757c5e68b,DISK], DatanodeInfoWithStorage[127.0.0.1:46024,DS-6c5680da-7eb4-48b8-90c8-24a6baa64c07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1027711830-172.17.0.6-1597743342460:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33920,DS-fdb59fb9-c9fc-4e3a-98e0-fb8b1b292e87,DISK], DatanodeInfoWithStorage[127.0.0.1:45546,DS-0cc31249-7ec5-4097-8c8a-d47534bb7e48,DISK], DatanodeInfoWithStorage[127.0.0.1:39070,DS-faae1e9b-1386-4146-9983-c39fce367318,DISK], DatanodeInfoWithStorage[127.0.0.1:43466,DS-c71cdb81-dcd1-4e1a-b94d-8db6a43df2f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34018,DS-af6e45c6-8c64-4ec5-beec-9aa21721aab9,DISK], DatanodeInfoWithStorage[127.0.0.1:44332,DS-57a31d96-890d-4ef4-bc89-520e5ae7a644,DISK], DatanodeInfoWithStorage[127.0.0.1:45335,DS-8e1ef97b-2cd2-44d4-bb40-662757c5e68b,DISK], DatanodeInfoWithStorage[127.0.0.1:46024,DS-6c5680da-7eb4-48b8-90c8-24a6baa64c07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 1048576
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-223781125-172.17.0.6-1597744103533:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40261,DS-58f75b89-60cd-41cd-a1c5-0b3a6af249ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40901,DS-4d84e2d0-e34a-40db-97b4-8fe85d5d16bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33969,DS-af844281-77b7-43f6-93b7-637c7aedbcf8,DISK], DatanodeInfoWithStorage[127.0.0.1:46494,DS-b98d819c-20cc-41e9-bcf3-f104c581db1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43257,DS-7c2c73a2-c993-48f9-93df-ffe2e2ac4f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39714,DS-99c99279-ade3-4699-a96e-523939bf5050,DISK], DatanodeInfoWithStorage[127.0.0.1:34866,DS-09024327-e688-46b7-b9d4-0205828eaf5d,DISK], DatanodeInfoWithStorage[127.0.0.1:33662,DS-b9189619-3787-4d7b-b5ee-3ee5d9cf0cf8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-223781125-172.17.0.6-1597744103533:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40261,DS-58f75b89-60cd-41cd-a1c5-0b3a6af249ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40901,DS-4d84e2d0-e34a-40db-97b4-8fe85d5d16bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33969,DS-af844281-77b7-43f6-93b7-637c7aedbcf8,DISK], DatanodeInfoWithStorage[127.0.0.1:46494,DS-b98d819c-20cc-41e9-bcf3-f104c581db1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43257,DS-7c2c73a2-c993-48f9-93df-ffe2e2ac4f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39714,DS-99c99279-ade3-4699-a96e-523939bf5050,DISK], DatanodeInfoWithStorage[127.0.0.1:34866,DS-09024327-e688-46b7-b9d4-0205828eaf5d,DISK], DatanodeInfoWithStorage[127.0.0.1:33662,DS-b9189619-3787-4d7b-b5ee-3ee5d9cf0cf8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 1048576
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-552686561-172.17.0.6-1597744501210:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38383,DS-acf732db-6f5f-449a-be58-a3f8e24fa62d,DISK], DatanodeInfoWithStorage[127.0.0.1:33958,DS-7855c3d2-3ca6-4ee0-abaf-2a424dcf3430,DISK], DatanodeInfoWithStorage[127.0.0.1:34288,DS-7c5ef5ef-9dda-4cb2-a493-16bdaa33dc61,DISK], DatanodeInfoWithStorage[127.0.0.1:39124,DS-757f60da-2ec5-479b-ab60-6cdecace82b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37599,DS-b186318e-491a-40bf-9d0a-d400c79a5b53,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-9de92aa0-6fc6-41d0-ad3f-d3287baa4b71,DISK], DatanodeInfoWithStorage[127.0.0.1:41393,DS-e34dec36-2247-46da-9165-a5cf9688fe3f,DISK], DatanodeInfoWithStorage[127.0.0.1:37779,DS-ec12f0e8-395b-473a-aee6-fd33b7ecfc8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-552686561-172.17.0.6-1597744501210:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38383,DS-acf732db-6f5f-449a-be58-a3f8e24fa62d,DISK], DatanodeInfoWithStorage[127.0.0.1:33958,DS-7855c3d2-3ca6-4ee0-abaf-2a424dcf3430,DISK], DatanodeInfoWithStorage[127.0.0.1:34288,DS-7c5ef5ef-9dda-4cb2-a493-16bdaa33dc61,DISK], DatanodeInfoWithStorage[127.0.0.1:39124,DS-757f60da-2ec5-479b-ab60-6cdecace82b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37599,DS-b186318e-491a-40bf-9d0a-d400c79a5b53,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-9de92aa0-6fc6-41d0-ad3f-d3287baa4b71,DISK], DatanodeInfoWithStorage[127.0.0.1:41393,DS-e34dec36-2247-46da-9165-a5cf9688fe3f,DISK], DatanodeInfoWithStorage[127.0.0.1:37779,DS-ec12f0e8-395b-473a-aee6-fd33b7ecfc8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 1048576
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1550506156-172.17.0.6-1597744684714:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38551,DS-9c3000c8-928a-4dd9-9df3-8dde8ce5d56e,DISK], DatanodeInfoWithStorage[127.0.0.1:46142,DS-21088b3a-8808-41be-bc06-4067dcfb7885,DISK], DatanodeInfoWithStorage[127.0.0.1:42880,DS-7a934353-0f30-4227-8e26-3e10f8f329e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39362,DS-f6be66d2-64f3-4b19-9b13-fda2f91ade61,DISK], DatanodeInfoWithStorage[127.0.0.1:33473,DS-338bd092-78a6-4c69-9bed-3ec25f27234e,DISK], DatanodeInfoWithStorage[127.0.0.1:35279,DS-d678898c-f925-46c5-9eb3-3d7f97ed867e,DISK], DatanodeInfoWithStorage[127.0.0.1:45980,DS-d7e1aa25-eecd-4154-8674-6df9f06e3d47,DISK], DatanodeInfoWithStorage[127.0.0.1:40027,DS-751ca886-0805-4356-82fd-318a159987ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1550506156-172.17.0.6-1597744684714:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38551,DS-9c3000c8-928a-4dd9-9df3-8dde8ce5d56e,DISK], DatanodeInfoWithStorage[127.0.0.1:46142,DS-21088b3a-8808-41be-bc06-4067dcfb7885,DISK], DatanodeInfoWithStorage[127.0.0.1:42880,DS-7a934353-0f30-4227-8e26-3e10f8f329e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39362,DS-f6be66d2-64f3-4b19-9b13-fda2f91ade61,DISK], DatanodeInfoWithStorage[127.0.0.1:33473,DS-338bd092-78a6-4c69-9bed-3ec25f27234e,DISK], DatanodeInfoWithStorage[127.0.0.1:35279,DS-d678898c-f925-46c5-9eb3-3d7f97ed867e,DISK], DatanodeInfoWithStorage[127.0.0.1:45980,DS-d7e1aa25-eecd-4154-8674-6df9f06e3d47,DISK], DatanodeInfoWithStorage[127.0.0.1:40027,DS-751ca886-0805-4356-82fd-318a159987ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 1048576
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-248738181-172.17.0.6-1597745083527:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36330,DS-24402dad-dbf8-4f3a-baff-044df9f3cbcf,DISK], DatanodeInfoWithStorage[127.0.0.1:35453,DS-0e98204d-1e87-46fe-ab5c-d5ed8f08fc67,DISK], DatanodeInfoWithStorage[127.0.0.1:45671,DS-0c0d7ea9-fb81-4809-931e-d4fd40cbbee3,DISK], DatanodeInfoWithStorage[127.0.0.1:40523,DS-d649f117-ea0f-4a47-bda6-dfcf41226a94,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-b95053e0-d12f-44e1-9b6b-2889d22905c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45966,DS-b2e6943a-d0f8-4fca-8b90-45361018d1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44262,DS-1e280e63-f971-4e70-be3f-18ae039f9d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37221,DS-bd5bd701-7ddb-4405-ade8-27b2c91c9e16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-248738181-172.17.0.6-1597745083527:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36330,DS-24402dad-dbf8-4f3a-baff-044df9f3cbcf,DISK], DatanodeInfoWithStorage[127.0.0.1:35453,DS-0e98204d-1e87-46fe-ab5c-d5ed8f08fc67,DISK], DatanodeInfoWithStorage[127.0.0.1:45671,DS-0c0d7ea9-fb81-4809-931e-d4fd40cbbee3,DISK], DatanodeInfoWithStorage[127.0.0.1:40523,DS-d649f117-ea0f-4a47-bda6-dfcf41226a94,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-b95053e0-d12f-44e1-9b6b-2889d22905c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45966,DS-b2e6943a-d0f8-4fca-8b90-45361018d1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44262,DS-1e280e63-f971-4e70-be3f-18ae039f9d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37221,DS-bd5bd701-7ddb-4405-ade8-27b2c91c9e16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 1048576
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-348387395-172.17.0.6-1597745226620:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36188,DS-4802bae7-36e6-4d42-a0b2-06a69f7ea14c,DISK], DatanodeInfoWithStorage[127.0.0.1:43605,DS-14b7ec95-bc46-464b-95bd-89788399bb6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33361,DS-1698306e-c7ac-4868-b358-b18fa6ac33e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40139,DS-1db99a0c-19ca-40c5-b97d-66642c86d531,DISK], DatanodeInfoWithStorage[127.0.0.1:35336,DS-6d62b5bf-f355-44e7-a684-cac1a90853c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40784,DS-a5f40f09-347d-417b-b74d-11e453da2a64,DISK], DatanodeInfoWithStorage[127.0.0.1:41881,DS-db6e6201-b45c-41f2-a170-847945dfd88c,DISK], DatanodeInfoWithStorage[127.0.0.1:33217,DS-031d627d-f7b5-4a5a-ad70-0ac0b896756e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-348387395-172.17.0.6-1597745226620:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36188,DS-4802bae7-36e6-4d42-a0b2-06a69f7ea14c,DISK], DatanodeInfoWithStorage[127.0.0.1:43605,DS-14b7ec95-bc46-464b-95bd-89788399bb6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33361,DS-1698306e-c7ac-4868-b358-b18fa6ac33e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40139,DS-1db99a0c-19ca-40c5-b97d-66642c86d531,DISK], DatanodeInfoWithStorage[127.0.0.1:35336,DS-6d62b5bf-f355-44e7-a684-cac1a90853c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40784,DS-a5f40f09-347d-417b-b74d-11e453da2a64,DISK], DatanodeInfoWithStorage[127.0.0.1:41881,DS-db6e6201-b45c-41f2-a170-847945dfd88c,DISK], DatanodeInfoWithStorage[127.0.0.1:33217,DS-031d627d-f7b5-4a5a-ad70-0ac0b896756e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 1048576
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1560558918-172.17.0.6-1597745611803:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35251,DS-59fa9b5d-aff6-436b-94f4-bab3454c450c,DISK], DatanodeInfoWithStorage[127.0.0.1:37581,DS-64ac8eff-a021-49d2-8685-b56f035b6228,DISK], DatanodeInfoWithStorage[127.0.0.1:43789,DS-e0e2ebb2-ac12-4bc8-bc18-0f96e4f6e4ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36916,DS-153defb4-2488-4af3-b52e-66c8e2af5614,DISK], DatanodeInfoWithStorage[127.0.0.1:37081,DS-356344eb-0db5-4b9e-917a-97b4d711a343,DISK], DatanodeInfoWithStorage[127.0.0.1:46753,DS-ab9f11cf-6dfc-4e9e-b173-3597a75930c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39872,DS-bb8f7cc1-b04c-4e8d-b9b4-a2789db4c629,DISK], DatanodeInfoWithStorage[127.0.0.1:37386,DS-a6b645ea-17a2-472a-ac6a-cc57253f08ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1560558918-172.17.0.6-1597745611803:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35251,DS-59fa9b5d-aff6-436b-94f4-bab3454c450c,DISK], DatanodeInfoWithStorage[127.0.0.1:37581,DS-64ac8eff-a021-49d2-8685-b56f035b6228,DISK], DatanodeInfoWithStorage[127.0.0.1:43789,DS-e0e2ebb2-ac12-4bc8-bc18-0f96e4f6e4ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36916,DS-153defb4-2488-4af3-b52e-66c8e2af5614,DISK], DatanodeInfoWithStorage[127.0.0.1:37081,DS-356344eb-0db5-4b9e-917a-97b4d711a343,DISK], DatanodeInfoWithStorage[127.0.0.1:46753,DS-ab9f11cf-6dfc-4e9e-b173-3597a75930c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39872,DS-bb8f7cc1-b04c-4e8d-b9b4-a2789db4c629,DISK], DatanodeInfoWithStorage[127.0.0.1:37386,DS-a6b645ea-17a2-472a-ac6a-cc57253f08ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 1048576
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1914224329-172.17.0.6-1597745965357:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43599,DS-07cd2622-2c76-4f65-b94f-d1cfecb550c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39468,DS-2fb7c5d2-a858-4ec1-83cb-2215e8dece5d,DISK], DatanodeInfoWithStorage[127.0.0.1:43063,DS-20b26a19-58ee-44f7-bc57-1e1058289bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:43081,DS-29697bf8-22b4-4e41-8299-4c1762588d95,DISK], DatanodeInfoWithStorage[127.0.0.1:39175,DS-023f5dce-110e-4bbd-a0b8-b9624fc577fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37005,DS-69f0a419-0e27-4ae2-a804-c958ec735123,DISK], DatanodeInfoWithStorage[127.0.0.1:39356,DS-a8a7fbc9-1b2a-4ca6-a74a-a1288471fd8d,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-e385ae79-e7a3-4774-877b-52fea0175eef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1914224329-172.17.0.6-1597745965357:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43599,DS-07cd2622-2c76-4f65-b94f-d1cfecb550c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39468,DS-2fb7c5d2-a858-4ec1-83cb-2215e8dece5d,DISK], DatanodeInfoWithStorage[127.0.0.1:43063,DS-20b26a19-58ee-44f7-bc57-1e1058289bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:43081,DS-29697bf8-22b4-4e41-8299-4c1762588d95,DISK], DatanodeInfoWithStorage[127.0.0.1:39175,DS-023f5dce-110e-4bbd-a0b8-b9624fc577fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37005,DS-69f0a419-0e27-4ae2-a804-c958ec735123,DISK], DatanodeInfoWithStorage[127.0.0.1:39356,DS-a8a7fbc9-1b2a-4ca6-a74a-a1288471fd8d,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-e385ae79-e7a3-4774-877b-52fea0175eef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 1048576
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-729558991-172.17.0.6-1597746136434:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40434,DS-ecaef615-c8a7-4809-a36e-b575c3c8cf73,DISK], DatanodeInfoWithStorage[127.0.0.1:35616,DS-4917c623-9c5d-4aa0-bb2d-8988f50f1881,DISK], DatanodeInfoWithStorage[127.0.0.1:38390,DS-f74aed75-56e7-472b-9d8d-18e181e2d3dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42745,DS-07b3dcf9-38be-4631-a40e-3212a1baf164,DISK], DatanodeInfoWithStorage[127.0.0.1:46560,DS-3b5ab7c9-3ff7-43fb-a953-22a72c63bddc,DISK], DatanodeInfoWithStorage[127.0.0.1:45606,DS-524090a3-51f9-4c0d-9e99-d921237bbae6,DISK], DatanodeInfoWithStorage[127.0.0.1:38159,DS-2b75b8bf-1930-4575-ad27-901dbffa58fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39151,DS-f02f0293-33ce-4c62-8ba7-000089be1c8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-729558991-172.17.0.6-1597746136434:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40434,DS-ecaef615-c8a7-4809-a36e-b575c3c8cf73,DISK], DatanodeInfoWithStorage[127.0.0.1:35616,DS-4917c623-9c5d-4aa0-bb2d-8988f50f1881,DISK], DatanodeInfoWithStorage[127.0.0.1:38390,DS-f74aed75-56e7-472b-9d8d-18e181e2d3dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42745,DS-07b3dcf9-38be-4631-a40e-3212a1baf164,DISK], DatanodeInfoWithStorage[127.0.0.1:46560,DS-3b5ab7c9-3ff7-43fb-a953-22a72c63bddc,DISK], DatanodeInfoWithStorage[127.0.0.1:45606,DS-524090a3-51f9-4c0d-9e99-d921237bbae6,DISK], DatanodeInfoWithStorage[127.0.0.1:38159,DS-2b75b8bf-1930-4575-ad27-901dbffa58fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39151,DS-f02f0293-33ce-4c62-8ba7-000089be1c8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 1048576
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-781787961-172.17.0.6-1597746285547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42012,DS-2f995c8d-5755-45ac-9025-d8357b9602d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34718,DS-f1e791ee-f28e-42d4-b407-3ebd4e17ebda,DISK], DatanodeInfoWithStorage[127.0.0.1:41279,DS-92a4959e-1455-436d-a60d-d8ae9ae0cd23,DISK], DatanodeInfoWithStorage[127.0.0.1:36162,DS-75b9f832-83df-4f59-a17a-c38a6b19412c,DISK], DatanodeInfoWithStorage[127.0.0.1:39022,DS-3e49d57a-8bf0-46fb-8c00-0d32c85acf8f,DISK], DatanodeInfoWithStorage[127.0.0.1:41868,DS-f49c5886-3ae5-4902-a037-07824c418205,DISK], DatanodeInfoWithStorage[127.0.0.1:43804,DS-20284c19-ade4-4d43-876d-19f6d7d84eee,DISK], DatanodeInfoWithStorage[127.0.0.1:35370,DS-5c18bdb3-3bd2-423f-8c97-a55b06f678d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-781787961-172.17.0.6-1597746285547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42012,DS-2f995c8d-5755-45ac-9025-d8357b9602d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34718,DS-f1e791ee-f28e-42d4-b407-3ebd4e17ebda,DISK], DatanodeInfoWithStorage[127.0.0.1:41279,DS-92a4959e-1455-436d-a60d-d8ae9ae0cd23,DISK], DatanodeInfoWithStorage[127.0.0.1:36162,DS-75b9f832-83df-4f59-a17a-c38a6b19412c,DISK], DatanodeInfoWithStorage[127.0.0.1:39022,DS-3e49d57a-8bf0-46fb-8c00-0d32c85acf8f,DISK], DatanodeInfoWithStorage[127.0.0.1:41868,DS-f49c5886-3ae5-4902-a037-07824c418205,DISK], DatanodeInfoWithStorage[127.0.0.1:43804,DS-20284c19-ade4-4d43-876d-19f6d7d84eee,DISK], DatanodeInfoWithStorage[127.0.0.1:35370,DS-5c18bdb3-3bd2-423f-8c97-a55b06f678d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 1048576
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1746396290-172.17.0.6-1597747034549:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39180,DS-feb4fb33-cf9f-41f3-8988-8af0b52fc343,DISK], DatanodeInfoWithStorage[127.0.0.1:40010,DS-9de009bd-31ec-4bb6-884e-fd92e1ad9a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:34497,DS-32866a91-dd1d-4273-a481-b2c0e8079ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:43582,DS-c40d17ac-cd6b-4777-a1e7-34132f0c4765,DISK], DatanodeInfoWithStorage[127.0.0.1:42458,DS-81e65d7d-c4c4-4abd-9714-6a972b9f909f,DISK], DatanodeInfoWithStorage[127.0.0.1:38465,DS-3f479da0-f9f3-4629-a1c7-1b23af75e813,DISK], DatanodeInfoWithStorage[127.0.0.1:41041,DS-4b134b6a-0cae-4594-aae2-0af21f1d83f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40344,DS-08f828ad-e7f1-4866-ac53-559178db6e68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1746396290-172.17.0.6-1597747034549:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39180,DS-feb4fb33-cf9f-41f3-8988-8af0b52fc343,DISK], DatanodeInfoWithStorage[127.0.0.1:40010,DS-9de009bd-31ec-4bb6-884e-fd92e1ad9a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:34497,DS-32866a91-dd1d-4273-a481-b2c0e8079ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:43582,DS-c40d17ac-cd6b-4777-a1e7-34132f0c4765,DISK], DatanodeInfoWithStorage[127.0.0.1:42458,DS-81e65d7d-c4c4-4abd-9714-6a972b9f909f,DISK], DatanodeInfoWithStorage[127.0.0.1:38465,DS-3f479da0-f9f3-4629-a1c7-1b23af75e813,DISK], DatanodeInfoWithStorage[127.0.0.1:41041,DS-4b134b6a-0cae-4594-aae2-0af21f1d83f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40344,DS-08f828ad-e7f1-4866-ac53-559178db6e68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 1048576
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1699661727-172.17.0.6-1597747150536:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35484,DS-7b3f81d4-69ff-46ea-a55d-fe517d043c82,DISK], DatanodeInfoWithStorage[127.0.0.1:36732,DS-da74c13f-e444-440b-8db3-533577dde9c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40334,DS-b8aff25d-a9a4-40fc-b9cc-5235c0434da2,DISK], DatanodeInfoWithStorage[127.0.0.1:46711,DS-de2d2e94-47e3-4c11-ab48-d4505d883df4,DISK], DatanodeInfoWithStorage[127.0.0.1:37903,DS-d7943d0a-361b-47b3-a899-c613cb872035,DISK], DatanodeInfoWithStorage[127.0.0.1:46815,DS-37a681e1-9414-4e49-9b61-be6093e0b2be,DISK], DatanodeInfoWithStorage[127.0.0.1:41096,DS-fdf10020-49e2-43e7-9a4d-9901be78febf,DISK], DatanodeInfoWithStorage[127.0.0.1:42686,DS-8a72c90e-0772-4f85-904a-d4546f0dadca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1699661727-172.17.0.6-1597747150536:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35484,DS-7b3f81d4-69ff-46ea-a55d-fe517d043c82,DISK], DatanodeInfoWithStorage[127.0.0.1:36732,DS-da74c13f-e444-440b-8db3-533577dde9c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40334,DS-b8aff25d-a9a4-40fc-b9cc-5235c0434da2,DISK], DatanodeInfoWithStorage[127.0.0.1:46711,DS-de2d2e94-47e3-4c11-ab48-d4505d883df4,DISK], DatanodeInfoWithStorage[127.0.0.1:37903,DS-d7943d0a-361b-47b3-a899-c613cb872035,DISK], DatanodeInfoWithStorage[127.0.0.1:46815,DS-37a681e1-9414-4e49-9b61-be6093e0b2be,DISK], DatanodeInfoWithStorage[127.0.0.1:41096,DS-fdf10020-49e2-43e7-9a4d-9901be78febf,DISK], DatanodeInfoWithStorage[127.0.0.1:42686,DS-8a72c90e-0772-4f85-904a-d4546f0dadca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 1048576
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1990190683-172.17.0.6-1597747341240:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43894,DS-7f6285fa-0e7b-420b-ae14-84553c623576,DISK], DatanodeInfoWithStorage[127.0.0.1:39891,DS-baafd98d-f954-4ec9-b94d-48a5dfb774e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35708,DS-5a9e001d-361c-4f93-bdc7-c9c70d4729da,DISK], DatanodeInfoWithStorage[127.0.0.1:40336,DS-04cc75f8-4f4a-41e1-a895-65571eb14a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38973,DS-1be10a56-3451-4b26-b93f-31e247136336,DISK], DatanodeInfoWithStorage[127.0.0.1:41674,DS-57d54925-315d-4ef9-8b1f-f40bce0827ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37703,DS-ee590464-c5c9-4516-b0b1-8bb310ba1a15,DISK], DatanodeInfoWithStorage[127.0.0.1:35446,DS-41811c2e-e23a-42ce-9740-e0acb84e3a46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1990190683-172.17.0.6-1597747341240:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43894,DS-7f6285fa-0e7b-420b-ae14-84553c623576,DISK], DatanodeInfoWithStorage[127.0.0.1:39891,DS-baafd98d-f954-4ec9-b94d-48a5dfb774e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35708,DS-5a9e001d-361c-4f93-bdc7-c9c70d4729da,DISK], DatanodeInfoWithStorage[127.0.0.1:40336,DS-04cc75f8-4f4a-41e1-a895-65571eb14a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38973,DS-1be10a56-3451-4b26-b93f-31e247136336,DISK], DatanodeInfoWithStorage[127.0.0.1:41674,DS-57d54925-315d-4ef9-8b1f-f40bce0827ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37703,DS-ee590464-c5c9-4516-b0b1-8bb310ba1a15,DISK], DatanodeInfoWithStorage[127.0.0.1:35446,DS-41811c2e-e23a-42ce-9740-e0acb84e3a46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5453
