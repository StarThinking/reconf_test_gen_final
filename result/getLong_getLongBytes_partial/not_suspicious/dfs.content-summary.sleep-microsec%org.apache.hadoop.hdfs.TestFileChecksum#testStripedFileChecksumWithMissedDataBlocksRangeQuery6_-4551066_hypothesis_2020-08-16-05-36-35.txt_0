reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-839193319-172.17.0.6-1597556210567:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41058,DS-4e3eb8af-3018-4e67-9960-2215f7853081,DISK], DatanodeInfoWithStorage[127.0.0.1:34965,DS-0aec0cee-49c8-4bd2-a5de-5fc9ac8de4ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35111,DS-32a25d50-dae1-4251-bb41-679de0becf5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42875,DS-f30b5efa-ca45-47d8-bee3-df4d792fd41d,DISK], DatanodeInfoWithStorage[127.0.0.1:41980,DS-8a5dc92e-bd74-4ac7-ae33-559a21cb74bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36340,DS-e4eb8f8b-20f7-49f9-92b3-d492e5ca6e78,DISK], DatanodeInfoWithStorage[127.0.0.1:44497,DS-3c8a972d-89c7-42b2-8f26-8be3ad4609b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38850,DS-23a7eaa9-f0ef-41bb-9526-a9575e8a2838,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-839193319-172.17.0.6-1597556210567:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41058,DS-4e3eb8af-3018-4e67-9960-2215f7853081,DISK], DatanodeInfoWithStorage[127.0.0.1:34965,DS-0aec0cee-49c8-4bd2-a5de-5fc9ac8de4ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35111,DS-32a25d50-dae1-4251-bb41-679de0becf5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42875,DS-f30b5efa-ca45-47d8-bee3-df4d792fd41d,DISK], DatanodeInfoWithStorage[127.0.0.1:41980,DS-8a5dc92e-bd74-4ac7-ae33-559a21cb74bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36340,DS-e4eb8f8b-20f7-49f9-92b3-d492e5ca6e78,DISK], DatanodeInfoWithStorage[127.0.0.1:44497,DS-3c8a972d-89c7-42b2-8f26-8be3ad4609b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38850,DS-23a7eaa9-f0ef-41bb-9526-a9575e8a2838,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-330127355-172.17.0.6-1597556246397:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45031,DS-00a619f8-2580-4457-b385-17e988085308,DISK], DatanodeInfoWithStorage[127.0.0.1:45397,DS-1d8e4d51-b5ed-480e-b854-cb5491be1a26,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-4e91d6a7-fb25-40a7-a910-014773de88e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37169,DS-887427b9-71b9-4a52-8b9a-924fd51e9bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:37816,DS-597fd28b-9145-473e-9718-c32ed7864386,DISK], DatanodeInfoWithStorage[127.0.0.1:44349,DS-c387b5fc-20ac-47c0-8c40-ac3978e5c98b,DISK], DatanodeInfoWithStorage[127.0.0.1:42278,DS-60f56ea1-098e-4498-9078-8eb5a9841919,DISK], DatanodeInfoWithStorage[127.0.0.1:35932,DS-1b6e3b72-f4cb-458b-a6a2-e6f39874bfb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-330127355-172.17.0.6-1597556246397:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45031,DS-00a619f8-2580-4457-b385-17e988085308,DISK], DatanodeInfoWithStorage[127.0.0.1:45397,DS-1d8e4d51-b5ed-480e-b854-cb5491be1a26,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-4e91d6a7-fb25-40a7-a910-014773de88e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37169,DS-887427b9-71b9-4a52-8b9a-924fd51e9bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:37816,DS-597fd28b-9145-473e-9718-c32ed7864386,DISK], DatanodeInfoWithStorage[127.0.0.1:44349,DS-c387b5fc-20ac-47c0-8c40-ac3978e5c98b,DISK], DatanodeInfoWithStorage[127.0.0.1:42278,DS-60f56ea1-098e-4498-9078-8eb5a9841919,DISK], DatanodeInfoWithStorage[127.0.0.1:35932,DS-1b6e3b72-f4cb-458b-a6a2-e6f39874bfb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-913222961-172.17.0.6-1597556634274:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32791,DS-13bd57e6-8d4a-4d1d-9703-82a033f84957,DISK], DatanodeInfoWithStorage[127.0.0.1:40168,DS-f052c9bb-11a0-4564-8d99-34946740222d,DISK], DatanodeInfoWithStorage[127.0.0.1:33859,DS-3c8fd5cd-d53e-4aee-bf46-40d1a01d293b,DISK], DatanodeInfoWithStorage[127.0.0.1:33430,DS-49ff1643-7d36-4c42-a4ee-445751a25518,DISK], DatanodeInfoWithStorage[127.0.0.1:42726,DS-d09f4182-687d-4cac-8468-40c4b34e25c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36254,DS-221e203f-571d-4bf6-92ac-61c5b68c6519,DISK], DatanodeInfoWithStorage[127.0.0.1:35777,DS-e15b26b1-752f-4a5e-8ab6-4d2b8b53e14c,DISK], DatanodeInfoWithStorage[127.0.0.1:41743,DS-e7d15eed-1d67-4588-90cf-101a68c3cbff,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-913222961-172.17.0.6-1597556634274:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32791,DS-13bd57e6-8d4a-4d1d-9703-82a033f84957,DISK], DatanodeInfoWithStorage[127.0.0.1:40168,DS-f052c9bb-11a0-4564-8d99-34946740222d,DISK], DatanodeInfoWithStorage[127.0.0.1:33859,DS-3c8fd5cd-d53e-4aee-bf46-40d1a01d293b,DISK], DatanodeInfoWithStorage[127.0.0.1:33430,DS-49ff1643-7d36-4c42-a4ee-445751a25518,DISK], DatanodeInfoWithStorage[127.0.0.1:42726,DS-d09f4182-687d-4cac-8468-40c4b34e25c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36254,DS-221e203f-571d-4bf6-92ac-61c5b68c6519,DISK], DatanodeInfoWithStorage[127.0.0.1:35777,DS-e15b26b1-752f-4a5e-8ab6-4d2b8b53e14c,DISK], DatanodeInfoWithStorage[127.0.0.1:41743,DS-e7d15eed-1d67-4588-90cf-101a68c3cbff,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1530350415-172.17.0.6-1597556805794:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46253,DS-93ab9619-6813-406d-8699-a602b9786423,DISK], DatanodeInfoWithStorage[127.0.0.1:35627,DS-06edf647-074c-425a-b682-75037b63e187,DISK], DatanodeInfoWithStorage[127.0.0.1:42957,DS-ca4a901d-b37a-4fd8-805a-70dc4ea19961,DISK], DatanodeInfoWithStorage[127.0.0.1:34161,DS-5f2ff57b-7338-41cf-8256-9442bc37a354,DISK], DatanodeInfoWithStorage[127.0.0.1:36571,DS-933e01e6-6c91-417c-916e-0f8c69905702,DISK], DatanodeInfoWithStorage[127.0.0.1:44449,DS-dd3cd952-0526-4e34-8103-8ead6ec0d551,DISK], DatanodeInfoWithStorage[127.0.0.1:45234,DS-6b8275ad-9451-498d-b536-5596bf5986a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33664,DS-14945e6e-5a4c-447e-8b8d-ca2f9c1e1e23,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1530350415-172.17.0.6-1597556805794:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46253,DS-93ab9619-6813-406d-8699-a602b9786423,DISK], DatanodeInfoWithStorage[127.0.0.1:35627,DS-06edf647-074c-425a-b682-75037b63e187,DISK], DatanodeInfoWithStorage[127.0.0.1:42957,DS-ca4a901d-b37a-4fd8-805a-70dc4ea19961,DISK], DatanodeInfoWithStorage[127.0.0.1:34161,DS-5f2ff57b-7338-41cf-8256-9442bc37a354,DISK], DatanodeInfoWithStorage[127.0.0.1:36571,DS-933e01e6-6c91-417c-916e-0f8c69905702,DISK], DatanodeInfoWithStorage[127.0.0.1:44449,DS-dd3cd952-0526-4e34-8103-8ead6ec0d551,DISK], DatanodeInfoWithStorage[127.0.0.1:45234,DS-6b8275ad-9451-498d-b536-5596bf5986a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33664,DS-14945e6e-5a4c-447e-8b8d-ca2f9c1e1e23,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1546575661-172.17.0.6-1597556849914:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35472,DS-b6f62d26-4429-4b39-90e0-c3a183a10858,DISK], DatanodeInfoWithStorage[127.0.0.1:43009,DS-47f1e737-b83f-434c-8b2e-244638cd231f,DISK], DatanodeInfoWithStorage[127.0.0.1:35512,DS-54a9dab1-7626-4031-840e-c8414862463d,DISK], DatanodeInfoWithStorage[127.0.0.1:46206,DS-a0e1a377-ac1c-44ab-9778-a6422d446956,DISK], DatanodeInfoWithStorage[127.0.0.1:43410,DS-227a3292-c5a1-4d51-92df-ebfecbe66986,DISK], DatanodeInfoWithStorage[127.0.0.1:35870,DS-df45c634-e15c-4a8a-a18f-3b1be0b8fb2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36001,DS-e5a4a2a5-69fb-4ddd-b3d0-e2a4b91c5ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:33961,DS-54cc3e11-7cf3-4e3e-a00c-5b6aab5f5c55,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1546575661-172.17.0.6-1597556849914:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35472,DS-b6f62d26-4429-4b39-90e0-c3a183a10858,DISK], DatanodeInfoWithStorage[127.0.0.1:43009,DS-47f1e737-b83f-434c-8b2e-244638cd231f,DISK], DatanodeInfoWithStorage[127.0.0.1:35512,DS-54a9dab1-7626-4031-840e-c8414862463d,DISK], DatanodeInfoWithStorage[127.0.0.1:46206,DS-a0e1a377-ac1c-44ab-9778-a6422d446956,DISK], DatanodeInfoWithStorage[127.0.0.1:43410,DS-227a3292-c5a1-4d51-92df-ebfecbe66986,DISK], DatanodeInfoWithStorage[127.0.0.1:35870,DS-df45c634-e15c-4a8a-a18f-3b1be0b8fb2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36001,DS-e5a4a2a5-69fb-4ddd-b3d0-e2a4b91c5ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:33961,DS-54cc3e11-7cf3-4e3e-a00c-5b6aab5f5c55,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-36793761-172.17.0.6-1597556970662:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39784,DS-77647ac9-62fe-4c4d-aa49-38099ac74d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45184,DS-b3e00949-5ac5-4e9e-bf15-67358d4842c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36702,DS-d02cb07f-2f1f-44b6-a9ff-b0b54b9a4a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:38255,DS-a176e43d-795d-4a3d-b374-68bc73fc0303,DISK], DatanodeInfoWithStorage[127.0.0.1:36444,DS-2d88ff3b-ff49-4cd6-8a85-1f1dfaabd020,DISK], DatanodeInfoWithStorage[127.0.0.1:34428,DS-efeeed21-f9f1-4216-be2c-f396752f6bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:33615,DS-38e71de3-a38e-4171-a918-4ea115e84cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:37548,DS-347ed71d-a8f4-4134-8fd6-870300705bd2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-36793761-172.17.0.6-1597556970662:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39784,DS-77647ac9-62fe-4c4d-aa49-38099ac74d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45184,DS-b3e00949-5ac5-4e9e-bf15-67358d4842c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36702,DS-d02cb07f-2f1f-44b6-a9ff-b0b54b9a4a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:38255,DS-a176e43d-795d-4a3d-b374-68bc73fc0303,DISK], DatanodeInfoWithStorage[127.0.0.1:36444,DS-2d88ff3b-ff49-4cd6-8a85-1f1dfaabd020,DISK], DatanodeInfoWithStorage[127.0.0.1:34428,DS-efeeed21-f9f1-4216-be2c-f396752f6bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:33615,DS-38e71de3-a38e-4171-a918-4ea115e84cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:37548,DS-347ed71d-a8f4-4134-8fd6-870300705bd2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1135177623-172.17.0.6-1597557076161:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40735,DS-bda7136a-71ca-44cf-9b9d-941453f14da3,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-e948aa28-66c9-46de-89e5-b7c9acc26119,DISK], DatanodeInfoWithStorage[127.0.0.1:34183,DS-e3604017-21ec-4477-acee-88776c3d121b,DISK], DatanodeInfoWithStorage[127.0.0.1:37304,DS-1496de28-544b-4c82-9478-7d87709c2615,DISK], DatanodeInfoWithStorage[127.0.0.1:43590,DS-79b08379-266e-4abe-bbb2-a84675c023cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38762,DS-bc879835-45e4-45c4-ad1d-9e37a85722af,DISK], DatanodeInfoWithStorage[127.0.0.1:46155,DS-83cdbf40-db77-468a-8761-a0bdb1583fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:36805,DS-84405363-3de9-4fe1-86c9-2914b6fa6779,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1135177623-172.17.0.6-1597557076161:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40735,DS-bda7136a-71ca-44cf-9b9d-941453f14da3,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-e948aa28-66c9-46de-89e5-b7c9acc26119,DISK], DatanodeInfoWithStorage[127.0.0.1:34183,DS-e3604017-21ec-4477-acee-88776c3d121b,DISK], DatanodeInfoWithStorage[127.0.0.1:37304,DS-1496de28-544b-4c82-9478-7d87709c2615,DISK], DatanodeInfoWithStorage[127.0.0.1:43590,DS-79b08379-266e-4abe-bbb2-a84675c023cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38762,DS-bc879835-45e4-45c4-ad1d-9e37a85722af,DISK], DatanodeInfoWithStorage[127.0.0.1:46155,DS-83cdbf40-db77-468a-8761-a0bdb1583fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:36805,DS-84405363-3de9-4fe1-86c9-2914b6fa6779,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-731245068-172.17.0.6-1597557444388:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34812,DS-8e21f91c-4aa2-45e6-837f-58665f5cd8b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43274,DS-c1f88994-2c55-424c-8b67-b6fbb57978b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45634,DS-584d29f4-1695-4917-8d85-5379d1dc8189,DISK], DatanodeInfoWithStorage[127.0.0.1:33692,DS-9467efef-eaa5-46e1-b53c-b24e3b3e4c89,DISK], DatanodeInfoWithStorage[127.0.0.1:44131,DS-fea1db9c-f1f1-4307-8ab4-4a32db6e68fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45306,DS-78290322-ec99-4dc0-9479-322dd71258b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43585,DS-0e67f7bc-be82-47a1-9e75-60df2cb54935,DISK], DatanodeInfoWithStorage[127.0.0.1:37716,DS-8727c908-9e2c-475f-8e07-d4d46f000f69,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-731245068-172.17.0.6-1597557444388:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34812,DS-8e21f91c-4aa2-45e6-837f-58665f5cd8b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43274,DS-c1f88994-2c55-424c-8b67-b6fbb57978b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45634,DS-584d29f4-1695-4917-8d85-5379d1dc8189,DISK], DatanodeInfoWithStorage[127.0.0.1:33692,DS-9467efef-eaa5-46e1-b53c-b24e3b3e4c89,DISK], DatanodeInfoWithStorage[127.0.0.1:44131,DS-fea1db9c-f1f1-4307-8ab4-4a32db6e68fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45306,DS-78290322-ec99-4dc0-9479-322dd71258b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43585,DS-0e67f7bc-be82-47a1-9e75-60df2cb54935,DISK], DatanodeInfoWithStorage[127.0.0.1:37716,DS-8727c908-9e2c-475f-8e07-d4d46f000f69,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-599343883-172.17.0.6-1597557527026:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42344,DS-acd1b9d2-b5e9-44d8-997f-9ceab5899db2,DISK], DatanodeInfoWithStorage[127.0.0.1:39511,DS-5639ce6a-0dc8-482e-a23f-18080de9f2e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42426,DS-be17cde6-574a-4fad-a9c2-d3840529edac,DISK], DatanodeInfoWithStorage[127.0.0.1:34134,DS-8252d060-bafe-40ef-9f0b-12bd5269bcb1,DISK], DatanodeInfoWithStorage[127.0.0.1:43190,DS-5a605a23-fd32-41c0-8fd8-6df5fb14a1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37584,DS-71191a56-9219-424f-a609-dace3dff9797,DISK], DatanodeInfoWithStorage[127.0.0.1:32774,DS-791a3fc1-c96f-4fa2-8d5a-0b71202518c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46285,DS-e4d634b2-dad8-4cc8-8c8e-5d4a93373595,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-599343883-172.17.0.6-1597557527026:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42344,DS-acd1b9d2-b5e9-44d8-997f-9ceab5899db2,DISK], DatanodeInfoWithStorage[127.0.0.1:39511,DS-5639ce6a-0dc8-482e-a23f-18080de9f2e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42426,DS-be17cde6-574a-4fad-a9c2-d3840529edac,DISK], DatanodeInfoWithStorage[127.0.0.1:34134,DS-8252d060-bafe-40ef-9f0b-12bd5269bcb1,DISK], DatanodeInfoWithStorage[127.0.0.1:43190,DS-5a605a23-fd32-41c0-8fd8-6df5fb14a1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37584,DS-71191a56-9219-424f-a609-dace3dff9797,DISK], DatanodeInfoWithStorage[127.0.0.1:32774,DS-791a3fc1-c96f-4fa2-8d5a-0b71202518c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46285,DS-e4d634b2-dad8-4cc8-8c8e-5d4a93373595,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-708600224-172.17.0.6-1597557573654:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43363,DS-25a6383d-3d6a-4de3-98e0-e03ad1cc8f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39672,DS-35b7f6a1-aaa4-4b4c-b6e9-b09fd8877f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:35446,DS-ce5ae529-a504-4c03-b21f-8c615d06efef,DISK], DatanodeInfoWithStorage[127.0.0.1:46207,DS-90b488d4-2787-4db1-87b5-1b4ba983d278,DISK], DatanodeInfoWithStorage[127.0.0.1:45879,DS-d5b61e66-f31b-4588-ba39-09c1146bcb39,DISK], DatanodeInfoWithStorage[127.0.0.1:42180,DS-a1cb8770-ac43-4ba6-8b0e-21efb0d94542,DISK], DatanodeInfoWithStorage[127.0.0.1:42367,DS-48ad116c-5de6-4a53-8acd-69c014be4d99,DISK], DatanodeInfoWithStorage[127.0.0.1:40427,DS-e41f1137-1ab2-446c-bdc0-e09c8e7da542,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-708600224-172.17.0.6-1597557573654:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43363,DS-25a6383d-3d6a-4de3-98e0-e03ad1cc8f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39672,DS-35b7f6a1-aaa4-4b4c-b6e9-b09fd8877f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:35446,DS-ce5ae529-a504-4c03-b21f-8c615d06efef,DISK], DatanodeInfoWithStorage[127.0.0.1:46207,DS-90b488d4-2787-4db1-87b5-1b4ba983d278,DISK], DatanodeInfoWithStorage[127.0.0.1:45879,DS-d5b61e66-f31b-4588-ba39-09c1146bcb39,DISK], DatanodeInfoWithStorage[127.0.0.1:42180,DS-a1cb8770-ac43-4ba6-8b0e-21efb0d94542,DISK], DatanodeInfoWithStorage[127.0.0.1:42367,DS-48ad116c-5de6-4a53-8acd-69c014be4d99,DISK], DatanodeInfoWithStorage[127.0.0.1:40427,DS-e41f1137-1ab2-446c-bdc0-e09c8e7da542,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1475523716-172.17.0.6-1597557710083:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35575,DS-052e4b26-58c8-4489-a3ce-62cc8a170de7,DISK], DatanodeInfoWithStorage[127.0.0.1:44190,DS-be632ac5-bc2a-43c7-acff-339e81f2c1c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41029,DS-1f889e88-da87-4989-b32c-5170b603cb77,DISK], DatanodeInfoWithStorage[127.0.0.1:36930,DS-08b78d91-21a1-46d0-912c-8eb014726467,DISK], DatanodeInfoWithStorage[127.0.0.1:40578,DS-b7fc8489-757c-4d28-98ff-d37b5abfc32a,DISK], DatanodeInfoWithStorage[127.0.0.1:43604,DS-5af53a2c-96fd-4b81-b1f2-0085450031e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33211,DS-55bce7d6-fc77-4ab0-9a1a-fa01ed904e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:41616,DS-bf08fb51-0cd1-4a3c-87d9-7ca42c0ad567,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1475523716-172.17.0.6-1597557710083:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35575,DS-052e4b26-58c8-4489-a3ce-62cc8a170de7,DISK], DatanodeInfoWithStorage[127.0.0.1:44190,DS-be632ac5-bc2a-43c7-acff-339e81f2c1c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41029,DS-1f889e88-da87-4989-b32c-5170b603cb77,DISK], DatanodeInfoWithStorage[127.0.0.1:36930,DS-08b78d91-21a1-46d0-912c-8eb014726467,DISK], DatanodeInfoWithStorage[127.0.0.1:40578,DS-b7fc8489-757c-4d28-98ff-d37b5abfc32a,DISK], DatanodeInfoWithStorage[127.0.0.1:43604,DS-5af53a2c-96fd-4b81-b1f2-0085450031e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33211,DS-55bce7d6-fc77-4ab0-9a1a-fa01ed904e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:41616,DS-bf08fb51-0cd1-4a3c-87d9-7ca42c0ad567,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1046660257-172.17.0.6-1597557806102:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46480,DS-ae5d6158-2db6-4f50-9921-8c2e6919461a,DISK], DatanodeInfoWithStorage[127.0.0.1:35908,DS-c598a1b5-6045-4c87-b59f-07aacb8438c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36042,DS-9f8cc8d7-7a31-4713-82bf-6c47cb879096,DISK], DatanodeInfoWithStorage[127.0.0.1:38122,DS-48e79554-c23e-411f-bd60-a53c11d8a56d,DISK], DatanodeInfoWithStorage[127.0.0.1:44438,DS-82082ec2-c98c-4a7f-9850-85021497642b,DISK], DatanodeInfoWithStorage[127.0.0.1:38906,DS-9b9f2083-ec47-47c8-88bf-4ee8f89a0494,DISK], DatanodeInfoWithStorage[127.0.0.1:38487,DS-3b5192d7-a86c-4420-8d97-50a17afb7b93,DISK], DatanodeInfoWithStorage[127.0.0.1:37146,DS-ced13472-db45-4bdb-9361-b853a98caa05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1046660257-172.17.0.6-1597557806102:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46480,DS-ae5d6158-2db6-4f50-9921-8c2e6919461a,DISK], DatanodeInfoWithStorage[127.0.0.1:35908,DS-c598a1b5-6045-4c87-b59f-07aacb8438c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36042,DS-9f8cc8d7-7a31-4713-82bf-6c47cb879096,DISK], DatanodeInfoWithStorage[127.0.0.1:38122,DS-48e79554-c23e-411f-bd60-a53c11d8a56d,DISK], DatanodeInfoWithStorage[127.0.0.1:44438,DS-82082ec2-c98c-4a7f-9850-85021497642b,DISK], DatanodeInfoWithStorage[127.0.0.1:38906,DS-9b9f2083-ec47-47c8-88bf-4ee8f89a0494,DISK], DatanodeInfoWithStorage[127.0.0.1:38487,DS-3b5192d7-a86c-4420-8d97-50a17afb7b93,DISK], DatanodeInfoWithStorage[127.0.0.1:37146,DS-ced13472-db45-4bdb-9361-b853a98caa05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1219703650-172.17.0.6-1597557945460:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42947,DS-b0b52a74-dbb7-4fa5-8441-3a755ec93e93,DISK], DatanodeInfoWithStorage[127.0.0.1:34325,DS-13e8341b-53d9-452a-8774-d6870a0e8b06,DISK], DatanodeInfoWithStorage[127.0.0.1:43873,DS-fba1d4e9-e4c5-4df7-9589-e66a0c9942da,DISK], DatanodeInfoWithStorage[127.0.0.1:41775,DS-9a044a95-03dd-41a1-8025-735a74cd4ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:42391,DS-2e9ca135-fbcc-415d-bf84-43f092637178,DISK], DatanodeInfoWithStorage[127.0.0.1:45421,DS-a80cc3e3-d304-4d9b-941d-d27d731457a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45054,DS-5dbf6dff-39da-48c3-a32c-8bc2d970cc07,DISK], DatanodeInfoWithStorage[127.0.0.1:42768,DS-29f81f96-565b-446b-b030-eb689f1671de,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1219703650-172.17.0.6-1597557945460:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42947,DS-b0b52a74-dbb7-4fa5-8441-3a755ec93e93,DISK], DatanodeInfoWithStorage[127.0.0.1:34325,DS-13e8341b-53d9-452a-8774-d6870a0e8b06,DISK], DatanodeInfoWithStorage[127.0.0.1:43873,DS-fba1d4e9-e4c5-4df7-9589-e66a0c9942da,DISK], DatanodeInfoWithStorage[127.0.0.1:41775,DS-9a044a95-03dd-41a1-8025-735a74cd4ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:42391,DS-2e9ca135-fbcc-415d-bf84-43f092637178,DISK], DatanodeInfoWithStorage[127.0.0.1:45421,DS-a80cc3e3-d304-4d9b-941d-d27d731457a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45054,DS-5dbf6dff-39da-48c3-a32c-8bc2d970cc07,DISK], DatanodeInfoWithStorage[127.0.0.1:42768,DS-29f81f96-565b-446b-b030-eb689f1671de,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-921118215-172.17.0.6-1597558027010:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37465,DS-236a2ddf-9bd7-4690-98c9-510e5d4e7bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:42270,DS-79ec4313-955f-49d2-872b-05a5e18fcea6,DISK], DatanodeInfoWithStorage[127.0.0.1:41067,DS-52b46857-a5bb-4371-b6ce-489698f0d3d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46172,DS-cc72caaf-a6fa-4860-b8f4-cad420ac7695,DISK], DatanodeInfoWithStorage[127.0.0.1:33310,DS-99bd9100-15c4-4466-a103-bca75c98b78b,DISK], DatanodeInfoWithStorage[127.0.0.1:43037,DS-def7c36a-fadb-4266-a0ee-363c59628427,DISK], DatanodeInfoWithStorage[127.0.0.1:37019,DS-0f2be83c-4ee1-4b6b-b81a-a90a24b6faa4,DISK], DatanodeInfoWithStorage[127.0.0.1:36358,DS-e9f9582c-4136-4abd-a884-3d75311652c0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-921118215-172.17.0.6-1597558027010:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37465,DS-236a2ddf-9bd7-4690-98c9-510e5d4e7bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:42270,DS-79ec4313-955f-49d2-872b-05a5e18fcea6,DISK], DatanodeInfoWithStorage[127.0.0.1:41067,DS-52b46857-a5bb-4371-b6ce-489698f0d3d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46172,DS-cc72caaf-a6fa-4860-b8f4-cad420ac7695,DISK], DatanodeInfoWithStorage[127.0.0.1:33310,DS-99bd9100-15c4-4466-a103-bca75c98b78b,DISK], DatanodeInfoWithStorage[127.0.0.1:43037,DS-def7c36a-fadb-4266-a0ee-363c59628427,DISK], DatanodeInfoWithStorage[127.0.0.1:37019,DS-0f2be83c-4ee1-4b6b-b81a-a90a24b6faa4,DISK], DatanodeInfoWithStorage[127.0.0.1:36358,DS-e9f9582c-4136-4abd-a884-3d75311652c0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1332581142-172.17.0.6-1597558121222:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41424,DS-7983c675-a248-4d89-8725-b7d9a4083df5,DISK], DatanodeInfoWithStorage[127.0.0.1:35213,DS-0de1fa1d-b75b-415e-9bc0-fcb0af503df9,DISK], DatanodeInfoWithStorage[127.0.0.1:44607,DS-0a1c41f1-ffb8-4c13-aaa8-824106c07df1,DISK], DatanodeInfoWithStorage[127.0.0.1:45642,DS-5b9a5a49-3dad-4f9a-a17a-bdcb27b07c38,DISK], DatanodeInfoWithStorage[127.0.0.1:37223,DS-e3d07a18-d94c-4cf4-9d6b-414dc9929b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:44348,DS-2f3cfd1d-beac-409d-88c4-0f9cd053331d,DISK], DatanodeInfoWithStorage[127.0.0.1:46301,DS-d3e70ab7-ad3d-450f-b75e-ab16440a24c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36929,DS-6e336f9f-7bcf-476e-8f55-dbb752518766,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1332581142-172.17.0.6-1597558121222:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41424,DS-7983c675-a248-4d89-8725-b7d9a4083df5,DISK], DatanodeInfoWithStorage[127.0.0.1:35213,DS-0de1fa1d-b75b-415e-9bc0-fcb0af503df9,DISK], DatanodeInfoWithStorage[127.0.0.1:44607,DS-0a1c41f1-ffb8-4c13-aaa8-824106c07df1,DISK], DatanodeInfoWithStorage[127.0.0.1:45642,DS-5b9a5a49-3dad-4f9a-a17a-bdcb27b07c38,DISK], DatanodeInfoWithStorage[127.0.0.1:37223,DS-e3d07a18-d94c-4cf4-9d6b-414dc9929b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:44348,DS-2f3cfd1d-beac-409d-88c4-0f9cd053331d,DISK], DatanodeInfoWithStorage[127.0.0.1:46301,DS-d3e70ab7-ad3d-450f-b75e-ab16440a24c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36929,DS-6e336f9f-7bcf-476e-8f55-dbb752518766,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1680392194-172.17.0.6-1597558347407:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40459,DS-8132be0e-8078-4ef1-93c5-b21320c67eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:45996,DS-a72a7eec-8d99-4a98-8fd0-69438f4c3cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:36133,DS-fc962fb4-2345-4812-b7e6-0df92ddd6643,DISK], DatanodeInfoWithStorage[127.0.0.1:36275,DS-ff7a3ef4-75d9-432d-b784-a6e7d72b98a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35133,DS-169d6cd8-631e-4547-a891-6d2834229c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:36276,DS-b4ebf383-bc25-46e4-9022-056acde3a023,DISK], DatanodeInfoWithStorage[127.0.0.1:35687,DS-6e63bf05-5439-4267-b346-f6c69151ede9,DISK], DatanodeInfoWithStorage[127.0.0.1:32982,DS-261b1180-9381-4cdc-8a2b-cb7391198a7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1680392194-172.17.0.6-1597558347407:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40459,DS-8132be0e-8078-4ef1-93c5-b21320c67eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:45996,DS-a72a7eec-8d99-4a98-8fd0-69438f4c3cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:36133,DS-fc962fb4-2345-4812-b7e6-0df92ddd6643,DISK], DatanodeInfoWithStorage[127.0.0.1:36275,DS-ff7a3ef4-75d9-432d-b784-a6e7d72b98a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35133,DS-169d6cd8-631e-4547-a891-6d2834229c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:36276,DS-b4ebf383-bc25-46e4-9022-056acde3a023,DISK], DatanodeInfoWithStorage[127.0.0.1:35687,DS-6e63bf05-5439-4267-b346-f6c69151ede9,DISK], DatanodeInfoWithStorage[127.0.0.1:32982,DS-261b1180-9381-4cdc-8a2b-cb7391198a7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1498320255-172.17.0.6-1597558398736:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37723,DS-4498c373-16ee-4587-b88e-6ef20b81a4b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35389,DS-6295e4ab-7cfe-42bb-94b3-a1074234c33d,DISK], DatanodeInfoWithStorage[127.0.0.1:39597,DS-9adedae7-cc0b-4d60-af0b-c6158bbd93cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46634,DS-31476a7d-fffd-415f-9579-7d91942a15e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44269,DS-f37f9f8d-dae6-4665-85e4-ef8e89d32523,DISK], DatanodeInfoWithStorage[127.0.0.1:45851,DS-bbf41931-a57c-492f-a854-7685fa898d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:45080,DS-b90a9d8b-9edc-4bc8-9dee-67dddefe1bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:44698,DS-3f49a3c6-e090-4544-b047-fc5e777ff436,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1498320255-172.17.0.6-1597558398736:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37723,DS-4498c373-16ee-4587-b88e-6ef20b81a4b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35389,DS-6295e4ab-7cfe-42bb-94b3-a1074234c33d,DISK], DatanodeInfoWithStorage[127.0.0.1:39597,DS-9adedae7-cc0b-4d60-af0b-c6158bbd93cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46634,DS-31476a7d-fffd-415f-9579-7d91942a15e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44269,DS-f37f9f8d-dae6-4665-85e4-ef8e89d32523,DISK], DatanodeInfoWithStorage[127.0.0.1:45851,DS-bbf41931-a57c-492f-a854-7685fa898d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:45080,DS-b90a9d8b-9edc-4bc8-9dee-67dddefe1bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:44698,DS-3f49a3c6-e090-4544-b047-fc5e777ff436,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1909654940-172.17.0.6-1597558526412:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44903,DS-3165e19f-43d9-440c-a9ab-4fc23c15ce84,DISK], DatanodeInfoWithStorage[127.0.0.1:38682,DS-d3e3f221-4fb8-4e40-a40e-e75416f663c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36825,DS-48aaf400-2533-425d-a282-c2cdd792b4c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33844,DS-3aafd6fe-e546-43db-8683-f0b69d3d7074,DISK], DatanodeInfoWithStorage[127.0.0.1:37986,DS-4504d839-c650-45de-a0d0-a76314cba5c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39314,DS-14fa5417-e63e-4f12-af05-ce0dae21f9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42828,DS-090fc8c2-7cf3-4e78-9463-718a81b12c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35911,DS-afce8840-ec73-4f67-b360-ff8945ec3605,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1909654940-172.17.0.6-1597558526412:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44903,DS-3165e19f-43d9-440c-a9ab-4fc23c15ce84,DISK], DatanodeInfoWithStorage[127.0.0.1:38682,DS-d3e3f221-4fb8-4e40-a40e-e75416f663c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36825,DS-48aaf400-2533-425d-a282-c2cdd792b4c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33844,DS-3aafd6fe-e546-43db-8683-f0b69d3d7074,DISK], DatanodeInfoWithStorage[127.0.0.1:37986,DS-4504d839-c650-45de-a0d0-a76314cba5c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39314,DS-14fa5417-e63e-4f12-af05-ce0dae21f9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42828,DS-090fc8c2-7cf3-4e78-9463-718a81b12c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35911,DS-afce8840-ec73-4f67-b360-ff8945ec3605,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1343638805-172.17.0.6-1597558564082:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39078,DS-983c515a-3b6c-4e3e-a09c-a4430714ebba,DISK], DatanodeInfoWithStorage[127.0.0.1:43403,DS-11e2300c-5952-4a5a-a423-5f42813806cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41989,DS-bbc3e066-77f8-40b9-91bf-80df67a646ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39839,DS-df5b6296-ac31-4c89-a953-6a3b44a285e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36855,DS-1aec564b-83ef-4c35-8883-cda1232e5720,DISK], DatanodeInfoWithStorage[127.0.0.1:44225,DS-300469c9-4b89-4c05-ac88-0b991d68e74e,DISK], DatanodeInfoWithStorage[127.0.0.1:37646,DS-10e82b3c-09dd-485d-94f9-48127b397fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:41548,DS-3e2d7345-2794-4880-8265-86c9c9a4cc16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1343638805-172.17.0.6-1597558564082:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39078,DS-983c515a-3b6c-4e3e-a09c-a4430714ebba,DISK], DatanodeInfoWithStorage[127.0.0.1:43403,DS-11e2300c-5952-4a5a-a423-5f42813806cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41989,DS-bbc3e066-77f8-40b9-91bf-80df67a646ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39839,DS-df5b6296-ac31-4c89-a953-6a3b44a285e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36855,DS-1aec564b-83ef-4c35-8883-cda1232e5720,DISK], DatanodeInfoWithStorage[127.0.0.1:44225,DS-300469c9-4b89-4c05-ac88-0b991d68e74e,DISK], DatanodeInfoWithStorage[127.0.0.1:37646,DS-10e82b3c-09dd-485d-94f9-48127b397fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:41548,DS-3e2d7345-2794-4880-8265-86c9c9a4cc16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1568938924-172.17.0.6-1597558607787:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46834,DS-af5ba5f8-5285-4c26-9e4a-e19ee1edb5f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35434,DS-2605fbbd-c3a5-4b40-a93d-48f695e50a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40341,DS-85bd4651-0a30-4999-b0fc-626e7c729157,DISK], DatanodeInfoWithStorage[127.0.0.1:39318,DS-6f91ccdf-927a-4c1e-ab12-081ec91c2110,DISK], DatanodeInfoWithStorage[127.0.0.1:45897,DS-2283f7d4-1be3-47fd-bb3b-efaf8470e480,DISK], DatanodeInfoWithStorage[127.0.0.1:40537,DS-48c708d9-53b3-402c-bc7f-b64decf32f08,DISK], DatanodeInfoWithStorage[127.0.0.1:44259,DS-2fc86ef8-3cb0-480b-9443-18e56ddb1182,DISK], DatanodeInfoWithStorage[127.0.0.1:36093,DS-e9828f28-d791-4736-af97-614b2fda70a2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1568938924-172.17.0.6-1597558607787:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46834,DS-af5ba5f8-5285-4c26-9e4a-e19ee1edb5f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35434,DS-2605fbbd-c3a5-4b40-a93d-48f695e50a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40341,DS-85bd4651-0a30-4999-b0fc-626e7c729157,DISK], DatanodeInfoWithStorage[127.0.0.1:39318,DS-6f91ccdf-927a-4c1e-ab12-081ec91c2110,DISK], DatanodeInfoWithStorage[127.0.0.1:45897,DS-2283f7d4-1be3-47fd-bb3b-efaf8470e480,DISK], DatanodeInfoWithStorage[127.0.0.1:40537,DS-48c708d9-53b3-402c-bc7f-b64decf32f08,DISK], DatanodeInfoWithStorage[127.0.0.1:44259,DS-2fc86ef8-3cb0-480b-9443-18e56ddb1182,DISK], DatanodeInfoWithStorage[127.0.0.1:36093,DS-e9828f28-d791-4736-af97-614b2fda70a2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1369327626-172.17.0.6-1597558700952:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38892,DS-59550eb3-90f6-4fce-9af0-6bed8eb1a3a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35668,DS-ea60b77c-3ea3-42c1-a196-57e40fd51edb,DISK], DatanodeInfoWithStorage[127.0.0.1:37903,DS-3065ccac-9439-4cf9-be33-465685da6188,DISK], DatanodeInfoWithStorage[127.0.0.1:40046,DS-2ab96310-4d96-47a7-8da8-0a7fa4c3ba54,DISK], DatanodeInfoWithStorage[127.0.0.1:35698,DS-98ce59e5-725d-444e-b126-cedb6a49c080,DISK], DatanodeInfoWithStorage[127.0.0.1:36776,DS-d746285a-6489-49f2-a76b-22dd9180dec6,DISK], DatanodeInfoWithStorage[127.0.0.1:36967,DS-af20ce72-564c-41fb-999c-edef3d4434c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41884,DS-89507614-3046-48a9-8bca-6fcbb58f196c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1369327626-172.17.0.6-1597558700952:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38892,DS-59550eb3-90f6-4fce-9af0-6bed8eb1a3a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35668,DS-ea60b77c-3ea3-42c1-a196-57e40fd51edb,DISK], DatanodeInfoWithStorage[127.0.0.1:37903,DS-3065ccac-9439-4cf9-be33-465685da6188,DISK], DatanodeInfoWithStorage[127.0.0.1:40046,DS-2ab96310-4d96-47a7-8da8-0a7fa4c3ba54,DISK], DatanodeInfoWithStorage[127.0.0.1:35698,DS-98ce59e5-725d-444e-b126-cedb6a49c080,DISK], DatanodeInfoWithStorage[127.0.0.1:36776,DS-d746285a-6489-49f2-a76b-22dd9180dec6,DISK], DatanodeInfoWithStorage[127.0.0.1:36967,DS-af20ce72-564c-41fb-999c-edef3d4434c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41884,DS-89507614-3046-48a9-8bca-6fcbb58f196c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2062496498-172.17.0.6-1597559231552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39264,DS-9a87f1fc-8839-4dfd-8378-1731f557cbc2,DISK], DatanodeInfoWithStorage[127.0.0.1:41426,DS-ef8dcc0e-2b06-4cf0-937a-ca6a97941409,DISK], DatanodeInfoWithStorage[127.0.0.1:35324,DS-2b269c01-b384-4a79-8431-70381d8056d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43037,DS-1ff7df1e-12e3-4218-bbb6-25e8af880fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:34152,DS-f09d30b0-e221-4548-b54b-e30029b0bbee,DISK], DatanodeInfoWithStorage[127.0.0.1:45824,DS-f688242f-10aa-4ba7-afbb-6c3f5fed4a45,DISK], DatanodeInfoWithStorage[127.0.0.1:45828,DS-04349d04-c928-4f82-bc39-d81503af0573,DISK], DatanodeInfoWithStorage[127.0.0.1:41263,DS-af1cfa5e-4414-435b-9acc-0f2af8cc7272,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2062496498-172.17.0.6-1597559231552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39264,DS-9a87f1fc-8839-4dfd-8378-1731f557cbc2,DISK], DatanodeInfoWithStorage[127.0.0.1:41426,DS-ef8dcc0e-2b06-4cf0-937a-ca6a97941409,DISK], DatanodeInfoWithStorage[127.0.0.1:35324,DS-2b269c01-b384-4a79-8431-70381d8056d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43037,DS-1ff7df1e-12e3-4218-bbb6-25e8af880fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:34152,DS-f09d30b0-e221-4548-b54b-e30029b0bbee,DISK], DatanodeInfoWithStorage[127.0.0.1:45824,DS-f688242f-10aa-4ba7-afbb-6c3f5fed4a45,DISK], DatanodeInfoWithStorage[127.0.0.1:45828,DS-04349d04-c928-4f82-bc39-d81503af0573,DISK], DatanodeInfoWithStorage[127.0.0.1:41263,DS-af1cfa5e-4414-435b-9acc-0f2af8cc7272,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1835205073-172.17.0.6-1597559504170:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42033,DS-6051ceb5-1361-4b60-963f-4686040d5208,DISK], DatanodeInfoWithStorage[127.0.0.1:39513,DS-4a27aa5f-1d8e-4fe5-91f5-886924b57b10,DISK], DatanodeInfoWithStorage[127.0.0.1:45546,DS-2e42ae37-436e-40ec-bed7-83bf78c07364,DISK], DatanodeInfoWithStorage[127.0.0.1:36394,DS-d44c5f81-4811-495c-83b8-a8f8f650a806,DISK], DatanodeInfoWithStorage[127.0.0.1:36100,DS-0041baa4-faa6-458c-a9c0-133256ef3e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:42769,DS-bea411dd-1a0e-4d9f-9a1a-af9de8f3b4b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46514,DS-4183712e-8053-45e0-87b2-da67d77b83eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34990,DS-e457b589-5b74-41e8-9841-a52a217a7c23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1835205073-172.17.0.6-1597559504170:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42033,DS-6051ceb5-1361-4b60-963f-4686040d5208,DISK], DatanodeInfoWithStorage[127.0.0.1:39513,DS-4a27aa5f-1d8e-4fe5-91f5-886924b57b10,DISK], DatanodeInfoWithStorage[127.0.0.1:45546,DS-2e42ae37-436e-40ec-bed7-83bf78c07364,DISK], DatanodeInfoWithStorage[127.0.0.1:36394,DS-d44c5f81-4811-495c-83b8-a8f8f650a806,DISK], DatanodeInfoWithStorage[127.0.0.1:36100,DS-0041baa4-faa6-458c-a9c0-133256ef3e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:42769,DS-bea411dd-1a0e-4d9f-9a1a-af9de8f3b4b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46514,DS-4183712e-8053-45e0-87b2-da67d77b83eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34990,DS-e457b589-5b74-41e8-9841-a52a217a7c23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1795652830-172.17.0.6-1597560835242:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45043,DS-a958ce77-1ce2-4f54-b8ee-26b2e07a166e,DISK], DatanodeInfoWithStorage[127.0.0.1:33873,DS-1db5b7be-1d2d-4f43-935c-d928f2a0e801,DISK], DatanodeInfoWithStorage[127.0.0.1:35165,DS-bccb3bcf-f67e-41d5-a1c0-9bf9ff421583,DISK], DatanodeInfoWithStorage[127.0.0.1:38417,DS-f8fae1a5-97d2-4e7b-84b1-9cfa82d1690c,DISK], DatanodeInfoWithStorage[127.0.0.1:46602,DS-ab45c858-3b31-4fa9-8348-57ab8d34f369,DISK], DatanodeInfoWithStorage[127.0.0.1:36388,DS-cafb1ee8-ed6f-4339-82e8-fb4dc7ac9c95,DISK], DatanodeInfoWithStorage[127.0.0.1:42299,DS-a62de865-53f0-4988-97b3-ff3402bbb781,DISK], DatanodeInfoWithStorage[127.0.0.1:41256,DS-1e2dc627-437a-4c8d-9f11-850b95f7f959,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1795652830-172.17.0.6-1597560835242:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45043,DS-a958ce77-1ce2-4f54-b8ee-26b2e07a166e,DISK], DatanodeInfoWithStorage[127.0.0.1:33873,DS-1db5b7be-1d2d-4f43-935c-d928f2a0e801,DISK], DatanodeInfoWithStorage[127.0.0.1:35165,DS-bccb3bcf-f67e-41d5-a1c0-9bf9ff421583,DISK], DatanodeInfoWithStorage[127.0.0.1:38417,DS-f8fae1a5-97d2-4e7b-84b1-9cfa82d1690c,DISK], DatanodeInfoWithStorage[127.0.0.1:46602,DS-ab45c858-3b31-4fa9-8348-57ab8d34f369,DISK], DatanodeInfoWithStorage[127.0.0.1:36388,DS-cafb1ee8-ed6f-4339-82e8-fb4dc7ac9c95,DISK], DatanodeInfoWithStorage[127.0.0.1:42299,DS-a62de865-53f0-4988-97b3-ff3402bbb781,DISK], DatanodeInfoWithStorage[127.0.0.1:41256,DS-1e2dc627-437a-4c8d-9f11-850b95f7f959,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2108135618-172.17.0.6-1597561208664:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43159,DS-0a6f7b41-3997-414d-85db-9f5be693a070,DISK], DatanodeInfoWithStorage[127.0.0.1:32791,DS-fc341a05-e4e6-40a1-82b9-4ee5f743857b,DISK], DatanodeInfoWithStorage[127.0.0.1:41923,DS-60c527b3-a742-4ea2-9af5-ca71de4d3208,DISK], DatanodeInfoWithStorage[127.0.0.1:43121,DS-a0d86db0-60ee-482d-9a3c-8cf05b4c5ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:44772,DS-bce00acb-c51b-452e-9b19-48f04b2c84f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40299,DS-e1c5d2fe-f4f1-4429-ae42-4435591f39e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41850,DS-9b3b6993-3b64-4349-8afe-4d7a73a9ba70,DISK], DatanodeInfoWithStorage[127.0.0.1:42951,DS-b6f2b5b8-9797-429d-b2da-8135d1ec34ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2108135618-172.17.0.6-1597561208664:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43159,DS-0a6f7b41-3997-414d-85db-9f5be693a070,DISK], DatanodeInfoWithStorage[127.0.0.1:32791,DS-fc341a05-e4e6-40a1-82b9-4ee5f743857b,DISK], DatanodeInfoWithStorage[127.0.0.1:41923,DS-60c527b3-a742-4ea2-9af5-ca71de4d3208,DISK], DatanodeInfoWithStorage[127.0.0.1:43121,DS-a0d86db0-60ee-482d-9a3c-8cf05b4c5ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:44772,DS-bce00acb-c51b-452e-9b19-48f04b2c84f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40299,DS-e1c5d2fe-f4f1-4429-ae42-4435591f39e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41850,DS-9b3b6993-3b64-4349-8afe-4d7a73a9ba70,DISK], DatanodeInfoWithStorage[127.0.0.1:42951,DS-b6f2b5b8-9797-429d-b2da-8135d1ec34ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-510567958-172.17.0.6-1597561336466:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34422,DS-faed3a66-0273-4ceb-85f7-3575128eafa5,DISK], DatanodeInfoWithStorage[127.0.0.1:36090,DS-80591bb6-7cd3-42e6-acf8-8950cf92864f,DISK], DatanodeInfoWithStorage[127.0.0.1:36572,DS-a4e2c986-842e-4cbf-8e15-5fc554ac2299,DISK], DatanodeInfoWithStorage[127.0.0.1:41732,DS-23711d6f-008e-4217-bd8e-25ddf67abd8c,DISK], DatanodeInfoWithStorage[127.0.0.1:43956,DS-9e8ad055-2552-4742-a3b0-71ed8a7196d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40481,DS-091613a5-23b8-49b9-84a0-a212ca02da6b,DISK], DatanodeInfoWithStorage[127.0.0.1:39740,DS-060b579a-9eb0-4d5e-83be-3cce36589827,DISK], DatanodeInfoWithStorage[127.0.0.1:45394,DS-8770bfe0-85c9-43ed-95e0-bf9cf58880a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-510567958-172.17.0.6-1597561336466:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34422,DS-faed3a66-0273-4ceb-85f7-3575128eafa5,DISK], DatanodeInfoWithStorage[127.0.0.1:36090,DS-80591bb6-7cd3-42e6-acf8-8950cf92864f,DISK], DatanodeInfoWithStorage[127.0.0.1:36572,DS-a4e2c986-842e-4cbf-8e15-5fc554ac2299,DISK], DatanodeInfoWithStorage[127.0.0.1:41732,DS-23711d6f-008e-4217-bd8e-25ddf67abd8c,DISK], DatanodeInfoWithStorage[127.0.0.1:43956,DS-9e8ad055-2552-4742-a3b0-71ed8a7196d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40481,DS-091613a5-23b8-49b9-84a0-a212ca02da6b,DISK], DatanodeInfoWithStorage[127.0.0.1:39740,DS-060b579a-9eb0-4d5e-83be-3cce36589827,DISK], DatanodeInfoWithStorage[127.0.0.1:45394,DS-8770bfe0-85c9-43ed-95e0-bf9cf58880a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1551933455-172.17.0.6-1597561389498:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38015,DS-2e25a666-3a7a-4ce2-9128-1308c0537811,DISK], DatanodeInfoWithStorage[127.0.0.1:33094,DS-e334cf83-44e7-4a67-bf34-c855a2251e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40764,DS-7b3d4494-0343-43fa-ba60-cfa39bcb8d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:37380,DS-700ee020-b571-45d2-8293-015e77e021d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44127,DS-fccedcf6-8021-40c8-9bdb-c3d7a16bfc92,DISK], DatanodeInfoWithStorage[127.0.0.1:37930,DS-c7dc63ec-fc8b-4e48-9b73-8617786500b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-976a30be-f0b1-4a49-8fcd-b5cd15829d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33012,DS-f776573c-3c74-43c7-ab72-77eace53f3ff,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1551933455-172.17.0.6-1597561389498:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38015,DS-2e25a666-3a7a-4ce2-9128-1308c0537811,DISK], DatanodeInfoWithStorage[127.0.0.1:33094,DS-e334cf83-44e7-4a67-bf34-c855a2251e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40764,DS-7b3d4494-0343-43fa-ba60-cfa39bcb8d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:37380,DS-700ee020-b571-45d2-8293-015e77e021d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44127,DS-fccedcf6-8021-40c8-9bdb-c3d7a16bfc92,DISK], DatanodeInfoWithStorage[127.0.0.1:37930,DS-c7dc63ec-fc8b-4e48-9b73-8617786500b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-976a30be-f0b1-4a49-8fcd-b5cd15829d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33012,DS-f776573c-3c74-43c7-ab72-77eace53f3ff,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1612743168-172.17.0.6-1597561630205:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46688,DS-7974e236-d294-459e-b62e-326acc8e1307,DISK], DatanodeInfoWithStorage[127.0.0.1:45002,DS-22b72039-b215-4169-aea8-9f16e4af5db6,DISK], DatanodeInfoWithStorage[127.0.0.1:35849,DS-8c63bd27-6987-4625-80ea-473e4ca3afc2,DISK], DatanodeInfoWithStorage[127.0.0.1:43223,DS-8c60d0e3-7dff-49ff-8b79-71dec63ad790,DISK], DatanodeInfoWithStorage[127.0.0.1:45406,DS-d7b59ae7-d599-4ad8-a28e-a2bed137c093,DISK], DatanodeInfoWithStorage[127.0.0.1:40286,DS-8e08556d-b8e3-4a91-9d74-e59b06955126,DISK], DatanodeInfoWithStorage[127.0.0.1:34328,DS-820c290d-b55c-4957-85e3-48d4cc332f89,DISK], DatanodeInfoWithStorage[127.0.0.1:36789,DS-aa258de4-e03e-4596-87a9-8488c4266f77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1612743168-172.17.0.6-1597561630205:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46688,DS-7974e236-d294-459e-b62e-326acc8e1307,DISK], DatanodeInfoWithStorage[127.0.0.1:45002,DS-22b72039-b215-4169-aea8-9f16e4af5db6,DISK], DatanodeInfoWithStorage[127.0.0.1:35849,DS-8c63bd27-6987-4625-80ea-473e4ca3afc2,DISK], DatanodeInfoWithStorage[127.0.0.1:43223,DS-8c60d0e3-7dff-49ff-8b79-71dec63ad790,DISK], DatanodeInfoWithStorage[127.0.0.1:45406,DS-d7b59ae7-d599-4ad8-a28e-a2bed137c093,DISK], DatanodeInfoWithStorage[127.0.0.1:40286,DS-8e08556d-b8e3-4a91-9d74-e59b06955126,DISK], DatanodeInfoWithStorage[127.0.0.1:34328,DS-820c290d-b55c-4957-85e3-48d4cc332f89,DISK], DatanodeInfoWithStorage[127.0.0.1:36789,DS-aa258de4-e03e-4596-87a9-8488c4266f77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-753794265-172.17.0.6-1597561813829:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42911,DS-9935b0cc-7f46-4788-b4e1-8120001b445c,DISK], DatanodeInfoWithStorage[127.0.0.1:40279,DS-07e44fad-e1c8-4e45-8ecf-604eabb77e69,DISK], DatanodeInfoWithStorage[127.0.0.1:34386,DS-64d88044-3748-4dee-8b32-4278943811c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44711,DS-0620a9be-0d3a-45b8-96f4-a883617a789b,DISK], DatanodeInfoWithStorage[127.0.0.1:37629,DS-c9c4d260-fefb-4884-b467-7a6f586efe90,DISK], DatanodeInfoWithStorage[127.0.0.1:45925,DS-e62a23c3-a613-49e0-b4a7-21eb53ad8afc,DISK], DatanodeInfoWithStorage[127.0.0.1:35055,DS-454263f3-41da-422f-a020-5f59e4b85b33,DISK], DatanodeInfoWithStorage[127.0.0.1:44508,DS-d21c9951-e196-4dc3-b3e4-d8820c5bcae6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-753794265-172.17.0.6-1597561813829:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42911,DS-9935b0cc-7f46-4788-b4e1-8120001b445c,DISK], DatanodeInfoWithStorage[127.0.0.1:40279,DS-07e44fad-e1c8-4e45-8ecf-604eabb77e69,DISK], DatanodeInfoWithStorage[127.0.0.1:34386,DS-64d88044-3748-4dee-8b32-4278943811c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44711,DS-0620a9be-0d3a-45b8-96f4-a883617a789b,DISK], DatanodeInfoWithStorage[127.0.0.1:37629,DS-c9c4d260-fefb-4884-b467-7a6f586efe90,DISK], DatanodeInfoWithStorage[127.0.0.1:45925,DS-e62a23c3-a613-49e0-b4a7-21eb53ad8afc,DISK], DatanodeInfoWithStorage[127.0.0.1:35055,DS-454263f3-41da-422f-a020-5f59e4b85b33,DISK], DatanodeInfoWithStorage[127.0.0.1:44508,DS-d21c9951-e196-4dc3-b3e4-d8820c5bcae6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1970301234-172.17.0.6-1597561915402:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37131,DS-aba6eee5-799e-48fc-afc0-ca24ad83db0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36886,DS-776361da-a0d8-4224-ac7e-518fdbf78a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44333,DS-08a54b24-04c2-47df-ad6b-dc5e39af0c34,DISK], DatanodeInfoWithStorage[127.0.0.1:42411,DS-ccec5c29-e3ae-4d6c-8051-1ae256bd9589,DISK], DatanodeInfoWithStorage[127.0.0.1:38986,DS-786a2096-b769-4ae3-9c47-bb2d6a49f529,DISK], DatanodeInfoWithStorage[127.0.0.1:38222,DS-6773f457-31d3-4c85-8740-554f3cb1e67b,DISK], DatanodeInfoWithStorage[127.0.0.1:40793,DS-33a6929b-d715-4229-b0a7-a7c397e50592,DISK], DatanodeInfoWithStorage[127.0.0.1:40484,DS-a9cb7d57-17f0-4a9d-b14c-0d0a13fe52f5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1970301234-172.17.0.6-1597561915402:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37131,DS-aba6eee5-799e-48fc-afc0-ca24ad83db0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36886,DS-776361da-a0d8-4224-ac7e-518fdbf78a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44333,DS-08a54b24-04c2-47df-ad6b-dc5e39af0c34,DISK], DatanodeInfoWithStorage[127.0.0.1:42411,DS-ccec5c29-e3ae-4d6c-8051-1ae256bd9589,DISK], DatanodeInfoWithStorage[127.0.0.1:38986,DS-786a2096-b769-4ae3-9c47-bb2d6a49f529,DISK], DatanodeInfoWithStorage[127.0.0.1:38222,DS-6773f457-31d3-4c85-8740-554f3cb1e67b,DISK], DatanodeInfoWithStorage[127.0.0.1:40793,DS-33a6929b-d715-4229-b0a7-a7c397e50592,DISK], DatanodeInfoWithStorage[127.0.0.1:40484,DS-a9cb7d57-17f0-4a9d-b14c-0d0a13fe52f5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1085339118-172.17.0.6-1597561971056:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39443,DS-8cb1644a-0947-4b3c-b200-8232091a0033,DISK], DatanodeInfoWithStorage[127.0.0.1:44695,DS-860755fa-b647-45c1-b3f3-1973d3f9576f,DISK], DatanodeInfoWithStorage[127.0.0.1:34290,DS-19f7634b-d50a-4395-87e4-e697aab8bd7d,DISK], DatanodeInfoWithStorage[127.0.0.1:43239,DS-68591b79-6258-4125-a590-6dcf11eeb6a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44052,DS-5a9de9d4-aadb-40b1-9370-9c1e51f130f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44965,DS-9d5f0f8c-df47-440e-9b04-1cf23f88a6d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45307,DS-f903136d-b07a-4648-9c0d-8a5acc239e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:34178,DS-0a7e130d-0e76-49f3-8b26-d2fd3edec5a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1085339118-172.17.0.6-1597561971056:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39443,DS-8cb1644a-0947-4b3c-b200-8232091a0033,DISK], DatanodeInfoWithStorage[127.0.0.1:44695,DS-860755fa-b647-45c1-b3f3-1973d3f9576f,DISK], DatanodeInfoWithStorage[127.0.0.1:34290,DS-19f7634b-d50a-4395-87e4-e697aab8bd7d,DISK], DatanodeInfoWithStorage[127.0.0.1:43239,DS-68591b79-6258-4125-a590-6dcf11eeb6a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44052,DS-5a9de9d4-aadb-40b1-9370-9c1e51f130f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44965,DS-9d5f0f8c-df47-440e-9b04-1cf23f88a6d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45307,DS-f903136d-b07a-4648-9c0d-8a5acc239e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:34178,DS-0a7e130d-0e76-49f3-8b26-d2fd3edec5a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-508161373-172.17.0.6-1597562420739:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42619,DS-3fa27f82-8fdb-4f50-b5d6-80ff2b513a94,DISK], DatanodeInfoWithStorage[127.0.0.1:42550,DS-9922fa9e-5cc9-4df6-a41e-e04ccddeb01c,DISK], DatanodeInfoWithStorage[127.0.0.1:35968,DS-c81803c2-6d8d-44a0-af66-6f1250da996f,DISK], DatanodeInfoWithStorage[127.0.0.1:41235,DS-dc9d12c5-ac49-4c30-954d-7b8472552b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33931,DS-113ec6de-f5b5-4549-af26-d8afc65cacb3,DISK], DatanodeInfoWithStorage[127.0.0.1:36500,DS-63d28389-d75c-45af-9fa1-c03672ae823a,DISK], DatanodeInfoWithStorage[127.0.0.1:42377,DS-0d11c6b5-ad73-4e89-813d-373352d0b39b,DISK], DatanodeInfoWithStorage[127.0.0.1:37268,DS-32c856dc-6d11-4bca-bd7f-024704289880,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-508161373-172.17.0.6-1597562420739:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42619,DS-3fa27f82-8fdb-4f50-b5d6-80ff2b513a94,DISK], DatanodeInfoWithStorage[127.0.0.1:42550,DS-9922fa9e-5cc9-4df6-a41e-e04ccddeb01c,DISK], DatanodeInfoWithStorage[127.0.0.1:35968,DS-c81803c2-6d8d-44a0-af66-6f1250da996f,DISK], DatanodeInfoWithStorage[127.0.0.1:41235,DS-dc9d12c5-ac49-4c30-954d-7b8472552b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33931,DS-113ec6de-f5b5-4549-af26-d8afc65cacb3,DISK], DatanodeInfoWithStorage[127.0.0.1:36500,DS-63d28389-d75c-45af-9fa1-c03672ae823a,DISK], DatanodeInfoWithStorage[127.0.0.1:42377,DS-0d11c6b5-ad73-4e89-813d-373352d0b39b,DISK], DatanodeInfoWithStorage[127.0.0.1:37268,DS-32c856dc-6d11-4bca-bd7f-024704289880,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-388826655-172.17.0.6-1597562809622:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44723,DS-409e9f31-2026-4a52-a9c8-b930efb57e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:43279,DS-afb70bdf-09a0-452e-870e-57afd4c3cd34,DISK], DatanodeInfoWithStorage[127.0.0.1:38836,DS-783f59e4-150c-44c1-a9e3-e564cb9fd682,DISK], DatanodeInfoWithStorage[127.0.0.1:42913,DS-7763dfb2-7127-4da8-93e0-e10b4a710bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:44088,DS-f302b677-80b3-482f-81d9-855142bcfa03,DISK], DatanodeInfoWithStorage[127.0.0.1:37409,DS-a0ec7bf4-ac6a-431c-b090-2c945270d946,DISK], DatanodeInfoWithStorage[127.0.0.1:38931,DS-dbed6595-835f-4f14-abf3-851fcba20aae,DISK], DatanodeInfoWithStorage[127.0.0.1:34780,DS-6e3ce423-3604-47ea-9ed6-e6b500ffd054,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-388826655-172.17.0.6-1597562809622:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44723,DS-409e9f31-2026-4a52-a9c8-b930efb57e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:43279,DS-afb70bdf-09a0-452e-870e-57afd4c3cd34,DISK], DatanodeInfoWithStorage[127.0.0.1:38836,DS-783f59e4-150c-44c1-a9e3-e564cb9fd682,DISK], DatanodeInfoWithStorage[127.0.0.1:42913,DS-7763dfb2-7127-4da8-93e0-e10b4a710bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:44088,DS-f302b677-80b3-482f-81d9-855142bcfa03,DISK], DatanodeInfoWithStorage[127.0.0.1:37409,DS-a0ec7bf4-ac6a-431c-b090-2c945270d946,DISK], DatanodeInfoWithStorage[127.0.0.1:38931,DS-dbed6595-835f-4f14-abf3-851fcba20aae,DISK], DatanodeInfoWithStorage[127.0.0.1:34780,DS-6e3ce423-3604-47ea-9ed6-e6b500ffd054,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-686930409-172.17.0.6-1597562999450:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43938,DS-775d53ba-6ac5-4c33-b7fb-6d76cf5fbb67,DISK], DatanodeInfoWithStorage[127.0.0.1:33278,DS-1b6fc96b-02cf-45fd-a006-17a52084efef,DISK], DatanodeInfoWithStorage[127.0.0.1:36333,DS-4b73da3f-6421-43a0-ad72-74f7636d6671,DISK], DatanodeInfoWithStorage[127.0.0.1:34157,DS-c777d3a4-3d2a-4897-93e1-6956cb91e4f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42969,DS-0ded0466-9004-4e3d-8ac5-10e16c1a1eef,DISK], DatanodeInfoWithStorage[127.0.0.1:39468,DS-54683d75-2f00-41c9-9a36-7abf9774d080,DISK], DatanodeInfoWithStorage[127.0.0.1:35298,DS-bb507730-7603-4c1c-ad15-5875ce74e92e,DISK], DatanodeInfoWithStorage[127.0.0.1:35893,DS-8a92846e-49ff-4fa5-932f-86563b99c125,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-686930409-172.17.0.6-1597562999450:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43938,DS-775d53ba-6ac5-4c33-b7fb-6d76cf5fbb67,DISK], DatanodeInfoWithStorage[127.0.0.1:33278,DS-1b6fc96b-02cf-45fd-a006-17a52084efef,DISK], DatanodeInfoWithStorage[127.0.0.1:36333,DS-4b73da3f-6421-43a0-ad72-74f7636d6671,DISK], DatanodeInfoWithStorage[127.0.0.1:34157,DS-c777d3a4-3d2a-4897-93e1-6956cb91e4f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42969,DS-0ded0466-9004-4e3d-8ac5-10e16c1a1eef,DISK], DatanodeInfoWithStorage[127.0.0.1:39468,DS-54683d75-2f00-41c9-9a36-7abf9774d080,DISK], DatanodeInfoWithStorage[127.0.0.1:35298,DS-bb507730-7603-4c1c-ad15-5875ce74e92e,DISK], DatanodeInfoWithStorage[127.0.0.1:35893,DS-8a92846e-49ff-4fa5-932f-86563b99c125,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 21 out of 50
result: false positive !!!
Total execution time in seconds : 6921
