reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 262144
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 262144
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-723010590-172.17.0.11-1597370077811:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34553,DS-13e014e8-ed3f-4e38-bea9-dabfeca2e830,DISK], DatanodeInfoWithStorage[127.0.0.1:36304,DS-84b2ea8e-a625-47b5-a3e4-0fbeaac23e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35850,DS-26fe50d7-e74b-4f8f-a17f-232eeef2aee1,DISK], DatanodeInfoWithStorage[127.0.0.1:34931,DS-a28319f4-f290-4727-835d-f1e7dd6881ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34193,DS-777b205a-f437-4dd9-9a2e-4455b618e464,DISK], DatanodeInfoWithStorage[127.0.0.1:44966,DS-e98dca98-1bcb-4c8c-acfb-45cb7742093e,DISK], DatanodeInfoWithStorage[127.0.0.1:36625,DS-c101a4a4-b5ac-43cf-bbca-fa84dc9ca55e,DISK], DatanodeInfoWithStorage[127.0.0.1:33391,DS-096903e8-a54d-4b6a-b940-86c6675a70ba,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-723010590-172.17.0.11-1597370077811:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34553,DS-13e014e8-ed3f-4e38-bea9-dabfeca2e830,DISK], DatanodeInfoWithStorage[127.0.0.1:36304,DS-84b2ea8e-a625-47b5-a3e4-0fbeaac23e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35850,DS-26fe50d7-e74b-4f8f-a17f-232eeef2aee1,DISK], DatanodeInfoWithStorage[127.0.0.1:34931,DS-a28319f4-f290-4727-835d-f1e7dd6881ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34193,DS-777b205a-f437-4dd9-9a2e-4455b618e464,DISK], DatanodeInfoWithStorage[127.0.0.1:44966,DS-e98dca98-1bcb-4c8c-acfb-45cb7742093e,DISK], DatanodeInfoWithStorage[127.0.0.1:36625,DS-c101a4a4-b5ac-43cf-bbca-fa84dc9ca55e,DISK], DatanodeInfoWithStorage[127.0.0.1:33391,DS-096903e8-a54d-4b6a-b940-86c6675a70ba,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 262144
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-293577360-172.17.0.11-1597370411777:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36784,DS-eb8f98e3-df05-4872-96ef-2d5f86142203,DISK], DatanodeInfoWithStorage[127.0.0.1:44258,DS-5d7d1c67-c9ba-4f04-8f2c-7ad37927c861,DISK], DatanodeInfoWithStorage[127.0.0.1:46083,DS-a67b4ad5-709d-4246-9a4d-c826bda2ef1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35027,DS-0fe09f83-4e2e-4810-8fff-0fda5b92c3c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46279,DS-01cdd395-c701-4d5b-b8d2-e7323fb73dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:36557,DS-be7114f6-d54f-4549-80ae-2ee4317c5b77,DISK], DatanodeInfoWithStorage[127.0.0.1:39897,DS-e4fedbcc-d949-4a90-9df9-ffcbc0f6fb4e,DISK], DatanodeInfoWithStorage[127.0.0.1:42267,DS-02089d07-8a99-4d9d-9e5d-ed130d4ad9b9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-293577360-172.17.0.11-1597370411777:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36784,DS-eb8f98e3-df05-4872-96ef-2d5f86142203,DISK], DatanodeInfoWithStorage[127.0.0.1:44258,DS-5d7d1c67-c9ba-4f04-8f2c-7ad37927c861,DISK], DatanodeInfoWithStorage[127.0.0.1:46083,DS-a67b4ad5-709d-4246-9a4d-c826bda2ef1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35027,DS-0fe09f83-4e2e-4810-8fff-0fda5b92c3c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46279,DS-01cdd395-c701-4d5b-b8d2-e7323fb73dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:36557,DS-be7114f6-d54f-4549-80ae-2ee4317c5b77,DISK], DatanodeInfoWithStorage[127.0.0.1:39897,DS-e4fedbcc-d949-4a90-9df9-ffcbc0f6fb4e,DISK], DatanodeInfoWithStorage[127.0.0.1:42267,DS-02089d07-8a99-4d9d-9e5d-ed130d4ad9b9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 262144
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1114423915-172.17.0.11-1597370704968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34399,DS-7e794c3b-e262-4274-804f-296119f1a690,DISK], DatanodeInfoWithStorage[127.0.0.1:44055,DS-e5ad4b45-0c86-411e-acb0-10fd9f82d6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39665,DS-dbe5522a-b832-4d40-b4ec-423ffb7dbbe6,DISK], DatanodeInfoWithStorage[127.0.0.1:34123,DS-7eb02b78-6ca0-45c8-ab47-56b2a1338d51,DISK], DatanodeInfoWithStorage[127.0.0.1:35657,DS-4b3b1d9e-e270-4ec3-9309-e62778e2fc3b,DISK], DatanodeInfoWithStorage[127.0.0.1:44040,DS-314e245d-37af-4a69-9e28-6a55ebb2949a,DISK], DatanodeInfoWithStorage[127.0.0.1:38357,DS-7c338209-731c-4fef-bdde-b88be26f9ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:42222,DS-771e3663-5156-43d8-9cfb-f9ec7b16ab0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1114423915-172.17.0.11-1597370704968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34399,DS-7e794c3b-e262-4274-804f-296119f1a690,DISK], DatanodeInfoWithStorage[127.0.0.1:44055,DS-e5ad4b45-0c86-411e-acb0-10fd9f82d6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39665,DS-dbe5522a-b832-4d40-b4ec-423ffb7dbbe6,DISK], DatanodeInfoWithStorage[127.0.0.1:34123,DS-7eb02b78-6ca0-45c8-ab47-56b2a1338d51,DISK], DatanodeInfoWithStorage[127.0.0.1:35657,DS-4b3b1d9e-e270-4ec3-9309-e62778e2fc3b,DISK], DatanodeInfoWithStorage[127.0.0.1:44040,DS-314e245d-37af-4a69-9e28-6a55ebb2949a,DISK], DatanodeInfoWithStorage[127.0.0.1:38357,DS-7c338209-731c-4fef-bdde-b88be26f9ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:42222,DS-771e3663-5156-43d8-9cfb-f9ec7b16ab0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 262144
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1482006728-172.17.0.11-1597370799385:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38690,DS-c8423884-191f-4c23-b06d-2aefac9c8d17,DISK], DatanodeInfoWithStorage[127.0.0.1:39569,DS-c7308e92-b2c9-4875-a5f5-29cafc9571c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37989,DS-833d4058-b28d-49de-a8f9-feca5f528d74,DISK], DatanodeInfoWithStorage[127.0.0.1:41550,DS-81f1e961-ffda-4afc-87bd-712b9708900a,DISK], DatanodeInfoWithStorage[127.0.0.1:36662,DS-1da70062-e87f-4d53-a5d0-43feed9a3897,DISK], DatanodeInfoWithStorage[127.0.0.1:40684,DS-83fe8dd2-a5f3-45f2-a0cb-1d61f8956780,DISK], DatanodeInfoWithStorage[127.0.0.1:39811,DS-0a3ff047-d8e6-4815-8c85-eeefac266dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:34055,DS-e653c68d-edc4-4125-9263-677e1716c6f2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1482006728-172.17.0.11-1597370799385:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38690,DS-c8423884-191f-4c23-b06d-2aefac9c8d17,DISK], DatanodeInfoWithStorage[127.0.0.1:39569,DS-c7308e92-b2c9-4875-a5f5-29cafc9571c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37989,DS-833d4058-b28d-49de-a8f9-feca5f528d74,DISK], DatanodeInfoWithStorage[127.0.0.1:41550,DS-81f1e961-ffda-4afc-87bd-712b9708900a,DISK], DatanodeInfoWithStorage[127.0.0.1:36662,DS-1da70062-e87f-4d53-a5d0-43feed9a3897,DISK], DatanodeInfoWithStorage[127.0.0.1:40684,DS-83fe8dd2-a5f3-45f2-a0cb-1d61f8956780,DISK], DatanodeInfoWithStorage[127.0.0.1:39811,DS-0a3ff047-d8e6-4815-8c85-eeefac266dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:34055,DS-e653c68d-edc4-4125-9263-677e1716c6f2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 262144
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1033512638-172.17.0.11-1597370964867:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32996,DS-b17902d3-2579-4bad-800c-1af6b0dba5c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41348,DS-2d54f9ed-79cc-493f-a761-afe279105839,DISK], DatanodeInfoWithStorage[127.0.0.1:35084,DS-f084add0-cd2f-4d9e-8953-c7b51d8391ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40536,DS-c27760fd-d9e6-4f33-90d1-606a4282162d,DISK], DatanodeInfoWithStorage[127.0.0.1:40924,DS-d2d54ffa-ca04-48fe-9f3d-dc53fd68bcb8,DISK], DatanodeInfoWithStorage[127.0.0.1:35035,DS-a26f72ae-30ce-49e9-9186-52a6a91790eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46347,DS-20a8f7fe-4754-426c-8f96-f7bc33e232b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45845,DS-36e99f6f-e41e-4889-8822-74ac836d1d97,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1033512638-172.17.0.11-1597370964867:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32996,DS-b17902d3-2579-4bad-800c-1af6b0dba5c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41348,DS-2d54f9ed-79cc-493f-a761-afe279105839,DISK], DatanodeInfoWithStorage[127.0.0.1:35084,DS-f084add0-cd2f-4d9e-8953-c7b51d8391ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40536,DS-c27760fd-d9e6-4f33-90d1-606a4282162d,DISK], DatanodeInfoWithStorage[127.0.0.1:40924,DS-d2d54ffa-ca04-48fe-9f3d-dc53fd68bcb8,DISK], DatanodeInfoWithStorage[127.0.0.1:35035,DS-a26f72ae-30ce-49e9-9186-52a6a91790eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46347,DS-20a8f7fe-4754-426c-8f96-f7bc33e232b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45845,DS-36e99f6f-e41e-4889-8822-74ac836d1d97,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 262144
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-444489440-172.17.0.11-1597371092592:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37887,DS-aa7ff8ad-899b-4785-ad39-d7793586cfea,DISK], DatanodeInfoWithStorage[127.0.0.1:33545,DS-7d32828f-a54e-49e9-a970-3185ff6599c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35302,DS-8de2cdeb-06af-40e1-8c33-5742713e69e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46881,DS-47efef3a-ae2c-45e1-be4d-74e4c19e1f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:34474,DS-7300e960-34af-4c47-84d0-300a755f39f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42007,DS-f36930eb-fc9c-4bd9-b691-fe3f80f417e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33556,DS-fec82b17-826f-4af4-8c3f-ce42cd1f69e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41985,DS-e05eda5d-dc5f-4277-917d-3752a0174df6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-444489440-172.17.0.11-1597371092592:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37887,DS-aa7ff8ad-899b-4785-ad39-d7793586cfea,DISK], DatanodeInfoWithStorage[127.0.0.1:33545,DS-7d32828f-a54e-49e9-a970-3185ff6599c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35302,DS-8de2cdeb-06af-40e1-8c33-5742713e69e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46881,DS-47efef3a-ae2c-45e1-be4d-74e4c19e1f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:34474,DS-7300e960-34af-4c47-84d0-300a755f39f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42007,DS-f36930eb-fc9c-4bd9-b691-fe3f80f417e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33556,DS-fec82b17-826f-4af4-8c3f-ce42cd1f69e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41985,DS-e05eda5d-dc5f-4277-917d-3752a0174df6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 262144
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-31964158-172.17.0.11-1597371195931:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38912,DS-0bbe0336-2b94-41d2-ae66-444af7e36cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:37233,DS-20081bca-dfb2-4aca-96f5-cbe20cb17adb,DISK], DatanodeInfoWithStorage[127.0.0.1:39795,DS-0707211c-4838-4e89-bdac-a88a5f9abfaf,DISK], DatanodeInfoWithStorage[127.0.0.1:44907,DS-78a15fce-f0c9-4818-835c-c381a129f9f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37981,DS-96af1a23-a877-4b6c-9d78-6f1d480df258,DISK], DatanodeInfoWithStorage[127.0.0.1:42047,DS-8f1433cd-a2af-4e0c-b2e5-7fc9586c7d20,DISK], DatanodeInfoWithStorage[127.0.0.1:42682,DS-4338f237-b72e-4c55-8c70-99843beaa50b,DISK], DatanodeInfoWithStorage[127.0.0.1:33792,DS-f1e34c1d-9f32-47f8-9f50-94b57898f244,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-31964158-172.17.0.11-1597371195931:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38912,DS-0bbe0336-2b94-41d2-ae66-444af7e36cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:37233,DS-20081bca-dfb2-4aca-96f5-cbe20cb17adb,DISK], DatanodeInfoWithStorage[127.0.0.1:39795,DS-0707211c-4838-4e89-bdac-a88a5f9abfaf,DISK], DatanodeInfoWithStorage[127.0.0.1:44907,DS-78a15fce-f0c9-4818-835c-c381a129f9f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37981,DS-96af1a23-a877-4b6c-9d78-6f1d480df258,DISK], DatanodeInfoWithStorage[127.0.0.1:42047,DS-8f1433cd-a2af-4e0c-b2e5-7fc9586c7d20,DISK], DatanodeInfoWithStorage[127.0.0.1:42682,DS-4338f237-b72e-4c55-8c70-99843beaa50b,DISK], DatanodeInfoWithStorage[127.0.0.1:33792,DS-f1e34c1d-9f32-47f8-9f50-94b57898f244,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 262144
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-870503846-172.17.0.11-1597371394590:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37199,DS-41978cb3-40cd-49b4-918b-6e3eebaa9795,DISK], DatanodeInfoWithStorage[127.0.0.1:43529,DS-9e69f4e7-609c-4662-9759-4360c85aae6e,DISK], DatanodeInfoWithStorage[127.0.0.1:41742,DS-6764cb90-b631-4b33-8752-457550e708ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38417,DS-a50b72fb-869d-4ef7-9531-18b21b0050a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34096,DS-10354086-978d-44cd-bc97-8ac7bf8ef4d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34156,DS-09f6b2a4-ac63-49ac-b89f-50618170f8aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46375,DS-c1bb6f21-5735-4851-8a67-e70f008b893b,DISK], DatanodeInfoWithStorage[127.0.0.1:33378,DS-2aeea8b1-dfc4-4f3f-b915-f50ed9d8651e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-870503846-172.17.0.11-1597371394590:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37199,DS-41978cb3-40cd-49b4-918b-6e3eebaa9795,DISK], DatanodeInfoWithStorage[127.0.0.1:43529,DS-9e69f4e7-609c-4662-9759-4360c85aae6e,DISK], DatanodeInfoWithStorage[127.0.0.1:41742,DS-6764cb90-b631-4b33-8752-457550e708ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38417,DS-a50b72fb-869d-4ef7-9531-18b21b0050a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34096,DS-10354086-978d-44cd-bc97-8ac7bf8ef4d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34156,DS-09f6b2a4-ac63-49ac-b89f-50618170f8aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46375,DS-c1bb6f21-5735-4851-8a67-e70f008b893b,DISK], DatanodeInfoWithStorage[127.0.0.1:33378,DS-2aeea8b1-dfc4-4f3f-b915-f50ed9d8651e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 262144
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-89249091-172.17.0.11-1597372028967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43832,DS-4aa099bf-ca1c-4deb-9c84-f145900330b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33305,DS-e6caa9ab-0911-4c71-81d0-1c118e2b5953,DISK], DatanodeInfoWithStorage[127.0.0.1:35830,DS-74d7dd30-c607-4a2f-a98c-e801ca3db3c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43844,DS-08bfbe30-8f9b-40d7-af11-52f67c894a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:44047,DS-6778b470-e85f-44a4-96f5-cb4ffabb729e,DISK], DatanodeInfoWithStorage[127.0.0.1:39126,DS-51e05fc7-0ad1-418c-805e-380183ae7d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:33382,DS-db84c7dd-cf46-42ee-b044-52fab9df9246,DISK], DatanodeInfoWithStorage[127.0.0.1:44806,DS-733f9295-5ed3-4eaf-8b5f-040b2199e1ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-89249091-172.17.0.11-1597372028967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43832,DS-4aa099bf-ca1c-4deb-9c84-f145900330b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33305,DS-e6caa9ab-0911-4c71-81d0-1c118e2b5953,DISK], DatanodeInfoWithStorage[127.0.0.1:35830,DS-74d7dd30-c607-4a2f-a98c-e801ca3db3c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43844,DS-08bfbe30-8f9b-40d7-af11-52f67c894a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:44047,DS-6778b470-e85f-44a4-96f5-cb4ffabb729e,DISK], DatanodeInfoWithStorage[127.0.0.1:39126,DS-51e05fc7-0ad1-418c-805e-380183ae7d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:33382,DS-db84c7dd-cf46-42ee-b044-52fab9df9246,DISK], DatanodeInfoWithStorage[127.0.0.1:44806,DS-733f9295-5ed3-4eaf-8b5f-040b2199e1ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 262144
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2007708268-172.17.0.11-1597372079618:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42499,DS-f9a54727-91d3-4f28-b0e2-59b6486821e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36617,DS-6eeed2aa-0253-424a-8713-139a8f0f160d,DISK], DatanodeInfoWithStorage[127.0.0.1:40140,DS-42977b3b-09ce-4b75-b6f8-ee15683b7ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:36224,DS-ca41942e-f7a2-4dcd-a5f0-d7a3c5d77c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:40532,DS-643395f1-cfeb-489e-bbf9-81a2a69a1059,DISK], DatanodeInfoWithStorage[127.0.0.1:40593,DS-331ad88d-88b0-4bee-8ade-5fdb216138bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35580,DS-2bd44dc7-5d88-436d-9433-02af83e2a3be,DISK], DatanodeInfoWithStorage[127.0.0.1:38428,DS-677867a1-20e7-4f4c-9cbb-a9bea0434bb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2007708268-172.17.0.11-1597372079618:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42499,DS-f9a54727-91d3-4f28-b0e2-59b6486821e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36617,DS-6eeed2aa-0253-424a-8713-139a8f0f160d,DISK], DatanodeInfoWithStorage[127.0.0.1:40140,DS-42977b3b-09ce-4b75-b6f8-ee15683b7ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:36224,DS-ca41942e-f7a2-4dcd-a5f0-d7a3c5d77c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:40532,DS-643395f1-cfeb-489e-bbf9-81a2a69a1059,DISK], DatanodeInfoWithStorage[127.0.0.1:40593,DS-331ad88d-88b0-4bee-8ade-5fdb216138bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35580,DS-2bd44dc7-5d88-436d-9433-02af83e2a3be,DISK], DatanodeInfoWithStorage[127.0.0.1:38428,DS-677867a1-20e7-4f4c-9cbb-a9bea0434bb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 262144
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-725968599-172.17.0.11-1597372606938:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33594,DS-4e978370-fb8d-4332-87fb-cf5d89ef0765,DISK], DatanodeInfoWithStorage[127.0.0.1:33478,DS-81013242-ee5a-4b26-9cca-ce7da6fc1455,DISK], DatanodeInfoWithStorage[127.0.0.1:38670,DS-5dce234c-10ff-45b5-9396-9b6934458b41,DISK], DatanodeInfoWithStorage[127.0.0.1:35138,DS-5d850157-845e-4478-a98b-6b4ce20ddb56,DISK], DatanodeInfoWithStorage[127.0.0.1:44599,DS-80c622ae-1724-4e18-a9e3-28a253745338,DISK], DatanodeInfoWithStorage[127.0.0.1:36735,DS-4d37723f-7796-48fe-aaba-f086aa27a879,DISK], DatanodeInfoWithStorage[127.0.0.1:42077,DS-9a6bc005-67e6-44ec-8f83-7b41f89a9aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:33754,DS-4fb73609-4476-42a0-8971-c0135667cdfb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-725968599-172.17.0.11-1597372606938:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33594,DS-4e978370-fb8d-4332-87fb-cf5d89ef0765,DISK], DatanodeInfoWithStorage[127.0.0.1:33478,DS-81013242-ee5a-4b26-9cca-ce7da6fc1455,DISK], DatanodeInfoWithStorage[127.0.0.1:38670,DS-5dce234c-10ff-45b5-9396-9b6934458b41,DISK], DatanodeInfoWithStorage[127.0.0.1:35138,DS-5d850157-845e-4478-a98b-6b4ce20ddb56,DISK], DatanodeInfoWithStorage[127.0.0.1:44599,DS-80c622ae-1724-4e18-a9e3-28a253745338,DISK], DatanodeInfoWithStorage[127.0.0.1:36735,DS-4d37723f-7796-48fe-aaba-f086aa27a879,DISK], DatanodeInfoWithStorage[127.0.0.1:42077,DS-9a6bc005-67e6-44ec-8f83-7b41f89a9aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:33754,DS-4fb73609-4476-42a0-8971-c0135667cdfb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 262144
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-810899756-172.17.0.11-1597372652188:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33245,DS-9f22b4e6-9444-4682-8264-168049a7d1c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45214,DS-4967546b-50c0-4233-8215-f30ccc123689,DISK], DatanodeInfoWithStorage[127.0.0.1:43260,DS-513047f9-6085-4905-af6f-b94934a56ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:40135,DS-7e787922-e519-42e5-83de-42eb7d1a06cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43894,DS-cfa219ec-d17b-4ab9-949c-b08e8c842efc,DISK], DatanodeInfoWithStorage[127.0.0.1:42652,DS-84facb5f-daed-4e2b-b566-28f43b9682b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44784,DS-875a0948-b7fd-464f-b12f-b140266eee19,DISK], DatanodeInfoWithStorage[127.0.0.1:37958,DS-aaa96539-0e4c-4d37-a52b-26e4c6a32e59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-810899756-172.17.0.11-1597372652188:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33245,DS-9f22b4e6-9444-4682-8264-168049a7d1c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45214,DS-4967546b-50c0-4233-8215-f30ccc123689,DISK], DatanodeInfoWithStorage[127.0.0.1:43260,DS-513047f9-6085-4905-af6f-b94934a56ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:40135,DS-7e787922-e519-42e5-83de-42eb7d1a06cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43894,DS-cfa219ec-d17b-4ab9-949c-b08e8c842efc,DISK], DatanodeInfoWithStorage[127.0.0.1:42652,DS-84facb5f-daed-4e2b-b566-28f43b9682b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44784,DS-875a0948-b7fd-464f-b12f-b140266eee19,DISK], DatanodeInfoWithStorage[127.0.0.1:37958,DS-aaa96539-0e4c-4d37-a52b-26e4c6a32e59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 262144
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-614626115-172.17.0.11-1597372747562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44724,DS-6729c84c-f9a9-45bb-957f-da675dfba5d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45592,DS-c64e404d-755a-46cd-9b8c-ff17c59fb6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42211,DS-a8f3eb20-317a-484a-a0c2-756a02c27576,DISK], DatanodeInfoWithStorage[127.0.0.1:42985,DS-cf68c60a-b58a-4e06-ae7d-544c0c71ae7d,DISK], DatanodeInfoWithStorage[127.0.0.1:37368,DS-938783c5-9b47-475b-bd00-f4e5e4994dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:44559,DS-c63de76e-9ace-440c-80f1-90a4064dae96,DISK], DatanodeInfoWithStorage[127.0.0.1:33851,DS-8ee7b46e-1fa8-4853-b02a-aece5a81fe83,DISK], DatanodeInfoWithStorage[127.0.0.1:37895,DS-efa457b7-c067-497d-aea9-43385f1ee315,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-614626115-172.17.0.11-1597372747562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44724,DS-6729c84c-f9a9-45bb-957f-da675dfba5d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45592,DS-c64e404d-755a-46cd-9b8c-ff17c59fb6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42211,DS-a8f3eb20-317a-484a-a0c2-756a02c27576,DISK], DatanodeInfoWithStorage[127.0.0.1:42985,DS-cf68c60a-b58a-4e06-ae7d-544c0c71ae7d,DISK], DatanodeInfoWithStorage[127.0.0.1:37368,DS-938783c5-9b47-475b-bd00-f4e5e4994dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:44559,DS-c63de76e-9ace-440c-80f1-90a4064dae96,DISK], DatanodeInfoWithStorage[127.0.0.1:33851,DS-8ee7b46e-1fa8-4853-b02a-aece5a81fe83,DISK], DatanodeInfoWithStorage[127.0.0.1:37895,DS-efa457b7-c067-497d-aea9-43385f1ee315,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 262144
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-423454648-172.17.0.11-1597372981710:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42419,DS-fb1365f3-c29a-481f-ae40-d94bb6bdfb10,DISK], DatanodeInfoWithStorage[127.0.0.1:44715,DS-daa9eed0-5380-4bff-9d3e-b2fdee944a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:35743,DS-e5dd25c4-9f37-4ad0-bd49-bac9e09a8d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:46270,DS-bed4d662-9d88-4d85-8196-c0fcddfaf8ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38963,DS-5f3d0218-b4ab-4fbb-b615-7b24e82a03e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34484,DS-1eb60864-b7bf-45b3-a47b-1994ec47f906,DISK], DatanodeInfoWithStorage[127.0.0.1:39130,DS-9c71bc6d-bbd8-4753-8d68-1dc0961659bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34447,DS-fb1bf634-831c-495a-a4af-11d84005a213,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-423454648-172.17.0.11-1597372981710:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42419,DS-fb1365f3-c29a-481f-ae40-d94bb6bdfb10,DISK], DatanodeInfoWithStorage[127.0.0.1:44715,DS-daa9eed0-5380-4bff-9d3e-b2fdee944a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:35743,DS-e5dd25c4-9f37-4ad0-bd49-bac9e09a8d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:46270,DS-bed4d662-9d88-4d85-8196-c0fcddfaf8ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38963,DS-5f3d0218-b4ab-4fbb-b615-7b24e82a03e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34484,DS-1eb60864-b7bf-45b3-a47b-1994ec47f906,DISK], DatanodeInfoWithStorage[127.0.0.1:39130,DS-9c71bc6d-bbd8-4753-8d68-1dc0961659bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34447,DS-fb1bf634-831c-495a-a4af-11d84005a213,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 262144
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-692115389-172.17.0.11-1597373289155:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44249,DS-1dc12815-2e32-4b8f-a154-37ccd40db8c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38498,DS-7c518e4d-c5c7-4d72-af4c-20ac073b197e,DISK], DatanodeInfoWithStorage[127.0.0.1:41585,DS-e71011b0-f3e2-4036-9505-8531151b0f56,DISK], DatanodeInfoWithStorage[127.0.0.1:33089,DS-2f40daee-5573-4b66-8696-5b2f9dd59303,DISK], DatanodeInfoWithStorage[127.0.0.1:46391,DS-e9eed2ac-3f43-4c28-8cb8-e517512f90fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46472,DS-d9831292-f306-43a3-b600-24e4cfc22051,DISK], DatanodeInfoWithStorage[127.0.0.1:32785,DS-54b0fd47-0c7f-4485-a675-75c5d6bf305a,DISK], DatanodeInfoWithStorage[127.0.0.1:43873,DS-291a6bb8-bc2c-4236-9c4b-a25ec17fa7b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-692115389-172.17.0.11-1597373289155:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44249,DS-1dc12815-2e32-4b8f-a154-37ccd40db8c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38498,DS-7c518e4d-c5c7-4d72-af4c-20ac073b197e,DISK], DatanodeInfoWithStorage[127.0.0.1:41585,DS-e71011b0-f3e2-4036-9505-8531151b0f56,DISK], DatanodeInfoWithStorage[127.0.0.1:33089,DS-2f40daee-5573-4b66-8696-5b2f9dd59303,DISK], DatanodeInfoWithStorage[127.0.0.1:46391,DS-e9eed2ac-3f43-4c28-8cb8-e517512f90fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46472,DS-d9831292-f306-43a3-b600-24e4cfc22051,DISK], DatanodeInfoWithStorage[127.0.0.1:32785,DS-54b0fd47-0c7f-4485-a675-75c5d6bf305a,DISK], DatanodeInfoWithStorage[127.0.0.1:43873,DS-291a6bb8-bc2c-4236-9c4b-a25ec17fa7b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 262144
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1103743764-172.17.0.11-1597373446791:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43345,DS-ebaf23b8-0ae7-4c07-b953-9e27634d2c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:33799,DS-a71c041f-9571-446a-a2bf-064caf0f2b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:35208,DS-9424c5d2-79e1-4bc6-879a-127410d25cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:38610,DS-5c241187-bb4f-43aa-9308-a305ecd9ea40,DISK], DatanodeInfoWithStorage[127.0.0.1:35860,DS-f80244d3-f373-4a09-a801-58e589166955,DISK], DatanodeInfoWithStorage[127.0.0.1:34234,DS-b00aaac8-d8e6-478e-962d-ba34ac3d4b44,DISK], DatanodeInfoWithStorage[127.0.0.1:35725,DS-0a52b043-05be-4347-9ec3-11d18b035b88,DISK], DatanodeInfoWithStorage[127.0.0.1:34990,DS-dff11150-eaab-40fa-994a-db32c8517968,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1103743764-172.17.0.11-1597373446791:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43345,DS-ebaf23b8-0ae7-4c07-b953-9e27634d2c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:33799,DS-a71c041f-9571-446a-a2bf-064caf0f2b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:35208,DS-9424c5d2-79e1-4bc6-879a-127410d25cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:38610,DS-5c241187-bb4f-43aa-9308-a305ecd9ea40,DISK], DatanodeInfoWithStorage[127.0.0.1:35860,DS-f80244d3-f373-4a09-a801-58e589166955,DISK], DatanodeInfoWithStorage[127.0.0.1:34234,DS-b00aaac8-d8e6-478e-962d-ba34ac3d4b44,DISK], DatanodeInfoWithStorage[127.0.0.1:35725,DS-0a52b043-05be-4347-9ec3-11d18b035b88,DISK], DatanodeInfoWithStorage[127.0.0.1:34990,DS-dff11150-eaab-40fa-994a-db32c8517968,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 262144
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-925885921-172.17.0.11-1597373684162:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35286,DS-a5a98953-3739-4d05-b9a3-93093b1bf7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42035,DS-bd037bb7-dfb2-44be-b65f-3509d19bcd6f,DISK], DatanodeInfoWithStorage[127.0.0.1:40184,DS-567576e3-59c8-4228-9613-fcce4af846c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45491,DS-31c1c7b7-c942-4035-9d94-7199784d6a64,DISK], DatanodeInfoWithStorage[127.0.0.1:40774,DS-cdaf473f-bf18-4c20-b9d3-4eb6d7043b35,DISK], DatanodeInfoWithStorage[127.0.0.1:39078,DS-a6f0b65a-3de2-42f5-95c9-c245fb0fff58,DISK], DatanodeInfoWithStorage[127.0.0.1:46678,DS-ef96ab40-7e65-428c-b693-838506217b04,DISK], DatanodeInfoWithStorage[127.0.0.1:37592,DS-46762533-31d7-478e-a4dd-312ee263e3c2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-925885921-172.17.0.11-1597373684162:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35286,DS-a5a98953-3739-4d05-b9a3-93093b1bf7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42035,DS-bd037bb7-dfb2-44be-b65f-3509d19bcd6f,DISK], DatanodeInfoWithStorage[127.0.0.1:40184,DS-567576e3-59c8-4228-9613-fcce4af846c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45491,DS-31c1c7b7-c942-4035-9d94-7199784d6a64,DISK], DatanodeInfoWithStorage[127.0.0.1:40774,DS-cdaf473f-bf18-4c20-b9d3-4eb6d7043b35,DISK], DatanodeInfoWithStorage[127.0.0.1:39078,DS-a6f0b65a-3de2-42f5-95c9-c245fb0fff58,DISK], DatanodeInfoWithStorage[127.0.0.1:46678,DS-ef96ab40-7e65-428c-b693-838506217b04,DISK], DatanodeInfoWithStorage[127.0.0.1:37592,DS-46762533-31d7-478e-a4dd-312ee263e3c2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 262144
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-164294164-172.17.0.11-1597373844125:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37359,DS-f922454b-e0be-4f6a-83ae-8cda725c7c72,DISK], DatanodeInfoWithStorage[127.0.0.1:40796,DS-c76089f5-c282-439a-a909-6ac66b3bcd52,DISK], DatanodeInfoWithStorage[127.0.0.1:38978,DS-c17e0aec-4caa-4f94-95c4-8f400bbdf993,DISK], DatanodeInfoWithStorage[127.0.0.1:41833,DS-0f0ee55d-37f2-4fd2-b18b-5d7cd516f153,DISK], DatanodeInfoWithStorage[127.0.0.1:37121,DS-03ae1bd0-f97a-4ffc-9068-2f9c84ec4cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:41630,DS-d104a691-da5f-427d-8880-8e5a8ded29fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43521,DS-242bb36f-a85c-4eb1-b5bd-d5566f3957fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42840,DS-2721a9da-847a-48b0-b0d0-7f3a52b4b0dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-164294164-172.17.0.11-1597373844125:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37359,DS-f922454b-e0be-4f6a-83ae-8cda725c7c72,DISK], DatanodeInfoWithStorage[127.0.0.1:40796,DS-c76089f5-c282-439a-a909-6ac66b3bcd52,DISK], DatanodeInfoWithStorage[127.0.0.1:38978,DS-c17e0aec-4caa-4f94-95c4-8f400bbdf993,DISK], DatanodeInfoWithStorage[127.0.0.1:41833,DS-0f0ee55d-37f2-4fd2-b18b-5d7cd516f153,DISK], DatanodeInfoWithStorage[127.0.0.1:37121,DS-03ae1bd0-f97a-4ffc-9068-2f9c84ec4cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:41630,DS-d104a691-da5f-427d-8880-8e5a8ded29fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43521,DS-242bb36f-a85c-4eb1-b5bd-d5566f3957fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42840,DS-2721a9da-847a-48b0-b0d0-7f3a52b4b0dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 262144
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-235942757-172.17.0.11-1597374552535:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39678,DS-58750def-667b-4e64-bca3-1d86b7f8d282,DISK], DatanodeInfoWithStorage[127.0.0.1:46499,DS-a6af1d9a-4867-4ef8-bf38-73c6192d0028,DISK], DatanodeInfoWithStorage[127.0.0.1:33321,DS-975b542c-49fb-4146-887b-e1207232e7e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41552,DS-ffc5e6b6-f621-40bb-8339-66ec618631af,DISK], DatanodeInfoWithStorage[127.0.0.1:43104,DS-066ed783-4f8b-4c21-9ab5-48f282a8ce79,DISK], DatanodeInfoWithStorage[127.0.0.1:33791,DS-2814f358-c7ae-49c0-8975-3bef4caafd46,DISK], DatanodeInfoWithStorage[127.0.0.1:36754,DS-7f5c4d62-8351-4b88-87e2-4ee539907ade,DISK], DatanodeInfoWithStorage[127.0.0.1:45514,DS-c3628ecd-5516-43ed-bed2-e9c5a9cd5cb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-235942757-172.17.0.11-1597374552535:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39678,DS-58750def-667b-4e64-bca3-1d86b7f8d282,DISK], DatanodeInfoWithStorage[127.0.0.1:46499,DS-a6af1d9a-4867-4ef8-bf38-73c6192d0028,DISK], DatanodeInfoWithStorage[127.0.0.1:33321,DS-975b542c-49fb-4146-887b-e1207232e7e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41552,DS-ffc5e6b6-f621-40bb-8339-66ec618631af,DISK], DatanodeInfoWithStorage[127.0.0.1:43104,DS-066ed783-4f8b-4c21-9ab5-48f282a8ce79,DISK], DatanodeInfoWithStorage[127.0.0.1:33791,DS-2814f358-c7ae-49c0-8975-3bef4caafd46,DISK], DatanodeInfoWithStorage[127.0.0.1:36754,DS-7f5c4d62-8351-4b88-87e2-4ee539907ade,DISK], DatanodeInfoWithStorage[127.0.0.1:45514,DS-c3628ecd-5516-43ed-bed2-e9c5a9cd5cb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 262144
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-700757054-172.17.0.11-1597374803232:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44701,DS-11a4e822-148b-4184-8b18-0ed8e0a311b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43512,DS-1f71ed3b-5d51-40c3-9ef3-4ce926f1889f,DISK], DatanodeInfoWithStorage[127.0.0.1:38791,DS-566a4fc3-0ec7-4e42-972b-da34bb8f99b1,DISK], DatanodeInfoWithStorage[127.0.0.1:32789,DS-a0b40357-eaf5-499e-a165-43d4647d335c,DISK], DatanodeInfoWithStorage[127.0.0.1:37377,DS-9f7d8910-5b83-41ab-a07d-46b17c72e17b,DISK], DatanodeInfoWithStorage[127.0.0.1:45491,DS-8588aecd-c83d-46ab-8469-6c502e415dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:34271,DS-ca29b683-bf56-4910-8d49-5d02a199d6ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44290,DS-947dafad-b8f0-4f4c-9bcb-36b77161f405,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-700757054-172.17.0.11-1597374803232:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44701,DS-11a4e822-148b-4184-8b18-0ed8e0a311b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43512,DS-1f71ed3b-5d51-40c3-9ef3-4ce926f1889f,DISK], DatanodeInfoWithStorage[127.0.0.1:38791,DS-566a4fc3-0ec7-4e42-972b-da34bb8f99b1,DISK], DatanodeInfoWithStorage[127.0.0.1:32789,DS-a0b40357-eaf5-499e-a165-43d4647d335c,DISK], DatanodeInfoWithStorage[127.0.0.1:37377,DS-9f7d8910-5b83-41ab-a07d-46b17c72e17b,DISK], DatanodeInfoWithStorage[127.0.0.1:45491,DS-8588aecd-c83d-46ab-8469-6c502e415dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:34271,DS-ca29b683-bf56-4910-8d49-5d02a199d6ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44290,DS-947dafad-b8f0-4f4c-9bcb-36b77161f405,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 262144
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-835141720-172.17.0.11-1597375540156:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42506,DS-cc9d8221-c6ea-485b-a04b-17169be81f52,DISK], DatanodeInfoWithStorage[127.0.0.1:40651,DS-bc65191e-939e-4c4f-bef9-a337ede67e12,DISK], DatanodeInfoWithStorage[127.0.0.1:43357,DS-49f39d88-9097-4d7e-b4fb-497f2abe6de2,DISK], DatanodeInfoWithStorage[127.0.0.1:42676,DS-dad5d923-692e-4974-8c49-f95b9a25fafc,DISK], DatanodeInfoWithStorage[127.0.0.1:34177,DS-6c7a2a13-b157-4081-83f0-b790342b9468,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-fe2317da-9e96-4c5e-97e1-39c1589491c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38798,DS-62c11803-e4da-4e92-b973-899b58c1a432,DISK], DatanodeInfoWithStorage[127.0.0.1:40518,DS-61d138b1-1f58-4d17-bf12-7a68d3803f02,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-835141720-172.17.0.11-1597375540156:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42506,DS-cc9d8221-c6ea-485b-a04b-17169be81f52,DISK], DatanodeInfoWithStorage[127.0.0.1:40651,DS-bc65191e-939e-4c4f-bef9-a337ede67e12,DISK], DatanodeInfoWithStorage[127.0.0.1:43357,DS-49f39d88-9097-4d7e-b4fb-497f2abe6de2,DISK], DatanodeInfoWithStorage[127.0.0.1:42676,DS-dad5d923-692e-4974-8c49-f95b9a25fafc,DISK], DatanodeInfoWithStorage[127.0.0.1:34177,DS-6c7a2a13-b157-4081-83f0-b790342b9468,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-fe2317da-9e96-4c5e-97e1-39c1589491c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38798,DS-62c11803-e4da-4e92-b973-899b58c1a432,DISK], DatanodeInfoWithStorage[127.0.0.1:40518,DS-61d138b1-1f58-4d17-bf12-7a68d3803f02,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 262144
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-395999732-172.17.0.11-1597375724848:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32900,DS-0c36265f-c1a1-4300-ae50-3b05cd38f00f,DISK], DatanodeInfoWithStorage[127.0.0.1:46677,DS-c832110d-5a2e-4917-803e-0196dc11d25d,DISK], DatanodeInfoWithStorage[127.0.0.1:37865,DS-cb35d911-7ac3-4d17-88e3-c329c96bf394,DISK], DatanodeInfoWithStorage[127.0.0.1:44590,DS-5a473d68-f652-447f-964e-d3ab571562cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40427,DS-2c2c4d52-eb2d-49a1-9408-3b990b6573c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37258,DS-d6ae4894-c9c3-434d-9030-b1d2d476cd2e,DISK], DatanodeInfoWithStorage[127.0.0.1:44149,DS-bd895ac5-88fb-4a11-a300-ad332b993564,DISK], DatanodeInfoWithStorage[127.0.0.1:34426,DS-37e06b39-8b9c-44e9-85c6-ada19f3a1a03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-395999732-172.17.0.11-1597375724848:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32900,DS-0c36265f-c1a1-4300-ae50-3b05cd38f00f,DISK], DatanodeInfoWithStorage[127.0.0.1:46677,DS-c832110d-5a2e-4917-803e-0196dc11d25d,DISK], DatanodeInfoWithStorage[127.0.0.1:37865,DS-cb35d911-7ac3-4d17-88e3-c329c96bf394,DISK], DatanodeInfoWithStorage[127.0.0.1:44590,DS-5a473d68-f652-447f-964e-d3ab571562cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40427,DS-2c2c4d52-eb2d-49a1-9408-3b990b6573c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37258,DS-d6ae4894-c9c3-434d-9030-b1d2d476cd2e,DISK], DatanodeInfoWithStorage[127.0.0.1:44149,DS-bd895ac5-88fb-4a11-a300-ad332b993564,DISK], DatanodeInfoWithStorage[127.0.0.1:34426,DS-37e06b39-8b9c-44e9-85c6-ada19f3a1a03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 262144
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1786811580-172.17.0.11-1597375871921:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39426,DS-c62f70c3-68fa-4345-aefd-1bcab3e3d792,DISK], DatanodeInfoWithStorage[127.0.0.1:37875,DS-4f787860-84ac-4ea9-abc6-40fd2be23811,DISK], DatanodeInfoWithStorage[127.0.0.1:43774,DS-70fb7a7d-04f0-4deb-b372-0a7ec9fa608a,DISK], DatanodeInfoWithStorage[127.0.0.1:42405,DS-5429b605-77a2-4068-aa7e-a99ad74f0fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:36891,DS-c7bda97d-410a-4e36-bf72-72e58006b50a,DISK], DatanodeInfoWithStorage[127.0.0.1:41353,DS-a0a54b66-429e-4296-aaba-5bb4e4036b46,DISK], DatanodeInfoWithStorage[127.0.0.1:42643,DS-46bd138e-1c33-48ba-b605-19bc0ba15a53,DISK], DatanodeInfoWithStorage[127.0.0.1:42061,DS-011bc0f0-c87f-45ca-a11d-b508cc50b4a4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1786811580-172.17.0.11-1597375871921:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39426,DS-c62f70c3-68fa-4345-aefd-1bcab3e3d792,DISK], DatanodeInfoWithStorage[127.0.0.1:37875,DS-4f787860-84ac-4ea9-abc6-40fd2be23811,DISK], DatanodeInfoWithStorage[127.0.0.1:43774,DS-70fb7a7d-04f0-4deb-b372-0a7ec9fa608a,DISK], DatanodeInfoWithStorage[127.0.0.1:42405,DS-5429b605-77a2-4068-aa7e-a99ad74f0fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:36891,DS-c7bda97d-410a-4e36-bf72-72e58006b50a,DISK], DatanodeInfoWithStorage[127.0.0.1:41353,DS-a0a54b66-429e-4296-aaba-5bb4e4036b46,DISK], DatanodeInfoWithStorage[127.0.0.1:42643,DS-46bd138e-1c33-48ba-b605-19bc0ba15a53,DISK], DatanodeInfoWithStorage[127.0.0.1:42061,DS-011bc0f0-c87f-45ca-a11d-b508cc50b4a4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 262144
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-665287568-172.17.0.11-1597376959236:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40764,DS-a2d3091c-c039-4afa-b53a-b65690fde285,DISK], DatanodeInfoWithStorage[127.0.0.1:39560,DS-25bc69df-d1b3-4d51-bf85-d8bfcc3fa4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40070,DS-aec542d2-4ddf-4897-b316-1061a8c32f90,DISK], DatanodeInfoWithStorage[127.0.0.1:33224,DS-537f2a27-3f00-4113-bf1c-9d93e2ad554f,DISK], DatanodeInfoWithStorage[127.0.0.1:39709,DS-4c536936-c999-4ca1-b7bf-a84b1ce85ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:44516,DS-8a50844b-1997-4ab8-8fe3-b3cd966ff9e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42917,DS-3547d8ea-69ca-4961-9e23-f713b883e9f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46882,DS-1eeb0702-1f84-42e8-9267-efe8ef80d2ff,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-665287568-172.17.0.11-1597376959236:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40764,DS-a2d3091c-c039-4afa-b53a-b65690fde285,DISK], DatanodeInfoWithStorage[127.0.0.1:39560,DS-25bc69df-d1b3-4d51-bf85-d8bfcc3fa4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40070,DS-aec542d2-4ddf-4897-b316-1061a8c32f90,DISK], DatanodeInfoWithStorage[127.0.0.1:33224,DS-537f2a27-3f00-4113-bf1c-9d93e2ad554f,DISK], DatanodeInfoWithStorage[127.0.0.1:39709,DS-4c536936-c999-4ca1-b7bf-a84b1ce85ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:44516,DS-8a50844b-1997-4ab8-8fe3-b3cd966ff9e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42917,DS-3547d8ea-69ca-4961-9e23-f713b883e9f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46882,DS-1eeb0702-1f84-42e8-9267-efe8ef80d2ff,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 17 out of 50
result: false positive !!!
Total execution time in seconds : 7319
