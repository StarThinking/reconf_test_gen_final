reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-201873602-172.17.0.10-1597748682722:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45334,DS-ecfbe0af-5180-4c7a-9ff1-6fe0ac3cc2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35246,DS-730aacba-de75-44d6-b18f-b4d47bb64d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39354,DS-9d8ef501-55a2-4ede-8716-50cee6d31ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:35024,DS-0f4b8807-5815-40cd-b639-cf85ec69c420,DISK], DatanodeInfoWithStorage[127.0.0.1:42334,DS-98f7eb75-2ded-4f14-be38-f56246974f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:46569,DS-49a0fc74-94f6-42fe-8a46-71d3dcc39a75,DISK], DatanodeInfoWithStorage[127.0.0.1:44024,DS-cc96e924-0a35-4169-a49e-26ce61f8e3db,DISK], DatanodeInfoWithStorage[127.0.0.1:39532,DS-459f15bd-4a5f-4206-be9a-eca9dc8661e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-201873602-172.17.0.10-1597748682722:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45334,DS-ecfbe0af-5180-4c7a-9ff1-6fe0ac3cc2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35246,DS-730aacba-de75-44d6-b18f-b4d47bb64d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39354,DS-9d8ef501-55a2-4ede-8716-50cee6d31ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:35024,DS-0f4b8807-5815-40cd-b639-cf85ec69c420,DISK], DatanodeInfoWithStorage[127.0.0.1:42334,DS-98f7eb75-2ded-4f14-be38-f56246974f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:46569,DS-49a0fc74-94f6-42fe-8a46-71d3dcc39a75,DISK], DatanodeInfoWithStorage[127.0.0.1:44024,DS-cc96e924-0a35-4169-a49e-26ce61f8e3db,DISK], DatanodeInfoWithStorage[127.0.0.1:39532,DS-459f15bd-4a5f-4206-be9a-eca9dc8661e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-170623087-172.17.0.10-1597748722962:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37404,DS-0c6cde35-8709-449a-b05d-b063a66fecac,DISK], DatanodeInfoWithStorage[127.0.0.1:42878,DS-a16e4c87-d51f-4f3c-9e84-50d77679ec95,DISK], DatanodeInfoWithStorage[127.0.0.1:40843,DS-650a6112-476b-44c9-af29-db2d642449fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-4593b03a-7251-4fb0-84b6-ccaeadb9a68b,DISK], DatanodeInfoWithStorage[127.0.0.1:35795,DS-4f0d1133-acdd-4681-b173-cec98f927368,DISK], DatanodeInfoWithStorage[127.0.0.1:44571,DS-117158df-e2dd-4349-9dce-883e64d835d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41270,DS-00e9d18b-417f-4b4b-a9af-70a0f2e49207,DISK], DatanodeInfoWithStorage[127.0.0.1:40570,DS-f24c9cc8-47e5-469e-9de1-78a69947ab60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-170623087-172.17.0.10-1597748722962:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37404,DS-0c6cde35-8709-449a-b05d-b063a66fecac,DISK], DatanodeInfoWithStorage[127.0.0.1:42878,DS-a16e4c87-d51f-4f3c-9e84-50d77679ec95,DISK], DatanodeInfoWithStorage[127.0.0.1:40843,DS-650a6112-476b-44c9-af29-db2d642449fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-4593b03a-7251-4fb0-84b6-ccaeadb9a68b,DISK], DatanodeInfoWithStorage[127.0.0.1:35795,DS-4f0d1133-acdd-4681-b173-cec98f927368,DISK], DatanodeInfoWithStorage[127.0.0.1:44571,DS-117158df-e2dd-4349-9dce-883e64d835d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41270,DS-00e9d18b-417f-4b4b-a9af-70a0f2e49207,DISK], DatanodeInfoWithStorage[127.0.0.1:40570,DS-f24c9cc8-47e5-469e-9de1-78a69947ab60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-716879429-172.17.0.10-1597749238197:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39168,DS-915029c7-166b-4c03-8f9d-b1dd5300c2bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35697,DS-66ff9917-9566-47f6-b9c2-a208783e8427,DISK], DatanodeInfoWithStorage[127.0.0.1:38066,DS-abaa1271-5220-46a0-8e2d-120ec9fe41a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45157,DS-a39c1e05-2e99-44cc-a24f-885032948015,DISK], DatanodeInfoWithStorage[127.0.0.1:44613,DS-e93cd1e2-c3b1-4b66-bb5c-85a30c4c0972,DISK], DatanodeInfoWithStorage[127.0.0.1:43810,DS-3946285e-ceec-4753-8db6-b4e23dc4aafa,DISK], DatanodeInfoWithStorage[127.0.0.1:44891,DS-3f1a55b1-95f3-4bc5-95f8-1fe9b5c99f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:40368,DS-59ffb1d2-b5c0-455e-84d2-fe1fe9e0d9ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-716879429-172.17.0.10-1597749238197:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39168,DS-915029c7-166b-4c03-8f9d-b1dd5300c2bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35697,DS-66ff9917-9566-47f6-b9c2-a208783e8427,DISK], DatanodeInfoWithStorage[127.0.0.1:38066,DS-abaa1271-5220-46a0-8e2d-120ec9fe41a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45157,DS-a39c1e05-2e99-44cc-a24f-885032948015,DISK], DatanodeInfoWithStorage[127.0.0.1:44613,DS-e93cd1e2-c3b1-4b66-bb5c-85a30c4c0972,DISK], DatanodeInfoWithStorage[127.0.0.1:43810,DS-3946285e-ceec-4753-8db6-b4e23dc4aafa,DISK], DatanodeInfoWithStorage[127.0.0.1:44891,DS-3f1a55b1-95f3-4bc5-95f8-1fe9b5c99f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:40368,DS-59ffb1d2-b5c0-455e-84d2-fe1fe9e0d9ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1922414268-172.17.0.10-1597749313166:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45906,DS-9bce7704-cb5f-479a-9852-ba6a85cafd5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42294,DS-cc7c9860-1ed3-4a97-8e15-4104b77e5d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:37970,DS-10fc1853-79ca-4b92-bed4-2a4fc5775f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45853,DS-7ae2dd76-eaf3-405f-915c-664c38091243,DISK], DatanodeInfoWithStorage[127.0.0.1:36506,DS-631ed405-5b0a-4c37-a6ea-f8086edcbf25,DISK], DatanodeInfoWithStorage[127.0.0.1:40079,DS-3b21142b-eed1-45fd-9677-7b59a796101c,DISK], DatanodeInfoWithStorage[127.0.0.1:42595,DS-524d58fe-bc5f-493a-9938-a1d020f2d7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44125,DS-dd8adc81-8e2d-41fd-919b-4ac2be83527f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1922414268-172.17.0.10-1597749313166:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45906,DS-9bce7704-cb5f-479a-9852-ba6a85cafd5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42294,DS-cc7c9860-1ed3-4a97-8e15-4104b77e5d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:37970,DS-10fc1853-79ca-4b92-bed4-2a4fc5775f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45853,DS-7ae2dd76-eaf3-405f-915c-664c38091243,DISK], DatanodeInfoWithStorage[127.0.0.1:36506,DS-631ed405-5b0a-4c37-a6ea-f8086edcbf25,DISK], DatanodeInfoWithStorage[127.0.0.1:40079,DS-3b21142b-eed1-45fd-9677-7b59a796101c,DISK], DatanodeInfoWithStorage[127.0.0.1:42595,DS-524d58fe-bc5f-493a-9938-a1d020f2d7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44125,DS-dd8adc81-8e2d-41fd-919b-4ac2be83527f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-497914307-172.17.0.10-1597749390493:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46043,DS-18acede4-2bd1-4c6d-8cd2-787a873b2fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:39204,DS-4754e84e-facd-4296-8698-b88dc52f2533,DISK], DatanodeInfoWithStorage[127.0.0.1:41454,DS-e1250e73-a85c-41ab-87df-0c01253e8eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:39407,DS-4f83a261-67f4-48f0-87ea-5dece3213394,DISK], DatanodeInfoWithStorage[127.0.0.1:41918,DS-874cb5ea-7d92-4c51-b994-d846488274ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35336,DS-fd1cfa4a-4c89-4e8b-983a-ffc061788156,DISK], DatanodeInfoWithStorage[127.0.0.1:34237,DS-922327fe-6349-4e93-bf17-baf31f6982de,DISK], DatanodeInfoWithStorage[127.0.0.1:42089,DS-a73e9656-4899-43a9-b7c5-e5a737d3acde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-497914307-172.17.0.10-1597749390493:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46043,DS-18acede4-2bd1-4c6d-8cd2-787a873b2fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:39204,DS-4754e84e-facd-4296-8698-b88dc52f2533,DISK], DatanodeInfoWithStorage[127.0.0.1:41454,DS-e1250e73-a85c-41ab-87df-0c01253e8eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:39407,DS-4f83a261-67f4-48f0-87ea-5dece3213394,DISK], DatanodeInfoWithStorage[127.0.0.1:41918,DS-874cb5ea-7d92-4c51-b994-d846488274ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35336,DS-fd1cfa4a-4c89-4e8b-983a-ffc061788156,DISK], DatanodeInfoWithStorage[127.0.0.1:34237,DS-922327fe-6349-4e93-bf17-baf31f6982de,DISK], DatanodeInfoWithStorage[127.0.0.1:42089,DS-a73e9656-4899-43a9-b7c5-e5a737d3acde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-49058485-172.17.0.10-1597749570648:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44439,DS-c1dc93a3-e17f-41e3-9898-9ac9e3fd8c53,DISK], DatanodeInfoWithStorage[127.0.0.1:45934,DS-5cf1cbe0-07ad-42af-9779-c1d87fdc5cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:38438,DS-ce4d27cf-011d-4cfd-befa-9d0fe1d09b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43246,DS-021a65c7-bcd6-4659-8839-3c572e30d6c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35189,DS-67567afe-6e36-4724-8a17-cafda896510a,DISK], DatanodeInfoWithStorage[127.0.0.1:32892,DS-5f91b807-e774-4d14-b11a-f6da7387fe6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35791,DS-146fb4b9-c0b2-4b90-8c12-a5ecf86bd097,DISK], DatanodeInfoWithStorage[127.0.0.1:45919,DS-4512c8d6-5cdf-4e7d-a999-209dd4f07e6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-49058485-172.17.0.10-1597749570648:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44439,DS-c1dc93a3-e17f-41e3-9898-9ac9e3fd8c53,DISK], DatanodeInfoWithStorage[127.0.0.1:45934,DS-5cf1cbe0-07ad-42af-9779-c1d87fdc5cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:38438,DS-ce4d27cf-011d-4cfd-befa-9d0fe1d09b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43246,DS-021a65c7-bcd6-4659-8839-3c572e30d6c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35189,DS-67567afe-6e36-4724-8a17-cafda896510a,DISK], DatanodeInfoWithStorage[127.0.0.1:32892,DS-5f91b807-e774-4d14-b11a-f6da7387fe6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35791,DS-146fb4b9-c0b2-4b90-8c12-a5ecf86bd097,DISK], DatanodeInfoWithStorage[127.0.0.1:45919,DS-4512c8d6-5cdf-4e7d-a999-209dd4f07e6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1292751220-172.17.0.10-1597749734419:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34351,DS-c35394fb-3194-405e-9301-a6c6f82f9dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:38889,DS-1f56352d-832f-4618-b66b-085eb7545de0,DISK], DatanodeInfoWithStorage[127.0.0.1:46448,DS-c39764dd-4463-4e03-8cc7-062726dd101d,DISK], DatanodeInfoWithStorage[127.0.0.1:35283,DS-2da4dfc3-9087-4d18-a5d6-f5d200ad7188,DISK], DatanodeInfoWithStorage[127.0.0.1:44231,DS-71c2f160-0d51-443e-835b-a16b798b2769,DISK], DatanodeInfoWithStorage[127.0.0.1:33448,DS-60e73d8a-c07f-4cd8-879d-aa8de12d2dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:37660,DS-494bab40-932c-4143-a57f-ac87be569bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:45488,DS-8ebd4339-1367-4d79-ac1c-f0f73c024469,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1292751220-172.17.0.10-1597749734419:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34351,DS-c35394fb-3194-405e-9301-a6c6f82f9dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:38889,DS-1f56352d-832f-4618-b66b-085eb7545de0,DISK], DatanodeInfoWithStorage[127.0.0.1:46448,DS-c39764dd-4463-4e03-8cc7-062726dd101d,DISK], DatanodeInfoWithStorage[127.0.0.1:35283,DS-2da4dfc3-9087-4d18-a5d6-f5d200ad7188,DISK], DatanodeInfoWithStorage[127.0.0.1:44231,DS-71c2f160-0d51-443e-835b-a16b798b2769,DISK], DatanodeInfoWithStorage[127.0.0.1:33448,DS-60e73d8a-c07f-4cd8-879d-aa8de12d2dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:37660,DS-494bab40-932c-4143-a57f-ac87be569bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:45488,DS-8ebd4339-1367-4d79-ac1c-f0f73c024469,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-495133840-172.17.0.10-1597749960054:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44192,DS-38b22745-8e40-47db-babf-aa2a43809749,DISK], DatanodeInfoWithStorage[127.0.0.1:32800,DS-1fb5007b-514d-429b-b219-ad3ec61ca5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33561,DS-5acf411a-575c-41bd-b62d-d72e2b9bfca7,DISK], DatanodeInfoWithStorage[127.0.0.1:38354,DS-8625b379-168a-4ad8-b746-158432e0890d,DISK], DatanodeInfoWithStorage[127.0.0.1:38344,DS-a06a19fc-2aba-42a3-bbf7-7a9257c0e40a,DISK], DatanodeInfoWithStorage[127.0.0.1:35123,DS-ab63d785-bfe0-46e5-aed2-e6792cdf3e65,DISK], DatanodeInfoWithStorage[127.0.0.1:42561,DS-21c52dc1-7eee-435f-aa52-eca81769eab8,DISK], DatanodeInfoWithStorage[127.0.0.1:41731,DS-63b038a1-0f12-4c63-80a0-f4ca334d57e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-495133840-172.17.0.10-1597749960054:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44192,DS-38b22745-8e40-47db-babf-aa2a43809749,DISK], DatanodeInfoWithStorage[127.0.0.1:32800,DS-1fb5007b-514d-429b-b219-ad3ec61ca5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33561,DS-5acf411a-575c-41bd-b62d-d72e2b9bfca7,DISK], DatanodeInfoWithStorage[127.0.0.1:38354,DS-8625b379-168a-4ad8-b746-158432e0890d,DISK], DatanodeInfoWithStorage[127.0.0.1:38344,DS-a06a19fc-2aba-42a3-bbf7-7a9257c0e40a,DISK], DatanodeInfoWithStorage[127.0.0.1:35123,DS-ab63d785-bfe0-46e5-aed2-e6792cdf3e65,DISK], DatanodeInfoWithStorage[127.0.0.1:42561,DS-21c52dc1-7eee-435f-aa52-eca81769eab8,DISK], DatanodeInfoWithStorage[127.0.0.1:41731,DS-63b038a1-0f12-4c63-80a0-f4ca334d57e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1368538268-172.17.0.10-1597749993868:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38154,DS-7e7cc799-0910-4992-b0aa-2dc51ecc17e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37364,DS-9d7bdd1d-ab35-4cb9-8e56-f56d19f9a138,DISK], DatanodeInfoWithStorage[127.0.0.1:43754,DS-f813c103-1535-42ee-a515-8bfdb428309c,DISK], DatanodeInfoWithStorage[127.0.0.1:45636,DS-bfdf4a88-0e29-4d9a-9638-70eb9558b057,DISK], DatanodeInfoWithStorage[127.0.0.1:41677,DS-08e05b74-7135-4243-80d5-83984a74ae42,DISK], DatanodeInfoWithStorage[127.0.0.1:39643,DS-33ce9057-cc00-4fbe-99aa-d1908ef4d862,DISK], DatanodeInfoWithStorage[127.0.0.1:42301,DS-967afe18-7450-4f18-aea5-f2c8dc2e1516,DISK], DatanodeInfoWithStorage[127.0.0.1:40811,DS-1d777e5c-8971-4992-bb81-c1ce58a117de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1368538268-172.17.0.10-1597749993868:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38154,DS-7e7cc799-0910-4992-b0aa-2dc51ecc17e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37364,DS-9d7bdd1d-ab35-4cb9-8e56-f56d19f9a138,DISK], DatanodeInfoWithStorage[127.0.0.1:43754,DS-f813c103-1535-42ee-a515-8bfdb428309c,DISK], DatanodeInfoWithStorage[127.0.0.1:45636,DS-bfdf4a88-0e29-4d9a-9638-70eb9558b057,DISK], DatanodeInfoWithStorage[127.0.0.1:41677,DS-08e05b74-7135-4243-80d5-83984a74ae42,DISK], DatanodeInfoWithStorage[127.0.0.1:39643,DS-33ce9057-cc00-4fbe-99aa-d1908ef4d862,DISK], DatanodeInfoWithStorage[127.0.0.1:42301,DS-967afe18-7450-4f18-aea5-f2c8dc2e1516,DISK], DatanodeInfoWithStorage[127.0.0.1:40811,DS-1d777e5c-8971-4992-bb81-c1ce58a117de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-667465080-172.17.0.10-1597750058801:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38712,DS-4bd358b8-3ed5-48d7-8469-d3c2c1b00581,DISK], DatanodeInfoWithStorage[127.0.0.1:37601,DS-994e895d-1693-4906-b9b2-f771388edb72,DISK], DatanodeInfoWithStorage[127.0.0.1:37398,DS-d6bee7c9-cf8c-4984-ac50-043e99084f10,DISK], DatanodeInfoWithStorage[127.0.0.1:37352,DS-3b64bec7-2dea-4466-923f-5504eca380c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44270,DS-cf24ec74-9eef-409f-b016-83e78714ea6a,DISK], DatanodeInfoWithStorage[127.0.0.1:36371,DS-5317f9e3-5253-4605-9d0e-51367587431f,DISK], DatanodeInfoWithStorage[127.0.0.1:34729,DS-1174eb15-c299-4b6a-9f74-886939e2c179,DISK], DatanodeInfoWithStorage[127.0.0.1:38997,DS-39c3c853-79e3-4add-83bc-6327666a4693,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-667465080-172.17.0.10-1597750058801:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38712,DS-4bd358b8-3ed5-48d7-8469-d3c2c1b00581,DISK], DatanodeInfoWithStorage[127.0.0.1:37601,DS-994e895d-1693-4906-b9b2-f771388edb72,DISK], DatanodeInfoWithStorage[127.0.0.1:37398,DS-d6bee7c9-cf8c-4984-ac50-043e99084f10,DISK], DatanodeInfoWithStorage[127.0.0.1:37352,DS-3b64bec7-2dea-4466-923f-5504eca380c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44270,DS-cf24ec74-9eef-409f-b016-83e78714ea6a,DISK], DatanodeInfoWithStorage[127.0.0.1:36371,DS-5317f9e3-5253-4605-9d0e-51367587431f,DISK], DatanodeInfoWithStorage[127.0.0.1:34729,DS-1174eb15-c299-4b6a-9f74-886939e2c179,DISK], DatanodeInfoWithStorage[127.0.0.1:38997,DS-39c3c853-79e3-4add-83bc-6327666a4693,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1538971063-172.17.0.10-1597750198805:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36574,DS-1f4906c1-82ba-4549-8f16-9a2911247182,DISK], DatanodeInfoWithStorage[127.0.0.1:44309,DS-aa54784c-00db-4b4b-9b21-d12ac97ee62d,DISK], DatanodeInfoWithStorage[127.0.0.1:45286,DS-5e44a2c6-cec1-4f02-9c06-2ce06c95db92,DISK], DatanodeInfoWithStorage[127.0.0.1:45490,DS-ef3ebd69-b988-49e1-be6e-a37f0f1d4449,DISK], DatanodeInfoWithStorage[127.0.0.1:43707,DS-5c0688b0-0a0c-4f9e-8cb5-162cad60ac3b,DISK], DatanodeInfoWithStorage[127.0.0.1:38479,DS-b8370079-5df2-41ef-be75-fd40e9561170,DISK], DatanodeInfoWithStorage[127.0.0.1:33151,DS-984372ff-ef8f-49ac-84be-876d2d9a54d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44829,DS-d3fa5817-384a-4dde-ba68-f13421dcb02e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1538971063-172.17.0.10-1597750198805:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36574,DS-1f4906c1-82ba-4549-8f16-9a2911247182,DISK], DatanodeInfoWithStorage[127.0.0.1:44309,DS-aa54784c-00db-4b4b-9b21-d12ac97ee62d,DISK], DatanodeInfoWithStorage[127.0.0.1:45286,DS-5e44a2c6-cec1-4f02-9c06-2ce06c95db92,DISK], DatanodeInfoWithStorage[127.0.0.1:45490,DS-ef3ebd69-b988-49e1-be6e-a37f0f1d4449,DISK], DatanodeInfoWithStorage[127.0.0.1:43707,DS-5c0688b0-0a0c-4f9e-8cb5-162cad60ac3b,DISK], DatanodeInfoWithStorage[127.0.0.1:38479,DS-b8370079-5df2-41ef-be75-fd40e9561170,DISK], DatanodeInfoWithStorage[127.0.0.1:33151,DS-984372ff-ef8f-49ac-84be-876d2d9a54d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44829,DS-d3fa5817-384a-4dde-ba68-f13421dcb02e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1295858572-172.17.0.10-1597750519014:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37616,DS-9d92a32e-1bb3-4eed-b035-5508175e494c,DISK], DatanodeInfoWithStorage[127.0.0.1:45313,DS-30a02058-da76-4522-9cbe-31981164378e,DISK], DatanodeInfoWithStorage[127.0.0.1:41101,DS-669f2837-696c-4cfa-a7e7-f93d2cf582f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40832,DS-49abb526-8993-46fe-8fd9-aa8f3f80884e,DISK], DatanodeInfoWithStorage[127.0.0.1:44680,DS-81b44ebb-0aba-4f9e-9230-9d8c2432112e,DISK], DatanodeInfoWithStorage[127.0.0.1:40997,DS-cef3c3a1-c5e3-44bd-a507-4153c4121437,DISK], DatanodeInfoWithStorage[127.0.0.1:38382,DS-4cbaeb31-8a50-4459-9ab5-0ad50b3cc28f,DISK], DatanodeInfoWithStorage[127.0.0.1:44374,DS-bdee83e1-cc26-4741-b5b0-2b2dc42e1e23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1295858572-172.17.0.10-1597750519014:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37616,DS-9d92a32e-1bb3-4eed-b035-5508175e494c,DISK], DatanodeInfoWithStorage[127.0.0.1:45313,DS-30a02058-da76-4522-9cbe-31981164378e,DISK], DatanodeInfoWithStorage[127.0.0.1:41101,DS-669f2837-696c-4cfa-a7e7-f93d2cf582f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40832,DS-49abb526-8993-46fe-8fd9-aa8f3f80884e,DISK], DatanodeInfoWithStorage[127.0.0.1:44680,DS-81b44ebb-0aba-4f9e-9230-9d8c2432112e,DISK], DatanodeInfoWithStorage[127.0.0.1:40997,DS-cef3c3a1-c5e3-44bd-a507-4153c4121437,DISK], DatanodeInfoWithStorage[127.0.0.1:38382,DS-4cbaeb31-8a50-4459-9ab5-0ad50b3cc28f,DISK], DatanodeInfoWithStorage[127.0.0.1:44374,DS-bdee83e1-cc26-4741-b5b0-2b2dc42e1e23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1722592301-172.17.0.10-1597751103924:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36360,DS-b2898a42-ef6f-45af-b00d-d46d844fcace,DISK], DatanodeInfoWithStorage[127.0.0.1:41306,DS-8e1ca4aa-3870-440c-a134-b6ce53dfb2e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39472,DS-5f89e05a-ae6e-46eb-be0e-3e44e54ad11d,DISK], DatanodeInfoWithStorage[127.0.0.1:33557,DS-53978fff-e3c9-4774-ad00-b7064d4bc24a,DISK], DatanodeInfoWithStorage[127.0.0.1:44385,DS-6688c377-02d4-482a-8885-5d95fae32d78,DISK], DatanodeInfoWithStorage[127.0.0.1:44983,DS-268459e1-e703-41fa-a734-c4219d49a853,DISK], DatanodeInfoWithStorage[127.0.0.1:40625,DS-d5c40919-4431-4188-b3f5-7387cf75abfe,DISK], DatanodeInfoWithStorage[127.0.0.1:44866,DS-4ae51b7a-4cd0-4af2-8938-8ecfce83b254,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1722592301-172.17.0.10-1597751103924:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36360,DS-b2898a42-ef6f-45af-b00d-d46d844fcace,DISK], DatanodeInfoWithStorage[127.0.0.1:41306,DS-8e1ca4aa-3870-440c-a134-b6ce53dfb2e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39472,DS-5f89e05a-ae6e-46eb-be0e-3e44e54ad11d,DISK], DatanodeInfoWithStorage[127.0.0.1:33557,DS-53978fff-e3c9-4774-ad00-b7064d4bc24a,DISK], DatanodeInfoWithStorage[127.0.0.1:44385,DS-6688c377-02d4-482a-8885-5d95fae32d78,DISK], DatanodeInfoWithStorage[127.0.0.1:44983,DS-268459e1-e703-41fa-a734-c4219d49a853,DISK], DatanodeInfoWithStorage[127.0.0.1:40625,DS-d5c40919-4431-4188-b3f5-7387cf75abfe,DISK], DatanodeInfoWithStorage[127.0.0.1:44866,DS-4ae51b7a-4cd0-4af2-8938-8ecfce83b254,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2076130710-172.17.0.10-1597751373192:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33126,DS-997b81dc-e072-4d8f-8a43-0b5aba3c1c71,DISK], DatanodeInfoWithStorage[127.0.0.1:42414,DS-63250bc1-efae-45e0-a166-1b0673834409,DISK], DatanodeInfoWithStorage[127.0.0.1:42633,DS-9241a4e1-52c4-4627-b8d8-253e57f89401,DISK], DatanodeInfoWithStorage[127.0.0.1:43128,DS-79e68d75-e813-4116-a7b6-a185b8bb8a76,DISK], DatanodeInfoWithStorage[127.0.0.1:44593,DS-a5723979-7e39-4d1b-8ad4-0e6b0808f063,DISK], DatanodeInfoWithStorage[127.0.0.1:38414,DS-8b291dc9-5d88-4fdc-86b9-c5fbb616b5cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39665,DS-5cb56bca-a35f-4b0f-9652-ab15d25c7828,DISK], DatanodeInfoWithStorage[127.0.0.1:44928,DS-9d827e44-b89d-4704-bc64-e44c3238a6c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2076130710-172.17.0.10-1597751373192:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33126,DS-997b81dc-e072-4d8f-8a43-0b5aba3c1c71,DISK], DatanodeInfoWithStorage[127.0.0.1:42414,DS-63250bc1-efae-45e0-a166-1b0673834409,DISK], DatanodeInfoWithStorage[127.0.0.1:42633,DS-9241a4e1-52c4-4627-b8d8-253e57f89401,DISK], DatanodeInfoWithStorage[127.0.0.1:43128,DS-79e68d75-e813-4116-a7b6-a185b8bb8a76,DISK], DatanodeInfoWithStorage[127.0.0.1:44593,DS-a5723979-7e39-4d1b-8ad4-0e6b0808f063,DISK], DatanodeInfoWithStorage[127.0.0.1:38414,DS-8b291dc9-5d88-4fdc-86b9-c5fbb616b5cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39665,DS-5cb56bca-a35f-4b0f-9652-ab15d25c7828,DISK], DatanodeInfoWithStorage[127.0.0.1:44928,DS-9d827e44-b89d-4704-bc64-e44c3238a6c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-614690697-172.17.0.10-1597752246969:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36559,DS-13a90561-8b74-4131-8a01-3b18a1531f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:35359,DS-24c46c61-a90a-4863-ae3f-3cf0703edf5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33120,DS-dea59263-0d22-4026-a27b-34180147026e,DISK], DatanodeInfoWithStorage[127.0.0.1:32992,DS-a285e22d-cce1-4417-9e11-1077e432e63d,DISK], DatanodeInfoWithStorage[127.0.0.1:39940,DS-7cedbce0-335e-4efb-a020-b1778c8f4aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:38628,DS-aeb5b131-aaf1-4c3f-9a9d-f5ceb507e883,DISK], DatanodeInfoWithStorage[127.0.0.1:37573,DS-3390847d-f8b1-4ae1-aa22-15653407b83f,DISK], DatanodeInfoWithStorage[127.0.0.1:37851,DS-2a64f771-7bf1-426b-856f-28889fa69ab1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-614690697-172.17.0.10-1597752246969:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36559,DS-13a90561-8b74-4131-8a01-3b18a1531f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:35359,DS-24c46c61-a90a-4863-ae3f-3cf0703edf5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33120,DS-dea59263-0d22-4026-a27b-34180147026e,DISK], DatanodeInfoWithStorage[127.0.0.1:32992,DS-a285e22d-cce1-4417-9e11-1077e432e63d,DISK], DatanodeInfoWithStorage[127.0.0.1:39940,DS-7cedbce0-335e-4efb-a020-b1778c8f4aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:38628,DS-aeb5b131-aaf1-4c3f-9a9d-f5ceb507e883,DISK], DatanodeInfoWithStorage[127.0.0.1:37573,DS-3390847d-f8b1-4ae1-aa22-15653407b83f,DISK], DatanodeInfoWithStorage[127.0.0.1:37851,DS-2a64f771-7bf1-426b-856f-28889fa69ab1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1128658116-172.17.0.10-1597752465822:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41079,DS-f71fa8f5-619f-41be-ad8e-1ac665dac414,DISK], DatanodeInfoWithStorage[127.0.0.1:45060,DS-16784331-3b74-4685-b510-c5148557b451,DISK], DatanodeInfoWithStorage[127.0.0.1:43348,DS-c9db2a29-0793-4a2c-bdb1-27044c3ff4fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42441,DS-deeadc34-202d-4e24-b42d-3084554f605d,DISK], DatanodeInfoWithStorage[127.0.0.1:41775,DS-165cb22c-63e1-447e-bd84-13bc4d23fe26,DISK], DatanodeInfoWithStorage[127.0.0.1:34830,DS-c4a242bd-91db-414d-b3f3-4956b95d7ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:32853,DS-65dd1a26-56d7-4358-bd29-1d679e885c70,DISK], DatanodeInfoWithStorage[127.0.0.1:40876,DS-1b285032-a919-4cc9-b6d3-c9d56e52ab7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1128658116-172.17.0.10-1597752465822:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41079,DS-f71fa8f5-619f-41be-ad8e-1ac665dac414,DISK], DatanodeInfoWithStorage[127.0.0.1:45060,DS-16784331-3b74-4685-b510-c5148557b451,DISK], DatanodeInfoWithStorage[127.0.0.1:43348,DS-c9db2a29-0793-4a2c-bdb1-27044c3ff4fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42441,DS-deeadc34-202d-4e24-b42d-3084554f605d,DISK], DatanodeInfoWithStorage[127.0.0.1:41775,DS-165cb22c-63e1-447e-bd84-13bc4d23fe26,DISK], DatanodeInfoWithStorage[127.0.0.1:34830,DS-c4a242bd-91db-414d-b3f3-4956b95d7ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:32853,DS-65dd1a26-56d7-4358-bd29-1d679e885c70,DISK], DatanodeInfoWithStorage[127.0.0.1:40876,DS-1b285032-a919-4cc9-b6d3-c9d56e52ab7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2088256634-172.17.0.10-1597752505687:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36375,DS-a07af416-64bc-4502-9dee-7a78ececf445,DISK], DatanodeInfoWithStorage[127.0.0.1:41394,DS-087b6dde-a37d-4360-8442-74910e9b1cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:39952,DS-86f2845c-49a5-4e1f-998c-f77c09e1141b,DISK], DatanodeInfoWithStorage[127.0.0.1:36214,DS-d0f81260-4c91-4af5-a095-cefb86b66052,DISK], DatanodeInfoWithStorage[127.0.0.1:39860,DS-ffe55d8d-4825-4e45-8cab-e37fc0a1e7e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42910,DS-f115cf8b-0399-4756-8859-008524901709,DISK], DatanodeInfoWithStorage[127.0.0.1:44480,DS-86daa53a-1960-41a2-b537-7e58607815d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38504,DS-ad4fe236-b322-4c0d-b268-c31e02474bab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2088256634-172.17.0.10-1597752505687:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36375,DS-a07af416-64bc-4502-9dee-7a78ececf445,DISK], DatanodeInfoWithStorage[127.0.0.1:41394,DS-087b6dde-a37d-4360-8442-74910e9b1cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:39952,DS-86f2845c-49a5-4e1f-998c-f77c09e1141b,DISK], DatanodeInfoWithStorage[127.0.0.1:36214,DS-d0f81260-4c91-4af5-a095-cefb86b66052,DISK], DatanodeInfoWithStorage[127.0.0.1:39860,DS-ffe55d8d-4825-4e45-8cab-e37fc0a1e7e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42910,DS-f115cf8b-0399-4756-8859-008524901709,DISK], DatanodeInfoWithStorage[127.0.0.1:44480,DS-86daa53a-1960-41a2-b537-7e58607815d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38504,DS-ad4fe236-b322-4c0d-b268-c31e02474bab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2063407828-172.17.0.10-1597752734820:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38756,DS-d9312068-6c2f-4d9e-87ad-7f4e8c109a95,DISK], DatanodeInfoWithStorage[127.0.0.1:46579,DS-f96b552a-171a-453a-85db-25c9386e0038,DISK], DatanodeInfoWithStorage[127.0.0.1:45231,DS-c0ee04b3-b73a-4240-abcf-b2c2f15adc7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42879,DS-ee579dc3-59e8-43ed-8f8a-5a8b45f8f34e,DISK], DatanodeInfoWithStorage[127.0.0.1:38972,DS-2d3edc4c-0b3e-48af-bb94-296c0f7cee92,DISK], DatanodeInfoWithStorage[127.0.0.1:32796,DS-44f7f248-b995-4c15-bae0-76b20d4414c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35472,DS-a45ebb92-ed42-4d07-acd5-b5149a059d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:36273,DS-b75b4283-90d1-486a-a8fe-1ca1901865dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2063407828-172.17.0.10-1597752734820:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38756,DS-d9312068-6c2f-4d9e-87ad-7f4e8c109a95,DISK], DatanodeInfoWithStorage[127.0.0.1:46579,DS-f96b552a-171a-453a-85db-25c9386e0038,DISK], DatanodeInfoWithStorage[127.0.0.1:45231,DS-c0ee04b3-b73a-4240-abcf-b2c2f15adc7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42879,DS-ee579dc3-59e8-43ed-8f8a-5a8b45f8f34e,DISK], DatanodeInfoWithStorage[127.0.0.1:38972,DS-2d3edc4c-0b3e-48af-bb94-296c0f7cee92,DISK], DatanodeInfoWithStorage[127.0.0.1:32796,DS-44f7f248-b995-4c15-bae0-76b20d4414c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35472,DS-a45ebb92-ed42-4d07-acd5-b5149a059d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:36273,DS-b75b4283-90d1-486a-a8fe-1ca1901865dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-861493670-172.17.0.10-1597752887607:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33575,DS-fc19382a-3c98-44c0-b229-30ecc7de0e29,DISK], DatanodeInfoWithStorage[127.0.0.1:42264,DS-afdb5e25-4d63-4367-9b69-15edb6aedf37,DISK], DatanodeInfoWithStorage[127.0.0.1:38303,DS-b31cec99-1fe5-48fb-a83f-b6870d0d97ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42337,DS-4e648d74-6713-4c18-965a-3017b1dea277,DISK], DatanodeInfoWithStorage[127.0.0.1:41938,DS-f931b8eb-a2af-4aa2-bf96-dc639a29a377,DISK], DatanodeInfoWithStorage[127.0.0.1:39951,DS-4fa9a733-56b2-4c1b-b6cf-fbcb1784f68c,DISK], DatanodeInfoWithStorage[127.0.0.1:39322,DS-3f0bb32b-fc4e-4a37-8ec4-0930f2cb6078,DISK], DatanodeInfoWithStorage[127.0.0.1:41740,DS-e7dc4742-85d4-45ff-85e9-f6f08b6a8d6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-861493670-172.17.0.10-1597752887607:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33575,DS-fc19382a-3c98-44c0-b229-30ecc7de0e29,DISK], DatanodeInfoWithStorage[127.0.0.1:42264,DS-afdb5e25-4d63-4367-9b69-15edb6aedf37,DISK], DatanodeInfoWithStorage[127.0.0.1:38303,DS-b31cec99-1fe5-48fb-a83f-b6870d0d97ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42337,DS-4e648d74-6713-4c18-965a-3017b1dea277,DISK], DatanodeInfoWithStorage[127.0.0.1:41938,DS-f931b8eb-a2af-4aa2-bf96-dc639a29a377,DISK], DatanodeInfoWithStorage[127.0.0.1:39951,DS-4fa9a733-56b2-4c1b-b6cf-fbcb1784f68c,DISK], DatanodeInfoWithStorage[127.0.0.1:39322,DS-3f0bb32b-fc4e-4a37-8ec4-0930f2cb6078,DISK], DatanodeInfoWithStorage[127.0.0.1:41740,DS-e7dc4742-85d4-45ff-85e9-f6f08b6a8d6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1143566822-172.17.0.10-1597752916058:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36429,DS-48439de5-0fdf-416e-9203-55547e867199,DISK], DatanodeInfoWithStorage[127.0.0.1:41159,DS-e2409961-7939-41c9-b922-9c09594cbdbe,DISK], DatanodeInfoWithStorage[127.0.0.1:42253,DS-0d4a7a98-b228-42c1-bf31-191b7ace54c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35609,DS-5bfdc22b-30da-4d05-9016-5bc46f48bdca,DISK], DatanodeInfoWithStorage[127.0.0.1:42788,DS-b6322cef-93d4-432f-8ec1-6d0a1cf322f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33261,DS-28818ab6-ac9b-4088-974f-dfcbf18601e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44185,DS-8f3f07fc-1390-46a7-bde6-5eef02f1ac34,DISK], DatanodeInfoWithStorage[127.0.0.1:39239,DS-04261095-779b-4d18-990a-9caac9285e88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1143566822-172.17.0.10-1597752916058:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36429,DS-48439de5-0fdf-416e-9203-55547e867199,DISK], DatanodeInfoWithStorage[127.0.0.1:41159,DS-e2409961-7939-41c9-b922-9c09594cbdbe,DISK], DatanodeInfoWithStorage[127.0.0.1:42253,DS-0d4a7a98-b228-42c1-bf31-191b7ace54c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35609,DS-5bfdc22b-30da-4d05-9016-5bc46f48bdca,DISK], DatanodeInfoWithStorage[127.0.0.1:42788,DS-b6322cef-93d4-432f-8ec1-6d0a1cf322f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33261,DS-28818ab6-ac9b-4088-974f-dfcbf18601e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44185,DS-8f3f07fc-1390-46a7-bde6-5eef02f1ac34,DISK], DatanodeInfoWithStorage[127.0.0.1:39239,DS-04261095-779b-4d18-990a-9caac9285e88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1992378142-172.17.0.10-1597753028615:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41755,DS-e48e4284-294c-42b7-bff5-b5282f5a8234,DISK], DatanodeInfoWithStorage[127.0.0.1:33799,DS-8b509bc9-01ab-4ec4-ab3a-35070eaacc00,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-fad8a0f2-8736-40a5-aa5f-698f2a356132,DISK], DatanodeInfoWithStorage[127.0.0.1:43003,DS-f2291a1f-3745-4814-aaec-83cc6bca6609,DISK], DatanodeInfoWithStorage[127.0.0.1:35044,DS-db9474f0-d2a0-4756-b157-068c9e4e7c13,DISK], DatanodeInfoWithStorage[127.0.0.1:42203,DS-a3de67c1-f75b-4c6e-af89-090071736119,DISK], DatanodeInfoWithStorage[127.0.0.1:40486,DS-a28c4544-3ff3-46b1-8d55-293d0bc55c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:34688,DS-0e6c12c8-cb65-4c4c-8d9c-a75901b60dc9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1992378142-172.17.0.10-1597753028615:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41755,DS-e48e4284-294c-42b7-bff5-b5282f5a8234,DISK], DatanodeInfoWithStorage[127.0.0.1:33799,DS-8b509bc9-01ab-4ec4-ab3a-35070eaacc00,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-fad8a0f2-8736-40a5-aa5f-698f2a356132,DISK], DatanodeInfoWithStorage[127.0.0.1:43003,DS-f2291a1f-3745-4814-aaec-83cc6bca6609,DISK], DatanodeInfoWithStorage[127.0.0.1:35044,DS-db9474f0-d2a0-4756-b157-068c9e4e7c13,DISK], DatanodeInfoWithStorage[127.0.0.1:42203,DS-a3de67c1-f75b-4c6e-af89-090071736119,DISK], DatanodeInfoWithStorage[127.0.0.1:40486,DS-a28c4544-3ff3-46b1-8d55-293d0bc55c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:34688,DS-0e6c12c8-cb65-4c4c-8d9c-a75901b60dc9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-160765699-172.17.0.10-1597753131361:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43915,DS-636c2856-8911-4006-835c-bda9c6ec67ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39711,DS-79f71dc0-0816-4bee-bd90-a17f9e6fb994,DISK], DatanodeInfoWithStorage[127.0.0.1:33322,DS-86f38b16-38c4-4f7e-a133-8b99128efe67,DISK], DatanodeInfoWithStorage[127.0.0.1:33291,DS-843e8ccb-346b-478c-9d5a-0e372bf8cfcb,DISK], DatanodeInfoWithStorage[127.0.0.1:45745,DS-a9fe9b73-4a06-4798-9545-929984c3d48a,DISK], DatanodeInfoWithStorage[127.0.0.1:34753,DS-8759a15c-31a4-416a-880c-0627b5441866,DISK], DatanodeInfoWithStorage[127.0.0.1:41057,DS-a880fb2e-9c36-4c64-ba24-da57aac36e84,DISK], DatanodeInfoWithStorage[127.0.0.1:44705,DS-75dce185-c3a4-4316-af90-c3f39b418878,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-160765699-172.17.0.10-1597753131361:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43915,DS-636c2856-8911-4006-835c-bda9c6ec67ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39711,DS-79f71dc0-0816-4bee-bd90-a17f9e6fb994,DISK], DatanodeInfoWithStorage[127.0.0.1:33322,DS-86f38b16-38c4-4f7e-a133-8b99128efe67,DISK], DatanodeInfoWithStorage[127.0.0.1:33291,DS-843e8ccb-346b-478c-9d5a-0e372bf8cfcb,DISK], DatanodeInfoWithStorage[127.0.0.1:45745,DS-a9fe9b73-4a06-4798-9545-929984c3d48a,DISK], DatanodeInfoWithStorage[127.0.0.1:34753,DS-8759a15c-31a4-416a-880c-0627b5441866,DISK], DatanodeInfoWithStorage[127.0.0.1:41057,DS-a880fb2e-9c36-4c64-ba24-da57aac36e84,DISK], DatanodeInfoWithStorage[127.0.0.1:44705,DS-75dce185-c3a4-4316-af90-c3f39b418878,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-226802948-172.17.0.10-1597753670065:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41099,DS-3bc27610-7abf-4b1b-87b0-a9fc4626e511,DISK], DatanodeInfoWithStorage[127.0.0.1:46169,DS-2e77b30c-a10f-464b-a5af-540efbb7a4d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45248,DS-56dc3a54-c508-40a6-989b-a74224785bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:43160,DS-7b930c1d-2e2d-4cfe-976f-d0c273313bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:40403,DS-7c92b6e5-dad1-489a-8fdc-1b471ba5fab1,DISK], DatanodeInfoWithStorage[127.0.0.1:39962,DS-7be3c4d6-f149-402a-977b-d02f297c3c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:37042,DS-5540616d-dd6c-4fa2-845f-79c7b827d056,DISK], DatanodeInfoWithStorage[127.0.0.1:46011,DS-d3c8fd41-8f76-4382-a888-bd6791775399,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-226802948-172.17.0.10-1597753670065:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41099,DS-3bc27610-7abf-4b1b-87b0-a9fc4626e511,DISK], DatanodeInfoWithStorage[127.0.0.1:46169,DS-2e77b30c-a10f-464b-a5af-540efbb7a4d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45248,DS-56dc3a54-c508-40a6-989b-a74224785bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:43160,DS-7b930c1d-2e2d-4cfe-976f-d0c273313bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:40403,DS-7c92b6e5-dad1-489a-8fdc-1b471ba5fab1,DISK], DatanodeInfoWithStorage[127.0.0.1:39962,DS-7be3c4d6-f149-402a-977b-d02f297c3c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:37042,DS-5540616d-dd6c-4fa2-845f-79c7b827d056,DISK], DatanodeInfoWithStorage[127.0.0.1:46011,DS-d3c8fd41-8f76-4382-a888-bd6791775399,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 16 out of 50
result: false positive !!!
Total execution time in seconds : 5527
