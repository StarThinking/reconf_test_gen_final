reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-397213651-172.17.0.15-1597320827443:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35484,DS-99e4fe87-98d6-491a-9539-1339e9e1ecfd,DISK], DatanodeInfoWithStorage[127.0.0.1:37358,DS-7ba76878-4694-4f96-83fd-eabe12c271f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40424,DS-2144fa9b-c161-4b2b-b039-12934f58d9dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43568,DS-c985a239-1344-4281-8cb8-38ef2adc6b24,DISK], DatanodeInfoWithStorage[127.0.0.1:42932,DS-15905cfa-714b-4b6b-947c-9e5357ced88c,DISK], DatanodeInfoWithStorage[127.0.0.1:38458,DS-8ccdedd4-c85d-4663-bec5-8bf31c23296f,DISK], DatanodeInfoWithStorage[127.0.0.1:39339,DS-0e5ac827-8377-4755-8da1-9cce65b0b588,DISK], DatanodeInfoWithStorage[127.0.0.1:44049,DS-238a11bf-a158-4aca-9e4a-393b7abff990,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-397213651-172.17.0.15-1597320827443:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35484,DS-99e4fe87-98d6-491a-9539-1339e9e1ecfd,DISK], DatanodeInfoWithStorage[127.0.0.1:37358,DS-7ba76878-4694-4f96-83fd-eabe12c271f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40424,DS-2144fa9b-c161-4b2b-b039-12934f58d9dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43568,DS-c985a239-1344-4281-8cb8-38ef2adc6b24,DISK], DatanodeInfoWithStorage[127.0.0.1:42932,DS-15905cfa-714b-4b6b-947c-9e5357ced88c,DISK], DatanodeInfoWithStorage[127.0.0.1:38458,DS-8ccdedd4-c85d-4663-bec5-8bf31c23296f,DISK], DatanodeInfoWithStorage[127.0.0.1:39339,DS-0e5ac827-8377-4755-8da1-9cce65b0b588,DISK], DatanodeInfoWithStorage[127.0.0.1:44049,DS-238a11bf-a158-4aca-9e4a-393b7abff990,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1885378168-172.17.0.15-1597322183063:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34925,DS-025714c8-6f6e-49a9-ac9f-7bcaf84eb91b,DISK], DatanodeInfoWithStorage[127.0.0.1:42052,DS-1da8d24f-8f45-4db6-a16a-5c0ac2a13ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:40378,DS-b5bfd986-5b9e-4191-ab5d-1505f70733ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40514,DS-3e93aa6d-7069-4313-b135-660bd64993fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42811,DS-3354658f-b9e0-467c-8e69-aed1fb7d88f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34803,DS-40cb09b0-0f19-42e0-8564-6b002c677e17,DISK], DatanodeInfoWithStorage[127.0.0.1:46530,DS-324335c8-b135-4d6a-9a73-7fa96c555fae,DISK], DatanodeInfoWithStorage[127.0.0.1:40849,DS-50ff128c-3da4-4ea6-95c4-54bce34bd703,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1885378168-172.17.0.15-1597322183063:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34925,DS-025714c8-6f6e-49a9-ac9f-7bcaf84eb91b,DISK], DatanodeInfoWithStorage[127.0.0.1:42052,DS-1da8d24f-8f45-4db6-a16a-5c0ac2a13ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:40378,DS-b5bfd986-5b9e-4191-ab5d-1505f70733ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40514,DS-3e93aa6d-7069-4313-b135-660bd64993fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42811,DS-3354658f-b9e0-467c-8e69-aed1fb7d88f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34803,DS-40cb09b0-0f19-42e0-8564-6b002c677e17,DISK], DatanodeInfoWithStorage[127.0.0.1:46530,DS-324335c8-b135-4d6a-9a73-7fa96c555fae,DISK], DatanodeInfoWithStorage[127.0.0.1:40849,DS-50ff128c-3da4-4ea6-95c4-54bce34bd703,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-380508546-172.17.0.15-1597322401475:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35406,DS-fba299e8-f5c5-48e8-b989-c15c55eaf161,DISK], DatanodeInfoWithStorage[127.0.0.1:45019,DS-9d871050-8d93-45d9-b7a0-0fa93cb3734f,DISK], DatanodeInfoWithStorage[127.0.0.1:34336,DS-568c930c-714b-46cb-9c1e-3239da500d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35280,DS-d705e8ca-cfc0-46db-a0a8-ad326a12f19c,DISK], DatanodeInfoWithStorage[127.0.0.1:43834,DS-a9c0b62e-5ef0-4b4b-a887-1ffa287e9629,DISK], DatanodeInfoWithStorage[127.0.0.1:32797,DS-487e3b9c-01cf-416d-9fd5-5e718fc2cc71,DISK], DatanodeInfoWithStorage[127.0.0.1:35927,DS-231cae53-3762-4e39-bfe4-441c80eb59b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41433,DS-9f5c378b-91cd-40fc-97a2-e4fbc386f41d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-380508546-172.17.0.15-1597322401475:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35406,DS-fba299e8-f5c5-48e8-b989-c15c55eaf161,DISK], DatanodeInfoWithStorage[127.0.0.1:45019,DS-9d871050-8d93-45d9-b7a0-0fa93cb3734f,DISK], DatanodeInfoWithStorage[127.0.0.1:34336,DS-568c930c-714b-46cb-9c1e-3239da500d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35280,DS-d705e8ca-cfc0-46db-a0a8-ad326a12f19c,DISK], DatanodeInfoWithStorage[127.0.0.1:43834,DS-a9c0b62e-5ef0-4b4b-a887-1ffa287e9629,DISK], DatanodeInfoWithStorage[127.0.0.1:32797,DS-487e3b9c-01cf-416d-9fd5-5e718fc2cc71,DISK], DatanodeInfoWithStorage[127.0.0.1:35927,DS-231cae53-3762-4e39-bfe4-441c80eb59b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41433,DS-9f5c378b-91cd-40fc-97a2-e4fbc386f41d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-402645852-172.17.0.15-1597323779435:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33952,DS-083943fd-ac37-46ab-9915-298992d30f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45458,DS-9bbacf67-5e84-4505-ac24-b9c3c845dff6,DISK], DatanodeInfoWithStorage[127.0.0.1:38392,DS-59d34850-4274-4902-94f5-cd6853eb332b,DISK], DatanodeInfoWithStorage[127.0.0.1:42747,DS-b8d98f41-b6c0-4b15-ac83-9919bd3f130b,DISK], DatanodeInfoWithStorage[127.0.0.1:36308,DS-3e0e6ab4-af87-4681-b011-141275153207,DISK], DatanodeInfoWithStorage[127.0.0.1:33447,DS-1aad5b42-c92a-4184-85ac-be43528ba8e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34622,DS-ceead890-f195-437c-9ac4-4dcadd09fdf9,DISK], DatanodeInfoWithStorage[127.0.0.1:42098,DS-457de0d1-d707-4dc8-b947-a132504e0d95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-402645852-172.17.0.15-1597323779435:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33952,DS-083943fd-ac37-46ab-9915-298992d30f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45458,DS-9bbacf67-5e84-4505-ac24-b9c3c845dff6,DISK], DatanodeInfoWithStorage[127.0.0.1:38392,DS-59d34850-4274-4902-94f5-cd6853eb332b,DISK], DatanodeInfoWithStorage[127.0.0.1:42747,DS-b8d98f41-b6c0-4b15-ac83-9919bd3f130b,DISK], DatanodeInfoWithStorage[127.0.0.1:36308,DS-3e0e6ab4-af87-4681-b011-141275153207,DISK], DatanodeInfoWithStorage[127.0.0.1:33447,DS-1aad5b42-c92a-4184-85ac-be43528ba8e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34622,DS-ceead890-f195-437c-9ac4-4dcadd09fdf9,DISK], DatanodeInfoWithStorage[127.0.0.1:42098,DS-457de0d1-d707-4dc8-b947-a132504e0d95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-91123556-172.17.0.15-1597323964538:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41198,DS-518ecc2f-311c-4708-b374-8d9fcb48ac09,DISK], DatanodeInfoWithStorage[127.0.0.1:37682,DS-f8f3e480-c167-44c9-a0ca-01272f400b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34748,DS-d4b9e4d6-44a7-48ec-944d-685167839ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:34308,DS-b64c6d16-dc57-45c0-be21-0ac24afc9315,DISK], DatanodeInfoWithStorage[127.0.0.1:35352,DS-84021eda-f35f-48c0-ace3-aba191037617,DISK], DatanodeInfoWithStorage[127.0.0.1:39838,DS-f9519ba2-6fb8-4304-a536-b9d4a3d5ca15,DISK], DatanodeInfoWithStorage[127.0.0.1:35168,DS-124aa8f1-6bb4-4773-b721-3e1db29398c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39035,DS-018659d3-22e6-49e3-af39-dad46d3f9b3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-91123556-172.17.0.15-1597323964538:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41198,DS-518ecc2f-311c-4708-b374-8d9fcb48ac09,DISK], DatanodeInfoWithStorage[127.0.0.1:37682,DS-f8f3e480-c167-44c9-a0ca-01272f400b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34748,DS-d4b9e4d6-44a7-48ec-944d-685167839ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:34308,DS-b64c6d16-dc57-45c0-be21-0ac24afc9315,DISK], DatanodeInfoWithStorage[127.0.0.1:35352,DS-84021eda-f35f-48c0-ace3-aba191037617,DISK], DatanodeInfoWithStorage[127.0.0.1:39838,DS-f9519ba2-6fb8-4304-a536-b9d4a3d5ca15,DISK], DatanodeInfoWithStorage[127.0.0.1:35168,DS-124aa8f1-6bb4-4773-b721-3e1db29398c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39035,DS-018659d3-22e6-49e3-af39-dad46d3f9b3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2002564895-172.17.0.15-1597324290776:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37502,DS-d478376c-285e-4351-a88f-b90d537005c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42486,DS-0f636bc0-80d6-4234-818e-570e219e4f53,DISK], DatanodeInfoWithStorage[127.0.0.1:35995,DS-7334bccc-f397-4adf-bd17-8d2382a8f690,DISK], DatanodeInfoWithStorage[127.0.0.1:36719,DS-37aad850-9054-4909-83c7-e6d0002597ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34097,DS-790e4b1b-529c-4a64-88bd-38f421df0cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:38292,DS-08c50aee-1e93-4a28-bc7c-8badab4615fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45039,DS-d9ca7728-3ea0-4348-8870-798a01168027,DISK], DatanodeInfoWithStorage[127.0.0.1:43369,DS-9b3fa863-6cde-4850-b27e-b732b104bb0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2002564895-172.17.0.15-1597324290776:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37502,DS-d478376c-285e-4351-a88f-b90d537005c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42486,DS-0f636bc0-80d6-4234-818e-570e219e4f53,DISK], DatanodeInfoWithStorage[127.0.0.1:35995,DS-7334bccc-f397-4adf-bd17-8d2382a8f690,DISK], DatanodeInfoWithStorage[127.0.0.1:36719,DS-37aad850-9054-4909-83c7-e6d0002597ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34097,DS-790e4b1b-529c-4a64-88bd-38f421df0cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:38292,DS-08c50aee-1e93-4a28-bc7c-8badab4615fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45039,DS-d9ca7728-3ea0-4348-8870-798a01168027,DISK], DatanodeInfoWithStorage[127.0.0.1:43369,DS-9b3fa863-6cde-4850-b27e-b732b104bb0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-914193860-172.17.0.15-1597325191954:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38427,DS-62e535da-d2f9-451c-8f65-a92c76e32792,DISK], DatanodeInfoWithStorage[127.0.0.1:35773,DS-cd21bc46-54b5-41ac-9e03-ce1f62df8251,DISK], DatanodeInfoWithStorage[127.0.0.1:39520,DS-4229b08f-50c2-419d-b188-a734f7698e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:36142,DS-09fe5e56-ce1c-4f68-8516-b56bcc26c168,DISK], DatanodeInfoWithStorage[127.0.0.1:42795,DS-633c1008-8138-407b-acd6-252a068cc1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45206,DS-1d41fa37-bda0-4e0e-861c-0f15adab09b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46538,DS-debc5bd7-b476-4ce7-b892-b9c6498727a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39127,DS-47d33599-77a3-4aa5-a636-f448a678f0db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-914193860-172.17.0.15-1597325191954:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38427,DS-62e535da-d2f9-451c-8f65-a92c76e32792,DISK], DatanodeInfoWithStorage[127.0.0.1:35773,DS-cd21bc46-54b5-41ac-9e03-ce1f62df8251,DISK], DatanodeInfoWithStorage[127.0.0.1:39520,DS-4229b08f-50c2-419d-b188-a734f7698e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:36142,DS-09fe5e56-ce1c-4f68-8516-b56bcc26c168,DISK], DatanodeInfoWithStorage[127.0.0.1:42795,DS-633c1008-8138-407b-acd6-252a068cc1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45206,DS-1d41fa37-bda0-4e0e-861c-0f15adab09b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46538,DS-debc5bd7-b476-4ce7-b892-b9c6498727a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39127,DS-47d33599-77a3-4aa5-a636-f448a678f0db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1742525701-172.17.0.15-1597325943300:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34830,DS-00b80680-d4b6-4d70-aa07-80020cfe457a,DISK], DatanodeInfoWithStorage[127.0.0.1:44031,DS-e19f25ab-8593-448f-896b-3298a3832e20,DISK], DatanodeInfoWithStorage[127.0.0.1:42125,DS-413b9548-af2f-42a8-bef5-3d3bbf5ac5bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37849,DS-1b99a02d-c2ad-4ff0-af13-13e2760ebaa6,DISK], DatanodeInfoWithStorage[127.0.0.1:34351,DS-aa203688-7da3-4d4c-9063-33e3021215c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37751,DS-2b3da928-0128-4a88-9644-a873b42ebb22,DISK], DatanodeInfoWithStorage[127.0.0.1:44991,DS-23a73ee5-93f0-4b3b-9158-0297da27f355,DISK], DatanodeInfoWithStorage[127.0.0.1:36434,DS-de8ac9ab-d462-4b67-baed-5c3fc535a3fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1742525701-172.17.0.15-1597325943300:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34830,DS-00b80680-d4b6-4d70-aa07-80020cfe457a,DISK], DatanodeInfoWithStorage[127.0.0.1:44031,DS-e19f25ab-8593-448f-896b-3298a3832e20,DISK], DatanodeInfoWithStorage[127.0.0.1:42125,DS-413b9548-af2f-42a8-bef5-3d3bbf5ac5bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37849,DS-1b99a02d-c2ad-4ff0-af13-13e2760ebaa6,DISK], DatanodeInfoWithStorage[127.0.0.1:34351,DS-aa203688-7da3-4d4c-9063-33e3021215c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37751,DS-2b3da928-0128-4a88-9644-a873b42ebb22,DISK], DatanodeInfoWithStorage[127.0.0.1:44991,DS-23a73ee5-93f0-4b3b-9158-0297da27f355,DISK], DatanodeInfoWithStorage[127.0.0.1:36434,DS-de8ac9ab-d462-4b67-baed-5c3fc535a3fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1689459217-172.17.0.15-1597326666269:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35992,DS-59e51522-0cde-42ad-b6b8-fe5e7c3223cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44852,DS-d8f9d102-abca-4e7c-b7a5-6bc96e29b3a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34596,DS-adeab835-4e40-4db0-bd1f-6dac4e813487,DISK], DatanodeInfoWithStorage[127.0.0.1:33223,DS-d311673e-aa04-448b-a176-6507c8c665e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34495,DS-eb1bbe8a-e22e-40e6-a0b6-1d4e2b9baa92,DISK], DatanodeInfoWithStorage[127.0.0.1:33092,DS-82dd928d-7c0e-4440-bc0d-159ec5427bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:36889,DS-540e77fc-d25d-4e6b-9946-40cecce71cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:41655,DS-cbbd6daa-98ac-418d-98d5-f8efdfbc45af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1689459217-172.17.0.15-1597326666269:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35992,DS-59e51522-0cde-42ad-b6b8-fe5e7c3223cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44852,DS-d8f9d102-abca-4e7c-b7a5-6bc96e29b3a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34596,DS-adeab835-4e40-4db0-bd1f-6dac4e813487,DISK], DatanodeInfoWithStorage[127.0.0.1:33223,DS-d311673e-aa04-448b-a176-6507c8c665e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34495,DS-eb1bbe8a-e22e-40e6-a0b6-1d4e2b9baa92,DISK], DatanodeInfoWithStorage[127.0.0.1:33092,DS-82dd928d-7c0e-4440-bc0d-159ec5427bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:36889,DS-540e77fc-d25d-4e6b-9946-40cecce71cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:41655,DS-cbbd6daa-98ac-418d-98d5-f8efdfbc45af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-349248775-172.17.0.15-1597326964382:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33894,DS-744a19b1-490c-4ae0-a6c5-296fbf8f0553,DISK], DatanodeInfoWithStorage[127.0.0.1:46330,DS-e2fd2aec-8136-4c34-b151-f3b746c4b815,DISK], DatanodeInfoWithStorage[127.0.0.1:33232,DS-66c77c8f-053f-4dc4-b0e5-6f97c54e8b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43249,DS-c98bcb86-208f-4256-b74f-8b0e4c4b44d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39659,DS-a7805f72-0be3-4915-bacb-aff600fd8faa,DISK], DatanodeInfoWithStorage[127.0.0.1:41145,DS-88dee734-82a5-4304-94a3-876e3b22217d,DISK], DatanodeInfoWithStorage[127.0.0.1:39115,DS-897f70df-4407-4740-b75a-81c14524da24,DISK], DatanodeInfoWithStorage[127.0.0.1:34687,DS-f2f6c2ab-b128-441e-8d2f-ca8b9ca21350,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-349248775-172.17.0.15-1597326964382:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33894,DS-744a19b1-490c-4ae0-a6c5-296fbf8f0553,DISK], DatanodeInfoWithStorage[127.0.0.1:46330,DS-e2fd2aec-8136-4c34-b151-f3b746c4b815,DISK], DatanodeInfoWithStorage[127.0.0.1:33232,DS-66c77c8f-053f-4dc4-b0e5-6f97c54e8b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43249,DS-c98bcb86-208f-4256-b74f-8b0e4c4b44d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39659,DS-a7805f72-0be3-4915-bacb-aff600fd8faa,DISK], DatanodeInfoWithStorage[127.0.0.1:41145,DS-88dee734-82a5-4304-94a3-876e3b22217d,DISK], DatanodeInfoWithStorage[127.0.0.1:39115,DS-897f70df-4407-4740-b75a-81c14524da24,DISK], DatanodeInfoWithStorage[127.0.0.1:34687,DS-f2f6c2ab-b128-441e-8d2f-ca8b9ca21350,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 7118
