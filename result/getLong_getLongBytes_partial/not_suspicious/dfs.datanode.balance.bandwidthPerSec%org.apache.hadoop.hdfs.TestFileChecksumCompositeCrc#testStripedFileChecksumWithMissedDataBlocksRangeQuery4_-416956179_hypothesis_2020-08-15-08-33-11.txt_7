reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1066313522-172.17.0.3-1597480516131:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45428,DS-d46ef782-de43-4205-983b-d0f118d2be64,DISK], DatanodeInfoWithStorage[127.0.0.1:37495,DS-07baf70f-0c5f-4d7e-9ea8-c93ad364d49c,DISK], DatanodeInfoWithStorage[127.0.0.1:37630,DS-8ba1bfed-bbee-4ed3-beae-616b653f6f85,DISK], DatanodeInfoWithStorage[127.0.0.1:46339,DS-d7530001-8b96-494c-83a8-9cf553b559aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44385,DS-d2eb0099-0f93-4cf8-9920-54dd39e3193e,DISK], DatanodeInfoWithStorage[127.0.0.1:46633,DS-634bec1d-6483-4e09-9ee7-355a933a3efd,DISK], DatanodeInfoWithStorage[127.0.0.1:37920,DS-5e8e1281-0aa4-404e-b156-5b14f66d32af,DISK], DatanodeInfoWithStorage[127.0.0.1:39151,DS-c2fc6acd-c94c-47c0-819f-a5362e1ea707,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1066313522-172.17.0.3-1597480516131:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45428,DS-d46ef782-de43-4205-983b-d0f118d2be64,DISK], DatanodeInfoWithStorage[127.0.0.1:37495,DS-07baf70f-0c5f-4d7e-9ea8-c93ad364d49c,DISK], DatanodeInfoWithStorage[127.0.0.1:37630,DS-8ba1bfed-bbee-4ed3-beae-616b653f6f85,DISK], DatanodeInfoWithStorage[127.0.0.1:46339,DS-d7530001-8b96-494c-83a8-9cf553b559aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44385,DS-d2eb0099-0f93-4cf8-9920-54dd39e3193e,DISK], DatanodeInfoWithStorage[127.0.0.1:46633,DS-634bec1d-6483-4e09-9ee7-355a933a3efd,DISK], DatanodeInfoWithStorage[127.0.0.1:37920,DS-5e8e1281-0aa4-404e-b156-5b14f66d32af,DISK], DatanodeInfoWithStorage[127.0.0.1:39151,DS-c2fc6acd-c94c-47c0-819f-a5362e1ea707,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-799497587-172.17.0.3-1597480549128:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46798,DS-2c5c472a-9d37-405b-9134-7fe2c78b2bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:37639,DS-4b760fc5-05aa-4508-80b6-638f964a4bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:35515,DS-611329c2-6616-49e4-a35d-ff316fd14482,DISK], DatanodeInfoWithStorage[127.0.0.1:40926,DS-bf37d764-2690-4584-92d3-d8917490505d,DISK], DatanodeInfoWithStorage[127.0.0.1:33566,DS-f460e3c0-9db2-45eb-8047-0dab54f2c9ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38208,DS-cfb95ccd-d906-4ae6-98e6-22bed4bb6e69,DISK], DatanodeInfoWithStorage[127.0.0.1:33929,DS-457fb3d6-4aa3-4588-9daf-d9e02e108fab,DISK], DatanodeInfoWithStorage[127.0.0.1:38904,DS-3f5f0974-dcbd-450a-80aa-eb81b680b2dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-799497587-172.17.0.3-1597480549128:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46798,DS-2c5c472a-9d37-405b-9134-7fe2c78b2bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:37639,DS-4b760fc5-05aa-4508-80b6-638f964a4bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:35515,DS-611329c2-6616-49e4-a35d-ff316fd14482,DISK], DatanodeInfoWithStorage[127.0.0.1:40926,DS-bf37d764-2690-4584-92d3-d8917490505d,DISK], DatanodeInfoWithStorage[127.0.0.1:33566,DS-f460e3c0-9db2-45eb-8047-0dab54f2c9ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38208,DS-cfb95ccd-d906-4ae6-98e6-22bed4bb6e69,DISK], DatanodeInfoWithStorage[127.0.0.1:33929,DS-457fb3d6-4aa3-4588-9daf-d9e02e108fab,DISK], DatanodeInfoWithStorage[127.0.0.1:38904,DS-3f5f0974-dcbd-450a-80aa-eb81b680b2dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1170446716-172.17.0.3-1597480932147:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33123,DS-884de5bb-a9d6-4405-879f-a0063069021d,DISK], DatanodeInfoWithStorage[127.0.0.1:39272,DS-cd7d49e8-e598-4b27-aae2-4c25d9c035a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33411,DS-c2fcaaa9-7118-4044-a509-901cf87428dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41395,DS-4bf61452-9990-4081-90ec-afdc74f0b1ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37476,DS-1e239271-de5b-4a73-bf8d-f544e9ad66c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38132,DS-3ff13c58-7eb2-4d5f-a952-62105c44f8ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33376,DS-86785439-90ba-446e-8a70-c5a204632097,DISK], DatanodeInfoWithStorage[127.0.0.1:41783,DS-212b8c9d-0577-4ef2-a405-528c03f0933a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1170446716-172.17.0.3-1597480932147:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33123,DS-884de5bb-a9d6-4405-879f-a0063069021d,DISK], DatanodeInfoWithStorage[127.0.0.1:39272,DS-cd7d49e8-e598-4b27-aae2-4c25d9c035a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33411,DS-c2fcaaa9-7118-4044-a509-901cf87428dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41395,DS-4bf61452-9990-4081-90ec-afdc74f0b1ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37476,DS-1e239271-de5b-4a73-bf8d-f544e9ad66c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38132,DS-3ff13c58-7eb2-4d5f-a952-62105c44f8ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33376,DS-86785439-90ba-446e-8a70-c5a204632097,DISK], DatanodeInfoWithStorage[127.0.0.1:41783,DS-212b8c9d-0577-4ef2-a405-528c03f0933a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1405647141-172.17.0.3-1597481142753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37540,DS-d2c416e3-8736-4c1a-83a9-1181aac0451a,DISK], DatanodeInfoWithStorage[127.0.0.1:34312,DS-b9f080cf-cc5e-4c28-bab2-fbace749eefe,DISK], DatanodeInfoWithStorage[127.0.0.1:42895,DS-4c8a86fa-0471-4b35-b38c-36236ce63211,DISK], DatanodeInfoWithStorage[127.0.0.1:46339,DS-3674c028-bf7d-4256-810f-c373d00187fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35382,DS-e27d48a8-37c4-4b5a-a583-762b0e4537ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44722,DS-0d98ddd6-86e3-4ff7-a3c3-e872130ad968,DISK], DatanodeInfoWithStorage[127.0.0.1:44393,DS-24afea1f-bdb6-4aac-8468-4d89b31b62a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37944,DS-47230744-1153-4f46-b1b5-016daf859d88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1405647141-172.17.0.3-1597481142753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37540,DS-d2c416e3-8736-4c1a-83a9-1181aac0451a,DISK], DatanodeInfoWithStorage[127.0.0.1:34312,DS-b9f080cf-cc5e-4c28-bab2-fbace749eefe,DISK], DatanodeInfoWithStorage[127.0.0.1:42895,DS-4c8a86fa-0471-4b35-b38c-36236ce63211,DISK], DatanodeInfoWithStorage[127.0.0.1:46339,DS-3674c028-bf7d-4256-810f-c373d00187fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35382,DS-e27d48a8-37c4-4b5a-a583-762b0e4537ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44722,DS-0d98ddd6-86e3-4ff7-a3c3-e872130ad968,DISK], DatanodeInfoWithStorage[127.0.0.1:44393,DS-24afea1f-bdb6-4aac-8468-4d89b31b62a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37944,DS-47230744-1153-4f46-b1b5-016daf859d88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-226988849-172.17.0.3-1597481660073:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41461,DS-5363c21a-a706-4778-81f3-d79d59d0587d,DISK], DatanodeInfoWithStorage[127.0.0.1:45708,DS-041c1764-b1c5-4804-b16b-f5f8d26802f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41936,DS-7a3bba86-bd57-4c3c-833d-75dd5cf2b77b,DISK], DatanodeInfoWithStorage[127.0.0.1:34287,DS-7034aeee-580f-487a-9b24-e631c70fa72a,DISK], DatanodeInfoWithStorage[127.0.0.1:42826,DS-d0c2b492-ce7c-4015-b0a8-ef9dd8b85c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:37336,DS-acc32b6c-7c12-4680-a895-bb9c3e8d4dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:35455,DS-dcf29d6d-85c1-4f9d-9127-de2f9ee9522c,DISK], DatanodeInfoWithStorage[127.0.0.1:39594,DS-796335b6-3f29-49e6-bca0-e0fa04307b34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-226988849-172.17.0.3-1597481660073:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41461,DS-5363c21a-a706-4778-81f3-d79d59d0587d,DISK], DatanodeInfoWithStorage[127.0.0.1:45708,DS-041c1764-b1c5-4804-b16b-f5f8d26802f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41936,DS-7a3bba86-bd57-4c3c-833d-75dd5cf2b77b,DISK], DatanodeInfoWithStorage[127.0.0.1:34287,DS-7034aeee-580f-487a-9b24-e631c70fa72a,DISK], DatanodeInfoWithStorage[127.0.0.1:42826,DS-d0c2b492-ce7c-4015-b0a8-ef9dd8b85c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:37336,DS-acc32b6c-7c12-4680-a895-bb9c3e8d4dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:35455,DS-dcf29d6d-85c1-4f9d-9127-de2f9ee9522c,DISK], DatanodeInfoWithStorage[127.0.0.1:39594,DS-796335b6-3f29-49e6-bca0-e0fa04307b34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1819430251-172.17.0.3-1597481831751:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37544,DS-2561d751-86c0-4b80-bc79-9a2814a29e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:37982,DS-3cb7101b-e6fc-4eac-b4e4-8ebfd21b167a,DISK], DatanodeInfoWithStorage[127.0.0.1:36498,DS-b5c354d9-422c-40b6-80f2-68a8a13fd178,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-23f545f2-37d0-4d7e-9f79-3e7fe1fe50c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33638,DS-3b642dc2-77a6-4130-b481-f6d7f6f523bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40857,DS-5bb98aca-16b4-469a-b9f8-98fe61c134d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38143,DS-66259462-7fca-4d2f-b417-1d128b561834,DISK], DatanodeInfoWithStorage[127.0.0.1:40407,DS-4898d472-7dae-42b3-b117-41b7c64b55ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1819430251-172.17.0.3-1597481831751:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37544,DS-2561d751-86c0-4b80-bc79-9a2814a29e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:37982,DS-3cb7101b-e6fc-4eac-b4e4-8ebfd21b167a,DISK], DatanodeInfoWithStorage[127.0.0.1:36498,DS-b5c354d9-422c-40b6-80f2-68a8a13fd178,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-23f545f2-37d0-4d7e-9f79-3e7fe1fe50c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33638,DS-3b642dc2-77a6-4130-b481-f6d7f6f523bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40857,DS-5bb98aca-16b4-469a-b9f8-98fe61c134d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38143,DS-66259462-7fca-4d2f-b417-1d128b561834,DISK], DatanodeInfoWithStorage[127.0.0.1:40407,DS-4898d472-7dae-42b3-b117-41b7c64b55ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1784014271-172.17.0.3-1597482088978:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37847,DS-7c599445-6f5a-4cd3-8ca9-efb1723df83b,DISK], DatanodeInfoWithStorage[127.0.0.1:35101,DS-9f6c7d89-ebd8-4f7a-a2da-d7805fd0ac96,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-ae24a6f0-279d-4ab7-ae1f-745ced21ceff,DISK], DatanodeInfoWithStorage[127.0.0.1:42518,DS-1ecdfe84-4cb4-4dae-9a86-e0d743bca2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40875,DS-6be186ea-5767-4f50-82c5-b4ba3b603b68,DISK], DatanodeInfoWithStorage[127.0.0.1:36361,DS-47eb00d3-fd6f-4c1d-af8e-5908088518d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45621,DS-6024a8f3-c784-4b13-b19c-1a3f85715e82,DISK], DatanodeInfoWithStorage[127.0.0.1:36422,DS-9802d690-b327-44e8-ad26-a785cfe57625,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1784014271-172.17.0.3-1597482088978:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37847,DS-7c599445-6f5a-4cd3-8ca9-efb1723df83b,DISK], DatanodeInfoWithStorage[127.0.0.1:35101,DS-9f6c7d89-ebd8-4f7a-a2da-d7805fd0ac96,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-ae24a6f0-279d-4ab7-ae1f-745ced21ceff,DISK], DatanodeInfoWithStorage[127.0.0.1:42518,DS-1ecdfe84-4cb4-4dae-9a86-e0d743bca2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40875,DS-6be186ea-5767-4f50-82c5-b4ba3b603b68,DISK], DatanodeInfoWithStorage[127.0.0.1:36361,DS-47eb00d3-fd6f-4c1d-af8e-5908088518d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45621,DS-6024a8f3-c784-4b13-b19c-1a3f85715e82,DISK], DatanodeInfoWithStorage[127.0.0.1:36422,DS-9802d690-b327-44e8-ad26-a785cfe57625,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1442469556-172.17.0.3-1597482160867:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33672,DS-a4cbef6f-2469-4a47-92ba-399cd43a8a05,DISK], DatanodeInfoWithStorage[127.0.0.1:46333,DS-9a48b52a-f346-4c5e-9420-081d44da7478,DISK], DatanodeInfoWithStorage[127.0.0.1:34536,DS-ce297a03-3f76-40d0-a221-8ff110180679,DISK], DatanodeInfoWithStorage[127.0.0.1:43926,DS-0d9dd3cc-9652-4cfb-ad6a-47fe852ff3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38966,DS-108b1f90-b080-477b-a8d0-8448388f5f19,DISK], DatanodeInfoWithStorage[127.0.0.1:37579,DS-e87ea296-3beb-43a9-87a5-c69c7260fff5,DISK], DatanodeInfoWithStorage[127.0.0.1:39627,DS-512ee470-3463-4427-a560-0e8f665b5e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42155,DS-ebc6b8a1-09bf-47ff-b561-43bf9eec18aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1442469556-172.17.0.3-1597482160867:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33672,DS-a4cbef6f-2469-4a47-92ba-399cd43a8a05,DISK], DatanodeInfoWithStorage[127.0.0.1:46333,DS-9a48b52a-f346-4c5e-9420-081d44da7478,DISK], DatanodeInfoWithStorage[127.0.0.1:34536,DS-ce297a03-3f76-40d0-a221-8ff110180679,DISK], DatanodeInfoWithStorage[127.0.0.1:43926,DS-0d9dd3cc-9652-4cfb-ad6a-47fe852ff3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38966,DS-108b1f90-b080-477b-a8d0-8448388f5f19,DISK], DatanodeInfoWithStorage[127.0.0.1:37579,DS-e87ea296-3beb-43a9-87a5-c69c7260fff5,DISK], DatanodeInfoWithStorage[127.0.0.1:39627,DS-512ee470-3463-4427-a560-0e8f665b5e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42155,DS-ebc6b8a1-09bf-47ff-b561-43bf9eec18aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-690438588-172.17.0.3-1597482240338:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35226,DS-30c4ed41-ada2-4458-8625-418cf02d6e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:34672,DS-85d984ec-6641-42dd-beed-01af279aca40,DISK], DatanodeInfoWithStorage[127.0.0.1:40609,DS-cc1445f9-ffa5-47bb-9363-b5fa1d8f4b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:38279,DS-187aa65f-4f64-4e26-aa15-04bae06a2865,DISK], DatanodeInfoWithStorage[127.0.0.1:37883,DS-60759baa-b6bf-47c1-b199-3b997d256657,DISK], DatanodeInfoWithStorage[127.0.0.1:45079,DS-16ba5684-dfaa-47d4-9556-c95e42ad59d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37692,DS-fa9ab9d2-6251-4143-8fd2-fcae23f02778,DISK], DatanodeInfoWithStorage[127.0.0.1:46622,DS-13a225d0-d56f-4a7d-824a-2eb0e5e838fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-690438588-172.17.0.3-1597482240338:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35226,DS-30c4ed41-ada2-4458-8625-418cf02d6e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:34672,DS-85d984ec-6641-42dd-beed-01af279aca40,DISK], DatanodeInfoWithStorage[127.0.0.1:40609,DS-cc1445f9-ffa5-47bb-9363-b5fa1d8f4b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:38279,DS-187aa65f-4f64-4e26-aa15-04bae06a2865,DISK], DatanodeInfoWithStorage[127.0.0.1:37883,DS-60759baa-b6bf-47c1-b199-3b997d256657,DISK], DatanodeInfoWithStorage[127.0.0.1:45079,DS-16ba5684-dfaa-47d4-9556-c95e42ad59d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37692,DS-fa9ab9d2-6251-4143-8fd2-fcae23f02778,DISK], DatanodeInfoWithStorage[127.0.0.1:46622,DS-13a225d0-d56f-4a7d-824a-2eb0e5e838fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-424405444-172.17.0.3-1597482517756:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34829,DS-c2dc0c20-cfe1-4049-9862-14d23c4f67ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33918,DS-4def2a9d-4b32-43b4-9278-99f8974b2c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42086,DS-053fb2d0-8cbb-461a-bf45-b9611278cc11,DISK], DatanodeInfoWithStorage[127.0.0.1:41276,DS-f895e057-ba89-4624-b2ad-af7bb9eb73d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39084,DS-167ffb49-981f-4e43-b802-11259f79ff09,DISK], DatanodeInfoWithStorage[127.0.0.1:36483,DS-570ee166-88aa-4110-8f65-9c247cb0896f,DISK], DatanodeInfoWithStorage[127.0.0.1:38039,DS-cc60fbe5-fc83-442b-8ca1-fa48c87baf10,DISK], DatanodeInfoWithStorage[127.0.0.1:34233,DS-5676b470-15aa-4cff-bde0-0725bfc422db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-424405444-172.17.0.3-1597482517756:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34829,DS-c2dc0c20-cfe1-4049-9862-14d23c4f67ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33918,DS-4def2a9d-4b32-43b4-9278-99f8974b2c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42086,DS-053fb2d0-8cbb-461a-bf45-b9611278cc11,DISK], DatanodeInfoWithStorage[127.0.0.1:41276,DS-f895e057-ba89-4624-b2ad-af7bb9eb73d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39084,DS-167ffb49-981f-4e43-b802-11259f79ff09,DISK], DatanodeInfoWithStorage[127.0.0.1:36483,DS-570ee166-88aa-4110-8f65-9c247cb0896f,DISK], DatanodeInfoWithStorage[127.0.0.1:38039,DS-cc60fbe5-fc83-442b-8ca1-fa48c87baf10,DISK], DatanodeInfoWithStorage[127.0.0.1:34233,DS-5676b470-15aa-4cff-bde0-0725bfc422db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1063222984-172.17.0.3-1597482946750:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44088,DS-2c3f1acc-689d-4aef-bdc3-9a786d995850,DISK], DatanodeInfoWithStorage[127.0.0.1:43873,DS-c2546657-423c-4688-a60d-12bb256c3290,DISK], DatanodeInfoWithStorage[127.0.0.1:36369,DS-8c1d3f65-6b50-44e9-b236-4d02406d19f7,DISK], DatanodeInfoWithStorage[127.0.0.1:46386,DS-5c277418-69f1-4712-8baa-841b78d3c45d,DISK], DatanodeInfoWithStorage[127.0.0.1:46062,DS-56782895-fdd9-43ca-be90-388d3054d3a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33889,DS-83c804c2-9a53-421d-b20a-3b984b1cbd35,DISK], DatanodeInfoWithStorage[127.0.0.1:38104,DS-fa60f559-b88c-4da9-b7a3-c5d4db0f49be,DISK], DatanodeInfoWithStorage[127.0.0.1:41906,DS-b3becf50-c976-4e4f-9bb3-28c0148f7142,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1063222984-172.17.0.3-1597482946750:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44088,DS-2c3f1acc-689d-4aef-bdc3-9a786d995850,DISK], DatanodeInfoWithStorage[127.0.0.1:43873,DS-c2546657-423c-4688-a60d-12bb256c3290,DISK], DatanodeInfoWithStorage[127.0.0.1:36369,DS-8c1d3f65-6b50-44e9-b236-4d02406d19f7,DISK], DatanodeInfoWithStorage[127.0.0.1:46386,DS-5c277418-69f1-4712-8baa-841b78d3c45d,DISK], DatanodeInfoWithStorage[127.0.0.1:46062,DS-56782895-fdd9-43ca-be90-388d3054d3a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33889,DS-83c804c2-9a53-421d-b20a-3b984b1cbd35,DISK], DatanodeInfoWithStorage[127.0.0.1:38104,DS-fa60f559-b88c-4da9-b7a3-c5d4db0f49be,DISK], DatanodeInfoWithStorage[127.0.0.1:41906,DS-b3becf50-c976-4e4f-9bb3-28c0148f7142,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-688876987-172.17.0.3-1597482989499:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39804,DS-c33db232-ad7d-4d6e-b93d-f7c889626e43,DISK], DatanodeInfoWithStorage[127.0.0.1:37652,DS-fb7c1ecc-6a6c-46cd-bca2-c6bfec9448d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38902,DS-e4bdd28f-4501-4f96-8cc9-d85717d6fc5d,DISK], DatanodeInfoWithStorage[127.0.0.1:46716,DS-f424101b-c04f-46ba-b9ab-4375188c4f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:41778,DS-5165045a-9f3d-4486-947b-ca2ff239057f,DISK], DatanodeInfoWithStorage[127.0.0.1:32995,DS-3198cac8-0d07-46d4-92c3-e4de6f11c4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33037,DS-81df8055-968d-450e-9927-4d4586fa19ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38090,DS-a5f47c9e-945b-4dc9-800e-65ec590ba275,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-688876987-172.17.0.3-1597482989499:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39804,DS-c33db232-ad7d-4d6e-b93d-f7c889626e43,DISK], DatanodeInfoWithStorage[127.0.0.1:37652,DS-fb7c1ecc-6a6c-46cd-bca2-c6bfec9448d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38902,DS-e4bdd28f-4501-4f96-8cc9-d85717d6fc5d,DISK], DatanodeInfoWithStorage[127.0.0.1:46716,DS-f424101b-c04f-46ba-b9ab-4375188c4f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:41778,DS-5165045a-9f3d-4486-947b-ca2ff239057f,DISK], DatanodeInfoWithStorage[127.0.0.1:32995,DS-3198cac8-0d07-46d4-92c3-e4de6f11c4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33037,DS-81df8055-968d-450e-9927-4d4586fa19ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38090,DS-a5f47c9e-945b-4dc9-800e-65ec590ba275,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2093753937-172.17.0.3-1597483144159:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41149,DS-7c953d62-81f9-4a8d-8668-59d60f9b2884,DISK], DatanodeInfoWithStorage[127.0.0.1:37676,DS-1e91312f-ee2c-42a0-a424-5d8a1bcec69b,DISK], DatanodeInfoWithStorage[127.0.0.1:42415,DS-25b1e028-8b29-4605-8f59-88d1e471c98d,DISK], DatanodeInfoWithStorage[127.0.0.1:40528,DS-1dba9610-be03-4d55-9961-926a81ba7f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:43358,DS-4ee15d98-25d9-4f05-9b44-e0a32c59bde3,DISK], DatanodeInfoWithStorage[127.0.0.1:41497,DS-d5cdbff5-c0c6-49e3-ae78-c2fd3a119808,DISK], DatanodeInfoWithStorage[127.0.0.1:44978,DS-c524994b-86e6-484d-bafc-156719fbeadc,DISK], DatanodeInfoWithStorage[127.0.0.1:33915,DS-f7eeb626-f66a-4366-bbfb-eaff8e6c022c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2093753937-172.17.0.3-1597483144159:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41149,DS-7c953d62-81f9-4a8d-8668-59d60f9b2884,DISK], DatanodeInfoWithStorage[127.0.0.1:37676,DS-1e91312f-ee2c-42a0-a424-5d8a1bcec69b,DISK], DatanodeInfoWithStorage[127.0.0.1:42415,DS-25b1e028-8b29-4605-8f59-88d1e471c98d,DISK], DatanodeInfoWithStorage[127.0.0.1:40528,DS-1dba9610-be03-4d55-9961-926a81ba7f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:43358,DS-4ee15d98-25d9-4f05-9b44-e0a32c59bde3,DISK], DatanodeInfoWithStorage[127.0.0.1:41497,DS-d5cdbff5-c0c6-49e3-ae78-c2fd3a119808,DISK], DatanodeInfoWithStorage[127.0.0.1:44978,DS-c524994b-86e6-484d-bafc-156719fbeadc,DISK], DatanodeInfoWithStorage[127.0.0.1:33915,DS-f7eeb626-f66a-4366-bbfb-eaff8e6c022c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-910619410-172.17.0.3-1597483296646:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46743,DS-28f4f1f3-4ab6-4f47-837b-c9c23f4f6b95,DISK], DatanodeInfoWithStorage[127.0.0.1:37959,DS-d4eea6b8-bde1-4c42-878a-fc0d4bda795b,DISK], DatanodeInfoWithStorage[127.0.0.1:40276,DS-86f6db09-1fac-4011-a4c0-5577bc6fc47f,DISK], DatanodeInfoWithStorage[127.0.0.1:43855,DS-139921c4-8519-4942-bf87-e3a67c43d717,DISK], DatanodeInfoWithStorage[127.0.0.1:43561,DS-5e3190da-51db-499d-a0ed-b2b18e8827aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43594,DS-ea6e2d9e-e856-42c2-85f7-b1f3fac65ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:36648,DS-827d9658-9980-46a7-9aa8-620709ff424d,DISK], DatanodeInfoWithStorage[127.0.0.1:33214,DS-7aff7a22-ee6a-467f-a0c6-c1010461ea9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-910619410-172.17.0.3-1597483296646:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46743,DS-28f4f1f3-4ab6-4f47-837b-c9c23f4f6b95,DISK], DatanodeInfoWithStorage[127.0.0.1:37959,DS-d4eea6b8-bde1-4c42-878a-fc0d4bda795b,DISK], DatanodeInfoWithStorage[127.0.0.1:40276,DS-86f6db09-1fac-4011-a4c0-5577bc6fc47f,DISK], DatanodeInfoWithStorage[127.0.0.1:43855,DS-139921c4-8519-4942-bf87-e3a67c43d717,DISK], DatanodeInfoWithStorage[127.0.0.1:43561,DS-5e3190da-51db-499d-a0ed-b2b18e8827aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43594,DS-ea6e2d9e-e856-42c2-85f7-b1f3fac65ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:36648,DS-827d9658-9980-46a7-9aa8-620709ff424d,DISK], DatanodeInfoWithStorage[127.0.0.1:33214,DS-7aff7a22-ee6a-467f-a0c6-c1010461ea9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1403932067-172.17.0.3-1597483411261:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45408,DS-244b03d1-0927-412d-9090-e39bbb2e7b90,DISK], DatanodeInfoWithStorage[127.0.0.1:38890,DS-276c063c-2978-4919-9fd0-eff51bdc60ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34301,DS-221ea9e7-80ec-4a4f-b657-125c02540fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:41979,DS-1573e15b-6b81-4847-83d7-cdd4ae1847cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42402,DS-e539d88d-09cf-4dd3-b959-383e27ad05a4,DISK], DatanodeInfoWithStorage[127.0.0.1:46687,DS-c8b039af-7b7f-407d-b9cc-8acda081daef,DISK], DatanodeInfoWithStorage[127.0.0.1:44017,DS-ff2402c5-758c-4749-9e9c-85e96aa1c494,DISK], DatanodeInfoWithStorage[127.0.0.1:46377,DS-83e6801a-8f7e-4714-987c-e76979531d32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1403932067-172.17.0.3-1597483411261:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45408,DS-244b03d1-0927-412d-9090-e39bbb2e7b90,DISK], DatanodeInfoWithStorage[127.0.0.1:38890,DS-276c063c-2978-4919-9fd0-eff51bdc60ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34301,DS-221ea9e7-80ec-4a4f-b657-125c02540fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:41979,DS-1573e15b-6b81-4847-83d7-cdd4ae1847cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42402,DS-e539d88d-09cf-4dd3-b959-383e27ad05a4,DISK], DatanodeInfoWithStorage[127.0.0.1:46687,DS-c8b039af-7b7f-407d-b9cc-8acda081daef,DISK], DatanodeInfoWithStorage[127.0.0.1:44017,DS-ff2402c5-758c-4749-9e9c-85e96aa1c494,DISK], DatanodeInfoWithStorage[127.0.0.1:46377,DS-83e6801a-8f7e-4714-987c-e76979531d32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-478481521-172.17.0.3-1597483715631:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45488,DS-8e7d4469-0f4c-4ca3-a82c-5d31a7a474e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40030,DS-d6c7d34e-27c8-40c1-9778-54becfa253e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39511,DS-248167e3-40bc-4ac1-b926-858cf73583e1,DISK], DatanodeInfoWithStorage[127.0.0.1:32834,DS-bb063f64-2e1f-4429-9639-d214e064c46d,DISK], DatanodeInfoWithStorage[127.0.0.1:41851,DS-b1030f8e-25de-4159-810a-42c61b306b28,DISK], DatanodeInfoWithStorage[127.0.0.1:32857,DS-c88ac465-e2b0-4060-9a7d-af44e44e60c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41809,DS-f61420f0-026e-4b62-9f3a-3be5553c3a97,DISK], DatanodeInfoWithStorage[127.0.0.1:46215,DS-dee84135-7bdc-411c-854a-fdca83a8f89f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-478481521-172.17.0.3-1597483715631:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45488,DS-8e7d4469-0f4c-4ca3-a82c-5d31a7a474e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40030,DS-d6c7d34e-27c8-40c1-9778-54becfa253e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39511,DS-248167e3-40bc-4ac1-b926-858cf73583e1,DISK], DatanodeInfoWithStorage[127.0.0.1:32834,DS-bb063f64-2e1f-4429-9639-d214e064c46d,DISK], DatanodeInfoWithStorage[127.0.0.1:41851,DS-b1030f8e-25de-4159-810a-42c61b306b28,DISK], DatanodeInfoWithStorage[127.0.0.1:32857,DS-c88ac465-e2b0-4060-9a7d-af44e44e60c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41809,DS-f61420f0-026e-4b62-9f3a-3be5553c3a97,DISK], DatanodeInfoWithStorage[127.0.0.1:46215,DS-dee84135-7bdc-411c-854a-fdca83a8f89f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1096295673-172.17.0.3-1597485077977:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41186,DS-0896528c-5fca-404b-a14c-66760d6143ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38575,DS-6ed8e856-4930-4f72-8976-57f57d718f01,DISK], DatanodeInfoWithStorage[127.0.0.1:46378,DS-fba00975-fb8f-4e96-bf78-d5129a9c94c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37607,DS-595cdb22-16c9-4880-8233-532a5434ae78,DISK], DatanodeInfoWithStorage[127.0.0.1:33804,DS-3c413fca-73e8-4ffc-9e82-25cb67c4476d,DISK], DatanodeInfoWithStorage[127.0.0.1:39799,DS-2a34a9cc-2424-4156-8783-39682653d2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35770,DS-eeb9b0bc-1678-4a9b-be60-1f7c6b92aed0,DISK], DatanodeInfoWithStorage[127.0.0.1:38865,DS-796acd2a-74d6-42af-a96e-d44f20460e13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1096295673-172.17.0.3-1597485077977:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41186,DS-0896528c-5fca-404b-a14c-66760d6143ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38575,DS-6ed8e856-4930-4f72-8976-57f57d718f01,DISK], DatanodeInfoWithStorage[127.0.0.1:46378,DS-fba00975-fb8f-4e96-bf78-d5129a9c94c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37607,DS-595cdb22-16c9-4880-8233-532a5434ae78,DISK], DatanodeInfoWithStorage[127.0.0.1:33804,DS-3c413fca-73e8-4ffc-9e82-25cb67c4476d,DISK], DatanodeInfoWithStorage[127.0.0.1:39799,DS-2a34a9cc-2424-4156-8783-39682653d2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35770,DS-eeb9b0bc-1678-4a9b-be60-1f7c6b92aed0,DISK], DatanodeInfoWithStorage[127.0.0.1:38865,DS-796acd2a-74d6-42af-a96e-d44f20460e13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-727487872-172.17.0.3-1597485637682:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39327,DS-67efbb43-0f4d-44df-a752-ef074fdfeaa2,DISK], DatanodeInfoWithStorage[127.0.0.1:46570,DS-3ff5b2e1-ebd5-4f28-b23b-ad2fcf3670d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42777,DS-18559a5b-3da7-4fab-8cd6-e5091aa23202,DISK], DatanodeInfoWithStorage[127.0.0.1:42415,DS-af69f6a1-b9a4-4835-8d40-486709b7fddc,DISK], DatanodeInfoWithStorage[127.0.0.1:35678,DS-77004954-97b5-46da-8fd6-7d0898fc71bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44245,DS-4111c579-4d66-40bc-bf6e-febc5f095925,DISK], DatanodeInfoWithStorage[127.0.0.1:38780,DS-c2215bc1-b46d-4ea4-8720-074c26776d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:43399,DS-2e6a3351-3c72-4452-b1ae-65863fb4718a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-727487872-172.17.0.3-1597485637682:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39327,DS-67efbb43-0f4d-44df-a752-ef074fdfeaa2,DISK], DatanodeInfoWithStorage[127.0.0.1:46570,DS-3ff5b2e1-ebd5-4f28-b23b-ad2fcf3670d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42777,DS-18559a5b-3da7-4fab-8cd6-e5091aa23202,DISK], DatanodeInfoWithStorage[127.0.0.1:42415,DS-af69f6a1-b9a4-4835-8d40-486709b7fddc,DISK], DatanodeInfoWithStorage[127.0.0.1:35678,DS-77004954-97b5-46da-8fd6-7d0898fc71bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44245,DS-4111c579-4d66-40bc-bf6e-febc5f095925,DISK], DatanodeInfoWithStorage[127.0.0.1:38780,DS-c2215bc1-b46d-4ea4-8720-074c26776d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:43399,DS-2e6a3351-3c72-4452-b1ae-65863fb4718a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-283705238-172.17.0.3-1597485908638:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42218,DS-21cc19f5-0529-4278-8c52-2d157e5cb0b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40900,DS-1610c224-1bc9-4e41-9334-d435743039cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43330,DS-6a51aeb8-945b-4754-a76d-9fe2f04c53c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35571,DS-685acf5a-c2bb-4766-82fd-0ac5d02541e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44245,DS-dd18bdcb-167b-4408-9aec-ec2c87314342,DISK], DatanodeInfoWithStorage[127.0.0.1:43074,DS-04883d41-84d3-443b-90ed-221bf61375d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37834,DS-36f66310-8221-494c-958f-fefd44ddfb6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34809,DS-ddc040fc-c0f7-412c-81f9-c9a98ebaa95e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-283705238-172.17.0.3-1597485908638:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42218,DS-21cc19f5-0529-4278-8c52-2d157e5cb0b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40900,DS-1610c224-1bc9-4e41-9334-d435743039cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43330,DS-6a51aeb8-945b-4754-a76d-9fe2f04c53c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35571,DS-685acf5a-c2bb-4766-82fd-0ac5d02541e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44245,DS-dd18bdcb-167b-4408-9aec-ec2c87314342,DISK], DatanodeInfoWithStorage[127.0.0.1:43074,DS-04883d41-84d3-443b-90ed-221bf61375d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37834,DS-36f66310-8221-494c-958f-fefd44ddfb6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34809,DS-ddc040fc-c0f7-412c-81f9-c9a98ebaa95e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5690
