reconf_parameter: dfs.namenode.blocks.per.postponedblocks.rescan
component: hdfs:NameNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blocks.per.postponedblocks.rescan
component: hdfs:NameNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-434835753-172.17.0.11-1597396835621:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44581,DS-7c8359a9-8906-40ef-ae87-4a6f626f74e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45959,DS-0a1b051f-7758-45b2-b335-e4be6e93a82d,DISK], DatanodeInfoWithStorage[127.0.0.1:36336,DS-0765b11b-7fb9-497f-b81b-9f0326fd268d,DISK], DatanodeInfoWithStorage[127.0.0.1:43432,DS-fdefdb98-e17e-4e41-929d-27b3343e02a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40947,DS-6427e667-5ac6-495f-aad7-f705dbe26e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40596,DS-565971d7-c9ea-45e4-88c7-7009ab7d975e,DISK], DatanodeInfoWithStorage[127.0.0.1:40903,DS-d934bbf6-9889-438c-aa97-3710579ef9dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44915,DS-6772f60f-c7ef-4319-83ad-5c4432947248,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-434835753-172.17.0.11-1597396835621:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44581,DS-7c8359a9-8906-40ef-ae87-4a6f626f74e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45959,DS-0a1b051f-7758-45b2-b335-e4be6e93a82d,DISK], DatanodeInfoWithStorage[127.0.0.1:36336,DS-0765b11b-7fb9-497f-b81b-9f0326fd268d,DISK], DatanodeInfoWithStorage[127.0.0.1:43432,DS-fdefdb98-e17e-4e41-929d-27b3343e02a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40947,DS-6427e667-5ac6-495f-aad7-f705dbe26e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40596,DS-565971d7-c9ea-45e4-88c7-7009ab7d975e,DISK], DatanodeInfoWithStorage[127.0.0.1:40903,DS-d934bbf6-9889-438c-aa97-3710579ef9dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44915,DS-6772f60f-c7ef-4319-83ad-5c4432947248,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blocks.per.postponedblocks.rescan
component: hdfs:NameNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2040152946-172.17.0.11-1597397297922:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43483,DS-9612adf6-ac77-443d-8000-6185c483036e,DISK], DatanodeInfoWithStorage[127.0.0.1:40005,DS-a957ef8a-12f1-4250-b4c4-250b0193b175,DISK], DatanodeInfoWithStorage[127.0.0.1:33390,DS-648218e7-8383-4306-a71d-75603dd4d052,DISK], DatanodeInfoWithStorage[127.0.0.1:39787,DS-c85f667f-e78e-4615-86f4-5c6dda631dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:35272,DS-fe4d6b07-7c61-495e-adf5-d93c478e8212,DISK], DatanodeInfoWithStorage[127.0.0.1:44064,DS-e93953a5-5e05-43ad-8c8f-f170284754e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44991,DS-b4838412-21a5-49c6-80cd-bf3e1fce93cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35867,DS-57e12fc4-844c-4105-a15c-ff4ee44ecce7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2040152946-172.17.0.11-1597397297922:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43483,DS-9612adf6-ac77-443d-8000-6185c483036e,DISK], DatanodeInfoWithStorage[127.0.0.1:40005,DS-a957ef8a-12f1-4250-b4c4-250b0193b175,DISK], DatanodeInfoWithStorage[127.0.0.1:33390,DS-648218e7-8383-4306-a71d-75603dd4d052,DISK], DatanodeInfoWithStorage[127.0.0.1:39787,DS-c85f667f-e78e-4615-86f4-5c6dda631dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:35272,DS-fe4d6b07-7c61-495e-adf5-d93c478e8212,DISK], DatanodeInfoWithStorage[127.0.0.1:44064,DS-e93953a5-5e05-43ad-8c8f-f170284754e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44991,DS-b4838412-21a5-49c6-80cd-bf3e1fce93cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35867,DS-57e12fc4-844c-4105-a15c-ff4ee44ecce7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blocks.per.postponedblocks.rescan
component: hdfs:NameNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1478174875-172.17.0.11-1597397527213:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40458,DS-684041eb-c546-4d38-b266-8c1f577f36e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33637,DS-2f917790-71c9-470a-8429-942cd646d080,DISK], DatanodeInfoWithStorage[127.0.0.1:45716,DS-07217402-8333-425b-acd9-927237ea7957,DISK], DatanodeInfoWithStorage[127.0.0.1:35567,DS-cf5c7dc8-0ca9-42ca-b11c-3be7ea0a3a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:36520,DS-e48cae01-b60a-4e41-bdc3-6266952fa50e,DISK], DatanodeInfoWithStorage[127.0.0.1:40546,DS-b314b62c-a9b8-457e-8f54-78fb7f0035d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39951,DS-c8f1c1dd-ce8a-4e5f-ab7e-3a4921b71533,DISK], DatanodeInfoWithStorage[127.0.0.1:43165,DS-b3ac825d-a373-42c6-a12d-54baa3f3f10f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1478174875-172.17.0.11-1597397527213:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40458,DS-684041eb-c546-4d38-b266-8c1f577f36e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33637,DS-2f917790-71c9-470a-8429-942cd646d080,DISK], DatanodeInfoWithStorage[127.0.0.1:45716,DS-07217402-8333-425b-acd9-927237ea7957,DISK], DatanodeInfoWithStorage[127.0.0.1:35567,DS-cf5c7dc8-0ca9-42ca-b11c-3be7ea0a3a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:36520,DS-e48cae01-b60a-4e41-bdc3-6266952fa50e,DISK], DatanodeInfoWithStorage[127.0.0.1:40546,DS-b314b62c-a9b8-457e-8f54-78fb7f0035d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39951,DS-c8f1c1dd-ce8a-4e5f-ab7e-3a4921b71533,DISK], DatanodeInfoWithStorage[127.0.0.1:43165,DS-b3ac825d-a373-42c6-a12d-54baa3f3f10f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.blocks.per.postponedblocks.rescan
component: hdfs:NameNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-192639201-172.17.0.11-1597397933672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38675,DS-2480b1ac-2a5b-437d-8897-6ce385d27127,DISK], DatanodeInfoWithStorage[127.0.0.1:38629,DS-ef468f68-f6cf-4f26-812b-3bc2e20d0f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35442,DS-2bdc8072-e86e-4c4c-89ea-db8b9e0acef1,DISK], DatanodeInfoWithStorage[127.0.0.1:36699,DS-44181f47-caa5-4502-a532-2299810d4406,DISK], DatanodeInfoWithStorage[127.0.0.1:34692,DS-3bb06185-844c-40c3-a593-ee314ddff2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43804,DS-04da2b38-80d7-4e9b-a768-d885261706ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37110,DS-3c7fe6a9-7be7-455e-b49d-2269a6becbf3,DISK], DatanodeInfoWithStorage[127.0.0.1:38887,DS-c4c1aea0-7cca-41e8-a970-e6f45368088d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-192639201-172.17.0.11-1597397933672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38675,DS-2480b1ac-2a5b-437d-8897-6ce385d27127,DISK], DatanodeInfoWithStorage[127.0.0.1:38629,DS-ef468f68-f6cf-4f26-812b-3bc2e20d0f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35442,DS-2bdc8072-e86e-4c4c-89ea-db8b9e0acef1,DISK], DatanodeInfoWithStorage[127.0.0.1:36699,DS-44181f47-caa5-4502-a532-2299810d4406,DISK], DatanodeInfoWithStorage[127.0.0.1:34692,DS-3bb06185-844c-40c3-a593-ee314ddff2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43804,DS-04da2b38-80d7-4e9b-a768-d885261706ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37110,DS-3c7fe6a9-7be7-455e-b49d-2269a6becbf3,DISK], DatanodeInfoWithStorage[127.0.0.1:38887,DS-c4c1aea0-7cca-41e8-a970-e6f45368088d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blocks.per.postponedblocks.rescan
component: hdfs:NameNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1015343304-172.17.0.11-1597398204661:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36031,DS-4bcfb763-f744-489a-861e-3558e82cc3d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36030,DS-b8db8692-412b-4fdc-b3aa-a8f3b5e628aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41578,DS-282515de-5c2a-49ca-8650-4c2a7f3a9e12,DISK], DatanodeInfoWithStorage[127.0.0.1:33758,DS-19d15f79-a086-4f06-a8c8-8d1b18bc6643,DISK], DatanodeInfoWithStorage[127.0.0.1:42056,DS-4af257f9-f3af-4135-83e1-022955728c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36319,DS-c55ab9dc-2825-4c5b-9857-88f3934051a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38167,DS-12054585-944a-40ef-8a15-859f055f5e88,DISK], DatanodeInfoWithStorage[127.0.0.1:38990,DS-8a530062-1de6-4c58-845f-6353857ab796,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1015343304-172.17.0.11-1597398204661:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36031,DS-4bcfb763-f744-489a-861e-3558e82cc3d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36030,DS-b8db8692-412b-4fdc-b3aa-a8f3b5e628aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41578,DS-282515de-5c2a-49ca-8650-4c2a7f3a9e12,DISK], DatanodeInfoWithStorage[127.0.0.1:33758,DS-19d15f79-a086-4f06-a8c8-8d1b18bc6643,DISK], DatanodeInfoWithStorage[127.0.0.1:42056,DS-4af257f9-f3af-4135-83e1-022955728c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36319,DS-c55ab9dc-2825-4c5b-9857-88f3934051a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38167,DS-12054585-944a-40ef-8a15-859f055f5e88,DISK], DatanodeInfoWithStorage[127.0.0.1:38990,DS-8a530062-1de6-4c58-845f-6353857ab796,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.blocks.per.postponedblocks.rescan
component: hdfs:NameNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-92947291-172.17.0.11-1597398718116:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38474,DS-274e10f3-87f8-4654-9b03-124493b72390,DISK], DatanodeInfoWithStorage[127.0.0.1:32993,DS-3461def1-ab67-42e5-bf61-2873ed677631,DISK], DatanodeInfoWithStorage[127.0.0.1:41930,DS-5cf564f9-b7d0-48c2-b232-5d3da7bb1d92,DISK], DatanodeInfoWithStorage[127.0.0.1:42143,DS-1f79507b-61ac-4d6a-9484-ce2fff391949,DISK], DatanodeInfoWithStorage[127.0.0.1:34201,DS-6b1afccc-b90b-4f0e-bd5a-e2184d777b29,DISK], DatanodeInfoWithStorage[127.0.0.1:38373,DS-e1896f62-9cb5-4aa9-8fd2-3c289e2b12bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39183,DS-de36f176-fa8f-4f18-8f0d-63b5698eed8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40559,DS-4a5a22af-ada1-4526-8581-d1d2916dc4f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-92947291-172.17.0.11-1597398718116:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38474,DS-274e10f3-87f8-4654-9b03-124493b72390,DISK], DatanodeInfoWithStorage[127.0.0.1:32993,DS-3461def1-ab67-42e5-bf61-2873ed677631,DISK], DatanodeInfoWithStorage[127.0.0.1:41930,DS-5cf564f9-b7d0-48c2-b232-5d3da7bb1d92,DISK], DatanodeInfoWithStorage[127.0.0.1:42143,DS-1f79507b-61ac-4d6a-9484-ce2fff391949,DISK], DatanodeInfoWithStorage[127.0.0.1:34201,DS-6b1afccc-b90b-4f0e-bd5a-e2184d777b29,DISK], DatanodeInfoWithStorage[127.0.0.1:38373,DS-e1896f62-9cb5-4aa9-8fd2-3c289e2b12bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39183,DS-de36f176-fa8f-4f18-8f0d-63b5698eed8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40559,DS-4a5a22af-ada1-4526-8581-d1d2916dc4f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blocks.per.postponedblocks.rescan
component: hdfs:NameNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-129264583-172.17.0.11-1597398984144:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41396,DS-e0c628c2-5150-4ae0-a49c-cde3dfc28834,DISK], DatanodeInfoWithStorage[127.0.0.1:32944,DS-c3e6d0cd-65ec-4ea1-a137-cfd8a48d0f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37001,DS-d1b5c4f3-3bf6-4224-b889-794cf7a1cedc,DISK], DatanodeInfoWithStorage[127.0.0.1:45728,DS-c6eb619e-43ef-445f-b53a-0c201c33de10,DISK], DatanodeInfoWithStorage[127.0.0.1:37221,DS-e52611e6-02e5-4849-94bb-4e16ac31666d,DISK], DatanodeInfoWithStorage[127.0.0.1:46754,DS-953edf8f-463d-4682-ad13-127aa06d4ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:33951,DS-ff355f70-2a69-4e76-a613-9c962af0a083,DISK], DatanodeInfoWithStorage[127.0.0.1:38636,DS-8ebd292a-4863-42f5-b67f-61ca928696b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-129264583-172.17.0.11-1597398984144:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41396,DS-e0c628c2-5150-4ae0-a49c-cde3dfc28834,DISK], DatanodeInfoWithStorage[127.0.0.1:32944,DS-c3e6d0cd-65ec-4ea1-a137-cfd8a48d0f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37001,DS-d1b5c4f3-3bf6-4224-b889-794cf7a1cedc,DISK], DatanodeInfoWithStorage[127.0.0.1:45728,DS-c6eb619e-43ef-445f-b53a-0c201c33de10,DISK], DatanodeInfoWithStorage[127.0.0.1:37221,DS-e52611e6-02e5-4849-94bb-4e16ac31666d,DISK], DatanodeInfoWithStorage[127.0.0.1:46754,DS-953edf8f-463d-4682-ad13-127aa06d4ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:33951,DS-ff355f70-2a69-4e76-a613-9c962af0a083,DISK], DatanodeInfoWithStorage[127.0.0.1:38636,DS-8ebd292a-4863-42f5-b67f-61ca928696b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.blocks.per.postponedblocks.rescan
component: hdfs:NameNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1980565371-172.17.0.11-1597399030273:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39371,DS-4ae44376-e044-45ee-8f82-d9aabd9786f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39566,DS-3be8e51a-89cc-4d5f-ac87-7aa7b24593ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37619,DS-a11ec459-8792-40b6-be0a-f20bc9fd3275,DISK], DatanodeInfoWithStorage[127.0.0.1:46170,DS-2beebd39-bb0c-4692-9530-4cc84e2f7055,DISK], DatanodeInfoWithStorage[127.0.0.1:45880,DS-2003e895-0764-4bfa-a784-6c2d8fea0925,DISK], DatanodeInfoWithStorage[127.0.0.1:36928,DS-4500d17e-a27d-4cb1-930c-dd0f32473b30,DISK], DatanodeInfoWithStorage[127.0.0.1:35089,DS-f72b034e-27ea-45aa-87ad-1d2d2acbbe93,DISK], DatanodeInfoWithStorage[127.0.0.1:46120,DS-d37bc22a-13d4-4269-832b-a3ab9b164239,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1980565371-172.17.0.11-1597399030273:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39371,DS-4ae44376-e044-45ee-8f82-d9aabd9786f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39566,DS-3be8e51a-89cc-4d5f-ac87-7aa7b24593ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37619,DS-a11ec459-8792-40b6-be0a-f20bc9fd3275,DISK], DatanodeInfoWithStorage[127.0.0.1:46170,DS-2beebd39-bb0c-4692-9530-4cc84e2f7055,DISK], DatanodeInfoWithStorage[127.0.0.1:45880,DS-2003e895-0764-4bfa-a784-6c2d8fea0925,DISK], DatanodeInfoWithStorage[127.0.0.1:36928,DS-4500d17e-a27d-4cb1-930c-dd0f32473b30,DISK], DatanodeInfoWithStorage[127.0.0.1:35089,DS-f72b034e-27ea-45aa-87ad-1d2d2acbbe93,DISK], DatanodeInfoWithStorage[127.0.0.1:46120,DS-d37bc22a-13d4-4269-832b-a3ab9b164239,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.blocks.per.postponedblocks.rescan
component: hdfs:NameNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1086410333-172.17.0.11-1597399170072:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37854,DS-99588567-a382-4714-bc54-e751416b9c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:44668,DS-fb3051ec-bc89-4eee-873c-d9ca498b051d,DISK], DatanodeInfoWithStorage[127.0.0.1:34237,DS-14cc555d-5b4a-4c83-98e1-429d7c4ef9aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39446,DS-b8303dc3-1d90-4f33-bebe-d0f0a1957a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39560,DS-77e95fa0-1a2a-49e6-865b-c20b58671988,DISK], DatanodeInfoWithStorage[127.0.0.1:35747,DS-22e4a0aa-ec9f-4d98-ba0f-2b2c280fea08,DISK], DatanodeInfoWithStorage[127.0.0.1:38940,DS-4b1fc953-6dd6-4fb0-b593-e7109a930175,DISK], DatanodeInfoWithStorage[127.0.0.1:36590,DS-987bb029-82fc-4fcb-a467-a36b309c8ea2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1086410333-172.17.0.11-1597399170072:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37854,DS-99588567-a382-4714-bc54-e751416b9c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:44668,DS-fb3051ec-bc89-4eee-873c-d9ca498b051d,DISK], DatanodeInfoWithStorage[127.0.0.1:34237,DS-14cc555d-5b4a-4c83-98e1-429d7c4ef9aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39446,DS-b8303dc3-1d90-4f33-bebe-d0f0a1957a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39560,DS-77e95fa0-1a2a-49e6-865b-c20b58671988,DISK], DatanodeInfoWithStorage[127.0.0.1:35747,DS-22e4a0aa-ec9f-4d98-ba0f-2b2c280fea08,DISK], DatanodeInfoWithStorage[127.0.0.1:38940,DS-4b1fc953-6dd6-4fb0-b593-e7109a930175,DISK], DatanodeInfoWithStorage[127.0.0.1:36590,DS-987bb029-82fc-4fcb-a467-a36b309c8ea2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blocks.per.postponedblocks.rescan
component: hdfs:NameNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1629787178-172.17.0.11-1597399206599:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45347,DS-2fb7d722-2871-42d1-b59b-c6408a0a14ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34798,DS-6b8bfea6-1949-4649-9feb-dc2acc463b22,DISK], DatanodeInfoWithStorage[127.0.0.1:45276,DS-83603b07-cb41-419c-9583-1ae4ea21b852,DISK], DatanodeInfoWithStorage[127.0.0.1:44208,DS-d0629c03-31cb-422d-a5c4-88fcf66cbce7,DISK], DatanodeInfoWithStorage[127.0.0.1:39777,DS-c3554a4a-2fa7-41a3-adcf-0d52a4ec51af,DISK], DatanodeInfoWithStorage[127.0.0.1:33886,DS-8122a4c0-5c78-44e9-bb3d-06807d36df12,DISK], DatanodeInfoWithStorage[127.0.0.1:35181,DS-bd4fed83-d4d9-490a-b31b-0a2b2db56ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:33532,DS-e034aa18-0e2c-4dd1-9535-fa347e860f93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1629787178-172.17.0.11-1597399206599:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45347,DS-2fb7d722-2871-42d1-b59b-c6408a0a14ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34798,DS-6b8bfea6-1949-4649-9feb-dc2acc463b22,DISK], DatanodeInfoWithStorage[127.0.0.1:45276,DS-83603b07-cb41-419c-9583-1ae4ea21b852,DISK], DatanodeInfoWithStorage[127.0.0.1:44208,DS-d0629c03-31cb-422d-a5c4-88fcf66cbce7,DISK], DatanodeInfoWithStorage[127.0.0.1:39777,DS-c3554a4a-2fa7-41a3-adcf-0d52a4ec51af,DISK], DatanodeInfoWithStorage[127.0.0.1:33886,DS-8122a4c0-5c78-44e9-bb3d-06807d36df12,DISK], DatanodeInfoWithStorage[127.0.0.1:35181,DS-bd4fed83-d4d9-490a-b31b-0a2b2db56ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:33532,DS-e034aa18-0e2c-4dd1-9535-fa347e860f93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blocks.per.postponedblocks.rescan
component: hdfs:NameNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1983970844-172.17.0.11-1597399555291:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38988,DS-d912ae46-a12f-4d75-97ba-0d462641b058,DISK], DatanodeInfoWithStorage[127.0.0.1:39474,DS-76637c8e-a075-4646-9097-7e69683bf7fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39894,DS-d47fbd97-c265-437c-bb79-e9658db759ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39415,DS-714f6b5f-b052-4275-80b9-1fb678519e11,DISK], DatanodeInfoWithStorage[127.0.0.1:42635,DS-a50a2600-5b41-4e14-b754-b541ee367a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:41509,DS-ea8e91d0-d7b8-4c9d-a83f-6e499eedaa61,DISK], DatanodeInfoWithStorage[127.0.0.1:34163,DS-5fb0d0a8-3800-4be9-a00e-b4cdebb481b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41262,DS-187890cd-0a8b-41c7-8421-7b247b583691,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1983970844-172.17.0.11-1597399555291:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38988,DS-d912ae46-a12f-4d75-97ba-0d462641b058,DISK], DatanodeInfoWithStorage[127.0.0.1:39474,DS-76637c8e-a075-4646-9097-7e69683bf7fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39894,DS-d47fbd97-c265-437c-bb79-e9658db759ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39415,DS-714f6b5f-b052-4275-80b9-1fb678519e11,DISK], DatanodeInfoWithStorage[127.0.0.1:42635,DS-a50a2600-5b41-4e14-b754-b541ee367a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:41509,DS-ea8e91d0-d7b8-4c9d-a83f-6e499eedaa61,DISK], DatanodeInfoWithStorage[127.0.0.1:34163,DS-5fb0d0a8-3800-4be9-a00e-b4cdebb481b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41262,DS-187890cd-0a8b-41c7-8421-7b247b583691,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.blocks.per.postponedblocks.rescan
component: hdfs:NameNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-214500338-172.17.0.11-1597400054572:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32919,DS-f2528a13-876a-4481-9e14-5dd59d3d1971,DISK], DatanodeInfoWithStorage[127.0.0.1:40114,DS-90b5d6cc-ed8e-46be-9a23-a79030009cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:39732,DS-55e7c7d9-c838-46ff-9812-3d04e127b462,DISK], DatanodeInfoWithStorage[127.0.0.1:42503,DS-ac1623eb-2e07-4eb1-87cb-bce66275eba6,DISK], DatanodeInfoWithStorage[127.0.0.1:34079,DS-7b0fad3c-5b83-471b-bcbd-8de3a7b115e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39098,DS-ea434b2a-9b5b-4c19-b965-0fcfc65c54a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42011,DS-61b7f052-374b-4503-8dd8-dae3e991a561,DISK], DatanodeInfoWithStorage[127.0.0.1:45238,DS-775cd746-dbfc-4dd7-9970-a6c88c55041f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-214500338-172.17.0.11-1597400054572:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32919,DS-f2528a13-876a-4481-9e14-5dd59d3d1971,DISK], DatanodeInfoWithStorage[127.0.0.1:40114,DS-90b5d6cc-ed8e-46be-9a23-a79030009cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:39732,DS-55e7c7d9-c838-46ff-9812-3d04e127b462,DISK], DatanodeInfoWithStorage[127.0.0.1:42503,DS-ac1623eb-2e07-4eb1-87cb-bce66275eba6,DISK], DatanodeInfoWithStorage[127.0.0.1:34079,DS-7b0fad3c-5b83-471b-bcbd-8de3a7b115e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39098,DS-ea434b2a-9b5b-4c19-b965-0fcfc65c54a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42011,DS-61b7f052-374b-4503-8dd8-dae3e991a561,DISK], DatanodeInfoWithStorage[127.0.0.1:45238,DS-775cd746-dbfc-4dd7-9970-a6c88c55041f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blocks.per.postponedblocks.rescan
component: hdfs:NameNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-112061283-172.17.0.11-1597400436863:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46054,DS-6d71b1dd-e949-42f0-944e-a9ae513e7bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:37096,DS-448deed7-0241-401c-9195-74a123fdfa35,DISK], DatanodeInfoWithStorage[127.0.0.1:33106,DS-1bd2723b-bfe8-4c85-a0a5-02f91d08bcd5,DISK], DatanodeInfoWithStorage[127.0.0.1:36485,DS-91cffb97-68ec-430b-969d-9806bf91f8a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35321,DS-9fb3a41a-8312-4127-8580-a5e7eb84822e,DISK], DatanodeInfoWithStorage[127.0.0.1:35180,DS-4bdf1e2b-b33c-4467-93c1-78fa237f1a10,DISK], DatanodeInfoWithStorage[127.0.0.1:37985,DS-f694f7a5-9048-420f-9ada-63fae7796132,DISK], DatanodeInfoWithStorage[127.0.0.1:43277,DS-61b5172e-b744-4276-9317-f4de6b412e95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-112061283-172.17.0.11-1597400436863:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46054,DS-6d71b1dd-e949-42f0-944e-a9ae513e7bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:37096,DS-448deed7-0241-401c-9195-74a123fdfa35,DISK], DatanodeInfoWithStorage[127.0.0.1:33106,DS-1bd2723b-bfe8-4c85-a0a5-02f91d08bcd5,DISK], DatanodeInfoWithStorage[127.0.0.1:36485,DS-91cffb97-68ec-430b-969d-9806bf91f8a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35321,DS-9fb3a41a-8312-4127-8580-a5e7eb84822e,DISK], DatanodeInfoWithStorage[127.0.0.1:35180,DS-4bdf1e2b-b33c-4467-93c1-78fa237f1a10,DISK], DatanodeInfoWithStorage[127.0.0.1:37985,DS-f694f7a5-9048-420f-9ada-63fae7796132,DISK], DatanodeInfoWithStorage[127.0.0.1:43277,DS-61b5172e-b744-4276-9317-f4de6b412e95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blocks.per.postponedblocks.rescan
component: hdfs:NameNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1315933784-172.17.0.11-1597400588452:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38568,DS-04d12140-988f-4a04-bb67-ced24f224eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:42070,DS-c5269b2f-6f4d-4fa3-a180-51173cb4597c,DISK], DatanodeInfoWithStorage[127.0.0.1:46275,DS-ead9099e-7fa3-40b0-bf9c-5245da92c0e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38396,DS-d682f7f2-39df-41e9-bedd-e3122b0df39c,DISK], DatanodeInfoWithStorage[127.0.0.1:44828,DS-9f562e8c-d2f1-4111-8ff7-b72b62155f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37179,DS-b1f6b517-cafc-4d19-b795-6cc9911dbb4c,DISK], DatanodeInfoWithStorage[127.0.0.1:35033,DS-f9f19cb5-90eb-4cb7-9aac-141b385e7198,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-109efaa0-31e4-4166-a674-af0e3fe1b2aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1315933784-172.17.0.11-1597400588452:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38568,DS-04d12140-988f-4a04-bb67-ced24f224eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:42070,DS-c5269b2f-6f4d-4fa3-a180-51173cb4597c,DISK], DatanodeInfoWithStorage[127.0.0.1:46275,DS-ead9099e-7fa3-40b0-bf9c-5245da92c0e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38396,DS-d682f7f2-39df-41e9-bedd-e3122b0df39c,DISK], DatanodeInfoWithStorage[127.0.0.1:44828,DS-9f562e8c-d2f1-4111-8ff7-b72b62155f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37179,DS-b1f6b517-cafc-4d19-b795-6cc9911dbb4c,DISK], DatanodeInfoWithStorage[127.0.0.1:35033,DS-f9f19cb5-90eb-4cb7-9aac-141b385e7198,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-109efaa0-31e4-4166-a674-af0e3fe1b2aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blocks.per.postponedblocks.rescan
component: hdfs:NameNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1203472678-172.17.0.11-1597400999788:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46663,DS-e2f412a2-e560-4f0a-bb93-1d86895ac2e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43738,DS-e77fae67-5aec-4c0e-afde-89845c815171,DISK], DatanodeInfoWithStorage[127.0.0.1:33216,DS-fc58a9af-7c20-4af4-910c-a153dbd77ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:42753,DS-31996230-6306-4b94-bf25-4d0317c5024a,DISK], DatanodeInfoWithStorage[127.0.0.1:41883,DS-c5848d46-3ccb-4748-b556-033e4f952c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44939,DS-7b6b4def-0ff6-4451-a6ce-416ad4b5fabd,DISK], DatanodeInfoWithStorage[127.0.0.1:35806,DS-d3742451-37a1-40b1-8288-b6bbd0901059,DISK], DatanodeInfoWithStorage[127.0.0.1:41688,DS-a05aa4a3-08e2-4d9d-b631-9116607ffb98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1203472678-172.17.0.11-1597400999788:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46663,DS-e2f412a2-e560-4f0a-bb93-1d86895ac2e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43738,DS-e77fae67-5aec-4c0e-afde-89845c815171,DISK], DatanodeInfoWithStorage[127.0.0.1:33216,DS-fc58a9af-7c20-4af4-910c-a153dbd77ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:42753,DS-31996230-6306-4b94-bf25-4d0317c5024a,DISK], DatanodeInfoWithStorage[127.0.0.1:41883,DS-c5848d46-3ccb-4748-b556-033e4f952c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44939,DS-7b6b4def-0ff6-4451-a6ce-416ad4b5fabd,DISK], DatanodeInfoWithStorage[127.0.0.1:35806,DS-d3742451-37a1-40b1-8288-b6bbd0901059,DISK], DatanodeInfoWithStorage[127.0.0.1:41688,DS-a05aa4a3-08e2-4d9d-b631-9116607ffb98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blocks.per.postponedblocks.rescan
component: hdfs:NameNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1275355196-172.17.0.11-1597401324532:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34512,DS-8ef72213-5827-42f1-a89c-34a7e5d41430,DISK], DatanodeInfoWithStorage[127.0.0.1:43761,DS-8618d6c6-4682-4655-8c85-40fdb1e5a595,DISK], DatanodeInfoWithStorage[127.0.0.1:34700,DS-5ec6a628-1df9-4d24-8e44-32714206a013,DISK], DatanodeInfoWithStorage[127.0.0.1:33903,DS-0a9e47f2-797f-410d-be08-43c0ccb93207,DISK], DatanodeInfoWithStorage[127.0.0.1:37055,DS-6d0bbf26-abd7-4f88-ba21-0661845d5b19,DISK], DatanodeInfoWithStorage[127.0.0.1:34506,DS-9e73cf21-7124-4cd7-8af5-30faad29a4af,DISK], DatanodeInfoWithStorage[127.0.0.1:45759,DS-879f8fe6-9aec-42d6-91d7-eee280d19663,DISK], DatanodeInfoWithStorage[127.0.0.1:42477,DS-30bbbb99-88cc-4520-a56b-aab59a6b4705,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1275355196-172.17.0.11-1597401324532:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34512,DS-8ef72213-5827-42f1-a89c-34a7e5d41430,DISK], DatanodeInfoWithStorage[127.0.0.1:43761,DS-8618d6c6-4682-4655-8c85-40fdb1e5a595,DISK], DatanodeInfoWithStorage[127.0.0.1:34700,DS-5ec6a628-1df9-4d24-8e44-32714206a013,DISK], DatanodeInfoWithStorage[127.0.0.1:33903,DS-0a9e47f2-797f-410d-be08-43c0ccb93207,DISK], DatanodeInfoWithStorage[127.0.0.1:37055,DS-6d0bbf26-abd7-4f88-ba21-0661845d5b19,DISK], DatanodeInfoWithStorage[127.0.0.1:34506,DS-9e73cf21-7124-4cd7-8af5-30faad29a4af,DISK], DatanodeInfoWithStorage[127.0.0.1:45759,DS-879f8fe6-9aec-42d6-91d7-eee280d19663,DISK], DatanodeInfoWithStorage[127.0.0.1:42477,DS-30bbbb99-88cc-4520-a56b-aab59a6b4705,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blocks.per.postponedblocks.rescan
component: hdfs:NameNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-129087553-172.17.0.11-1597401471672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41000,DS-c5ee2e51-e9b0-4fcf-a0a7-2e216bd74d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:36575,DS-814544a2-849b-4d7b-8dac-561890c4073b,DISK], DatanodeInfoWithStorage[127.0.0.1:33623,DS-1317553f-4935-426e-b92c-ff58c88356a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45529,DS-b5dd35e6-e52f-48a8-afc5-6949f1cda9ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46406,DS-4b84a59f-a1a1-4b6d-b521-8cbb7e919e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34815,DS-108bdff5-29ef-4eb2-aa8a-59fd9c098210,DISK], DatanodeInfoWithStorage[127.0.0.1:38518,DS-fee1b9e7-7728-4e2c-b9fa-2031d7432a12,DISK], DatanodeInfoWithStorage[127.0.0.1:41623,DS-7b7b0140-e846-4275-8cfb-8fdcee3a5ac2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-129087553-172.17.0.11-1597401471672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41000,DS-c5ee2e51-e9b0-4fcf-a0a7-2e216bd74d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:36575,DS-814544a2-849b-4d7b-8dac-561890c4073b,DISK], DatanodeInfoWithStorage[127.0.0.1:33623,DS-1317553f-4935-426e-b92c-ff58c88356a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45529,DS-b5dd35e6-e52f-48a8-afc5-6949f1cda9ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46406,DS-4b84a59f-a1a1-4b6d-b521-8cbb7e919e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34815,DS-108bdff5-29ef-4eb2-aa8a-59fd9c098210,DISK], DatanodeInfoWithStorage[127.0.0.1:38518,DS-fee1b9e7-7728-4e2c-b9fa-2031d7432a12,DISK], DatanodeInfoWithStorage[127.0.0.1:41623,DS-7b7b0140-e846-4275-8cfb-8fdcee3a5ac2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blocks.per.postponedblocks.rescan
component: hdfs:NameNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-944692586-172.17.0.11-1597401688263:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36591,DS-dde7c85d-bc80-4264-8e70-b00d063ce45f,DISK], DatanodeInfoWithStorage[127.0.0.1:46155,DS-fb461ae7-031b-49be-8077-f3839f38cd46,DISK], DatanodeInfoWithStorage[127.0.0.1:42022,DS-5c5338bf-b1ab-4d2c-b76a-5f3449ba42c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39631,DS-df00e6d4-8396-4868-a150-5296f91a35c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44449,DS-1fa74cd3-c28e-4a79-965b-89313e87fa31,DISK], DatanodeInfoWithStorage[127.0.0.1:40758,DS-03dcb84f-4d31-40df-a43f-2526c78e74b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37515,DS-ff0bb282-92e7-45ec-bf6b-bdb13e86cd57,DISK], DatanodeInfoWithStorage[127.0.0.1:45150,DS-4a1d9e92-da1e-437f-a762-0fcd3d41c96e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-944692586-172.17.0.11-1597401688263:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36591,DS-dde7c85d-bc80-4264-8e70-b00d063ce45f,DISK], DatanodeInfoWithStorage[127.0.0.1:46155,DS-fb461ae7-031b-49be-8077-f3839f38cd46,DISK], DatanodeInfoWithStorage[127.0.0.1:42022,DS-5c5338bf-b1ab-4d2c-b76a-5f3449ba42c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39631,DS-df00e6d4-8396-4868-a150-5296f91a35c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44449,DS-1fa74cd3-c28e-4a79-965b-89313e87fa31,DISK], DatanodeInfoWithStorage[127.0.0.1:40758,DS-03dcb84f-4d31-40df-a43f-2526c78e74b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37515,DS-ff0bb282-92e7-45ec-bf6b-bdb13e86cd57,DISK], DatanodeInfoWithStorage[127.0.0.1:45150,DS-4a1d9e92-da1e-437f-a762-0fcd3d41c96e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blocks.per.postponedblocks.rescan
component: hdfs:NameNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1727429919-172.17.0.11-1597401800939:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33465,DS-968655c8-af20-463d-a622-e44a232b08fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45818,DS-d371565c-3cff-4aaa-8250-248fb0a350f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38275,DS-d09a62a4-5f5e-4c80-9d55-45700a80d6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44923,DS-8c84481a-fdb9-4fd4-a358-f99003da1689,DISK], DatanodeInfoWithStorage[127.0.0.1:46200,DS-c3bbd914-bec9-445a-b54d-a1651ac710c3,DISK], DatanodeInfoWithStorage[127.0.0.1:32873,DS-ebb0fa5c-21cf-42ca-98e3-156fc87cef73,DISK], DatanodeInfoWithStorage[127.0.0.1:45890,DS-71781eae-6ec7-4bf4-a4aa-236d9034852b,DISK], DatanodeInfoWithStorage[127.0.0.1:39361,DS-d3afcda0-9cc8-4f3a-b36a-d17d70daf7fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1727429919-172.17.0.11-1597401800939:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33465,DS-968655c8-af20-463d-a622-e44a232b08fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45818,DS-d371565c-3cff-4aaa-8250-248fb0a350f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38275,DS-d09a62a4-5f5e-4c80-9d55-45700a80d6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44923,DS-8c84481a-fdb9-4fd4-a358-f99003da1689,DISK], DatanodeInfoWithStorage[127.0.0.1:46200,DS-c3bbd914-bec9-445a-b54d-a1651ac710c3,DISK], DatanodeInfoWithStorage[127.0.0.1:32873,DS-ebb0fa5c-21cf-42ca-98e3-156fc87cef73,DISK], DatanodeInfoWithStorage[127.0.0.1:45890,DS-71781eae-6ec7-4bf4-a4aa-236d9034852b,DISK], DatanodeInfoWithStorage[127.0.0.1:39361,DS-d3afcda0-9cc8-4f3a-b36a-d17d70daf7fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.blocks.per.postponedblocks.rescan
component: hdfs:NameNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1142170053-172.17.0.11-1597401945379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35372,DS-6bd0c6a7-03ef-42cd-b20d-617eb08ec6ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43621,DS-d793ebe2-9bd3-4ea7-b6b3-9b62270dc134,DISK], DatanodeInfoWithStorage[127.0.0.1:33052,DS-98cc508e-8af9-4b5d-a3f4-8257dbc4da95,DISK], DatanodeInfoWithStorage[127.0.0.1:40153,DS-c4d8fd7e-9be5-4756-b872-1e7dddff61e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37638,DS-3f1ddcd3-e27b-4fde-b860-0b9d568c3cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:41396,DS-3a79d773-3571-44d9-b48a-a4db2894790f,DISK], DatanodeInfoWithStorage[127.0.0.1:40162,DS-56cec7aa-e646-4cc8-9ebe-aa9e7c1acd4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44817,DS-e71aa8bd-e983-4981-971d-62800b891d00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1142170053-172.17.0.11-1597401945379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35372,DS-6bd0c6a7-03ef-42cd-b20d-617eb08ec6ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43621,DS-d793ebe2-9bd3-4ea7-b6b3-9b62270dc134,DISK], DatanodeInfoWithStorage[127.0.0.1:33052,DS-98cc508e-8af9-4b5d-a3f4-8257dbc4da95,DISK], DatanodeInfoWithStorage[127.0.0.1:40153,DS-c4d8fd7e-9be5-4756-b872-1e7dddff61e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37638,DS-3f1ddcd3-e27b-4fde-b860-0b9d568c3cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:41396,DS-3a79d773-3571-44d9-b48a-a4db2894790f,DISK], DatanodeInfoWithStorage[127.0.0.1:40162,DS-56cec7aa-e646-4cc8-9ebe-aa9e7c1acd4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44817,DS-e71aa8bd-e983-4981-971d-62800b891d00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5600
