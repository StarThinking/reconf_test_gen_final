reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-701175169-172.17.0.20-1597738297271:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44799,DS-c2cc4575-3654-42e1-bbe9-f5beb2a21c70,DISK], DatanodeInfoWithStorage[127.0.0.1:45000,DS-953085da-eeae-483f-951c-7c755629955b,DISK], DatanodeInfoWithStorage[127.0.0.1:44128,DS-ffdac74f-66c3-4df1-afe7-7766860a4442,DISK], DatanodeInfoWithStorage[127.0.0.1:38636,DS-6847b6fc-9e10-4699-9ba0-0309115c059d,DISK], DatanodeInfoWithStorage[127.0.0.1:42213,DS-9f5ec3c4-e0e4-49e9-9fc5-229950a5f399,DISK], DatanodeInfoWithStorage[127.0.0.1:38872,DS-36b62abd-1fa1-455c-831c-a520b652a2a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34776,DS-57fe6156-5901-4564-af3d-5f779fd4dbbf,DISK], DatanodeInfoWithStorage[127.0.0.1:46169,DS-127a2678-323f-40d1-8c5c-8373f9d470e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-701175169-172.17.0.20-1597738297271:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44799,DS-c2cc4575-3654-42e1-bbe9-f5beb2a21c70,DISK], DatanodeInfoWithStorage[127.0.0.1:45000,DS-953085da-eeae-483f-951c-7c755629955b,DISK], DatanodeInfoWithStorage[127.0.0.1:44128,DS-ffdac74f-66c3-4df1-afe7-7766860a4442,DISK], DatanodeInfoWithStorage[127.0.0.1:38636,DS-6847b6fc-9e10-4699-9ba0-0309115c059d,DISK], DatanodeInfoWithStorage[127.0.0.1:42213,DS-9f5ec3c4-e0e4-49e9-9fc5-229950a5f399,DISK], DatanodeInfoWithStorage[127.0.0.1:38872,DS-36b62abd-1fa1-455c-831c-a520b652a2a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34776,DS-57fe6156-5901-4564-af3d-5f779fd4dbbf,DISK], DatanodeInfoWithStorage[127.0.0.1:46169,DS-127a2678-323f-40d1-8c5c-8373f9d470e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1601303329-172.17.0.20-1597738365849:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34860,DS-535a056c-9b2b-447a-ae45-00c504d6a29f,DISK], DatanodeInfoWithStorage[127.0.0.1:45586,DS-71d1d3d9-42df-419c-ab0f-468d5fb63a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:42080,DS-35d7be38-63d8-4aff-aee6-d41e44c69543,DISK], DatanodeInfoWithStorage[127.0.0.1:38008,DS-1bcf429a-9cc8-43f1-8174-e335a96b6f10,DISK], DatanodeInfoWithStorage[127.0.0.1:46317,DS-5a9af1e5-02db-489f-be11-064d4b96a4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43477,DS-d6f672af-47b7-4e34-b4ac-61dc373da929,DISK], DatanodeInfoWithStorage[127.0.0.1:42615,DS-5d6805ab-acc6-40a1-91a3-35097c46bf74,DISK], DatanodeInfoWithStorage[127.0.0.1:46840,DS-c8c44b68-d268-4291-81ef-11dbb7eea58f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1601303329-172.17.0.20-1597738365849:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34860,DS-535a056c-9b2b-447a-ae45-00c504d6a29f,DISK], DatanodeInfoWithStorage[127.0.0.1:45586,DS-71d1d3d9-42df-419c-ab0f-468d5fb63a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:42080,DS-35d7be38-63d8-4aff-aee6-d41e44c69543,DISK], DatanodeInfoWithStorage[127.0.0.1:38008,DS-1bcf429a-9cc8-43f1-8174-e335a96b6f10,DISK], DatanodeInfoWithStorage[127.0.0.1:46317,DS-5a9af1e5-02db-489f-be11-064d4b96a4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43477,DS-d6f672af-47b7-4e34-b4ac-61dc373da929,DISK], DatanodeInfoWithStorage[127.0.0.1:42615,DS-5d6805ab-acc6-40a1-91a3-35097c46bf74,DISK], DatanodeInfoWithStorage[127.0.0.1:46840,DS-c8c44b68-d268-4291-81ef-11dbb7eea58f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1225277336-172.17.0.20-1597738619929:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36470,DS-c8533e50-ab94-4916-bb39-3334dffddf5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37552,DS-74f31033-073e-4213-af46-d6b66b9dab20,DISK], DatanodeInfoWithStorage[127.0.0.1:39563,DS-f6e11b6e-426c-4e97-b7ab-f27efd3575b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37563,DS-d72864b6-1cee-4b90-8ac2-32b7ec74d2b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42289,DS-752b2c13-3cd3-4600-827a-f08a29d78661,DISK], DatanodeInfoWithStorage[127.0.0.1:43140,DS-5ae6b0db-0911-4acc-b0e4-82a0e73acd85,DISK], DatanodeInfoWithStorage[127.0.0.1:38264,DS-30a8e1ab-4ced-4475-838d-d6456183f677,DISK], DatanodeInfoWithStorage[127.0.0.1:36990,DS-60ccecce-4a06-417b-9aa5-227f59c56426,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1225277336-172.17.0.20-1597738619929:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36470,DS-c8533e50-ab94-4916-bb39-3334dffddf5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37552,DS-74f31033-073e-4213-af46-d6b66b9dab20,DISK], DatanodeInfoWithStorage[127.0.0.1:39563,DS-f6e11b6e-426c-4e97-b7ab-f27efd3575b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37563,DS-d72864b6-1cee-4b90-8ac2-32b7ec74d2b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42289,DS-752b2c13-3cd3-4600-827a-f08a29d78661,DISK], DatanodeInfoWithStorage[127.0.0.1:43140,DS-5ae6b0db-0911-4acc-b0e4-82a0e73acd85,DISK], DatanodeInfoWithStorage[127.0.0.1:38264,DS-30a8e1ab-4ced-4475-838d-d6456183f677,DISK], DatanodeInfoWithStorage[127.0.0.1:36990,DS-60ccecce-4a06-417b-9aa5-227f59c56426,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2136339736-172.17.0.20-1597738943511:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34374,DS-99e84c56-36cc-484a-813e-4188e4a233e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34070,DS-177cba3d-00d0-41af-99ca-be6836dc391a,DISK], DatanodeInfoWithStorage[127.0.0.1:35929,DS-776298b7-892b-42cd-926b-91ad2b32d897,DISK], DatanodeInfoWithStorage[127.0.0.1:35965,DS-cfbec572-afe6-42e3-8591-7ca10c173d38,DISK], DatanodeInfoWithStorage[127.0.0.1:34244,DS-c76e6988-867b-478e-86ad-83e67c57e2fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35468,DS-afae3b92-4da4-47b6-95a9-ae1bab47a01c,DISK], DatanodeInfoWithStorage[127.0.0.1:43340,DS-5cfadbf0-dc28-4e5f-8945-a43fbf0b4f42,DISK], DatanodeInfoWithStorage[127.0.0.1:36870,DS-ff454f28-904f-48f4-81e4-162bef53c901,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2136339736-172.17.0.20-1597738943511:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34374,DS-99e84c56-36cc-484a-813e-4188e4a233e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34070,DS-177cba3d-00d0-41af-99ca-be6836dc391a,DISK], DatanodeInfoWithStorage[127.0.0.1:35929,DS-776298b7-892b-42cd-926b-91ad2b32d897,DISK], DatanodeInfoWithStorage[127.0.0.1:35965,DS-cfbec572-afe6-42e3-8591-7ca10c173d38,DISK], DatanodeInfoWithStorage[127.0.0.1:34244,DS-c76e6988-867b-478e-86ad-83e67c57e2fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35468,DS-afae3b92-4da4-47b6-95a9-ae1bab47a01c,DISK], DatanodeInfoWithStorage[127.0.0.1:43340,DS-5cfadbf0-dc28-4e5f-8945-a43fbf0b4f42,DISK], DatanodeInfoWithStorage[127.0.0.1:36870,DS-ff454f28-904f-48f4-81e4-162bef53c901,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1078694381-172.17.0.20-1597739137095:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35847,DS-963ca1b0-0787-4fd2-8a67-cdaed09fd9c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41654,DS-d4d36e17-2134-485c-8623-e04220921286,DISK], DatanodeInfoWithStorage[127.0.0.1:44556,DS-150f43af-0da8-4db2-abdb-a4577574862d,DISK], DatanodeInfoWithStorage[127.0.0.1:34718,DS-915501f5-4527-4e3a-8358-a1d021c7c842,DISK], DatanodeInfoWithStorage[127.0.0.1:39163,DS-2d019449-9e4d-42a6-93f4-4367eebd4bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:44750,DS-92ba54ad-6e5e-40c9-8f15-a1927c123347,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-5e7c48e7-ab9a-496e-8382-e3d847a56baa,DISK], DatanodeInfoWithStorage[127.0.0.1:41758,DS-90d1cc55-7d57-4a4b-9198-29f3925e1b37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1078694381-172.17.0.20-1597739137095:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35847,DS-963ca1b0-0787-4fd2-8a67-cdaed09fd9c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41654,DS-d4d36e17-2134-485c-8623-e04220921286,DISK], DatanodeInfoWithStorage[127.0.0.1:44556,DS-150f43af-0da8-4db2-abdb-a4577574862d,DISK], DatanodeInfoWithStorage[127.0.0.1:34718,DS-915501f5-4527-4e3a-8358-a1d021c7c842,DISK], DatanodeInfoWithStorage[127.0.0.1:39163,DS-2d019449-9e4d-42a6-93f4-4367eebd4bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:44750,DS-92ba54ad-6e5e-40c9-8f15-a1927c123347,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-5e7c48e7-ab9a-496e-8382-e3d847a56baa,DISK], DatanodeInfoWithStorage[127.0.0.1:41758,DS-90d1cc55-7d57-4a4b-9198-29f3925e1b37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2027246281-172.17.0.20-1597739171450:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37081,DS-f61a546f-0547-43db-a933-20410172e018,DISK], DatanodeInfoWithStorage[127.0.0.1:35382,DS-bf6ecf1f-7506-41e5-b1f0-d02c5c09d91c,DISK], DatanodeInfoWithStorage[127.0.0.1:41678,DS-8695d7ed-abe3-4fef-b945-3d29cbdc5549,DISK], DatanodeInfoWithStorage[127.0.0.1:37659,DS-c199e083-8732-4af4-a81d-7d5a11049e69,DISK], DatanodeInfoWithStorage[127.0.0.1:40170,DS-10ccae7d-fedc-4fcb-9327-3c1eb95db546,DISK], DatanodeInfoWithStorage[127.0.0.1:36471,DS-cc50cd2a-c7fa-425e-aac1-a2dd1100a30c,DISK], DatanodeInfoWithStorage[127.0.0.1:33465,DS-7e0ff285-4e96-4a55-b3a1-45f543ca9460,DISK], DatanodeInfoWithStorage[127.0.0.1:46730,DS-de04ef00-ef4c-41dd-a9d8-4f130440e5b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2027246281-172.17.0.20-1597739171450:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37081,DS-f61a546f-0547-43db-a933-20410172e018,DISK], DatanodeInfoWithStorage[127.0.0.1:35382,DS-bf6ecf1f-7506-41e5-b1f0-d02c5c09d91c,DISK], DatanodeInfoWithStorage[127.0.0.1:41678,DS-8695d7ed-abe3-4fef-b945-3d29cbdc5549,DISK], DatanodeInfoWithStorage[127.0.0.1:37659,DS-c199e083-8732-4af4-a81d-7d5a11049e69,DISK], DatanodeInfoWithStorage[127.0.0.1:40170,DS-10ccae7d-fedc-4fcb-9327-3c1eb95db546,DISK], DatanodeInfoWithStorage[127.0.0.1:36471,DS-cc50cd2a-c7fa-425e-aac1-a2dd1100a30c,DISK], DatanodeInfoWithStorage[127.0.0.1:33465,DS-7e0ff285-4e96-4a55-b3a1-45f543ca9460,DISK], DatanodeInfoWithStorage[127.0.0.1:46730,DS-de04ef00-ef4c-41dd-a9d8-4f130440e5b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1114894530-172.17.0.20-1597740132457:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39098,DS-ada4d0c3-82ae-4d7a-b783-9eb3809b43c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44580,DS-4d31a2fe-066a-4d26-bdf6-dd259c22f42a,DISK], DatanodeInfoWithStorage[127.0.0.1:37742,DS-3d7b0507-94fa-49cf-a076-dc20a7e158ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36833,DS-f2292fa4-402f-4fa8-b281-e2a44353d8cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45312,DS-e815b71a-6d8e-4abe-bc95-7878fc513493,DISK], DatanodeInfoWithStorage[127.0.0.1:43115,DS-5e66319c-5c1d-4263-86d5-f3c774acacd6,DISK], DatanodeInfoWithStorage[127.0.0.1:35140,DS-60d229fd-f369-4588-9d6a-ee419f559f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46197,DS-fe975fb7-2b15-4374-a52e-7e528bb991ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1114894530-172.17.0.20-1597740132457:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39098,DS-ada4d0c3-82ae-4d7a-b783-9eb3809b43c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44580,DS-4d31a2fe-066a-4d26-bdf6-dd259c22f42a,DISK], DatanodeInfoWithStorage[127.0.0.1:37742,DS-3d7b0507-94fa-49cf-a076-dc20a7e158ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36833,DS-f2292fa4-402f-4fa8-b281-e2a44353d8cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45312,DS-e815b71a-6d8e-4abe-bc95-7878fc513493,DISK], DatanodeInfoWithStorage[127.0.0.1:43115,DS-5e66319c-5c1d-4263-86d5-f3c774acacd6,DISK], DatanodeInfoWithStorage[127.0.0.1:35140,DS-60d229fd-f369-4588-9d6a-ee419f559f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46197,DS-fe975fb7-2b15-4374-a52e-7e528bb991ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1870487866-172.17.0.20-1597740172360:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33283,DS-c3c850c1-60e1-4317-9f8b-28b906083887,DISK], DatanodeInfoWithStorage[127.0.0.1:39326,DS-8f863a9c-6c51-47c4-8679-0e65b6170aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:35945,DS-2bdbce01-fd03-4d4e-ab54-715060f9b11a,DISK], DatanodeInfoWithStorage[127.0.0.1:44536,DS-3cec3dd9-f9d4-4ffd-b365-25fda1e94ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:33737,DS-ba0595c6-fdbf-4488-a385-bc6c8ac99ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:36075,DS-33e824d5-0594-4a55-85d9-4d947e0bbc5f,DISK], DatanodeInfoWithStorage[127.0.0.1:35529,DS-2ddbbd97-f21c-4e2a-a359-3ff4a7261ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:33860,DS-c18afe58-e4f0-4f19-a010-47a46ed8bd45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1870487866-172.17.0.20-1597740172360:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33283,DS-c3c850c1-60e1-4317-9f8b-28b906083887,DISK], DatanodeInfoWithStorage[127.0.0.1:39326,DS-8f863a9c-6c51-47c4-8679-0e65b6170aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:35945,DS-2bdbce01-fd03-4d4e-ab54-715060f9b11a,DISK], DatanodeInfoWithStorage[127.0.0.1:44536,DS-3cec3dd9-f9d4-4ffd-b365-25fda1e94ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:33737,DS-ba0595c6-fdbf-4488-a385-bc6c8ac99ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:36075,DS-33e824d5-0594-4a55-85d9-4d947e0bbc5f,DISK], DatanodeInfoWithStorage[127.0.0.1:35529,DS-2ddbbd97-f21c-4e2a-a359-3ff4a7261ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:33860,DS-c18afe58-e4f0-4f19-a010-47a46ed8bd45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-974580519-172.17.0.20-1597740387908:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44780,DS-958eed0e-06ca-4ae5-8820-47110fc2d15f,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-7a47316a-c900-4e7e-a4fd-c8a27b3bd93c,DISK], DatanodeInfoWithStorage[127.0.0.1:34836,DS-49cf2bb6-dd62-449f-b32c-ad877c19a7b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39487,DS-c6701684-566c-47a7-b35e-fdb4b90906f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45144,DS-73da38b3-1a53-4341-93f1-b2337b924bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:33337,DS-8fff9722-bae7-45a7-9916-a081057a9858,DISK], DatanodeInfoWithStorage[127.0.0.1:33591,DS-607351c6-2992-48a3-b22d-c1e72c5a8a03,DISK], DatanodeInfoWithStorage[127.0.0.1:35027,DS-75f9273d-98a4-4952-b3cb-fecba12cc781,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-974580519-172.17.0.20-1597740387908:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44780,DS-958eed0e-06ca-4ae5-8820-47110fc2d15f,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-7a47316a-c900-4e7e-a4fd-c8a27b3bd93c,DISK], DatanodeInfoWithStorage[127.0.0.1:34836,DS-49cf2bb6-dd62-449f-b32c-ad877c19a7b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39487,DS-c6701684-566c-47a7-b35e-fdb4b90906f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45144,DS-73da38b3-1a53-4341-93f1-b2337b924bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:33337,DS-8fff9722-bae7-45a7-9916-a081057a9858,DISK], DatanodeInfoWithStorage[127.0.0.1:33591,DS-607351c6-2992-48a3-b22d-c1e72c5a8a03,DISK], DatanodeInfoWithStorage[127.0.0.1:35027,DS-75f9273d-98a4-4952-b3cb-fecba12cc781,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1570569675-172.17.0.20-1597740765700:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42411,DS-77178422-4e59-42ea-81d9-e613aee5199f,DISK], DatanodeInfoWithStorage[127.0.0.1:46410,DS-ce070aa6-0ed7-45cb-b9ad-42bc1697028c,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-45b431fc-2c52-43ac-8020-7b6a60f25443,DISK], DatanodeInfoWithStorage[127.0.0.1:38238,DS-43622550-3aac-4522-8ea0-13a34581c93c,DISK], DatanodeInfoWithStorage[127.0.0.1:46845,DS-675baef6-4ef5-4e74-a756-e0664449c976,DISK], DatanodeInfoWithStorage[127.0.0.1:32830,DS-0f16118b-ed2a-450f-aa2d-c0c80065788e,DISK], DatanodeInfoWithStorage[127.0.0.1:44578,DS-57782413-4b1e-4287-b050-bf77efec0339,DISK], DatanodeInfoWithStorage[127.0.0.1:42969,DS-826e2404-808f-41fd-b685-06fd9e1019c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1570569675-172.17.0.20-1597740765700:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42411,DS-77178422-4e59-42ea-81d9-e613aee5199f,DISK], DatanodeInfoWithStorage[127.0.0.1:46410,DS-ce070aa6-0ed7-45cb-b9ad-42bc1697028c,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-45b431fc-2c52-43ac-8020-7b6a60f25443,DISK], DatanodeInfoWithStorage[127.0.0.1:38238,DS-43622550-3aac-4522-8ea0-13a34581c93c,DISK], DatanodeInfoWithStorage[127.0.0.1:46845,DS-675baef6-4ef5-4e74-a756-e0664449c976,DISK], DatanodeInfoWithStorage[127.0.0.1:32830,DS-0f16118b-ed2a-450f-aa2d-c0c80065788e,DISK], DatanodeInfoWithStorage[127.0.0.1:44578,DS-57782413-4b1e-4287-b050-bf77efec0339,DISK], DatanodeInfoWithStorage[127.0.0.1:42969,DS-826e2404-808f-41fd-b685-06fd9e1019c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-507376095-172.17.0.20-1597740833829:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40021,DS-4515bb24-e22d-473c-93ef-44f23c6ac500,DISK], DatanodeInfoWithStorage[127.0.0.1:45160,DS-f9e946c8-61f7-4e8c-ac55-fde8edc6737a,DISK], DatanodeInfoWithStorage[127.0.0.1:41664,DS-14e3fccd-20a2-476c-9e37-0e7663c0b019,DISK], DatanodeInfoWithStorage[127.0.0.1:43323,DS-159b76be-e7e3-4b2c-a5b2-b040cd5188df,DISK], DatanodeInfoWithStorage[127.0.0.1:42954,DS-9efeec22-656b-4a44-a166-47d9c6c5c5b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39272,DS-984dde41-2e9d-4434-996a-c6e1b5783e46,DISK], DatanodeInfoWithStorage[127.0.0.1:39258,DS-65959a04-95a0-4c18-b24d-13fd6487b626,DISK], DatanodeInfoWithStorage[127.0.0.1:41097,DS-3d86f21e-0a57-4da4-b67f-6f3b23023397,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-507376095-172.17.0.20-1597740833829:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40021,DS-4515bb24-e22d-473c-93ef-44f23c6ac500,DISK], DatanodeInfoWithStorage[127.0.0.1:45160,DS-f9e946c8-61f7-4e8c-ac55-fde8edc6737a,DISK], DatanodeInfoWithStorage[127.0.0.1:41664,DS-14e3fccd-20a2-476c-9e37-0e7663c0b019,DISK], DatanodeInfoWithStorage[127.0.0.1:43323,DS-159b76be-e7e3-4b2c-a5b2-b040cd5188df,DISK], DatanodeInfoWithStorage[127.0.0.1:42954,DS-9efeec22-656b-4a44-a166-47d9c6c5c5b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39272,DS-984dde41-2e9d-4434-996a-c6e1b5783e46,DISK], DatanodeInfoWithStorage[127.0.0.1:39258,DS-65959a04-95a0-4c18-b24d-13fd6487b626,DISK], DatanodeInfoWithStorage[127.0.0.1:41097,DS-3d86f21e-0a57-4da4-b67f-6f3b23023397,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-397355748-172.17.0.20-1597741439928:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35008,DS-046086c7-2d88-4341-aed4-e6be6c7caf0f,DISK], DatanodeInfoWithStorage[127.0.0.1:39814,DS-24ba5f4c-b62d-482b-ac96-d20d4cec78dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35024,DS-f235d436-04bb-4df1-9461-e70994f781a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40328,DS-5d96f4bb-1000-452e-8d23-e48d23f0b0d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42230,DS-c0423ab4-0b3e-4ca4-a673-0e6410946d67,DISK], DatanodeInfoWithStorage[127.0.0.1:39884,DS-f421daf0-f14b-46b4-9830-9423f2b47d42,DISK], DatanodeInfoWithStorage[127.0.0.1:35579,DS-aebe3d43-a176-4a5e-b256-00e627046671,DISK], DatanodeInfoWithStorage[127.0.0.1:35854,DS-d0b9e3f7-0f95-4560-8cc1-d845097c0fe6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-397355748-172.17.0.20-1597741439928:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35008,DS-046086c7-2d88-4341-aed4-e6be6c7caf0f,DISK], DatanodeInfoWithStorage[127.0.0.1:39814,DS-24ba5f4c-b62d-482b-ac96-d20d4cec78dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35024,DS-f235d436-04bb-4df1-9461-e70994f781a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40328,DS-5d96f4bb-1000-452e-8d23-e48d23f0b0d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42230,DS-c0423ab4-0b3e-4ca4-a673-0e6410946d67,DISK], DatanodeInfoWithStorage[127.0.0.1:39884,DS-f421daf0-f14b-46b4-9830-9423f2b47d42,DISK], DatanodeInfoWithStorage[127.0.0.1:35579,DS-aebe3d43-a176-4a5e-b256-00e627046671,DISK], DatanodeInfoWithStorage[127.0.0.1:35854,DS-d0b9e3f7-0f95-4560-8cc1-d845097c0fe6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-280599501-172.17.0.20-1597741475163:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35651,DS-09537698-22fd-4597-a16f-97170d2eeddd,DISK], DatanodeInfoWithStorage[127.0.0.1:36354,DS-7ac7583a-a70a-4140-a636-0b46e8c76146,DISK], DatanodeInfoWithStorage[127.0.0.1:45358,DS-d59a7977-316c-4dcd-a980-8795f3ae5f37,DISK], DatanodeInfoWithStorage[127.0.0.1:39550,DS-26eca5fe-8527-482a-b2b6-e41dbd06e266,DISK], DatanodeInfoWithStorage[127.0.0.1:37305,DS-9a3f18ec-9da4-48a1-b65f-1f64ecfef063,DISK], DatanodeInfoWithStorage[127.0.0.1:34143,DS-238ac6b5-6b23-495e-aad8-6ca12fd61dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:45169,DS-aa2ded7c-61f9-4852-a9cf-7c045585ddf8,DISK], DatanodeInfoWithStorage[127.0.0.1:32774,DS-f91ee03b-7ab7-4702-bd2f-327a1c29db2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-280599501-172.17.0.20-1597741475163:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35651,DS-09537698-22fd-4597-a16f-97170d2eeddd,DISK], DatanodeInfoWithStorage[127.0.0.1:36354,DS-7ac7583a-a70a-4140-a636-0b46e8c76146,DISK], DatanodeInfoWithStorage[127.0.0.1:45358,DS-d59a7977-316c-4dcd-a980-8795f3ae5f37,DISK], DatanodeInfoWithStorage[127.0.0.1:39550,DS-26eca5fe-8527-482a-b2b6-e41dbd06e266,DISK], DatanodeInfoWithStorage[127.0.0.1:37305,DS-9a3f18ec-9da4-48a1-b65f-1f64ecfef063,DISK], DatanodeInfoWithStorage[127.0.0.1:34143,DS-238ac6b5-6b23-495e-aad8-6ca12fd61dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:45169,DS-aa2ded7c-61f9-4852-a9cf-7c045585ddf8,DISK], DatanodeInfoWithStorage[127.0.0.1:32774,DS-f91ee03b-7ab7-4702-bd2f-327a1c29db2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1241337689-172.17.0.20-1597741889993:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40824,DS-30c3ac1c-dfc7-453e-8dcb-f740cf2f0af0,DISK], DatanodeInfoWithStorage[127.0.0.1:37880,DS-2c69bba6-2bc6-4281-966e-814b4f7150da,DISK], DatanodeInfoWithStorage[127.0.0.1:42454,DS-7c60a5b1-daa7-409e-bdf6-842ada1aeda0,DISK], DatanodeInfoWithStorage[127.0.0.1:46396,DS-c9ab6142-c388-410f-8c2a-a8f560f114d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35659,DS-b19e89ef-8dc2-4d16-a1b5-b8df1ca50b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:40624,DS-17b8f8ec-5645-4f13-b5b0-1bfc54bf10bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43574,DS-c57254f5-4b09-46ef-ab16-6045559b23db,DISK], DatanodeInfoWithStorage[127.0.0.1:34700,DS-fb637749-9111-4304-9579-bcde3f86a530,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1241337689-172.17.0.20-1597741889993:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40824,DS-30c3ac1c-dfc7-453e-8dcb-f740cf2f0af0,DISK], DatanodeInfoWithStorage[127.0.0.1:37880,DS-2c69bba6-2bc6-4281-966e-814b4f7150da,DISK], DatanodeInfoWithStorage[127.0.0.1:42454,DS-7c60a5b1-daa7-409e-bdf6-842ada1aeda0,DISK], DatanodeInfoWithStorage[127.0.0.1:46396,DS-c9ab6142-c388-410f-8c2a-a8f560f114d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35659,DS-b19e89ef-8dc2-4d16-a1b5-b8df1ca50b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:40624,DS-17b8f8ec-5645-4f13-b5b0-1bfc54bf10bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43574,DS-c57254f5-4b09-46ef-ab16-6045559b23db,DISK], DatanodeInfoWithStorage[127.0.0.1:34700,DS-fb637749-9111-4304-9579-bcde3f86a530,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1990097680-172.17.0.20-1597742318360:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38780,DS-a45f3f1c-4776-4665-b0ef-cc7dfe95b2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36551,DS-863393ad-1ccd-40ee-9da2-8edc76afe1e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34073,DS-698362c6-96ff-4718-91eb-36d86832de6a,DISK], DatanodeInfoWithStorage[127.0.0.1:40933,DS-226b4a4b-1e1c-4392-a0d6-5d080f33ff17,DISK], DatanodeInfoWithStorage[127.0.0.1:33110,DS-34effd69-32f9-4576-b513-ef44e3047cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:39697,DS-5bccef74-c026-4261-ac5f-5e259f50c5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44966,DS-470e8be6-53fc-43bb-829c-ff190a80383e,DISK], DatanodeInfoWithStorage[127.0.0.1:39180,DS-f6b7c159-d427-4107-ab68-2db92d9f24c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1990097680-172.17.0.20-1597742318360:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38780,DS-a45f3f1c-4776-4665-b0ef-cc7dfe95b2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36551,DS-863393ad-1ccd-40ee-9da2-8edc76afe1e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34073,DS-698362c6-96ff-4718-91eb-36d86832de6a,DISK], DatanodeInfoWithStorage[127.0.0.1:40933,DS-226b4a4b-1e1c-4392-a0d6-5d080f33ff17,DISK], DatanodeInfoWithStorage[127.0.0.1:33110,DS-34effd69-32f9-4576-b513-ef44e3047cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:39697,DS-5bccef74-c026-4261-ac5f-5e259f50c5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44966,DS-470e8be6-53fc-43bb-829c-ff190a80383e,DISK], DatanodeInfoWithStorage[127.0.0.1:39180,DS-f6b7c159-d427-4107-ab68-2db92d9f24c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5019
