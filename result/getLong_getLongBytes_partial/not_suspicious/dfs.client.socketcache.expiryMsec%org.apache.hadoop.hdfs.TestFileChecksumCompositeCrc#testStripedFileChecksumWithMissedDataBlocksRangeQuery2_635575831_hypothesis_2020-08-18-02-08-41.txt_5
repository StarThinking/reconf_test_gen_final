reconf_parameter: dfs.client.socketcache.expiryMsec
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socketcache.expiryMsec
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1007183203-172.17.0.16-1597716614062:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42579,DS-779a8405-412b-4a59-9efe-8fb69c3c24fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33246,DS-2816ea85-6e45-443e-97d1-512645cf6912,DISK], DatanodeInfoWithStorage[127.0.0.1:45265,DS-eda81307-1ac6-4531-b140-643142bb873e,DISK], DatanodeInfoWithStorage[127.0.0.1:38007,DS-e992bc65-7f00-4620-afd6-ee2ccdea9ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:37517,DS-68f86681-ce7b-4959-8de8-66dab979b34c,DISK], DatanodeInfoWithStorage[127.0.0.1:46322,DS-6bf81b7f-993c-487c-9c21-9aa527cc2763,DISK], DatanodeInfoWithStorage[127.0.0.1:42146,DS-3c7088ef-f513-407b-800b-a2f952de2685,DISK], DatanodeInfoWithStorage[127.0.0.1:45989,DS-9bc24daf-7bef-47c7-8e25-847a5ccb3b90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1007183203-172.17.0.16-1597716614062:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42579,DS-779a8405-412b-4a59-9efe-8fb69c3c24fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33246,DS-2816ea85-6e45-443e-97d1-512645cf6912,DISK], DatanodeInfoWithStorage[127.0.0.1:45265,DS-eda81307-1ac6-4531-b140-643142bb873e,DISK], DatanodeInfoWithStorage[127.0.0.1:38007,DS-e992bc65-7f00-4620-afd6-ee2ccdea9ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:37517,DS-68f86681-ce7b-4959-8de8-66dab979b34c,DISK], DatanodeInfoWithStorage[127.0.0.1:46322,DS-6bf81b7f-993c-487c-9c21-9aa527cc2763,DISK], DatanodeInfoWithStorage[127.0.0.1:42146,DS-3c7088ef-f513-407b-800b-a2f952de2685,DISK], DatanodeInfoWithStorage[127.0.0.1:45989,DS-9bc24daf-7bef-47c7-8e25-847a5ccb3b90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socketcache.expiryMsec
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-794995345-172.17.0.16-1597716651468:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44623,DS-5361b800-6f22-43f2-9479-ec436ab95a43,DISK], DatanodeInfoWithStorage[127.0.0.1:43354,DS-0f2131a4-121e-40f5-bbce-32d09e99d0e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38525,DS-413a8aa4-95a1-40d9-bf7a-997c5c141929,DISK], DatanodeInfoWithStorage[127.0.0.1:46249,DS-b0f8b5b0-bc06-4380-90b2-5aa16c24fc05,DISK], DatanodeInfoWithStorage[127.0.0.1:35560,DS-8749b786-271d-441e-a531-244976dc6a78,DISK], DatanodeInfoWithStorage[127.0.0.1:33291,DS-74d3f725-4173-446b-a11a-d720b118e2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35224,DS-97edae01-ba7f-43b9-94ce-59f585014e84,DISK], DatanodeInfoWithStorage[127.0.0.1:37454,DS-ec2e767c-744e-457a-9d54-73a67fe74683,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-794995345-172.17.0.16-1597716651468:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44623,DS-5361b800-6f22-43f2-9479-ec436ab95a43,DISK], DatanodeInfoWithStorage[127.0.0.1:43354,DS-0f2131a4-121e-40f5-bbce-32d09e99d0e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38525,DS-413a8aa4-95a1-40d9-bf7a-997c5c141929,DISK], DatanodeInfoWithStorage[127.0.0.1:46249,DS-b0f8b5b0-bc06-4380-90b2-5aa16c24fc05,DISK], DatanodeInfoWithStorage[127.0.0.1:35560,DS-8749b786-271d-441e-a531-244976dc6a78,DISK], DatanodeInfoWithStorage[127.0.0.1:33291,DS-74d3f725-4173-446b-a11a-d720b118e2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35224,DS-97edae01-ba7f-43b9-94ce-59f585014e84,DISK], DatanodeInfoWithStorage[127.0.0.1:37454,DS-ec2e767c-744e-457a-9d54-73a67fe74683,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socketcache.expiryMsec
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-890177552-172.17.0.16-1597716766648:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43519,DS-e1266e3c-29cf-4328-aa80-37565f93899d,DISK], DatanodeInfoWithStorage[127.0.0.1:34583,DS-540d5a4f-6f5f-4016-855d-c5c9411b0675,DISK], DatanodeInfoWithStorage[127.0.0.1:33777,DS-e069750b-6fdf-443e-8eaf-3c69c2defe08,DISK], DatanodeInfoWithStorage[127.0.0.1:34441,DS-3461476c-c4b6-44e8-a1d8-f441dbfcb9ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41966,DS-093808e3-e6df-4142-9477-f4902ecf0414,DISK], DatanodeInfoWithStorage[127.0.0.1:34336,DS-edb5040c-0cf9-441e-ba24-682e2e1ddf11,DISK], DatanodeInfoWithStorage[127.0.0.1:44849,DS-14c01a8e-e7b2-4a56-a175-9739063052ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40237,DS-f6897fb2-3759-46b0-b994-ab0280e6b4e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-890177552-172.17.0.16-1597716766648:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43519,DS-e1266e3c-29cf-4328-aa80-37565f93899d,DISK], DatanodeInfoWithStorage[127.0.0.1:34583,DS-540d5a4f-6f5f-4016-855d-c5c9411b0675,DISK], DatanodeInfoWithStorage[127.0.0.1:33777,DS-e069750b-6fdf-443e-8eaf-3c69c2defe08,DISK], DatanodeInfoWithStorage[127.0.0.1:34441,DS-3461476c-c4b6-44e8-a1d8-f441dbfcb9ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41966,DS-093808e3-e6df-4142-9477-f4902ecf0414,DISK], DatanodeInfoWithStorage[127.0.0.1:34336,DS-edb5040c-0cf9-441e-ba24-682e2e1ddf11,DISK], DatanodeInfoWithStorage[127.0.0.1:44849,DS-14c01a8e-e7b2-4a56-a175-9739063052ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40237,DS-f6897fb2-3759-46b0-b994-ab0280e6b4e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socketcache.expiryMsec
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1630164566-172.17.0.16-1597717125729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46300,DS-50bc00ec-e1e0-4719-8bf6-49eecacae722,DISK], DatanodeInfoWithStorage[127.0.0.1:42319,DS-afe85264-369c-46e2-a65e-01bf3ec6c762,DISK], DatanodeInfoWithStorage[127.0.0.1:36695,DS-d3394a7b-f65b-452d-84e7-a7d82047f189,DISK], DatanodeInfoWithStorage[127.0.0.1:34067,DS-3a618343-459f-4c6b-9f24-62da2aacdbb9,DISK], DatanodeInfoWithStorage[127.0.0.1:42987,DS-3be4bb7c-07ba-412c-a4ef-808c36b6325b,DISK], DatanodeInfoWithStorage[127.0.0.1:36738,DS-c6498135-92ba-4e75-a301-b7231fe3f301,DISK], DatanodeInfoWithStorage[127.0.0.1:35508,DS-309aeeb4-d3ff-40a0-83df-07179ffec252,DISK], DatanodeInfoWithStorage[127.0.0.1:36987,DS-efcfa070-7d65-41ed-92c0-9c3df29ddf42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1630164566-172.17.0.16-1597717125729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46300,DS-50bc00ec-e1e0-4719-8bf6-49eecacae722,DISK], DatanodeInfoWithStorage[127.0.0.1:42319,DS-afe85264-369c-46e2-a65e-01bf3ec6c762,DISK], DatanodeInfoWithStorage[127.0.0.1:36695,DS-d3394a7b-f65b-452d-84e7-a7d82047f189,DISK], DatanodeInfoWithStorage[127.0.0.1:34067,DS-3a618343-459f-4c6b-9f24-62da2aacdbb9,DISK], DatanodeInfoWithStorage[127.0.0.1:42987,DS-3be4bb7c-07ba-412c-a4ef-808c36b6325b,DISK], DatanodeInfoWithStorage[127.0.0.1:36738,DS-c6498135-92ba-4e75-a301-b7231fe3f301,DISK], DatanodeInfoWithStorage[127.0.0.1:35508,DS-309aeeb4-d3ff-40a0-83df-07179ffec252,DISK], DatanodeInfoWithStorage[127.0.0.1:36987,DS-efcfa070-7d65-41ed-92c0-9c3df29ddf42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socketcache.expiryMsec
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1826286316-172.17.0.16-1597717286857:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45994,DS-15febcbe-16d8-4da2-b0c6-fca6f92f9c55,DISK], DatanodeInfoWithStorage[127.0.0.1:37563,DS-e523438a-76ed-4420-afb8-227351db3138,DISK], DatanodeInfoWithStorage[127.0.0.1:39975,DS-71ddb5cd-63c0-4e2d-8dec-ec77af38ba52,DISK], DatanodeInfoWithStorage[127.0.0.1:43257,DS-b1d3ea87-9647-4736-bab9-85f3814a7d84,DISK], DatanodeInfoWithStorage[127.0.0.1:36639,DS-7872e51e-3147-48a7-9d70-c3b40d7d880b,DISK], DatanodeInfoWithStorage[127.0.0.1:41561,DS-0c3ea9b1-6b8c-43d7-8982-5533be30ddaa,DISK], DatanodeInfoWithStorage[127.0.0.1:41268,DS-d0bcb4be-a179-4bf0-974a-58bf60456bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:37534,DS-751ccbce-03ae-4907-9e81-a9fae1439e44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1826286316-172.17.0.16-1597717286857:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45994,DS-15febcbe-16d8-4da2-b0c6-fca6f92f9c55,DISK], DatanodeInfoWithStorage[127.0.0.1:37563,DS-e523438a-76ed-4420-afb8-227351db3138,DISK], DatanodeInfoWithStorage[127.0.0.1:39975,DS-71ddb5cd-63c0-4e2d-8dec-ec77af38ba52,DISK], DatanodeInfoWithStorage[127.0.0.1:43257,DS-b1d3ea87-9647-4736-bab9-85f3814a7d84,DISK], DatanodeInfoWithStorage[127.0.0.1:36639,DS-7872e51e-3147-48a7-9d70-c3b40d7d880b,DISK], DatanodeInfoWithStorage[127.0.0.1:41561,DS-0c3ea9b1-6b8c-43d7-8982-5533be30ddaa,DISK], DatanodeInfoWithStorage[127.0.0.1:41268,DS-d0bcb4be-a179-4bf0-974a-58bf60456bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:37534,DS-751ccbce-03ae-4907-9e81-a9fae1439e44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.socketcache.expiryMsec
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-589160324-172.17.0.16-1597717328687:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45303,DS-189efb97-8661-4485-8bd8-c640f24d8262,DISK], DatanodeInfoWithStorage[127.0.0.1:40838,DS-2833890e-8b03-41e1-bf26-3e7f6a77a217,DISK], DatanodeInfoWithStorage[127.0.0.1:38263,DS-df15468b-5a0d-4ff1-a9ed-c2d13b0a5de3,DISK], DatanodeInfoWithStorage[127.0.0.1:39326,DS-a40e335b-08ee-4f0a-a588-193d7d8cb272,DISK], DatanodeInfoWithStorage[127.0.0.1:46652,DS-739c4ba3-cc28-4b92-b7b7-e562d4228256,DISK], DatanodeInfoWithStorage[127.0.0.1:45115,DS-caa69163-fa9c-4b5e-986b-8853263f19ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41079,DS-9153b0e6-f573-42f5-b6a0-1656146535e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33780,DS-5556d887-b6b6-4f38-be38-cdbd2748fa7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-589160324-172.17.0.16-1597717328687:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45303,DS-189efb97-8661-4485-8bd8-c640f24d8262,DISK], DatanodeInfoWithStorage[127.0.0.1:40838,DS-2833890e-8b03-41e1-bf26-3e7f6a77a217,DISK], DatanodeInfoWithStorage[127.0.0.1:38263,DS-df15468b-5a0d-4ff1-a9ed-c2d13b0a5de3,DISK], DatanodeInfoWithStorage[127.0.0.1:39326,DS-a40e335b-08ee-4f0a-a588-193d7d8cb272,DISK], DatanodeInfoWithStorage[127.0.0.1:46652,DS-739c4ba3-cc28-4b92-b7b7-e562d4228256,DISK], DatanodeInfoWithStorage[127.0.0.1:45115,DS-caa69163-fa9c-4b5e-986b-8853263f19ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41079,DS-9153b0e6-f573-42f5-b6a0-1656146535e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33780,DS-5556d887-b6b6-4f38-be38-cdbd2748fa7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socketcache.expiryMsec
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-209323174-172.17.0.16-1597717758945:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35802,DS-43d0cabb-f73c-4509-9f54-73afd032994c,DISK], DatanodeInfoWithStorage[127.0.0.1:40611,DS-27721ad1-9c1d-4dc9-9733-573b91ce0806,DISK], DatanodeInfoWithStorage[127.0.0.1:46615,DS-d723d432-e43e-472f-a474-feffeec6670f,DISK], DatanodeInfoWithStorage[127.0.0.1:39008,DS-481127cf-0710-4068-8329-d0f77419e2b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43974,DS-b155ad77-c201-4f0d-9122-55480395d59a,DISK], DatanodeInfoWithStorage[127.0.0.1:37551,DS-de3aa505-cce7-45a6-95f5-e85548a51f33,DISK], DatanodeInfoWithStorage[127.0.0.1:41778,DS-bae7345a-7063-461b-afba-fa0ba63f56ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39539,DS-62025c55-0a19-4c94-9692-68d51887a449,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-209323174-172.17.0.16-1597717758945:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35802,DS-43d0cabb-f73c-4509-9f54-73afd032994c,DISK], DatanodeInfoWithStorage[127.0.0.1:40611,DS-27721ad1-9c1d-4dc9-9733-573b91ce0806,DISK], DatanodeInfoWithStorage[127.0.0.1:46615,DS-d723d432-e43e-472f-a474-feffeec6670f,DISK], DatanodeInfoWithStorage[127.0.0.1:39008,DS-481127cf-0710-4068-8329-d0f77419e2b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43974,DS-b155ad77-c201-4f0d-9122-55480395d59a,DISK], DatanodeInfoWithStorage[127.0.0.1:37551,DS-de3aa505-cce7-45a6-95f5-e85548a51f33,DISK], DatanodeInfoWithStorage[127.0.0.1:41778,DS-bae7345a-7063-461b-afba-fa0ba63f56ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39539,DS-62025c55-0a19-4c94-9692-68d51887a449,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socketcache.expiryMsec
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-52574658-172.17.0.16-1597718168440:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33004,DS-06cb9e8f-3add-4c05-96ca-2aeab53b6834,DISK], DatanodeInfoWithStorage[127.0.0.1:32782,DS-a158e50f-0526-45fd-ae8f-2ad1a4ac07cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42024,DS-1100f131-1125-446d-b9ae-47cf8290362d,DISK], DatanodeInfoWithStorage[127.0.0.1:37562,DS-554fb8ec-4c60-4979-b3e7-54223f3604ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35144,DS-24599ec4-b495-4906-bee5-bf2a4a586fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:40307,DS-10dbf08a-51fb-4083-ac5c-01fb839f71f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38729,DS-5eec9782-05b6-4a90-bd8e-f0e5693c48bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37794,DS-630f46ca-6c52-4353-af5f-ce0f022f04f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-52574658-172.17.0.16-1597718168440:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33004,DS-06cb9e8f-3add-4c05-96ca-2aeab53b6834,DISK], DatanodeInfoWithStorage[127.0.0.1:32782,DS-a158e50f-0526-45fd-ae8f-2ad1a4ac07cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42024,DS-1100f131-1125-446d-b9ae-47cf8290362d,DISK], DatanodeInfoWithStorage[127.0.0.1:37562,DS-554fb8ec-4c60-4979-b3e7-54223f3604ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35144,DS-24599ec4-b495-4906-bee5-bf2a4a586fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:40307,DS-10dbf08a-51fb-4083-ac5c-01fb839f71f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38729,DS-5eec9782-05b6-4a90-bd8e-f0e5693c48bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37794,DS-630f46ca-6c52-4353-af5f-ce0f022f04f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socketcache.expiryMsec
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-816859027-172.17.0.16-1597718282811:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33013,DS-8619b6ff-b0c4-449c-ae69-3f9638b561c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44160,DS-f0545463-450f-4e1e-a0f6-c2207e171796,DISK], DatanodeInfoWithStorage[127.0.0.1:44932,DS-f93e76f4-e3eb-4f12-83f5-87073d9e23a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34384,DS-6daec2a4-9bb4-4eab-8a84-4a6ad45acac8,DISK], DatanodeInfoWithStorage[127.0.0.1:43432,DS-f9322bec-bc50-411e-a48e-da825a45e172,DISK], DatanodeInfoWithStorage[127.0.0.1:41782,DS-78792ed9-88e7-4139-af50-b521abd37537,DISK], DatanodeInfoWithStorage[127.0.0.1:40729,DS-6e6cb191-8f0e-42a5-a49f-2e27094b697f,DISK], DatanodeInfoWithStorage[127.0.0.1:33719,DS-af48899f-7205-4c87-9b6c-cd9a40780979,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-816859027-172.17.0.16-1597718282811:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33013,DS-8619b6ff-b0c4-449c-ae69-3f9638b561c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44160,DS-f0545463-450f-4e1e-a0f6-c2207e171796,DISK], DatanodeInfoWithStorage[127.0.0.1:44932,DS-f93e76f4-e3eb-4f12-83f5-87073d9e23a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34384,DS-6daec2a4-9bb4-4eab-8a84-4a6ad45acac8,DISK], DatanodeInfoWithStorage[127.0.0.1:43432,DS-f9322bec-bc50-411e-a48e-da825a45e172,DISK], DatanodeInfoWithStorage[127.0.0.1:41782,DS-78792ed9-88e7-4139-af50-b521abd37537,DISK], DatanodeInfoWithStorage[127.0.0.1:40729,DS-6e6cb191-8f0e-42a5-a49f-2e27094b697f,DISK], DatanodeInfoWithStorage[127.0.0.1:33719,DS-af48899f-7205-4c87-9b6c-cd9a40780979,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socketcache.expiryMsec
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-642106614-172.17.0.16-1597718438329:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42346,DS-22856ba8-c35e-48ab-a929-cb12a6b57d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:45175,DS-d97584a3-7e6e-497a-8746-b06905cce5d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43996,DS-60acfff4-77b6-46c4-98ca-94d06042cdb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36123,DS-b22708a2-3ffa-41b0-80c8-09bad2e3c040,DISK], DatanodeInfoWithStorage[127.0.0.1:38612,DS-4b2bf262-e4ef-4e89-aa0a-df67367a0176,DISK], DatanodeInfoWithStorage[127.0.0.1:44865,DS-ee4e47c1-de0d-4920-8ac8-dfc7d3d40ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:37608,DS-98a19073-77d7-4734-b7bc-17628d10a973,DISK], DatanodeInfoWithStorage[127.0.0.1:39437,DS-48a324ad-bfdd-4615-9fa0-14cca5ec369e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-642106614-172.17.0.16-1597718438329:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42346,DS-22856ba8-c35e-48ab-a929-cb12a6b57d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:45175,DS-d97584a3-7e6e-497a-8746-b06905cce5d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43996,DS-60acfff4-77b6-46c4-98ca-94d06042cdb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36123,DS-b22708a2-3ffa-41b0-80c8-09bad2e3c040,DISK], DatanodeInfoWithStorage[127.0.0.1:38612,DS-4b2bf262-e4ef-4e89-aa0a-df67367a0176,DISK], DatanodeInfoWithStorage[127.0.0.1:44865,DS-ee4e47c1-de0d-4920-8ac8-dfc7d3d40ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:37608,DS-98a19073-77d7-4734-b7bc-17628d10a973,DISK], DatanodeInfoWithStorage[127.0.0.1:39437,DS-48a324ad-bfdd-4615-9fa0-14cca5ec369e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socketcache.expiryMsec
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-451879054-172.17.0.16-1597718864407:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45518,DS-2d84ad8e-30cb-40da-8240-5e0d165eb566,DISK], DatanodeInfoWithStorage[127.0.0.1:44338,DS-d6317e0b-0790-4248-9eb2-6b3673c48f52,DISK], DatanodeInfoWithStorage[127.0.0.1:45328,DS-e246e346-08f5-41f3-91c1-657b1a70680f,DISK], DatanodeInfoWithStorage[127.0.0.1:39551,DS-f3053a65-dcdd-477e-8ebf-492264cff942,DISK], DatanodeInfoWithStorage[127.0.0.1:37946,DS-fd3066cf-6ea1-4d18-a194-7cdfcd642379,DISK], DatanodeInfoWithStorage[127.0.0.1:36653,DS-3fba3906-f869-4187-8964-655d02add323,DISK], DatanodeInfoWithStorage[127.0.0.1:36883,DS-57994dc0-62a6-42fc-bc20-c4a47dd92eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:43321,DS-0e631cfe-58a5-41d0-b8b8-8c5a55ff34a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-451879054-172.17.0.16-1597718864407:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45518,DS-2d84ad8e-30cb-40da-8240-5e0d165eb566,DISK], DatanodeInfoWithStorage[127.0.0.1:44338,DS-d6317e0b-0790-4248-9eb2-6b3673c48f52,DISK], DatanodeInfoWithStorage[127.0.0.1:45328,DS-e246e346-08f5-41f3-91c1-657b1a70680f,DISK], DatanodeInfoWithStorage[127.0.0.1:39551,DS-f3053a65-dcdd-477e-8ebf-492264cff942,DISK], DatanodeInfoWithStorage[127.0.0.1:37946,DS-fd3066cf-6ea1-4d18-a194-7cdfcd642379,DISK], DatanodeInfoWithStorage[127.0.0.1:36653,DS-3fba3906-f869-4187-8964-655d02add323,DISK], DatanodeInfoWithStorage[127.0.0.1:36883,DS-57994dc0-62a6-42fc-bc20-c4a47dd92eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:43321,DS-0e631cfe-58a5-41d0-b8b8-8c5a55ff34a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socketcache.expiryMsec
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-858717618-172.17.0.16-1597719613570:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41744,DS-b37d7302-a947-4196-9a21-3b2a309c7a40,DISK], DatanodeInfoWithStorage[127.0.0.1:36557,DS-ee2dd3cd-d157-48e7-9ba1-182c009b8da8,DISK], DatanodeInfoWithStorage[127.0.0.1:34879,DS-2c61f59b-a64d-4d75-a5e6-646e7d9c2d10,DISK], DatanodeInfoWithStorage[127.0.0.1:39841,DS-75d4ef7a-89bd-40a5-bce0-4e926bb9aa60,DISK], DatanodeInfoWithStorage[127.0.0.1:45728,DS-a303b908-aa3c-4220-a070-2b854bca486b,DISK], DatanodeInfoWithStorage[127.0.0.1:37176,DS-cf5eca6c-f427-4324-bbe0-49f61951d04a,DISK], DatanodeInfoWithStorage[127.0.0.1:44310,DS-c23ce912-1a5b-498b-bd29-dc49caae4feb,DISK], DatanodeInfoWithStorage[127.0.0.1:43871,DS-db00e599-9154-4a22-92a8-044e404a392e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-858717618-172.17.0.16-1597719613570:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41744,DS-b37d7302-a947-4196-9a21-3b2a309c7a40,DISK], DatanodeInfoWithStorage[127.0.0.1:36557,DS-ee2dd3cd-d157-48e7-9ba1-182c009b8da8,DISK], DatanodeInfoWithStorage[127.0.0.1:34879,DS-2c61f59b-a64d-4d75-a5e6-646e7d9c2d10,DISK], DatanodeInfoWithStorage[127.0.0.1:39841,DS-75d4ef7a-89bd-40a5-bce0-4e926bb9aa60,DISK], DatanodeInfoWithStorage[127.0.0.1:45728,DS-a303b908-aa3c-4220-a070-2b854bca486b,DISK], DatanodeInfoWithStorage[127.0.0.1:37176,DS-cf5eca6c-f427-4324-bbe0-49f61951d04a,DISK], DatanodeInfoWithStorage[127.0.0.1:44310,DS-c23ce912-1a5b-498b-bd29-dc49caae4feb,DISK], DatanodeInfoWithStorage[127.0.0.1:43871,DS-db00e599-9154-4a22-92a8-044e404a392e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socketcache.expiryMsec
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1910111674-172.17.0.16-1597719763006:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39378,DS-d7e998e2-4d53-4668-8d4c-690f0ed5a40f,DISK], DatanodeInfoWithStorage[127.0.0.1:38427,DS-a3d58bfa-59a0-457e-9430-7bc517e57476,DISK], DatanodeInfoWithStorage[127.0.0.1:35700,DS-94d7a8da-bbeb-4ff1-bb9c-270552c30817,DISK], DatanodeInfoWithStorage[127.0.0.1:46809,DS-695a6e74-519b-49be-9d5a-8d3a742bc23c,DISK], DatanodeInfoWithStorage[127.0.0.1:39831,DS-1b552ad4-8a12-4110-ad16-7649bb570a94,DISK], DatanodeInfoWithStorage[127.0.0.1:45370,DS-8bb847a3-8b1a-4fd9-b35d-81476cd2f5f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41228,DS-cf85b7e4-dad0-4614-a9f1-ef7120cf567d,DISK], DatanodeInfoWithStorage[127.0.0.1:39141,DS-7f756db3-bd02-4cbe-8690-27546537d066,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1910111674-172.17.0.16-1597719763006:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39378,DS-d7e998e2-4d53-4668-8d4c-690f0ed5a40f,DISK], DatanodeInfoWithStorage[127.0.0.1:38427,DS-a3d58bfa-59a0-457e-9430-7bc517e57476,DISK], DatanodeInfoWithStorage[127.0.0.1:35700,DS-94d7a8da-bbeb-4ff1-bb9c-270552c30817,DISK], DatanodeInfoWithStorage[127.0.0.1:46809,DS-695a6e74-519b-49be-9d5a-8d3a742bc23c,DISK], DatanodeInfoWithStorage[127.0.0.1:39831,DS-1b552ad4-8a12-4110-ad16-7649bb570a94,DISK], DatanodeInfoWithStorage[127.0.0.1:45370,DS-8bb847a3-8b1a-4fd9-b35d-81476cd2f5f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41228,DS-cf85b7e4-dad0-4614-a9f1-ef7120cf567d,DISK], DatanodeInfoWithStorage[127.0.0.1:39141,DS-7f756db3-bd02-4cbe-8690-27546537d066,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socketcache.expiryMsec
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-664433906-172.17.0.16-1597719908405:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34438,DS-88b3cf8a-fac5-4088-9020-9f6b997a3f15,DISK], DatanodeInfoWithStorage[127.0.0.1:42611,DS-64b66702-53f1-47e6-93b6-05fa48bb7980,DISK], DatanodeInfoWithStorage[127.0.0.1:34583,DS-b96f113a-db24-4f7e-aa85-00241252f8e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35908,DS-904ebaaf-5c94-4739-8a0e-d4c23d979d86,DISK], DatanodeInfoWithStorage[127.0.0.1:34464,DS-20898056-20bd-4bcb-a2ad-debeaacc2209,DISK], DatanodeInfoWithStorage[127.0.0.1:44959,DS-0c930503-5ca9-40cd-9116-fe0428ec7554,DISK], DatanodeInfoWithStorage[127.0.0.1:40097,DS-b1b24aba-a7da-4e19-a6c7-a03fa753e907,DISK], DatanodeInfoWithStorage[127.0.0.1:40488,DS-63420301-1643-4581-b2d3-5484e8e41d74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-664433906-172.17.0.16-1597719908405:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34438,DS-88b3cf8a-fac5-4088-9020-9f6b997a3f15,DISK], DatanodeInfoWithStorage[127.0.0.1:42611,DS-64b66702-53f1-47e6-93b6-05fa48bb7980,DISK], DatanodeInfoWithStorage[127.0.0.1:34583,DS-b96f113a-db24-4f7e-aa85-00241252f8e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35908,DS-904ebaaf-5c94-4739-8a0e-d4c23d979d86,DISK], DatanodeInfoWithStorage[127.0.0.1:34464,DS-20898056-20bd-4bcb-a2ad-debeaacc2209,DISK], DatanodeInfoWithStorage[127.0.0.1:44959,DS-0c930503-5ca9-40cd-9116-fe0428ec7554,DISK], DatanodeInfoWithStorage[127.0.0.1:40097,DS-b1b24aba-a7da-4e19-a6c7-a03fa753e907,DISK], DatanodeInfoWithStorage[127.0.0.1:40488,DS-63420301-1643-4581-b2d3-5484e8e41d74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socketcache.expiryMsec
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1865977845-172.17.0.16-1597719948688:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36911,DS-fbcc89d6-5fea-427a-8bbd-24f860cd3076,DISK], DatanodeInfoWithStorage[127.0.0.1:34684,DS-759920b1-bb4e-4323-8475-dd25fce72bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:39012,DS-6b857ae9-2d5a-478b-bb14-1a98c0c9cc9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43921,DS-e2282992-1131-4c82-a329-1ad93e4b9f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43957,DS-0e67a531-5b0a-46f1-baf4-33915dc27017,DISK], DatanodeInfoWithStorage[127.0.0.1:34992,DS-b00e70e4-c7fd-4986-b4ef-6d5fcb2a9a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34680,DS-ab35c2d9-3e59-4f32-8823-2c528289a25d,DISK], DatanodeInfoWithStorage[127.0.0.1:46433,DS-51abf8e6-48df-43a4-8b6a-1d23748db1ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1865977845-172.17.0.16-1597719948688:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36911,DS-fbcc89d6-5fea-427a-8bbd-24f860cd3076,DISK], DatanodeInfoWithStorage[127.0.0.1:34684,DS-759920b1-bb4e-4323-8475-dd25fce72bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:39012,DS-6b857ae9-2d5a-478b-bb14-1a98c0c9cc9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43921,DS-e2282992-1131-4c82-a329-1ad93e4b9f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43957,DS-0e67a531-5b0a-46f1-baf4-33915dc27017,DISK], DatanodeInfoWithStorage[127.0.0.1:34992,DS-b00e70e4-c7fd-4986-b4ef-6d5fcb2a9a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34680,DS-ab35c2d9-3e59-4f32-8823-2c528289a25d,DISK], DatanodeInfoWithStorage[127.0.0.1:46433,DS-51abf8e6-48df-43a4-8b6a-1d23748db1ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socketcache.expiryMsec
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1936701623-172.17.0.16-1597720060808:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36623,DS-5f9e8089-40d6-408f-8c07-9c887be0522c,DISK], DatanodeInfoWithStorage[127.0.0.1:34741,DS-5843d8c4-8724-4059-8006-998ec192541b,DISK], DatanodeInfoWithStorage[127.0.0.1:43670,DS-34a3a85c-9cbf-4cf5-935d-27370c1ee0b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39826,DS-765f58eb-33b0-47f3-bbc0-e117dab77d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33234,DS-3bf8be7c-c951-44bc-ad00-7c4931fa36e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36537,DS-5ac41dde-ef5b-47c8-adb7-521d943cf416,DISK], DatanodeInfoWithStorage[127.0.0.1:42338,DS-cbc03d88-9cf3-4c53-b71b-10e6a4cd6d23,DISK], DatanodeInfoWithStorage[127.0.0.1:37694,DS-d30b6b17-9f0f-4e00-a69d-581d9bf0dc6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1936701623-172.17.0.16-1597720060808:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36623,DS-5f9e8089-40d6-408f-8c07-9c887be0522c,DISK], DatanodeInfoWithStorage[127.0.0.1:34741,DS-5843d8c4-8724-4059-8006-998ec192541b,DISK], DatanodeInfoWithStorage[127.0.0.1:43670,DS-34a3a85c-9cbf-4cf5-935d-27370c1ee0b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39826,DS-765f58eb-33b0-47f3-bbc0-e117dab77d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33234,DS-3bf8be7c-c951-44bc-ad00-7c4931fa36e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36537,DS-5ac41dde-ef5b-47c8-adb7-521d943cf416,DISK], DatanodeInfoWithStorage[127.0.0.1:42338,DS-cbc03d88-9cf3-4c53-b71b-10e6a4cd6d23,DISK], DatanodeInfoWithStorage[127.0.0.1:37694,DS-d30b6b17-9f0f-4e00-a69d-581d9bf0dc6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socketcache.expiryMsec
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-861188229-172.17.0.16-1597720675792:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43054,DS-2f2b16f8-27a5-4367-a3a4-9913bef9b103,DISK], DatanodeInfoWithStorage[127.0.0.1:35843,DS-87567b6f-2e6f-4253-a458-2a1441769f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:46182,DS-c85b1e80-003d-4e6e-a9f5-7604a2d75e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:35713,DS-f05068a9-daf8-4afc-a306-40cb4a1f3a49,DISK], DatanodeInfoWithStorage[127.0.0.1:34128,DS-3987a2c0-ff57-4754-9309-28f055a74bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36521,DS-3018abb9-6d74-46a0-ae8c-cb7d23703ece,DISK], DatanodeInfoWithStorage[127.0.0.1:36111,DS-e96d2d92-fd0e-4ad9-a667-866bdb20f243,DISK], DatanodeInfoWithStorage[127.0.0.1:44578,DS-f61acd69-e4d9-401a-96cc-8ea62970e549,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-861188229-172.17.0.16-1597720675792:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43054,DS-2f2b16f8-27a5-4367-a3a4-9913bef9b103,DISK], DatanodeInfoWithStorage[127.0.0.1:35843,DS-87567b6f-2e6f-4253-a458-2a1441769f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:46182,DS-c85b1e80-003d-4e6e-a9f5-7604a2d75e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:35713,DS-f05068a9-daf8-4afc-a306-40cb4a1f3a49,DISK], DatanodeInfoWithStorage[127.0.0.1:34128,DS-3987a2c0-ff57-4754-9309-28f055a74bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36521,DS-3018abb9-6d74-46a0-ae8c-cb7d23703ece,DISK], DatanodeInfoWithStorage[127.0.0.1:36111,DS-e96d2d92-fd0e-4ad9-a667-866bdb20f243,DISK], DatanodeInfoWithStorage[127.0.0.1:44578,DS-f61acd69-e4d9-401a-96cc-8ea62970e549,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socketcache.expiryMsec
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1645824662-172.17.0.16-1597721286768:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44977,DS-bdc92466-d074-4ac6-ba5b-e4bc9fbaa33c,DISK], DatanodeInfoWithStorage[127.0.0.1:38551,DS-fb39354e-4c9c-491c-a6ee-a604b943cf46,DISK], DatanodeInfoWithStorage[127.0.0.1:44279,DS-90ccc839-6f97-403a-825b-782ae590bfad,DISK], DatanodeInfoWithStorage[127.0.0.1:40848,DS-70ffd362-e8f6-44f7-865b-d5636f2600cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46767,DS-5fe46fbb-5d4c-4578-b15c-f58fafe50706,DISK], DatanodeInfoWithStorage[127.0.0.1:35869,DS-3f4352e6-95e4-4ea6-9651-21074c394162,DISK], DatanodeInfoWithStorage[127.0.0.1:41943,DS-7bf2d7bf-d3bb-42f3-b0c5-78257a8508bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42341,DS-2b081b7b-e9b7-4f1d-8d1e-17e5c195acc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1645824662-172.17.0.16-1597721286768:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44977,DS-bdc92466-d074-4ac6-ba5b-e4bc9fbaa33c,DISK], DatanodeInfoWithStorage[127.0.0.1:38551,DS-fb39354e-4c9c-491c-a6ee-a604b943cf46,DISK], DatanodeInfoWithStorage[127.0.0.1:44279,DS-90ccc839-6f97-403a-825b-782ae590bfad,DISK], DatanodeInfoWithStorage[127.0.0.1:40848,DS-70ffd362-e8f6-44f7-865b-d5636f2600cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46767,DS-5fe46fbb-5d4c-4578-b15c-f58fafe50706,DISK], DatanodeInfoWithStorage[127.0.0.1:35869,DS-3f4352e6-95e4-4ea6-9651-21074c394162,DISK], DatanodeInfoWithStorage[127.0.0.1:41943,DS-7bf2d7bf-d3bb-42f3-b0c5-78257a8508bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42341,DS-2b081b7b-e9b7-4f1d-8d1e-17e5c195acc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socketcache.expiryMsec
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2030537846-172.17.0.16-1597721414703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35621,DS-6806f3ed-8c9f-409e-9a92-de097db37f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:46328,DS-8e551e08-475d-4d51-9dbb-8846f252142c,DISK], DatanodeInfoWithStorage[127.0.0.1:43314,DS-610287d5-47ea-4799-8e26-8e878eae12c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40672,DS-134641fd-9af3-45f9-9489-7f83b457ad8b,DISK], DatanodeInfoWithStorage[127.0.0.1:40965,DS-f4aaebb2-2b87-43a7-9be5-189e7d53179f,DISK], DatanodeInfoWithStorage[127.0.0.1:36233,DS-7a9e948a-13ae-4e52-8121-bd02cdcc2291,DISK], DatanodeInfoWithStorage[127.0.0.1:37477,DS-557f608a-b333-4485-862a-5ed154aa6b04,DISK], DatanodeInfoWithStorage[127.0.0.1:41259,DS-c72ec225-0c2b-4fde-b232-dc6f30e9be13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2030537846-172.17.0.16-1597721414703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35621,DS-6806f3ed-8c9f-409e-9a92-de097db37f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:46328,DS-8e551e08-475d-4d51-9dbb-8846f252142c,DISK], DatanodeInfoWithStorage[127.0.0.1:43314,DS-610287d5-47ea-4799-8e26-8e878eae12c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40672,DS-134641fd-9af3-45f9-9489-7f83b457ad8b,DISK], DatanodeInfoWithStorage[127.0.0.1:40965,DS-f4aaebb2-2b87-43a7-9be5-189e7d53179f,DISK], DatanodeInfoWithStorage[127.0.0.1:36233,DS-7a9e948a-13ae-4e52-8121-bd02cdcc2291,DISK], DatanodeInfoWithStorage[127.0.0.1:37477,DS-557f608a-b333-4485-862a-5ed154aa6b04,DISK], DatanodeInfoWithStorage[127.0.0.1:41259,DS-c72ec225-0c2b-4fde-b232-dc6f30e9be13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socketcache.expiryMsec
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-79130050-172.17.0.16-1597721800292:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44652,DS-87b8c1f7-2f4a-4f1f-84fa-950852ac6754,DISK], DatanodeInfoWithStorage[127.0.0.1:41604,DS-f7fa0631-0fc1-468c-abb6-d79f373c7e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:41398,DS-d2bf3a74-b8ff-4ee6-bfd6-9b0794a67569,DISK], DatanodeInfoWithStorage[127.0.0.1:39854,DS-6ee1d134-3608-4a83-a48d-39766185a1c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33016,DS-ed61ab7b-8468-4873-a45e-3cb339e34cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:35494,DS-a9d561d0-4a72-4fe4-9bda-dc47f12bec8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42520,DS-6cbea4af-474c-47b6-8f81-3586471d9931,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-fb87c243-038d-4e79-80f9-ef27b8df8009,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-79130050-172.17.0.16-1597721800292:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44652,DS-87b8c1f7-2f4a-4f1f-84fa-950852ac6754,DISK], DatanodeInfoWithStorage[127.0.0.1:41604,DS-f7fa0631-0fc1-468c-abb6-d79f373c7e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:41398,DS-d2bf3a74-b8ff-4ee6-bfd6-9b0794a67569,DISK], DatanodeInfoWithStorage[127.0.0.1:39854,DS-6ee1d134-3608-4a83-a48d-39766185a1c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33016,DS-ed61ab7b-8468-4873-a45e-3cb339e34cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:35494,DS-a9d561d0-4a72-4fe4-9bda-dc47f12bec8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42520,DS-6cbea4af-474c-47b6-8f81-3586471d9931,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-fb87c243-038d-4e79-80f9-ef27b8df8009,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socketcache.expiryMsec
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1127781855-172.17.0.16-1597722319824:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37872,DS-6ac53953-d1ea-49d4-b8a3-3fffa45ad3c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45952,DS-ece3508e-746b-453c-96bb-2847f19bb1a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40003,DS-ce55cf9f-b0d8-400b-9b69-27d0be02cb38,DISK], DatanodeInfoWithStorage[127.0.0.1:42029,DS-25983979-6fb0-437d-b6a5-9c64f6843581,DISK], DatanodeInfoWithStorage[127.0.0.1:38762,DS-d519d9b1-cb37-4213-8f3a-705a53ea8b27,DISK], DatanodeInfoWithStorage[127.0.0.1:37331,DS-dfa7b834-437d-4ab3-b831-e59414ebf5f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33312,DS-4582a765-760c-4af7-9e74-a14f623587e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39261,DS-efa3dec3-af43-4dd3-abaa-0651529ce633,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1127781855-172.17.0.16-1597722319824:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37872,DS-6ac53953-d1ea-49d4-b8a3-3fffa45ad3c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45952,DS-ece3508e-746b-453c-96bb-2847f19bb1a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40003,DS-ce55cf9f-b0d8-400b-9b69-27d0be02cb38,DISK], DatanodeInfoWithStorage[127.0.0.1:42029,DS-25983979-6fb0-437d-b6a5-9c64f6843581,DISK], DatanodeInfoWithStorage[127.0.0.1:38762,DS-d519d9b1-cb37-4213-8f3a-705a53ea8b27,DISK], DatanodeInfoWithStorage[127.0.0.1:37331,DS-dfa7b834-437d-4ab3-b831-e59414ebf5f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33312,DS-4582a765-760c-4af7-9e74-a14f623587e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39261,DS-efa3dec3-af43-4dd3-abaa-0651529ce633,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5817
