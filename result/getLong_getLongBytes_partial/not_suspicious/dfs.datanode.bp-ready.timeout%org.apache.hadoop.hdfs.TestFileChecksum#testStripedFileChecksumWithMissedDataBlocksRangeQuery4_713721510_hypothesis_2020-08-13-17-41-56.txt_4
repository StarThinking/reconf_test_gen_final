reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 0s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 0s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-898763919-172.17.0.17-1597341219922:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38842,DS-631b98bd-8631-4bcd-be26-226b7cdcc4de,DISK], DatanodeInfoWithStorage[127.0.0.1:45153,DS-6ef86aee-1284-4377-9b0f-9f12edfde8ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40941,DS-7f0d6ab9-a709-4fed-aa07-d11a7cd2f4a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36512,DS-7c8c8643-e882-43c1-926d-11dd088ceadc,DISK], DatanodeInfoWithStorage[127.0.0.1:34622,DS-1bd6e234-d8fe-44f3-ba78-a5ad57510c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:38839,DS-dc8fe18b-55a5-44ca-8b7e-f45e596d099d,DISK], DatanodeInfoWithStorage[127.0.0.1:43924,DS-cb81cf59-1dc0-4781-a1c6-56e5b65d9c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35852,DS-e0941df4-3732-4611-a734-0c61c26f06c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-898763919-172.17.0.17-1597341219922:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38842,DS-631b98bd-8631-4bcd-be26-226b7cdcc4de,DISK], DatanodeInfoWithStorage[127.0.0.1:45153,DS-6ef86aee-1284-4377-9b0f-9f12edfde8ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40941,DS-7f0d6ab9-a709-4fed-aa07-d11a7cd2f4a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36512,DS-7c8c8643-e882-43c1-926d-11dd088ceadc,DISK], DatanodeInfoWithStorage[127.0.0.1:34622,DS-1bd6e234-d8fe-44f3-ba78-a5ad57510c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:38839,DS-dc8fe18b-55a5-44ca-8b7e-f45e596d099d,DISK], DatanodeInfoWithStorage[127.0.0.1:43924,DS-cb81cf59-1dc0-4781-a1c6-56e5b65d9c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35852,DS-e0941df4-3732-4611-a734-0c61c26f06c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 0s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1243380534-172.17.0.17-1597341897831:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42058,DS-8fd571e8-585f-4550-a52b-23aa0c6bf930,DISK], DatanodeInfoWithStorage[127.0.0.1:43143,DS-78ae3dcb-4b35-4f33-a134-2aef5f175502,DISK], DatanodeInfoWithStorage[127.0.0.1:40822,DS-26c67164-e6fd-4d72-914e-bd69fa1c4d98,DISK], DatanodeInfoWithStorage[127.0.0.1:40012,DS-30cf65a2-cf51-423c-b9c4-e32524649d45,DISK], DatanodeInfoWithStorage[127.0.0.1:41102,DS-5788c5dc-c2f9-4258-9e0b-5e62f14f3b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:35109,DS-8eb4ec6d-dc9a-4a56-8416-4ee7795d5ade,DISK], DatanodeInfoWithStorage[127.0.0.1:36332,DS-8a47a46c-1793-40b5-b8ac-a7b2707e2ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:34412,DS-d02eac6e-2b75-495b-92a0-f57dcd4601fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1243380534-172.17.0.17-1597341897831:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42058,DS-8fd571e8-585f-4550-a52b-23aa0c6bf930,DISK], DatanodeInfoWithStorage[127.0.0.1:43143,DS-78ae3dcb-4b35-4f33-a134-2aef5f175502,DISK], DatanodeInfoWithStorage[127.0.0.1:40822,DS-26c67164-e6fd-4d72-914e-bd69fa1c4d98,DISK], DatanodeInfoWithStorage[127.0.0.1:40012,DS-30cf65a2-cf51-423c-b9c4-e32524649d45,DISK], DatanodeInfoWithStorage[127.0.0.1:41102,DS-5788c5dc-c2f9-4258-9e0b-5e62f14f3b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:35109,DS-8eb4ec6d-dc9a-4a56-8416-4ee7795d5ade,DISK], DatanodeInfoWithStorage[127.0.0.1:36332,DS-8a47a46c-1793-40b5-b8ac-a7b2707e2ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:34412,DS-d02eac6e-2b75-495b-92a0-f57dcd4601fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 0s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1376639492-172.17.0.17-1597342135549:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44734,DS-ab16fa5a-522a-4d74-8b42-5810c0315919,DISK], DatanodeInfoWithStorage[127.0.0.1:35400,DS-66ed7d26-b31d-4d30-b662-b7f910fe7c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:36753,DS-44acf50c-a9cd-49f2-9479-5760137beb0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44162,DS-6059b31a-7828-4d46-acd6-a6b571ef61a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37961,DS-00b2f06b-5069-4e7a-8f0d-fe8f8b07d452,DISK], DatanodeInfoWithStorage[127.0.0.1:45716,DS-d0763829-66ab-42eb-bfa5-93a7d4f7eee5,DISK], DatanodeInfoWithStorage[127.0.0.1:42203,DS-c3dc94e5-b81b-4cfd-985a-267f7c12361d,DISK], DatanodeInfoWithStorage[127.0.0.1:39207,DS-86cd92f1-5372-40cf-8e6a-e5fb90911d46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1376639492-172.17.0.17-1597342135549:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44734,DS-ab16fa5a-522a-4d74-8b42-5810c0315919,DISK], DatanodeInfoWithStorage[127.0.0.1:35400,DS-66ed7d26-b31d-4d30-b662-b7f910fe7c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:36753,DS-44acf50c-a9cd-49f2-9479-5760137beb0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44162,DS-6059b31a-7828-4d46-acd6-a6b571ef61a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37961,DS-00b2f06b-5069-4e7a-8f0d-fe8f8b07d452,DISK], DatanodeInfoWithStorage[127.0.0.1:45716,DS-d0763829-66ab-42eb-bfa5-93a7d4f7eee5,DISK], DatanodeInfoWithStorage[127.0.0.1:42203,DS-c3dc94e5-b81b-4cfd-985a-267f7c12361d,DISK], DatanodeInfoWithStorage[127.0.0.1:39207,DS-86cd92f1-5372-40cf-8e6a-e5fb90911d46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 0s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1578265033-172.17.0.17-1597342405748:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43238,DS-6ff7d977-0937-4626-a09e-cfbea0ff2549,DISK], DatanodeInfoWithStorage[127.0.0.1:43395,DS-4dc1ad2f-665c-4ab3-ad2e-1ef235627767,DISK], DatanodeInfoWithStorage[127.0.0.1:39650,DS-80e6e989-4230-4312-ae00-0223b358d69f,DISK], DatanodeInfoWithStorage[127.0.0.1:37461,DS-ff90b876-b41c-48f2-bf1b-3f08838729ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34197,DS-cac7a83e-7109-4e5b-b3d6-e8017922ab93,DISK], DatanodeInfoWithStorage[127.0.0.1:35956,DS-16fa853a-022e-4bb9-a318-9229505b67c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46470,DS-d6c866e1-726f-4144-a1b9-87350e749e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:46062,DS-88d93766-c3d6-4235-ab71-c484da4bf468,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1578265033-172.17.0.17-1597342405748:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43238,DS-6ff7d977-0937-4626-a09e-cfbea0ff2549,DISK], DatanodeInfoWithStorage[127.0.0.1:43395,DS-4dc1ad2f-665c-4ab3-ad2e-1ef235627767,DISK], DatanodeInfoWithStorage[127.0.0.1:39650,DS-80e6e989-4230-4312-ae00-0223b358d69f,DISK], DatanodeInfoWithStorage[127.0.0.1:37461,DS-ff90b876-b41c-48f2-bf1b-3f08838729ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34197,DS-cac7a83e-7109-4e5b-b3d6-e8017922ab93,DISK], DatanodeInfoWithStorage[127.0.0.1:35956,DS-16fa853a-022e-4bb9-a318-9229505b67c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46470,DS-d6c866e1-726f-4144-a1b9-87350e749e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:46062,DS-88d93766-c3d6-4235-ab71-c484da4bf468,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 0s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-204044886-172.17.0.17-1597342445240:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44235,DS-e832ae1f-2ed9-4432-87e0-d47f3c601459,DISK], DatanodeInfoWithStorage[127.0.0.1:33549,DS-af078b7d-aab7-4304-b2c3-9fa223afab77,DISK], DatanodeInfoWithStorage[127.0.0.1:40844,DS-0e7549ed-cce3-4160-b524-e1dfb9b65c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36960,DS-c8219bb8-939a-4005-a874-3395b6d0a074,DISK], DatanodeInfoWithStorage[127.0.0.1:40684,DS-c2515e90-0deb-4d7d-a783-468920b5967c,DISK], DatanodeInfoWithStorage[127.0.0.1:34438,DS-ba0e18b8-13df-4dc2-9623-467bf8153689,DISK], DatanodeInfoWithStorage[127.0.0.1:38112,DS-4ecb7c76-7f17-436f-9f84-70f0f1e80d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38351,DS-f4ca45e0-8854-4e9e-bb6a-2cdaafa1e3db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-204044886-172.17.0.17-1597342445240:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44235,DS-e832ae1f-2ed9-4432-87e0-d47f3c601459,DISK], DatanodeInfoWithStorage[127.0.0.1:33549,DS-af078b7d-aab7-4304-b2c3-9fa223afab77,DISK], DatanodeInfoWithStorage[127.0.0.1:40844,DS-0e7549ed-cce3-4160-b524-e1dfb9b65c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36960,DS-c8219bb8-939a-4005-a874-3395b6d0a074,DISK], DatanodeInfoWithStorage[127.0.0.1:40684,DS-c2515e90-0deb-4d7d-a783-468920b5967c,DISK], DatanodeInfoWithStorage[127.0.0.1:34438,DS-ba0e18b8-13df-4dc2-9623-467bf8153689,DISK], DatanodeInfoWithStorage[127.0.0.1:38112,DS-4ecb7c76-7f17-436f-9f84-70f0f1e80d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38351,DS-f4ca45e0-8854-4e9e-bb6a-2cdaafa1e3db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 0s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1397686961-172.17.0.17-1597342493848:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33615,DS-531b2331-31fc-46a3-b422-2657955e7951,DISK], DatanodeInfoWithStorage[127.0.0.1:41815,DS-5630166f-67dd-45d5-9732-e0b0c75be018,DISK], DatanodeInfoWithStorage[127.0.0.1:43713,DS-a365ed64-1700-47c2-9ae3-d65a6928b223,DISK], DatanodeInfoWithStorage[127.0.0.1:34901,DS-fc1f0b65-d1e2-4962-ac71-9475e2b4e86b,DISK], DatanodeInfoWithStorage[127.0.0.1:42619,DS-7a847a95-6c22-4cff-a588-d6810a7aab00,DISK], DatanodeInfoWithStorage[127.0.0.1:43734,DS-548a70cf-ed7c-44d1-9c52-09cc47c879f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41123,DS-e394ba2e-1be4-4910-8f9b-40711bec5025,DISK], DatanodeInfoWithStorage[127.0.0.1:37640,DS-3314647c-f647-4c8d-b965-2ec4e4706d92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1397686961-172.17.0.17-1597342493848:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33615,DS-531b2331-31fc-46a3-b422-2657955e7951,DISK], DatanodeInfoWithStorage[127.0.0.1:41815,DS-5630166f-67dd-45d5-9732-e0b0c75be018,DISK], DatanodeInfoWithStorage[127.0.0.1:43713,DS-a365ed64-1700-47c2-9ae3-d65a6928b223,DISK], DatanodeInfoWithStorage[127.0.0.1:34901,DS-fc1f0b65-d1e2-4962-ac71-9475e2b4e86b,DISK], DatanodeInfoWithStorage[127.0.0.1:42619,DS-7a847a95-6c22-4cff-a588-d6810a7aab00,DISK], DatanodeInfoWithStorage[127.0.0.1:43734,DS-548a70cf-ed7c-44d1-9c52-09cc47c879f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41123,DS-e394ba2e-1be4-4910-8f9b-40711bec5025,DISK], DatanodeInfoWithStorage[127.0.0.1:37640,DS-3314647c-f647-4c8d-b965-2ec4e4706d92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 0s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-303829013-172.17.0.17-1597342942320:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34378,DS-d1ba678b-e3e2-4208-a3a4-5ff31dcb43db,DISK], DatanodeInfoWithStorage[127.0.0.1:41839,DS-9127b2a1-f78e-40cd-9404-e891d8c88b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:40500,DS-66b2e5b7-5863-42d7-a124-85b9125482a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36311,DS-89a4fa59-5fc1-4365-a7b9-abfb62d8f87e,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-21ac73a2-01a7-4f29-93fb-33da14c3175f,DISK], DatanodeInfoWithStorage[127.0.0.1:39343,DS-1dc46daa-1ec0-4d9b-b8a2-739aab780b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33179,DS-64304358-6474-4097-869d-8fa71fe6018d,DISK], DatanodeInfoWithStorage[127.0.0.1:35336,DS-b884f5de-90d4-47e1-b228-ca5473f7a274,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-303829013-172.17.0.17-1597342942320:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34378,DS-d1ba678b-e3e2-4208-a3a4-5ff31dcb43db,DISK], DatanodeInfoWithStorage[127.0.0.1:41839,DS-9127b2a1-f78e-40cd-9404-e891d8c88b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:40500,DS-66b2e5b7-5863-42d7-a124-85b9125482a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36311,DS-89a4fa59-5fc1-4365-a7b9-abfb62d8f87e,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-21ac73a2-01a7-4f29-93fb-33da14c3175f,DISK], DatanodeInfoWithStorage[127.0.0.1:39343,DS-1dc46daa-1ec0-4d9b-b8a2-739aab780b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33179,DS-64304358-6474-4097-869d-8fa71fe6018d,DISK], DatanodeInfoWithStorage[127.0.0.1:35336,DS-b884f5de-90d4-47e1-b228-ca5473f7a274,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 0s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1178873985-172.17.0.17-1597343084966:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35341,DS-05bff0ba-8928-4722-8e95-3d183caf2ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:44225,DS-db772023-694e-41f9-a84b-1da94a42c577,DISK], DatanodeInfoWithStorage[127.0.0.1:35056,DS-53193963-7b04-413e-984f-5bc1b8cca733,DISK], DatanodeInfoWithStorage[127.0.0.1:45422,DS-23cf037b-3f95-4c9f-81e9-e772dd2d0f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:44553,DS-60a1ade2-c602-487d-89bf-cc4babeaa919,DISK], DatanodeInfoWithStorage[127.0.0.1:38425,DS-c074dca8-719c-4b8a-a05c-68badcb6ad1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42126,DS-eb8824b6-1223-4d66-84d0-038e4c3e6bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:34863,DS-d4e516be-637d-4570-83f3-8fc01055286d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1178873985-172.17.0.17-1597343084966:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35341,DS-05bff0ba-8928-4722-8e95-3d183caf2ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:44225,DS-db772023-694e-41f9-a84b-1da94a42c577,DISK], DatanodeInfoWithStorage[127.0.0.1:35056,DS-53193963-7b04-413e-984f-5bc1b8cca733,DISK], DatanodeInfoWithStorage[127.0.0.1:45422,DS-23cf037b-3f95-4c9f-81e9-e772dd2d0f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:44553,DS-60a1ade2-c602-487d-89bf-cc4babeaa919,DISK], DatanodeInfoWithStorage[127.0.0.1:38425,DS-c074dca8-719c-4b8a-a05c-68badcb6ad1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42126,DS-eb8824b6-1223-4d66-84d0-038e4c3e6bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:34863,DS-d4e516be-637d-4570-83f3-8fc01055286d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 0s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1672071669-172.17.0.17-1597343153972:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33945,DS-49324f9a-38b0-4bd1-9de6-31fab7898601,DISK], DatanodeInfoWithStorage[127.0.0.1:41814,DS-15ceac91-3581-4602-b0f3-87e0c8b23543,DISK], DatanodeInfoWithStorage[127.0.0.1:43441,DS-2bf835d4-4400-4a2b-b7fa-55a49a5b57c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38462,DS-0d2e9e07-d270-4e0b-a7b8-270e3f10e2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:32809,DS-c7087fab-6eef-461c-a53b-ae6e2943bb6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33466,DS-e7e2e3d6-1dd4-4d52-bbbe-e1dcfb4c38df,DISK], DatanodeInfoWithStorage[127.0.0.1:38139,DS-53a6eb6f-16e4-4cc4-a60c-393b21221981,DISK], DatanodeInfoWithStorage[127.0.0.1:33069,DS-e6842dd6-3a82-4fb9-8958-186ff870306e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1672071669-172.17.0.17-1597343153972:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33945,DS-49324f9a-38b0-4bd1-9de6-31fab7898601,DISK], DatanodeInfoWithStorage[127.0.0.1:41814,DS-15ceac91-3581-4602-b0f3-87e0c8b23543,DISK], DatanodeInfoWithStorage[127.0.0.1:43441,DS-2bf835d4-4400-4a2b-b7fa-55a49a5b57c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38462,DS-0d2e9e07-d270-4e0b-a7b8-270e3f10e2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:32809,DS-c7087fab-6eef-461c-a53b-ae6e2943bb6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33466,DS-e7e2e3d6-1dd4-4d52-bbbe-e1dcfb4c38df,DISK], DatanodeInfoWithStorage[127.0.0.1:38139,DS-53a6eb6f-16e4-4cc4-a60c-393b21221981,DISK], DatanodeInfoWithStorage[127.0.0.1:33069,DS-e6842dd6-3a82-4fb9-8958-186ff870306e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 0s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1317001937-172.17.0.17-1597343759280:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33552,DS-be9aed12-6860-4082-a071-484944f68bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:41008,DS-e2a86c67-4c9b-490a-9268-efa3a4e749b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36768,DS-37f01fe7-55de-4efa-ae05-a202ef2d46ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44850,DS-1c23b8a7-64bf-464e-aee8-24c0937b03e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33387,DS-debd24f2-3a7d-411b-92ba-b35aff487f30,DISK], DatanodeInfoWithStorage[127.0.0.1:41676,DS-13d552e4-3aed-414c-adab-903748f75bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:36374,DS-7cf49cfd-7623-41a8-aa87-ee637d308a42,DISK], DatanodeInfoWithStorage[127.0.0.1:42218,DS-c2681f92-1619-4c66-9859-5385aec21ad4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1317001937-172.17.0.17-1597343759280:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33552,DS-be9aed12-6860-4082-a071-484944f68bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:41008,DS-e2a86c67-4c9b-490a-9268-efa3a4e749b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36768,DS-37f01fe7-55de-4efa-ae05-a202ef2d46ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44850,DS-1c23b8a7-64bf-464e-aee8-24c0937b03e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33387,DS-debd24f2-3a7d-411b-92ba-b35aff487f30,DISK], DatanodeInfoWithStorage[127.0.0.1:41676,DS-13d552e4-3aed-414c-adab-903748f75bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:36374,DS-7cf49cfd-7623-41a8-aa87-ee637d308a42,DISK], DatanodeInfoWithStorage[127.0.0.1:42218,DS-c2681f92-1619-4c66-9859-5385aec21ad4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 0s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-605267177-172.17.0.17-1597344010064:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42394,DS-db065e4d-f39f-4845-b512-5162be1a98eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41342,DS-ef3454c7-9aa8-42e1-bcf6-b15990830e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39537,DS-509b6feb-f7e4-403b-896a-0d05a40bb884,DISK], DatanodeInfoWithStorage[127.0.0.1:41513,DS-d5bc593f-bad3-44e8-a916-d4fe8f459bae,DISK], DatanodeInfoWithStorage[127.0.0.1:35918,DS-46c9c7c1-2299-4753-b015-da9b1d24b6a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35623,DS-b8fca05b-41c4-46a7-8aaf-9cabd7ea5f44,DISK], DatanodeInfoWithStorage[127.0.0.1:36315,DS-4d2492b6-8a23-42e7-a088-132330ee5646,DISK], DatanodeInfoWithStorage[127.0.0.1:46195,DS-bafbc573-8b94-45ec-aeed-775aaa1392fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-605267177-172.17.0.17-1597344010064:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42394,DS-db065e4d-f39f-4845-b512-5162be1a98eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41342,DS-ef3454c7-9aa8-42e1-bcf6-b15990830e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39537,DS-509b6feb-f7e4-403b-896a-0d05a40bb884,DISK], DatanodeInfoWithStorage[127.0.0.1:41513,DS-d5bc593f-bad3-44e8-a916-d4fe8f459bae,DISK], DatanodeInfoWithStorage[127.0.0.1:35918,DS-46c9c7c1-2299-4753-b015-da9b1d24b6a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35623,DS-b8fca05b-41c4-46a7-8aaf-9cabd7ea5f44,DISK], DatanodeInfoWithStorage[127.0.0.1:36315,DS-4d2492b6-8a23-42e7-a088-132330ee5646,DISK], DatanodeInfoWithStorage[127.0.0.1:46195,DS-bafbc573-8b94-45ec-aeed-775aaa1392fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 0s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-103157958-172.17.0.17-1597344054226:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40684,DS-915a8790-b3cf-466b-b7d8-c20d864fde80,DISK], DatanodeInfoWithStorage[127.0.0.1:33512,DS-fcf2b686-ed05-49e9-8518-4e68e5d119d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34942,DS-dd4bf3c7-ac33-431e-9241-2426e6016d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:44511,DS-93b6240d-ead0-404d-a638-3bc8f6312d14,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-ba7ae67e-c9e5-40d3-929b-32d86c39311c,DISK], DatanodeInfoWithStorage[127.0.0.1:38424,DS-a6891345-0145-4854-9423-a714794109ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34277,DS-26f92094-4d8c-46ff-9b1d-aa3d9969895c,DISK], DatanodeInfoWithStorage[127.0.0.1:37890,DS-d0531236-e096-4532-94d0-cd3b7360bc50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-103157958-172.17.0.17-1597344054226:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40684,DS-915a8790-b3cf-466b-b7d8-c20d864fde80,DISK], DatanodeInfoWithStorage[127.0.0.1:33512,DS-fcf2b686-ed05-49e9-8518-4e68e5d119d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34942,DS-dd4bf3c7-ac33-431e-9241-2426e6016d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:44511,DS-93b6240d-ead0-404d-a638-3bc8f6312d14,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-ba7ae67e-c9e5-40d3-929b-32d86c39311c,DISK], DatanodeInfoWithStorage[127.0.0.1:38424,DS-a6891345-0145-4854-9423-a714794109ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34277,DS-26f92094-4d8c-46ff-9b1d-aa3d9969895c,DISK], DatanodeInfoWithStorage[127.0.0.1:37890,DS-d0531236-e096-4532-94d0-cd3b7360bc50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 0s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2080929588-172.17.0.17-1597344783849:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45562,DS-e171ee13-8ef6-42e2-a824-ffd3cc63d241,DISK], DatanodeInfoWithStorage[127.0.0.1:36824,DS-9314f8c4-3790-4537-a825-8299066e7074,DISK], DatanodeInfoWithStorage[127.0.0.1:33648,DS-3d4a3dd7-a09e-484c-8f88-c1e2b5b02f79,DISK], DatanodeInfoWithStorage[127.0.0.1:33923,DS-1bc28c91-1664-4c17-8a03-af32bb9e731e,DISK], DatanodeInfoWithStorage[127.0.0.1:34954,DS-3b231c0f-7c4b-44d1-a5c8-56cec6d087a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40166,DS-b99737f7-aff4-471c-b12e-f585818db8a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42766,DS-c3fefaab-8f3f-4c5e-a34c-81aa1cde1d99,DISK], DatanodeInfoWithStorage[127.0.0.1:33270,DS-6321db74-eb03-47ba-9704-da5dc285f918,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2080929588-172.17.0.17-1597344783849:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45562,DS-e171ee13-8ef6-42e2-a824-ffd3cc63d241,DISK], DatanodeInfoWithStorage[127.0.0.1:36824,DS-9314f8c4-3790-4537-a825-8299066e7074,DISK], DatanodeInfoWithStorage[127.0.0.1:33648,DS-3d4a3dd7-a09e-484c-8f88-c1e2b5b02f79,DISK], DatanodeInfoWithStorage[127.0.0.1:33923,DS-1bc28c91-1664-4c17-8a03-af32bb9e731e,DISK], DatanodeInfoWithStorage[127.0.0.1:34954,DS-3b231c0f-7c4b-44d1-a5c8-56cec6d087a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40166,DS-b99737f7-aff4-471c-b12e-f585818db8a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42766,DS-c3fefaab-8f3f-4c5e-a34c-81aa1cde1d99,DISK], DatanodeInfoWithStorage[127.0.0.1:33270,DS-6321db74-eb03-47ba-9704-da5dc285f918,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 0s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1214682534-172.17.0.17-1597345505833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38655,DS-a11a8ff2-5a69-47ab-8176-5df2859fa097,DISK], DatanodeInfoWithStorage[127.0.0.1:41214,DS-954a1989-3431-4546-b550-e0074ed199cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36220,DS-2a59ba31-91cd-43c0-a75c-06331f3bfff7,DISK], DatanodeInfoWithStorage[127.0.0.1:33876,DS-62a9255f-7d3f-4455-9bd5-36259ccfc7fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37143,DS-af8f7689-17d4-4887-9fba-eb1c6fb0d958,DISK], DatanodeInfoWithStorage[127.0.0.1:44305,DS-08719779-36e3-424b-8926-1e860996fe03,DISK], DatanodeInfoWithStorage[127.0.0.1:38595,DS-7a87dd50-9d6e-4304-bb78-e608029273c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42896,DS-6018fde8-07b6-4852-a3bf-832dcb0aa08a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1214682534-172.17.0.17-1597345505833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38655,DS-a11a8ff2-5a69-47ab-8176-5df2859fa097,DISK], DatanodeInfoWithStorage[127.0.0.1:41214,DS-954a1989-3431-4546-b550-e0074ed199cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36220,DS-2a59ba31-91cd-43c0-a75c-06331f3bfff7,DISK], DatanodeInfoWithStorage[127.0.0.1:33876,DS-62a9255f-7d3f-4455-9bd5-36259ccfc7fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37143,DS-af8f7689-17d4-4887-9fba-eb1c6fb0d958,DISK], DatanodeInfoWithStorage[127.0.0.1:44305,DS-08719779-36e3-424b-8926-1e860996fe03,DISK], DatanodeInfoWithStorage[127.0.0.1:38595,DS-7a87dd50-9d6e-4304-bb78-e608029273c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42896,DS-6018fde8-07b6-4852-a3bf-832dcb0aa08a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 0s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-457033637-172.17.0.17-1597345845177:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41367,DS-897bfd15-31de-47b6-a16d-a375426feb73,DISK], DatanodeInfoWithStorage[127.0.0.1:37690,DS-fb3a06fe-18dd-4ce1-a079-036794825daf,DISK], DatanodeInfoWithStorage[127.0.0.1:39608,DS-afcfa688-57f9-4723-9c76-67e0d70305c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46071,DS-9d6c6183-25d0-498e-a36d-9f06b73939f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36026,DS-996a9d4d-e797-4a9b-858e-b7902d1b3b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40582,DS-9a3ad8fa-dd82-41aa-b672-8f9493f35fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:37867,DS-131c26fe-f445-4205-9b95-ce65c607ee8a,DISK], DatanodeInfoWithStorage[127.0.0.1:38101,DS-eb99946b-3767-4d85-a230-13f37f660c56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-457033637-172.17.0.17-1597345845177:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41367,DS-897bfd15-31de-47b6-a16d-a375426feb73,DISK], DatanodeInfoWithStorage[127.0.0.1:37690,DS-fb3a06fe-18dd-4ce1-a079-036794825daf,DISK], DatanodeInfoWithStorage[127.0.0.1:39608,DS-afcfa688-57f9-4723-9c76-67e0d70305c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46071,DS-9d6c6183-25d0-498e-a36d-9f06b73939f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36026,DS-996a9d4d-e797-4a9b-858e-b7902d1b3b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40582,DS-9a3ad8fa-dd82-41aa-b672-8f9493f35fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:37867,DS-131c26fe-f445-4205-9b95-ce65c607ee8a,DISK], DatanodeInfoWithStorage[127.0.0.1:38101,DS-eb99946b-3767-4d85-a230-13f37f660c56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5746
