reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2115983222-172.17.0.6-1597335971271:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44900,DS-370ca036-d573-4081-a74a-6f673b265cba,DISK], DatanodeInfoWithStorage[127.0.0.1:36947,DS-76ca78db-b4e1-4485-81d1-b1b3dc0e488d,DISK], DatanodeInfoWithStorage[127.0.0.1:36404,DS-1f30b7b9-4921-497d-a213-70091cebbc44,DISK], DatanodeInfoWithStorage[127.0.0.1:37536,DS-b7f41a74-694c-4892-a32a-79f9c9e50a94,DISK], DatanodeInfoWithStorage[127.0.0.1:42707,DS-54a084ba-7358-4bb5-b734-2725b40e0df7,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-b123e409-3c14-4542-943b-dfec7d971e65,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-09810e1a-3a16-4d5a-bdf0-e356d3118994,DISK], DatanodeInfoWithStorage[127.0.0.1:33410,DS-4ea29723-97d4-4500-9767-b1925964bb8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2115983222-172.17.0.6-1597335971271:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44900,DS-370ca036-d573-4081-a74a-6f673b265cba,DISK], DatanodeInfoWithStorage[127.0.0.1:36947,DS-76ca78db-b4e1-4485-81d1-b1b3dc0e488d,DISK], DatanodeInfoWithStorage[127.0.0.1:36404,DS-1f30b7b9-4921-497d-a213-70091cebbc44,DISK], DatanodeInfoWithStorage[127.0.0.1:37536,DS-b7f41a74-694c-4892-a32a-79f9c9e50a94,DISK], DatanodeInfoWithStorage[127.0.0.1:42707,DS-54a084ba-7358-4bb5-b734-2725b40e0df7,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-b123e409-3c14-4542-943b-dfec7d971e65,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-09810e1a-3a16-4d5a-bdf0-e356d3118994,DISK], DatanodeInfoWithStorage[127.0.0.1:33410,DS-4ea29723-97d4-4500-9767-b1925964bb8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-78471371-172.17.0.6-1597336069671:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35003,DS-18b61452-c10e-4df4-aee3-2c18c618d1d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36021,DS-10e40d24-8c1b-4557-9a82-8c37ceb43f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:35338,DS-e023b502-fdc8-4825-9ef0-e3ac142f614e,DISK], DatanodeInfoWithStorage[127.0.0.1:38551,DS-7d8a06bf-f6fd-422b-b31e-edc2b48d9b61,DISK], DatanodeInfoWithStorage[127.0.0.1:44910,DS-a744842a-40e6-4705-8c74-14d65c716d90,DISK], DatanodeInfoWithStorage[127.0.0.1:36221,DS-9e809f9c-60c9-45b0-9d1d-77f571316069,DISK], DatanodeInfoWithStorage[127.0.0.1:37301,DS-788816ac-ebab-48c2-9ebd-14dd9db9ed47,DISK], DatanodeInfoWithStorage[127.0.0.1:37176,DS-c1caade3-9d84-411a-96d7-227d944c6977,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-78471371-172.17.0.6-1597336069671:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35003,DS-18b61452-c10e-4df4-aee3-2c18c618d1d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36021,DS-10e40d24-8c1b-4557-9a82-8c37ceb43f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:35338,DS-e023b502-fdc8-4825-9ef0-e3ac142f614e,DISK], DatanodeInfoWithStorage[127.0.0.1:38551,DS-7d8a06bf-f6fd-422b-b31e-edc2b48d9b61,DISK], DatanodeInfoWithStorage[127.0.0.1:44910,DS-a744842a-40e6-4705-8c74-14d65c716d90,DISK], DatanodeInfoWithStorage[127.0.0.1:36221,DS-9e809f9c-60c9-45b0-9d1d-77f571316069,DISK], DatanodeInfoWithStorage[127.0.0.1:37301,DS-788816ac-ebab-48c2-9ebd-14dd9db9ed47,DISK], DatanodeInfoWithStorage[127.0.0.1:37176,DS-c1caade3-9d84-411a-96d7-227d944c6977,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-208247097-172.17.0.6-1597336429177:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34271,DS-0c0eb5a3-8a6f-4c2e-ac21-7fae4967c90a,DISK], DatanodeInfoWithStorage[127.0.0.1:40683,DS-3485c808-84f5-4709-a51d-8c07680481df,DISK], DatanodeInfoWithStorage[127.0.0.1:35467,DS-1427adb7-9d29-44bd-88ec-c9d97e53fa36,DISK], DatanodeInfoWithStorage[127.0.0.1:40880,DS-0eb4fe92-59cf-4b6b-9486-ef86cb896ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:37619,DS-986f9b88-1e89-4f22-9f93-d7acc1854b59,DISK], DatanodeInfoWithStorage[127.0.0.1:39238,DS-e67869ae-7d3a-4f54-9b3d-32314ff5c1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-bf251fa0-41eb-4572-9ae3-847ef8a21d29,DISK], DatanodeInfoWithStorage[127.0.0.1:34889,DS-c9bac2d2-3d55-4d29-a61c-7b2cdd68a964,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-208247097-172.17.0.6-1597336429177:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34271,DS-0c0eb5a3-8a6f-4c2e-ac21-7fae4967c90a,DISK], DatanodeInfoWithStorage[127.0.0.1:40683,DS-3485c808-84f5-4709-a51d-8c07680481df,DISK], DatanodeInfoWithStorage[127.0.0.1:35467,DS-1427adb7-9d29-44bd-88ec-c9d97e53fa36,DISK], DatanodeInfoWithStorage[127.0.0.1:40880,DS-0eb4fe92-59cf-4b6b-9486-ef86cb896ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:37619,DS-986f9b88-1e89-4f22-9f93-d7acc1854b59,DISK], DatanodeInfoWithStorage[127.0.0.1:39238,DS-e67869ae-7d3a-4f54-9b3d-32314ff5c1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-bf251fa0-41eb-4572-9ae3-847ef8a21d29,DISK], DatanodeInfoWithStorage[127.0.0.1:34889,DS-c9bac2d2-3d55-4d29-a61c-7b2cdd68a964,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1282509287-172.17.0.6-1597336510597:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41947,DS-0772a817-3020-48db-9836-db0948b454c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45963,DS-1841e59d-4966-4abf-a114-2cd828d30480,DISK], DatanodeInfoWithStorage[127.0.0.1:45505,DS-4d4c79b5-d960-4ed6-a944-d2ced417f5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41419,DS-076c16c0-effe-4943-915b-3ae48cc1c7b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43111,DS-985caa39-4a07-4b28-9e71-689565a071ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45215,DS-d531b746-181d-4bcf-8d0c-9bb61c98707d,DISK], DatanodeInfoWithStorage[127.0.0.1:37965,DS-0556a945-3af2-437c-b194-135e76220829,DISK], DatanodeInfoWithStorage[127.0.0.1:40878,DS-753944e2-b44f-4b83-a089-268e1de35c3e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1282509287-172.17.0.6-1597336510597:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41947,DS-0772a817-3020-48db-9836-db0948b454c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45963,DS-1841e59d-4966-4abf-a114-2cd828d30480,DISK], DatanodeInfoWithStorage[127.0.0.1:45505,DS-4d4c79b5-d960-4ed6-a944-d2ced417f5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41419,DS-076c16c0-effe-4943-915b-3ae48cc1c7b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43111,DS-985caa39-4a07-4b28-9e71-689565a071ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45215,DS-d531b746-181d-4bcf-8d0c-9bb61c98707d,DISK], DatanodeInfoWithStorage[127.0.0.1:37965,DS-0556a945-3af2-437c-b194-135e76220829,DISK], DatanodeInfoWithStorage[127.0.0.1:40878,DS-753944e2-b44f-4b83-a089-268e1de35c3e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1903506296-172.17.0.6-1597336694593:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37936,DS-9233b571-48ce-4827-b9ba-0cf6c350db9c,DISK], DatanodeInfoWithStorage[127.0.0.1:34432,DS-0b785325-b64c-4c64-ac3c-f632974024a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42152,DS-8da85042-1fd3-438b-9bf8-be213692ad29,DISK], DatanodeInfoWithStorage[127.0.0.1:46810,DS-33b69c5c-45b8-47d4-a99c-75d0a48850f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33104,DS-81655869-045e-4742-a34b-1d5d74b6b5e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42984,DS-4f49cc7a-cac4-4545-a2d9-807649020117,DISK], DatanodeInfoWithStorage[127.0.0.1:34531,DS-c1be0a00-8ad0-4e6c-a657-0cf7516c6478,DISK], DatanodeInfoWithStorage[127.0.0.1:43051,DS-162e609d-761b-45d6-a764-e61599cd7cde,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1903506296-172.17.0.6-1597336694593:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37936,DS-9233b571-48ce-4827-b9ba-0cf6c350db9c,DISK], DatanodeInfoWithStorage[127.0.0.1:34432,DS-0b785325-b64c-4c64-ac3c-f632974024a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42152,DS-8da85042-1fd3-438b-9bf8-be213692ad29,DISK], DatanodeInfoWithStorage[127.0.0.1:46810,DS-33b69c5c-45b8-47d4-a99c-75d0a48850f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33104,DS-81655869-045e-4742-a34b-1d5d74b6b5e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42984,DS-4f49cc7a-cac4-4545-a2d9-807649020117,DISK], DatanodeInfoWithStorage[127.0.0.1:34531,DS-c1be0a00-8ad0-4e6c-a657-0cf7516c6478,DISK], DatanodeInfoWithStorage[127.0.0.1:43051,DS-162e609d-761b-45d6-a764-e61599cd7cde,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1045763411-172.17.0.6-1597336737884:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40804,DS-8432866c-c7f2-4a64-a931-4435c3f86eac,DISK], DatanodeInfoWithStorage[127.0.0.1:33732,DS-2742ed40-8516-40a3-9f35-b2771326edfb,DISK], DatanodeInfoWithStorage[127.0.0.1:45660,DS-57a46daf-1bfe-4cef-87ee-2095f9407c58,DISK], DatanodeInfoWithStorage[127.0.0.1:45891,DS-7cabf5c8-d861-44aa-9e9e-53e3c6640dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:41707,DS-66368eba-b04b-455a-b6bd-86a30bc89fef,DISK], DatanodeInfoWithStorage[127.0.0.1:37066,DS-59337c5a-b42e-4d87-b324-9a5767ded4f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33064,DS-91a29a17-9d92-4aed-95b4-4f39862a098d,DISK], DatanodeInfoWithStorage[127.0.0.1:46583,DS-93dda7bc-5614-43d5-9e40-633425b7b595,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1045763411-172.17.0.6-1597336737884:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40804,DS-8432866c-c7f2-4a64-a931-4435c3f86eac,DISK], DatanodeInfoWithStorage[127.0.0.1:33732,DS-2742ed40-8516-40a3-9f35-b2771326edfb,DISK], DatanodeInfoWithStorage[127.0.0.1:45660,DS-57a46daf-1bfe-4cef-87ee-2095f9407c58,DISK], DatanodeInfoWithStorage[127.0.0.1:45891,DS-7cabf5c8-d861-44aa-9e9e-53e3c6640dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:41707,DS-66368eba-b04b-455a-b6bd-86a30bc89fef,DISK], DatanodeInfoWithStorage[127.0.0.1:37066,DS-59337c5a-b42e-4d87-b324-9a5767ded4f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33064,DS-91a29a17-9d92-4aed-95b4-4f39862a098d,DISK], DatanodeInfoWithStorage[127.0.0.1:46583,DS-93dda7bc-5614-43d5-9e40-633425b7b595,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2029542361-172.17.0.6-1597336827322:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44230,DS-f84d481a-d609-4308-b24c-04fffb1423fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40211,DS-38d8ebe8-6c25-47e6-83a8-df07dc3d6c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42204,DS-18b77a1f-87c4-4ba3-9dd8-1de8e55c2f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:42943,DS-c22a84b5-aace-4db6-beab-6dfa1def6d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:46554,DS-69dd11ec-ba4b-419e-a1b8-476be4f223c5,DISK], DatanodeInfoWithStorage[127.0.0.1:32917,DS-18b236ee-8a6e-45c8-a019-8e3d045e8ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:37736,DS-410264b6-bdcc-4d0d-8d01-2a4b03a02821,DISK], DatanodeInfoWithStorage[127.0.0.1:38741,DS-ede16bd0-6a48-4e77-a97c-54a6388d9c9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2029542361-172.17.0.6-1597336827322:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44230,DS-f84d481a-d609-4308-b24c-04fffb1423fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40211,DS-38d8ebe8-6c25-47e6-83a8-df07dc3d6c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42204,DS-18b77a1f-87c4-4ba3-9dd8-1de8e55c2f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:42943,DS-c22a84b5-aace-4db6-beab-6dfa1def6d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:46554,DS-69dd11ec-ba4b-419e-a1b8-476be4f223c5,DISK], DatanodeInfoWithStorage[127.0.0.1:32917,DS-18b236ee-8a6e-45c8-a019-8e3d045e8ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:37736,DS-410264b6-bdcc-4d0d-8d01-2a4b03a02821,DISK], DatanodeInfoWithStorage[127.0.0.1:38741,DS-ede16bd0-6a48-4e77-a97c-54a6388d9c9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-645687379-172.17.0.6-1597336903443:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46824,DS-46fb48fd-19f8-40a1-9162-7217ec564bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:40238,DS-37112e53-ec34-48bd-801c-20252a44bda5,DISK], DatanodeInfoWithStorage[127.0.0.1:42178,DS-c2d36b8f-2c14-410a-95d0-9fa8cb1d16cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40897,DS-b2983a49-dc8a-42bc-bae9-67d58b930caa,DISK], DatanodeInfoWithStorage[127.0.0.1:43217,DS-ce82da55-945d-417c-a317-4f07de5c96b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38935,DS-f5d63876-0819-45b0-b0f9-99016f8c066a,DISK], DatanodeInfoWithStorage[127.0.0.1:43710,DS-14bd9350-7fca-45f4-8596-23c1327de773,DISK], DatanodeInfoWithStorage[127.0.0.1:43939,DS-49b6c72e-2800-4fb9-a348-e4a19ee06d11,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-645687379-172.17.0.6-1597336903443:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46824,DS-46fb48fd-19f8-40a1-9162-7217ec564bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:40238,DS-37112e53-ec34-48bd-801c-20252a44bda5,DISK], DatanodeInfoWithStorage[127.0.0.1:42178,DS-c2d36b8f-2c14-410a-95d0-9fa8cb1d16cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40897,DS-b2983a49-dc8a-42bc-bae9-67d58b930caa,DISK], DatanodeInfoWithStorage[127.0.0.1:43217,DS-ce82da55-945d-417c-a317-4f07de5c96b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38935,DS-f5d63876-0819-45b0-b0f9-99016f8c066a,DISK], DatanodeInfoWithStorage[127.0.0.1:43710,DS-14bd9350-7fca-45f4-8596-23c1327de773,DISK], DatanodeInfoWithStorage[127.0.0.1:43939,DS-49b6c72e-2800-4fb9-a348-e4a19ee06d11,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2053624159-172.17.0.6-1597337050448:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45022,DS-9994c1af-03a5-461c-9a75-f3cbab9e31e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40294,DS-bde5dd09-7ecf-4847-a393-429f1e0692a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46388,DS-9db12f88-0dfe-4fc5-8239-9c339b0dc620,DISK], DatanodeInfoWithStorage[127.0.0.1:45025,DS-c0b616a3-ff3a-4425-bec0-7007ce78425b,DISK], DatanodeInfoWithStorage[127.0.0.1:36195,DS-6d2cf747-a859-447d-8439-10be9519af61,DISK], DatanodeInfoWithStorage[127.0.0.1:46078,DS-59cb6d87-3779-4cdd-8c58-3b9eba9ad9d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33367,DS-8759bf17-1d4c-4d8c-836c-d53692339d61,DISK], DatanodeInfoWithStorage[127.0.0.1:39435,DS-56e8bcfb-83bf-4758-9b70-23f45248471e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2053624159-172.17.0.6-1597337050448:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45022,DS-9994c1af-03a5-461c-9a75-f3cbab9e31e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40294,DS-bde5dd09-7ecf-4847-a393-429f1e0692a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46388,DS-9db12f88-0dfe-4fc5-8239-9c339b0dc620,DISK], DatanodeInfoWithStorage[127.0.0.1:45025,DS-c0b616a3-ff3a-4425-bec0-7007ce78425b,DISK], DatanodeInfoWithStorage[127.0.0.1:36195,DS-6d2cf747-a859-447d-8439-10be9519af61,DISK], DatanodeInfoWithStorage[127.0.0.1:46078,DS-59cb6d87-3779-4cdd-8c58-3b9eba9ad9d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33367,DS-8759bf17-1d4c-4d8c-836c-d53692339d61,DISK], DatanodeInfoWithStorage[127.0.0.1:39435,DS-56e8bcfb-83bf-4758-9b70-23f45248471e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-203317850-172.17.0.6-1597337142206:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35683,DS-f9f5b6e3-2a84-4674-a85e-d03f15c1bc34,DISK], DatanodeInfoWithStorage[127.0.0.1:39415,DS-a84fb913-a4fa-4767-b3ba-088697f3c557,DISK], DatanodeInfoWithStorage[127.0.0.1:39537,DS-05b69927-e188-488c-82ab-71511e08a77c,DISK], DatanodeInfoWithStorage[127.0.0.1:37269,DS-be341554-689b-4234-9065-35f41bb84f02,DISK], DatanodeInfoWithStorage[127.0.0.1:37950,DS-191ac786-6758-409a-84c8-af2ce14371f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36723,DS-e53835df-a755-4974-8210-57a7714a18db,DISK], DatanodeInfoWithStorage[127.0.0.1:38215,DS-da57a073-bc68-4dec-973b-0cfb97e8f949,DISK], DatanodeInfoWithStorage[127.0.0.1:43891,DS-adb39dcd-f2bd-440e-a215-890711452088,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-203317850-172.17.0.6-1597337142206:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35683,DS-f9f5b6e3-2a84-4674-a85e-d03f15c1bc34,DISK], DatanodeInfoWithStorage[127.0.0.1:39415,DS-a84fb913-a4fa-4767-b3ba-088697f3c557,DISK], DatanodeInfoWithStorage[127.0.0.1:39537,DS-05b69927-e188-488c-82ab-71511e08a77c,DISK], DatanodeInfoWithStorage[127.0.0.1:37269,DS-be341554-689b-4234-9065-35f41bb84f02,DISK], DatanodeInfoWithStorage[127.0.0.1:37950,DS-191ac786-6758-409a-84c8-af2ce14371f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36723,DS-e53835df-a755-4974-8210-57a7714a18db,DISK], DatanodeInfoWithStorage[127.0.0.1:38215,DS-da57a073-bc68-4dec-973b-0cfb97e8f949,DISK], DatanodeInfoWithStorage[127.0.0.1:43891,DS-adb39dcd-f2bd-440e-a215-890711452088,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-502443212-172.17.0.6-1597337337468:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39317,DS-46b49201-4fe4-4d18-befb-c668d81b91b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41591,DS-c97cd9b6-0af4-4d73-868b-13bae0157999,DISK], DatanodeInfoWithStorage[127.0.0.1:37512,DS-4f3177a5-ae6b-4cce-89b1-d323b7361442,DISK], DatanodeInfoWithStorage[127.0.0.1:42814,DS-c3e0c1c3-6caa-4d8b-8426-bfd78ba7334f,DISK], DatanodeInfoWithStorage[127.0.0.1:38171,DS-f350391a-6b1b-4c94-aa0c-d384ce3756c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40770,DS-4437f4b8-de74-4459-98fe-599b28fcfee7,DISK], DatanodeInfoWithStorage[127.0.0.1:35252,DS-c35ff0bb-ce91-4f8b-a66e-86377c96ef8a,DISK], DatanodeInfoWithStorage[127.0.0.1:46321,DS-98976c05-722a-4e94-80f7-5a489c418dc8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-502443212-172.17.0.6-1597337337468:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39317,DS-46b49201-4fe4-4d18-befb-c668d81b91b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41591,DS-c97cd9b6-0af4-4d73-868b-13bae0157999,DISK], DatanodeInfoWithStorage[127.0.0.1:37512,DS-4f3177a5-ae6b-4cce-89b1-d323b7361442,DISK], DatanodeInfoWithStorage[127.0.0.1:42814,DS-c3e0c1c3-6caa-4d8b-8426-bfd78ba7334f,DISK], DatanodeInfoWithStorage[127.0.0.1:38171,DS-f350391a-6b1b-4c94-aa0c-d384ce3756c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40770,DS-4437f4b8-de74-4459-98fe-599b28fcfee7,DISK], DatanodeInfoWithStorage[127.0.0.1:35252,DS-c35ff0bb-ce91-4f8b-a66e-86377c96ef8a,DISK], DatanodeInfoWithStorage[127.0.0.1:46321,DS-98976c05-722a-4e94-80f7-5a489c418dc8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-818702113-172.17.0.6-1597337475195:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35607,DS-57181140-cfdd-48aa-a5ff-73da7e9fb922,DISK], DatanodeInfoWithStorage[127.0.0.1:43837,DS-7b7e7542-69af-457e-bd35-ee7e68bd4f36,DISK], DatanodeInfoWithStorage[127.0.0.1:33799,DS-e2177acc-ad7f-473a-b3c5-e4c76757c55e,DISK], DatanodeInfoWithStorage[127.0.0.1:44926,DS-546419f5-3f31-4d66-9dc9-e185f9038d02,DISK], DatanodeInfoWithStorage[127.0.0.1:45713,DS-ed0099b7-50a5-4f01-bbb3-b957bded066d,DISK], DatanodeInfoWithStorage[127.0.0.1:37478,DS-4a3cca89-42d4-4fba-a28a-d91ec3b51ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:38644,DS-318a8b31-2471-4d58-9928-e61ccc0f476f,DISK], DatanodeInfoWithStorage[127.0.0.1:42047,DS-ca247d72-4edd-4697-b3da-c38c3c42fbb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-818702113-172.17.0.6-1597337475195:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35607,DS-57181140-cfdd-48aa-a5ff-73da7e9fb922,DISK], DatanodeInfoWithStorage[127.0.0.1:43837,DS-7b7e7542-69af-457e-bd35-ee7e68bd4f36,DISK], DatanodeInfoWithStorage[127.0.0.1:33799,DS-e2177acc-ad7f-473a-b3c5-e4c76757c55e,DISK], DatanodeInfoWithStorage[127.0.0.1:44926,DS-546419f5-3f31-4d66-9dc9-e185f9038d02,DISK], DatanodeInfoWithStorage[127.0.0.1:45713,DS-ed0099b7-50a5-4f01-bbb3-b957bded066d,DISK], DatanodeInfoWithStorage[127.0.0.1:37478,DS-4a3cca89-42d4-4fba-a28a-d91ec3b51ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:38644,DS-318a8b31-2471-4d58-9928-e61ccc0f476f,DISK], DatanodeInfoWithStorage[127.0.0.1:42047,DS-ca247d72-4edd-4697-b3da-c38c3c42fbb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-989879571-172.17.0.6-1597337745879:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34840,DS-f199e384-6e9d-49a1-911e-dee850152561,DISK], DatanodeInfoWithStorage[127.0.0.1:45129,DS-a3ffd880-79fd-460f-b91f-6efbbebb323d,DISK], DatanodeInfoWithStorage[127.0.0.1:33882,DS-f68ed0ed-0f53-4754-894e-d72d163949d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37631,DS-b99e12c7-935b-4810-9683-88b14f18befc,DISK], DatanodeInfoWithStorage[127.0.0.1:34245,DS-d0c6d3a8-e676-403b-a0dd-1e08a8f9f697,DISK], DatanodeInfoWithStorage[127.0.0.1:38475,DS-2f9c8eaa-f16e-4b05-b34b-7de80497b404,DISK], DatanodeInfoWithStorage[127.0.0.1:44524,DS-f488b391-99ab-4270-b223-34dc65554d18,DISK], DatanodeInfoWithStorage[127.0.0.1:41100,DS-405e28a9-0e2c-4174-b44b-c263ab9932bb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-989879571-172.17.0.6-1597337745879:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34840,DS-f199e384-6e9d-49a1-911e-dee850152561,DISK], DatanodeInfoWithStorage[127.0.0.1:45129,DS-a3ffd880-79fd-460f-b91f-6efbbebb323d,DISK], DatanodeInfoWithStorage[127.0.0.1:33882,DS-f68ed0ed-0f53-4754-894e-d72d163949d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37631,DS-b99e12c7-935b-4810-9683-88b14f18befc,DISK], DatanodeInfoWithStorage[127.0.0.1:34245,DS-d0c6d3a8-e676-403b-a0dd-1e08a8f9f697,DISK], DatanodeInfoWithStorage[127.0.0.1:38475,DS-2f9c8eaa-f16e-4b05-b34b-7de80497b404,DISK], DatanodeInfoWithStorage[127.0.0.1:44524,DS-f488b391-99ab-4270-b223-34dc65554d18,DISK], DatanodeInfoWithStorage[127.0.0.1:41100,DS-405e28a9-0e2c-4174-b44b-c263ab9932bb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1428252969-172.17.0.6-1597337975956:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45922,DS-c2fda540-8165-497b-9ac9-0a2ccb62d258,DISK], DatanodeInfoWithStorage[127.0.0.1:39088,DS-a0f9eef3-a89d-409e-acfe-597dbc14f3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34142,DS-8e75e82c-b477-4314-af8a-880fc6e408f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37025,DS-f6f4899f-896a-4c6f-b884-b786917e9d25,DISK], DatanodeInfoWithStorage[127.0.0.1:41012,DS-9cf500a4-0903-461b-a47f-4215e0957c38,DISK], DatanodeInfoWithStorage[127.0.0.1:45212,DS-be0cee0e-962b-4db8-938b-8784ee3b3580,DISK], DatanodeInfoWithStorage[127.0.0.1:45546,DS-d955aa87-b6f8-4e0c-b44e-ce4fb663e4dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33902,DS-0cd84afa-020e-4835-b815-9b87b877cc4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1428252969-172.17.0.6-1597337975956:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45922,DS-c2fda540-8165-497b-9ac9-0a2ccb62d258,DISK], DatanodeInfoWithStorage[127.0.0.1:39088,DS-a0f9eef3-a89d-409e-acfe-597dbc14f3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34142,DS-8e75e82c-b477-4314-af8a-880fc6e408f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37025,DS-f6f4899f-896a-4c6f-b884-b786917e9d25,DISK], DatanodeInfoWithStorage[127.0.0.1:41012,DS-9cf500a4-0903-461b-a47f-4215e0957c38,DISK], DatanodeInfoWithStorage[127.0.0.1:45212,DS-be0cee0e-962b-4db8-938b-8784ee3b3580,DISK], DatanodeInfoWithStorage[127.0.0.1:45546,DS-d955aa87-b6f8-4e0c-b44e-ce4fb663e4dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33902,DS-0cd84afa-020e-4835-b815-9b87b877cc4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-698886622-172.17.0.6-1597338259829:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38998,DS-e75ce112-1264-4f6a-9020-b2d90c286ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:44298,DS-97d41835-4a90-4284-9d40-8517374c1f60,DISK], DatanodeInfoWithStorage[127.0.0.1:43287,DS-7e68eae6-08db-4e72-bfcd-60bb8813a59f,DISK], DatanodeInfoWithStorage[127.0.0.1:33955,DS-cf00e6b6-a069-407c-81be-d093cc900ada,DISK], DatanodeInfoWithStorage[127.0.0.1:35058,DS-161d56dd-8197-4ba8-ba7f-ee8d3b3c7773,DISK], DatanodeInfoWithStorage[127.0.0.1:40297,DS-3e2aea61-4ced-44db-9cfb-1d2942ce9383,DISK], DatanodeInfoWithStorage[127.0.0.1:41849,DS-8d56e7c6-5c94-4ec9-a270-f0a37f6aa5fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45994,DS-96bc25a2-73b5-4e71-8bd3-40905a679ae6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-698886622-172.17.0.6-1597338259829:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38998,DS-e75ce112-1264-4f6a-9020-b2d90c286ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:44298,DS-97d41835-4a90-4284-9d40-8517374c1f60,DISK], DatanodeInfoWithStorage[127.0.0.1:43287,DS-7e68eae6-08db-4e72-bfcd-60bb8813a59f,DISK], DatanodeInfoWithStorage[127.0.0.1:33955,DS-cf00e6b6-a069-407c-81be-d093cc900ada,DISK], DatanodeInfoWithStorage[127.0.0.1:35058,DS-161d56dd-8197-4ba8-ba7f-ee8d3b3c7773,DISK], DatanodeInfoWithStorage[127.0.0.1:40297,DS-3e2aea61-4ced-44db-9cfb-1d2942ce9383,DISK], DatanodeInfoWithStorage[127.0.0.1:41849,DS-8d56e7c6-5c94-4ec9-a270-f0a37f6aa5fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45994,DS-96bc25a2-73b5-4e71-8bd3-40905a679ae6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1055983695-172.17.0.6-1597338300352:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43214,DS-cfbe40e6-5b23-4c63-8872-539244caca8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39747,DS-1fe01a23-8dc0-4d93-89fc-0caa352079e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34279,DS-8c3603dc-4262-4e80-8efd-e93eb87f41b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34263,DS-5a738276-84f8-450e-8357-dcc3362855f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44045,DS-6eeef438-c498-485b-90ff-453e676d72ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34636,DS-1ed99efa-a59e-417b-8666-ad1b7a023f22,DISK], DatanodeInfoWithStorage[127.0.0.1:41323,DS-33a20b30-c896-4aa0-939f-dc2a979fd01b,DISK], DatanodeInfoWithStorage[127.0.0.1:45770,DS-add9bce8-1dd6-4eca-884e-62fc7ec8a23c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1055983695-172.17.0.6-1597338300352:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43214,DS-cfbe40e6-5b23-4c63-8872-539244caca8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39747,DS-1fe01a23-8dc0-4d93-89fc-0caa352079e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34279,DS-8c3603dc-4262-4e80-8efd-e93eb87f41b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34263,DS-5a738276-84f8-450e-8357-dcc3362855f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44045,DS-6eeef438-c498-485b-90ff-453e676d72ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34636,DS-1ed99efa-a59e-417b-8666-ad1b7a023f22,DISK], DatanodeInfoWithStorage[127.0.0.1:41323,DS-33a20b30-c896-4aa0-939f-dc2a979fd01b,DISK], DatanodeInfoWithStorage[127.0.0.1:45770,DS-add9bce8-1dd6-4eca-884e-62fc7ec8a23c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-639575962-172.17.0.6-1597338582775:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45401,DS-06c61b49-78a2-40be-a8f9-e694a49a2c82,DISK], DatanodeInfoWithStorage[127.0.0.1:37329,DS-b9a7c22c-078f-4036-b7be-94b2edcfcba9,DISK], DatanodeInfoWithStorage[127.0.0.1:41406,DS-561355f9-cff8-49b9-a463-b91310f63835,DISK], DatanodeInfoWithStorage[127.0.0.1:45395,DS-94bd1cb0-04c0-4647-9734-a17c09a1b164,DISK], DatanodeInfoWithStorage[127.0.0.1:44850,DS-442fa7a2-f5ac-4b58-bea6-d98167694544,DISK], DatanodeInfoWithStorage[127.0.0.1:34727,DS-470ec895-8fe5-476a-b712-569afad1f0fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38113,DS-a386a87c-30d0-48bb-9c0d-ffdfbdd7bbd7,DISK], DatanodeInfoWithStorage[127.0.0.1:44376,DS-17f58efd-afc0-4e26-bf69-b2693ea429f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-639575962-172.17.0.6-1597338582775:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45401,DS-06c61b49-78a2-40be-a8f9-e694a49a2c82,DISK], DatanodeInfoWithStorage[127.0.0.1:37329,DS-b9a7c22c-078f-4036-b7be-94b2edcfcba9,DISK], DatanodeInfoWithStorage[127.0.0.1:41406,DS-561355f9-cff8-49b9-a463-b91310f63835,DISK], DatanodeInfoWithStorage[127.0.0.1:45395,DS-94bd1cb0-04c0-4647-9734-a17c09a1b164,DISK], DatanodeInfoWithStorage[127.0.0.1:44850,DS-442fa7a2-f5ac-4b58-bea6-d98167694544,DISK], DatanodeInfoWithStorage[127.0.0.1:34727,DS-470ec895-8fe5-476a-b712-569afad1f0fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38113,DS-a386a87c-30d0-48bb-9c0d-ffdfbdd7bbd7,DISK], DatanodeInfoWithStorage[127.0.0.1:44376,DS-17f58efd-afc0-4e26-bf69-b2693ea429f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2047384148-172.17.0.6-1597338630874:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37558,DS-5c96d9d3-0d9b-4144-a420-26f7b0c4089c,DISK], DatanodeInfoWithStorage[127.0.0.1:41709,DS-88ab20c3-e281-4f68-b19a-58626c1461e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45633,DS-be34071a-b8e9-4493-8e05-607cf6025d25,DISK], DatanodeInfoWithStorage[127.0.0.1:46096,DS-2ea4dc7d-0b75-4959-8c55-d82fdf6164d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40764,DS-db0545be-5c68-4f46-9033-e6e6b0e395f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45525,DS-6d279cb2-515d-488d-bd66-e903fc9b5eac,DISK], DatanodeInfoWithStorage[127.0.0.1:44873,DS-45d9f0a5-958e-4f67-9e96-7cbb588d1063,DISK], DatanodeInfoWithStorage[127.0.0.1:41635,DS-50b6cdf3-2b7b-4efd-b415-f3f4e3b9ab44,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2047384148-172.17.0.6-1597338630874:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37558,DS-5c96d9d3-0d9b-4144-a420-26f7b0c4089c,DISK], DatanodeInfoWithStorage[127.0.0.1:41709,DS-88ab20c3-e281-4f68-b19a-58626c1461e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45633,DS-be34071a-b8e9-4493-8e05-607cf6025d25,DISK], DatanodeInfoWithStorage[127.0.0.1:46096,DS-2ea4dc7d-0b75-4959-8c55-d82fdf6164d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40764,DS-db0545be-5c68-4f46-9033-e6e6b0e395f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45525,DS-6d279cb2-515d-488d-bd66-e903fc9b5eac,DISK], DatanodeInfoWithStorage[127.0.0.1:44873,DS-45d9f0a5-958e-4f67-9e96-7cbb588d1063,DISK], DatanodeInfoWithStorage[127.0.0.1:41635,DS-50b6cdf3-2b7b-4efd-b415-f3f4e3b9ab44,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1519574084-172.17.0.6-1597338811558:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36390,DS-a445e728-f74e-461c-8fa1-f85d8b378da2,DISK], DatanodeInfoWithStorage[127.0.0.1:38562,DS-55f3d754-bfb0-4c2a-8d17-cbd7a1700d37,DISK], DatanodeInfoWithStorage[127.0.0.1:46086,DS-5e580cd8-fba5-4ccc-9e46-ffb92f96c537,DISK], DatanodeInfoWithStorage[127.0.0.1:46631,DS-42fc9bfd-2baf-45d3-87de-1f1f606f1846,DISK], DatanodeInfoWithStorage[127.0.0.1:37092,DS-6375be2a-004f-48e2-956e-39f6dd06b0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38788,DS-04775b30-2ab9-497a-a0f5-38b75965719c,DISK], DatanodeInfoWithStorage[127.0.0.1:45258,DS-8928fc6f-6c08-443f-95f1-a28fa7470fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:42568,DS-dbd3f31b-e66d-4707-9918-bd47aa711bb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1519574084-172.17.0.6-1597338811558:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36390,DS-a445e728-f74e-461c-8fa1-f85d8b378da2,DISK], DatanodeInfoWithStorage[127.0.0.1:38562,DS-55f3d754-bfb0-4c2a-8d17-cbd7a1700d37,DISK], DatanodeInfoWithStorage[127.0.0.1:46086,DS-5e580cd8-fba5-4ccc-9e46-ffb92f96c537,DISK], DatanodeInfoWithStorage[127.0.0.1:46631,DS-42fc9bfd-2baf-45d3-87de-1f1f606f1846,DISK], DatanodeInfoWithStorage[127.0.0.1:37092,DS-6375be2a-004f-48e2-956e-39f6dd06b0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38788,DS-04775b30-2ab9-497a-a0f5-38b75965719c,DISK], DatanodeInfoWithStorage[127.0.0.1:45258,DS-8928fc6f-6c08-443f-95f1-a28fa7470fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:42568,DS-dbd3f31b-e66d-4707-9918-bd47aa711bb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1120546623-172.17.0.6-1597339233070:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39548,DS-98351933-6d57-49c5-82e1-dca14b2eb9ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33473,DS-9283a302-2e92-462b-a086-42316a4f26a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46041,DS-943b3a33-e423-4607-ac81-ee112cdc4a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:38095,DS-684cfc32-0bc8-4ffe-894c-f04f7eb1f5b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45223,DS-23e49f1a-ca8c-441e-993f-76f5520321c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33301,DS-1a93a05c-c58f-450b-a739-a82e590607d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45596,DS-789dde0a-83b9-4869-838a-5da195903dab,DISK], DatanodeInfoWithStorage[127.0.0.1:38784,DS-5598cef0-9263-472a-bcb0-22d04e7e53ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1120546623-172.17.0.6-1597339233070:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39548,DS-98351933-6d57-49c5-82e1-dca14b2eb9ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33473,DS-9283a302-2e92-462b-a086-42316a4f26a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46041,DS-943b3a33-e423-4607-ac81-ee112cdc4a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:38095,DS-684cfc32-0bc8-4ffe-894c-f04f7eb1f5b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45223,DS-23e49f1a-ca8c-441e-993f-76f5520321c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33301,DS-1a93a05c-c58f-450b-a739-a82e590607d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45596,DS-789dde0a-83b9-4869-838a-5da195903dab,DISK], DatanodeInfoWithStorage[127.0.0.1:38784,DS-5598cef0-9263-472a-bcb0-22d04e7e53ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1199162368-172.17.0.6-1597339329506:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33734,DS-251f6c4e-df6b-4b0c-a4d2-38ea49dd6e93,DISK], DatanodeInfoWithStorage[127.0.0.1:39091,DS-6863501c-f1ce-4eee-942d-0af990784fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:37147,DS-70542e52-c53e-49ec-a655-d0ce3e14c8ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44147,DS-957f4580-cf5d-47ab-9380-5404d2768758,DISK], DatanodeInfoWithStorage[127.0.0.1:43543,DS-7eafab7c-d807-4d75-90d5-4822ef9fc263,DISK], DatanodeInfoWithStorage[127.0.0.1:46171,DS-e01a007b-33a2-4f2e-b52d-6f6445dc3b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:41907,DS-d5715f35-2a75-411e-9a2d-c7a95aecd88d,DISK], DatanodeInfoWithStorage[127.0.0.1:40449,DS-5094da59-ad08-434a-b073-0a081d61df8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1199162368-172.17.0.6-1597339329506:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33734,DS-251f6c4e-df6b-4b0c-a4d2-38ea49dd6e93,DISK], DatanodeInfoWithStorage[127.0.0.1:39091,DS-6863501c-f1ce-4eee-942d-0af990784fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:37147,DS-70542e52-c53e-49ec-a655-d0ce3e14c8ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44147,DS-957f4580-cf5d-47ab-9380-5404d2768758,DISK], DatanodeInfoWithStorage[127.0.0.1:43543,DS-7eafab7c-d807-4d75-90d5-4822ef9fc263,DISK], DatanodeInfoWithStorage[127.0.0.1:46171,DS-e01a007b-33a2-4f2e-b52d-6f6445dc3b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:41907,DS-d5715f35-2a75-411e-9a2d-c7a95aecd88d,DISK], DatanodeInfoWithStorage[127.0.0.1:40449,DS-5094da59-ad08-434a-b073-0a081d61df8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-239922797-172.17.0.6-1597339418594:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36394,DS-f5cac719-0d27-4688-a698-2fb7eab6738b,DISK], DatanodeInfoWithStorage[127.0.0.1:40170,DS-01dd8c22-2444-4c9a-ba91-0145a8939923,DISK], DatanodeInfoWithStorage[127.0.0.1:36357,DS-bd7920d5-0837-47d3-97fb-09eee77d32ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39025,DS-01b0a8da-7ff6-4f49-b232-f2300abcee88,DISK], DatanodeInfoWithStorage[127.0.0.1:36837,DS-906a0298-7245-4704-bd82-2a2dd2834594,DISK], DatanodeInfoWithStorage[127.0.0.1:34574,DS-8c751fda-bcc1-4704-bec4-d4ad74045bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:41317,DS-00db9be2-cb5f-40e5-bcfe-673b0c7ef099,DISK], DatanodeInfoWithStorage[127.0.0.1:44100,DS-3f91a449-9cc8-487c-b948-3ac551a95f93,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-239922797-172.17.0.6-1597339418594:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36394,DS-f5cac719-0d27-4688-a698-2fb7eab6738b,DISK], DatanodeInfoWithStorage[127.0.0.1:40170,DS-01dd8c22-2444-4c9a-ba91-0145a8939923,DISK], DatanodeInfoWithStorage[127.0.0.1:36357,DS-bd7920d5-0837-47d3-97fb-09eee77d32ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39025,DS-01b0a8da-7ff6-4f49-b232-f2300abcee88,DISK], DatanodeInfoWithStorage[127.0.0.1:36837,DS-906a0298-7245-4704-bd82-2a2dd2834594,DISK], DatanodeInfoWithStorage[127.0.0.1:34574,DS-8c751fda-bcc1-4704-bec4-d4ad74045bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:41317,DS-00db9be2-cb5f-40e5-bcfe-673b0c7ef099,DISK], DatanodeInfoWithStorage[127.0.0.1:44100,DS-3f91a449-9cc8-487c-b948-3ac551a95f93,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-65500436-172.17.0.6-1597339668764:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35758,DS-4597ebe5-2ead-4c78-b13a-73b6550150fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40529,DS-b4aa4e91-5a13-4b15-9370-d2937add5ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:41033,DS-176ea84a-7d5d-4a9b-8592-8767f5942dda,DISK], DatanodeInfoWithStorage[127.0.0.1:35479,DS-7f70a006-84c1-4f35-a0a7-83e7265dc27c,DISK], DatanodeInfoWithStorage[127.0.0.1:40225,DS-8c1feb07-6efb-4ca8-b818-6cb2476dbb4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40525,DS-31ed32de-487b-4e3b-bf02-d1378aefea23,DISK], DatanodeInfoWithStorage[127.0.0.1:35531,DS-7c685e95-a787-45e5-aa5e-b3210d58bf70,DISK], DatanodeInfoWithStorage[127.0.0.1:37474,DS-a5685eaf-591a-4ff0-8227-d3609ef775f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-65500436-172.17.0.6-1597339668764:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35758,DS-4597ebe5-2ead-4c78-b13a-73b6550150fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40529,DS-b4aa4e91-5a13-4b15-9370-d2937add5ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:41033,DS-176ea84a-7d5d-4a9b-8592-8767f5942dda,DISK], DatanodeInfoWithStorage[127.0.0.1:35479,DS-7f70a006-84c1-4f35-a0a7-83e7265dc27c,DISK], DatanodeInfoWithStorage[127.0.0.1:40225,DS-8c1feb07-6efb-4ca8-b818-6cb2476dbb4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40525,DS-31ed32de-487b-4e3b-bf02-d1378aefea23,DISK], DatanodeInfoWithStorage[127.0.0.1:35531,DS-7c685e95-a787-45e5-aa5e-b3210d58bf70,DISK], DatanodeInfoWithStorage[127.0.0.1:37474,DS-a5685eaf-591a-4ff0-8227-d3609ef775f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1888596843-172.17.0.6-1597339900357:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42354,DS-eae92a53-6c79-4dfd-8c9b-02ce51e3cb3f,DISK], DatanodeInfoWithStorage[127.0.0.1:45213,DS-1071d1f0-5a8a-4ad0-aaf8-757f751edfe3,DISK], DatanodeInfoWithStorage[127.0.0.1:35058,DS-defbd9c9-cb74-4581-848b-bf6adf12d62d,DISK], DatanodeInfoWithStorage[127.0.0.1:46019,DS-7e400a50-beca-48a9-9d45-13b5ecea9a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:46038,DS-4e67c3a9-8fa3-434c-b440-2119b4505bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:43924,DS-f20a3c4a-2840-41b1-ab9c-2c026af6e6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46082,DS-5f034cfe-7b31-4a5a-96dc-6ae0d8adbed1,DISK], DatanodeInfoWithStorage[127.0.0.1:33771,DS-b4ce4cd5-b3af-4baa-9155-f98ea813b204,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1888596843-172.17.0.6-1597339900357:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42354,DS-eae92a53-6c79-4dfd-8c9b-02ce51e3cb3f,DISK], DatanodeInfoWithStorage[127.0.0.1:45213,DS-1071d1f0-5a8a-4ad0-aaf8-757f751edfe3,DISK], DatanodeInfoWithStorage[127.0.0.1:35058,DS-defbd9c9-cb74-4581-848b-bf6adf12d62d,DISK], DatanodeInfoWithStorage[127.0.0.1:46019,DS-7e400a50-beca-48a9-9d45-13b5ecea9a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:46038,DS-4e67c3a9-8fa3-434c-b440-2119b4505bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:43924,DS-f20a3c4a-2840-41b1-ab9c-2c026af6e6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46082,DS-5f034cfe-7b31-4a5a-96dc-6ae0d8adbed1,DISK], DatanodeInfoWithStorage[127.0.0.1:33771,DS-b4ce4cd5-b3af-4baa-9155-f98ea813b204,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-3339704-172.17.0.6-1597340096136:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39807,DS-80523bcc-5d0a-456f-b39d-ce598829ea33,DISK], DatanodeInfoWithStorage[127.0.0.1:42188,DS-22acfb7c-d596-45cc-9e2a-113190624312,DISK], DatanodeInfoWithStorage[127.0.0.1:39699,DS-f575e074-7531-4b5a-8ee5-76a06f907eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:37709,DS-32ae3e17-5fce-4854-90a5-074338c432ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37383,DS-1c545e10-b579-474a-9f77-c2ea7634b2be,DISK], DatanodeInfoWithStorage[127.0.0.1:37333,DS-15eda478-a79f-41c9-bf60-10e997459cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:32846,DS-c98ea889-b8e3-48b8-bc4c-aa03d8f45afb,DISK], DatanodeInfoWithStorage[127.0.0.1:43148,DS-a51eb381-439d-4f4b-8264-e29c834a3ee8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-3339704-172.17.0.6-1597340096136:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39807,DS-80523bcc-5d0a-456f-b39d-ce598829ea33,DISK], DatanodeInfoWithStorage[127.0.0.1:42188,DS-22acfb7c-d596-45cc-9e2a-113190624312,DISK], DatanodeInfoWithStorage[127.0.0.1:39699,DS-f575e074-7531-4b5a-8ee5-76a06f907eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:37709,DS-32ae3e17-5fce-4854-90a5-074338c432ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37383,DS-1c545e10-b579-474a-9f77-c2ea7634b2be,DISK], DatanodeInfoWithStorage[127.0.0.1:37333,DS-15eda478-a79f-41c9-bf60-10e997459cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:32846,DS-c98ea889-b8e3-48b8-bc4c-aa03d8f45afb,DISK], DatanodeInfoWithStorage[127.0.0.1:43148,DS-a51eb381-439d-4f4b-8264-e29c834a3ee8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1799866674-172.17.0.6-1597340243542:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39330,DS-58574a56-d342-4d3e-973d-eb0f35da26b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38314,DS-b470bad6-1509-4479-9ecf-74add02d8698,DISK], DatanodeInfoWithStorage[127.0.0.1:37153,DS-7f568ea2-b445-49f1-8d8a-296b3369a5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37167,DS-3c74227b-6c28-45fc-a02c-4e714357198a,DISK], DatanodeInfoWithStorage[127.0.0.1:38625,DS-f1069219-3a7f-4544-a7d1-6928aa3efdd0,DISK], DatanodeInfoWithStorage[127.0.0.1:40071,DS-5f3eafe0-cee5-48c8-ad92-af6f782c649c,DISK], DatanodeInfoWithStorage[127.0.0.1:32961,DS-61e78e11-fd66-4c6c-aa26-957f4c8aae20,DISK], DatanodeInfoWithStorage[127.0.0.1:33623,DS-6569dd72-3ea1-44a1-ab22-b809dc7906d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1799866674-172.17.0.6-1597340243542:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39330,DS-58574a56-d342-4d3e-973d-eb0f35da26b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38314,DS-b470bad6-1509-4479-9ecf-74add02d8698,DISK], DatanodeInfoWithStorage[127.0.0.1:37153,DS-7f568ea2-b445-49f1-8d8a-296b3369a5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37167,DS-3c74227b-6c28-45fc-a02c-4e714357198a,DISK], DatanodeInfoWithStorage[127.0.0.1:38625,DS-f1069219-3a7f-4544-a7d1-6928aa3efdd0,DISK], DatanodeInfoWithStorage[127.0.0.1:40071,DS-5f3eafe0-cee5-48c8-ad92-af6f782c649c,DISK], DatanodeInfoWithStorage[127.0.0.1:32961,DS-61e78e11-fd66-4c6c-aa26-957f4c8aae20,DISK], DatanodeInfoWithStorage[127.0.0.1:33623,DS-6569dd72-3ea1-44a1-ab22-b809dc7906d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1022658646-172.17.0.6-1597340282594:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45896,DS-34aab3d5-6052-4b52-bf0a-0a0777a289e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41076,DS-57137a26-753f-4afd-a2d4-2a6aca546628,DISK], DatanodeInfoWithStorage[127.0.0.1:33469,DS-8087f552-7000-4d40-85d0-33d6dc4cd3a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39536,DS-822ab6e1-fa17-48ce-ae20-bf55c2251d47,DISK], DatanodeInfoWithStorage[127.0.0.1:42609,DS-160a4522-06df-4fbb-867c-0528e314bda5,DISK], DatanodeInfoWithStorage[127.0.0.1:34544,DS-5f93a76d-ad5d-4916-836b-aa0b8d88d7f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42574,DS-8ccf8709-d162-40d2-8b3d-02995e3244e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37575,DS-742ba8c4-6aee-4857-8c37-e50d3556fcc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1022658646-172.17.0.6-1597340282594:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45896,DS-34aab3d5-6052-4b52-bf0a-0a0777a289e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41076,DS-57137a26-753f-4afd-a2d4-2a6aca546628,DISK], DatanodeInfoWithStorage[127.0.0.1:33469,DS-8087f552-7000-4d40-85d0-33d6dc4cd3a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39536,DS-822ab6e1-fa17-48ce-ae20-bf55c2251d47,DISK], DatanodeInfoWithStorage[127.0.0.1:42609,DS-160a4522-06df-4fbb-867c-0528e314bda5,DISK], DatanodeInfoWithStorage[127.0.0.1:34544,DS-5f93a76d-ad5d-4916-836b-aa0b8d88d7f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42574,DS-8ccf8709-d162-40d2-8b3d-02995e3244e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37575,DS-742ba8c4-6aee-4857-8c37-e50d3556fcc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1638044991-172.17.0.6-1597340330744:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37203,DS-c1dec96b-0100-4b25-a56c-553490cd534c,DISK], DatanodeInfoWithStorage[127.0.0.1:37181,DS-0c6da7f7-5acf-427c-8d2a-ddf5b648db8a,DISK], DatanodeInfoWithStorage[127.0.0.1:38837,DS-1d27c880-5611-4061-8858-0775e49e3f99,DISK], DatanodeInfoWithStorage[127.0.0.1:45798,DS-5b11ba1a-3179-4dee-b6f3-aa938e860bde,DISK], DatanodeInfoWithStorage[127.0.0.1:34132,DS-fcdccb2e-3177-4665-8f4e-0f0bb6a7c6b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41908,DS-5cc4717f-8f7b-4f09-9c8c-90d4508220cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43911,DS-95e8a652-6ea4-4a58-b9b3-94a6f54774f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43466,DS-9f4e51bb-1466-4c47-81b7-dbcbf608a815,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1638044991-172.17.0.6-1597340330744:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37203,DS-c1dec96b-0100-4b25-a56c-553490cd534c,DISK], DatanodeInfoWithStorage[127.0.0.1:37181,DS-0c6da7f7-5acf-427c-8d2a-ddf5b648db8a,DISK], DatanodeInfoWithStorage[127.0.0.1:38837,DS-1d27c880-5611-4061-8858-0775e49e3f99,DISK], DatanodeInfoWithStorage[127.0.0.1:45798,DS-5b11ba1a-3179-4dee-b6f3-aa938e860bde,DISK], DatanodeInfoWithStorage[127.0.0.1:34132,DS-fcdccb2e-3177-4665-8f4e-0f0bb6a7c6b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41908,DS-5cc4717f-8f7b-4f09-9c8c-90d4508220cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43911,DS-95e8a652-6ea4-4a58-b9b3-94a6f54774f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43466,DS-9f4e51bb-1466-4c47-81b7-dbcbf608a815,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1175356187-172.17.0.6-1597340494517:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38248,DS-fb6cb4df-0d79-46ec-a0ac-3740afa30764,DISK], DatanodeInfoWithStorage[127.0.0.1:37112,DS-8b669c4e-b7ca-4e95-85e4-46ea16564958,DISK], DatanodeInfoWithStorage[127.0.0.1:38573,DS-ab6f9751-5322-4c5b-9c28-adb41ab06b09,DISK], DatanodeInfoWithStorage[127.0.0.1:42522,DS-fe511171-725d-4091-91d4-0a503f9f2a46,DISK], DatanodeInfoWithStorage[127.0.0.1:35964,DS-5a1031a6-cf3e-4a85-b898-7d947aadced4,DISK], DatanodeInfoWithStorage[127.0.0.1:45996,DS-488ecaa8-d102-4ea4-bb35-c695908bde81,DISK], DatanodeInfoWithStorage[127.0.0.1:34139,DS-a49d46df-1061-49d9-8e51-9592c4ada00d,DISK], DatanodeInfoWithStorage[127.0.0.1:44210,DS-e90c6bbb-43ea-4627-af3c-cc41c8a3303f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1175356187-172.17.0.6-1597340494517:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38248,DS-fb6cb4df-0d79-46ec-a0ac-3740afa30764,DISK], DatanodeInfoWithStorage[127.0.0.1:37112,DS-8b669c4e-b7ca-4e95-85e4-46ea16564958,DISK], DatanodeInfoWithStorage[127.0.0.1:38573,DS-ab6f9751-5322-4c5b-9c28-adb41ab06b09,DISK], DatanodeInfoWithStorage[127.0.0.1:42522,DS-fe511171-725d-4091-91d4-0a503f9f2a46,DISK], DatanodeInfoWithStorage[127.0.0.1:35964,DS-5a1031a6-cf3e-4a85-b898-7d947aadced4,DISK], DatanodeInfoWithStorage[127.0.0.1:45996,DS-488ecaa8-d102-4ea4-bb35-c695908bde81,DISK], DatanodeInfoWithStorage[127.0.0.1:34139,DS-a49d46df-1061-49d9-8e51-9592c4ada00d,DISK], DatanodeInfoWithStorage[127.0.0.1:44210,DS-e90c6bbb-43ea-4627-af3c-cc41c8a3303f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-720718755-172.17.0.6-1597340769595:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42359,DS-05de4155-8ec3-4dd5-b591-84e53b187d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-6be4b6b0-82e6-4fb0-b57b-632a24d66942,DISK], DatanodeInfoWithStorage[127.0.0.1:41580,DS-0dd05e24-d813-4bbc-b6cb-f72dc26526ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34381,DS-7e65d694-89f7-4154-a48a-e4761329aa0f,DISK], DatanodeInfoWithStorage[127.0.0.1:32936,DS-79b0614a-d5a6-4a73-9552-dbb9b011e823,DISK], DatanodeInfoWithStorage[127.0.0.1:35308,DS-29a854d0-e05a-48bd-962d-58403c54c395,DISK], DatanodeInfoWithStorage[127.0.0.1:37645,DS-b7f48627-5efe-4545-b368-f723e3bd6065,DISK], DatanodeInfoWithStorage[127.0.0.1:45718,DS-b9bf54ce-d413-4dd9-9ea7-55882ae2b80e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-720718755-172.17.0.6-1597340769595:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42359,DS-05de4155-8ec3-4dd5-b591-84e53b187d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-6be4b6b0-82e6-4fb0-b57b-632a24d66942,DISK], DatanodeInfoWithStorage[127.0.0.1:41580,DS-0dd05e24-d813-4bbc-b6cb-f72dc26526ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34381,DS-7e65d694-89f7-4154-a48a-e4761329aa0f,DISK], DatanodeInfoWithStorage[127.0.0.1:32936,DS-79b0614a-d5a6-4a73-9552-dbb9b011e823,DISK], DatanodeInfoWithStorage[127.0.0.1:35308,DS-29a854d0-e05a-48bd-962d-58403c54c395,DISK], DatanodeInfoWithStorage[127.0.0.1:37645,DS-b7f48627-5efe-4545-b368-f723e3bd6065,DISK], DatanodeInfoWithStorage[127.0.0.1:45718,DS-b9bf54ce-d413-4dd9-9ea7-55882ae2b80e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-84796087-172.17.0.6-1597340861085:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46150,DS-cb11462b-e605-4783-a1ad-e42c149972de,DISK], DatanodeInfoWithStorage[127.0.0.1:42493,DS-85e81e3f-fafd-44bd-b671-73b8ce8de6f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35825,DS-c2978437-0536-49b2-b848-c4fa0e1a42d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34700,DS-18805eb0-76c0-4794-8c08-ad08031cb9c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41181,DS-db16fe3d-bfab-47aa-827e-d9c5e98d0d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:41593,DS-3147c7dd-99f0-43b5-9230-427859e22e96,DISK], DatanodeInfoWithStorage[127.0.0.1:43779,DS-70288069-62a0-4107-a789-0bcb75a4c1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38797,DS-a7d89d26-53ab-4d73-8ec2-c5e75f17c25c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-84796087-172.17.0.6-1597340861085:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46150,DS-cb11462b-e605-4783-a1ad-e42c149972de,DISK], DatanodeInfoWithStorage[127.0.0.1:42493,DS-85e81e3f-fafd-44bd-b671-73b8ce8de6f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35825,DS-c2978437-0536-49b2-b848-c4fa0e1a42d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34700,DS-18805eb0-76c0-4794-8c08-ad08031cb9c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41181,DS-db16fe3d-bfab-47aa-827e-d9c5e98d0d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:41593,DS-3147c7dd-99f0-43b5-9230-427859e22e96,DISK], DatanodeInfoWithStorage[127.0.0.1:43779,DS-70288069-62a0-4107-a789-0bcb75a4c1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38797,DS-a7d89d26-53ab-4d73-8ec2-c5e75f17c25c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-522522720-172.17.0.6-1597341040690:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34403,DS-86cc5e73-61cc-406e-8a98-c396ec0811c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33435,DS-4fde7f93-1d70-4bcb-bee6-0dcb409106b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41272,DS-0cd1da5d-db0a-4a4c-958c-ee745f53a0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33147,DS-92e3a6b8-abba-44af-9095-2da53917f654,DISK], DatanodeInfoWithStorage[127.0.0.1:34775,DS-597011db-160a-4fdf-88dd-1e2c4f9d01c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44210,DS-c8ac9d24-ae77-4a38-b422-d482b2a9f9f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36162,DS-8c3d1081-a111-4611-a308-07c2a8510c81,DISK], DatanodeInfoWithStorage[127.0.0.1:45398,DS-cc33883b-cff6-4a39-892a-7cd05f12bd1b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-522522720-172.17.0.6-1597341040690:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34403,DS-86cc5e73-61cc-406e-8a98-c396ec0811c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33435,DS-4fde7f93-1d70-4bcb-bee6-0dcb409106b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41272,DS-0cd1da5d-db0a-4a4c-958c-ee745f53a0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33147,DS-92e3a6b8-abba-44af-9095-2da53917f654,DISK], DatanodeInfoWithStorage[127.0.0.1:34775,DS-597011db-160a-4fdf-88dd-1e2c4f9d01c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44210,DS-c8ac9d24-ae77-4a38-b422-d482b2a9f9f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36162,DS-8c3d1081-a111-4611-a308-07c2a8510c81,DISK], DatanodeInfoWithStorage[127.0.0.1:45398,DS-cc33883b-cff6-4a39-892a-7cd05f12bd1b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1408086260-172.17.0.6-1597341144127:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39446,DS-e5016faa-a931-4843-abf2-1819337121ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34977,DS-986d5099-3093-4def-ab1c-f6bae45995a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36211,DS-3ed26c15-33a9-4ec3-af85-42574c0f2abc,DISK], DatanodeInfoWithStorage[127.0.0.1:35953,DS-f8e86f84-f845-4a1c-b178-3f7591ce5bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:37400,DS-7819181d-2a77-44e4-8da5-8ff6bfa74362,DISK], DatanodeInfoWithStorage[127.0.0.1:35669,DS-f6501f61-d699-480f-af17-91e789bc5bef,DISK], DatanodeInfoWithStorage[127.0.0.1:36057,DS-f6be5640-f540-44bd-bdb0-5a1b96f932db,DISK], DatanodeInfoWithStorage[127.0.0.1:37549,DS-1c053275-5438-44db-993a-3fef6330db23,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1408086260-172.17.0.6-1597341144127:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39446,DS-e5016faa-a931-4843-abf2-1819337121ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34977,DS-986d5099-3093-4def-ab1c-f6bae45995a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36211,DS-3ed26c15-33a9-4ec3-af85-42574c0f2abc,DISK], DatanodeInfoWithStorage[127.0.0.1:35953,DS-f8e86f84-f845-4a1c-b178-3f7591ce5bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:37400,DS-7819181d-2a77-44e4-8da5-8ff6bfa74362,DISK], DatanodeInfoWithStorage[127.0.0.1:35669,DS-f6501f61-d699-480f-af17-91e789bc5bef,DISK], DatanodeInfoWithStorage[127.0.0.1:36057,DS-f6be5640-f540-44bd-bdb0-5a1b96f932db,DISK], DatanodeInfoWithStorage[127.0.0.1:37549,DS-1c053275-5438-44db-993a-3fef6330db23,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-529765891-172.17.0.6-1597341245854:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33187,DS-86f648e4-4751-49b8-9f25-a35cec5df9e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39917,DS-22446bd0-fb54-46f4-9faa-8e1f134188ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35431,DS-5d761101-d3c2-4eac-b359-6d3649f3321b,DISK], DatanodeInfoWithStorage[127.0.0.1:37234,DS-828962ed-b8e5-4844-8594-b94582e410bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39906,DS-0d83f350-3ef1-43ea-9640-76a9fcd200e7,DISK], DatanodeInfoWithStorage[127.0.0.1:32803,DS-390737fe-171e-4049-8f6f-3fae6904c186,DISK], DatanodeInfoWithStorage[127.0.0.1:40023,DS-4cdc5fe6-66a7-4512-b62f-e6311a1b4648,DISK], DatanodeInfoWithStorage[127.0.0.1:34963,DS-eaa0d7e6-a996-49b8-a0de-497e841d1372,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-529765891-172.17.0.6-1597341245854:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33187,DS-86f648e4-4751-49b8-9f25-a35cec5df9e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39917,DS-22446bd0-fb54-46f4-9faa-8e1f134188ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35431,DS-5d761101-d3c2-4eac-b359-6d3649f3321b,DISK], DatanodeInfoWithStorage[127.0.0.1:37234,DS-828962ed-b8e5-4844-8594-b94582e410bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39906,DS-0d83f350-3ef1-43ea-9640-76a9fcd200e7,DISK], DatanodeInfoWithStorage[127.0.0.1:32803,DS-390737fe-171e-4049-8f6f-3fae6904c186,DISK], DatanodeInfoWithStorage[127.0.0.1:40023,DS-4cdc5fe6-66a7-4512-b62f-e6311a1b4648,DISK], DatanodeInfoWithStorage[127.0.0.1:34963,DS-eaa0d7e6-a996-49b8-a0de-497e841d1372,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2026951619-172.17.0.6-1597341573468:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39280,DS-c192fa43-5ce6-4b37-a414-13e9cc017e96,DISK], DatanodeInfoWithStorage[127.0.0.1:35948,DS-8bbd8d2d-aec8-4785-ab60-6d33f6c7dd50,DISK], DatanodeInfoWithStorage[127.0.0.1:46609,DS-938755f6-0a0c-4aaf-89a9-8f5484c296bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33412,DS-473a9a9b-ff7e-4779-b1e9-451c735d4f80,DISK], DatanodeInfoWithStorage[127.0.0.1:36522,DS-e9758a77-878f-4814-b41e-41185a702f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35459,DS-4691926a-3e56-4ff6-9ad3-c7e859650f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:42074,DS-f0f2f2bc-91a6-498b-8ebe-b635673ce6a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45302,DS-60d3c935-4131-4cc0-a660-ffb6b83b9fda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2026951619-172.17.0.6-1597341573468:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39280,DS-c192fa43-5ce6-4b37-a414-13e9cc017e96,DISK], DatanodeInfoWithStorage[127.0.0.1:35948,DS-8bbd8d2d-aec8-4785-ab60-6d33f6c7dd50,DISK], DatanodeInfoWithStorage[127.0.0.1:46609,DS-938755f6-0a0c-4aaf-89a9-8f5484c296bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33412,DS-473a9a9b-ff7e-4779-b1e9-451c735d4f80,DISK], DatanodeInfoWithStorage[127.0.0.1:36522,DS-e9758a77-878f-4814-b41e-41185a702f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35459,DS-4691926a-3e56-4ff6-9ad3-c7e859650f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:42074,DS-f0f2f2bc-91a6-498b-8ebe-b635673ce6a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45302,DS-60d3c935-4131-4cc0-a660-ffb6b83b9fda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-850024357-172.17.0.6-1597341979913:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39284,DS-ef704af3-aea7-4632-b025-ed0a924919e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45710,DS-a0872d38-6617-4dd7-8144-a36d1d502ead,DISK], DatanodeInfoWithStorage[127.0.0.1:41963,DS-5bed26e9-3005-40eb-8eef-246dd3375cff,DISK], DatanodeInfoWithStorage[127.0.0.1:36675,DS-9dfadb0a-78a6-4a47-886f-62d7106931af,DISK], DatanodeInfoWithStorage[127.0.0.1:36487,DS-7072be7f-a77f-4a06-851f-95dac77e46fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40459,DS-7aa1c68e-3923-4806-87c1-f62e98ed2568,DISK], DatanodeInfoWithStorage[127.0.0.1:46172,DS-d21e55b6-f033-43df-94dc-8996e6e06de1,DISK], DatanodeInfoWithStorage[127.0.0.1:46227,DS-39001193-da62-431a-a6e6-b1663db08fe3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-850024357-172.17.0.6-1597341979913:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39284,DS-ef704af3-aea7-4632-b025-ed0a924919e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45710,DS-a0872d38-6617-4dd7-8144-a36d1d502ead,DISK], DatanodeInfoWithStorage[127.0.0.1:41963,DS-5bed26e9-3005-40eb-8eef-246dd3375cff,DISK], DatanodeInfoWithStorage[127.0.0.1:36675,DS-9dfadb0a-78a6-4a47-886f-62d7106931af,DISK], DatanodeInfoWithStorage[127.0.0.1:36487,DS-7072be7f-a77f-4a06-851f-95dac77e46fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40459,DS-7aa1c68e-3923-4806-87c1-f62e98ed2568,DISK], DatanodeInfoWithStorage[127.0.0.1:46172,DS-d21e55b6-f033-43df-94dc-8996e6e06de1,DISK], DatanodeInfoWithStorage[127.0.0.1:46227,DS-39001193-da62-431a-a6e6-b1663db08fe3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1968700727-172.17.0.6-1597342124384:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38312,DS-e65ae77f-18a5-4fb4-8ede-7153f7af3b33,DISK], DatanodeInfoWithStorage[127.0.0.1:43965,DS-1c3a2efc-2560-4cc4-b7d7-f00ad1d698e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37445,DS-03ceb8c5-51ae-4fef-9627-02e5604713be,DISK], DatanodeInfoWithStorage[127.0.0.1:41650,DS-80b99ab8-f1f7-40cd-a1f6-e7f2d416a2f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45726,DS-7cae12e2-35c6-425c-9407-1196f6b051a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36129,DS-8c2a9c6d-6f7a-4189-b5f3-88f7aba5f8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40915,DS-c46f8180-0e97-4bbb-90f6-7b45e3a2e269,DISK], DatanodeInfoWithStorage[127.0.0.1:43064,DS-22dc50ce-58cd-47fd-9bef-fc8c9d1bdd61,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1968700727-172.17.0.6-1597342124384:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38312,DS-e65ae77f-18a5-4fb4-8ede-7153f7af3b33,DISK], DatanodeInfoWithStorage[127.0.0.1:43965,DS-1c3a2efc-2560-4cc4-b7d7-f00ad1d698e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37445,DS-03ceb8c5-51ae-4fef-9627-02e5604713be,DISK], DatanodeInfoWithStorage[127.0.0.1:41650,DS-80b99ab8-f1f7-40cd-a1f6-e7f2d416a2f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45726,DS-7cae12e2-35c6-425c-9407-1196f6b051a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36129,DS-8c2a9c6d-6f7a-4189-b5f3-88f7aba5f8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40915,DS-c46f8180-0e97-4bbb-90f6-7b45e3a2e269,DISK], DatanodeInfoWithStorage[127.0.0.1:43064,DS-22dc50ce-58cd-47fd-9bef-fc8c9d1bdd61,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-922224917-172.17.0.6-1597342427989:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44853,DS-7972e8bc-a19f-41dc-b394-c1e709d8a428,DISK], DatanodeInfoWithStorage[127.0.0.1:34369,DS-8817a13e-b248-40c7-bbf6-94d7bf2426af,DISK], DatanodeInfoWithStorage[127.0.0.1:43393,DS-66aab337-0def-4ab2-bd77-0525d0920705,DISK], DatanodeInfoWithStorage[127.0.0.1:44834,DS-c821698a-c57b-4d47-b11a-ea2069b66884,DISK], DatanodeInfoWithStorage[127.0.0.1:46555,DS-4452204e-e66d-4ad1-a45a-f56cce6f80c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35665,DS-daab44ef-8a36-451f-8db6-abf2440ddff4,DISK], DatanodeInfoWithStorage[127.0.0.1:40150,DS-dbaaad4d-8746-4a5a-b0cc-9de54c9286b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45133,DS-a8b46fc4-35ae-4132-8f3c-03876f403cdb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-922224917-172.17.0.6-1597342427989:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44853,DS-7972e8bc-a19f-41dc-b394-c1e709d8a428,DISK], DatanodeInfoWithStorage[127.0.0.1:34369,DS-8817a13e-b248-40c7-bbf6-94d7bf2426af,DISK], DatanodeInfoWithStorage[127.0.0.1:43393,DS-66aab337-0def-4ab2-bd77-0525d0920705,DISK], DatanodeInfoWithStorage[127.0.0.1:44834,DS-c821698a-c57b-4d47-b11a-ea2069b66884,DISK], DatanodeInfoWithStorage[127.0.0.1:46555,DS-4452204e-e66d-4ad1-a45a-f56cce6f80c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35665,DS-daab44ef-8a36-451f-8db6-abf2440ddff4,DISK], DatanodeInfoWithStorage[127.0.0.1:40150,DS-dbaaad4d-8746-4a5a-b0cc-9de54c9286b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45133,DS-a8b46fc4-35ae-4132-8f3c-03876f403cdb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-530584661-172.17.0.6-1597342526143:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44299,DS-be850694-e0ae-4ab0-adae-f3772655bed4,DISK], DatanodeInfoWithStorage[127.0.0.1:46410,DS-6ec0d647-f945-4e72-aa03-6d8ed785535f,DISK], DatanodeInfoWithStorage[127.0.0.1:38696,DS-65737764-386f-450c-889d-050cf5154e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:40232,DS-fc84be1b-ec24-400d-8ad4-fe17ec0684f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44628,DS-b7f6cb18-3323-4532-a184-e8174edcf549,DISK], DatanodeInfoWithStorage[127.0.0.1:36513,DS-cf73eb4e-a38a-4136-9d40-e89331b1424d,DISK], DatanodeInfoWithStorage[127.0.0.1:34082,DS-4e9c9d84-d22d-43ad-8ae6-d60c12ea78e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46075,DS-9fc3cd2d-43df-4671-9e1c-5ca2746e29f0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-530584661-172.17.0.6-1597342526143:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44299,DS-be850694-e0ae-4ab0-adae-f3772655bed4,DISK], DatanodeInfoWithStorage[127.0.0.1:46410,DS-6ec0d647-f945-4e72-aa03-6d8ed785535f,DISK], DatanodeInfoWithStorage[127.0.0.1:38696,DS-65737764-386f-450c-889d-050cf5154e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:40232,DS-fc84be1b-ec24-400d-8ad4-fe17ec0684f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44628,DS-b7f6cb18-3323-4532-a184-e8174edcf549,DISK], DatanodeInfoWithStorage[127.0.0.1:36513,DS-cf73eb4e-a38a-4136-9d40-e89331b1424d,DISK], DatanodeInfoWithStorage[127.0.0.1:34082,DS-4e9c9d84-d22d-43ad-8ae6-d60c12ea78e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46075,DS-9fc3cd2d-43df-4671-9e1c-5ca2746e29f0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1613537403-172.17.0.6-1597342717310:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42920,DS-c24673b2-535e-4781-bb6f-d9b341faa385,DISK], DatanodeInfoWithStorage[127.0.0.1:45296,DS-c6e699d1-b120-4ff5-865e-33b7bb1c740c,DISK], DatanodeInfoWithStorage[127.0.0.1:43820,DS-ef19bffe-5a46-4d31-8081-96e608b87dff,DISK], DatanodeInfoWithStorage[127.0.0.1:42071,DS-9875233c-bd05-4788-b223-a773c2d7195c,DISK], DatanodeInfoWithStorage[127.0.0.1:36635,DS-54a0e689-1595-4108-b518-8c21bf016ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:40974,DS-f14542fb-6ec7-457f-8a96-132da94da7fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41123,DS-c682214f-1859-4722-80c4-298b5216768f,DISK], DatanodeInfoWithStorage[127.0.0.1:41821,DS-c9e195d6-7365-4856-8405-247d0d0693cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1613537403-172.17.0.6-1597342717310:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42920,DS-c24673b2-535e-4781-bb6f-d9b341faa385,DISK], DatanodeInfoWithStorage[127.0.0.1:45296,DS-c6e699d1-b120-4ff5-865e-33b7bb1c740c,DISK], DatanodeInfoWithStorage[127.0.0.1:43820,DS-ef19bffe-5a46-4d31-8081-96e608b87dff,DISK], DatanodeInfoWithStorage[127.0.0.1:42071,DS-9875233c-bd05-4788-b223-a773c2d7195c,DISK], DatanodeInfoWithStorage[127.0.0.1:36635,DS-54a0e689-1595-4108-b518-8c21bf016ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:40974,DS-f14542fb-6ec7-457f-8a96-132da94da7fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41123,DS-c682214f-1859-4722-80c4-298b5216768f,DISK], DatanodeInfoWithStorage[127.0.0.1:41821,DS-c9e195d6-7365-4856-8405-247d0d0693cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1573774029-172.17.0.6-1597342815310:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43808,DS-bd06f4f1-a9d8-4e89-97f1-ffbb8fc8d93f,DISK], DatanodeInfoWithStorage[127.0.0.1:39621,DS-14120657-4140-4e19-8e30-448a14546652,DISK], DatanodeInfoWithStorage[127.0.0.1:35716,DS-2a1887e8-35a8-4981-bc2e-b05fb2feed02,DISK], DatanodeInfoWithStorage[127.0.0.1:34292,DS-1a44156a-c328-4151-bd2a-b00238325012,DISK], DatanodeInfoWithStorage[127.0.0.1:33177,DS-7f8d10c5-f131-43de-b563-f242da0afa01,DISK], DatanodeInfoWithStorage[127.0.0.1:46432,DS-11aa9ada-c056-47d9-b84a-749601ceef01,DISK], DatanodeInfoWithStorage[127.0.0.1:35022,DS-78012429-1788-4d36-b48b-405879ae940b,DISK], DatanodeInfoWithStorage[127.0.0.1:46623,DS-084957c1-67ad-4bf6-9b3e-e1fac44875cb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1573774029-172.17.0.6-1597342815310:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43808,DS-bd06f4f1-a9d8-4e89-97f1-ffbb8fc8d93f,DISK], DatanodeInfoWithStorage[127.0.0.1:39621,DS-14120657-4140-4e19-8e30-448a14546652,DISK], DatanodeInfoWithStorage[127.0.0.1:35716,DS-2a1887e8-35a8-4981-bc2e-b05fb2feed02,DISK], DatanodeInfoWithStorage[127.0.0.1:34292,DS-1a44156a-c328-4151-bd2a-b00238325012,DISK], DatanodeInfoWithStorage[127.0.0.1:33177,DS-7f8d10c5-f131-43de-b563-f242da0afa01,DISK], DatanodeInfoWithStorage[127.0.0.1:46432,DS-11aa9ada-c056-47d9-b84a-749601ceef01,DISK], DatanodeInfoWithStorage[127.0.0.1:35022,DS-78012429-1788-4d36-b48b-405879ae940b,DISK], DatanodeInfoWithStorage[127.0.0.1:46623,DS-084957c1-67ad-4bf6-9b3e-e1fac44875cb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 16 out of 50
v1v1v2v2 failed with probability 23 out of 50
result: false positive !!!
Total execution time in seconds : 6933
