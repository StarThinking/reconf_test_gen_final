reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-235237297-172.17.0.10-1597655959086:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37806,DS-7f3397ac-8723-43da-b8fc-6192ee3bab15,DISK], DatanodeInfoWithStorage[127.0.0.1:45404,DS-d451faea-1dd5-4124-ba21-7266f3be5048,DISK], DatanodeInfoWithStorage[127.0.0.1:40161,DS-b3630fb3-bdc9-476f-9ee6-3842f35145df,DISK], DatanodeInfoWithStorage[127.0.0.1:37755,DS-5f179633-6010-481c-98fb-903c3ba9faf6,DISK], DatanodeInfoWithStorage[127.0.0.1:35591,DS-bb5be4e1-8063-40b0-b6e1-c9b0ccd65a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:36930,DS-081c3bb2-c2ed-4e9b-994b-2fc93d29ea92,DISK], DatanodeInfoWithStorage[127.0.0.1:46293,DS-0061d662-99c8-47ed-9cd1-d86840263c55,DISK], DatanodeInfoWithStorage[127.0.0.1:35029,DS-21c32ee7-e99c-46cc-a2bb-bd1d30f1895e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-235237297-172.17.0.10-1597655959086:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37806,DS-7f3397ac-8723-43da-b8fc-6192ee3bab15,DISK], DatanodeInfoWithStorage[127.0.0.1:45404,DS-d451faea-1dd5-4124-ba21-7266f3be5048,DISK], DatanodeInfoWithStorage[127.0.0.1:40161,DS-b3630fb3-bdc9-476f-9ee6-3842f35145df,DISK], DatanodeInfoWithStorage[127.0.0.1:37755,DS-5f179633-6010-481c-98fb-903c3ba9faf6,DISK], DatanodeInfoWithStorage[127.0.0.1:35591,DS-bb5be4e1-8063-40b0-b6e1-c9b0ccd65a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:36930,DS-081c3bb2-c2ed-4e9b-994b-2fc93d29ea92,DISK], DatanodeInfoWithStorage[127.0.0.1:46293,DS-0061d662-99c8-47ed-9cd1-d86840263c55,DISK], DatanodeInfoWithStorage[127.0.0.1:35029,DS-21c32ee7-e99c-46cc-a2bb-bd1d30f1895e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-49306401-172.17.0.10-1597656353821:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33139,DS-86565b0d-5e4f-4270-b5d2-3f2cdac81630,DISK], DatanodeInfoWithStorage[127.0.0.1:44161,DS-34f110fe-28a1-48c3-891a-6375c2801fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:43213,DS-5ab19ef4-a29a-4bab-a2fd-cd02cb6effd1,DISK], DatanodeInfoWithStorage[127.0.0.1:42001,DS-7d4b2401-12ac-4103-8ca0-e29e706b1f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:41909,DS-910e0442-5045-47db-9875-3e6eaf3014ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40580,DS-c2e7ac3d-7255-449b-89e0-0a51bbdbd97f,DISK], DatanodeInfoWithStorage[127.0.0.1:36885,DS-057e7078-8304-46a2-b219-d0a75eda7dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:40484,DS-274baafc-fd96-4f96-87ef-f24026346cb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-49306401-172.17.0.10-1597656353821:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33139,DS-86565b0d-5e4f-4270-b5d2-3f2cdac81630,DISK], DatanodeInfoWithStorage[127.0.0.1:44161,DS-34f110fe-28a1-48c3-891a-6375c2801fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:43213,DS-5ab19ef4-a29a-4bab-a2fd-cd02cb6effd1,DISK], DatanodeInfoWithStorage[127.0.0.1:42001,DS-7d4b2401-12ac-4103-8ca0-e29e706b1f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:41909,DS-910e0442-5045-47db-9875-3e6eaf3014ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40580,DS-c2e7ac3d-7255-449b-89e0-0a51bbdbd97f,DISK], DatanodeInfoWithStorage[127.0.0.1:36885,DS-057e7078-8304-46a2-b219-d0a75eda7dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:40484,DS-274baafc-fd96-4f96-87ef-f24026346cb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1087941862-172.17.0.10-1597657163754:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45116,DS-92fac5dd-053b-4df1-9441-bbe60c60895b,DISK], DatanodeInfoWithStorage[127.0.0.1:42325,DS-f669b95a-c5d1-40b4-86ea-a25827e0a93b,DISK], DatanodeInfoWithStorage[127.0.0.1:41361,DS-7b7e7631-8520-443f-b93e-f25c2a17c9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36043,DS-ca002077-ff6b-4118-a702-086e9b64d3f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39631,DS-51f5346b-bc4b-47dd-8d37-55cb46e4f561,DISK], DatanodeInfoWithStorage[127.0.0.1:39563,DS-18993429-38b8-463a-91ae-ab9d493ece6b,DISK], DatanodeInfoWithStorage[127.0.0.1:34718,DS-3e744640-7f2e-46af-8cb1-6099fde0fc04,DISK], DatanodeInfoWithStorage[127.0.0.1:42311,DS-b847584f-b307-4635-81a4-dd6420c295ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1087941862-172.17.0.10-1597657163754:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45116,DS-92fac5dd-053b-4df1-9441-bbe60c60895b,DISK], DatanodeInfoWithStorage[127.0.0.1:42325,DS-f669b95a-c5d1-40b4-86ea-a25827e0a93b,DISK], DatanodeInfoWithStorage[127.0.0.1:41361,DS-7b7e7631-8520-443f-b93e-f25c2a17c9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36043,DS-ca002077-ff6b-4118-a702-086e9b64d3f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39631,DS-51f5346b-bc4b-47dd-8d37-55cb46e4f561,DISK], DatanodeInfoWithStorage[127.0.0.1:39563,DS-18993429-38b8-463a-91ae-ab9d493ece6b,DISK], DatanodeInfoWithStorage[127.0.0.1:34718,DS-3e744640-7f2e-46af-8cb1-6099fde0fc04,DISK], DatanodeInfoWithStorage[127.0.0.1:42311,DS-b847584f-b307-4635-81a4-dd6420c295ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-913694289-172.17.0.10-1597657321589:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36020,DS-2cde2020-68af-4048-a554-f393600a4dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:34690,DS-21db559b-b98c-4fb6-a751-c1e8c98f4323,DISK], DatanodeInfoWithStorage[127.0.0.1:40967,DS-fbd015b2-1db4-45c8-846e-daf3fb77825a,DISK], DatanodeInfoWithStorage[127.0.0.1:45893,DS-1b4e52b6-2410-489f-8e9e-925170bd7cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:34948,DS-15db0f6c-aadc-4b1d-ba50-b810db77469b,DISK], DatanodeInfoWithStorage[127.0.0.1:40158,DS-30159d00-c2aa-4508-8d63-5d302b68b643,DISK], DatanodeInfoWithStorage[127.0.0.1:42610,DS-9052ff67-af23-40eb-ab07-3332a453b30b,DISK], DatanodeInfoWithStorage[127.0.0.1:37583,DS-02cf792a-3151-40ef-b7aa-fa8864d36947,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-913694289-172.17.0.10-1597657321589:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36020,DS-2cde2020-68af-4048-a554-f393600a4dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:34690,DS-21db559b-b98c-4fb6-a751-c1e8c98f4323,DISK], DatanodeInfoWithStorage[127.0.0.1:40967,DS-fbd015b2-1db4-45c8-846e-daf3fb77825a,DISK], DatanodeInfoWithStorage[127.0.0.1:45893,DS-1b4e52b6-2410-489f-8e9e-925170bd7cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:34948,DS-15db0f6c-aadc-4b1d-ba50-b810db77469b,DISK], DatanodeInfoWithStorage[127.0.0.1:40158,DS-30159d00-c2aa-4508-8d63-5d302b68b643,DISK], DatanodeInfoWithStorage[127.0.0.1:42610,DS-9052ff67-af23-40eb-ab07-3332a453b30b,DISK], DatanodeInfoWithStorage[127.0.0.1:37583,DS-02cf792a-3151-40ef-b7aa-fa8864d36947,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1446272029-172.17.0.10-1597658247864:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43776,DS-853a6303-bd6f-46a0-9bc3-3418949da146,DISK], DatanodeInfoWithStorage[127.0.0.1:39170,DS-cd34042c-89b3-4865-ad68-e0d095ce9dde,DISK], DatanodeInfoWithStorage[127.0.0.1:43277,DS-ba9f2b28-f775-4f4b-921c-4fc7fff20f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:35208,DS-ca924dc8-8800-446a-8fe5-40c45bcde36c,DISK], DatanodeInfoWithStorage[127.0.0.1:45953,DS-cdbccc43-2a2b-4217-b639-2f2c2a018f95,DISK], DatanodeInfoWithStorage[127.0.0.1:39979,DS-1bd8552d-4fbc-4087-9f9f-90d07f5b0a23,DISK], DatanodeInfoWithStorage[127.0.0.1:34104,DS-dbe3a553-b634-4007-948d-7ef144166bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:34550,DS-4a10b708-9e2f-4284-95df-b770bbd6afd5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1446272029-172.17.0.10-1597658247864:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43776,DS-853a6303-bd6f-46a0-9bc3-3418949da146,DISK], DatanodeInfoWithStorage[127.0.0.1:39170,DS-cd34042c-89b3-4865-ad68-e0d095ce9dde,DISK], DatanodeInfoWithStorage[127.0.0.1:43277,DS-ba9f2b28-f775-4f4b-921c-4fc7fff20f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:35208,DS-ca924dc8-8800-446a-8fe5-40c45bcde36c,DISK], DatanodeInfoWithStorage[127.0.0.1:45953,DS-cdbccc43-2a2b-4217-b639-2f2c2a018f95,DISK], DatanodeInfoWithStorage[127.0.0.1:39979,DS-1bd8552d-4fbc-4087-9f9f-90d07f5b0a23,DISK], DatanodeInfoWithStorage[127.0.0.1:34104,DS-dbe3a553-b634-4007-948d-7ef144166bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:34550,DS-4a10b708-9e2f-4284-95df-b770bbd6afd5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1516324687-172.17.0.10-1597658423381:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46585,DS-4db0c7fe-b01e-45f1-b64d-f227e462d8a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39881,DS-e0dd3b83-46e6-4c47-a647-ac163dcdb01a,DISK], DatanodeInfoWithStorage[127.0.0.1:34749,DS-65afe646-24ff-4793-8264-c0baadb46657,DISK], DatanodeInfoWithStorage[127.0.0.1:36831,DS-74e44a0e-58e0-4ca6-8dee-40dc0a8d4329,DISK], DatanodeInfoWithStorage[127.0.0.1:39726,DS-bf151f66-f02f-44ef-b1fb-db7c0a4986e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-163c637e-d56a-490b-89aa-abc0f84934f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44290,DS-ffb1c615-af96-44e7-8aa7-53cf7cdca7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34693,DS-aeabb321-8e31-4f4c-bc71-5971beedd0d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1516324687-172.17.0.10-1597658423381:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46585,DS-4db0c7fe-b01e-45f1-b64d-f227e462d8a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39881,DS-e0dd3b83-46e6-4c47-a647-ac163dcdb01a,DISK], DatanodeInfoWithStorage[127.0.0.1:34749,DS-65afe646-24ff-4793-8264-c0baadb46657,DISK], DatanodeInfoWithStorage[127.0.0.1:36831,DS-74e44a0e-58e0-4ca6-8dee-40dc0a8d4329,DISK], DatanodeInfoWithStorage[127.0.0.1:39726,DS-bf151f66-f02f-44ef-b1fb-db7c0a4986e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-163c637e-d56a-490b-89aa-abc0f84934f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44290,DS-ffb1c615-af96-44e7-8aa7-53cf7cdca7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34693,DS-aeabb321-8e31-4f4c-bc71-5971beedd0d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1268784578-172.17.0.10-1597658538617:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41361,DS-9484e746-17a0-4e22-a1c9-d057676eca85,DISK], DatanodeInfoWithStorage[127.0.0.1:38941,DS-7878ccef-f38c-44a0-a38a-b27b168d940b,DISK], DatanodeInfoWithStorage[127.0.0.1:41708,DS-cb98b8c7-c509-4456-825b-8c39cabcb4de,DISK], DatanodeInfoWithStorage[127.0.0.1:35680,DS-8c06ccba-726c-40df-9351-0af674a014af,DISK], DatanodeInfoWithStorage[127.0.0.1:46628,DS-83d7a587-fa64-4caf-8a8c-0a6a8c9c9ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:41662,DS-5cebecc1-3f66-49af-8eed-f727525cee39,DISK], DatanodeInfoWithStorage[127.0.0.1:34462,DS-1b853138-4a41-4493-abac-764e06a38b02,DISK], DatanodeInfoWithStorage[127.0.0.1:46287,DS-860b2be0-6699-4ba6-8fb0-04834285e4da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1268784578-172.17.0.10-1597658538617:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41361,DS-9484e746-17a0-4e22-a1c9-d057676eca85,DISK], DatanodeInfoWithStorage[127.0.0.1:38941,DS-7878ccef-f38c-44a0-a38a-b27b168d940b,DISK], DatanodeInfoWithStorage[127.0.0.1:41708,DS-cb98b8c7-c509-4456-825b-8c39cabcb4de,DISK], DatanodeInfoWithStorage[127.0.0.1:35680,DS-8c06ccba-726c-40df-9351-0af674a014af,DISK], DatanodeInfoWithStorage[127.0.0.1:46628,DS-83d7a587-fa64-4caf-8a8c-0a6a8c9c9ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:41662,DS-5cebecc1-3f66-49af-8eed-f727525cee39,DISK], DatanodeInfoWithStorage[127.0.0.1:34462,DS-1b853138-4a41-4493-abac-764e06a38b02,DISK], DatanodeInfoWithStorage[127.0.0.1:46287,DS-860b2be0-6699-4ba6-8fb0-04834285e4da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1367027423-172.17.0.10-1597658952948:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43833,DS-c85b3760-f24d-4e40-b498-e0cde1d72564,DISK], DatanodeInfoWithStorage[127.0.0.1:41052,DS-d4d17054-bf3b-46b4-9912-77e07eeb0aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:41610,DS-be7c809d-7f73-4da2-8688-4c46e1c79c39,DISK], DatanodeInfoWithStorage[127.0.0.1:38270,DS-8019d274-3e79-4f23-aea6-182d5afb1cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:41780,DS-fe644470-7649-4a60-891b-6a8d96903364,DISK], DatanodeInfoWithStorage[127.0.0.1:41636,DS-d73cae80-c6c8-4455-8655-a1090a92f062,DISK], DatanodeInfoWithStorage[127.0.0.1:46581,DS-773acf26-5229-4438-beea-25e131eab381,DISK], DatanodeInfoWithStorage[127.0.0.1:41586,DS-017198e6-0561-464d-801c-1967282fd63f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1367027423-172.17.0.10-1597658952948:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43833,DS-c85b3760-f24d-4e40-b498-e0cde1d72564,DISK], DatanodeInfoWithStorage[127.0.0.1:41052,DS-d4d17054-bf3b-46b4-9912-77e07eeb0aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:41610,DS-be7c809d-7f73-4da2-8688-4c46e1c79c39,DISK], DatanodeInfoWithStorage[127.0.0.1:38270,DS-8019d274-3e79-4f23-aea6-182d5afb1cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:41780,DS-fe644470-7649-4a60-891b-6a8d96903364,DISK], DatanodeInfoWithStorage[127.0.0.1:41636,DS-d73cae80-c6c8-4455-8655-a1090a92f062,DISK], DatanodeInfoWithStorage[127.0.0.1:46581,DS-773acf26-5229-4438-beea-25e131eab381,DISK], DatanodeInfoWithStorage[127.0.0.1:41586,DS-017198e6-0561-464d-801c-1967282fd63f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1204129074-172.17.0.10-1597659027048:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39625,DS-b06e1435-8a11-4f07-b344-2d5500d2dc33,DISK], DatanodeInfoWithStorage[127.0.0.1:46862,DS-b552cbdd-7e8b-4653-acaf-1dec6e842be1,DISK], DatanodeInfoWithStorage[127.0.0.1:33842,DS-b90d1a35-fd5f-49d0-aba6-6195ae9e3975,DISK], DatanodeInfoWithStorage[127.0.0.1:46737,DS-4d5e3c59-6566-4165-a999-13ee1a47beee,DISK], DatanodeInfoWithStorage[127.0.0.1:39178,DS-110bac2c-04bc-44b9-b95e-066f4d8fb566,DISK], DatanodeInfoWithStorage[127.0.0.1:39010,DS-00b7f4c1-b1ca-4cec-9ed2-bc14079b497f,DISK], DatanodeInfoWithStorage[127.0.0.1:42271,DS-405a28a6-184a-4cf6-8a45-5dae505b0fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:45951,DS-ce12e34e-52a4-402a-adc5-a04542cd829c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1204129074-172.17.0.10-1597659027048:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39625,DS-b06e1435-8a11-4f07-b344-2d5500d2dc33,DISK], DatanodeInfoWithStorage[127.0.0.1:46862,DS-b552cbdd-7e8b-4653-acaf-1dec6e842be1,DISK], DatanodeInfoWithStorage[127.0.0.1:33842,DS-b90d1a35-fd5f-49d0-aba6-6195ae9e3975,DISK], DatanodeInfoWithStorage[127.0.0.1:46737,DS-4d5e3c59-6566-4165-a999-13ee1a47beee,DISK], DatanodeInfoWithStorage[127.0.0.1:39178,DS-110bac2c-04bc-44b9-b95e-066f4d8fb566,DISK], DatanodeInfoWithStorage[127.0.0.1:39010,DS-00b7f4c1-b1ca-4cec-9ed2-bc14079b497f,DISK], DatanodeInfoWithStorage[127.0.0.1:42271,DS-405a28a6-184a-4cf6-8a45-5dae505b0fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:45951,DS-ce12e34e-52a4-402a-adc5-a04542cd829c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-730696883-172.17.0.10-1597659335318:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40620,DS-d2689551-f810-4a3b-8481-37a05bd47d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39854,DS-1c27c4fb-6440-4323-9415-32166d2c56ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37711,DS-bffd06c5-bfb1-4e7f-bbd4-aaf42db7fcca,DISK], DatanodeInfoWithStorage[127.0.0.1:35602,DS-39805317-87c7-4801-9ee5-5c6522dde829,DISK], DatanodeInfoWithStorage[127.0.0.1:40274,DS-532dea4e-d73d-42c0-b367-fc1cb78087fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37525,DS-10f9e9d7-7398-46d4-9f66-40512e437f34,DISK], DatanodeInfoWithStorage[127.0.0.1:36936,DS-804f8c6c-9494-4e5d-abdb-8499443474b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36831,DS-bbee8152-0153-475b-bb55-119265d35fee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-730696883-172.17.0.10-1597659335318:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40620,DS-d2689551-f810-4a3b-8481-37a05bd47d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39854,DS-1c27c4fb-6440-4323-9415-32166d2c56ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37711,DS-bffd06c5-bfb1-4e7f-bbd4-aaf42db7fcca,DISK], DatanodeInfoWithStorage[127.0.0.1:35602,DS-39805317-87c7-4801-9ee5-5c6522dde829,DISK], DatanodeInfoWithStorage[127.0.0.1:40274,DS-532dea4e-d73d-42c0-b367-fc1cb78087fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37525,DS-10f9e9d7-7398-46d4-9f66-40512e437f34,DISK], DatanodeInfoWithStorage[127.0.0.1:36936,DS-804f8c6c-9494-4e5d-abdb-8499443474b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36831,DS-bbee8152-0153-475b-bb55-119265d35fee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1871147896-172.17.0.10-1597659414263:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46658,DS-0de7a3fa-f6b1-4018-ae37-3d567e314821,DISK], DatanodeInfoWithStorage[127.0.0.1:45829,DS-4ebf3383-ab68-4655-b0f2-10a4a7a78234,DISK], DatanodeInfoWithStorage[127.0.0.1:37049,DS-136c4837-f6b5-4444-8d54-2fefaf579914,DISK], DatanodeInfoWithStorage[127.0.0.1:42999,DS-57cffff0-8f8b-4fe8-9a01-4b769441bd14,DISK], DatanodeInfoWithStorage[127.0.0.1:38069,DS-68a7fea8-3e7b-42b7-a939-31425f80179d,DISK], DatanodeInfoWithStorage[127.0.0.1:39670,DS-2a9c592f-4adf-4882-ad4a-46b684de330d,DISK], DatanodeInfoWithStorage[127.0.0.1:34108,DS-16ffe920-7d6e-45cc-a6a8-fd008cb32f03,DISK], DatanodeInfoWithStorage[127.0.0.1:44541,DS-50fc3be1-92d0-459f-b428-b0d8ae3c8c1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1871147896-172.17.0.10-1597659414263:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46658,DS-0de7a3fa-f6b1-4018-ae37-3d567e314821,DISK], DatanodeInfoWithStorage[127.0.0.1:45829,DS-4ebf3383-ab68-4655-b0f2-10a4a7a78234,DISK], DatanodeInfoWithStorage[127.0.0.1:37049,DS-136c4837-f6b5-4444-8d54-2fefaf579914,DISK], DatanodeInfoWithStorage[127.0.0.1:42999,DS-57cffff0-8f8b-4fe8-9a01-4b769441bd14,DISK], DatanodeInfoWithStorage[127.0.0.1:38069,DS-68a7fea8-3e7b-42b7-a939-31425f80179d,DISK], DatanodeInfoWithStorage[127.0.0.1:39670,DS-2a9c592f-4adf-4882-ad4a-46b684de330d,DISK], DatanodeInfoWithStorage[127.0.0.1:34108,DS-16ffe920-7d6e-45cc-a6a8-fd008cb32f03,DISK], DatanodeInfoWithStorage[127.0.0.1:44541,DS-50fc3be1-92d0-459f-b428-b0d8ae3c8c1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1567889403-172.17.0.10-1597659482428:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36621,DS-a09e49da-fdb9-4e94-80e9-8535e3b424c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46319,DS-1198d76c-cf43-4141-89ed-2a264018d8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41940,DS-85973161-aa4d-418f-b41c-60f234faa0ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34854,DS-0eb5c2ca-3288-4e80-921a-200175264071,DISK], DatanodeInfoWithStorage[127.0.0.1:34040,DS-8c86b220-f00b-436a-8bde-a0609a8a85ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38213,DS-05318f70-2e50-4ab6-88a4-51ecdb1235e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36746,DS-5fce58e5-2971-44f1-bebd-e6483f038d58,DISK], DatanodeInfoWithStorage[127.0.0.1:44712,DS-f5ffb884-6dd0-4ec7-91d2-2f6e3ec22707,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1567889403-172.17.0.10-1597659482428:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36621,DS-a09e49da-fdb9-4e94-80e9-8535e3b424c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46319,DS-1198d76c-cf43-4141-89ed-2a264018d8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41940,DS-85973161-aa4d-418f-b41c-60f234faa0ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34854,DS-0eb5c2ca-3288-4e80-921a-200175264071,DISK], DatanodeInfoWithStorage[127.0.0.1:34040,DS-8c86b220-f00b-436a-8bde-a0609a8a85ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38213,DS-05318f70-2e50-4ab6-88a4-51ecdb1235e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36746,DS-5fce58e5-2971-44f1-bebd-e6483f038d58,DISK], DatanodeInfoWithStorage[127.0.0.1:44712,DS-f5ffb884-6dd0-4ec7-91d2-2f6e3ec22707,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1694942941-172.17.0.10-1597659556552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33647,DS-db3b409f-6289-407f-a09b-b4e49411718b,DISK], DatanodeInfoWithStorage[127.0.0.1:39732,DS-a2f16699-e620-4a14-9044-1c867dc8bc71,DISK], DatanodeInfoWithStorage[127.0.0.1:33078,DS-fad541e2-046b-43c9-89f5-57cc11f476b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36856,DS-8649af70-c8d7-4f73-a06f-82ec73305bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:40807,DS-ef3af560-26c2-4bd9-99db-af052486c0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44841,DS-da2c7972-b064-4f02-aa1f-c5bc55ad03e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41789,DS-d06a99a3-ca26-491e-8df3-853053b69f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43367,DS-0808d15f-f267-4fe3-90c2-ef0136fdbca3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1694942941-172.17.0.10-1597659556552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33647,DS-db3b409f-6289-407f-a09b-b4e49411718b,DISK], DatanodeInfoWithStorage[127.0.0.1:39732,DS-a2f16699-e620-4a14-9044-1c867dc8bc71,DISK], DatanodeInfoWithStorage[127.0.0.1:33078,DS-fad541e2-046b-43c9-89f5-57cc11f476b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36856,DS-8649af70-c8d7-4f73-a06f-82ec73305bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:40807,DS-ef3af560-26c2-4bd9-99db-af052486c0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44841,DS-da2c7972-b064-4f02-aa1f-c5bc55ad03e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41789,DS-d06a99a3-ca26-491e-8df3-853053b69f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43367,DS-0808d15f-f267-4fe3-90c2-ef0136fdbca3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-869048839-172.17.0.10-1597659630729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39576,DS-f0247ccd-f9c3-41e5-8f0f-03ba92ed29bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40072,DS-a274caad-ce35-4783-854a-ffba81559062,DISK], DatanodeInfoWithStorage[127.0.0.1:45285,DS-99965167-150e-43b0-a4b4-6135691b1e81,DISK], DatanodeInfoWithStorage[127.0.0.1:45129,DS-94183949-d73d-4e9a-b465-ef17e45efc51,DISK], DatanodeInfoWithStorage[127.0.0.1:35954,DS-c88bf08b-42e5-4250-a165-e1c56706cd90,DISK], DatanodeInfoWithStorage[127.0.0.1:43778,DS-d6bb9d99-5c73-4eb4-9091-5f9b520c8eca,DISK], DatanodeInfoWithStorage[127.0.0.1:36771,DS-5201a2f8-1f50-4be0-b750-b4920f9021d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45282,DS-2eea3577-e29e-4729-b03a-40543d4775e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-869048839-172.17.0.10-1597659630729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39576,DS-f0247ccd-f9c3-41e5-8f0f-03ba92ed29bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40072,DS-a274caad-ce35-4783-854a-ffba81559062,DISK], DatanodeInfoWithStorage[127.0.0.1:45285,DS-99965167-150e-43b0-a4b4-6135691b1e81,DISK], DatanodeInfoWithStorage[127.0.0.1:45129,DS-94183949-d73d-4e9a-b465-ef17e45efc51,DISK], DatanodeInfoWithStorage[127.0.0.1:35954,DS-c88bf08b-42e5-4250-a165-e1c56706cd90,DISK], DatanodeInfoWithStorage[127.0.0.1:43778,DS-d6bb9d99-5c73-4eb4-9091-5f9b520c8eca,DISK], DatanodeInfoWithStorage[127.0.0.1:36771,DS-5201a2f8-1f50-4be0-b750-b4920f9021d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45282,DS-2eea3577-e29e-4729-b03a-40543d4775e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-454069076-172.17.0.10-1597659986145:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43597,DS-89e45910-b248-4e14-905f-4f9049b9daa4,DISK], DatanodeInfoWithStorage[127.0.0.1:38390,DS-5839743c-6046-41ca-9a82-484659185f11,DISK], DatanodeInfoWithStorage[127.0.0.1:41646,DS-cf2c1235-33a5-4b84-bce3-bc17b870316a,DISK], DatanodeInfoWithStorage[127.0.0.1:35935,DS-73a70545-e7af-47c3-9bb9-0278d844c373,DISK], DatanodeInfoWithStorage[127.0.0.1:41953,DS-2447eefa-76e3-4f66-a412-2afabc95c2da,DISK], DatanodeInfoWithStorage[127.0.0.1:37883,DS-3c44dd9f-e7d0-449b-95b5-b29af77fa84f,DISK], DatanodeInfoWithStorage[127.0.0.1:40608,DS-7c10f0b2-7af1-4707-b5c3-415954089cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:40022,DS-145a062f-61f8-40d6-a08e-b0d500d579a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-454069076-172.17.0.10-1597659986145:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43597,DS-89e45910-b248-4e14-905f-4f9049b9daa4,DISK], DatanodeInfoWithStorage[127.0.0.1:38390,DS-5839743c-6046-41ca-9a82-484659185f11,DISK], DatanodeInfoWithStorage[127.0.0.1:41646,DS-cf2c1235-33a5-4b84-bce3-bc17b870316a,DISK], DatanodeInfoWithStorage[127.0.0.1:35935,DS-73a70545-e7af-47c3-9bb9-0278d844c373,DISK], DatanodeInfoWithStorage[127.0.0.1:41953,DS-2447eefa-76e3-4f66-a412-2afabc95c2da,DISK], DatanodeInfoWithStorage[127.0.0.1:37883,DS-3c44dd9f-e7d0-449b-95b5-b29af77fa84f,DISK], DatanodeInfoWithStorage[127.0.0.1:40608,DS-7c10f0b2-7af1-4707-b5c3-415954089cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:40022,DS-145a062f-61f8-40d6-a08e-b0d500d579a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1681136422-172.17.0.10-1597660024986:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39552,DS-0311ed76-d5f8-4418-bd0a-fa5ff79a8690,DISK], DatanodeInfoWithStorage[127.0.0.1:38181,DS-8316c815-0709-47cd-8e29-eef560f6476b,DISK], DatanodeInfoWithStorage[127.0.0.1:39124,DS-585f7965-aed2-4c9f-aba7-053a750ed213,DISK], DatanodeInfoWithStorage[127.0.0.1:46712,DS-6e5f2ffa-dc5e-480f-b1e5-d602f1f21e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:33420,DS-2753e157-483a-47e9-b063-3b58ceee0208,DISK], DatanodeInfoWithStorage[127.0.0.1:38127,DS-8eb4f1fd-e805-4339-b20c-c3d6a847005f,DISK], DatanodeInfoWithStorage[127.0.0.1:36756,DS-8624bf80-8671-4d53-9e45-0668688bff8a,DISK], DatanodeInfoWithStorage[127.0.0.1:32815,DS-b81b77f6-8e95-4bb9-bb3d-9be40c3b0e26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1681136422-172.17.0.10-1597660024986:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39552,DS-0311ed76-d5f8-4418-bd0a-fa5ff79a8690,DISK], DatanodeInfoWithStorage[127.0.0.1:38181,DS-8316c815-0709-47cd-8e29-eef560f6476b,DISK], DatanodeInfoWithStorage[127.0.0.1:39124,DS-585f7965-aed2-4c9f-aba7-053a750ed213,DISK], DatanodeInfoWithStorage[127.0.0.1:46712,DS-6e5f2ffa-dc5e-480f-b1e5-d602f1f21e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:33420,DS-2753e157-483a-47e9-b063-3b58ceee0208,DISK], DatanodeInfoWithStorage[127.0.0.1:38127,DS-8eb4f1fd-e805-4339-b20c-c3d6a847005f,DISK], DatanodeInfoWithStorage[127.0.0.1:36756,DS-8624bf80-8671-4d53-9e45-0668688bff8a,DISK], DatanodeInfoWithStorage[127.0.0.1:32815,DS-b81b77f6-8e95-4bb9-bb3d-9be40c3b0e26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1944686818-172.17.0.10-1597660072053:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41184,DS-a1fd2083-6fff-4ba2-b7c9-1281bffeed04,DISK], DatanodeInfoWithStorage[127.0.0.1:33212,DS-93a342a5-0a1b-40b5-a969-463a185cc8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34595,DS-17dc108d-625f-459e-aca1-20bd1248e7e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46247,DS-46c1e990-4f62-4440-85b9-9995db52e383,DISK], DatanodeInfoWithStorage[127.0.0.1:35545,DS-1cc4d912-b51d-4b5b-a128-6ccba4fdc568,DISK], DatanodeInfoWithStorage[127.0.0.1:33030,DS-6e51c822-23a6-41d8-bae8-3ce183166ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:39601,DS-ef4b2f35-67fb-4308-a280-5b931dcc0730,DISK], DatanodeInfoWithStorage[127.0.0.1:35759,DS-bae52c6c-977c-4767-97c5-6a575d5b1689,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1944686818-172.17.0.10-1597660072053:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41184,DS-a1fd2083-6fff-4ba2-b7c9-1281bffeed04,DISK], DatanodeInfoWithStorage[127.0.0.1:33212,DS-93a342a5-0a1b-40b5-a969-463a185cc8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34595,DS-17dc108d-625f-459e-aca1-20bd1248e7e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46247,DS-46c1e990-4f62-4440-85b9-9995db52e383,DISK], DatanodeInfoWithStorage[127.0.0.1:35545,DS-1cc4d912-b51d-4b5b-a128-6ccba4fdc568,DISK], DatanodeInfoWithStorage[127.0.0.1:33030,DS-6e51c822-23a6-41d8-bae8-3ce183166ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:39601,DS-ef4b2f35-67fb-4308-a280-5b931dcc0730,DISK], DatanodeInfoWithStorage[127.0.0.1:35759,DS-bae52c6c-977c-4767-97c5-6a575d5b1689,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1903616388-172.17.0.10-1597660715312:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36760,DS-e5485f13-e1b9-497b-9295-f5162eef249e,DISK], DatanodeInfoWithStorage[127.0.0.1:38772,DS-ff941fd9-d94a-4eb0-9012-91079368d114,DISK], DatanodeInfoWithStorage[127.0.0.1:39255,DS-0012bdaf-dc3e-49f0-a4c5-c7dc7573f54c,DISK], DatanodeInfoWithStorage[127.0.0.1:33032,DS-649d2f17-b4ab-4457-a686-a3781154c15f,DISK], DatanodeInfoWithStorage[127.0.0.1:34048,DS-a061d946-3f5d-41a5-8c83-c02c1c1d7a73,DISK], DatanodeInfoWithStorage[127.0.0.1:38874,DS-794c3ecd-74d5-44a8-8a85-2f409f86eb38,DISK], DatanodeInfoWithStorage[127.0.0.1:44570,DS-f6a92b70-b620-4959-aea8-bd54a32437b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37771,DS-130ac4f6-7bb5-4ca1-9f6e-1f3dd83b9b0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1903616388-172.17.0.10-1597660715312:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36760,DS-e5485f13-e1b9-497b-9295-f5162eef249e,DISK], DatanodeInfoWithStorage[127.0.0.1:38772,DS-ff941fd9-d94a-4eb0-9012-91079368d114,DISK], DatanodeInfoWithStorage[127.0.0.1:39255,DS-0012bdaf-dc3e-49f0-a4c5-c7dc7573f54c,DISK], DatanodeInfoWithStorage[127.0.0.1:33032,DS-649d2f17-b4ab-4457-a686-a3781154c15f,DISK], DatanodeInfoWithStorage[127.0.0.1:34048,DS-a061d946-3f5d-41a5-8c83-c02c1c1d7a73,DISK], DatanodeInfoWithStorage[127.0.0.1:38874,DS-794c3ecd-74d5-44a8-8a85-2f409f86eb38,DISK], DatanodeInfoWithStorage[127.0.0.1:44570,DS-f6a92b70-b620-4959-aea8-bd54a32437b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37771,DS-130ac4f6-7bb5-4ca1-9f6e-1f3dd83b9b0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-689416853-172.17.0.10-1597660756602:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39639,DS-41d10848-aa84-4ff7-baa4-c06e821b23f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40325,DS-68b8b6da-2ee7-444f-800b-237fe2327cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:38430,DS-22024da5-50dd-40bb-b7ad-ce6cc934630a,DISK], DatanodeInfoWithStorage[127.0.0.1:34926,DS-7b65408b-96b9-474a-85d6-704dc6307c71,DISK], DatanodeInfoWithStorage[127.0.0.1:45079,DS-bb443318-335f-4751-9e26-3968a5cb94d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33202,DS-6d2476f1-4128-4194-a2f0-686e7b86b856,DISK], DatanodeInfoWithStorage[127.0.0.1:36125,DS-0f7ecba0-ef73-49ad-81fa-0f17d378a514,DISK], DatanodeInfoWithStorage[127.0.0.1:46228,DS-862c28ab-f7fd-406b-b2e2-f41530fab03b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-689416853-172.17.0.10-1597660756602:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39639,DS-41d10848-aa84-4ff7-baa4-c06e821b23f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40325,DS-68b8b6da-2ee7-444f-800b-237fe2327cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:38430,DS-22024da5-50dd-40bb-b7ad-ce6cc934630a,DISK], DatanodeInfoWithStorage[127.0.0.1:34926,DS-7b65408b-96b9-474a-85d6-704dc6307c71,DISK], DatanodeInfoWithStorage[127.0.0.1:45079,DS-bb443318-335f-4751-9e26-3968a5cb94d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33202,DS-6d2476f1-4128-4194-a2f0-686e7b86b856,DISK], DatanodeInfoWithStorage[127.0.0.1:36125,DS-0f7ecba0-ef73-49ad-81fa-0f17d378a514,DISK], DatanodeInfoWithStorage[127.0.0.1:46228,DS-862c28ab-f7fd-406b-b2e2-f41530fab03b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1726005464-172.17.0.10-1597660915620:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38173,DS-ccba077f-3dc2-4ed8-9daf-b55af5b3afaa,DISK], DatanodeInfoWithStorage[127.0.0.1:35362,DS-d63110b8-5bc0-48e5-83ef-4d3adc20ff04,DISK], DatanodeInfoWithStorage[127.0.0.1:37500,DS-ccabd77d-3808-437c-b45f-4421dee36baa,DISK], DatanodeInfoWithStorage[127.0.0.1:42034,DS-a39ecef9-ee1d-45c1-88cb-afad240d9106,DISK], DatanodeInfoWithStorage[127.0.0.1:34280,DS-f43a3cb5-4693-43bc-aeba-0db3ee255b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:46458,DS-f7fce30b-918f-4aad-8750-d9b537119247,DISK], DatanodeInfoWithStorage[127.0.0.1:43522,DS-57cd1a40-647b-4e76-868e-cfa5598edb5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36136,DS-30f40f72-d6c8-46cd-bb94-8dccf1617163,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1726005464-172.17.0.10-1597660915620:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38173,DS-ccba077f-3dc2-4ed8-9daf-b55af5b3afaa,DISK], DatanodeInfoWithStorage[127.0.0.1:35362,DS-d63110b8-5bc0-48e5-83ef-4d3adc20ff04,DISK], DatanodeInfoWithStorage[127.0.0.1:37500,DS-ccabd77d-3808-437c-b45f-4421dee36baa,DISK], DatanodeInfoWithStorage[127.0.0.1:42034,DS-a39ecef9-ee1d-45c1-88cb-afad240d9106,DISK], DatanodeInfoWithStorage[127.0.0.1:34280,DS-f43a3cb5-4693-43bc-aeba-0db3ee255b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:46458,DS-f7fce30b-918f-4aad-8750-d9b537119247,DISK], DatanodeInfoWithStorage[127.0.0.1:43522,DS-57cd1a40-647b-4e76-868e-cfa5598edb5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36136,DS-30f40f72-d6c8-46cd-bb94-8dccf1617163,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-365001840-172.17.0.10-1597661067775:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36415,DS-98e8c195-7ec2-49aa-847e-15c3dec69dce,DISK], DatanodeInfoWithStorage[127.0.0.1:33271,DS-9c974996-5ddf-4327-a710-d74355e89c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:41718,DS-58c9d6c9-70a0-4c87-a92b-95e1b159d895,DISK], DatanodeInfoWithStorage[127.0.0.1:38521,DS-60df3d25-d69b-4301-9681-87b4e0751eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:40597,DS-c9bd9c79-619c-4420-8eb7-ea339d8221b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46362,DS-e0f25a1e-9869-4c82-9265-c34d19c6e45d,DISK], DatanodeInfoWithStorage[127.0.0.1:42556,DS-68678c23-741b-45dd-9e5d-5beca83b29f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43028,DS-0ba8a361-0f1b-4a38-acd7-c1913b09463c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-365001840-172.17.0.10-1597661067775:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36415,DS-98e8c195-7ec2-49aa-847e-15c3dec69dce,DISK], DatanodeInfoWithStorage[127.0.0.1:33271,DS-9c974996-5ddf-4327-a710-d74355e89c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:41718,DS-58c9d6c9-70a0-4c87-a92b-95e1b159d895,DISK], DatanodeInfoWithStorage[127.0.0.1:38521,DS-60df3d25-d69b-4301-9681-87b4e0751eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:40597,DS-c9bd9c79-619c-4420-8eb7-ea339d8221b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46362,DS-e0f25a1e-9869-4c82-9265-c34d19c6e45d,DISK], DatanodeInfoWithStorage[127.0.0.1:42556,DS-68678c23-741b-45dd-9e5d-5beca83b29f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43028,DS-0ba8a361-0f1b-4a38-acd7-c1913b09463c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-414260173-172.17.0.10-1597661107948:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37953,DS-665d00c2-d420-46ad-a022-410d1ce107fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44231,DS-faa6b06a-621e-4489-bd64-a6fb22be574a,DISK], DatanodeInfoWithStorage[127.0.0.1:42870,DS-f0179bdb-f9a6-4637-809d-2921ad7f10f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41414,DS-1ac574c7-760e-4859-b80c-e1dcc2b55433,DISK], DatanodeInfoWithStorage[127.0.0.1:38887,DS-90aa5573-5ac9-479c-96b6-35f9ab37c917,DISK], DatanodeInfoWithStorage[127.0.0.1:33460,DS-2588bb33-b298-4e86-809f-502fbbc68cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:41021,DS-6cd0b689-a855-46ff-8c89-f99070b4146e,DISK], DatanodeInfoWithStorage[127.0.0.1:41642,DS-2a534e03-84df-45ba-904c-458014f84f4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-414260173-172.17.0.10-1597661107948:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37953,DS-665d00c2-d420-46ad-a022-410d1ce107fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44231,DS-faa6b06a-621e-4489-bd64-a6fb22be574a,DISK], DatanodeInfoWithStorage[127.0.0.1:42870,DS-f0179bdb-f9a6-4637-809d-2921ad7f10f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41414,DS-1ac574c7-760e-4859-b80c-e1dcc2b55433,DISK], DatanodeInfoWithStorage[127.0.0.1:38887,DS-90aa5573-5ac9-479c-96b6-35f9ab37c917,DISK], DatanodeInfoWithStorage[127.0.0.1:33460,DS-2588bb33-b298-4e86-809f-502fbbc68cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:41021,DS-6cd0b689-a855-46ff-8c89-f99070b4146e,DISK], DatanodeInfoWithStorage[127.0.0.1:41642,DS-2a534e03-84df-45ba-904c-458014f84f4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-425029871-172.17.0.10-1597661395880:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46798,DS-41901994-10a7-4685-b6a5-e2d614f5a21d,DISK], DatanodeInfoWithStorage[127.0.0.1:44898,DS-4350d424-eb91-47cd-9c19-329f13695d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:34473,DS-06fd3ba5-5b97-4f2f-902e-1d65ff0eff22,DISK], DatanodeInfoWithStorage[127.0.0.1:38071,DS-cf64a7f4-bf79-4c8e-9387-9434b5729c00,DISK], DatanodeInfoWithStorage[127.0.0.1:33407,DS-30f3accc-9a6f-4f13-bad5-44549527100f,DISK], DatanodeInfoWithStorage[127.0.0.1:45630,DS-d45e2418-ecf2-4485-8710-13aa2e266c78,DISK], DatanodeInfoWithStorage[127.0.0.1:46048,DS-f9939737-ba51-4dec-b0c4-ee1fea6f2b10,DISK], DatanodeInfoWithStorage[127.0.0.1:44140,DS-406eac69-b81b-4013-b66a-072ed6e4e273,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-425029871-172.17.0.10-1597661395880:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46798,DS-41901994-10a7-4685-b6a5-e2d614f5a21d,DISK], DatanodeInfoWithStorage[127.0.0.1:44898,DS-4350d424-eb91-47cd-9c19-329f13695d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:34473,DS-06fd3ba5-5b97-4f2f-902e-1d65ff0eff22,DISK], DatanodeInfoWithStorage[127.0.0.1:38071,DS-cf64a7f4-bf79-4c8e-9387-9434b5729c00,DISK], DatanodeInfoWithStorage[127.0.0.1:33407,DS-30f3accc-9a6f-4f13-bad5-44549527100f,DISK], DatanodeInfoWithStorage[127.0.0.1:45630,DS-d45e2418-ecf2-4485-8710-13aa2e266c78,DISK], DatanodeInfoWithStorage[127.0.0.1:46048,DS-f9939737-ba51-4dec-b0c4-ee1fea6f2b10,DISK], DatanodeInfoWithStorage[127.0.0.1:44140,DS-406eac69-b81b-4013-b66a-072ed6e4e273,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-980250971-172.17.0.10-1597661438908:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33298,DS-6eaee43e-f35b-424b-9a5b-03f26aeeaaa0,DISK], DatanodeInfoWithStorage[127.0.0.1:38573,DS-49fd5dbe-909f-4b5c-ae8f-9fba419304b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40201,DS-6f5781c2-983f-4bd5-a6b7-3751171a7446,DISK], DatanodeInfoWithStorage[127.0.0.1:42381,DS-8041ba7d-338c-4746-9e5f-b3576cfa7e80,DISK], DatanodeInfoWithStorage[127.0.0.1:36444,DS-fa2a9fd7-41d7-473a-bad7-b1296b12056c,DISK], DatanodeInfoWithStorage[127.0.0.1:35762,DS-6a8cbf7d-25a5-4119-a2a0-3685b03b8d81,DISK], DatanodeInfoWithStorage[127.0.0.1:36652,DS-d01b0c89-fec2-42ad-9f0b-686c2e3f2f77,DISK], DatanodeInfoWithStorage[127.0.0.1:38587,DS-42e5756b-5631-4c24-8f3a-ccdcc0815813,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-980250971-172.17.0.10-1597661438908:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33298,DS-6eaee43e-f35b-424b-9a5b-03f26aeeaaa0,DISK], DatanodeInfoWithStorage[127.0.0.1:38573,DS-49fd5dbe-909f-4b5c-ae8f-9fba419304b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40201,DS-6f5781c2-983f-4bd5-a6b7-3751171a7446,DISK], DatanodeInfoWithStorage[127.0.0.1:42381,DS-8041ba7d-338c-4746-9e5f-b3576cfa7e80,DISK], DatanodeInfoWithStorage[127.0.0.1:36444,DS-fa2a9fd7-41d7-473a-bad7-b1296b12056c,DISK], DatanodeInfoWithStorage[127.0.0.1:35762,DS-6a8cbf7d-25a5-4119-a2a0-3685b03b8d81,DISK], DatanodeInfoWithStorage[127.0.0.1:36652,DS-d01b0c89-fec2-42ad-9f0b-686c2e3f2f77,DISK], DatanodeInfoWithStorage[127.0.0.1:38587,DS-42e5756b-5631-4c24-8f3a-ccdcc0815813,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5758
