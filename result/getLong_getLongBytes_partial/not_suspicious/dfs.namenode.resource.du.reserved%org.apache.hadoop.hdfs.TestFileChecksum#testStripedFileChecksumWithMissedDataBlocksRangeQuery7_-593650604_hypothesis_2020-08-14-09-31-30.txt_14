reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1825107546-172.17.0.5-1597397544919:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34048,DS-9905e46e-86ca-430d-8639-0a4337d1ec16,DISK], DatanodeInfoWithStorage[127.0.0.1:38469,DS-461c4773-d80a-49fa-be47-0ad05e80f103,DISK], DatanodeInfoWithStorage[127.0.0.1:36809,DS-eb2f0d66-1f7f-4596-abcd-505f1d41a264,DISK], DatanodeInfoWithStorage[127.0.0.1:42734,DS-bfb8445b-4b9d-4d46-a6a7-ae4128739d56,DISK], DatanodeInfoWithStorage[127.0.0.1:35310,DS-01b8a06c-370c-4e00-866c-83a2b2d09c19,DISK], DatanodeInfoWithStorage[127.0.0.1:34169,DS-5dcfff94-63e0-4b00-8664-ac9e15662cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:38754,DS-ae25efe9-f5ff-4715-86f2-37619d04c62d,DISK], DatanodeInfoWithStorage[127.0.0.1:36890,DS-bc6db9a7-d243-444b-a69b-0a27646a5cf5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1825107546-172.17.0.5-1597397544919:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34048,DS-9905e46e-86ca-430d-8639-0a4337d1ec16,DISK], DatanodeInfoWithStorage[127.0.0.1:38469,DS-461c4773-d80a-49fa-be47-0ad05e80f103,DISK], DatanodeInfoWithStorage[127.0.0.1:36809,DS-eb2f0d66-1f7f-4596-abcd-505f1d41a264,DISK], DatanodeInfoWithStorage[127.0.0.1:42734,DS-bfb8445b-4b9d-4d46-a6a7-ae4128739d56,DISK], DatanodeInfoWithStorage[127.0.0.1:35310,DS-01b8a06c-370c-4e00-866c-83a2b2d09c19,DISK], DatanodeInfoWithStorage[127.0.0.1:34169,DS-5dcfff94-63e0-4b00-8664-ac9e15662cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:38754,DS-ae25efe9-f5ff-4715-86f2-37619d04c62d,DISK], DatanodeInfoWithStorage[127.0.0.1:36890,DS-bc6db9a7-d243-444b-a69b-0a27646a5cf5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-122091615-172.17.0.5-1597397746279:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39654,DS-468ea412-6fc1-4dee-8516-988a29fb5e22,DISK], DatanodeInfoWithStorage[127.0.0.1:39531,DS-ff404dba-7966-42cf-8374-b28bef635dad,DISK], DatanodeInfoWithStorage[127.0.0.1:35717,DS-ad9409f8-9492-42fd-96b5-d247406daf45,DISK], DatanodeInfoWithStorage[127.0.0.1:42353,DS-ef261ba3-ea70-48fb-bc39-61ebe40e3ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:36923,DS-a4702883-0dfb-4805-990c-aaaa00934031,DISK], DatanodeInfoWithStorage[127.0.0.1:46074,DS-35e779e0-4f01-4f06-ac8d-3f6f333c67ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45267,DS-7716bb29-0609-4d51-91ef-20ae267eee7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45613,DS-c71f819c-367e-485e-a2e9-c6d3ce8d1367,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-122091615-172.17.0.5-1597397746279:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39654,DS-468ea412-6fc1-4dee-8516-988a29fb5e22,DISK], DatanodeInfoWithStorage[127.0.0.1:39531,DS-ff404dba-7966-42cf-8374-b28bef635dad,DISK], DatanodeInfoWithStorage[127.0.0.1:35717,DS-ad9409f8-9492-42fd-96b5-d247406daf45,DISK], DatanodeInfoWithStorage[127.0.0.1:42353,DS-ef261ba3-ea70-48fb-bc39-61ebe40e3ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:36923,DS-a4702883-0dfb-4805-990c-aaaa00934031,DISK], DatanodeInfoWithStorage[127.0.0.1:46074,DS-35e779e0-4f01-4f06-ac8d-3f6f333c67ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45267,DS-7716bb29-0609-4d51-91ef-20ae267eee7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45613,DS-c71f819c-367e-485e-a2e9-c6d3ce8d1367,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1500138459-172.17.0.5-1597398120127:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39730,DS-6b31f508-7818-457c-b60e-da574d625e49,DISK], DatanodeInfoWithStorage[127.0.0.1:44801,DS-a8434902-352e-4c9d-a159-76f2d796a5e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36604,DS-c6adf65f-7984-40fc-80ab-e797da976213,DISK], DatanodeInfoWithStorage[127.0.0.1:38788,DS-46b789e8-9380-4b73-a94d-9ab45901368e,DISK], DatanodeInfoWithStorage[127.0.0.1:36543,DS-5a6cebbb-0a7f-45c0-bebe-92d2a5c797af,DISK], DatanodeInfoWithStorage[127.0.0.1:34069,DS-347c017b-bf78-4d85-9f37-d302bc0b963e,DISK], DatanodeInfoWithStorage[127.0.0.1:34756,DS-eab13e7e-47ce-477b-93a6-459423f2104b,DISK], DatanodeInfoWithStorage[127.0.0.1:35620,DS-f711e4ff-de8c-47e8-88df-cd4c2fefadd4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1500138459-172.17.0.5-1597398120127:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39730,DS-6b31f508-7818-457c-b60e-da574d625e49,DISK], DatanodeInfoWithStorage[127.0.0.1:44801,DS-a8434902-352e-4c9d-a159-76f2d796a5e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36604,DS-c6adf65f-7984-40fc-80ab-e797da976213,DISK], DatanodeInfoWithStorage[127.0.0.1:38788,DS-46b789e8-9380-4b73-a94d-9ab45901368e,DISK], DatanodeInfoWithStorage[127.0.0.1:36543,DS-5a6cebbb-0a7f-45c0-bebe-92d2a5c797af,DISK], DatanodeInfoWithStorage[127.0.0.1:34069,DS-347c017b-bf78-4d85-9f37-d302bc0b963e,DISK], DatanodeInfoWithStorage[127.0.0.1:34756,DS-eab13e7e-47ce-477b-93a6-459423f2104b,DISK], DatanodeInfoWithStorage[127.0.0.1:35620,DS-f711e4ff-de8c-47e8-88df-cd4c2fefadd4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1839706882-172.17.0.5-1597398151227:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38325,DS-5fdca55a-1310-4fd5-8bd5-0c156920d571,DISK], DatanodeInfoWithStorage[127.0.0.1:35598,DS-16904cb4-e494-48d6-a082-e310c6498a42,DISK], DatanodeInfoWithStorage[127.0.0.1:42642,DS-4b21d736-8dc9-4960-a5d4-288d76dd47b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36196,DS-1a089528-26aa-477c-ae3e-40e5eab61e06,DISK], DatanodeInfoWithStorage[127.0.0.1:40267,DS-f66da33f-a887-4caa-908f-92b313d89f81,DISK], DatanodeInfoWithStorage[127.0.0.1:39464,DS-44197656-aab7-40e2-b98c-cf73fbb1c1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39184,DS-cf240180-29e7-4b63-8560-c8e60b3dd9ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39662,DS-2f063576-acc4-47af-8aad-b0dce78a0b83,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1839706882-172.17.0.5-1597398151227:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38325,DS-5fdca55a-1310-4fd5-8bd5-0c156920d571,DISK], DatanodeInfoWithStorage[127.0.0.1:35598,DS-16904cb4-e494-48d6-a082-e310c6498a42,DISK], DatanodeInfoWithStorage[127.0.0.1:42642,DS-4b21d736-8dc9-4960-a5d4-288d76dd47b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36196,DS-1a089528-26aa-477c-ae3e-40e5eab61e06,DISK], DatanodeInfoWithStorage[127.0.0.1:40267,DS-f66da33f-a887-4caa-908f-92b313d89f81,DISK], DatanodeInfoWithStorage[127.0.0.1:39464,DS-44197656-aab7-40e2-b98c-cf73fbb1c1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39184,DS-cf240180-29e7-4b63-8560-c8e60b3dd9ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39662,DS-2f063576-acc4-47af-8aad-b0dce78a0b83,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2098048478-172.17.0.5-1597398540779:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44988,DS-b5359a58-ae30-4095-aa29-a13ca06ecbfa,DISK], DatanodeInfoWithStorage[127.0.0.1:46418,DS-992fe21d-8ff4-4c07-bf8b-6d5ad435095f,DISK], DatanodeInfoWithStorage[127.0.0.1:36542,DS-8851e49c-69ad-4fb3-81a3-11724f71c4e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40302,DS-1e74d449-981f-4755-a10f-5c9467cc22f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33277,DS-4a128ae4-7b3b-4a7a-994c-a5e7dfb9a688,DISK], DatanodeInfoWithStorage[127.0.0.1:34810,DS-98ba5961-2be3-4cd2-9898-4bab75f33613,DISK], DatanodeInfoWithStorage[127.0.0.1:35526,DS-fb021a07-32b2-42dd-b89f-68ff200a0152,DISK], DatanodeInfoWithStorage[127.0.0.1:41212,DS-b8ef60b2-d236-4821-8f79-fa5dabf7c1a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2098048478-172.17.0.5-1597398540779:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44988,DS-b5359a58-ae30-4095-aa29-a13ca06ecbfa,DISK], DatanodeInfoWithStorage[127.0.0.1:46418,DS-992fe21d-8ff4-4c07-bf8b-6d5ad435095f,DISK], DatanodeInfoWithStorage[127.0.0.1:36542,DS-8851e49c-69ad-4fb3-81a3-11724f71c4e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40302,DS-1e74d449-981f-4755-a10f-5c9467cc22f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33277,DS-4a128ae4-7b3b-4a7a-994c-a5e7dfb9a688,DISK], DatanodeInfoWithStorage[127.0.0.1:34810,DS-98ba5961-2be3-4cd2-9898-4bab75f33613,DISK], DatanodeInfoWithStorage[127.0.0.1:35526,DS-fb021a07-32b2-42dd-b89f-68ff200a0152,DISK], DatanodeInfoWithStorage[127.0.0.1:41212,DS-b8ef60b2-d236-4821-8f79-fa5dabf7c1a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-645816785-172.17.0.5-1597398572725:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39581,DS-9a5882c5-8037-496b-a624-33d6c6fa6b00,DISK], DatanodeInfoWithStorage[127.0.0.1:38987,DS-a6122e41-f4a6-48a4-a50f-1058fb1df311,DISK], DatanodeInfoWithStorage[127.0.0.1:44065,DS-a2f95f9e-4af1-4ae6-85af-a672f6e334d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39974,DS-074caca7-67ae-4cf0-966a-ce2b6ab65e37,DISK], DatanodeInfoWithStorage[127.0.0.1:41926,DS-9979f69f-e7cc-49f2-9422-78061c2171c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33248,DS-91f1946e-4af2-4b26-945f-0be791875d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39361,DS-40424429-69ce-41dd-abc2-f0331fd9a5f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33773,DS-e5c5fb91-00ef-4a11-a872-5bfcfb943112,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-645816785-172.17.0.5-1597398572725:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39581,DS-9a5882c5-8037-496b-a624-33d6c6fa6b00,DISK], DatanodeInfoWithStorage[127.0.0.1:38987,DS-a6122e41-f4a6-48a4-a50f-1058fb1df311,DISK], DatanodeInfoWithStorage[127.0.0.1:44065,DS-a2f95f9e-4af1-4ae6-85af-a672f6e334d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39974,DS-074caca7-67ae-4cf0-966a-ce2b6ab65e37,DISK], DatanodeInfoWithStorage[127.0.0.1:41926,DS-9979f69f-e7cc-49f2-9422-78061c2171c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33248,DS-91f1946e-4af2-4b26-945f-0be791875d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39361,DS-40424429-69ce-41dd-abc2-f0331fd9a5f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33773,DS-e5c5fb91-00ef-4a11-a872-5bfcfb943112,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-302629329-172.17.0.5-1597398685285:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45922,DS-cf0c055d-417d-4a53-8c03-e440e8b93401,DISK], DatanodeInfoWithStorage[127.0.0.1:39442,DS-65c01644-a6f4-4fd5-92ec-944eea785901,DISK], DatanodeInfoWithStorage[127.0.0.1:37096,DS-6b31a1fb-1782-42e5-8800-ba907c0dbb87,DISK], DatanodeInfoWithStorage[127.0.0.1:45175,DS-d54ee0f1-56af-486b-8f97-86bf0fd9185a,DISK], DatanodeInfoWithStorage[127.0.0.1:41997,DS-805d2a0c-136e-40b4-928b-8676282d8323,DISK], DatanodeInfoWithStorage[127.0.0.1:37560,DS-a1884875-2920-42a3-b46c-5265d8fa3bee,DISK], DatanodeInfoWithStorage[127.0.0.1:46586,DS-06f0a52d-0638-492b-ad0d-148270ee90b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35009,DS-fcc0e49b-799b-4357-b122-dd3165e50859,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-302629329-172.17.0.5-1597398685285:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45922,DS-cf0c055d-417d-4a53-8c03-e440e8b93401,DISK], DatanodeInfoWithStorage[127.0.0.1:39442,DS-65c01644-a6f4-4fd5-92ec-944eea785901,DISK], DatanodeInfoWithStorage[127.0.0.1:37096,DS-6b31a1fb-1782-42e5-8800-ba907c0dbb87,DISK], DatanodeInfoWithStorage[127.0.0.1:45175,DS-d54ee0f1-56af-486b-8f97-86bf0fd9185a,DISK], DatanodeInfoWithStorage[127.0.0.1:41997,DS-805d2a0c-136e-40b4-928b-8676282d8323,DISK], DatanodeInfoWithStorage[127.0.0.1:37560,DS-a1884875-2920-42a3-b46c-5265d8fa3bee,DISK], DatanodeInfoWithStorage[127.0.0.1:46586,DS-06f0a52d-0638-492b-ad0d-148270ee90b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35009,DS-fcc0e49b-799b-4357-b122-dd3165e50859,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-436980108-172.17.0.5-1597398840776:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43612,DS-0a942e54-fdbe-4dbf-ad6a-64aacb611b66,DISK], DatanodeInfoWithStorage[127.0.0.1:41698,DS-3501a62b-f9e9-4f1f-91e1-dfe44e41a3ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42918,DS-5a208427-9b91-4003-b32e-e70f432d1096,DISK], DatanodeInfoWithStorage[127.0.0.1:37786,DS-5f1ed832-9844-4c8d-ad56-d8ed36012c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:38414,DS-889bee55-54be-4c0d-b7f0-cb827407e7e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38412,DS-aaa5455b-cb31-4092-8f86-ce69d2d6ba80,DISK], DatanodeInfoWithStorage[127.0.0.1:38908,DS-c138bfa6-431a-4c90-b800-8c59bbeffc7e,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-31cdd9db-b68b-4839-87ba-df1b33923d17,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-436980108-172.17.0.5-1597398840776:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43612,DS-0a942e54-fdbe-4dbf-ad6a-64aacb611b66,DISK], DatanodeInfoWithStorage[127.0.0.1:41698,DS-3501a62b-f9e9-4f1f-91e1-dfe44e41a3ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42918,DS-5a208427-9b91-4003-b32e-e70f432d1096,DISK], DatanodeInfoWithStorage[127.0.0.1:37786,DS-5f1ed832-9844-4c8d-ad56-d8ed36012c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:38414,DS-889bee55-54be-4c0d-b7f0-cb827407e7e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38412,DS-aaa5455b-cb31-4092-8f86-ce69d2d6ba80,DISK], DatanodeInfoWithStorage[127.0.0.1:38908,DS-c138bfa6-431a-4c90-b800-8c59bbeffc7e,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-31cdd9db-b68b-4839-87ba-df1b33923d17,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1063690588-172.17.0.5-1597399177704:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46846,DS-fd487d65-4254-4db9-918d-f84d40359dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:42840,DS-f8f9750b-340e-45a5-81de-e3edcc8acdea,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-beee45db-7736-492c-b080-a12a0ca471ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45050,DS-f0cc253d-2687-4dce-9a6a-48f759f0c7f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40409,DS-96b07a82-164d-4787-aa22-7c9b3c681362,DISK], DatanodeInfoWithStorage[127.0.0.1:40631,DS-a7174b65-c36b-47ee-a024-a44e2b2b447a,DISK], DatanodeInfoWithStorage[127.0.0.1:42897,DS-bf941d05-7fa1-4b9e-ac0c-98167d996619,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-5d157511-f003-40d6-99ba-c5e077ff9301,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1063690588-172.17.0.5-1597399177704:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46846,DS-fd487d65-4254-4db9-918d-f84d40359dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:42840,DS-f8f9750b-340e-45a5-81de-e3edcc8acdea,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-beee45db-7736-492c-b080-a12a0ca471ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45050,DS-f0cc253d-2687-4dce-9a6a-48f759f0c7f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40409,DS-96b07a82-164d-4787-aa22-7c9b3c681362,DISK], DatanodeInfoWithStorage[127.0.0.1:40631,DS-a7174b65-c36b-47ee-a024-a44e2b2b447a,DISK], DatanodeInfoWithStorage[127.0.0.1:42897,DS-bf941d05-7fa1-4b9e-ac0c-98167d996619,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-5d157511-f003-40d6-99ba-c5e077ff9301,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1544967810-172.17.0.5-1597399279589:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39203,DS-d5bd61df-8806-42d8-a395-b94750742593,DISK], DatanodeInfoWithStorage[127.0.0.1:39333,DS-1e7380e0-5791-4447-a969-36b658f036d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35107,DS-bdf5a667-34d2-4990-899a-f20b9e7572d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39093,DS-b51c10e5-5beb-4f1f-9d96-29c456410f18,DISK], DatanodeInfoWithStorage[127.0.0.1:35698,DS-2e72a48e-be87-4696-b0f2-b9e1175c40e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46535,DS-6eb48af6-9615-48a2-beba-ffb3e210b1ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45693,DS-7ca432ba-f03b-4d32-b521-d0115ccd0246,DISK], DatanodeInfoWithStorage[127.0.0.1:38422,DS-0ac7f469-7110-46e8-a508-3d73f80e7e4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1544967810-172.17.0.5-1597399279589:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39203,DS-d5bd61df-8806-42d8-a395-b94750742593,DISK], DatanodeInfoWithStorage[127.0.0.1:39333,DS-1e7380e0-5791-4447-a969-36b658f036d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35107,DS-bdf5a667-34d2-4990-899a-f20b9e7572d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39093,DS-b51c10e5-5beb-4f1f-9d96-29c456410f18,DISK], DatanodeInfoWithStorage[127.0.0.1:35698,DS-2e72a48e-be87-4696-b0f2-b9e1175c40e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46535,DS-6eb48af6-9615-48a2-beba-ffb3e210b1ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45693,DS-7ca432ba-f03b-4d32-b521-d0115ccd0246,DISK], DatanodeInfoWithStorage[127.0.0.1:38422,DS-0ac7f469-7110-46e8-a508-3d73f80e7e4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-629479008-172.17.0.5-1597399344965:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35582,DS-41f12481-f098-4425-b6a5-39afc5287490,DISK], DatanodeInfoWithStorage[127.0.0.1:44572,DS-a5a3fa23-e888-49c0-961b-9dbb28fb8cea,DISK], DatanodeInfoWithStorage[127.0.0.1:46469,DS-93da6000-ce78-4427-aee8-b5ac8feaa893,DISK], DatanodeInfoWithStorage[127.0.0.1:38792,DS-22d3df47-e264-428d-8bbc-c34cbc257aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:36044,DS-87397568-cd88-4c90-b241-2ef381b5b53f,DISK], DatanodeInfoWithStorage[127.0.0.1:46791,DS-933e2192-80ba-4983-b695-f2ed84a02464,DISK], DatanodeInfoWithStorage[127.0.0.1:36416,DS-90f7899e-edbf-40ae-ac8c-e42cd2d76f81,DISK], DatanodeInfoWithStorage[127.0.0.1:35499,DS-cee7c1b2-d1d8-47a8-8bf9-4829b8bdcf0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-629479008-172.17.0.5-1597399344965:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35582,DS-41f12481-f098-4425-b6a5-39afc5287490,DISK], DatanodeInfoWithStorage[127.0.0.1:44572,DS-a5a3fa23-e888-49c0-961b-9dbb28fb8cea,DISK], DatanodeInfoWithStorage[127.0.0.1:46469,DS-93da6000-ce78-4427-aee8-b5ac8feaa893,DISK], DatanodeInfoWithStorage[127.0.0.1:38792,DS-22d3df47-e264-428d-8bbc-c34cbc257aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:36044,DS-87397568-cd88-4c90-b241-2ef381b5b53f,DISK], DatanodeInfoWithStorage[127.0.0.1:46791,DS-933e2192-80ba-4983-b695-f2ed84a02464,DISK], DatanodeInfoWithStorage[127.0.0.1:36416,DS-90f7899e-edbf-40ae-ac8c-e42cd2d76f81,DISK], DatanodeInfoWithStorage[127.0.0.1:35499,DS-cee7c1b2-d1d8-47a8-8bf9-4829b8bdcf0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1040168130-172.17.0.5-1597399384694:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35960,DS-f37cc5b9-b1d2-4aab-86cf-2da2f4a72e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40371,DS-3ba382f9-5b0d-4108-87d6-db1db8ce6b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:44181,DS-e98aef77-da68-4f1b-a6e8-5b8dd24778a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46655,DS-cf465998-d535-4231-af80-21baea52b55f,DISK], DatanodeInfoWithStorage[127.0.0.1:46719,DS-d1e8f98f-2f01-4aab-bbfa-b7ef875df6d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43673,DS-35cdc5d7-7b89-4977-87de-5a3a64426181,DISK], DatanodeInfoWithStorage[127.0.0.1:35266,DS-5e70d4da-731f-44ff-afe6-982468cc626b,DISK], DatanodeInfoWithStorage[127.0.0.1:45214,DS-3167f54b-7fce-454a-81b9-a5bbdaece77b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1040168130-172.17.0.5-1597399384694:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35960,DS-f37cc5b9-b1d2-4aab-86cf-2da2f4a72e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40371,DS-3ba382f9-5b0d-4108-87d6-db1db8ce6b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:44181,DS-e98aef77-da68-4f1b-a6e8-5b8dd24778a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46655,DS-cf465998-d535-4231-af80-21baea52b55f,DISK], DatanodeInfoWithStorage[127.0.0.1:46719,DS-d1e8f98f-2f01-4aab-bbfa-b7ef875df6d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43673,DS-35cdc5d7-7b89-4977-87de-5a3a64426181,DISK], DatanodeInfoWithStorage[127.0.0.1:35266,DS-5e70d4da-731f-44ff-afe6-982468cc626b,DISK], DatanodeInfoWithStorage[127.0.0.1:45214,DS-3167f54b-7fce-454a-81b9-a5bbdaece77b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-6310610-172.17.0.5-1597399488539:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46445,DS-d20d18ed-53fd-4b49-9657-7bc7c1487488,DISK], DatanodeInfoWithStorage[127.0.0.1:39815,DS-74a15b91-c779-45cd-b340-cc64ab9b2fca,DISK], DatanodeInfoWithStorage[127.0.0.1:45605,DS-2eaeca1f-dcb6-4a35-a6c4-f3a3e7f334bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45026,DS-92171cff-444f-4f7e-a9cd-6544b4da49b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-96ef7754-7749-4f68-ac17-20a70afa24a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42303,DS-0a30da30-0322-4102-844b-6e790b48c08a,DISK], DatanodeInfoWithStorage[127.0.0.1:34603,DS-13ba46e7-7380-4138-8300-c13dcf50dca6,DISK], DatanodeInfoWithStorage[127.0.0.1:37374,DS-fa3e5533-d6a0-4299-a053-5d65f0d67a52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-6310610-172.17.0.5-1597399488539:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46445,DS-d20d18ed-53fd-4b49-9657-7bc7c1487488,DISK], DatanodeInfoWithStorage[127.0.0.1:39815,DS-74a15b91-c779-45cd-b340-cc64ab9b2fca,DISK], DatanodeInfoWithStorage[127.0.0.1:45605,DS-2eaeca1f-dcb6-4a35-a6c4-f3a3e7f334bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45026,DS-92171cff-444f-4f7e-a9cd-6544b4da49b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-96ef7754-7749-4f68-ac17-20a70afa24a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42303,DS-0a30da30-0322-4102-844b-6e790b48c08a,DISK], DatanodeInfoWithStorage[127.0.0.1:34603,DS-13ba46e7-7380-4138-8300-c13dcf50dca6,DISK], DatanodeInfoWithStorage[127.0.0.1:37374,DS-fa3e5533-d6a0-4299-a053-5d65f0d67a52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2147333707-172.17.0.5-1597399666585:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43311,DS-f123e9d6-48ad-4499-8f09-149066904c02,DISK], DatanodeInfoWithStorage[127.0.0.1:46124,DS-6e623226-4890-425a-9c1e-be0cf98d7f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:34394,DS-dcd58129-c3e1-4ca4-8245-ae48762bf91b,DISK], DatanodeInfoWithStorage[127.0.0.1:34397,DS-d423c83a-f695-440f-aafb-d1d60a744b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:40439,DS-702d9ac4-810b-4313-965c-8afb93f1cce3,DISK], DatanodeInfoWithStorage[127.0.0.1:38195,DS-39a2813c-8ac1-4b66-927b-21cecaeb16d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40045,DS-0c28929d-bd6e-44ef-a1f5-6283c8200bce,DISK], DatanodeInfoWithStorage[127.0.0.1:45771,DS-8b0723c8-ca2c-4573-a9f1-5fcb31dda075,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2147333707-172.17.0.5-1597399666585:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43311,DS-f123e9d6-48ad-4499-8f09-149066904c02,DISK], DatanodeInfoWithStorage[127.0.0.1:46124,DS-6e623226-4890-425a-9c1e-be0cf98d7f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:34394,DS-dcd58129-c3e1-4ca4-8245-ae48762bf91b,DISK], DatanodeInfoWithStorage[127.0.0.1:34397,DS-d423c83a-f695-440f-aafb-d1d60a744b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:40439,DS-702d9ac4-810b-4313-965c-8afb93f1cce3,DISK], DatanodeInfoWithStorage[127.0.0.1:38195,DS-39a2813c-8ac1-4b66-927b-21cecaeb16d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40045,DS-0c28929d-bd6e-44ef-a1f5-6283c8200bce,DISK], DatanodeInfoWithStorage[127.0.0.1:45771,DS-8b0723c8-ca2c-4573-a9f1-5fcb31dda075,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1202367283-172.17.0.5-1597399696730:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36964,DS-922e1cf9-5e84-4510-804a-432a9dbd1548,DISK], DatanodeInfoWithStorage[127.0.0.1:33112,DS-ecaee246-1568-418e-bca8-a491229792f2,DISK], DatanodeInfoWithStorage[127.0.0.1:32941,DS-72671c0f-b22f-4202-97cb-319d486da96a,DISK], DatanodeInfoWithStorage[127.0.0.1:46038,DS-3739c404-9809-4d18-80bf-8c0682c2be47,DISK], DatanodeInfoWithStorage[127.0.0.1:45860,DS-3c6c49f1-e275-4826-a8a9-bdfdc516c6ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40822,DS-370ed3bd-e469-4e39-94f7-fe43700c7f64,DISK], DatanodeInfoWithStorage[127.0.0.1:41888,DS-1eb2f5ee-829e-4fa1-9d1d-f2249401d76b,DISK], DatanodeInfoWithStorage[127.0.0.1:40774,DS-33ef86cd-c2f6-4c04-b131-9d95e88811d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1202367283-172.17.0.5-1597399696730:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36964,DS-922e1cf9-5e84-4510-804a-432a9dbd1548,DISK], DatanodeInfoWithStorage[127.0.0.1:33112,DS-ecaee246-1568-418e-bca8-a491229792f2,DISK], DatanodeInfoWithStorage[127.0.0.1:32941,DS-72671c0f-b22f-4202-97cb-319d486da96a,DISK], DatanodeInfoWithStorage[127.0.0.1:46038,DS-3739c404-9809-4d18-80bf-8c0682c2be47,DISK], DatanodeInfoWithStorage[127.0.0.1:45860,DS-3c6c49f1-e275-4826-a8a9-bdfdc516c6ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40822,DS-370ed3bd-e469-4e39-94f7-fe43700c7f64,DISK], DatanodeInfoWithStorage[127.0.0.1:41888,DS-1eb2f5ee-829e-4fa1-9d1d-f2249401d76b,DISK], DatanodeInfoWithStorage[127.0.0.1:40774,DS-33ef86cd-c2f6-4c04-b131-9d95e88811d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2051941860-172.17.0.5-1597399815552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46421,DS-12a6ae50-6f28-4b07-8b1d-949492238153,DISK], DatanodeInfoWithStorage[127.0.0.1:42681,DS-1779a294-b391-49a4-8038-e2688e5b539d,DISK], DatanodeInfoWithStorage[127.0.0.1:39378,DS-d6cc0bbe-0fed-4987-906d-ef4f5d12019b,DISK], DatanodeInfoWithStorage[127.0.0.1:46286,DS-91034e96-11b2-46ef-9f8b-ca770c369175,DISK], DatanodeInfoWithStorage[127.0.0.1:43796,DS-44588cec-b32a-4d28-864f-e56c5196d313,DISK], DatanodeInfoWithStorage[127.0.0.1:33711,DS-d055dce8-e6f2-4a52-9d6d-2b63f29f368d,DISK], DatanodeInfoWithStorage[127.0.0.1:46850,DS-b42a9e15-8dae-4280-8006-ae644d5eee7e,DISK], DatanodeInfoWithStorage[127.0.0.1:34536,DS-d9320b5e-a7a8-43cf-b6b6-deee3e2d4d55,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2051941860-172.17.0.5-1597399815552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46421,DS-12a6ae50-6f28-4b07-8b1d-949492238153,DISK], DatanodeInfoWithStorage[127.0.0.1:42681,DS-1779a294-b391-49a4-8038-e2688e5b539d,DISK], DatanodeInfoWithStorage[127.0.0.1:39378,DS-d6cc0bbe-0fed-4987-906d-ef4f5d12019b,DISK], DatanodeInfoWithStorage[127.0.0.1:46286,DS-91034e96-11b2-46ef-9f8b-ca770c369175,DISK], DatanodeInfoWithStorage[127.0.0.1:43796,DS-44588cec-b32a-4d28-864f-e56c5196d313,DISK], DatanodeInfoWithStorage[127.0.0.1:33711,DS-d055dce8-e6f2-4a52-9d6d-2b63f29f368d,DISK], DatanodeInfoWithStorage[127.0.0.1:46850,DS-b42a9e15-8dae-4280-8006-ae644d5eee7e,DISK], DatanodeInfoWithStorage[127.0.0.1:34536,DS-d9320b5e-a7a8-43cf-b6b6-deee3e2d4d55,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-288475329-172.17.0.5-1597400179504:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46562,DS-f19ae70e-87c6-474a-b680-c61477f1868a,DISK], DatanodeInfoWithStorage[127.0.0.1:39326,DS-a420895f-a242-46c5-9499-1b90a9a8809e,DISK], DatanodeInfoWithStorage[127.0.0.1:46566,DS-86016887-aa75-4fc3-a1c6-dfbbfddffccf,DISK], DatanodeInfoWithStorage[127.0.0.1:41515,DS-14cb4be6-e4f1-41cd-bede-0912aa51af19,DISK], DatanodeInfoWithStorage[127.0.0.1:40210,DS-05fc4959-9824-491c-b999-cc5aa42fa37c,DISK], DatanodeInfoWithStorage[127.0.0.1:42601,DS-7fcacf90-5536-45d8-b3e6-6ff80540c1ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35359,DS-f2b39c9f-4900-45eb-a537-7fca48cbb668,DISK], DatanodeInfoWithStorage[127.0.0.1:33647,DS-32e1b22c-fc93-470b-8558-577ed6c7f21d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-288475329-172.17.0.5-1597400179504:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46562,DS-f19ae70e-87c6-474a-b680-c61477f1868a,DISK], DatanodeInfoWithStorage[127.0.0.1:39326,DS-a420895f-a242-46c5-9499-1b90a9a8809e,DISK], DatanodeInfoWithStorage[127.0.0.1:46566,DS-86016887-aa75-4fc3-a1c6-dfbbfddffccf,DISK], DatanodeInfoWithStorage[127.0.0.1:41515,DS-14cb4be6-e4f1-41cd-bede-0912aa51af19,DISK], DatanodeInfoWithStorage[127.0.0.1:40210,DS-05fc4959-9824-491c-b999-cc5aa42fa37c,DISK], DatanodeInfoWithStorage[127.0.0.1:42601,DS-7fcacf90-5536-45d8-b3e6-6ff80540c1ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35359,DS-f2b39c9f-4900-45eb-a537-7fca48cbb668,DISK], DatanodeInfoWithStorage[127.0.0.1:33647,DS-32e1b22c-fc93-470b-8558-577ed6c7f21d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-392966909-172.17.0.5-1597400217099:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34930,DS-cf155522-4f88-47a2-b821-29c445f28cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:45507,DS-c8b9cc6a-5d0c-4cd3-b56a-4de3ee8e66de,DISK], DatanodeInfoWithStorage[127.0.0.1:37564,DS-061e07c1-a0b9-474a-a958-7e074cdb67cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40536,DS-7d1a41dc-5f09-488d-9a68-16e2a10d0030,DISK], DatanodeInfoWithStorage[127.0.0.1:34592,DS-6b791414-c23d-48f8-bc4c-ade3241d1343,DISK], DatanodeInfoWithStorage[127.0.0.1:44578,DS-0be58d89-2b45-4877-acab-7e50c89ba141,DISK], DatanodeInfoWithStorage[127.0.0.1:37715,DS-1eee174f-119d-4676-be87-f4097027ac99,DISK], DatanodeInfoWithStorage[127.0.0.1:43839,DS-c3f0d933-1eba-4908-98a4-b7195dbeef1c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-392966909-172.17.0.5-1597400217099:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34930,DS-cf155522-4f88-47a2-b821-29c445f28cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:45507,DS-c8b9cc6a-5d0c-4cd3-b56a-4de3ee8e66de,DISK], DatanodeInfoWithStorage[127.0.0.1:37564,DS-061e07c1-a0b9-474a-a958-7e074cdb67cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40536,DS-7d1a41dc-5f09-488d-9a68-16e2a10d0030,DISK], DatanodeInfoWithStorage[127.0.0.1:34592,DS-6b791414-c23d-48f8-bc4c-ade3241d1343,DISK], DatanodeInfoWithStorage[127.0.0.1:44578,DS-0be58d89-2b45-4877-acab-7e50c89ba141,DISK], DatanodeInfoWithStorage[127.0.0.1:37715,DS-1eee174f-119d-4676-be87-f4097027ac99,DISK], DatanodeInfoWithStorage[127.0.0.1:43839,DS-c3f0d933-1eba-4908-98a4-b7195dbeef1c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-343053269-172.17.0.5-1597400380263:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43606,DS-0fa284f9-e578-41b6-8881-aaffedfda3b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45034,DS-15d4a11f-e7b4-4f1e-844d-d6866bfc1a86,DISK], DatanodeInfoWithStorage[127.0.0.1:35742,DS-72a82934-1fa4-49e4-a5c5-d9c66d0d02f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45115,DS-0363c650-897a-419d-a3a6-f7a85511d7ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43616,DS-36e2ab64-1ba0-4113-84e8-50f475f55d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:45549,DS-7385b513-9b91-4294-a97b-4d77ccfc8883,DISK], DatanodeInfoWithStorage[127.0.0.1:44474,DS-8a154c92-93e2-4399-ac8d-6561e156e304,DISK], DatanodeInfoWithStorage[127.0.0.1:45123,DS-f593eac3-e39f-486d-80b1-aad476fe95a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-343053269-172.17.0.5-1597400380263:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43606,DS-0fa284f9-e578-41b6-8881-aaffedfda3b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45034,DS-15d4a11f-e7b4-4f1e-844d-d6866bfc1a86,DISK], DatanodeInfoWithStorage[127.0.0.1:35742,DS-72a82934-1fa4-49e4-a5c5-d9c66d0d02f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45115,DS-0363c650-897a-419d-a3a6-f7a85511d7ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43616,DS-36e2ab64-1ba0-4113-84e8-50f475f55d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:45549,DS-7385b513-9b91-4294-a97b-4d77ccfc8883,DISK], DatanodeInfoWithStorage[127.0.0.1:44474,DS-8a154c92-93e2-4399-ac8d-6561e156e304,DISK], DatanodeInfoWithStorage[127.0.0.1:45123,DS-f593eac3-e39f-486d-80b1-aad476fe95a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-275089590-172.17.0.5-1597400500196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46053,DS-71c74fff-512e-4cac-8e10-a5125b6b5ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:38034,DS-1811875e-2f9c-4628-83da-3ab9d6799e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45086,DS-7d8636e7-a797-473c-8cb9-8c43ab35c92a,DISK], DatanodeInfoWithStorage[127.0.0.1:36871,DS-f44ad19a-142e-4afa-8f67-7c43f706aac3,DISK], DatanodeInfoWithStorage[127.0.0.1:42007,DS-6ee8427d-1c4c-4380-846b-4c5f99305428,DISK], DatanodeInfoWithStorage[127.0.0.1:34360,DS-76dbfa26-1819-44fb-a7a7-be6c7810f586,DISK], DatanodeInfoWithStorage[127.0.0.1:42888,DS-e0123524-be18-4096-bb4b-8ce5d6549f60,DISK], DatanodeInfoWithStorage[127.0.0.1:36463,DS-806842cc-dbca-4218-ae69-f029ccf8389e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-275089590-172.17.0.5-1597400500196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46053,DS-71c74fff-512e-4cac-8e10-a5125b6b5ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:38034,DS-1811875e-2f9c-4628-83da-3ab9d6799e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45086,DS-7d8636e7-a797-473c-8cb9-8c43ab35c92a,DISK], DatanodeInfoWithStorage[127.0.0.1:36871,DS-f44ad19a-142e-4afa-8f67-7c43f706aac3,DISK], DatanodeInfoWithStorage[127.0.0.1:42007,DS-6ee8427d-1c4c-4380-846b-4c5f99305428,DISK], DatanodeInfoWithStorage[127.0.0.1:34360,DS-76dbfa26-1819-44fb-a7a7-be6c7810f586,DISK], DatanodeInfoWithStorage[127.0.0.1:42888,DS-e0123524-be18-4096-bb4b-8ce5d6549f60,DISK], DatanodeInfoWithStorage[127.0.0.1:36463,DS-806842cc-dbca-4218-ae69-f029ccf8389e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-860249235-172.17.0.5-1597400622238:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35980,DS-5492a6cf-8534-48c6-8ee6-94e6736c2965,DISK], DatanodeInfoWithStorage[127.0.0.1:43325,DS-80ed9448-a0c6-4250-badd-54e81119e128,DISK], DatanodeInfoWithStorage[127.0.0.1:33055,DS-54527a23-0094-4ec9-8473-88f7ab71863e,DISK], DatanodeInfoWithStorage[127.0.0.1:35789,DS-b268cd84-d779-4638-ae3e-6f6bcfc3d64e,DISK], DatanodeInfoWithStorage[127.0.0.1:43439,DS-e8e62d6b-3cee-43f5-bffc-3ec23dc1addb,DISK], DatanodeInfoWithStorage[127.0.0.1:46466,DS-8ed244b1-5fed-4417-a754-110c234ee0b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44831,DS-85fbb949-122c-481c-a2a3-c1fdfdab763d,DISK], DatanodeInfoWithStorage[127.0.0.1:42433,DS-707f2a21-d9b6-4312-930c-4b179173e9e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-860249235-172.17.0.5-1597400622238:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35980,DS-5492a6cf-8534-48c6-8ee6-94e6736c2965,DISK], DatanodeInfoWithStorage[127.0.0.1:43325,DS-80ed9448-a0c6-4250-badd-54e81119e128,DISK], DatanodeInfoWithStorage[127.0.0.1:33055,DS-54527a23-0094-4ec9-8473-88f7ab71863e,DISK], DatanodeInfoWithStorage[127.0.0.1:35789,DS-b268cd84-d779-4638-ae3e-6f6bcfc3d64e,DISK], DatanodeInfoWithStorage[127.0.0.1:43439,DS-e8e62d6b-3cee-43f5-bffc-3ec23dc1addb,DISK], DatanodeInfoWithStorage[127.0.0.1:46466,DS-8ed244b1-5fed-4417-a754-110c234ee0b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44831,DS-85fbb949-122c-481c-a2a3-c1fdfdab763d,DISK], DatanodeInfoWithStorage[127.0.0.1:42433,DS-707f2a21-d9b6-4312-930c-4b179173e9e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-904496884-172.17.0.5-1597400803668:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35434,DS-fe1de888-8335-4cb5-8e1e-eceaff145bca,DISK], DatanodeInfoWithStorage[127.0.0.1:42585,DS-e75f35d7-5a7c-48b0-a345-a243f8b175a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40053,DS-52544222-d72c-4b19-8833-a3b7434ef63f,DISK], DatanodeInfoWithStorage[127.0.0.1:44533,DS-29431b7a-f75a-4fb6-8801-ab5aa77ccca6,DISK], DatanodeInfoWithStorage[127.0.0.1:41568,DS-66b532c9-2265-4061-950c-4e557873c336,DISK], DatanodeInfoWithStorage[127.0.0.1:42837,DS-7a2fff5d-4aa4-4203-91a7-12cbebe49489,DISK], DatanodeInfoWithStorage[127.0.0.1:36186,DS-86f0bdae-08c5-4c27-b6b7-438e43c59b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:40782,DS-5575122f-1800-480a-b880-1534fccb6369,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-904496884-172.17.0.5-1597400803668:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35434,DS-fe1de888-8335-4cb5-8e1e-eceaff145bca,DISK], DatanodeInfoWithStorage[127.0.0.1:42585,DS-e75f35d7-5a7c-48b0-a345-a243f8b175a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40053,DS-52544222-d72c-4b19-8833-a3b7434ef63f,DISK], DatanodeInfoWithStorage[127.0.0.1:44533,DS-29431b7a-f75a-4fb6-8801-ab5aa77ccca6,DISK], DatanodeInfoWithStorage[127.0.0.1:41568,DS-66b532c9-2265-4061-950c-4e557873c336,DISK], DatanodeInfoWithStorage[127.0.0.1:42837,DS-7a2fff5d-4aa4-4203-91a7-12cbebe49489,DISK], DatanodeInfoWithStorage[127.0.0.1:36186,DS-86f0bdae-08c5-4c27-b6b7-438e43c59b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:40782,DS-5575122f-1800-480a-b880-1534fccb6369,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-472277091-172.17.0.5-1597401241452:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34734,DS-5c3bddb2-b032-4351-bb95-b292986a51ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37509,DS-f6917a02-6748-4cb5-9263-7470aa93617f,DISK], DatanodeInfoWithStorage[127.0.0.1:41407,DS-01d7301c-16b0-4eef-ad25-8caab99b8f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34784,DS-0c769705-5704-47cb-bfe7-1da9237e4e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44820,DS-53d95b1c-631e-4023-aa5b-570778ca6897,DISK], DatanodeInfoWithStorage[127.0.0.1:39080,DS-e41f96ec-4e7e-4da3-8f45-c5e81f82ef27,DISK], DatanodeInfoWithStorage[127.0.0.1:39320,DS-e64a72cd-bc3a-466a-85f8-28c65091b02f,DISK], DatanodeInfoWithStorage[127.0.0.1:46882,DS-03a2e56a-8e55-404b-9eea-85415e4bb0b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-472277091-172.17.0.5-1597401241452:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34734,DS-5c3bddb2-b032-4351-bb95-b292986a51ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37509,DS-f6917a02-6748-4cb5-9263-7470aa93617f,DISK], DatanodeInfoWithStorage[127.0.0.1:41407,DS-01d7301c-16b0-4eef-ad25-8caab99b8f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34784,DS-0c769705-5704-47cb-bfe7-1da9237e4e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44820,DS-53d95b1c-631e-4023-aa5b-570778ca6897,DISK], DatanodeInfoWithStorage[127.0.0.1:39080,DS-e41f96ec-4e7e-4da3-8f45-c5e81f82ef27,DISK], DatanodeInfoWithStorage[127.0.0.1:39320,DS-e64a72cd-bc3a-466a-85f8-28c65091b02f,DISK], DatanodeInfoWithStorage[127.0.0.1:46882,DS-03a2e56a-8e55-404b-9eea-85415e4bb0b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1176909357-172.17.0.5-1597401366247:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35079,DS-755e1d68-659b-4ce9-8842-f53248869e75,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-be008d9d-e44b-4df9-9597-555aeef434b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38490,DS-4a886d3b-c848-4f8a-8a30-17ac49b42ead,DISK], DatanodeInfoWithStorage[127.0.0.1:36604,DS-3ce3f7ce-b548-4c58-88be-7d33a0330ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:41064,DS-c7624d3e-938c-43cc-948d-4ce2a219415a,DISK], DatanodeInfoWithStorage[127.0.0.1:38172,DS-1e751405-5219-468b-8329-ca84139048b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45522,DS-50d0509c-c7c0-416c-bab9-7dcf378126b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46148,DS-b08bfdfc-4f2c-4983-a8b8-ce19ee888264,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1176909357-172.17.0.5-1597401366247:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35079,DS-755e1d68-659b-4ce9-8842-f53248869e75,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-be008d9d-e44b-4df9-9597-555aeef434b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38490,DS-4a886d3b-c848-4f8a-8a30-17ac49b42ead,DISK], DatanodeInfoWithStorage[127.0.0.1:36604,DS-3ce3f7ce-b548-4c58-88be-7d33a0330ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:41064,DS-c7624d3e-938c-43cc-948d-4ce2a219415a,DISK], DatanodeInfoWithStorage[127.0.0.1:38172,DS-1e751405-5219-468b-8329-ca84139048b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45522,DS-50d0509c-c7c0-416c-bab9-7dcf378126b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46148,DS-b08bfdfc-4f2c-4983-a8b8-ce19ee888264,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1592669747-172.17.0.5-1597401482894:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41404,DS-0791bb88-3ab2-4bec-9847-449301da5bab,DISK], DatanodeInfoWithStorage[127.0.0.1:40284,DS-5f1fc97f-4cc9-49e7-9964-34b8575d01d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33508,DS-59ea2e31-5a32-4b0c-9b7d-bb18d6cb29f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42361,DS-447734e1-f6f9-4d36-a7bf-74cf7b04bc01,DISK], DatanodeInfoWithStorage[127.0.0.1:42843,DS-fc55714f-ca9f-4a90-98fb-a0c47f0c452b,DISK], DatanodeInfoWithStorage[127.0.0.1:39246,DS-be2b7349-5cef-4c68-96d4-ca5d12678b46,DISK], DatanodeInfoWithStorage[127.0.0.1:33944,DS-531e4a0e-fed7-4235-abdb-f1f9ce962c49,DISK], DatanodeInfoWithStorage[127.0.0.1:42640,DS-6ea98040-1146-4eba-bed7-1ea86e13daaa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1592669747-172.17.0.5-1597401482894:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41404,DS-0791bb88-3ab2-4bec-9847-449301da5bab,DISK], DatanodeInfoWithStorage[127.0.0.1:40284,DS-5f1fc97f-4cc9-49e7-9964-34b8575d01d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33508,DS-59ea2e31-5a32-4b0c-9b7d-bb18d6cb29f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42361,DS-447734e1-f6f9-4d36-a7bf-74cf7b04bc01,DISK], DatanodeInfoWithStorage[127.0.0.1:42843,DS-fc55714f-ca9f-4a90-98fb-a0c47f0c452b,DISK], DatanodeInfoWithStorage[127.0.0.1:39246,DS-be2b7349-5cef-4c68-96d4-ca5d12678b46,DISK], DatanodeInfoWithStorage[127.0.0.1:33944,DS-531e4a0e-fed7-4235-abdb-f1f9ce962c49,DISK], DatanodeInfoWithStorage[127.0.0.1:42640,DS-6ea98040-1146-4eba-bed7-1ea86e13daaa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1848343765-172.17.0.5-1597401521180:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45151,DS-932db9ec-b9a2-4475-8fb5-4aabe1dc82ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40457,DS-bed8c3e1-59a9-4044-95c0-d93b1bfd4aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:46498,DS-854af3b3-a7ae-462f-bead-b413933e1225,DISK], DatanodeInfoWithStorage[127.0.0.1:43053,DS-9aa766e8-d48a-4754-88f7-5e9729286bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:34970,DS-3f249fa2-f311-4ae0-9485-1b9ca57aa416,DISK], DatanodeInfoWithStorage[127.0.0.1:36736,DS-6ce86530-894a-4910-9ff7-35159ba62845,DISK], DatanodeInfoWithStorage[127.0.0.1:45699,DS-fdf5d360-63f5-44c6-a8b2-d03206d1f593,DISK], DatanodeInfoWithStorage[127.0.0.1:40692,DS-0bbd06c9-5cdc-402b-a56e-b39eaf80bca8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1848343765-172.17.0.5-1597401521180:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45151,DS-932db9ec-b9a2-4475-8fb5-4aabe1dc82ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40457,DS-bed8c3e1-59a9-4044-95c0-d93b1bfd4aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:46498,DS-854af3b3-a7ae-462f-bead-b413933e1225,DISK], DatanodeInfoWithStorage[127.0.0.1:43053,DS-9aa766e8-d48a-4754-88f7-5e9729286bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:34970,DS-3f249fa2-f311-4ae0-9485-1b9ca57aa416,DISK], DatanodeInfoWithStorage[127.0.0.1:36736,DS-6ce86530-894a-4910-9ff7-35159ba62845,DISK], DatanodeInfoWithStorage[127.0.0.1:45699,DS-fdf5d360-63f5-44c6-a8b2-d03206d1f593,DISK], DatanodeInfoWithStorage[127.0.0.1:40692,DS-0bbd06c9-5cdc-402b-a56e-b39eaf80bca8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1631806240-172.17.0.5-1597401603792:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42240,DS-fa5bbc52-7841-459c-8a6a-69dab4679177,DISK], DatanodeInfoWithStorage[127.0.0.1:35020,DS-1b8a7ac6-feb1-4fd8-b0e6-5850facd2d79,DISK], DatanodeInfoWithStorage[127.0.0.1:37473,DS-801616e6-b89b-4741-b7ae-71ba96dc0092,DISK], DatanodeInfoWithStorage[127.0.0.1:41094,DS-eae5948c-5190-4af2-9809-1bc9b7c0d9a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40196,DS-d2d760da-2c7a-436e-bb33-a4d8d871bd11,DISK], DatanodeInfoWithStorage[127.0.0.1:39889,DS-3ad3aa58-5ca3-4159-9eaf-9d1d65646bac,DISK], DatanodeInfoWithStorage[127.0.0.1:38187,DS-eff75146-ea4a-4d92-9bd6-47105661a349,DISK], DatanodeInfoWithStorage[127.0.0.1:35804,DS-36c1f3e8-30fc-42d7-9c70-763f9622a27b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1631806240-172.17.0.5-1597401603792:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42240,DS-fa5bbc52-7841-459c-8a6a-69dab4679177,DISK], DatanodeInfoWithStorage[127.0.0.1:35020,DS-1b8a7ac6-feb1-4fd8-b0e6-5850facd2d79,DISK], DatanodeInfoWithStorage[127.0.0.1:37473,DS-801616e6-b89b-4741-b7ae-71ba96dc0092,DISK], DatanodeInfoWithStorage[127.0.0.1:41094,DS-eae5948c-5190-4af2-9809-1bc9b7c0d9a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40196,DS-d2d760da-2c7a-436e-bb33-a4d8d871bd11,DISK], DatanodeInfoWithStorage[127.0.0.1:39889,DS-3ad3aa58-5ca3-4159-9eaf-9d1d65646bac,DISK], DatanodeInfoWithStorage[127.0.0.1:38187,DS-eff75146-ea4a-4d92-9bd6-47105661a349,DISK], DatanodeInfoWithStorage[127.0.0.1:35804,DS-36c1f3e8-30fc-42d7-9c70-763f9622a27b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1904824451-172.17.0.5-1597401794418:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39212,DS-a887125d-170b-4d1a-9dd9-e200a66e7e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:46540,DS-127b8bb3-e365-4655-84eb-e944907b0778,DISK], DatanodeInfoWithStorage[127.0.0.1:41368,DS-34bd9457-f0c0-4a8c-a284-4978f92d238b,DISK], DatanodeInfoWithStorage[127.0.0.1:41110,DS-444ec828-f386-4366-a19f-3553a4696dce,DISK], DatanodeInfoWithStorage[127.0.0.1:37838,DS-6d76e68f-340c-410d-b50a-d74ee653b0d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38107,DS-e4f466ed-f83b-4f6a-8cc9-cb9464231912,DISK], DatanodeInfoWithStorage[127.0.0.1:33167,DS-9396d067-46bf-40a2-94de-cd0d6137b6e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34736,DS-5ef30c81-bf99-4714-bf75-a3b6edd29cc8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1904824451-172.17.0.5-1597401794418:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39212,DS-a887125d-170b-4d1a-9dd9-e200a66e7e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:46540,DS-127b8bb3-e365-4655-84eb-e944907b0778,DISK], DatanodeInfoWithStorage[127.0.0.1:41368,DS-34bd9457-f0c0-4a8c-a284-4978f92d238b,DISK], DatanodeInfoWithStorage[127.0.0.1:41110,DS-444ec828-f386-4366-a19f-3553a4696dce,DISK], DatanodeInfoWithStorage[127.0.0.1:37838,DS-6d76e68f-340c-410d-b50a-d74ee653b0d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38107,DS-e4f466ed-f83b-4f6a-8cc9-cb9464231912,DISK], DatanodeInfoWithStorage[127.0.0.1:33167,DS-9396d067-46bf-40a2-94de-cd0d6137b6e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34736,DS-5ef30c81-bf99-4714-bf75-a3b6edd29cc8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1037739706-172.17.0.5-1597401829884:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35816,DS-82623a41-1176-4854-8319-cbd6b2b8cb14,DISK], DatanodeInfoWithStorage[127.0.0.1:42872,DS-f6b82cf9-3262-46be-89c1-4e35914046aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46589,DS-58d6c78e-6dea-48dd-9dfe-b7dd8dce3d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36006,DS-30d87f67-837a-466d-a36a-c88e7e8d5e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45867,DS-dddb5fdc-115e-4998-b81c-23c5c5635414,DISK], DatanodeInfoWithStorage[127.0.0.1:40394,DS-4be50cd1-071f-494b-8f69-544576bf3a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:37845,DS-7cd3da1a-acc1-4007-8c3e-e760d6f69ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:37068,DS-76cc8e9f-2a55-4f07-bac3-3f56c993caae,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1037739706-172.17.0.5-1597401829884:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35816,DS-82623a41-1176-4854-8319-cbd6b2b8cb14,DISK], DatanodeInfoWithStorage[127.0.0.1:42872,DS-f6b82cf9-3262-46be-89c1-4e35914046aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46589,DS-58d6c78e-6dea-48dd-9dfe-b7dd8dce3d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36006,DS-30d87f67-837a-466d-a36a-c88e7e8d5e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45867,DS-dddb5fdc-115e-4998-b81c-23c5c5635414,DISK], DatanodeInfoWithStorage[127.0.0.1:40394,DS-4be50cd1-071f-494b-8f69-544576bf3a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:37845,DS-7cd3da1a-acc1-4007-8c3e-e760d6f69ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:37068,DS-76cc8e9f-2a55-4f07-bac3-3f56c993caae,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1839985265-172.17.0.5-1597401915018:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43399,DS-79e7230e-e0ea-424a-a6b0-7b9ad5783d57,DISK], DatanodeInfoWithStorage[127.0.0.1:32899,DS-5dffda9d-2b2a-4da3-9953-2d4b272217b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44375,DS-bea9ff49-20a4-4ddc-acd7-a441e46d20fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39589,DS-2a1b14b2-b673-4a32-a1ff-27583e664c33,DISK], DatanodeInfoWithStorage[127.0.0.1:44877,DS-27e0f54a-3799-4dc6-8e8c-647f5cf41d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43627,DS-e836c506-6f40-493d-8ddb-131698247cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:45371,DS-45976aa5-eac4-46f8-a739-8322d8e7be2e,DISK], DatanodeInfoWithStorage[127.0.0.1:45208,DS-dc153482-3587-4ecd-99b5-48ae77395c44,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1839985265-172.17.0.5-1597401915018:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43399,DS-79e7230e-e0ea-424a-a6b0-7b9ad5783d57,DISK], DatanodeInfoWithStorage[127.0.0.1:32899,DS-5dffda9d-2b2a-4da3-9953-2d4b272217b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44375,DS-bea9ff49-20a4-4ddc-acd7-a441e46d20fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39589,DS-2a1b14b2-b673-4a32-a1ff-27583e664c33,DISK], DatanodeInfoWithStorage[127.0.0.1:44877,DS-27e0f54a-3799-4dc6-8e8c-647f5cf41d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43627,DS-e836c506-6f40-493d-8ddb-131698247cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:45371,DS-45976aa5-eac4-46f8-a739-8322d8e7be2e,DISK], DatanodeInfoWithStorage[127.0.0.1:45208,DS-dc153482-3587-4ecd-99b5-48ae77395c44,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2053285691-172.17.0.5-1597401988600:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37616,DS-26d96349-be47-4548-aff5-9e3024d50fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:45807,DS-8d669aca-e3bc-4953-a2e2-b63f2c096222,DISK], DatanodeInfoWithStorage[127.0.0.1:46166,DS-36e86f16-279b-4ab3-aa79-3cface905d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44423,DS-7ebc691f-079c-42e5-a69e-cabed2ac528a,DISK], DatanodeInfoWithStorage[127.0.0.1:44990,DS-1318722e-4051-4b19-a1c3-d644fbee01a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45477,DS-424783a7-a85a-4682-beee-f874fa93e056,DISK], DatanodeInfoWithStorage[127.0.0.1:44882,DS-32cdd098-9d01-4596-900b-3670b47ee3ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44387,DS-240ea605-6684-4607-bd36-ba05a9978a2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2053285691-172.17.0.5-1597401988600:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37616,DS-26d96349-be47-4548-aff5-9e3024d50fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:45807,DS-8d669aca-e3bc-4953-a2e2-b63f2c096222,DISK], DatanodeInfoWithStorage[127.0.0.1:46166,DS-36e86f16-279b-4ab3-aa79-3cface905d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44423,DS-7ebc691f-079c-42e5-a69e-cabed2ac528a,DISK], DatanodeInfoWithStorage[127.0.0.1:44990,DS-1318722e-4051-4b19-a1c3-d644fbee01a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45477,DS-424783a7-a85a-4682-beee-f874fa93e056,DISK], DatanodeInfoWithStorage[127.0.0.1:44882,DS-32cdd098-9d01-4596-900b-3670b47ee3ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44387,DS-240ea605-6684-4607-bd36-ba05a9978a2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1163885626-172.17.0.5-1597402067290:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36480,DS-c6604f2c-fb10-4b79-be0c-c1af5b4fe1dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34230,DS-a398e7cc-e73e-402e-96ae-fb2ae7236483,DISK], DatanodeInfoWithStorage[127.0.0.1:34052,DS-6712511f-e78d-43cd-86b5-55819639dbd9,DISK], DatanodeInfoWithStorage[127.0.0.1:40644,DS-724146a5-cbfe-4a50-a3c3-d0eeda087c87,DISK], DatanodeInfoWithStorage[127.0.0.1:38107,DS-cc7d23d4-ea60-46b2-b549-c016fb3a10be,DISK], DatanodeInfoWithStorage[127.0.0.1:44219,DS-9543bbcb-9f83-4c77-84c0-408bcf893d14,DISK], DatanodeInfoWithStorage[127.0.0.1:44059,DS-3bba640f-cbef-4848-b6c9-03568ad39e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40779,DS-e34fb21a-1b1c-4c58-ac9c-1080925d5caf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1163885626-172.17.0.5-1597402067290:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36480,DS-c6604f2c-fb10-4b79-be0c-c1af5b4fe1dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34230,DS-a398e7cc-e73e-402e-96ae-fb2ae7236483,DISK], DatanodeInfoWithStorage[127.0.0.1:34052,DS-6712511f-e78d-43cd-86b5-55819639dbd9,DISK], DatanodeInfoWithStorage[127.0.0.1:40644,DS-724146a5-cbfe-4a50-a3c3-d0eeda087c87,DISK], DatanodeInfoWithStorage[127.0.0.1:38107,DS-cc7d23d4-ea60-46b2-b549-c016fb3a10be,DISK], DatanodeInfoWithStorage[127.0.0.1:44219,DS-9543bbcb-9f83-4c77-84c0-408bcf893d14,DISK], DatanodeInfoWithStorage[127.0.0.1:44059,DS-3bba640f-cbef-4848-b6c9-03568ad39e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40779,DS-e34fb21a-1b1c-4c58-ac9c-1080925d5caf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1347636106-172.17.0.5-1597402100826:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41494,DS-351380d1-d5b3-4b62-8a25-4c71ce0d74f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36387,DS-11216c39-35f0-4355-a4c7-c871e7290f59,DISK], DatanodeInfoWithStorage[127.0.0.1:33613,DS-c6237a79-a81c-46ce-bdff-4e87e51d607a,DISK], DatanodeInfoWithStorage[127.0.0.1:37761,DS-1974171a-4472-457c-b730-4c2c171cff7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43928,DS-79bd7da6-3cac-4ef8-9e4a-3690be7f6afc,DISK], DatanodeInfoWithStorage[127.0.0.1:33868,DS-38970cd4-08eb-47dd-973e-303607db0fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:44946,DS-5dcb7e68-b491-4e5e-8b6c-5af443c0f4fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44968,DS-ad9a28b5-35a4-4850-a527-2d3b6231d9f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1347636106-172.17.0.5-1597402100826:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41494,DS-351380d1-d5b3-4b62-8a25-4c71ce0d74f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36387,DS-11216c39-35f0-4355-a4c7-c871e7290f59,DISK], DatanodeInfoWithStorage[127.0.0.1:33613,DS-c6237a79-a81c-46ce-bdff-4e87e51d607a,DISK], DatanodeInfoWithStorage[127.0.0.1:37761,DS-1974171a-4472-457c-b730-4c2c171cff7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43928,DS-79bd7da6-3cac-4ef8-9e4a-3690be7f6afc,DISK], DatanodeInfoWithStorage[127.0.0.1:33868,DS-38970cd4-08eb-47dd-973e-303607db0fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:44946,DS-5dcb7e68-b491-4e5e-8b6c-5af443c0f4fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44968,DS-ad9a28b5-35a4-4850-a527-2d3b6231d9f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1867884048-172.17.0.5-1597402142708:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42219,DS-3a83e65d-3471-4b03-b286-784a9807f713,DISK], DatanodeInfoWithStorage[127.0.0.1:43859,DS-d9b98677-c493-404b-9e52-972eb0a36ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:40899,DS-0c2787af-e449-41c1-8f44-15bacb7da0b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40477,DS-a4476bf8-0d68-4684-80fa-14af33745d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37169,DS-0e3a31cd-8679-4d05-bc39-7dd5fc8f40d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46478,DS-af5a1956-4b22-4cdc-980d-b173ec7967fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35727,DS-e44ff000-fd9b-45d9-a221-466776e5b1fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35117,DS-ca58d455-0d13-4005-9f3e-4494427eec03,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1867884048-172.17.0.5-1597402142708:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42219,DS-3a83e65d-3471-4b03-b286-784a9807f713,DISK], DatanodeInfoWithStorage[127.0.0.1:43859,DS-d9b98677-c493-404b-9e52-972eb0a36ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:40899,DS-0c2787af-e449-41c1-8f44-15bacb7da0b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40477,DS-a4476bf8-0d68-4684-80fa-14af33745d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37169,DS-0e3a31cd-8679-4d05-bc39-7dd5fc8f40d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46478,DS-af5a1956-4b22-4cdc-980d-b173ec7967fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35727,DS-e44ff000-fd9b-45d9-a221-466776e5b1fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35117,DS-ca58d455-0d13-4005-9f3e-4494427eec03,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-509953546-172.17.0.5-1597402862710:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41669,DS-34de33a1-b34e-4af6-b6ab-171088850467,DISK], DatanodeInfoWithStorage[127.0.0.1:45564,DS-cb4c7bc6-6df9-475a-baf8-80f06cc48983,DISK], DatanodeInfoWithStorage[127.0.0.1:34627,DS-866a80f4-c244-4911-b332-9a0a87335f20,DISK], DatanodeInfoWithStorage[127.0.0.1:36450,DS-aa99f40f-1be2-4cf5-9299-b2e212bf9551,DISK], DatanodeInfoWithStorage[127.0.0.1:40847,DS-2e79deb1-e029-4e2f-b5d0-605923b5e2d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35963,DS-d5b8dc6a-82b4-4fc8-b8fe-8f2c6b52d3a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36384,DS-ef456a72-9ac9-40a0-abe7-22e3159d7521,DISK], DatanodeInfoWithStorage[127.0.0.1:45301,DS-bd777c68-39b3-4ab8-8b4f-73415ca28d79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-509953546-172.17.0.5-1597402862710:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41669,DS-34de33a1-b34e-4af6-b6ab-171088850467,DISK], DatanodeInfoWithStorage[127.0.0.1:45564,DS-cb4c7bc6-6df9-475a-baf8-80f06cc48983,DISK], DatanodeInfoWithStorage[127.0.0.1:34627,DS-866a80f4-c244-4911-b332-9a0a87335f20,DISK], DatanodeInfoWithStorage[127.0.0.1:36450,DS-aa99f40f-1be2-4cf5-9299-b2e212bf9551,DISK], DatanodeInfoWithStorage[127.0.0.1:40847,DS-2e79deb1-e029-4e2f-b5d0-605923b5e2d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35963,DS-d5b8dc6a-82b4-4fc8-b8fe-8f2c6b52d3a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36384,DS-ef456a72-9ac9-40a0-abe7-22e3159d7521,DISK], DatanodeInfoWithStorage[127.0.0.1:45301,DS-bd777c68-39b3-4ab8-8b4f-73415ca28d79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1630135118-172.17.0.5-1597403150104:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42377,DS-6194e45c-e21d-4d40-9619-e59bbd0ca7d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41714,DS-11c65748-02ee-405f-ba56-ec20b8202aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:35757,DS-3bc65eb8-4da6-47f7-94ce-390362817d12,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-6399843c-ba32-4983-92fc-2b7af18a89fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41565,DS-87b1abcf-c64c-44ff-814f-58d4b6cd4d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:45160,DS-fdefe7d4-2d61-4baf-a576-996c128534d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35952,DS-66a01b97-f551-4003-ad6a-6a3888bd0bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:43604,DS-f1e395c9-dca0-49e3-befb-a2421583af0d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1630135118-172.17.0.5-1597403150104:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42377,DS-6194e45c-e21d-4d40-9619-e59bbd0ca7d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41714,DS-11c65748-02ee-405f-ba56-ec20b8202aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:35757,DS-3bc65eb8-4da6-47f7-94ce-390362817d12,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-6399843c-ba32-4983-92fc-2b7af18a89fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41565,DS-87b1abcf-c64c-44ff-814f-58d4b6cd4d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:45160,DS-fdefe7d4-2d61-4baf-a576-996c128534d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35952,DS-66a01b97-f551-4003-ad6a-6a3888bd0bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:43604,DS-f1e395c9-dca0-49e3-befb-a2421583af0d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-314455130-172.17.0.5-1597403230599:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41829,DS-c7cdea79-5450-4212-8a25-aced600c3130,DISK], DatanodeInfoWithStorage[127.0.0.1:35322,DS-4eb41d84-ab71-42e1-8e8a-6c3ec08100b1,DISK], DatanodeInfoWithStorage[127.0.0.1:32982,DS-4c5b0b0d-b2da-4eaa-9188-d84bcd911df1,DISK], DatanodeInfoWithStorage[127.0.0.1:40004,DS-fc025ebf-6dcc-4f6e-8d74-2d5e443d92d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39475,DS-94643fe9-b416-42b1-ac4e-459ddec9f94e,DISK], DatanodeInfoWithStorage[127.0.0.1:33537,DS-a664536d-81a5-481f-ad86-e0eb99b04234,DISK], DatanodeInfoWithStorage[127.0.0.1:36157,DS-9864bc90-0330-4a32-9a4a-ae658c677f50,DISK], DatanodeInfoWithStorage[127.0.0.1:32807,DS-cd5bf2f6-6e34-4edb-82ff-497e4b8db3e1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-314455130-172.17.0.5-1597403230599:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41829,DS-c7cdea79-5450-4212-8a25-aced600c3130,DISK], DatanodeInfoWithStorage[127.0.0.1:35322,DS-4eb41d84-ab71-42e1-8e8a-6c3ec08100b1,DISK], DatanodeInfoWithStorage[127.0.0.1:32982,DS-4c5b0b0d-b2da-4eaa-9188-d84bcd911df1,DISK], DatanodeInfoWithStorage[127.0.0.1:40004,DS-fc025ebf-6dcc-4f6e-8d74-2d5e443d92d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39475,DS-94643fe9-b416-42b1-ac4e-459ddec9f94e,DISK], DatanodeInfoWithStorage[127.0.0.1:33537,DS-a664536d-81a5-481f-ad86-e0eb99b04234,DISK], DatanodeInfoWithStorage[127.0.0.1:36157,DS-9864bc90-0330-4a32-9a4a-ae658c677f50,DISK], DatanodeInfoWithStorage[127.0.0.1:32807,DS-cd5bf2f6-6e34-4edb-82ff-497e4b8db3e1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 16 out of 50
v1v1v2v2 failed with probability 18 out of 50
result: false positive !!!
Total execution time in seconds : 5766
