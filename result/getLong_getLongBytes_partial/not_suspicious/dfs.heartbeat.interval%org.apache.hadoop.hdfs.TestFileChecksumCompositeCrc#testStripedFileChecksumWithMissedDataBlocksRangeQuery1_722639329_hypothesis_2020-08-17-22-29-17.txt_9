reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1683210933-172.17.0.7-1597703411781:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36978,DS-68572c1f-cc5d-4bfc-bdac-e5ad438a8382,DISK], DatanodeInfoWithStorage[127.0.0.1:45193,DS-7b6b3fe2-0847-4a7e-9b9f-3013dca25031,DISK], DatanodeInfoWithStorage[127.0.0.1:43426,DS-a56f8377-f5ad-4b09-b944-f71eb2cfcfe8,DISK], DatanodeInfoWithStorage[127.0.0.1:45697,DS-c091fd61-d9ef-43e1-8d39-3469062d9e03,DISK], DatanodeInfoWithStorage[127.0.0.1:46411,DS-bcb59ef0-9499-40e1-b2b7-eb3a820c314b,DISK], DatanodeInfoWithStorage[127.0.0.1:41741,DS-23eb1965-7615-4f2b-9df1-84060c12a9c2,DISK], DatanodeInfoWithStorage[127.0.0.1:32971,DS-7074bbbe-9c5f-4899-ae16-3d8c3952808f,DISK], DatanodeInfoWithStorage[127.0.0.1:38350,DS-067d6534-f4d5-4e6f-8ea0-f77fa2268f25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1683210933-172.17.0.7-1597703411781:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36978,DS-68572c1f-cc5d-4bfc-bdac-e5ad438a8382,DISK], DatanodeInfoWithStorage[127.0.0.1:45193,DS-7b6b3fe2-0847-4a7e-9b9f-3013dca25031,DISK], DatanodeInfoWithStorage[127.0.0.1:43426,DS-a56f8377-f5ad-4b09-b944-f71eb2cfcfe8,DISK], DatanodeInfoWithStorage[127.0.0.1:45697,DS-c091fd61-d9ef-43e1-8d39-3469062d9e03,DISK], DatanodeInfoWithStorage[127.0.0.1:46411,DS-bcb59ef0-9499-40e1-b2b7-eb3a820c314b,DISK], DatanodeInfoWithStorage[127.0.0.1:41741,DS-23eb1965-7615-4f2b-9df1-84060c12a9c2,DISK], DatanodeInfoWithStorage[127.0.0.1:32971,DS-7074bbbe-9c5f-4899-ae16-3d8c3952808f,DISK], DatanodeInfoWithStorage[127.0.0.1:38350,DS-067d6534-f4d5-4e6f-8ea0-f77fa2268f25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-702395256-172.17.0.7-1597703535415:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42083,DS-ba1e40f7-dcce-4517-8196-7e6abf8ace2e,DISK], DatanodeInfoWithStorage[127.0.0.1:33129,DS-5bd5416b-294b-42c3-993c-3ab13aac77a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33588,DS-01b5ebe0-2cb7-4d28-8dda-ee0f83c5f6d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41392,DS-e92964ff-4325-4c29-b092-77c17d89060f,DISK], DatanodeInfoWithStorage[127.0.0.1:44840,DS-d892bfbe-f0bb-4b30-aea5-cfe702558b56,DISK], DatanodeInfoWithStorage[127.0.0.1:45945,DS-1a4b0baf-e1b1-4e57-80ba-8834cf5e59e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46480,DS-2e00763d-9d69-4b3b-84bc-6aaed787f3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:32782,DS-d2ae24c8-17d0-44fa-9ce9-e155b4481c0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-702395256-172.17.0.7-1597703535415:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42083,DS-ba1e40f7-dcce-4517-8196-7e6abf8ace2e,DISK], DatanodeInfoWithStorage[127.0.0.1:33129,DS-5bd5416b-294b-42c3-993c-3ab13aac77a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33588,DS-01b5ebe0-2cb7-4d28-8dda-ee0f83c5f6d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41392,DS-e92964ff-4325-4c29-b092-77c17d89060f,DISK], DatanodeInfoWithStorage[127.0.0.1:44840,DS-d892bfbe-f0bb-4b30-aea5-cfe702558b56,DISK], DatanodeInfoWithStorage[127.0.0.1:45945,DS-1a4b0baf-e1b1-4e57-80ba-8834cf5e59e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46480,DS-2e00763d-9d69-4b3b-84bc-6aaed787f3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:32782,DS-d2ae24c8-17d0-44fa-9ce9-e155b4481c0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1960098091-172.17.0.7-1597703888783:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45599,DS-aaf4794e-2432-4fe7-806a-1d407d7a0e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40482,DS-e6972819-f813-4189-b847-a629e8f35098,DISK], DatanodeInfoWithStorage[127.0.0.1:43727,DS-6ee795a8-bff1-47e7-b126-43fcd7a9d831,DISK], DatanodeInfoWithStorage[127.0.0.1:45919,DS-1f0234a4-2b58-4f8c-800a-76ef16f4f04b,DISK], DatanodeInfoWithStorage[127.0.0.1:40846,DS-83608fb4-ae77-4d72-b0b6-ab136cbc5281,DISK], DatanodeInfoWithStorage[127.0.0.1:42003,DS-38d15617-a6ec-405a-9529-9ab65a8a36ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37281,DS-f4811398-24b2-4658-92f1-edaa72bcda0b,DISK], DatanodeInfoWithStorage[127.0.0.1:42817,DS-baaef1a8-12ab-430e-8705-fe012853211e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1960098091-172.17.0.7-1597703888783:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45599,DS-aaf4794e-2432-4fe7-806a-1d407d7a0e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40482,DS-e6972819-f813-4189-b847-a629e8f35098,DISK], DatanodeInfoWithStorage[127.0.0.1:43727,DS-6ee795a8-bff1-47e7-b126-43fcd7a9d831,DISK], DatanodeInfoWithStorage[127.0.0.1:45919,DS-1f0234a4-2b58-4f8c-800a-76ef16f4f04b,DISK], DatanodeInfoWithStorage[127.0.0.1:40846,DS-83608fb4-ae77-4d72-b0b6-ab136cbc5281,DISK], DatanodeInfoWithStorage[127.0.0.1:42003,DS-38d15617-a6ec-405a-9529-9ab65a8a36ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37281,DS-f4811398-24b2-4658-92f1-edaa72bcda0b,DISK], DatanodeInfoWithStorage[127.0.0.1:42817,DS-baaef1a8-12ab-430e-8705-fe012853211e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1245705252-172.17.0.7-1597703997336:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34297,DS-53c2eef1-5863-4c83-8b0e-246d1621bd3f,DISK], DatanodeInfoWithStorage[127.0.0.1:42090,DS-d9988731-88c9-4487-bbec-513b48c462cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33199,DS-3d8c9699-21c4-4cb9-a0a3-384ebb6e803b,DISK], DatanodeInfoWithStorage[127.0.0.1:39874,DS-56e4d042-6adb-4977-a3a3-d06a91aa24cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34844,DS-0fe84d05-306e-4d3a-8342-82b596fb7595,DISK], DatanodeInfoWithStorage[127.0.0.1:42271,DS-b8206b92-5576-489a-bd3b-c470ecae7f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45970,DS-2ea0e61f-6d02-410b-bb3b-6ef15e3398ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43452,DS-0372c3ad-4d35-448d-b9b0-0a377084880a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1245705252-172.17.0.7-1597703997336:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34297,DS-53c2eef1-5863-4c83-8b0e-246d1621bd3f,DISK], DatanodeInfoWithStorage[127.0.0.1:42090,DS-d9988731-88c9-4487-bbec-513b48c462cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33199,DS-3d8c9699-21c4-4cb9-a0a3-384ebb6e803b,DISK], DatanodeInfoWithStorage[127.0.0.1:39874,DS-56e4d042-6adb-4977-a3a3-d06a91aa24cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34844,DS-0fe84d05-306e-4d3a-8342-82b596fb7595,DISK], DatanodeInfoWithStorage[127.0.0.1:42271,DS-b8206b92-5576-489a-bd3b-c470ecae7f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45970,DS-2ea0e61f-6d02-410b-bb3b-6ef15e3398ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43452,DS-0372c3ad-4d35-448d-b9b0-0a377084880a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1742070747-172.17.0.7-1597704354013:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45155,DS-395b5aa5-11d3-43b4-be86-8bdb3747a724,DISK], DatanodeInfoWithStorage[127.0.0.1:33424,DS-410c5ccf-8f13-40e8-a8f7-5cd2e7521ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:40772,DS-6f865438-5ccb-4fa2-bace-fc7f4a68d33e,DISK], DatanodeInfoWithStorage[127.0.0.1:44335,DS-4bb14c1c-efe3-4215-b86a-ff7b78b82125,DISK], DatanodeInfoWithStorage[127.0.0.1:42911,DS-ca265749-2a4c-412a-909c-ec3dcd3faf52,DISK], DatanodeInfoWithStorage[127.0.0.1:40207,DS-c4f335ec-3bcb-419f-bcef-d0d722409cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:37515,DS-b552c44a-79da-4670-b7f7-6ceb2658fde5,DISK], DatanodeInfoWithStorage[127.0.0.1:39336,DS-ba583faa-ef82-4d12-97ae-16b1b95c8e45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1742070747-172.17.0.7-1597704354013:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45155,DS-395b5aa5-11d3-43b4-be86-8bdb3747a724,DISK], DatanodeInfoWithStorage[127.0.0.1:33424,DS-410c5ccf-8f13-40e8-a8f7-5cd2e7521ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:40772,DS-6f865438-5ccb-4fa2-bace-fc7f4a68d33e,DISK], DatanodeInfoWithStorage[127.0.0.1:44335,DS-4bb14c1c-efe3-4215-b86a-ff7b78b82125,DISK], DatanodeInfoWithStorage[127.0.0.1:42911,DS-ca265749-2a4c-412a-909c-ec3dcd3faf52,DISK], DatanodeInfoWithStorage[127.0.0.1:40207,DS-c4f335ec-3bcb-419f-bcef-d0d722409cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:37515,DS-b552c44a-79da-4670-b7f7-6ceb2658fde5,DISK], DatanodeInfoWithStorage[127.0.0.1:39336,DS-ba583faa-ef82-4d12-97ae-16b1b95c8e45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-229131154-172.17.0.7-1597704429479:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40574,DS-f276b28d-8619-4d5c-b9dd-b7dc44409c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44643,DS-df3c347f-7cc0-4790-ab6a-a56aab3ffc42,DISK], DatanodeInfoWithStorage[127.0.0.1:42577,DS-f0f3a92a-69e2-47b9-baf6-5fd5a25d2f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:41207,DS-a641c857-e05b-4cdf-9fa7-2a96322dc750,DISK], DatanodeInfoWithStorage[127.0.0.1:42928,DS-64951b47-b4a0-47ca-baca-3655454d1e66,DISK], DatanodeInfoWithStorage[127.0.0.1:41974,DS-188918d8-dff0-4d2a-a741-b339a818af4b,DISK], DatanodeInfoWithStorage[127.0.0.1:35959,DS-bfb027ff-0db1-43be-a26d-fad917ab527e,DISK], DatanodeInfoWithStorage[127.0.0.1:45445,DS-23ba8ccd-ea4b-4e4e-85db-4550dbdfa740,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-229131154-172.17.0.7-1597704429479:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40574,DS-f276b28d-8619-4d5c-b9dd-b7dc44409c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44643,DS-df3c347f-7cc0-4790-ab6a-a56aab3ffc42,DISK], DatanodeInfoWithStorage[127.0.0.1:42577,DS-f0f3a92a-69e2-47b9-baf6-5fd5a25d2f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:41207,DS-a641c857-e05b-4cdf-9fa7-2a96322dc750,DISK], DatanodeInfoWithStorage[127.0.0.1:42928,DS-64951b47-b4a0-47ca-baca-3655454d1e66,DISK], DatanodeInfoWithStorage[127.0.0.1:41974,DS-188918d8-dff0-4d2a-a741-b339a818af4b,DISK], DatanodeInfoWithStorage[127.0.0.1:35959,DS-bfb027ff-0db1-43be-a26d-fad917ab527e,DISK], DatanodeInfoWithStorage[127.0.0.1:45445,DS-23ba8ccd-ea4b-4e4e-85db-4550dbdfa740,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1175438421-172.17.0.7-1597704553958:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33663,DS-e2d4879b-97bb-43a8-8fed-1dd14ac6d3b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34659,DS-9286d2e4-17ec-4c82-b460-5122fe620766,DISK], DatanodeInfoWithStorage[127.0.0.1:36058,DS-93651103-bcd2-484d-897f-416623a7270c,DISK], DatanodeInfoWithStorage[127.0.0.1:40203,DS-7717d863-fe76-41bd-b1f5-8940b6655d08,DISK], DatanodeInfoWithStorage[127.0.0.1:41184,DS-1b87750a-398e-44c4-a007-f19515a510c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42754,DS-8e2da469-601b-42eb-80ec-87fc389169c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38471,DS-e0d0282f-2fae-4d3b-8464-5cca53279b96,DISK], DatanodeInfoWithStorage[127.0.0.1:32828,DS-1b68d4a4-ae0a-461e-927a-1ce2f66f6524,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1175438421-172.17.0.7-1597704553958:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33663,DS-e2d4879b-97bb-43a8-8fed-1dd14ac6d3b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34659,DS-9286d2e4-17ec-4c82-b460-5122fe620766,DISK], DatanodeInfoWithStorage[127.0.0.1:36058,DS-93651103-bcd2-484d-897f-416623a7270c,DISK], DatanodeInfoWithStorage[127.0.0.1:40203,DS-7717d863-fe76-41bd-b1f5-8940b6655d08,DISK], DatanodeInfoWithStorage[127.0.0.1:41184,DS-1b87750a-398e-44c4-a007-f19515a510c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42754,DS-8e2da469-601b-42eb-80ec-87fc389169c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38471,DS-e0d0282f-2fae-4d3b-8464-5cca53279b96,DISK], DatanodeInfoWithStorage[127.0.0.1:32828,DS-1b68d4a4-ae0a-461e-927a-1ce2f66f6524,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-83590751-172.17.0.7-1597704595014:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41109,DS-dae32686-301f-4594-b74e-26cba1c24ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:41868,DS-52f40d67-c851-4dc4-bfb5-4662ca3830ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44219,DS-d7f8db6b-b412-42af-b173-7757d8eb55e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37005,DS-01bc2fc2-fb52-4ec9-88dd-b2927f02423d,DISK], DatanodeInfoWithStorage[127.0.0.1:41174,DS-447f183e-459d-498b-bafa-4e5301de76c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38393,DS-8e7a04f8-6039-41ee-a41b-dd037bc6fd68,DISK], DatanodeInfoWithStorage[127.0.0.1:45968,DS-7fc2a150-5454-4c7e-b29b-e8c2caa6ffa7,DISK], DatanodeInfoWithStorage[127.0.0.1:43320,DS-cc661fc2-cd6d-48f7-b034-0c261eab859d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-83590751-172.17.0.7-1597704595014:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41109,DS-dae32686-301f-4594-b74e-26cba1c24ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:41868,DS-52f40d67-c851-4dc4-bfb5-4662ca3830ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44219,DS-d7f8db6b-b412-42af-b173-7757d8eb55e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37005,DS-01bc2fc2-fb52-4ec9-88dd-b2927f02423d,DISK], DatanodeInfoWithStorage[127.0.0.1:41174,DS-447f183e-459d-498b-bafa-4e5301de76c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38393,DS-8e7a04f8-6039-41ee-a41b-dd037bc6fd68,DISK], DatanodeInfoWithStorage[127.0.0.1:45968,DS-7fc2a150-5454-4c7e-b29b-e8c2caa6ffa7,DISK], DatanodeInfoWithStorage[127.0.0.1:43320,DS-cc661fc2-cd6d-48f7-b034-0c261eab859d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-537259318-172.17.0.7-1597705007095:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42495,DS-77bc8134-4e94-41c4-8354-276716c357ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39560,DS-b32646c8-1cbe-4251-bd3b-564ca158f868,DISK], DatanodeInfoWithStorage[127.0.0.1:43089,DS-6c2ffd99-6991-4c65-93cf-e012abe41c08,DISK], DatanodeInfoWithStorage[127.0.0.1:35061,DS-502447b5-8c9d-4dc9-ab11-35e6927a64bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37500,DS-c0e6a9f2-2327-482b-be80-c6980ce6ed6e,DISK], DatanodeInfoWithStorage[127.0.0.1:36724,DS-d9e17c9d-4433-47fa-a583-330a452450c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42414,DS-128dd84b-c472-4c4c-ab6d-5a52f529785e,DISK], DatanodeInfoWithStorage[127.0.0.1:40261,DS-ddc5fef5-ffbe-42c9-8b37-60541aa833ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-537259318-172.17.0.7-1597705007095:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42495,DS-77bc8134-4e94-41c4-8354-276716c357ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39560,DS-b32646c8-1cbe-4251-bd3b-564ca158f868,DISK], DatanodeInfoWithStorage[127.0.0.1:43089,DS-6c2ffd99-6991-4c65-93cf-e012abe41c08,DISK], DatanodeInfoWithStorage[127.0.0.1:35061,DS-502447b5-8c9d-4dc9-ab11-35e6927a64bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37500,DS-c0e6a9f2-2327-482b-be80-c6980ce6ed6e,DISK], DatanodeInfoWithStorage[127.0.0.1:36724,DS-d9e17c9d-4433-47fa-a583-330a452450c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42414,DS-128dd84b-c472-4c4c-ab6d-5a52f529785e,DISK], DatanodeInfoWithStorage[127.0.0.1:40261,DS-ddc5fef5-ffbe-42c9-8b37-60541aa833ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1019079173-172.17.0.7-1597705120656:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35003,DS-86b89ed1-4237-4c79-a8a8-5c6200606302,DISK], DatanodeInfoWithStorage[127.0.0.1:41724,DS-5e4ad53e-c04e-4a38-8657-2b0be91757ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36004,DS-494fcd59-1fa7-4cb7-ada1-cfbdd1fbc34d,DISK], DatanodeInfoWithStorage[127.0.0.1:42637,DS-4579f893-5c66-457e-aa93-93dcf3f1b56f,DISK], DatanodeInfoWithStorage[127.0.0.1:39314,DS-0a3230f7-df17-407c-9152-53e0eaad580e,DISK], DatanodeInfoWithStorage[127.0.0.1:41352,DS-dce5ae74-df5c-4025-b4b5-82d4f1bc506f,DISK], DatanodeInfoWithStorage[127.0.0.1:45514,DS-b19cb09e-ccd0-4c1c-8a6c-6f57c63784d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40275,DS-ca6bf0ec-efb8-45e9-8269-52515f5c0d4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1019079173-172.17.0.7-1597705120656:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35003,DS-86b89ed1-4237-4c79-a8a8-5c6200606302,DISK], DatanodeInfoWithStorage[127.0.0.1:41724,DS-5e4ad53e-c04e-4a38-8657-2b0be91757ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36004,DS-494fcd59-1fa7-4cb7-ada1-cfbdd1fbc34d,DISK], DatanodeInfoWithStorage[127.0.0.1:42637,DS-4579f893-5c66-457e-aa93-93dcf3f1b56f,DISK], DatanodeInfoWithStorage[127.0.0.1:39314,DS-0a3230f7-df17-407c-9152-53e0eaad580e,DISK], DatanodeInfoWithStorage[127.0.0.1:41352,DS-dce5ae74-df5c-4025-b4b5-82d4f1bc506f,DISK], DatanodeInfoWithStorage[127.0.0.1:45514,DS-b19cb09e-ccd0-4c1c-8a6c-6f57c63784d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40275,DS-ca6bf0ec-efb8-45e9-8269-52515f5c0d4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1455554313-172.17.0.7-1597705366805:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43675,DS-0064a8d1-c59b-4bf6-b607-5481d5fe94ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34872,DS-30cb635d-281c-4a40-9704-650993bdc689,DISK], DatanodeInfoWithStorage[127.0.0.1:43896,DS-9e57ec86-a9fb-4465-b56e-18724a8c730b,DISK], DatanodeInfoWithStorage[127.0.0.1:39935,DS-d8e2d79d-d21e-4678-a176-cda3ad8cbc59,DISK], DatanodeInfoWithStorage[127.0.0.1:44580,DS-d5703870-dbeb-48c4-9b4b-628415e670a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33427,DS-e84dc188-87e1-43f7-a03b-fce5a31952b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44717,DS-ce69ba7d-381a-42e3-ba2b-0d5ea96a603e,DISK], DatanodeInfoWithStorage[127.0.0.1:42052,DS-2bec4a34-2140-4849-bf79-41ec2bb5faa3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1455554313-172.17.0.7-1597705366805:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43675,DS-0064a8d1-c59b-4bf6-b607-5481d5fe94ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34872,DS-30cb635d-281c-4a40-9704-650993bdc689,DISK], DatanodeInfoWithStorage[127.0.0.1:43896,DS-9e57ec86-a9fb-4465-b56e-18724a8c730b,DISK], DatanodeInfoWithStorage[127.0.0.1:39935,DS-d8e2d79d-d21e-4678-a176-cda3ad8cbc59,DISK], DatanodeInfoWithStorage[127.0.0.1:44580,DS-d5703870-dbeb-48c4-9b4b-628415e670a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33427,DS-e84dc188-87e1-43f7-a03b-fce5a31952b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44717,DS-ce69ba7d-381a-42e3-ba2b-0d5ea96a603e,DISK], DatanodeInfoWithStorage[127.0.0.1:42052,DS-2bec4a34-2140-4849-bf79-41ec2bb5faa3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-242138885-172.17.0.7-1597705707736:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37361,DS-0aba3fdf-2bf6-4e92-b01a-fb3a6acaae60,DISK], DatanodeInfoWithStorage[127.0.0.1:37405,DS-8115f649-9327-439e-9c48-a5f8a4987458,DISK], DatanodeInfoWithStorage[127.0.0.1:41844,DS-da3705ca-17aa-4143-a300-fc13b2c8bc0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35971,DS-1d11cf6d-9eac-4fbd-95a8-c69a3894a43a,DISK], DatanodeInfoWithStorage[127.0.0.1:38930,DS-1c48cd03-8a06-48c8-8a50-bf48638d60dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37473,DS-30df7075-30c7-4da1-96fd-1f01dca8a476,DISK], DatanodeInfoWithStorage[127.0.0.1:37486,DS-48cbda1d-df09-404b-825e-1a77048b0b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:39374,DS-58ec13de-521d-4f0b-a94f-e58f488e92b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-242138885-172.17.0.7-1597705707736:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37361,DS-0aba3fdf-2bf6-4e92-b01a-fb3a6acaae60,DISK], DatanodeInfoWithStorage[127.0.0.1:37405,DS-8115f649-9327-439e-9c48-a5f8a4987458,DISK], DatanodeInfoWithStorage[127.0.0.1:41844,DS-da3705ca-17aa-4143-a300-fc13b2c8bc0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35971,DS-1d11cf6d-9eac-4fbd-95a8-c69a3894a43a,DISK], DatanodeInfoWithStorage[127.0.0.1:38930,DS-1c48cd03-8a06-48c8-8a50-bf48638d60dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37473,DS-30df7075-30c7-4da1-96fd-1f01dca8a476,DISK], DatanodeInfoWithStorage[127.0.0.1:37486,DS-48cbda1d-df09-404b-825e-1a77048b0b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:39374,DS-58ec13de-521d-4f0b-a94f-e58f488e92b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1996159951-172.17.0.7-1597705952582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45338,DS-7d3a5791-8d15-4146-8fa6-d431345ee8d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44520,DS-94f744ae-f510-4c89-a6ea-7dff10461f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:40677,DS-4d4f4583-7e6f-4956-9e5b-570bb94cb5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43176,DS-e893ac90-a8a2-4ec1-bd9d-5a15383325a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34272,DS-1eef05f9-3e28-43f7-a223-4b59ef6aac6d,DISK], DatanodeInfoWithStorage[127.0.0.1:37462,DS-a7254588-b197-4079-a0a7-6f17c9ee0593,DISK], DatanodeInfoWithStorage[127.0.0.1:46241,DS-496b4c06-a98b-43c3-9570-4887845c3c47,DISK], DatanodeInfoWithStorage[127.0.0.1:37327,DS-c16d2893-c9f1-4ab1-8ae3-e9fa4fa6316e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1996159951-172.17.0.7-1597705952582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45338,DS-7d3a5791-8d15-4146-8fa6-d431345ee8d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44520,DS-94f744ae-f510-4c89-a6ea-7dff10461f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:40677,DS-4d4f4583-7e6f-4956-9e5b-570bb94cb5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43176,DS-e893ac90-a8a2-4ec1-bd9d-5a15383325a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34272,DS-1eef05f9-3e28-43f7-a223-4b59ef6aac6d,DISK], DatanodeInfoWithStorage[127.0.0.1:37462,DS-a7254588-b197-4079-a0a7-6f17c9ee0593,DISK], DatanodeInfoWithStorage[127.0.0.1:46241,DS-496b4c06-a98b-43c3-9570-4887845c3c47,DISK], DatanodeInfoWithStorage[127.0.0.1:37327,DS-c16d2893-c9f1-4ab1-8ae3-e9fa4fa6316e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1308414531-172.17.0.7-1597706392784:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36981,DS-396269c2-e804-498a-b60d-ceb00f904576,DISK], DatanodeInfoWithStorage[127.0.0.1:40349,DS-e43079c3-3eb7-48c7-adfa-54d51699fd7a,DISK], DatanodeInfoWithStorage[127.0.0.1:45321,DS-70c75c9a-d028-4d99-aa56-33083312cd9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34887,DS-927ef8d7-be0b-4f7a-9966-a8170783e84d,DISK], DatanodeInfoWithStorage[127.0.0.1:39234,DS-597730d5-c395-4184-a1b7-2ef4d9db092f,DISK], DatanodeInfoWithStorage[127.0.0.1:41410,DS-cea5c42d-b250-4565-8c52-fb9ae7ae7801,DISK], DatanodeInfoWithStorage[127.0.0.1:44546,DS-9c3c7de7-59cc-4e1b-bbe3-20c9d2c49176,DISK], DatanodeInfoWithStorage[127.0.0.1:35790,DS-239dacce-71bf-43f2-95e7-fc443a22d7fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1308414531-172.17.0.7-1597706392784:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36981,DS-396269c2-e804-498a-b60d-ceb00f904576,DISK], DatanodeInfoWithStorage[127.0.0.1:40349,DS-e43079c3-3eb7-48c7-adfa-54d51699fd7a,DISK], DatanodeInfoWithStorage[127.0.0.1:45321,DS-70c75c9a-d028-4d99-aa56-33083312cd9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34887,DS-927ef8d7-be0b-4f7a-9966-a8170783e84d,DISK], DatanodeInfoWithStorage[127.0.0.1:39234,DS-597730d5-c395-4184-a1b7-2ef4d9db092f,DISK], DatanodeInfoWithStorage[127.0.0.1:41410,DS-cea5c42d-b250-4565-8c52-fb9ae7ae7801,DISK], DatanodeInfoWithStorage[127.0.0.1:44546,DS-9c3c7de7-59cc-4e1b-bbe3-20c9d2c49176,DISK], DatanodeInfoWithStorage[127.0.0.1:35790,DS-239dacce-71bf-43f2-95e7-fc443a22d7fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-414183840-172.17.0.7-1597707430437:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39620,DS-2f0c1db7-cd8a-428e-befd-4d21c8ba9ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:41920,DS-e6ae88ad-8b48-4eb4-a589-cc7cbffa4792,DISK], DatanodeInfoWithStorage[127.0.0.1:43903,DS-2cca60a6-a653-4918-bfeb-bb5475ea3dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:39568,DS-94e92f99-be56-4cce-938e-9bd2fd6c3670,DISK], DatanodeInfoWithStorage[127.0.0.1:40531,DS-6f672fa2-69f2-4539-9f58-1a3ab1cc5099,DISK], DatanodeInfoWithStorage[127.0.0.1:33889,DS-462ff0da-3cff-420b-b7db-4a629f167060,DISK], DatanodeInfoWithStorage[127.0.0.1:39657,DS-3a035c24-0ab2-4795-936c-42ce4d8a709a,DISK], DatanodeInfoWithStorage[127.0.0.1:38891,DS-9aa21e4a-3bf0-4e6f-9894-55c640a52380,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-414183840-172.17.0.7-1597707430437:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39620,DS-2f0c1db7-cd8a-428e-befd-4d21c8ba9ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:41920,DS-e6ae88ad-8b48-4eb4-a589-cc7cbffa4792,DISK], DatanodeInfoWithStorage[127.0.0.1:43903,DS-2cca60a6-a653-4918-bfeb-bb5475ea3dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:39568,DS-94e92f99-be56-4cce-938e-9bd2fd6c3670,DISK], DatanodeInfoWithStorage[127.0.0.1:40531,DS-6f672fa2-69f2-4539-9f58-1a3ab1cc5099,DISK], DatanodeInfoWithStorage[127.0.0.1:33889,DS-462ff0da-3cff-420b-b7db-4a629f167060,DISK], DatanodeInfoWithStorage[127.0.0.1:39657,DS-3a035c24-0ab2-4795-936c-42ce4d8a709a,DISK], DatanodeInfoWithStorage[127.0.0.1:38891,DS-9aa21e4a-3bf0-4e6f-9894-55c640a52380,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-177706142-172.17.0.7-1597708101977:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45976,DS-367d35c5-d151-46e9-8948-113384cb2e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:43115,DS-1965f70e-c728-4f71-ace2-cc494cfcd4f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42351,DS-9403577d-e059-450a-9df9-f10f5878faff,DISK], DatanodeInfoWithStorage[127.0.0.1:34542,DS-dc42007b-e55b-41d9-98d8-19fa1facf1a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40211,DS-0d7a425d-7c87-479c-b6a0-c701b6673177,DISK], DatanodeInfoWithStorage[127.0.0.1:38813,DS-3c1a9e29-bf00-496b-8b0d-f79bb49c4664,DISK], DatanodeInfoWithStorage[127.0.0.1:35410,DS-1e3a9596-2de8-4fd9-ae60-fdc933da1da3,DISK], DatanodeInfoWithStorage[127.0.0.1:42726,DS-acac56ab-b5c6-4c7c-b18d-dbe50801cf5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-177706142-172.17.0.7-1597708101977:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45976,DS-367d35c5-d151-46e9-8948-113384cb2e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:43115,DS-1965f70e-c728-4f71-ace2-cc494cfcd4f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42351,DS-9403577d-e059-450a-9df9-f10f5878faff,DISK], DatanodeInfoWithStorage[127.0.0.1:34542,DS-dc42007b-e55b-41d9-98d8-19fa1facf1a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40211,DS-0d7a425d-7c87-479c-b6a0-c701b6673177,DISK], DatanodeInfoWithStorage[127.0.0.1:38813,DS-3c1a9e29-bf00-496b-8b0d-f79bb49c4664,DISK], DatanodeInfoWithStorage[127.0.0.1:35410,DS-1e3a9596-2de8-4fd9-ae60-fdc933da1da3,DISK], DatanodeInfoWithStorage[127.0.0.1:42726,DS-acac56ab-b5c6-4c7c-b18d-dbe50801cf5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-499729163-172.17.0.7-1597708144770:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41538,DS-503ac38a-4cbc-470b-b52b-6bb793e831c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35612,DS-9c4a06d2-026e-4d22-b94e-94b4936727ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38518,DS-48071911-5882-42b2-bb79-e1a5ea33fb89,DISK], DatanodeInfoWithStorage[127.0.0.1:44183,DS-94035c42-de54-4692-a98b-7551d4709e23,DISK], DatanodeInfoWithStorage[127.0.0.1:40080,DS-d1b50dd9-f0b5-4906-a16c-d48fafb2cc72,DISK], DatanodeInfoWithStorage[127.0.0.1:43402,DS-6cf3e5d4-4a19-4a28-a33d-72ede2cf8752,DISK], DatanodeInfoWithStorage[127.0.0.1:33021,DS-da5e9ceb-34a2-4c39-81b9-e1c51cdd448d,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-624d183f-bad3-4609-a628-5607dec52466,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-499729163-172.17.0.7-1597708144770:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41538,DS-503ac38a-4cbc-470b-b52b-6bb793e831c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35612,DS-9c4a06d2-026e-4d22-b94e-94b4936727ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38518,DS-48071911-5882-42b2-bb79-e1a5ea33fb89,DISK], DatanodeInfoWithStorage[127.0.0.1:44183,DS-94035c42-de54-4692-a98b-7551d4709e23,DISK], DatanodeInfoWithStorage[127.0.0.1:40080,DS-d1b50dd9-f0b5-4906-a16c-d48fafb2cc72,DISK], DatanodeInfoWithStorage[127.0.0.1:43402,DS-6cf3e5d4-4a19-4a28-a33d-72ede2cf8752,DISK], DatanodeInfoWithStorage[127.0.0.1:33021,DS-da5e9ceb-34a2-4c39-81b9-e1c51cdd448d,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-624d183f-bad3-4609-a628-5607dec52466,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2121172234-172.17.0.7-1597708189761:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43458,DS-84db8bc3-2d05-4174-9a1a-ea0d1ba51efe,DISK], DatanodeInfoWithStorage[127.0.0.1:44158,DS-97f73361-ab7f-45c6-b340-09f91818d0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35177,DS-3cef806d-da40-4027-9ecb-522fff48ad39,DISK], DatanodeInfoWithStorage[127.0.0.1:42520,DS-3715bdc9-e26f-4188-96fd-2406cb769712,DISK], DatanodeInfoWithStorage[127.0.0.1:34098,DS-e0883475-2121-4b9d-951f-b3fa7f48aefa,DISK], DatanodeInfoWithStorage[127.0.0.1:33923,DS-08619e83-b701-44e6-ac4a-86c9d106dbf6,DISK], DatanodeInfoWithStorage[127.0.0.1:44704,DS-014d2675-af11-4eeb-91fc-60c3540ca6c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34721,DS-c8896e79-ac22-4428-8640-19ebd2511806,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2121172234-172.17.0.7-1597708189761:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43458,DS-84db8bc3-2d05-4174-9a1a-ea0d1ba51efe,DISK], DatanodeInfoWithStorage[127.0.0.1:44158,DS-97f73361-ab7f-45c6-b340-09f91818d0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35177,DS-3cef806d-da40-4027-9ecb-522fff48ad39,DISK], DatanodeInfoWithStorage[127.0.0.1:42520,DS-3715bdc9-e26f-4188-96fd-2406cb769712,DISK], DatanodeInfoWithStorage[127.0.0.1:34098,DS-e0883475-2121-4b9d-951f-b3fa7f48aefa,DISK], DatanodeInfoWithStorage[127.0.0.1:33923,DS-08619e83-b701-44e6-ac4a-86c9d106dbf6,DISK], DatanodeInfoWithStorage[127.0.0.1:44704,DS-014d2675-af11-4eeb-91fc-60c3540ca6c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34721,DS-c8896e79-ac22-4428-8640-19ebd2511806,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-636592896-172.17.0.7-1597708644438:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32884,DS-ef53f68e-b75a-44c4-8cd1-474c89d645fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46423,DS-72231675-8114-41d1-8666-9da960484827,DISK], DatanodeInfoWithStorage[127.0.0.1:42194,DS-61d75f2a-cc00-4993-b9a2-58c203b14e73,DISK], DatanodeInfoWithStorage[127.0.0.1:39789,DS-3e80d6b4-d667-4738-a389-092cec9422d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41236,DS-41229fff-f9d2-46b2-a65b-b69d994f44d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45756,DS-86a0bc19-4de2-443b-844a-8cc37e8e0134,DISK], DatanodeInfoWithStorage[127.0.0.1:44594,DS-0c0a5ec8-49e0-489e-806a-899b2c1a3267,DISK], DatanodeInfoWithStorage[127.0.0.1:35305,DS-f603c90b-d271-40ea-9a91-64ebb53c2da0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-636592896-172.17.0.7-1597708644438:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32884,DS-ef53f68e-b75a-44c4-8cd1-474c89d645fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46423,DS-72231675-8114-41d1-8666-9da960484827,DISK], DatanodeInfoWithStorage[127.0.0.1:42194,DS-61d75f2a-cc00-4993-b9a2-58c203b14e73,DISK], DatanodeInfoWithStorage[127.0.0.1:39789,DS-3e80d6b4-d667-4738-a389-092cec9422d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41236,DS-41229fff-f9d2-46b2-a65b-b69d994f44d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45756,DS-86a0bc19-4de2-443b-844a-8cc37e8e0134,DISK], DatanodeInfoWithStorage[127.0.0.1:44594,DS-0c0a5ec8-49e0-489e-806a-899b2c1a3267,DISK], DatanodeInfoWithStorage[127.0.0.1:35305,DS-f603c90b-d271-40ea-9a91-64ebb53c2da0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5984
