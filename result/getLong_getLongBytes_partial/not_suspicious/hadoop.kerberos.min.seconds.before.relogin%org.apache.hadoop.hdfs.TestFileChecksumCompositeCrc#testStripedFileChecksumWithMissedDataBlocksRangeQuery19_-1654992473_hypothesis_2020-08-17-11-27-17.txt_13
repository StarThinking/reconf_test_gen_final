reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 6
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 6
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-183340436-172.17.0.20-1597663867002:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41619,DS-668d25ce-031e-4d02-800d-0bf3bc978910,DISK], DatanodeInfoWithStorage[127.0.0.1:40363,DS-7a0f64a4-4b42-4f1b-8056-4dd1bf6493d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46819,DS-140b58e8-f248-475b-a2fc-0d39118513c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35537,DS-afea7af7-e4d1-46fd-aab6-372e820cee84,DISK], DatanodeInfoWithStorage[127.0.0.1:35385,DS-8b75960e-4db9-47cb-bd93-d5eeeef93e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40344,DS-b3722a94-6235-4df8-8c57-1eece0c61d87,DISK], DatanodeInfoWithStorage[127.0.0.1:38982,DS-97714e7e-a58d-4e2f-8315-68d15e337147,DISK], DatanodeInfoWithStorage[127.0.0.1:39677,DS-5f20103f-51e0-4058-83ab-b6a562317e46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-183340436-172.17.0.20-1597663867002:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41619,DS-668d25ce-031e-4d02-800d-0bf3bc978910,DISK], DatanodeInfoWithStorage[127.0.0.1:40363,DS-7a0f64a4-4b42-4f1b-8056-4dd1bf6493d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46819,DS-140b58e8-f248-475b-a2fc-0d39118513c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35537,DS-afea7af7-e4d1-46fd-aab6-372e820cee84,DISK], DatanodeInfoWithStorage[127.0.0.1:35385,DS-8b75960e-4db9-47cb-bd93-d5eeeef93e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40344,DS-b3722a94-6235-4df8-8c57-1eece0c61d87,DISK], DatanodeInfoWithStorage[127.0.0.1:38982,DS-97714e7e-a58d-4e2f-8315-68d15e337147,DISK], DatanodeInfoWithStorage[127.0.0.1:39677,DS-5f20103f-51e0-4058-83ab-b6a562317e46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 6
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-261989144-172.17.0.20-1597663908074:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38933,DS-c5f04b0d-7f76-47ff-8b9d-0426a293b3e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34911,DS-db1ae972-5872-4232-9fbf-b5975980447e,DISK], DatanodeInfoWithStorage[127.0.0.1:44108,DS-5f946496-c6f6-4c1a-9107-9b8965e7a057,DISK], DatanodeInfoWithStorage[127.0.0.1:33213,DS-551f19b8-d7d0-4157-916a-fd28a92cefcd,DISK], DatanodeInfoWithStorage[127.0.0.1:41100,DS-6b2e6810-c52f-4034-9dff-ccca75ea65a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41922,DS-2f160565-993e-4820-8984-d02607257281,DISK], DatanodeInfoWithStorage[127.0.0.1:43997,DS-2e7f0378-0198-49a7-85ff-52bffd1f2e74,DISK], DatanodeInfoWithStorage[127.0.0.1:42107,DS-08c00cc9-eee1-41b5-b996-85cdbecd9df0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-261989144-172.17.0.20-1597663908074:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38933,DS-c5f04b0d-7f76-47ff-8b9d-0426a293b3e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34911,DS-db1ae972-5872-4232-9fbf-b5975980447e,DISK], DatanodeInfoWithStorage[127.0.0.1:44108,DS-5f946496-c6f6-4c1a-9107-9b8965e7a057,DISK], DatanodeInfoWithStorage[127.0.0.1:33213,DS-551f19b8-d7d0-4157-916a-fd28a92cefcd,DISK], DatanodeInfoWithStorage[127.0.0.1:41100,DS-6b2e6810-c52f-4034-9dff-ccca75ea65a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41922,DS-2f160565-993e-4820-8984-d02607257281,DISK], DatanodeInfoWithStorage[127.0.0.1:43997,DS-2e7f0378-0198-49a7-85ff-52bffd1f2e74,DISK], DatanodeInfoWithStorage[127.0.0.1:42107,DS-08c00cc9-eee1-41b5-b996-85cdbecd9df0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 6
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1395912329-172.17.0.20-1597664097484:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45494,DS-4851a937-3fb3-4c57-89f6-395c806cd562,DISK], DatanodeInfoWithStorage[127.0.0.1:33448,DS-f1144345-c431-437d-8ae8-2b049abf5d7e,DISK], DatanodeInfoWithStorage[127.0.0.1:43595,DS-cb65a70c-ca56-48c4-a2db-8ca1ae248117,DISK], DatanodeInfoWithStorage[127.0.0.1:41685,DS-bb71abd3-869c-4ffb-a56e-a692873242f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46390,DS-2b620e38-e311-4c9a-912f-8a4dc767cc6e,DISK], DatanodeInfoWithStorage[127.0.0.1:35704,DS-b38353d8-092a-4aa7-973c-32abb75488e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46358,DS-b9f551ac-78d7-4617-a81c-edee8ed3e4ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41856,DS-6eb524ce-1ee0-4dfc-9621-7443d1d5b066,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1395912329-172.17.0.20-1597664097484:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45494,DS-4851a937-3fb3-4c57-89f6-395c806cd562,DISK], DatanodeInfoWithStorage[127.0.0.1:33448,DS-f1144345-c431-437d-8ae8-2b049abf5d7e,DISK], DatanodeInfoWithStorage[127.0.0.1:43595,DS-cb65a70c-ca56-48c4-a2db-8ca1ae248117,DISK], DatanodeInfoWithStorage[127.0.0.1:41685,DS-bb71abd3-869c-4ffb-a56e-a692873242f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46390,DS-2b620e38-e311-4c9a-912f-8a4dc767cc6e,DISK], DatanodeInfoWithStorage[127.0.0.1:35704,DS-b38353d8-092a-4aa7-973c-32abb75488e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46358,DS-b9f551ac-78d7-4617-a81c-edee8ed3e4ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41856,DS-6eb524ce-1ee0-4dfc-9621-7443d1d5b066,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 6
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1106199430-172.17.0.20-1597664217638:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38417,DS-e52d95f0-19cc-4500-9c28-a589429ea094,DISK], DatanodeInfoWithStorage[127.0.0.1:32922,DS-f217d235-4073-4a0c-bb0a-7e922766f91a,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-c8264938-5ad8-4940-9b9c-ba5d5ff0b5a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41886,DS-ebc54940-21f0-49b2-a11d-9b1d39aa9da3,DISK], DatanodeInfoWithStorage[127.0.0.1:36479,DS-49a4f2e0-839f-42b0-a313-9a4338e7639c,DISK], DatanodeInfoWithStorage[127.0.0.1:38953,DS-b74d74a6-85b4-4763-a502-1536b5b81398,DISK], DatanodeInfoWithStorage[127.0.0.1:39285,DS-674f8b60-9434-41f2-8039-e959f4d74c52,DISK], DatanodeInfoWithStorage[127.0.0.1:38063,DS-fced18b0-6e78-4157-8c02-8a5546a84976,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1106199430-172.17.0.20-1597664217638:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38417,DS-e52d95f0-19cc-4500-9c28-a589429ea094,DISK], DatanodeInfoWithStorage[127.0.0.1:32922,DS-f217d235-4073-4a0c-bb0a-7e922766f91a,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-c8264938-5ad8-4940-9b9c-ba5d5ff0b5a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41886,DS-ebc54940-21f0-49b2-a11d-9b1d39aa9da3,DISK], DatanodeInfoWithStorage[127.0.0.1:36479,DS-49a4f2e0-839f-42b0-a313-9a4338e7639c,DISK], DatanodeInfoWithStorage[127.0.0.1:38953,DS-b74d74a6-85b4-4763-a502-1536b5b81398,DISK], DatanodeInfoWithStorage[127.0.0.1:39285,DS-674f8b60-9434-41f2-8039-e959f4d74c52,DISK], DatanodeInfoWithStorage[127.0.0.1:38063,DS-fced18b0-6e78-4157-8c02-8a5546a84976,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 6
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-23556301-172.17.0.20-1597664438555:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37298,DS-1ece3702-9864-4b75-a0f2-11e66dc99815,DISK], DatanodeInfoWithStorage[127.0.0.1:39339,DS-5ea3af38-5eff-476e-936f-aae5275ecbd5,DISK], DatanodeInfoWithStorage[127.0.0.1:44655,DS-99f89593-5793-4581-a21a-d97edf8b0284,DISK], DatanodeInfoWithStorage[127.0.0.1:43270,DS-82dcc9cb-7c16-400f-bd03-991f5ee13e11,DISK], DatanodeInfoWithStorage[127.0.0.1:46561,DS-e8e79bcb-ba57-4b56-94ae-db0da735be9f,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-baa53bf2-f2e1-4fab-964f-2c82c7c85c03,DISK], DatanodeInfoWithStorage[127.0.0.1:43575,DS-49d9feeb-fa64-48aa-abb4-d7e49fcb758f,DISK], DatanodeInfoWithStorage[127.0.0.1:40370,DS-10082d94-6411-4a0a-a822-52e6973faf53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-23556301-172.17.0.20-1597664438555:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37298,DS-1ece3702-9864-4b75-a0f2-11e66dc99815,DISK], DatanodeInfoWithStorage[127.0.0.1:39339,DS-5ea3af38-5eff-476e-936f-aae5275ecbd5,DISK], DatanodeInfoWithStorage[127.0.0.1:44655,DS-99f89593-5793-4581-a21a-d97edf8b0284,DISK], DatanodeInfoWithStorage[127.0.0.1:43270,DS-82dcc9cb-7c16-400f-bd03-991f5ee13e11,DISK], DatanodeInfoWithStorage[127.0.0.1:46561,DS-e8e79bcb-ba57-4b56-94ae-db0da735be9f,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-baa53bf2-f2e1-4fab-964f-2c82c7c85c03,DISK], DatanodeInfoWithStorage[127.0.0.1:43575,DS-49d9feeb-fa64-48aa-abb4-d7e49fcb758f,DISK], DatanodeInfoWithStorage[127.0.0.1:40370,DS-10082d94-6411-4a0a-a822-52e6973faf53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 6
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2093361848-172.17.0.20-1597664590247:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44408,DS-1980e158-df01-439a-8e72-50f79dade0f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44458,DS-af3bfacf-2968-4800-9460-7b22b0628441,DISK], DatanodeInfoWithStorage[127.0.0.1:40060,DS-5f32d0de-d0a4-4a8f-a3a0-870acbffe8e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45836,DS-30097329-2955-48e8-af3c-e5aeada3cb4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39464,DS-6b2ca48d-d389-4ccb-8026-3c652dfb6938,DISK], DatanodeInfoWithStorage[127.0.0.1:35031,DS-d6a1624d-005b-4261-b67b-49a52f40ffb9,DISK], DatanodeInfoWithStorage[127.0.0.1:46674,DS-30a19677-8d85-4520-b94b-92f79fc77e41,DISK], DatanodeInfoWithStorage[127.0.0.1:43025,DS-9063d895-e2c5-4cb2-abed-470e38c120ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2093361848-172.17.0.20-1597664590247:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44408,DS-1980e158-df01-439a-8e72-50f79dade0f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44458,DS-af3bfacf-2968-4800-9460-7b22b0628441,DISK], DatanodeInfoWithStorage[127.0.0.1:40060,DS-5f32d0de-d0a4-4a8f-a3a0-870acbffe8e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45836,DS-30097329-2955-48e8-af3c-e5aeada3cb4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39464,DS-6b2ca48d-d389-4ccb-8026-3c652dfb6938,DISK], DatanodeInfoWithStorage[127.0.0.1:35031,DS-d6a1624d-005b-4261-b67b-49a52f40ffb9,DISK], DatanodeInfoWithStorage[127.0.0.1:46674,DS-30a19677-8d85-4520-b94b-92f79fc77e41,DISK], DatanodeInfoWithStorage[127.0.0.1:43025,DS-9063d895-e2c5-4cb2-abed-470e38c120ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 6
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1846161720-172.17.0.20-1597664820398:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45150,DS-7ecc7b32-5258-464f-88d2-d74953eeab12,DISK], DatanodeInfoWithStorage[127.0.0.1:44215,DS-e7773c2f-7ecd-4a16-8764-8a7a28606dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:43664,DS-be3330f8-23ac-4384-8d84-11a4b0d15c49,DISK], DatanodeInfoWithStorage[127.0.0.1:34160,DS-c89a9c61-2b10-44bb-ae56-7c72d7987485,DISK], DatanodeInfoWithStorage[127.0.0.1:34309,DS-ea69151c-b52e-4f5c-8ed6-1f494fce887b,DISK], DatanodeInfoWithStorage[127.0.0.1:40113,DS-876a4838-d440-4f5e-86ca-24ec4bfdd020,DISK], DatanodeInfoWithStorage[127.0.0.1:36584,DS-1b988d18-2cf0-4360-86c6-17221e65abce,DISK], DatanodeInfoWithStorage[127.0.0.1:42563,DS-e52bfd5b-ac30-4726-8ab6-7763ffbebee8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1846161720-172.17.0.20-1597664820398:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45150,DS-7ecc7b32-5258-464f-88d2-d74953eeab12,DISK], DatanodeInfoWithStorage[127.0.0.1:44215,DS-e7773c2f-7ecd-4a16-8764-8a7a28606dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:43664,DS-be3330f8-23ac-4384-8d84-11a4b0d15c49,DISK], DatanodeInfoWithStorage[127.0.0.1:34160,DS-c89a9c61-2b10-44bb-ae56-7c72d7987485,DISK], DatanodeInfoWithStorage[127.0.0.1:34309,DS-ea69151c-b52e-4f5c-8ed6-1f494fce887b,DISK], DatanodeInfoWithStorage[127.0.0.1:40113,DS-876a4838-d440-4f5e-86ca-24ec4bfdd020,DISK], DatanodeInfoWithStorage[127.0.0.1:36584,DS-1b988d18-2cf0-4360-86c6-17221e65abce,DISK], DatanodeInfoWithStorage[127.0.0.1:42563,DS-e52bfd5b-ac30-4726-8ab6-7763ffbebee8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 6
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2086088351-172.17.0.20-1597665383173:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39376,DS-cc220371-2b3d-4179-8dd6-f9943d02cf44,DISK], DatanodeInfoWithStorage[127.0.0.1:34931,DS-a1f5bb1f-fa4a-46d9-83fb-12b7751aacaa,DISK], DatanodeInfoWithStorage[127.0.0.1:38768,DS-464a7d04-0573-407c-9482-5181a6ddd8ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38812,DS-5a8946c4-c33a-4864-9751-07b692b79ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:44216,DS-d0ca133c-5180-4509-b452-1cb4df110c26,DISK], DatanodeInfoWithStorage[127.0.0.1:35927,DS-4c822c49-2729-4ab4-88b9-279e0698da68,DISK], DatanodeInfoWithStorage[127.0.0.1:43739,DS-74d5098e-d0df-4a50-b596-45cfb10ee884,DISK], DatanodeInfoWithStorage[127.0.0.1:36228,DS-8072049f-1746-4e4c-ac57-224a45dfec69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2086088351-172.17.0.20-1597665383173:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39376,DS-cc220371-2b3d-4179-8dd6-f9943d02cf44,DISK], DatanodeInfoWithStorage[127.0.0.1:34931,DS-a1f5bb1f-fa4a-46d9-83fb-12b7751aacaa,DISK], DatanodeInfoWithStorage[127.0.0.1:38768,DS-464a7d04-0573-407c-9482-5181a6ddd8ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38812,DS-5a8946c4-c33a-4864-9751-07b692b79ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:44216,DS-d0ca133c-5180-4509-b452-1cb4df110c26,DISK], DatanodeInfoWithStorage[127.0.0.1:35927,DS-4c822c49-2729-4ab4-88b9-279e0698da68,DISK], DatanodeInfoWithStorage[127.0.0.1:43739,DS-74d5098e-d0df-4a50-b596-45cfb10ee884,DISK], DatanodeInfoWithStorage[127.0.0.1:36228,DS-8072049f-1746-4e4c-ac57-224a45dfec69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 6
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2025517449-172.17.0.20-1597665534857:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33843,DS-a91b336a-de28-49b6-a2b5-8a5c1908ae97,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-bf289b34-a63f-4b3d-9240-f377b7ffbbb3,DISK], DatanodeInfoWithStorage[127.0.0.1:42956,DS-978a6469-a69a-45e7-a52f-9591087bd137,DISK], DatanodeInfoWithStorage[127.0.0.1:33924,DS-027c0380-ab3b-4ad0-aba9-afeb615bc2b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38143,DS-47759bbc-a785-49f0-b989-c2dde7321c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44879,DS-e87f3847-c9e7-4c0f-b624-52dc991276cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33481,DS-306e5e55-0983-4522-bf34-827d455cdfac,DISK], DatanodeInfoWithStorage[127.0.0.1:34659,DS-63ffbe72-a782-4dc6-b1f9-1dbf551e23fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2025517449-172.17.0.20-1597665534857:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33843,DS-a91b336a-de28-49b6-a2b5-8a5c1908ae97,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-bf289b34-a63f-4b3d-9240-f377b7ffbbb3,DISK], DatanodeInfoWithStorage[127.0.0.1:42956,DS-978a6469-a69a-45e7-a52f-9591087bd137,DISK], DatanodeInfoWithStorage[127.0.0.1:33924,DS-027c0380-ab3b-4ad0-aba9-afeb615bc2b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38143,DS-47759bbc-a785-49f0-b989-c2dde7321c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44879,DS-e87f3847-c9e7-4c0f-b624-52dc991276cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33481,DS-306e5e55-0983-4522-bf34-827d455cdfac,DISK], DatanodeInfoWithStorage[127.0.0.1:34659,DS-63ffbe72-a782-4dc6-b1f9-1dbf551e23fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 6
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1004105612-172.17.0.20-1597665644539:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38090,DS-97cea127-cb11-4c49-beb0-2396339640d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35086,DS-0660ded3-f700-4f2c-8d4b-d7964ac75f66,DISK], DatanodeInfoWithStorage[127.0.0.1:34272,DS-fc438163-6fe2-4061-ba3f-1a1ceeac4a24,DISK], DatanodeInfoWithStorage[127.0.0.1:40648,DS-39ca1800-40d5-41c1-8de6-4f7dba21f27d,DISK], DatanodeInfoWithStorage[127.0.0.1:38960,DS-50dd0f47-aa9a-4290-b3e3-f6a38c2e0b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:41224,DS-6a1e025f-4b6f-4f8c-a027-dfdd16a43081,DISK], DatanodeInfoWithStorage[127.0.0.1:33958,DS-9d674a97-7838-4d51-9b45-8802ef6870e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34149,DS-a3491f10-f810-43f6-88b8-926c8f821542,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1004105612-172.17.0.20-1597665644539:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38090,DS-97cea127-cb11-4c49-beb0-2396339640d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35086,DS-0660ded3-f700-4f2c-8d4b-d7964ac75f66,DISK], DatanodeInfoWithStorage[127.0.0.1:34272,DS-fc438163-6fe2-4061-ba3f-1a1ceeac4a24,DISK], DatanodeInfoWithStorage[127.0.0.1:40648,DS-39ca1800-40d5-41c1-8de6-4f7dba21f27d,DISK], DatanodeInfoWithStorage[127.0.0.1:38960,DS-50dd0f47-aa9a-4290-b3e3-f6a38c2e0b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:41224,DS-6a1e025f-4b6f-4f8c-a027-dfdd16a43081,DISK], DatanodeInfoWithStorage[127.0.0.1:33958,DS-9d674a97-7838-4d51-9b45-8802ef6870e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34149,DS-a3491f10-f810-43f6-88b8-926c8f821542,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 6
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1369844329-172.17.0.20-1597665788158:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41829,DS-2f3c087d-9784-412d-a9ee-74514fda8511,DISK], DatanodeInfoWithStorage[127.0.0.1:38526,DS-6b8f70b4-3ae8-4fba-9927-b984e7bf5545,DISK], DatanodeInfoWithStorage[127.0.0.1:36664,DS-e5085287-3fac-49e7-ab09-0ba04e6a6f76,DISK], DatanodeInfoWithStorage[127.0.0.1:37656,DS-cf9444d8-c859-4d26-be3f-82b95f7cddee,DISK], DatanodeInfoWithStorage[127.0.0.1:38537,DS-e9494d84-d8b2-43b9-a394-8133ec3df256,DISK], DatanodeInfoWithStorage[127.0.0.1:40087,DS-5ca224ac-1cb4-4e41-b14e-e778aaf23bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:44754,DS-76335b5e-b827-4f2f-9157-ca3b9369b155,DISK], DatanodeInfoWithStorage[127.0.0.1:35194,DS-ffe78b49-fd27-4433-ac60-ccf73b1302d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1369844329-172.17.0.20-1597665788158:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41829,DS-2f3c087d-9784-412d-a9ee-74514fda8511,DISK], DatanodeInfoWithStorage[127.0.0.1:38526,DS-6b8f70b4-3ae8-4fba-9927-b984e7bf5545,DISK], DatanodeInfoWithStorage[127.0.0.1:36664,DS-e5085287-3fac-49e7-ab09-0ba04e6a6f76,DISK], DatanodeInfoWithStorage[127.0.0.1:37656,DS-cf9444d8-c859-4d26-be3f-82b95f7cddee,DISK], DatanodeInfoWithStorage[127.0.0.1:38537,DS-e9494d84-d8b2-43b9-a394-8133ec3df256,DISK], DatanodeInfoWithStorage[127.0.0.1:40087,DS-5ca224ac-1cb4-4e41-b14e-e778aaf23bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:44754,DS-76335b5e-b827-4f2f-9157-ca3b9369b155,DISK], DatanodeInfoWithStorage[127.0.0.1:35194,DS-ffe78b49-fd27-4433-ac60-ccf73b1302d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 6
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-304435709-172.17.0.20-1597666152954:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39004,DS-4c66b3fc-a169-4352-824e-92f7f9fd5800,DISK], DatanodeInfoWithStorage[127.0.0.1:40406,DS-1222edbd-3c9b-4a6c-9439-2621df964466,DISK], DatanodeInfoWithStorage[127.0.0.1:35986,DS-df88b99e-e9c1-4be6-a0d3-539ed8b1e73c,DISK], DatanodeInfoWithStorage[127.0.0.1:43906,DS-5c87fbd5-6958-4896-a85d-e908d528406f,DISK], DatanodeInfoWithStorage[127.0.0.1:42212,DS-a30b3db3-cbf5-4a5c-bc85-224311384273,DISK], DatanodeInfoWithStorage[127.0.0.1:37651,DS-38eb773a-63d0-47d5-b9bf-6c8539a91de3,DISK], DatanodeInfoWithStorage[127.0.0.1:45491,DS-10b49f79-1f59-4931-9ca6-7c902a9c4e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36758,DS-3ca533ac-f482-459f-87f2-f566a7a98219,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-304435709-172.17.0.20-1597666152954:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39004,DS-4c66b3fc-a169-4352-824e-92f7f9fd5800,DISK], DatanodeInfoWithStorage[127.0.0.1:40406,DS-1222edbd-3c9b-4a6c-9439-2621df964466,DISK], DatanodeInfoWithStorage[127.0.0.1:35986,DS-df88b99e-e9c1-4be6-a0d3-539ed8b1e73c,DISK], DatanodeInfoWithStorage[127.0.0.1:43906,DS-5c87fbd5-6958-4896-a85d-e908d528406f,DISK], DatanodeInfoWithStorage[127.0.0.1:42212,DS-a30b3db3-cbf5-4a5c-bc85-224311384273,DISK], DatanodeInfoWithStorage[127.0.0.1:37651,DS-38eb773a-63d0-47d5-b9bf-6c8539a91de3,DISK], DatanodeInfoWithStorage[127.0.0.1:45491,DS-10b49f79-1f59-4931-9ca6-7c902a9c4e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36758,DS-3ca533ac-f482-459f-87f2-f566a7a98219,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 6
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1345129045-172.17.0.20-1597666494661:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38917,DS-cd904c65-048f-42fa-a351-9f372571d739,DISK], DatanodeInfoWithStorage[127.0.0.1:40845,DS-9ffb4519-520b-44e9-962a-59f0f1fa1405,DISK], DatanodeInfoWithStorage[127.0.0.1:38198,DS-c6aac4be-ce64-4e56-9851-d1735596fad9,DISK], DatanodeInfoWithStorage[127.0.0.1:39800,DS-0ec55cc8-26af-40f5-b767-ed562059630a,DISK], DatanodeInfoWithStorage[127.0.0.1:38230,DS-babb5cad-8bb6-410f-83d4-68e6a320efd3,DISK], DatanodeInfoWithStorage[127.0.0.1:34670,DS-5bdad8db-da97-4c96-a755-b1085839ad71,DISK], DatanodeInfoWithStorage[127.0.0.1:41860,DS-0b0116e8-6373-4e94-8a46-f57aa4f6717b,DISK], DatanodeInfoWithStorage[127.0.0.1:42110,DS-aef4e1ae-3f41-4353-99c3-6b5c2942861c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1345129045-172.17.0.20-1597666494661:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38917,DS-cd904c65-048f-42fa-a351-9f372571d739,DISK], DatanodeInfoWithStorage[127.0.0.1:40845,DS-9ffb4519-520b-44e9-962a-59f0f1fa1405,DISK], DatanodeInfoWithStorage[127.0.0.1:38198,DS-c6aac4be-ce64-4e56-9851-d1735596fad9,DISK], DatanodeInfoWithStorage[127.0.0.1:39800,DS-0ec55cc8-26af-40f5-b767-ed562059630a,DISK], DatanodeInfoWithStorage[127.0.0.1:38230,DS-babb5cad-8bb6-410f-83d4-68e6a320efd3,DISK], DatanodeInfoWithStorage[127.0.0.1:34670,DS-5bdad8db-da97-4c96-a755-b1085839ad71,DISK], DatanodeInfoWithStorage[127.0.0.1:41860,DS-0b0116e8-6373-4e94-8a46-f57aa4f6717b,DISK], DatanodeInfoWithStorage[127.0.0.1:42110,DS-aef4e1ae-3f41-4353-99c3-6b5c2942861c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 6
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-198801713-172.17.0.20-1597666528472:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37184,DS-6552b40d-b124-4411-8de0-d31f9265386a,DISK], DatanodeInfoWithStorage[127.0.0.1:37040,DS-3a1fb759-e685-40bf-9b03-ad26e7ff5b46,DISK], DatanodeInfoWithStorage[127.0.0.1:33236,DS-dbb320f5-987e-4e15-a651-76f95f9f4f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:35498,DS-c96154c1-f9d9-4679-9d6f-5a29a8dd13a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34935,DS-1ee66237-a7a0-48bb-8604-8dcb20b97c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:45791,DS-8e7dca79-f713-46c3-9464-e4bb4e192fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:45781,DS-889c901b-942c-4018-a68f-36bb2f83dfb9,DISK], DatanodeInfoWithStorage[127.0.0.1:42658,DS-bf927189-c757-4339-b4d8-1ebecc4c1c49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-198801713-172.17.0.20-1597666528472:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37184,DS-6552b40d-b124-4411-8de0-d31f9265386a,DISK], DatanodeInfoWithStorage[127.0.0.1:37040,DS-3a1fb759-e685-40bf-9b03-ad26e7ff5b46,DISK], DatanodeInfoWithStorage[127.0.0.1:33236,DS-dbb320f5-987e-4e15-a651-76f95f9f4f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:35498,DS-c96154c1-f9d9-4679-9d6f-5a29a8dd13a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34935,DS-1ee66237-a7a0-48bb-8604-8dcb20b97c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:45791,DS-8e7dca79-f713-46c3-9464-e4bb4e192fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:45781,DS-889c901b-942c-4018-a68f-36bb2f83dfb9,DISK], DatanodeInfoWithStorage[127.0.0.1:42658,DS-bf927189-c757-4339-b4d8-1ebecc4c1c49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 6
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1146144878-172.17.0.20-1597667095925:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44186,DS-103766dd-bb42-4fb3-86f2-0ab00264bf7a,DISK], DatanodeInfoWithStorage[127.0.0.1:45329,DS-17f97603-622f-4c37-b37f-6006dd7dc8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44284,DS-5b09b3f6-dd17-4906-b364-32096aa9aee1,DISK], DatanodeInfoWithStorage[127.0.0.1:41570,DS-bf274a02-0a04-4753-9563-4ea34db696c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42612,DS-b73f1aeb-a2fa-4161-bd13-f09cdf58a1da,DISK], DatanodeInfoWithStorage[127.0.0.1:33047,DS-687d2dec-6d16-42d3-a606-e2e8cef643ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38840,DS-654a6440-0e7f-4b11-a384-ba422fbef8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43124,DS-9afc227e-5419-42ef-b239-03bd22ea7a37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1146144878-172.17.0.20-1597667095925:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44186,DS-103766dd-bb42-4fb3-86f2-0ab00264bf7a,DISK], DatanodeInfoWithStorage[127.0.0.1:45329,DS-17f97603-622f-4c37-b37f-6006dd7dc8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44284,DS-5b09b3f6-dd17-4906-b364-32096aa9aee1,DISK], DatanodeInfoWithStorage[127.0.0.1:41570,DS-bf274a02-0a04-4753-9563-4ea34db696c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42612,DS-b73f1aeb-a2fa-4161-bd13-f09cdf58a1da,DISK], DatanodeInfoWithStorage[127.0.0.1:33047,DS-687d2dec-6d16-42d3-a606-e2e8cef643ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38840,DS-654a6440-0e7f-4b11-a384-ba422fbef8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43124,DS-9afc227e-5419-42ef-b239-03bd22ea7a37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 6
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-926847107-172.17.0.20-1597667210424:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34572,DS-fc58e0b3-79cb-43e0-aae1-534eb353858b,DISK], DatanodeInfoWithStorage[127.0.0.1:44878,DS-148175fa-eae1-4d91-b287-32bf54a8d391,DISK], DatanodeInfoWithStorage[127.0.0.1:39076,DS-d33f8cb6-ad52-40e7-9f69-b863a18e3a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:46298,DS-33d127a0-6217-4412-bfe6-5132bff747d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39154,DS-a73f54e8-71a3-486b-9ece-782958a6329e,DISK], DatanodeInfoWithStorage[127.0.0.1:35217,DS-ab54c5a3-180a-4aeb-a1b0-febe3ac9f655,DISK], DatanodeInfoWithStorage[127.0.0.1:40888,DS-9ddc48f1-e389-44ec-96dc-a50b81f98cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:37962,DS-72e86ed4-a856-4944-bae7-88b3c098ab79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-926847107-172.17.0.20-1597667210424:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34572,DS-fc58e0b3-79cb-43e0-aae1-534eb353858b,DISK], DatanodeInfoWithStorage[127.0.0.1:44878,DS-148175fa-eae1-4d91-b287-32bf54a8d391,DISK], DatanodeInfoWithStorage[127.0.0.1:39076,DS-d33f8cb6-ad52-40e7-9f69-b863a18e3a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:46298,DS-33d127a0-6217-4412-bfe6-5132bff747d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39154,DS-a73f54e8-71a3-486b-9ece-782958a6329e,DISK], DatanodeInfoWithStorage[127.0.0.1:35217,DS-ab54c5a3-180a-4aeb-a1b0-febe3ac9f655,DISK], DatanodeInfoWithStorage[127.0.0.1:40888,DS-9ddc48f1-e389-44ec-96dc-a50b81f98cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:37962,DS-72e86ed4-a856-4944-bae7-88b3c098ab79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 6
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-459633374-172.17.0.20-1597667532597:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35227,DS-80232d68-58f2-4872-a974-64a381c7a2ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45553,DS-276e3d77-09fa-452f-8a13-157fa93bd9fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46512,DS-6a2f9057-ce68-4d07-afa4-4c9607c008e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46262,DS-fd66b516-c0d7-496e-9089-3359ac45fc3e,DISK], DatanodeInfoWithStorage[127.0.0.1:43412,DS-6bad877d-50f1-498d-be95-8ea3cbaa03c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34114,DS-2f68ca3a-74c7-4a20-8832-cdb4dacf1b51,DISK], DatanodeInfoWithStorage[127.0.0.1:33478,DS-4f73312f-93f8-47f8-8602-5c0d31c820ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39049,DS-ad7d9641-a53a-4445-bfc9-412b6c70a147,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-459633374-172.17.0.20-1597667532597:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35227,DS-80232d68-58f2-4872-a974-64a381c7a2ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45553,DS-276e3d77-09fa-452f-8a13-157fa93bd9fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46512,DS-6a2f9057-ce68-4d07-afa4-4c9607c008e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46262,DS-fd66b516-c0d7-496e-9089-3359ac45fc3e,DISK], DatanodeInfoWithStorage[127.0.0.1:43412,DS-6bad877d-50f1-498d-be95-8ea3cbaa03c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34114,DS-2f68ca3a-74c7-4a20-8832-cdb4dacf1b51,DISK], DatanodeInfoWithStorage[127.0.0.1:33478,DS-4f73312f-93f8-47f8-8602-5c0d31c820ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39049,DS-ad7d9641-a53a-4445-bfc9-412b6c70a147,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 6
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1121759302-172.17.0.20-1597667629352:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40826,DS-975eaadc-5253-4817-b082-633f58e1738d,DISK], DatanodeInfoWithStorage[127.0.0.1:46302,DS-ab364e89-a4cd-4b2e-814b-7c4ea075e71c,DISK], DatanodeInfoWithStorage[127.0.0.1:37648,DS-7b69751f-0fdf-4725-8c72-bb3aecf20ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:46397,DS-c4ad6a6e-6162-4e15-a123-ab4de527a78d,DISK], DatanodeInfoWithStorage[127.0.0.1:44150,DS-3b61de6b-e234-4b8d-8f48-a06ba7531652,DISK], DatanodeInfoWithStorage[127.0.0.1:42356,DS-835db53a-de15-4c18-b6b2-517f34ec8c52,DISK], DatanodeInfoWithStorage[127.0.0.1:45033,DS-9ec9c909-21b4-4940-8724-8ebe6266fae1,DISK], DatanodeInfoWithStorage[127.0.0.1:40586,DS-0e8aca8a-0f8d-4234-b62c-b767a3530e86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1121759302-172.17.0.20-1597667629352:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40826,DS-975eaadc-5253-4817-b082-633f58e1738d,DISK], DatanodeInfoWithStorage[127.0.0.1:46302,DS-ab364e89-a4cd-4b2e-814b-7c4ea075e71c,DISK], DatanodeInfoWithStorage[127.0.0.1:37648,DS-7b69751f-0fdf-4725-8c72-bb3aecf20ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:46397,DS-c4ad6a6e-6162-4e15-a123-ab4de527a78d,DISK], DatanodeInfoWithStorage[127.0.0.1:44150,DS-3b61de6b-e234-4b8d-8f48-a06ba7531652,DISK], DatanodeInfoWithStorage[127.0.0.1:42356,DS-835db53a-de15-4c18-b6b2-517f34ec8c52,DISK], DatanodeInfoWithStorage[127.0.0.1:45033,DS-9ec9c909-21b4-4940-8724-8ebe6266fae1,DISK], DatanodeInfoWithStorage[127.0.0.1:40586,DS-0e8aca8a-0f8d-4234-b62c-b767a3530e86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 6
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1137335616-172.17.0.20-1597668290074:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39977,DS-c37d39a3-7b8b-48c8-a2d3-cd5195402e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:37566,DS-4ebdb2d8-e34c-4840-bdd3-d480dd306bee,DISK], DatanodeInfoWithStorage[127.0.0.1:37561,DS-8edc93a6-e7dd-4a0c-ab5e-5579fcdc136e,DISK], DatanodeInfoWithStorage[127.0.0.1:33558,DS-18f0354c-36e3-4a04-ba91-b399938477dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41083,DS-3f7ab035-65dd-4120-8e89-641bf1ae2887,DISK], DatanodeInfoWithStorage[127.0.0.1:33957,DS-32d6bc8d-0032-4015-9aa9-e74f4670cd16,DISK], DatanodeInfoWithStorage[127.0.0.1:42294,DS-d80d55ba-6fb0-45f7-ad36-ba09ca619030,DISK], DatanodeInfoWithStorage[127.0.0.1:44744,DS-ee9fd791-2ec7-4bac-9eaf-daeea6447e1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1137335616-172.17.0.20-1597668290074:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39977,DS-c37d39a3-7b8b-48c8-a2d3-cd5195402e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:37566,DS-4ebdb2d8-e34c-4840-bdd3-d480dd306bee,DISK], DatanodeInfoWithStorage[127.0.0.1:37561,DS-8edc93a6-e7dd-4a0c-ab5e-5579fcdc136e,DISK], DatanodeInfoWithStorage[127.0.0.1:33558,DS-18f0354c-36e3-4a04-ba91-b399938477dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41083,DS-3f7ab035-65dd-4120-8e89-641bf1ae2887,DISK], DatanodeInfoWithStorage[127.0.0.1:33957,DS-32d6bc8d-0032-4015-9aa9-e74f4670cd16,DISK], DatanodeInfoWithStorage[127.0.0.1:42294,DS-d80d55ba-6fb0-45f7-ad36-ba09ca619030,DISK], DatanodeInfoWithStorage[127.0.0.1:44744,DS-ee9fd791-2ec7-4bac-9eaf-daeea6447e1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 6
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1596390376-172.17.0.20-1597668641108:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45711,DS-3d1b478f-9a4d-4cb4-a093-cb702ec49e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44707,DS-395b9fc7-3e99-49fa-9d51-80c7a303ee88,DISK], DatanodeInfoWithStorage[127.0.0.1:46218,DS-11258115-dbaf-4be9-9b78-41e46505f8d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33300,DS-32044b18-fd01-47da-b0d1-499893a6b9d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35110,DS-04f39f26-dbd6-4ad3-9a17-b777ce8da72a,DISK], DatanodeInfoWithStorage[127.0.0.1:36366,DS-cd8bcbbd-7886-4202-9cb2-0bbe60d2a86e,DISK], DatanodeInfoWithStorage[127.0.0.1:36717,DS-449bde1f-f365-4cad-bb08-bf77dd0ad537,DISK], DatanodeInfoWithStorage[127.0.0.1:43393,DS-307d8ab2-6e71-4ed4-af67-5a6600add01d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1596390376-172.17.0.20-1597668641108:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45711,DS-3d1b478f-9a4d-4cb4-a093-cb702ec49e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44707,DS-395b9fc7-3e99-49fa-9d51-80c7a303ee88,DISK], DatanodeInfoWithStorage[127.0.0.1:46218,DS-11258115-dbaf-4be9-9b78-41e46505f8d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33300,DS-32044b18-fd01-47da-b0d1-499893a6b9d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35110,DS-04f39f26-dbd6-4ad3-9a17-b777ce8da72a,DISK], DatanodeInfoWithStorage[127.0.0.1:36366,DS-cd8bcbbd-7886-4202-9cb2-0bbe60d2a86e,DISK], DatanodeInfoWithStorage[127.0.0.1:36717,DS-449bde1f-f365-4cad-bb08-bf77dd0ad537,DISK], DatanodeInfoWithStorage[127.0.0.1:43393,DS-307d8ab2-6e71-4ed4-af67-5a6600add01d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5361
