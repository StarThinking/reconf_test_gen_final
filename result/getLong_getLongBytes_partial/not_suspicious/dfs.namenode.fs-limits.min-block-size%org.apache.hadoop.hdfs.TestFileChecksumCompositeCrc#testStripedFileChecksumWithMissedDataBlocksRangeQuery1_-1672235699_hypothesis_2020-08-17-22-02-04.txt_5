reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1272989614-172.17.0.5-1597701821369:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34007,DS-61cea4ba-352a-4230-aff3-d81783a165bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37034,DS-c0409813-78f0-40c6-8397-a4cce9dbeca1,DISK], DatanodeInfoWithStorage[127.0.0.1:45435,DS-9e33f48c-089b-43d4-a69b-00d8702c2306,DISK], DatanodeInfoWithStorage[127.0.0.1:41765,DS-0891f28b-c6a3-4f72-9630-74f82047f0e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41465,DS-0ad426b7-0780-42d9-b31d-c0d8d4a47ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:35311,DS-c4fa9c46-a777-494b-8669-ae920aa27c79,DISK], DatanodeInfoWithStorage[127.0.0.1:37773,DS-cc1945d2-8684-4ac9-9082-3e0ea5e9a6a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35950,DS-c2947e2a-a87d-48b5-955c-f6a4589fa96f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1272989614-172.17.0.5-1597701821369:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34007,DS-61cea4ba-352a-4230-aff3-d81783a165bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37034,DS-c0409813-78f0-40c6-8397-a4cce9dbeca1,DISK], DatanodeInfoWithStorage[127.0.0.1:45435,DS-9e33f48c-089b-43d4-a69b-00d8702c2306,DISK], DatanodeInfoWithStorage[127.0.0.1:41765,DS-0891f28b-c6a3-4f72-9630-74f82047f0e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41465,DS-0ad426b7-0780-42d9-b31d-c0d8d4a47ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:35311,DS-c4fa9c46-a777-494b-8669-ae920aa27c79,DISK], DatanodeInfoWithStorage[127.0.0.1:37773,DS-cc1945d2-8684-4ac9-9082-3e0ea5e9a6a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35950,DS-c2947e2a-a87d-48b5-955c-f6a4589fa96f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1553549557-172.17.0.5-1597701988013:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45730,DS-48cdbc2e-4e03-42e9-ab32-20048cff9443,DISK], DatanodeInfoWithStorage[127.0.0.1:43523,DS-651c091a-71ec-4ace-b045-807e0413722b,DISK], DatanodeInfoWithStorage[127.0.0.1:36842,DS-3e90644a-af33-4564-b1a7-67b9cbdad5c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43560,DS-825ee011-27f7-4652-9a9f-03fb1752b06d,DISK], DatanodeInfoWithStorage[127.0.0.1:41542,DS-0c5dc743-cfdc-450e-94a5-a37e60d8eb46,DISK], DatanodeInfoWithStorage[127.0.0.1:32980,DS-4f578a4f-328f-4a13-a086-6a437aa0ac02,DISK], DatanodeInfoWithStorage[127.0.0.1:34664,DS-e53b39e2-b440-404a-9e6f-bd5e2c593cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:45696,DS-1a40b1bf-824d-40a2-bddc-b55796ae3662,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1553549557-172.17.0.5-1597701988013:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45730,DS-48cdbc2e-4e03-42e9-ab32-20048cff9443,DISK], DatanodeInfoWithStorage[127.0.0.1:43523,DS-651c091a-71ec-4ace-b045-807e0413722b,DISK], DatanodeInfoWithStorage[127.0.0.1:36842,DS-3e90644a-af33-4564-b1a7-67b9cbdad5c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43560,DS-825ee011-27f7-4652-9a9f-03fb1752b06d,DISK], DatanodeInfoWithStorage[127.0.0.1:41542,DS-0c5dc743-cfdc-450e-94a5-a37e60d8eb46,DISK], DatanodeInfoWithStorage[127.0.0.1:32980,DS-4f578a4f-328f-4a13-a086-6a437aa0ac02,DISK], DatanodeInfoWithStorage[127.0.0.1:34664,DS-e53b39e2-b440-404a-9e6f-bd5e2c593cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:45696,DS-1a40b1bf-824d-40a2-bddc-b55796ae3662,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1352640225-172.17.0.5-1597702219228:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40143,DS-9113ce07-8b25-487a-889f-43b3c84b20e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38754,DS-6d5b9912-6564-43b7-ac1d-0fc166ccb04c,DISK], DatanodeInfoWithStorage[127.0.0.1:39552,DS-7260a530-7e69-44c2-9a68-91dbd112bda5,DISK], DatanodeInfoWithStorage[127.0.0.1:34338,DS-60a4be83-7507-4884-a1e7-e90984e842d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44660,DS-4e1901ee-683e-4d4a-abbd-aabe5e7e17a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33444,DS-78442d19-5627-441e-a50c-f49acf8da29f,DISK], DatanodeInfoWithStorage[127.0.0.1:42374,DS-e6952639-b595-4eb4-aba1-2052f9407d76,DISK], DatanodeInfoWithStorage[127.0.0.1:38935,DS-3be1c8bf-2a5c-4b98-a55b-d1ca00c5ed90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1352640225-172.17.0.5-1597702219228:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40143,DS-9113ce07-8b25-487a-889f-43b3c84b20e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38754,DS-6d5b9912-6564-43b7-ac1d-0fc166ccb04c,DISK], DatanodeInfoWithStorage[127.0.0.1:39552,DS-7260a530-7e69-44c2-9a68-91dbd112bda5,DISK], DatanodeInfoWithStorage[127.0.0.1:34338,DS-60a4be83-7507-4884-a1e7-e90984e842d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44660,DS-4e1901ee-683e-4d4a-abbd-aabe5e7e17a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33444,DS-78442d19-5627-441e-a50c-f49acf8da29f,DISK], DatanodeInfoWithStorage[127.0.0.1:42374,DS-e6952639-b595-4eb4-aba1-2052f9407d76,DISK], DatanodeInfoWithStorage[127.0.0.1:38935,DS-3be1c8bf-2a5c-4b98-a55b-d1ca00c5ed90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1469793665-172.17.0.5-1597702301521:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37165,DS-c96cbcb3-e067-4efd-ac82-fcac137ebce7,DISK], DatanodeInfoWithStorage[127.0.0.1:34939,DS-69b572ee-927a-4e12-b4ca-275ae24dd5d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40012,DS-1f469312-3c45-4453-82dc-89c68b07dad0,DISK], DatanodeInfoWithStorage[127.0.0.1:35712,DS-10011e6b-e82c-4760-affd-55f6f0323f55,DISK], DatanodeInfoWithStorage[127.0.0.1:33114,DS-d0bcfaa5-1d45-4e2e-a43c-a6aac330d935,DISK], DatanodeInfoWithStorage[127.0.0.1:37177,DS-cb5da1b3-9ec8-4915-b342-34e7fdcdecc2,DISK], DatanodeInfoWithStorage[127.0.0.1:36883,DS-513ebafd-b250-4a3f-91af-c458e46da2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35706,DS-79602502-16f0-4875-be2b-ecd338661527,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1469793665-172.17.0.5-1597702301521:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37165,DS-c96cbcb3-e067-4efd-ac82-fcac137ebce7,DISK], DatanodeInfoWithStorage[127.0.0.1:34939,DS-69b572ee-927a-4e12-b4ca-275ae24dd5d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40012,DS-1f469312-3c45-4453-82dc-89c68b07dad0,DISK], DatanodeInfoWithStorage[127.0.0.1:35712,DS-10011e6b-e82c-4760-affd-55f6f0323f55,DISK], DatanodeInfoWithStorage[127.0.0.1:33114,DS-d0bcfaa5-1d45-4e2e-a43c-a6aac330d935,DISK], DatanodeInfoWithStorage[127.0.0.1:37177,DS-cb5da1b3-9ec8-4915-b342-34e7fdcdecc2,DISK], DatanodeInfoWithStorage[127.0.0.1:36883,DS-513ebafd-b250-4a3f-91af-c458e46da2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35706,DS-79602502-16f0-4875-be2b-ecd338661527,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1821885149-172.17.0.5-1597702495342:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42728,DS-6b1f9f6a-a13e-45e5-a8c0-b5ea3580b19d,DISK], DatanodeInfoWithStorage[127.0.0.1:36363,DS-6290e70d-9888-4431-a841-08bc45a23cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:45342,DS-7734ab38-3bc0-425e-9ca5-6613d3e40c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34438,DS-725b5939-1589-4864-8648-1a1f6856c595,DISK], DatanodeInfoWithStorage[127.0.0.1:38259,DS-36bd63f4-1e39-4a1f-b58e-b01b0bc2c5b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42813,DS-153f04ca-1856-4ed8-836e-e3266e4e0d29,DISK], DatanodeInfoWithStorage[127.0.0.1:40125,DS-a847d60a-2fd2-4779-9347-2f6edca86a24,DISK], DatanodeInfoWithStorage[127.0.0.1:37820,DS-6aacaf81-7848-42c2-9abf-e973931f5fc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1821885149-172.17.0.5-1597702495342:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42728,DS-6b1f9f6a-a13e-45e5-a8c0-b5ea3580b19d,DISK], DatanodeInfoWithStorage[127.0.0.1:36363,DS-6290e70d-9888-4431-a841-08bc45a23cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:45342,DS-7734ab38-3bc0-425e-9ca5-6613d3e40c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34438,DS-725b5939-1589-4864-8648-1a1f6856c595,DISK], DatanodeInfoWithStorage[127.0.0.1:38259,DS-36bd63f4-1e39-4a1f-b58e-b01b0bc2c5b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42813,DS-153f04ca-1856-4ed8-836e-e3266e4e0d29,DISK], DatanodeInfoWithStorage[127.0.0.1:40125,DS-a847d60a-2fd2-4779-9347-2f6edca86a24,DISK], DatanodeInfoWithStorage[127.0.0.1:37820,DS-6aacaf81-7848-42c2-9abf-e973931f5fc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1080894278-172.17.0.5-1597702658895:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42271,DS-e5f8d93c-c9e8-4046-82c2-f8540a4698f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45689,DS-31f5fbd2-6540-43dd-9782-916b1cdf4a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:38709,DS-bc181e72-6911-4770-bf4e-ae2db5d32bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:45354,DS-533f3280-2c5b-4b11-9eb2-4bcf3bfdd208,DISK], DatanodeInfoWithStorage[127.0.0.1:45599,DS-1d81fe2a-90b0-4f95-95a2-a5968e375052,DISK], DatanodeInfoWithStorage[127.0.0.1:33778,DS-50b7ce20-c63e-47d5-bcf4-cca69dd27002,DISK], DatanodeInfoWithStorage[127.0.0.1:42707,DS-d263cf68-9ec9-4f05-b5c5-77c110c20d75,DISK], DatanodeInfoWithStorage[127.0.0.1:37484,DS-d9dadf15-f098-40c2-a5e2-c353b102aa2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1080894278-172.17.0.5-1597702658895:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42271,DS-e5f8d93c-c9e8-4046-82c2-f8540a4698f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45689,DS-31f5fbd2-6540-43dd-9782-916b1cdf4a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:38709,DS-bc181e72-6911-4770-bf4e-ae2db5d32bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:45354,DS-533f3280-2c5b-4b11-9eb2-4bcf3bfdd208,DISK], DatanodeInfoWithStorage[127.0.0.1:45599,DS-1d81fe2a-90b0-4f95-95a2-a5968e375052,DISK], DatanodeInfoWithStorage[127.0.0.1:33778,DS-50b7ce20-c63e-47d5-bcf4-cca69dd27002,DISK], DatanodeInfoWithStorage[127.0.0.1:42707,DS-d263cf68-9ec9-4f05-b5c5-77c110c20d75,DISK], DatanodeInfoWithStorage[127.0.0.1:37484,DS-d9dadf15-f098-40c2-a5e2-c353b102aa2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1205079607-172.17.0.5-1597702885738:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37540,DS-5cef9ff1-ba75-49e9-9c47-2c060cb2c7da,DISK], DatanodeInfoWithStorage[127.0.0.1:46206,DS-fee25179-1d76-478e-aee6-a4ca32dbc3e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34897,DS-475fbc9c-55bd-4691-93a6-a6505b343705,DISK], DatanodeInfoWithStorage[127.0.0.1:44006,DS-a265ab40-341d-4422-8690-f749d8ff689a,DISK], DatanodeInfoWithStorage[127.0.0.1:36676,DS-7a71b09a-5ea8-4e51-94f4-1e6ca7f714b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42476,DS-608cf4df-a37e-45cd-881c-f6481101051c,DISK], DatanodeInfoWithStorage[127.0.0.1:40570,DS-4af972c4-73f7-4fe0-a73f-55cb85862e51,DISK], DatanodeInfoWithStorage[127.0.0.1:45078,DS-319b4b61-7f21-4086-8465-79b8083b26d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1205079607-172.17.0.5-1597702885738:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37540,DS-5cef9ff1-ba75-49e9-9c47-2c060cb2c7da,DISK], DatanodeInfoWithStorage[127.0.0.1:46206,DS-fee25179-1d76-478e-aee6-a4ca32dbc3e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34897,DS-475fbc9c-55bd-4691-93a6-a6505b343705,DISK], DatanodeInfoWithStorage[127.0.0.1:44006,DS-a265ab40-341d-4422-8690-f749d8ff689a,DISK], DatanodeInfoWithStorage[127.0.0.1:36676,DS-7a71b09a-5ea8-4e51-94f4-1e6ca7f714b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42476,DS-608cf4df-a37e-45cd-881c-f6481101051c,DISK], DatanodeInfoWithStorage[127.0.0.1:40570,DS-4af972c4-73f7-4fe0-a73f-55cb85862e51,DISK], DatanodeInfoWithStorage[127.0.0.1:45078,DS-319b4b61-7f21-4086-8465-79b8083b26d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1860327314-172.17.0.5-1597705081136:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43286,DS-6d68385a-9772-4b20-9aff-fdded8eae647,DISK], DatanodeInfoWithStorage[127.0.0.1:45063,DS-25b24012-9915-4aa8-a5bd-4aa3b6e2366b,DISK], DatanodeInfoWithStorage[127.0.0.1:38082,DS-35b2d0db-ed3a-4063-9dba-e6beefacc720,DISK], DatanodeInfoWithStorage[127.0.0.1:42545,DS-c0e9bb0f-26fd-402e-a881-b477e3f07be4,DISK], DatanodeInfoWithStorage[127.0.0.1:33001,DS-1a0f0fb0-60e2-495e-8854-2ffddbf15d78,DISK], DatanodeInfoWithStorage[127.0.0.1:43261,DS-f8067a2a-5e1b-493e-88fc-6627dc7132a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34270,DS-8238ed59-3152-438a-aff9-40ee3583caba,DISK], DatanodeInfoWithStorage[127.0.0.1:45316,DS-eb91ae10-5aa8-4634-b329-e2b516684b9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1860327314-172.17.0.5-1597705081136:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43286,DS-6d68385a-9772-4b20-9aff-fdded8eae647,DISK], DatanodeInfoWithStorage[127.0.0.1:45063,DS-25b24012-9915-4aa8-a5bd-4aa3b6e2366b,DISK], DatanodeInfoWithStorage[127.0.0.1:38082,DS-35b2d0db-ed3a-4063-9dba-e6beefacc720,DISK], DatanodeInfoWithStorage[127.0.0.1:42545,DS-c0e9bb0f-26fd-402e-a881-b477e3f07be4,DISK], DatanodeInfoWithStorage[127.0.0.1:33001,DS-1a0f0fb0-60e2-495e-8854-2ffddbf15d78,DISK], DatanodeInfoWithStorage[127.0.0.1:43261,DS-f8067a2a-5e1b-493e-88fc-6627dc7132a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34270,DS-8238ed59-3152-438a-aff9-40ee3583caba,DISK], DatanodeInfoWithStorage[127.0.0.1:45316,DS-eb91ae10-5aa8-4634-b329-e2b516684b9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1725266666-172.17.0.5-1597705309382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33675,DS-5661edc7-195e-4cf9-966d-a80e27338b04,DISK], DatanodeInfoWithStorage[127.0.0.1:45219,DS-284c4c6c-71c5-4186-93ea-ede68fe57cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:36986,DS-f0e3d6c7-e77e-43de-a351-38f37beaf2b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43610,DS-0f0d2140-fb2c-49cd-911a-66e2d8c94903,DISK], DatanodeInfoWithStorage[127.0.0.1:43258,DS-b52628cd-a84c-4867-a03e-7fdd66b7b744,DISK], DatanodeInfoWithStorage[127.0.0.1:43139,DS-96166e2d-2766-49e6-bab7-78e83680a670,DISK], DatanodeInfoWithStorage[127.0.0.1:37871,DS-50929e8f-d7f8-47c7-b1d1-88599b2619c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34562,DS-0e9f6576-fdac-46ea-86ee-5bfb24c786f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1725266666-172.17.0.5-1597705309382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33675,DS-5661edc7-195e-4cf9-966d-a80e27338b04,DISK], DatanodeInfoWithStorage[127.0.0.1:45219,DS-284c4c6c-71c5-4186-93ea-ede68fe57cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:36986,DS-f0e3d6c7-e77e-43de-a351-38f37beaf2b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43610,DS-0f0d2140-fb2c-49cd-911a-66e2d8c94903,DISK], DatanodeInfoWithStorage[127.0.0.1:43258,DS-b52628cd-a84c-4867-a03e-7fdd66b7b744,DISK], DatanodeInfoWithStorage[127.0.0.1:43139,DS-96166e2d-2766-49e6-bab7-78e83680a670,DISK], DatanodeInfoWithStorage[127.0.0.1:37871,DS-50929e8f-d7f8-47c7-b1d1-88599b2619c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34562,DS-0e9f6576-fdac-46ea-86ee-5bfb24c786f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1623467693-172.17.0.5-1597706061423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43463,DS-cccdd2ca-5083-4ea3-9ebc-4dc761973f75,DISK], DatanodeInfoWithStorage[127.0.0.1:33696,DS-d5c5ca57-2809-4d24-ad41-1bff1728b747,DISK], DatanodeInfoWithStorage[127.0.0.1:40769,DS-8d7b020d-655b-49c8-ad39-11d2b2a218f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42428,DS-b2eb111d-6e91-47d7-8790-eb691fc2ce3e,DISK], DatanodeInfoWithStorage[127.0.0.1:41837,DS-d83d2195-5b2e-4275-a1b1-aedad747a461,DISK], DatanodeInfoWithStorage[127.0.0.1:39455,DS-9ae542fc-ee5c-4cdf-9e08-f18a157dd11e,DISK], DatanodeInfoWithStorage[127.0.0.1:43837,DS-a495f876-cb07-4a56-b261-41772abd7942,DISK], DatanodeInfoWithStorage[127.0.0.1:34320,DS-ee8efbda-8003-439d-ac89-6e82b0e65b3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1623467693-172.17.0.5-1597706061423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43463,DS-cccdd2ca-5083-4ea3-9ebc-4dc761973f75,DISK], DatanodeInfoWithStorage[127.0.0.1:33696,DS-d5c5ca57-2809-4d24-ad41-1bff1728b747,DISK], DatanodeInfoWithStorage[127.0.0.1:40769,DS-8d7b020d-655b-49c8-ad39-11d2b2a218f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42428,DS-b2eb111d-6e91-47d7-8790-eb691fc2ce3e,DISK], DatanodeInfoWithStorage[127.0.0.1:41837,DS-d83d2195-5b2e-4275-a1b1-aedad747a461,DISK], DatanodeInfoWithStorage[127.0.0.1:39455,DS-9ae542fc-ee5c-4cdf-9e08-f18a157dd11e,DISK], DatanodeInfoWithStorage[127.0.0.1:43837,DS-a495f876-cb07-4a56-b261-41772abd7942,DISK], DatanodeInfoWithStorage[127.0.0.1:34320,DS-ee8efbda-8003-439d-ac89-6e82b0e65b3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1429866635-172.17.0.5-1597706528317:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35239,DS-ea20d0ba-a8d6-4046-937c-c15a79f8b813,DISK], DatanodeInfoWithStorage[127.0.0.1:34931,DS-abbb4dfe-9abf-4a59-bed1-4b96032b7711,DISK], DatanodeInfoWithStorage[127.0.0.1:40667,DS-7ddd0922-5eca-46db-8ad0-14d1ff9dace3,DISK], DatanodeInfoWithStorage[127.0.0.1:36206,DS-495f379d-904e-4517-b607-8d6db8b45a12,DISK], DatanodeInfoWithStorage[127.0.0.1:36550,DS-c3efbef8-a02b-46b4-a7a0-fe2e3ab2af33,DISK], DatanodeInfoWithStorage[127.0.0.1:33332,DS-c6de4ae7-5a52-4fdd-a5f4-c09bed93b49d,DISK], DatanodeInfoWithStorage[127.0.0.1:43458,DS-3d022332-1747-4f3b-877e-b481fedc5364,DISK], DatanodeInfoWithStorage[127.0.0.1:42479,DS-67196d91-5988-4582-8594-ccb9af89f2f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1429866635-172.17.0.5-1597706528317:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35239,DS-ea20d0ba-a8d6-4046-937c-c15a79f8b813,DISK], DatanodeInfoWithStorage[127.0.0.1:34931,DS-abbb4dfe-9abf-4a59-bed1-4b96032b7711,DISK], DatanodeInfoWithStorage[127.0.0.1:40667,DS-7ddd0922-5eca-46db-8ad0-14d1ff9dace3,DISK], DatanodeInfoWithStorage[127.0.0.1:36206,DS-495f379d-904e-4517-b607-8d6db8b45a12,DISK], DatanodeInfoWithStorage[127.0.0.1:36550,DS-c3efbef8-a02b-46b4-a7a0-fe2e3ab2af33,DISK], DatanodeInfoWithStorage[127.0.0.1:33332,DS-c6de4ae7-5a52-4fdd-a5f4-c09bed93b49d,DISK], DatanodeInfoWithStorage[127.0.0.1:43458,DS-3d022332-1747-4f3b-877e-b481fedc5364,DISK], DatanodeInfoWithStorage[127.0.0.1:42479,DS-67196d91-5988-4582-8594-ccb9af89f2f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1157307977-172.17.0.5-1597706767241:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45490,DS-ba58bbdc-20fc-41d4-8634-14968aeb0fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:44318,DS-72bebf2f-6bf6-4b8f-8701-eabac84e4148,DISK], DatanodeInfoWithStorage[127.0.0.1:36256,DS-3deaca9f-e4a1-414f-88c5-4e67afeac87d,DISK], DatanodeInfoWithStorage[127.0.0.1:43061,DS-916d8b33-4f1a-4c59-8b06-a1fa7135e660,DISK], DatanodeInfoWithStorage[127.0.0.1:43225,DS-2171e1ef-6829-4139-8688-2f77e5a05ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:43060,DS-a2a86e74-dda7-4590-9ec8-c01a80934629,DISK], DatanodeInfoWithStorage[127.0.0.1:46634,DS-4814edf7-7574-4427-8a11-9010dc9bee39,DISK], DatanodeInfoWithStorage[127.0.0.1:40713,DS-561d1783-dd23-42b8-b303-57cac340c8a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1157307977-172.17.0.5-1597706767241:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45490,DS-ba58bbdc-20fc-41d4-8634-14968aeb0fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:44318,DS-72bebf2f-6bf6-4b8f-8701-eabac84e4148,DISK], DatanodeInfoWithStorage[127.0.0.1:36256,DS-3deaca9f-e4a1-414f-88c5-4e67afeac87d,DISK], DatanodeInfoWithStorage[127.0.0.1:43061,DS-916d8b33-4f1a-4c59-8b06-a1fa7135e660,DISK], DatanodeInfoWithStorage[127.0.0.1:43225,DS-2171e1ef-6829-4139-8688-2f77e5a05ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:43060,DS-a2a86e74-dda7-4590-9ec8-c01a80934629,DISK], DatanodeInfoWithStorage[127.0.0.1:46634,DS-4814edf7-7574-4427-8a11-9010dc9bee39,DISK], DatanodeInfoWithStorage[127.0.0.1:40713,DS-561d1783-dd23-42b8-b303-57cac340c8a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2067371912-172.17.0.5-1597706921295:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37635,DS-2e2415fb-a1ce-49f7-a5c3-11a2ef2514cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43312,DS-7c4cbe70-372f-4a2e-8516-65ea73c81d73,DISK], DatanodeInfoWithStorage[127.0.0.1:34828,DS-51bbd17f-f2fc-4908-8d89-2a8e524365fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41577,DS-5cf022a6-d43e-4d29-8d96-b4589cce1a75,DISK], DatanodeInfoWithStorage[127.0.0.1:43011,DS-487c50be-a170-4732-9d1b-b777649a1f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33368,DS-e7e70a29-ff0d-4da9-ba56-e643f6fcb42f,DISK], DatanodeInfoWithStorage[127.0.0.1:43284,DS-9aa8bc15-fd7e-4ed1-9cd5-613a1b9ecb95,DISK], DatanodeInfoWithStorage[127.0.0.1:41264,DS-cc395d03-06a0-4c97-a922-230c234f0170,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2067371912-172.17.0.5-1597706921295:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37635,DS-2e2415fb-a1ce-49f7-a5c3-11a2ef2514cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43312,DS-7c4cbe70-372f-4a2e-8516-65ea73c81d73,DISK], DatanodeInfoWithStorage[127.0.0.1:34828,DS-51bbd17f-f2fc-4908-8d89-2a8e524365fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41577,DS-5cf022a6-d43e-4d29-8d96-b4589cce1a75,DISK], DatanodeInfoWithStorage[127.0.0.1:43011,DS-487c50be-a170-4732-9d1b-b777649a1f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33368,DS-e7e70a29-ff0d-4da9-ba56-e643f6fcb42f,DISK], DatanodeInfoWithStorage[127.0.0.1:43284,DS-9aa8bc15-fd7e-4ed1-9cd5-613a1b9ecb95,DISK], DatanodeInfoWithStorage[127.0.0.1:41264,DS-cc395d03-06a0-4c97-a922-230c234f0170,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5798
