reconf_parameter: dfs.namenode.delegation.token.max-lifetime
component: hdfs:NameNode
v1: 604800000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.max-lifetime
component: hdfs:NameNode
v1: 604800000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1240697937-172.17.0.11-1597700756869:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46840,DS-f4dfb422-eb1c-4c92-b68f-e3e847d8ad59,DISK], DatanodeInfoWithStorage[127.0.0.1:34287,DS-110ccc7f-0f6c-44fb-ae3f-1d36ef4bc28e,DISK], DatanodeInfoWithStorage[127.0.0.1:46348,DS-f4eff0ee-4d01-4874-808d-723e6049edbd,DISK], DatanodeInfoWithStorage[127.0.0.1:41977,DS-d00f25d2-429f-49dc-a73b-f25bd0801a86,DISK], DatanodeInfoWithStorage[127.0.0.1:45268,DS-128183ed-d0cc-42b9-8c02-0b2f21596b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:46050,DS-d8f9a817-476b-4984-814b-8d2235a55dc1,DISK], DatanodeInfoWithStorage[127.0.0.1:35699,DS-338af8e9-8a0d-4efa-961d-a57b4b58269a,DISK], DatanodeInfoWithStorage[127.0.0.1:32908,DS-c88c4552-7d54-4f90-8dcd-bc42349a710b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1240697937-172.17.0.11-1597700756869:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46840,DS-f4dfb422-eb1c-4c92-b68f-e3e847d8ad59,DISK], DatanodeInfoWithStorage[127.0.0.1:34287,DS-110ccc7f-0f6c-44fb-ae3f-1d36ef4bc28e,DISK], DatanodeInfoWithStorage[127.0.0.1:46348,DS-f4eff0ee-4d01-4874-808d-723e6049edbd,DISK], DatanodeInfoWithStorage[127.0.0.1:41977,DS-d00f25d2-429f-49dc-a73b-f25bd0801a86,DISK], DatanodeInfoWithStorage[127.0.0.1:45268,DS-128183ed-d0cc-42b9-8c02-0b2f21596b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:46050,DS-d8f9a817-476b-4984-814b-8d2235a55dc1,DISK], DatanodeInfoWithStorage[127.0.0.1:35699,DS-338af8e9-8a0d-4efa-961d-a57b4b58269a,DISK], DatanodeInfoWithStorage[127.0.0.1:32908,DS-c88c4552-7d54-4f90-8dcd-bc42349a710b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.delegation.token.max-lifetime
component: hdfs:NameNode
v1: 604800000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-86158276-172.17.0.11-1597700803392:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44736,DS-4dc995c6-8d85-4728-80ff-6737762745a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46825,DS-35ceb0e0-3158-4361-995b-a6b35cbcc0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36039,DS-d20021ca-2deb-4fdb-ad45-62e12300090b,DISK], DatanodeInfoWithStorage[127.0.0.1:40147,DS-c03bae37-fc2d-44c9-a9a1-4e629b020937,DISK], DatanodeInfoWithStorage[127.0.0.1:42234,DS-b4548278-931a-4f85-97cd-bbefb2f3811a,DISK], DatanodeInfoWithStorage[127.0.0.1:41081,DS-d536ff8c-2c13-498d-b4f1-aeb95471fd53,DISK], DatanodeInfoWithStorage[127.0.0.1:35855,DS-4eb4f79c-0f36-4be7-a723-fea7072da87d,DISK], DatanodeInfoWithStorage[127.0.0.1:40900,DS-e9283a9e-8414-452f-9c40-31474a054f65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-86158276-172.17.0.11-1597700803392:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44736,DS-4dc995c6-8d85-4728-80ff-6737762745a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46825,DS-35ceb0e0-3158-4361-995b-a6b35cbcc0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36039,DS-d20021ca-2deb-4fdb-ad45-62e12300090b,DISK], DatanodeInfoWithStorage[127.0.0.1:40147,DS-c03bae37-fc2d-44c9-a9a1-4e629b020937,DISK], DatanodeInfoWithStorage[127.0.0.1:42234,DS-b4548278-931a-4f85-97cd-bbefb2f3811a,DISK], DatanodeInfoWithStorage[127.0.0.1:41081,DS-d536ff8c-2c13-498d-b4f1-aeb95471fd53,DISK], DatanodeInfoWithStorage[127.0.0.1:35855,DS-4eb4f79c-0f36-4be7-a723-fea7072da87d,DISK], DatanodeInfoWithStorage[127.0.0.1:40900,DS-e9283a9e-8414-452f-9c40-31474a054f65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.max-lifetime
component: hdfs:NameNode
v1: 604800000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-724231237-172.17.0.11-1597701195927:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45124,DS-8dab6717-ebda-45d6-90ba-c90caca1d685,DISK], DatanodeInfoWithStorage[127.0.0.1:33840,DS-d0c2e649-f8e7-4a47-9f06-3d848a6fdaa0,DISK], DatanodeInfoWithStorage[127.0.0.1:43959,DS-f7d70262-0511-47e5-b058-6ab5dec4cc95,DISK], DatanodeInfoWithStorage[127.0.0.1:33812,DS-2e30e5f2-f372-4d97-889b-98f0c3025db8,DISK], DatanodeInfoWithStorage[127.0.0.1:33738,DS-f8f360c5-ffd1-44ab-be6d-ceb6442cd3b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35273,DS-e570af6b-e914-440e-9429-9c0316c01651,DISK], DatanodeInfoWithStorage[127.0.0.1:42983,DS-6af2a770-5d00-4fc9-9ddf-3b4b2e9d2a30,DISK], DatanodeInfoWithStorage[127.0.0.1:46767,DS-877f9755-df32-43a4-b485-e6ef8d43f82b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-724231237-172.17.0.11-1597701195927:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45124,DS-8dab6717-ebda-45d6-90ba-c90caca1d685,DISK], DatanodeInfoWithStorage[127.0.0.1:33840,DS-d0c2e649-f8e7-4a47-9f06-3d848a6fdaa0,DISK], DatanodeInfoWithStorage[127.0.0.1:43959,DS-f7d70262-0511-47e5-b058-6ab5dec4cc95,DISK], DatanodeInfoWithStorage[127.0.0.1:33812,DS-2e30e5f2-f372-4d97-889b-98f0c3025db8,DISK], DatanodeInfoWithStorage[127.0.0.1:33738,DS-f8f360c5-ffd1-44ab-be6d-ceb6442cd3b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35273,DS-e570af6b-e914-440e-9429-9c0316c01651,DISK], DatanodeInfoWithStorage[127.0.0.1:42983,DS-6af2a770-5d00-4fc9-9ddf-3b4b2e9d2a30,DISK], DatanodeInfoWithStorage[127.0.0.1:46767,DS-877f9755-df32-43a4-b485-e6ef8d43f82b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.max-lifetime
component: hdfs:NameNode
v1: 604800000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2018785950-172.17.0.11-1597701509205:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44683,DS-3a4dbf3f-cf9c-42c1-950c-97cc29226f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:43066,DS-46eb83d5-b115-49e0-9fa9-a154d9bb21e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40642,DS-6a160754-4cca-42d3-87e2-0b767cfed1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34986,DS-f073f6b6-2f24-40d7-a9cb-90641a3420d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45001,DS-8152c90f-b9e8-4bcf-a145-abc83942ac73,DISK], DatanodeInfoWithStorage[127.0.0.1:40857,DS-5b589321-29b5-4cb9-ad99-977653192e55,DISK], DatanodeInfoWithStorage[127.0.0.1:40199,DS-58c292c2-6e87-44a6-ab96-d2e5a2491226,DISK], DatanodeInfoWithStorage[127.0.0.1:36201,DS-4e52c35f-334c-4cac-b563-e421720c18b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2018785950-172.17.0.11-1597701509205:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44683,DS-3a4dbf3f-cf9c-42c1-950c-97cc29226f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:43066,DS-46eb83d5-b115-49e0-9fa9-a154d9bb21e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40642,DS-6a160754-4cca-42d3-87e2-0b767cfed1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34986,DS-f073f6b6-2f24-40d7-a9cb-90641a3420d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45001,DS-8152c90f-b9e8-4bcf-a145-abc83942ac73,DISK], DatanodeInfoWithStorage[127.0.0.1:40857,DS-5b589321-29b5-4cb9-ad99-977653192e55,DISK], DatanodeInfoWithStorage[127.0.0.1:40199,DS-58c292c2-6e87-44a6-ab96-d2e5a2491226,DISK], DatanodeInfoWithStorage[127.0.0.1:36201,DS-4e52c35f-334c-4cac-b563-e421720c18b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.max-lifetime
component: hdfs:NameNode
v1: 604800000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1272750537-172.17.0.11-1597701623565:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41399,DS-6c4730f0-45c9-4242-a255-a6e034223f59,DISK], DatanodeInfoWithStorage[127.0.0.1:32784,DS-e2021ee7-383a-4f5a-b748-9fc2c91b2cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:36864,DS-8245446b-b25d-454f-8c79-30c219490c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:39625,DS-0765e29d-e782-4c7a-a0da-4c13458e4e00,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-f8ea172e-e178-44d2-8fad-c8614a1835dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33451,DS-6194a5da-739a-483c-86b6-4f507cdda013,DISK], DatanodeInfoWithStorage[127.0.0.1:40309,DS-cb6f8af8-4593-424f-9d0f-64dcefc3d5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41087,DS-3f3c025c-a546-4b99-94bf-06f6f09059f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1272750537-172.17.0.11-1597701623565:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41399,DS-6c4730f0-45c9-4242-a255-a6e034223f59,DISK], DatanodeInfoWithStorage[127.0.0.1:32784,DS-e2021ee7-383a-4f5a-b748-9fc2c91b2cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:36864,DS-8245446b-b25d-454f-8c79-30c219490c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:39625,DS-0765e29d-e782-4c7a-a0da-4c13458e4e00,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-f8ea172e-e178-44d2-8fad-c8614a1835dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33451,DS-6194a5da-739a-483c-86b6-4f507cdda013,DISK], DatanodeInfoWithStorage[127.0.0.1:40309,DS-cb6f8af8-4593-424f-9d0f-64dcefc3d5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41087,DS-3f3c025c-a546-4b99-94bf-06f6f09059f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.max-lifetime
component: hdfs:NameNode
v1: 604800000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1322310194-172.17.0.11-1597701731193:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38266,DS-dbc1c228-028d-405d-aec0-15217139fc7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42932,DS-7ea0c23b-2e3a-4e2d-bf80-7554282046c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35369,DS-6c88156d-a3ae-4986-853a-05b3715cf6d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40739,DS-d27038fb-fecf-4fc6-bdd8-ebc32eb21932,DISK], DatanodeInfoWithStorage[127.0.0.1:43411,DS-57af8d11-7f21-494c-8a2c-2cd9ec472093,DISK], DatanodeInfoWithStorage[127.0.0.1:39055,DS-a278ff45-db1a-4fb5-ac21-d9968d198ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:36267,DS-5a44af6a-b4e5-4e9e-8afc-be505463d6ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33749,DS-d52e7665-550b-42c0-bef0-6039955b68b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1322310194-172.17.0.11-1597701731193:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38266,DS-dbc1c228-028d-405d-aec0-15217139fc7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42932,DS-7ea0c23b-2e3a-4e2d-bf80-7554282046c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35369,DS-6c88156d-a3ae-4986-853a-05b3715cf6d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40739,DS-d27038fb-fecf-4fc6-bdd8-ebc32eb21932,DISK], DatanodeInfoWithStorage[127.0.0.1:43411,DS-57af8d11-7f21-494c-8a2c-2cd9ec472093,DISK], DatanodeInfoWithStorage[127.0.0.1:39055,DS-a278ff45-db1a-4fb5-ac21-d9968d198ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:36267,DS-5a44af6a-b4e5-4e9e-8afc-be505463d6ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33749,DS-d52e7665-550b-42c0-bef0-6039955b68b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.max-lifetime
component: hdfs:NameNode
v1: 604800000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1725058753-172.17.0.11-1597701770727:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34092,DS-8d010461-ae4f-4e8a-86b5-4b70686d6134,DISK], DatanodeInfoWithStorage[127.0.0.1:40581,DS-4fe7f423-0254-48a6-974f-bfbf630c8d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39515,DS-b7e621ce-3d03-4f66-8e19-120e124ddbb0,DISK], DatanodeInfoWithStorage[127.0.0.1:33923,DS-bf8360f8-31de-44a3-91fa-c4d04d669c64,DISK], DatanodeInfoWithStorage[127.0.0.1:37159,DS-8c1d8b99-062c-4ea6-93f4-f75918e04a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34392,DS-806ec0e4-9e37-42d7-95aa-b62926769b72,DISK], DatanodeInfoWithStorage[127.0.0.1:39333,DS-bca8c3b4-39bd-4f5e-8887-9b79d75064a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37481,DS-c288ec93-6e59-49f2-8e96-edbdb512655a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1725058753-172.17.0.11-1597701770727:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34092,DS-8d010461-ae4f-4e8a-86b5-4b70686d6134,DISK], DatanodeInfoWithStorage[127.0.0.1:40581,DS-4fe7f423-0254-48a6-974f-bfbf630c8d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39515,DS-b7e621ce-3d03-4f66-8e19-120e124ddbb0,DISK], DatanodeInfoWithStorage[127.0.0.1:33923,DS-bf8360f8-31de-44a3-91fa-c4d04d669c64,DISK], DatanodeInfoWithStorage[127.0.0.1:37159,DS-8c1d8b99-062c-4ea6-93f4-f75918e04a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34392,DS-806ec0e4-9e37-42d7-95aa-b62926769b72,DISK], DatanodeInfoWithStorage[127.0.0.1:39333,DS-bca8c3b4-39bd-4f5e-8887-9b79d75064a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37481,DS-c288ec93-6e59-49f2-8e96-edbdb512655a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.max-lifetime
component: hdfs:NameNode
v1: 604800000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-439286154-172.17.0.11-1597701973211:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44703,DS-b36e7d14-64f8-4566-920e-5fea7bda8a25,DISK], DatanodeInfoWithStorage[127.0.0.1:46507,DS-1b1491cc-4a3f-45b8-b456-fa77abfea207,DISK], DatanodeInfoWithStorage[127.0.0.1:36695,DS-1255b514-0845-41e9-b64c-82656a17db6d,DISK], DatanodeInfoWithStorage[127.0.0.1:46038,DS-4a3d7a4b-3fce-4feb-a0bb-03c1026c7070,DISK], DatanodeInfoWithStorage[127.0.0.1:41954,DS-819dd262-5d96-4ff6-858f-cd3ae951d343,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-92aab3a6-f863-412a-a919-3328fa909cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:34774,DS-24653478-2124-4124-8a11-36f8dbe2edfc,DISK], DatanodeInfoWithStorage[127.0.0.1:40090,DS-454fb609-a88b-4675-a054-4a5f7ea1ff33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-439286154-172.17.0.11-1597701973211:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44703,DS-b36e7d14-64f8-4566-920e-5fea7bda8a25,DISK], DatanodeInfoWithStorage[127.0.0.1:46507,DS-1b1491cc-4a3f-45b8-b456-fa77abfea207,DISK], DatanodeInfoWithStorage[127.0.0.1:36695,DS-1255b514-0845-41e9-b64c-82656a17db6d,DISK], DatanodeInfoWithStorage[127.0.0.1:46038,DS-4a3d7a4b-3fce-4feb-a0bb-03c1026c7070,DISK], DatanodeInfoWithStorage[127.0.0.1:41954,DS-819dd262-5d96-4ff6-858f-cd3ae951d343,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-92aab3a6-f863-412a-a919-3328fa909cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:34774,DS-24653478-2124-4124-8a11-36f8dbe2edfc,DISK], DatanodeInfoWithStorage[127.0.0.1:40090,DS-454fb609-a88b-4675-a054-4a5f7ea1ff33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.max-lifetime
component: hdfs:NameNode
v1: 604800000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1396037096-172.17.0.11-1597702270213:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44107,DS-61b38a1c-f1eb-407c-9a29-80488a752877,DISK], DatanodeInfoWithStorage[127.0.0.1:33726,DS-6673a75b-e3c3-4693-b081-0d8328007394,DISK], DatanodeInfoWithStorage[127.0.0.1:44880,DS-d9309c46-c203-49f8-9f6c-4b40935c1f86,DISK], DatanodeInfoWithStorage[127.0.0.1:34375,DS-6cfe4107-912c-4be4-bd2d-b4ffd6feae7d,DISK], DatanodeInfoWithStorage[127.0.0.1:33893,DS-b8b52888-9fb6-4b36-8a48-553a87186918,DISK], DatanodeInfoWithStorage[127.0.0.1:33033,DS-a0553006-841f-4bbe-9239-4931e45cf311,DISK], DatanodeInfoWithStorage[127.0.0.1:33557,DS-3989cbbd-f937-46e5-a515-ac45834bc685,DISK], DatanodeInfoWithStorage[127.0.0.1:37068,DS-94d679c6-d25a-4af7-a95f-fb7c079685d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1396037096-172.17.0.11-1597702270213:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44107,DS-61b38a1c-f1eb-407c-9a29-80488a752877,DISK], DatanodeInfoWithStorage[127.0.0.1:33726,DS-6673a75b-e3c3-4693-b081-0d8328007394,DISK], DatanodeInfoWithStorage[127.0.0.1:44880,DS-d9309c46-c203-49f8-9f6c-4b40935c1f86,DISK], DatanodeInfoWithStorage[127.0.0.1:34375,DS-6cfe4107-912c-4be4-bd2d-b4ffd6feae7d,DISK], DatanodeInfoWithStorage[127.0.0.1:33893,DS-b8b52888-9fb6-4b36-8a48-553a87186918,DISK], DatanodeInfoWithStorage[127.0.0.1:33033,DS-a0553006-841f-4bbe-9239-4931e45cf311,DISK], DatanodeInfoWithStorage[127.0.0.1:33557,DS-3989cbbd-f937-46e5-a515-ac45834bc685,DISK], DatanodeInfoWithStorage[127.0.0.1:37068,DS-94d679c6-d25a-4af7-a95f-fb7c079685d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.delegation.token.max-lifetime
component: hdfs:NameNode
v1: 604800000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-852167490-172.17.0.11-1597702306950:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35069,DS-e24caa1a-524d-4273-9eef-cb20d5679c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:42103,DS-1bdf7fb3-b38f-4eec-b982-70edbc752749,DISK], DatanodeInfoWithStorage[127.0.0.1:37911,DS-ae04a41b-85df-4cd6-9604-dbe654869dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:34096,DS-2b9270bd-d069-450d-bcb3-360a4db90ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:34018,DS-cc1a13a0-1b02-4da1-83ba-897d78e2b454,DISK], DatanodeInfoWithStorage[127.0.0.1:33577,DS-e5b14f10-c921-4fb8-98d2-a5e4030ff327,DISK], DatanodeInfoWithStorage[127.0.0.1:38478,DS-51d49505-f645-4e90-8e12-dd4773454e98,DISK], DatanodeInfoWithStorage[127.0.0.1:45238,DS-c262e069-d9d1-4415-b884-3c9f222b9af9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-852167490-172.17.0.11-1597702306950:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35069,DS-e24caa1a-524d-4273-9eef-cb20d5679c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:42103,DS-1bdf7fb3-b38f-4eec-b982-70edbc752749,DISK], DatanodeInfoWithStorage[127.0.0.1:37911,DS-ae04a41b-85df-4cd6-9604-dbe654869dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:34096,DS-2b9270bd-d069-450d-bcb3-360a4db90ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:34018,DS-cc1a13a0-1b02-4da1-83ba-897d78e2b454,DISK], DatanodeInfoWithStorage[127.0.0.1:33577,DS-e5b14f10-c921-4fb8-98d2-a5e4030ff327,DISK], DatanodeInfoWithStorage[127.0.0.1:38478,DS-51d49505-f645-4e90-8e12-dd4773454e98,DISK], DatanodeInfoWithStorage[127.0.0.1:45238,DS-c262e069-d9d1-4415-b884-3c9f222b9af9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.max-lifetime
component: hdfs:NameNode
v1: 604800000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-557155149-172.17.0.11-1597702418668:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43720,DS-81a0f858-7a5e-456e-a0ae-117dc7a24b99,DISK], DatanodeInfoWithStorage[127.0.0.1:32967,DS-0767512e-e4c1-4c61-a166-99d00327fc08,DISK], DatanodeInfoWithStorage[127.0.0.1:46556,DS-9b11f79b-910b-491a-bed7-ffdb65e655df,DISK], DatanodeInfoWithStorage[127.0.0.1:41053,DS-0e5d31be-b162-431b-bffc-2a5669800047,DISK], DatanodeInfoWithStorage[127.0.0.1:34432,DS-6b304ac5-c8fb-4bdf-b988-0231126b7bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:38552,DS-8486fcde-6eeb-4526-8aca-07da04572a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:34035,DS-f714a897-fbf2-47dd-9e35-3e950a387336,DISK], DatanodeInfoWithStorage[127.0.0.1:40715,DS-820bfb27-3275-4d14-a8af-0e4853cf37bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-557155149-172.17.0.11-1597702418668:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43720,DS-81a0f858-7a5e-456e-a0ae-117dc7a24b99,DISK], DatanodeInfoWithStorage[127.0.0.1:32967,DS-0767512e-e4c1-4c61-a166-99d00327fc08,DISK], DatanodeInfoWithStorage[127.0.0.1:46556,DS-9b11f79b-910b-491a-bed7-ffdb65e655df,DISK], DatanodeInfoWithStorage[127.0.0.1:41053,DS-0e5d31be-b162-431b-bffc-2a5669800047,DISK], DatanodeInfoWithStorage[127.0.0.1:34432,DS-6b304ac5-c8fb-4bdf-b988-0231126b7bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:38552,DS-8486fcde-6eeb-4526-8aca-07da04572a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:34035,DS-f714a897-fbf2-47dd-9e35-3e950a387336,DISK], DatanodeInfoWithStorage[127.0.0.1:40715,DS-820bfb27-3275-4d14-a8af-0e4853cf37bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.max-lifetime
component: hdfs:NameNode
v1: 604800000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-244976579-172.17.0.11-1597702583044:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46105,DS-a4b84e34-024c-4266-8510-0f57028e09d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36751,DS-f56a515c-c2d5-429c-a061-56a18274439a,DISK], DatanodeInfoWithStorage[127.0.0.1:38828,DS-aabd5696-8a40-47d4-a6e3-7aff53aca709,DISK], DatanodeInfoWithStorage[127.0.0.1:43467,DS-b50fe6da-1fda-4683-9114-ea3d2a94a21e,DISK], DatanodeInfoWithStorage[127.0.0.1:38402,DS-e32d9490-6b85-4633-9132-256954216e31,DISK], DatanodeInfoWithStorage[127.0.0.1:40069,DS-fe9d270d-bc29-46fd-8e86-695f8991fbf8,DISK], DatanodeInfoWithStorage[127.0.0.1:39131,DS-4b573ab4-4277-4020-9170-aef6250e1283,DISK], DatanodeInfoWithStorage[127.0.0.1:36105,DS-6b08510b-84a0-4fb3-bf3f-6e50485d9a88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-244976579-172.17.0.11-1597702583044:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46105,DS-a4b84e34-024c-4266-8510-0f57028e09d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36751,DS-f56a515c-c2d5-429c-a061-56a18274439a,DISK], DatanodeInfoWithStorage[127.0.0.1:38828,DS-aabd5696-8a40-47d4-a6e3-7aff53aca709,DISK], DatanodeInfoWithStorage[127.0.0.1:43467,DS-b50fe6da-1fda-4683-9114-ea3d2a94a21e,DISK], DatanodeInfoWithStorage[127.0.0.1:38402,DS-e32d9490-6b85-4633-9132-256954216e31,DISK], DatanodeInfoWithStorage[127.0.0.1:40069,DS-fe9d270d-bc29-46fd-8e86-695f8991fbf8,DISK], DatanodeInfoWithStorage[127.0.0.1:39131,DS-4b573ab4-4277-4020-9170-aef6250e1283,DISK], DatanodeInfoWithStorage[127.0.0.1:36105,DS-6b08510b-84a0-4fb3-bf3f-6e50485d9a88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.delegation.token.max-lifetime
component: hdfs:NameNode
v1: 604800000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-978487329-172.17.0.11-1597702620481:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39553,DS-5ce3eb12-a704-40ff-88c2-01dec8394596,DISK], DatanodeInfoWithStorage[127.0.0.1:38220,DS-4786b42e-a3b8-42ff-b9f0-58922a65c11e,DISK], DatanodeInfoWithStorage[127.0.0.1:42659,DS-7eb040b9-4274-4fa3-b634-35d2a3583ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:36468,DS-522d84c4-43bc-43e6-81c7-405ba452aa06,DISK], DatanodeInfoWithStorage[127.0.0.1:43920,DS-364387d5-fbd3-4f7e-86bd-d2335be50a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:35337,DS-99e1792e-2bd2-4c10-b344-f2dcca874670,DISK], DatanodeInfoWithStorage[127.0.0.1:46636,DS-4b005f71-d309-434f-9dcf-647b1f76b439,DISK], DatanodeInfoWithStorage[127.0.0.1:44789,DS-7d6df9e0-bedc-4df6-a533-23f299793b75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-978487329-172.17.0.11-1597702620481:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39553,DS-5ce3eb12-a704-40ff-88c2-01dec8394596,DISK], DatanodeInfoWithStorage[127.0.0.1:38220,DS-4786b42e-a3b8-42ff-b9f0-58922a65c11e,DISK], DatanodeInfoWithStorage[127.0.0.1:42659,DS-7eb040b9-4274-4fa3-b634-35d2a3583ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:36468,DS-522d84c4-43bc-43e6-81c7-405ba452aa06,DISK], DatanodeInfoWithStorage[127.0.0.1:43920,DS-364387d5-fbd3-4f7e-86bd-d2335be50a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:35337,DS-99e1792e-2bd2-4c10-b344-f2dcca874670,DISK], DatanodeInfoWithStorage[127.0.0.1:46636,DS-4b005f71-d309-434f-9dcf-647b1f76b439,DISK], DatanodeInfoWithStorage[127.0.0.1:44789,DS-7d6df9e0-bedc-4df6-a533-23f299793b75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.max-lifetime
component: hdfs:NameNode
v1: 604800000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-905197717-172.17.0.11-1597702935320:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44730,DS-1846eb63-d5cd-44e1-ab6e-a50eaf6e7003,DISK], DatanodeInfoWithStorage[127.0.0.1:40331,DS-ac605d93-7cb6-425d-a59c-c5945fbb8354,DISK], DatanodeInfoWithStorage[127.0.0.1:36411,DS-62e8de13-44e7-4452-a0b0-450601789771,DISK], DatanodeInfoWithStorage[127.0.0.1:32956,DS-ab2584ec-aa03-4d44-9fae-723c15ffbc0f,DISK], DatanodeInfoWithStorage[127.0.0.1:40626,DS-2170ffaf-9933-4dac-9dc8-a0381a7e1951,DISK], DatanodeInfoWithStorage[127.0.0.1:37445,DS-4b6a7bf7-3d61-4e36-94ce-e9dad968e60d,DISK], DatanodeInfoWithStorage[127.0.0.1:33017,DS-32694c7a-95a1-4530-8ac2-f4e76be85ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:42036,DS-4a0f8120-77c7-4626-b21b-7d23bff118e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-905197717-172.17.0.11-1597702935320:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44730,DS-1846eb63-d5cd-44e1-ab6e-a50eaf6e7003,DISK], DatanodeInfoWithStorage[127.0.0.1:40331,DS-ac605d93-7cb6-425d-a59c-c5945fbb8354,DISK], DatanodeInfoWithStorage[127.0.0.1:36411,DS-62e8de13-44e7-4452-a0b0-450601789771,DISK], DatanodeInfoWithStorage[127.0.0.1:32956,DS-ab2584ec-aa03-4d44-9fae-723c15ffbc0f,DISK], DatanodeInfoWithStorage[127.0.0.1:40626,DS-2170ffaf-9933-4dac-9dc8-a0381a7e1951,DISK], DatanodeInfoWithStorage[127.0.0.1:37445,DS-4b6a7bf7-3d61-4e36-94ce-e9dad968e60d,DISK], DatanodeInfoWithStorage[127.0.0.1:33017,DS-32694c7a-95a1-4530-8ac2-f4e76be85ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:42036,DS-4a0f8120-77c7-4626-b21b-7d23bff118e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.max-lifetime
component: hdfs:NameNode
v1: 604800000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-742876856-172.17.0.11-1597703000151:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43435,DS-65ce6c6f-4f36-4cf7-b03c-d6d4cd787235,DISK], DatanodeInfoWithStorage[127.0.0.1:36683,DS-b8be6668-cfe8-45d1-896f-c158d75bd728,DISK], DatanodeInfoWithStorage[127.0.0.1:35468,DS-4434a010-98db-4a38-8ff2-982261323c90,DISK], DatanodeInfoWithStorage[127.0.0.1:41600,DS-07cb8779-3edd-41ca-be67-a55580dbab71,DISK], DatanodeInfoWithStorage[127.0.0.1:39318,DS-41896bd9-d181-4900-a9b0-1b26b1437b04,DISK], DatanodeInfoWithStorage[127.0.0.1:36027,DS-c78e2a55-cd31-4493-be14-b5f151e517f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42293,DS-f4065f15-b79f-4f8d-905d-ef4707ecb7dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37289,DS-d6843d33-f69d-4234-be5c-b451ab7f6454,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-742876856-172.17.0.11-1597703000151:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43435,DS-65ce6c6f-4f36-4cf7-b03c-d6d4cd787235,DISK], DatanodeInfoWithStorage[127.0.0.1:36683,DS-b8be6668-cfe8-45d1-896f-c158d75bd728,DISK], DatanodeInfoWithStorage[127.0.0.1:35468,DS-4434a010-98db-4a38-8ff2-982261323c90,DISK], DatanodeInfoWithStorage[127.0.0.1:41600,DS-07cb8779-3edd-41ca-be67-a55580dbab71,DISK], DatanodeInfoWithStorage[127.0.0.1:39318,DS-41896bd9-d181-4900-a9b0-1b26b1437b04,DISK], DatanodeInfoWithStorage[127.0.0.1:36027,DS-c78e2a55-cd31-4493-be14-b5f151e517f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42293,DS-f4065f15-b79f-4f8d-905d-ef4707ecb7dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37289,DS-d6843d33-f69d-4234-be5c-b451ab7f6454,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.max-lifetime
component: hdfs:NameNode
v1: 604800000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2049967925-172.17.0.11-1597703204491:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44477,DS-a256c91b-68d6-4654-8da1-0fd0c72dcbe6,DISK], DatanodeInfoWithStorage[127.0.0.1:43776,DS-f16b17d5-c693-4254-a9dc-878b2f63b21c,DISK], DatanodeInfoWithStorage[127.0.0.1:33126,DS-823c64d9-a2c0-43b5-a2ba-e81950ed2af8,DISK], DatanodeInfoWithStorage[127.0.0.1:37861,DS-47dc8a2a-047b-47ae-8cd3-dac5a71a2e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39388,DS-e279ba4d-d0e2-4798-98f2-f4122a596a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:34947,DS-8db88c93-5eac-4731-944d-78f4cc95249d,DISK], DatanodeInfoWithStorage[127.0.0.1:45114,DS-989ab517-ef18-42ca-83e2-df732de785f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33722,DS-d38acf94-f0f3-4bab-9629-375e258a8506,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2049967925-172.17.0.11-1597703204491:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44477,DS-a256c91b-68d6-4654-8da1-0fd0c72dcbe6,DISK], DatanodeInfoWithStorage[127.0.0.1:43776,DS-f16b17d5-c693-4254-a9dc-878b2f63b21c,DISK], DatanodeInfoWithStorage[127.0.0.1:33126,DS-823c64d9-a2c0-43b5-a2ba-e81950ed2af8,DISK], DatanodeInfoWithStorage[127.0.0.1:37861,DS-47dc8a2a-047b-47ae-8cd3-dac5a71a2e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39388,DS-e279ba4d-d0e2-4798-98f2-f4122a596a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:34947,DS-8db88c93-5eac-4731-944d-78f4cc95249d,DISK], DatanodeInfoWithStorage[127.0.0.1:45114,DS-989ab517-ef18-42ca-83e2-df732de785f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33722,DS-d38acf94-f0f3-4bab-9629-375e258a8506,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.max-lifetime
component: hdfs:NameNode
v1: 604800000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-783668546-172.17.0.11-1597703841199:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41414,DS-6fb6af0e-7c48-4d80-8258-8753aefa67c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38557,DS-7c03f1a2-f111-49ad-8ada-24d5c07f2124,DISK], DatanodeInfoWithStorage[127.0.0.1:46398,DS-eeaaeaee-7871-4a9d-8789-4490c66b7dea,DISK], DatanodeInfoWithStorage[127.0.0.1:46682,DS-73bea279-0e71-4651-89f7-7670fd0b46f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44454,DS-e4937db5-9918-441e-b04f-75f24edf243f,DISK], DatanodeInfoWithStorage[127.0.0.1:40348,DS-e2378649-5ffe-4551-bf66-f252d4938447,DISK], DatanodeInfoWithStorage[127.0.0.1:44132,DS-c953d324-01fc-4755-9e69-14169465b4eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43853,DS-57c78551-bb96-46b3-8a3a-81bb36c64d98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-783668546-172.17.0.11-1597703841199:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41414,DS-6fb6af0e-7c48-4d80-8258-8753aefa67c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38557,DS-7c03f1a2-f111-49ad-8ada-24d5c07f2124,DISK], DatanodeInfoWithStorage[127.0.0.1:46398,DS-eeaaeaee-7871-4a9d-8789-4490c66b7dea,DISK], DatanodeInfoWithStorage[127.0.0.1:46682,DS-73bea279-0e71-4651-89f7-7670fd0b46f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44454,DS-e4937db5-9918-441e-b04f-75f24edf243f,DISK], DatanodeInfoWithStorage[127.0.0.1:40348,DS-e2378649-5ffe-4551-bf66-f252d4938447,DISK], DatanodeInfoWithStorage[127.0.0.1:44132,DS-c953d324-01fc-4755-9e69-14169465b4eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43853,DS-57c78551-bb96-46b3-8a3a-81bb36c64d98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.max-lifetime
component: hdfs:NameNode
v1: 604800000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-12587809-172.17.0.11-1597704354138:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38221,DS-5c628425-70cb-4a84-bbbe-ced6893e97ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42115,DS-7a66e660-58a9-44be-947c-c5d6fdbfd13f,DISK], DatanodeInfoWithStorage[127.0.0.1:36815,DS-863a36ba-435f-4509-b179-aac8f9f8cd5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36613,DS-3b311f46-f23f-4f27-a897-484f74353dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:34648,DS-0046fc30-b813-4340-aa76-f6784bf2a46c,DISK], DatanodeInfoWithStorage[127.0.0.1:34953,DS-6d2201ef-d734-4b93-be2e-b8c2901ddbed,DISK], DatanodeInfoWithStorage[127.0.0.1:45982,DS-7fbd1098-1c7a-4624-bd81-79535ee773f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39398,DS-198bba18-099d-4eaa-a9ed-b85c9af3f7af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-12587809-172.17.0.11-1597704354138:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38221,DS-5c628425-70cb-4a84-bbbe-ced6893e97ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42115,DS-7a66e660-58a9-44be-947c-c5d6fdbfd13f,DISK], DatanodeInfoWithStorage[127.0.0.1:36815,DS-863a36ba-435f-4509-b179-aac8f9f8cd5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36613,DS-3b311f46-f23f-4f27-a897-484f74353dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:34648,DS-0046fc30-b813-4340-aa76-f6784bf2a46c,DISK], DatanodeInfoWithStorage[127.0.0.1:34953,DS-6d2201ef-d734-4b93-be2e-b8c2901ddbed,DISK], DatanodeInfoWithStorage[127.0.0.1:45982,DS-7fbd1098-1c7a-4624-bd81-79535ee773f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39398,DS-198bba18-099d-4eaa-a9ed-b85c9af3f7af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.max-lifetime
component: hdfs:NameNode
v1: 604800000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1732234896-172.17.0.11-1597704482385:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33049,DS-b209eb1c-ee53-4fe5-a508-b72135e4f849,DISK], DatanodeInfoWithStorage[127.0.0.1:38384,DS-74e672a1-dce9-47d6-a6c9-a34135338056,DISK], DatanodeInfoWithStorage[127.0.0.1:39858,DS-b4518be6-5b17-401e-b7dd-47263fc0b5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33742,DS-96a4e4a6-00e0-4770-88ca-81dab78b83ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36394,DS-531a6e58-56ea-4b9c-95d4-0bd8fd832746,DISK], DatanodeInfoWithStorage[127.0.0.1:34995,DS-1de4156f-1e04-4bbe-8995-ed6c48d27435,DISK], DatanodeInfoWithStorage[127.0.0.1:39671,DS-a1fac65a-28ec-47ea-9e70-3e4ed04aa5c8,DISK], DatanodeInfoWithStorage[127.0.0.1:32788,DS-b92d6991-2c86-4e61-98f9-91b95c8b6269,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1732234896-172.17.0.11-1597704482385:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33049,DS-b209eb1c-ee53-4fe5-a508-b72135e4f849,DISK], DatanodeInfoWithStorage[127.0.0.1:38384,DS-74e672a1-dce9-47d6-a6c9-a34135338056,DISK], DatanodeInfoWithStorage[127.0.0.1:39858,DS-b4518be6-5b17-401e-b7dd-47263fc0b5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33742,DS-96a4e4a6-00e0-4770-88ca-81dab78b83ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36394,DS-531a6e58-56ea-4b9c-95d4-0bd8fd832746,DISK], DatanodeInfoWithStorage[127.0.0.1:34995,DS-1de4156f-1e04-4bbe-8995-ed6c48d27435,DISK], DatanodeInfoWithStorage[127.0.0.1:39671,DS-a1fac65a-28ec-47ea-9e70-3e4ed04aa5c8,DISK], DatanodeInfoWithStorage[127.0.0.1:32788,DS-b92d6991-2c86-4e61-98f9-91b95c8b6269,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.max-lifetime
component: hdfs:NameNode
v1: 604800000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-798922138-172.17.0.11-1597704636987:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42223,DS-64cc7491-2185-4e45-bf77-ef8abd49a3c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39007,DS-fca38b1b-8dd7-4946-8114-ac61217c5b48,DISK], DatanodeInfoWithStorage[127.0.0.1:44474,DS-c90ccd0d-1cf4-4d19-ad61-165f13ceccec,DISK], DatanodeInfoWithStorage[127.0.0.1:37604,DS-407a255e-039f-43e1-a406-767fd94f7264,DISK], DatanodeInfoWithStorage[127.0.0.1:33871,DS-f645ae22-3fac-41d6-b911-0dce2c19e243,DISK], DatanodeInfoWithStorage[127.0.0.1:46869,DS-823841ec-7b80-41bc-b24f-e807cb2bec0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38963,DS-ac64aa16-77ce-4f43-946a-500393cda524,DISK], DatanodeInfoWithStorage[127.0.0.1:36705,DS-cb7d92ad-994b-4ab3-8299-47f7cfe3a2d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-798922138-172.17.0.11-1597704636987:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42223,DS-64cc7491-2185-4e45-bf77-ef8abd49a3c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39007,DS-fca38b1b-8dd7-4946-8114-ac61217c5b48,DISK], DatanodeInfoWithStorage[127.0.0.1:44474,DS-c90ccd0d-1cf4-4d19-ad61-165f13ceccec,DISK], DatanodeInfoWithStorage[127.0.0.1:37604,DS-407a255e-039f-43e1-a406-767fd94f7264,DISK], DatanodeInfoWithStorage[127.0.0.1:33871,DS-f645ae22-3fac-41d6-b911-0dce2c19e243,DISK], DatanodeInfoWithStorage[127.0.0.1:46869,DS-823841ec-7b80-41bc-b24f-e807cb2bec0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38963,DS-ac64aa16-77ce-4f43-946a-500393cda524,DISK], DatanodeInfoWithStorage[127.0.0.1:36705,DS-cb7d92ad-994b-4ab3-8299-47f7cfe3a2d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.max-lifetime
component: hdfs:NameNode
v1: 604800000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1066967579-172.17.0.11-1597704824271:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36392,DS-52063621-98fe-4652-8467-645799b1d01e,DISK], DatanodeInfoWithStorage[127.0.0.1:38322,DS-d6cbcfea-7654-42bf-9d03-72d88bfd72f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44335,DS-f9d2fc83-2971-4c71-97bc-4f01b4d5801c,DISK], DatanodeInfoWithStorage[127.0.0.1:40390,DS-d0640fd1-c79c-4ba4-9c4b-59fb4ef22883,DISK], DatanodeInfoWithStorage[127.0.0.1:42027,DS-2541096c-738f-4520-9c77-0a8325a301f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33225,DS-99936fa1-94a4-4362-9f57-4f8182199503,DISK], DatanodeInfoWithStorage[127.0.0.1:45395,DS-8c36ca6b-b558-4fbc-ba81-b29f10fdbfd9,DISK], DatanodeInfoWithStorage[127.0.0.1:36848,DS-5cc276ca-8dbb-4b41-91a9-b1b02e4d0c3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1066967579-172.17.0.11-1597704824271:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36392,DS-52063621-98fe-4652-8467-645799b1d01e,DISK], DatanodeInfoWithStorage[127.0.0.1:38322,DS-d6cbcfea-7654-42bf-9d03-72d88bfd72f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44335,DS-f9d2fc83-2971-4c71-97bc-4f01b4d5801c,DISK], DatanodeInfoWithStorage[127.0.0.1:40390,DS-d0640fd1-c79c-4ba4-9c4b-59fb4ef22883,DISK], DatanodeInfoWithStorage[127.0.0.1:42027,DS-2541096c-738f-4520-9c77-0a8325a301f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33225,DS-99936fa1-94a4-4362-9f57-4f8182199503,DISK], DatanodeInfoWithStorage[127.0.0.1:45395,DS-8c36ca6b-b558-4fbc-ba81-b29f10fdbfd9,DISK], DatanodeInfoWithStorage[127.0.0.1:36848,DS-5cc276ca-8dbb-4b41-91a9-b1b02e4d0c3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.max-lifetime
component: hdfs:NameNode
v1: 604800000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1446689912-172.17.0.11-1597704858503:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38692,DS-aa90eddd-db98-4cd1-8a6a-c4f16f70c1aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40759,DS-c7279a36-b9ad-457a-abd6-5e890c192231,DISK], DatanodeInfoWithStorage[127.0.0.1:34579,DS-59bde551-c3bb-4305-8ca0-9d11f7564480,DISK], DatanodeInfoWithStorage[127.0.0.1:44472,DS-ec77bf00-08ce-4fb7-9551-60f05d07e447,DISK], DatanodeInfoWithStorage[127.0.0.1:33522,DS-3678d8a3-c6a5-4aef-9111-07efb17cb511,DISK], DatanodeInfoWithStorage[127.0.0.1:45398,DS-3654e2ad-2737-42e3-a670-53ac2799fbd9,DISK], DatanodeInfoWithStorage[127.0.0.1:42994,DS-f6f99555-3b69-4c37-af5c-84e72f045de0,DISK], DatanodeInfoWithStorage[127.0.0.1:35231,DS-99ccbe28-f2be-4060-9eaf-e846f8ee6c6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1446689912-172.17.0.11-1597704858503:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38692,DS-aa90eddd-db98-4cd1-8a6a-c4f16f70c1aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40759,DS-c7279a36-b9ad-457a-abd6-5e890c192231,DISK], DatanodeInfoWithStorage[127.0.0.1:34579,DS-59bde551-c3bb-4305-8ca0-9d11f7564480,DISK], DatanodeInfoWithStorage[127.0.0.1:44472,DS-ec77bf00-08ce-4fb7-9551-60f05d07e447,DISK], DatanodeInfoWithStorage[127.0.0.1:33522,DS-3678d8a3-c6a5-4aef-9111-07efb17cb511,DISK], DatanodeInfoWithStorage[127.0.0.1:45398,DS-3654e2ad-2737-42e3-a670-53ac2799fbd9,DISK], DatanodeInfoWithStorage[127.0.0.1:42994,DS-f6f99555-3b69-4c37-af5c-84e72f045de0,DISK], DatanodeInfoWithStorage[127.0.0.1:35231,DS-99ccbe28-f2be-4060-9eaf-e846f8ee6c6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.max-lifetime
component: hdfs:NameNode
v1: 604800000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1704462206-172.17.0.11-1597705627098:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45283,DS-f1f06dc9-7159-4d28-800e-5c0be399f97d,DISK], DatanodeInfoWithStorage[127.0.0.1:42339,DS-9ca7a40d-b3bd-4117-828a-8881b7703fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:33613,DS-3b4186a5-d203-48f2-91dc-23438b6f5201,DISK], DatanodeInfoWithStorage[127.0.0.1:38802,DS-dc27f3d3-2f8a-432b-8d3c-930572915e97,DISK], DatanodeInfoWithStorage[127.0.0.1:42424,DS-a8ca6f9e-8cbd-4ab7-bb8e-004634156cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:42512,DS-364d2948-9577-412c-8e60-9698cec8e429,DISK], DatanodeInfoWithStorage[127.0.0.1:45456,DS-2a746333-0730-4510-ab4c-8b227f1a4aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:44738,DS-a6f05a6e-8720-4776-8e75-c91854bfda3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1704462206-172.17.0.11-1597705627098:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45283,DS-f1f06dc9-7159-4d28-800e-5c0be399f97d,DISK], DatanodeInfoWithStorage[127.0.0.1:42339,DS-9ca7a40d-b3bd-4117-828a-8881b7703fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:33613,DS-3b4186a5-d203-48f2-91dc-23438b6f5201,DISK], DatanodeInfoWithStorage[127.0.0.1:38802,DS-dc27f3d3-2f8a-432b-8d3c-930572915e97,DISK], DatanodeInfoWithStorage[127.0.0.1:42424,DS-a8ca6f9e-8cbd-4ab7-bb8e-004634156cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:42512,DS-364d2948-9577-412c-8e60-9698cec8e429,DISK], DatanodeInfoWithStorage[127.0.0.1:45456,DS-2a746333-0730-4510-ab4c-8b227f1a4aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:44738,DS-a6f05a6e-8720-4776-8e75-c91854bfda3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.max-lifetime
component: hdfs:NameNode
v1: 604800000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-994379109-172.17.0.11-1597705854178:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41636,DS-e14e094a-63c5-4386-b206-f61a36d406b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35176,DS-5beca960-45ef-48f8-af6f-058f431f4935,DISK], DatanodeInfoWithStorage[127.0.0.1:32830,DS-9a1d74fe-1860-46a2-9c6f-aca1cb61b6ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36491,DS-8dff0639-382f-44d2-b4cd-d0e6bea5ff39,DISK], DatanodeInfoWithStorage[127.0.0.1:40732,DS-2b323408-d2af-426f-80e9-579000126d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45974,DS-6a74dd0c-d779-4893-a404-38b4706022f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41699,DS-a88d1d7d-fcd3-4eb5-b185-c2433fc354f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42945,DS-c7deda66-c3ec-4447-ae54-50d6b7a405f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-994379109-172.17.0.11-1597705854178:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41636,DS-e14e094a-63c5-4386-b206-f61a36d406b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35176,DS-5beca960-45ef-48f8-af6f-058f431f4935,DISK], DatanodeInfoWithStorage[127.0.0.1:32830,DS-9a1d74fe-1860-46a2-9c6f-aca1cb61b6ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36491,DS-8dff0639-382f-44d2-b4cd-d0e6bea5ff39,DISK], DatanodeInfoWithStorage[127.0.0.1:40732,DS-2b323408-d2af-426f-80e9-579000126d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45974,DS-6a74dd0c-d779-4893-a404-38b4706022f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41699,DS-a88d1d7d-fcd3-4eb5-b185-c2433fc354f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42945,DS-c7deda66-c3ec-4447-ae54-50d6b7a405f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.max-lifetime
component: hdfs:NameNode
v1: 604800000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-401475816-172.17.0.11-1597706084669:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43719,DS-72e74d81-0023-40ae-a355-577a06b241db,DISK], DatanodeInfoWithStorage[127.0.0.1:43541,DS-3e8f6d33-2ac1-4984-adcc-60d627aececf,DISK], DatanodeInfoWithStorage[127.0.0.1:42541,DS-fe92bc9d-a5d0-4f57-b8e6-5bcaa03e77c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41393,DS-c94e2095-67d2-4bfc-9399-6312771207d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38055,DS-b8aa85e2-4933-443d-998e-9f394439d409,DISK], DatanodeInfoWithStorage[127.0.0.1:35556,DS-f9f77925-89c5-4b0f-b82a-10b67bb30acd,DISK], DatanodeInfoWithStorage[127.0.0.1:45372,DS-e4f23b01-faf1-442c-9cf1-5705f00b4d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33131,DS-70769635-21c5-43b4-b8f9-db9d3d5c0598,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-401475816-172.17.0.11-1597706084669:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43719,DS-72e74d81-0023-40ae-a355-577a06b241db,DISK], DatanodeInfoWithStorage[127.0.0.1:43541,DS-3e8f6d33-2ac1-4984-adcc-60d627aececf,DISK], DatanodeInfoWithStorage[127.0.0.1:42541,DS-fe92bc9d-a5d0-4f57-b8e6-5bcaa03e77c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41393,DS-c94e2095-67d2-4bfc-9399-6312771207d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38055,DS-b8aa85e2-4933-443d-998e-9f394439d409,DISK], DatanodeInfoWithStorage[127.0.0.1:35556,DS-f9f77925-89c5-4b0f-b82a-10b67bb30acd,DISK], DatanodeInfoWithStorage[127.0.0.1:45372,DS-e4f23b01-faf1-442c-9cf1-5705f00b4d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33131,DS-70769635-21c5-43b4-b8f9-db9d3d5c0598,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5583
