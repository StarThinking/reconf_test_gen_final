reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1801432023-172.17.0.5-1597343703733:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42824,DS-155dabb4-5173-491a-b643-a8e6fccfbb53,DISK], DatanodeInfoWithStorage[127.0.0.1:35530,DS-9afbf1aa-6745-451a-b572-555eae558599,DISK], DatanodeInfoWithStorage[127.0.0.1:40255,DS-7acb9c9d-041a-4087-8fd7-26620ec88ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:46061,DS-45e85b86-b596-4edf-b3ef-375305164dff,DISK], DatanodeInfoWithStorage[127.0.0.1:38904,DS-600850b3-2432-4822-b38f-191b9ccec96d,DISK], DatanodeInfoWithStorage[127.0.0.1:44822,DS-ff53950d-ffdb-4408-b748-897ed461fa4b,DISK], DatanodeInfoWithStorage[127.0.0.1:40315,DS-13271fd7-4a76-4861-a6fe-a28f3d2ba7d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-e0439b6c-d89b-444c-b7e0-0f8d31c7ca15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1801432023-172.17.0.5-1597343703733:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42824,DS-155dabb4-5173-491a-b643-a8e6fccfbb53,DISK], DatanodeInfoWithStorage[127.0.0.1:35530,DS-9afbf1aa-6745-451a-b572-555eae558599,DISK], DatanodeInfoWithStorage[127.0.0.1:40255,DS-7acb9c9d-041a-4087-8fd7-26620ec88ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:46061,DS-45e85b86-b596-4edf-b3ef-375305164dff,DISK], DatanodeInfoWithStorage[127.0.0.1:38904,DS-600850b3-2432-4822-b38f-191b9ccec96d,DISK], DatanodeInfoWithStorage[127.0.0.1:44822,DS-ff53950d-ffdb-4408-b748-897ed461fa4b,DISK], DatanodeInfoWithStorage[127.0.0.1:40315,DS-13271fd7-4a76-4861-a6fe-a28f3d2ba7d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-e0439b6c-d89b-444c-b7e0-0f8d31c7ca15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-362205156-172.17.0.5-1597343859492:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37673,DS-c006450b-ece9-4080-a651-f9e63fffad24,DISK], DatanodeInfoWithStorage[127.0.0.1:40300,DS-c2dfe0be-6fb6-4f62-a24a-fccda92da331,DISK], DatanodeInfoWithStorage[127.0.0.1:46630,DS-807fc9b3-d920-4d98-90e7-7c243ba83ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:44957,DS-d9163853-7d73-4453-8346-8037ff6863c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39744,DS-c57b4742-abdf-4383-bc59-4ac9fc223ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:38263,DS-763a10c4-61bb-4991-800c-721127febf1a,DISK], DatanodeInfoWithStorage[127.0.0.1:37488,DS-497ae280-50f9-43e6-8d3c-acf1f803bedd,DISK], DatanodeInfoWithStorage[127.0.0.1:41036,DS-b8ce670b-63ac-4747-a1dd-fa92f7257b05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-362205156-172.17.0.5-1597343859492:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37673,DS-c006450b-ece9-4080-a651-f9e63fffad24,DISK], DatanodeInfoWithStorage[127.0.0.1:40300,DS-c2dfe0be-6fb6-4f62-a24a-fccda92da331,DISK], DatanodeInfoWithStorage[127.0.0.1:46630,DS-807fc9b3-d920-4d98-90e7-7c243ba83ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:44957,DS-d9163853-7d73-4453-8346-8037ff6863c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39744,DS-c57b4742-abdf-4383-bc59-4ac9fc223ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:38263,DS-763a10c4-61bb-4991-800c-721127febf1a,DISK], DatanodeInfoWithStorage[127.0.0.1:37488,DS-497ae280-50f9-43e6-8d3c-acf1f803bedd,DISK], DatanodeInfoWithStorage[127.0.0.1:41036,DS-b8ce670b-63ac-4747-a1dd-fa92f7257b05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-672975548-172.17.0.5-1597344276779:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37165,DS-296fcccf-699d-447c-b9c0-4318f3f1c3b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35728,DS-cbe9ec1d-290b-45a9-bcb1-a137a7737bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:36936,DS-735b1ef0-46ce-4f13-b389-05ec275261e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42145,DS-b93717fc-cd79-4fca-b9ea-615ad054cbb0,DISK], DatanodeInfoWithStorage[127.0.0.1:35746,DS-d1bf7ab5-a864-402a-9909-369c789ea4bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44092,DS-e8a3b597-87e7-4f1d-933e-f756ab8f1f85,DISK], DatanodeInfoWithStorage[127.0.0.1:45569,DS-41009e5b-6e26-46fe-aabd-305e048592dc,DISK], DatanodeInfoWithStorage[127.0.0.1:32897,DS-6e55c43c-4399-48d3-9cc3-b9cddf69f355,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-672975548-172.17.0.5-1597344276779:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37165,DS-296fcccf-699d-447c-b9c0-4318f3f1c3b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35728,DS-cbe9ec1d-290b-45a9-bcb1-a137a7737bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:36936,DS-735b1ef0-46ce-4f13-b389-05ec275261e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42145,DS-b93717fc-cd79-4fca-b9ea-615ad054cbb0,DISK], DatanodeInfoWithStorage[127.0.0.1:35746,DS-d1bf7ab5-a864-402a-9909-369c789ea4bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44092,DS-e8a3b597-87e7-4f1d-933e-f756ab8f1f85,DISK], DatanodeInfoWithStorage[127.0.0.1:45569,DS-41009e5b-6e26-46fe-aabd-305e048592dc,DISK], DatanodeInfoWithStorage[127.0.0.1:32897,DS-6e55c43c-4399-48d3-9cc3-b9cddf69f355,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-356401584-172.17.0.5-1597344320488:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46020,DS-52de4ffd-5eaa-4eb5-acd3-a751a929101d,DISK], DatanodeInfoWithStorage[127.0.0.1:44582,DS-4832d4bb-f56f-42e0-ac22-fb09d6434f52,DISK], DatanodeInfoWithStorage[127.0.0.1:41377,DS-59f19355-5577-4fdb-8d80-6d3aa5ace4f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40601,DS-d4fa20e8-62ac-4170-92af-e61427c7dd39,DISK], DatanodeInfoWithStorage[127.0.0.1:39007,DS-4fd233c2-d763-496f-a896-f8ec61b09a96,DISK], DatanodeInfoWithStorage[127.0.0.1:45165,DS-b9a64135-735b-4a2f-9e7f-82461c01b9d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33490,DS-464ecd89-4c64-4508-a4d7-a7d0f8c62a89,DISK], DatanodeInfoWithStorage[127.0.0.1:40686,DS-2a5e6ef0-7925-4bfa-b63a-3dc7dd4b42ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-356401584-172.17.0.5-1597344320488:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46020,DS-52de4ffd-5eaa-4eb5-acd3-a751a929101d,DISK], DatanodeInfoWithStorage[127.0.0.1:44582,DS-4832d4bb-f56f-42e0-ac22-fb09d6434f52,DISK], DatanodeInfoWithStorage[127.0.0.1:41377,DS-59f19355-5577-4fdb-8d80-6d3aa5ace4f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40601,DS-d4fa20e8-62ac-4170-92af-e61427c7dd39,DISK], DatanodeInfoWithStorage[127.0.0.1:39007,DS-4fd233c2-d763-496f-a896-f8ec61b09a96,DISK], DatanodeInfoWithStorage[127.0.0.1:45165,DS-b9a64135-735b-4a2f-9e7f-82461c01b9d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33490,DS-464ecd89-4c64-4508-a4d7-a7d0f8c62a89,DISK], DatanodeInfoWithStorage[127.0.0.1:40686,DS-2a5e6ef0-7925-4bfa-b63a-3dc7dd4b42ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-622441356-172.17.0.5-1597345118016:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39967,DS-c769c46f-c56a-4932-984c-ec3fbfb403bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42609,DS-ba46af6e-05a4-4a84-a8e3-53f913fedd3c,DISK], DatanodeInfoWithStorage[127.0.0.1:37698,DS-aed6cafa-ddfc-4d58-8927-36c368e1c8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36310,DS-d1e51de1-9d0d-4ca6-821d-12aa4a2670d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43477,DS-cb2e52fd-f50a-48f0-8b09-c0b7d64417eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44109,DS-bc734458-a0e3-4b1e-a9d4-73185a0ce1b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44349,DS-7296a07f-8832-4c5c-ab45-7d7231f597a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33390,DS-61d97012-a136-44dd-80d5-14756c965407,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-622441356-172.17.0.5-1597345118016:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39967,DS-c769c46f-c56a-4932-984c-ec3fbfb403bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42609,DS-ba46af6e-05a4-4a84-a8e3-53f913fedd3c,DISK], DatanodeInfoWithStorage[127.0.0.1:37698,DS-aed6cafa-ddfc-4d58-8927-36c368e1c8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36310,DS-d1e51de1-9d0d-4ca6-821d-12aa4a2670d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43477,DS-cb2e52fd-f50a-48f0-8b09-c0b7d64417eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44109,DS-bc734458-a0e3-4b1e-a9d4-73185a0ce1b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44349,DS-7296a07f-8832-4c5c-ab45-7d7231f597a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33390,DS-61d97012-a136-44dd-80d5-14756c965407,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-947607322-172.17.0.5-1597345792382:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43230,DS-cd30b061-a1a0-4032-a7fc-a07aaaf52b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:34976,DS-5303eac4-2603-49f9-8480-d02edf725ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:45357,DS-e50a2d97-5f12-41b6-99d6-ee1a12439ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:41765,DS-a8aa2d56-a2ff-4d82-99d2-f1da55f716b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42594,DS-07f28f11-e8f4-4e0f-beb6-82a263a422c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34549,DS-013cfc41-1376-4fd7-ae71-6c0ea833e131,DISK], DatanodeInfoWithStorage[127.0.0.1:43400,DS-03b6e25c-7946-44b6-8768-a08226f8f2ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34299,DS-2c9b12e4-e4c2-47da-bd8b-75efe2c2bc86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-947607322-172.17.0.5-1597345792382:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43230,DS-cd30b061-a1a0-4032-a7fc-a07aaaf52b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:34976,DS-5303eac4-2603-49f9-8480-d02edf725ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:45357,DS-e50a2d97-5f12-41b6-99d6-ee1a12439ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:41765,DS-a8aa2d56-a2ff-4d82-99d2-f1da55f716b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42594,DS-07f28f11-e8f4-4e0f-beb6-82a263a422c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34549,DS-013cfc41-1376-4fd7-ae71-6c0ea833e131,DISK], DatanodeInfoWithStorage[127.0.0.1:43400,DS-03b6e25c-7946-44b6-8768-a08226f8f2ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34299,DS-2c9b12e4-e4c2-47da-bd8b-75efe2c2bc86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1972078429-172.17.0.5-1597346361464:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34891,DS-02421e94-48c2-4e71-bc69-60cea867d7e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43432,DS-791f3020-66bd-4f51-b3a5-7005cda7708e,DISK], DatanodeInfoWithStorage[127.0.0.1:35299,DS-a9333a2f-fe75-468e-a45b-95414c0d396e,DISK], DatanodeInfoWithStorage[127.0.0.1:44875,DS-83f21409-8d5e-4829-b872-55055dc31847,DISK], DatanodeInfoWithStorage[127.0.0.1:42158,DS-7a676e7a-7021-4599-ae93-19e87c1d39e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39855,DS-11e99a4f-822d-4043-b6fb-f468d11bd9aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41701,DS-9c19bae4-d0a7-4eb7-a093-744ed2c69be3,DISK], DatanodeInfoWithStorage[127.0.0.1:42979,DS-eb0848fe-1545-4629-8ea4-dde644df296d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1972078429-172.17.0.5-1597346361464:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34891,DS-02421e94-48c2-4e71-bc69-60cea867d7e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43432,DS-791f3020-66bd-4f51-b3a5-7005cda7708e,DISK], DatanodeInfoWithStorage[127.0.0.1:35299,DS-a9333a2f-fe75-468e-a45b-95414c0d396e,DISK], DatanodeInfoWithStorage[127.0.0.1:44875,DS-83f21409-8d5e-4829-b872-55055dc31847,DISK], DatanodeInfoWithStorage[127.0.0.1:42158,DS-7a676e7a-7021-4599-ae93-19e87c1d39e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39855,DS-11e99a4f-822d-4043-b6fb-f468d11bd9aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41701,DS-9c19bae4-d0a7-4eb7-a093-744ed2c69be3,DISK], DatanodeInfoWithStorage[127.0.0.1:42979,DS-eb0848fe-1545-4629-8ea4-dde644df296d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1611364140-172.17.0.5-1597347393028:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40718,DS-9ffd5644-2255-4bd9-97f2-18942f92be96,DISK], DatanodeInfoWithStorage[127.0.0.1:44221,DS-691717c1-b115-4ec2-8998-c19aee8db7bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35732,DS-773cc397-5f2f-4d16-94e6-07015488c23c,DISK], DatanodeInfoWithStorage[127.0.0.1:37796,DS-80a95c74-b3be-4cd4-acaa-df04b7d57681,DISK], DatanodeInfoWithStorage[127.0.0.1:44229,DS-71c98384-dc4c-4f0d-95ac-d5f08937761b,DISK], DatanodeInfoWithStorage[127.0.0.1:40912,DS-a72b8c2f-ff0f-4245-92be-54a4c9fdc8fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33559,DS-092fe61d-56b0-47c1-b30e-30591d9a279b,DISK], DatanodeInfoWithStorage[127.0.0.1:34250,DS-5cdbbbc3-3c54-43c7-8b95-1b2bf9ec35c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1611364140-172.17.0.5-1597347393028:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40718,DS-9ffd5644-2255-4bd9-97f2-18942f92be96,DISK], DatanodeInfoWithStorage[127.0.0.1:44221,DS-691717c1-b115-4ec2-8998-c19aee8db7bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35732,DS-773cc397-5f2f-4d16-94e6-07015488c23c,DISK], DatanodeInfoWithStorage[127.0.0.1:37796,DS-80a95c74-b3be-4cd4-acaa-df04b7d57681,DISK], DatanodeInfoWithStorage[127.0.0.1:44229,DS-71c98384-dc4c-4f0d-95ac-d5f08937761b,DISK], DatanodeInfoWithStorage[127.0.0.1:40912,DS-a72b8c2f-ff0f-4245-92be-54a4c9fdc8fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33559,DS-092fe61d-56b0-47c1-b30e-30591d9a279b,DISK], DatanodeInfoWithStorage[127.0.0.1:34250,DS-5cdbbbc3-3c54-43c7-8b95-1b2bf9ec35c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1282737630-172.17.0.5-1597347795430:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34657,DS-f8854dc5-3106-4c44-b1bd-70821a2ebbff,DISK], DatanodeInfoWithStorage[127.0.0.1:42042,DS-8d004940-ed6f-4905-9830-0630f503562b,DISK], DatanodeInfoWithStorage[127.0.0.1:33934,DS-8d81e8d1-6462-425f-87f7-fbc539159794,DISK], DatanodeInfoWithStorage[127.0.0.1:43431,DS-29cde9ed-6f92-439d-90fc-ee44ede58af0,DISK], DatanodeInfoWithStorage[127.0.0.1:34965,DS-3e7d9531-629c-4a85-94ab-f9a7044910c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34491,DS-313ccc48-02aa-4871-aa83-b939c7d32a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43884,DS-e63d0fc6-c009-4b34-994d-9eb3ee8f64a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37359,DS-391f40a5-0203-4272-877f-238c7224797f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1282737630-172.17.0.5-1597347795430:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34657,DS-f8854dc5-3106-4c44-b1bd-70821a2ebbff,DISK], DatanodeInfoWithStorage[127.0.0.1:42042,DS-8d004940-ed6f-4905-9830-0630f503562b,DISK], DatanodeInfoWithStorage[127.0.0.1:33934,DS-8d81e8d1-6462-425f-87f7-fbc539159794,DISK], DatanodeInfoWithStorage[127.0.0.1:43431,DS-29cde9ed-6f92-439d-90fc-ee44ede58af0,DISK], DatanodeInfoWithStorage[127.0.0.1:34965,DS-3e7d9531-629c-4a85-94ab-f9a7044910c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34491,DS-313ccc48-02aa-4871-aa83-b939c7d32a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43884,DS-e63d0fc6-c009-4b34-994d-9eb3ee8f64a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37359,DS-391f40a5-0203-4272-877f-238c7224797f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1525631330-172.17.0.5-1597348286314:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43305,DS-cc05cbeb-2daa-4202-8cb1-437f471dc7f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38780,DS-4e4c850c-d1e9-4c9d-bbf7-af577c3f31f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33851,DS-77c8fbdb-05a4-4499-9fc1-5a4a4adec64d,DISK], DatanodeInfoWithStorage[127.0.0.1:34086,DS-487a667f-5d63-41e7-9aa5-3f8b103adde0,DISK], DatanodeInfoWithStorage[127.0.0.1:41736,DS-160fabd0-ec13-4372-9400-c1ce8b1a6480,DISK], DatanodeInfoWithStorage[127.0.0.1:32891,DS-8491e057-2bcd-41fe-a003-ae0e195a1f54,DISK], DatanodeInfoWithStorage[127.0.0.1:33170,DS-63fa6112-c7a3-4352-9805-b2f738f6a0fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44548,DS-88921e92-3798-4d13-b8e9-51ce0b5d1782,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1525631330-172.17.0.5-1597348286314:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43305,DS-cc05cbeb-2daa-4202-8cb1-437f471dc7f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38780,DS-4e4c850c-d1e9-4c9d-bbf7-af577c3f31f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33851,DS-77c8fbdb-05a4-4499-9fc1-5a4a4adec64d,DISK], DatanodeInfoWithStorage[127.0.0.1:34086,DS-487a667f-5d63-41e7-9aa5-3f8b103adde0,DISK], DatanodeInfoWithStorage[127.0.0.1:41736,DS-160fabd0-ec13-4372-9400-c1ce8b1a6480,DISK], DatanodeInfoWithStorage[127.0.0.1:32891,DS-8491e057-2bcd-41fe-a003-ae0e195a1f54,DISK], DatanodeInfoWithStorage[127.0.0.1:33170,DS-63fa6112-c7a3-4352-9805-b2f738f6a0fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44548,DS-88921e92-3798-4d13-b8e9-51ce0b5d1782,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-338095887-172.17.0.5-1597348427126:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46353,DS-4a4096bc-7862-4734-86ba-beb03290701a,DISK], DatanodeInfoWithStorage[127.0.0.1:35903,DS-6257e29d-a1f7-4470-9c93-9f554880ce84,DISK], DatanodeInfoWithStorage[127.0.0.1:43434,DS-ab1c040b-ef4a-4a31-8e2c-1253838dcac0,DISK], DatanodeInfoWithStorage[127.0.0.1:37199,DS-7a1d2daa-d58d-46e9-8353-e98537b4a9d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34070,DS-f4490180-fb75-43d7-9efe-d4f873360ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:38228,DS-b4a99385-8969-41cf-ac76-4e9f0243e654,DISK], DatanodeInfoWithStorage[127.0.0.1:40659,DS-b88ed2e0-5c6f-472d-8131-d0aba1a573ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36769,DS-c8c06f2b-81a2-4639-a88b-95e9fd3bd752,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-338095887-172.17.0.5-1597348427126:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46353,DS-4a4096bc-7862-4734-86ba-beb03290701a,DISK], DatanodeInfoWithStorage[127.0.0.1:35903,DS-6257e29d-a1f7-4470-9c93-9f554880ce84,DISK], DatanodeInfoWithStorage[127.0.0.1:43434,DS-ab1c040b-ef4a-4a31-8e2c-1253838dcac0,DISK], DatanodeInfoWithStorage[127.0.0.1:37199,DS-7a1d2daa-d58d-46e9-8353-e98537b4a9d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34070,DS-f4490180-fb75-43d7-9efe-d4f873360ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:38228,DS-b4a99385-8969-41cf-ac76-4e9f0243e654,DISK], DatanodeInfoWithStorage[127.0.0.1:40659,DS-b88ed2e0-5c6f-472d-8131-d0aba1a573ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36769,DS-c8c06f2b-81a2-4639-a88b-95e9fd3bd752,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1781737386-172.17.0.5-1597348469731:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37815,DS-a94240ce-f0b1-470a-879e-272877f474c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33810,DS-241dda83-71cd-4a11-adf0-6abfa61b034b,DISK], DatanodeInfoWithStorage[127.0.0.1:43895,DS-14ac3b41-dd2e-4846-a1cd-b60e42edc0b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38593,DS-99f91667-040a-4dba-a19a-a7c708f3cff4,DISK], DatanodeInfoWithStorage[127.0.0.1:40786,DS-565ecbda-92e0-466d-974b-8d962fa191ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41248,DS-f2990d2f-84c6-4d79-9541-bbd245e3c425,DISK], DatanodeInfoWithStorage[127.0.0.1:37895,DS-c567e578-72f6-4bc9-a25f-fad3389a89c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39175,DS-eabe4fe4-4c4c-47c9-93eb-4aca2b3f9403,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1781737386-172.17.0.5-1597348469731:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37815,DS-a94240ce-f0b1-470a-879e-272877f474c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33810,DS-241dda83-71cd-4a11-adf0-6abfa61b034b,DISK], DatanodeInfoWithStorage[127.0.0.1:43895,DS-14ac3b41-dd2e-4846-a1cd-b60e42edc0b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38593,DS-99f91667-040a-4dba-a19a-a7c708f3cff4,DISK], DatanodeInfoWithStorage[127.0.0.1:40786,DS-565ecbda-92e0-466d-974b-8d962fa191ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41248,DS-f2990d2f-84c6-4d79-9541-bbd245e3c425,DISK], DatanodeInfoWithStorage[127.0.0.1:37895,DS-c567e578-72f6-4bc9-a25f-fad3389a89c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39175,DS-eabe4fe4-4c4c-47c9-93eb-4aca2b3f9403,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-218885103-172.17.0.5-1597348790622:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35004,DS-822d06a1-4ade-438f-b362-c5ebe7e6c8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37541,DS-04a432c1-20d0-4397-be19-da23c2f94169,DISK], DatanodeInfoWithStorage[127.0.0.1:43987,DS-cbb5866e-a826-4057-9b9d-313d1d852aac,DISK], DatanodeInfoWithStorage[127.0.0.1:38045,DS-85466249-e5ba-4692-9aa7-d60127e266c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43417,DS-fbba1cd1-1bc7-47b8-b8ab-3d32f9682204,DISK], DatanodeInfoWithStorage[127.0.0.1:42435,DS-4a7bd344-2ed2-4ab3-9df1-893775983402,DISK], DatanodeInfoWithStorage[127.0.0.1:41146,DS-0ef08848-4edc-4dd4-8ab7-47fd66776cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:41563,DS-ad688a10-cf0e-4568-a528-0be0ae443d18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-218885103-172.17.0.5-1597348790622:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35004,DS-822d06a1-4ade-438f-b362-c5ebe7e6c8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37541,DS-04a432c1-20d0-4397-be19-da23c2f94169,DISK], DatanodeInfoWithStorage[127.0.0.1:43987,DS-cbb5866e-a826-4057-9b9d-313d1d852aac,DISK], DatanodeInfoWithStorage[127.0.0.1:38045,DS-85466249-e5ba-4692-9aa7-d60127e266c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43417,DS-fbba1cd1-1bc7-47b8-b8ab-3d32f9682204,DISK], DatanodeInfoWithStorage[127.0.0.1:42435,DS-4a7bd344-2ed2-4ab3-9df1-893775983402,DISK], DatanodeInfoWithStorage[127.0.0.1:41146,DS-0ef08848-4edc-4dd4-8ab7-47fd66776cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:41563,DS-ad688a10-cf0e-4568-a528-0be0ae443d18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2000833500-172.17.0.5-1597349429643:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40944,DS-2341ee63-0eb4-44b7-9070-9d852f6fc4b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42021,DS-a7ad9ae8-1794-40d0-aebe-ea51873dae14,DISK], DatanodeInfoWithStorage[127.0.0.1:44769,DS-d5f20271-2cc6-486f-a004-3e8ecdecac57,DISK], DatanodeInfoWithStorage[127.0.0.1:42074,DS-95e192b4-1508-4087-a3fd-5a9285718b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:41290,DS-14da4348-27f3-49cf-872c-946ce0ae943b,DISK], DatanodeInfoWithStorage[127.0.0.1:44056,DS-657464b8-7fb2-4033-b4b7-5bd403255b78,DISK], DatanodeInfoWithStorage[127.0.0.1:37694,DS-7ca05c9a-68dc-4540-8dcb-9b5666f051ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34795,DS-fd1f63d9-de2a-4025-b3ad-3e77c5eb2b78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2000833500-172.17.0.5-1597349429643:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40944,DS-2341ee63-0eb4-44b7-9070-9d852f6fc4b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42021,DS-a7ad9ae8-1794-40d0-aebe-ea51873dae14,DISK], DatanodeInfoWithStorage[127.0.0.1:44769,DS-d5f20271-2cc6-486f-a004-3e8ecdecac57,DISK], DatanodeInfoWithStorage[127.0.0.1:42074,DS-95e192b4-1508-4087-a3fd-5a9285718b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:41290,DS-14da4348-27f3-49cf-872c-946ce0ae943b,DISK], DatanodeInfoWithStorage[127.0.0.1:44056,DS-657464b8-7fb2-4033-b4b7-5bd403255b78,DISK], DatanodeInfoWithStorage[127.0.0.1:37694,DS-7ca05c9a-68dc-4540-8dcb-9b5666f051ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34795,DS-fd1f63d9-de2a-4025-b3ad-3e77c5eb2b78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2086927356-172.17.0.5-1597349938510:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40174,DS-795ec0c3-ff28-4655-9804-1792550e807a,DISK], DatanodeInfoWithStorage[127.0.0.1:41415,DS-4644fa60-851c-432a-8c7c-122b75b111be,DISK], DatanodeInfoWithStorage[127.0.0.1:40123,DS-50afaffd-eecf-430f-ad27-12fe00c0e33f,DISK], DatanodeInfoWithStorage[127.0.0.1:44708,DS-2a288622-04bd-47ab-a303-35a0983604b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39094,DS-8fbf8048-07e4-4c25-bf54-acc91c3fd6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36335,DS-0ecdbfa5-208c-4596-b82a-a2fddf6021c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38806,DS-a123c8ef-504b-4620-9004-c3401b06d4dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36110,DS-28685e62-3ebb-4022-a371-d92fd2cae4c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2086927356-172.17.0.5-1597349938510:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40174,DS-795ec0c3-ff28-4655-9804-1792550e807a,DISK], DatanodeInfoWithStorage[127.0.0.1:41415,DS-4644fa60-851c-432a-8c7c-122b75b111be,DISK], DatanodeInfoWithStorage[127.0.0.1:40123,DS-50afaffd-eecf-430f-ad27-12fe00c0e33f,DISK], DatanodeInfoWithStorage[127.0.0.1:44708,DS-2a288622-04bd-47ab-a303-35a0983604b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39094,DS-8fbf8048-07e4-4c25-bf54-acc91c3fd6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36335,DS-0ecdbfa5-208c-4596-b82a-a2fddf6021c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38806,DS-a123c8ef-504b-4620-9004-c3401b06d4dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36110,DS-28685e62-3ebb-4022-a371-d92fd2cae4c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1013142930-172.17.0.5-1597350191531:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46642,DS-bffa8c7f-e461-4bec-968e-c200259c5110,DISK], DatanodeInfoWithStorage[127.0.0.1:35304,DS-77e595f7-1f25-4e5a-b154-3dee07afe4a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42452,DS-57977444-c3af-47cd-bfa1-36536e456913,DISK], DatanodeInfoWithStorage[127.0.0.1:35895,DS-88b88c3e-cdf0-49ea-a2de-9e26173f61c8,DISK], DatanodeInfoWithStorage[127.0.0.1:32804,DS-d235580c-927a-4b43-a44a-7b63b8a6ff40,DISK], DatanodeInfoWithStorage[127.0.0.1:45799,DS-51aa95cc-8820-4a30-aa9f-cf2e1c0be4cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40645,DS-4cfc75b2-74b7-4f6f-ac3e-38e3aa639de2,DISK], DatanodeInfoWithStorage[127.0.0.1:43311,DS-788aa48a-d4c0-4538-9743-9818ab1fc38e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1013142930-172.17.0.5-1597350191531:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46642,DS-bffa8c7f-e461-4bec-968e-c200259c5110,DISK], DatanodeInfoWithStorage[127.0.0.1:35304,DS-77e595f7-1f25-4e5a-b154-3dee07afe4a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42452,DS-57977444-c3af-47cd-bfa1-36536e456913,DISK], DatanodeInfoWithStorage[127.0.0.1:35895,DS-88b88c3e-cdf0-49ea-a2de-9e26173f61c8,DISK], DatanodeInfoWithStorage[127.0.0.1:32804,DS-d235580c-927a-4b43-a44a-7b63b8a6ff40,DISK], DatanodeInfoWithStorage[127.0.0.1:45799,DS-51aa95cc-8820-4a30-aa9f-cf2e1c0be4cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40645,DS-4cfc75b2-74b7-4f6f-ac3e-38e3aa639de2,DISK], DatanodeInfoWithStorage[127.0.0.1:43311,DS-788aa48a-d4c0-4538-9743-9818ab1fc38e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1191908057-172.17.0.5-1597350434733:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41704,DS-8f2e75bf-bf88-4477-92fc-018204248cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:44882,DS-ae7a97fa-42fc-404e-b483-d70b6ae48767,DISK], DatanodeInfoWithStorage[127.0.0.1:46453,DS-2a055522-a7ef-4805-9f3f-bd691d4e689f,DISK], DatanodeInfoWithStorage[127.0.0.1:39897,DS-aec7f94b-eab7-4469-9411-a80af106ea84,DISK], DatanodeInfoWithStorage[127.0.0.1:34158,DS-39e8fa11-d055-463e-8851-aec5e70c5610,DISK], DatanodeInfoWithStorage[127.0.0.1:42377,DS-2b1cfba0-3195-4fad-a514-a662eacb6003,DISK], DatanodeInfoWithStorage[127.0.0.1:40626,DS-d236eb75-0e88-411d-90d1-43547f173855,DISK], DatanodeInfoWithStorage[127.0.0.1:43626,DS-7cd13235-35aa-49a4-9e0d-13e6bcf58321,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1191908057-172.17.0.5-1597350434733:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41704,DS-8f2e75bf-bf88-4477-92fc-018204248cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:44882,DS-ae7a97fa-42fc-404e-b483-d70b6ae48767,DISK], DatanodeInfoWithStorage[127.0.0.1:46453,DS-2a055522-a7ef-4805-9f3f-bd691d4e689f,DISK], DatanodeInfoWithStorage[127.0.0.1:39897,DS-aec7f94b-eab7-4469-9411-a80af106ea84,DISK], DatanodeInfoWithStorage[127.0.0.1:34158,DS-39e8fa11-d055-463e-8851-aec5e70c5610,DISK], DatanodeInfoWithStorage[127.0.0.1:42377,DS-2b1cfba0-3195-4fad-a514-a662eacb6003,DISK], DatanodeInfoWithStorage[127.0.0.1:40626,DS-d236eb75-0e88-411d-90d1-43547f173855,DISK], DatanodeInfoWithStorage[127.0.0.1:43626,DS-7cd13235-35aa-49a4-9e0d-13e6bcf58321,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-221285083-172.17.0.5-1597350563390:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39174,DS-0ea54fac-6414-487f-9a6d-c6523e028e83,DISK], DatanodeInfoWithStorage[127.0.0.1:44750,DS-62990344-e92a-4dba-abed-c91369cc0b62,DISK], DatanodeInfoWithStorage[127.0.0.1:39023,DS-8db6ebc8-a254-48b7-bd7a-86c14351e1ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42584,DS-a7391248-754e-439c-af11-657e55be54ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34606,DS-8e88180e-8653-4c0f-ae4a-96ab7c42984c,DISK], DatanodeInfoWithStorage[127.0.0.1:41542,DS-b0089791-caae-4575-877e-fdc119617b47,DISK], DatanodeInfoWithStorage[127.0.0.1:38040,DS-b00aeb61-b15c-4932-86ba-a56fa13baeab,DISK], DatanodeInfoWithStorage[127.0.0.1:45098,DS-9535b1eb-b4ea-4cd3-b8b5-49c2bea2828e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-221285083-172.17.0.5-1597350563390:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39174,DS-0ea54fac-6414-487f-9a6d-c6523e028e83,DISK], DatanodeInfoWithStorage[127.0.0.1:44750,DS-62990344-e92a-4dba-abed-c91369cc0b62,DISK], DatanodeInfoWithStorage[127.0.0.1:39023,DS-8db6ebc8-a254-48b7-bd7a-86c14351e1ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42584,DS-a7391248-754e-439c-af11-657e55be54ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34606,DS-8e88180e-8653-4c0f-ae4a-96ab7c42984c,DISK], DatanodeInfoWithStorage[127.0.0.1:41542,DS-b0089791-caae-4575-877e-fdc119617b47,DISK], DatanodeInfoWithStorage[127.0.0.1:38040,DS-b00aeb61-b15c-4932-86ba-a56fa13baeab,DISK], DatanodeInfoWithStorage[127.0.0.1:45098,DS-9535b1eb-b4ea-4cd3-b8b5-49c2bea2828e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 6943
