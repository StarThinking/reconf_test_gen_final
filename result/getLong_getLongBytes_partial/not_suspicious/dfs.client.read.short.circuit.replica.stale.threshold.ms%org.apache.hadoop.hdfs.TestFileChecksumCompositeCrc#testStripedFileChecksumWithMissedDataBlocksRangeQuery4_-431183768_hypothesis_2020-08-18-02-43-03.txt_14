reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 1800000
v2: 1800
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 1800000
v2: 1800
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2018800998-172.17.0.16-1597719023532:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39997,DS-32da9887-3edd-451f-b709-90f2173a638c,DISK], DatanodeInfoWithStorage[127.0.0.1:39704,DS-cc3d5057-5ff6-4a5d-ae3f-fc90b13faaf8,DISK], DatanodeInfoWithStorage[127.0.0.1:44414,DS-c2d5d111-6b77-4c37-a4db-d0055d98bc7f,DISK], DatanodeInfoWithStorage[127.0.0.1:46153,DS-eafe24db-85df-42ab-9989-5a533ed63e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39015,DS-b0114f08-6743-40f2-a504-9c27f0e2cf9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39708,DS-9d73a952-e6e4-4756-8948-01b0e0f89ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:36181,DS-93910220-2a56-4f58-a291-66444e75946b,DISK], DatanodeInfoWithStorage[127.0.0.1:44270,DS-3e5d27e5-d718-495f-9708-562b460c218c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2018800998-172.17.0.16-1597719023532:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39997,DS-32da9887-3edd-451f-b709-90f2173a638c,DISK], DatanodeInfoWithStorage[127.0.0.1:39704,DS-cc3d5057-5ff6-4a5d-ae3f-fc90b13faaf8,DISK], DatanodeInfoWithStorage[127.0.0.1:44414,DS-c2d5d111-6b77-4c37-a4db-d0055d98bc7f,DISK], DatanodeInfoWithStorage[127.0.0.1:46153,DS-eafe24db-85df-42ab-9989-5a533ed63e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39015,DS-b0114f08-6743-40f2-a504-9c27f0e2cf9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39708,DS-9d73a952-e6e4-4756-8948-01b0e0f89ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:36181,DS-93910220-2a56-4f58-a291-66444e75946b,DISK], DatanodeInfoWithStorage[127.0.0.1:44270,DS-3e5d27e5-d718-495f-9708-562b460c218c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 1800000
v2: 1800
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1152307529-172.17.0.16-1597719464908:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46100,DS-39a82ae4-bdfe-4e0b-a1da-ecc25f26eda8,DISK], DatanodeInfoWithStorage[127.0.0.1:44806,DS-4f78f9cd-f296-4e41-b39c-bbd6bb50fce9,DISK], DatanodeInfoWithStorage[127.0.0.1:45500,DS-bf020179-2ac6-457b-be0c-60bdda2f02ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40374,DS-5cbcaa65-ccbe-4970-98d7-d3969ca0ca9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36073,DS-0bd38a03-1c53-42ea-bbbb-945757c0cefc,DISK], DatanodeInfoWithStorage[127.0.0.1:43392,DS-6c98715e-69e6-413c-acde-0d00f4d017bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39279,DS-c8aa2ffe-c951-409d-aff1-752962b6d15b,DISK], DatanodeInfoWithStorage[127.0.0.1:38173,DS-af3f42cc-7cce-4619-8e20-c5e133da8af3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1152307529-172.17.0.16-1597719464908:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46100,DS-39a82ae4-bdfe-4e0b-a1da-ecc25f26eda8,DISK], DatanodeInfoWithStorage[127.0.0.1:44806,DS-4f78f9cd-f296-4e41-b39c-bbd6bb50fce9,DISK], DatanodeInfoWithStorage[127.0.0.1:45500,DS-bf020179-2ac6-457b-be0c-60bdda2f02ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40374,DS-5cbcaa65-ccbe-4970-98d7-d3969ca0ca9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36073,DS-0bd38a03-1c53-42ea-bbbb-945757c0cefc,DISK], DatanodeInfoWithStorage[127.0.0.1:43392,DS-6c98715e-69e6-413c-acde-0d00f4d017bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39279,DS-c8aa2ffe-c951-409d-aff1-752962b6d15b,DISK], DatanodeInfoWithStorage[127.0.0.1:38173,DS-af3f42cc-7cce-4619-8e20-c5e133da8af3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 1800000
v2: 1800
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2055431574-172.17.0.16-1597719618924:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42633,DS-3f0353b6-6e2a-4dbb-9093-a15a16ef068a,DISK], DatanodeInfoWithStorage[127.0.0.1:43547,DS-b419894e-1cab-4f4c-91fa-63649639389e,DISK], DatanodeInfoWithStorage[127.0.0.1:41612,DS-f9f2c529-8d16-4e97-b2ac-f6036e8b89ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36941,DS-b7fea12c-a3fc-4188-b9ec-12ff5a235969,DISK], DatanodeInfoWithStorage[127.0.0.1:34133,DS-8e977060-0651-4d98-a651-ce51fbedf620,DISK], DatanodeInfoWithStorage[127.0.0.1:41856,DS-f96bb000-3983-43cb-8855-19dbed037a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40703,DS-8562afba-36f8-4b8d-8c3a-613db4fb5155,DISK], DatanodeInfoWithStorage[127.0.0.1:34822,DS-beb4b111-0ea3-4bd4-8cb1-3c1edc8e5a2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2055431574-172.17.0.16-1597719618924:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42633,DS-3f0353b6-6e2a-4dbb-9093-a15a16ef068a,DISK], DatanodeInfoWithStorage[127.0.0.1:43547,DS-b419894e-1cab-4f4c-91fa-63649639389e,DISK], DatanodeInfoWithStorage[127.0.0.1:41612,DS-f9f2c529-8d16-4e97-b2ac-f6036e8b89ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36941,DS-b7fea12c-a3fc-4188-b9ec-12ff5a235969,DISK], DatanodeInfoWithStorage[127.0.0.1:34133,DS-8e977060-0651-4d98-a651-ce51fbedf620,DISK], DatanodeInfoWithStorage[127.0.0.1:41856,DS-f96bb000-3983-43cb-8855-19dbed037a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40703,DS-8562afba-36f8-4b8d-8c3a-613db4fb5155,DISK], DatanodeInfoWithStorage[127.0.0.1:34822,DS-beb4b111-0ea3-4bd4-8cb1-3c1edc8e5a2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 1800000
v2: 1800
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1835798786-172.17.0.16-1597720701349:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33349,DS-c3208ca4-9e80-4bc6-99dc-631698ae566c,DISK], DatanodeInfoWithStorage[127.0.0.1:44652,DS-d1e91afc-f219-43b4-a968-c274d4589285,DISK], DatanodeInfoWithStorage[127.0.0.1:32908,DS-80d41457-0091-4bfb-87f4-24682edcf6ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33927,DS-9471f626-44a7-4885-b682-c5432cfa2ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:35522,DS-afb6911d-32ae-4db3-96d9-b2c52ae14865,DISK], DatanodeInfoWithStorage[127.0.0.1:39679,DS-07711242-0d16-4e93-bf84-faf47a8e4e00,DISK], DatanodeInfoWithStorage[127.0.0.1:43765,DS-a9b4f843-aed5-4016-8b15-a5b4a4278c60,DISK], DatanodeInfoWithStorage[127.0.0.1:34679,DS-0f8f88dd-fee2-407a-a491-a445c77246e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1835798786-172.17.0.16-1597720701349:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33349,DS-c3208ca4-9e80-4bc6-99dc-631698ae566c,DISK], DatanodeInfoWithStorage[127.0.0.1:44652,DS-d1e91afc-f219-43b4-a968-c274d4589285,DISK], DatanodeInfoWithStorage[127.0.0.1:32908,DS-80d41457-0091-4bfb-87f4-24682edcf6ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33927,DS-9471f626-44a7-4885-b682-c5432cfa2ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:35522,DS-afb6911d-32ae-4db3-96d9-b2c52ae14865,DISK], DatanodeInfoWithStorage[127.0.0.1:39679,DS-07711242-0d16-4e93-bf84-faf47a8e4e00,DISK], DatanodeInfoWithStorage[127.0.0.1:43765,DS-a9b4f843-aed5-4016-8b15-a5b4a4278c60,DISK], DatanodeInfoWithStorage[127.0.0.1:34679,DS-0f8f88dd-fee2-407a-a491-a445c77246e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 1800000
v2: 1800
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-888165866-172.17.0.16-1597721373357:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45024,DS-d077b493-a7b9-429f-bad2-80a04e003bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:40804,DS-75e8cda8-95f5-466b-864d-8c84c791f7c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34148,DS-ece5ee36-9d44-4858-82c4-5b124d5bd655,DISK], DatanodeInfoWithStorage[127.0.0.1:40195,DS-9da9e2f4-7037-4495-a031-5e24c1436828,DISK], DatanodeInfoWithStorage[127.0.0.1:33231,DS-3ab73e30-173e-4a0b-acd2-41e877b94ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:43716,DS-8410efed-1116-4307-bea2-6f600aacd38f,DISK], DatanodeInfoWithStorage[127.0.0.1:39107,DS-3f45de8b-2ccf-4582-8597-888b7112db1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36077,DS-bd6b2ef0-2eaf-4659-b793-d423ea63aa07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-888165866-172.17.0.16-1597721373357:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45024,DS-d077b493-a7b9-429f-bad2-80a04e003bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:40804,DS-75e8cda8-95f5-466b-864d-8c84c791f7c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34148,DS-ece5ee36-9d44-4858-82c4-5b124d5bd655,DISK], DatanodeInfoWithStorage[127.0.0.1:40195,DS-9da9e2f4-7037-4495-a031-5e24c1436828,DISK], DatanodeInfoWithStorage[127.0.0.1:33231,DS-3ab73e30-173e-4a0b-acd2-41e877b94ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:43716,DS-8410efed-1116-4307-bea2-6f600aacd38f,DISK], DatanodeInfoWithStorage[127.0.0.1:39107,DS-3f45de8b-2ccf-4582-8597-888b7112db1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36077,DS-bd6b2ef0-2eaf-4659-b793-d423ea63aa07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 1800000
v2: 1800
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-372747180-172.17.0.16-1597721445242:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37288,DS-9739153b-203d-4754-94da-6a5f27f571a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38906,DS-5acdfce1-8bc2-4695-bf50-67c5984a7986,DISK], DatanodeInfoWithStorage[127.0.0.1:42741,DS-5ae715a5-1d41-483c-a751-787cf18211e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37813,DS-8ac44d78-0d3d-40c4-8f64-a5e930b423ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41451,DS-509e0030-d426-4f8c-9a89-0320328d1c56,DISK], DatanodeInfoWithStorage[127.0.0.1:43279,DS-065a012f-3371-421b-aa8b-dc2b38d3a932,DISK], DatanodeInfoWithStorage[127.0.0.1:40646,DS-457d56c0-c84f-4e3a-a5c7-541945a6f198,DISK], DatanodeInfoWithStorage[127.0.0.1:41062,DS-81478a80-cd7b-4b85-acbd-2547f2e8d6d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-372747180-172.17.0.16-1597721445242:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37288,DS-9739153b-203d-4754-94da-6a5f27f571a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38906,DS-5acdfce1-8bc2-4695-bf50-67c5984a7986,DISK], DatanodeInfoWithStorage[127.0.0.1:42741,DS-5ae715a5-1d41-483c-a751-787cf18211e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37813,DS-8ac44d78-0d3d-40c4-8f64-a5e930b423ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41451,DS-509e0030-d426-4f8c-9a89-0320328d1c56,DISK], DatanodeInfoWithStorage[127.0.0.1:43279,DS-065a012f-3371-421b-aa8b-dc2b38d3a932,DISK], DatanodeInfoWithStorage[127.0.0.1:40646,DS-457d56c0-c84f-4e3a-a5c7-541945a6f198,DISK], DatanodeInfoWithStorage[127.0.0.1:41062,DS-81478a80-cd7b-4b85-acbd-2547f2e8d6d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 1800000
v2: 1800
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1383357421-172.17.0.16-1597722270378:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39120,DS-b572e839-7560-4bbc-a58c-769a4d4e3788,DISK], DatanodeInfoWithStorage[127.0.0.1:45465,DS-337927f2-eea2-440c-a9e0-9c9d0c7de9ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37996,DS-e6aec1c9-a46a-4afb-b113-be009e21feba,DISK], DatanodeInfoWithStorage[127.0.0.1:44919,DS-b819ffeb-29a1-401f-83bf-1dfc34ebaf14,DISK], DatanodeInfoWithStorage[127.0.0.1:33479,DS-0175bd10-5e14-4bc9-9272-59bcd1d3d81f,DISK], DatanodeInfoWithStorage[127.0.0.1:37276,DS-11723d59-299c-4413-a829-97f4fdd8539f,DISK], DatanodeInfoWithStorage[127.0.0.1:37969,DS-86ff3e9e-ad85-40a5-abba-f6986e58aadd,DISK], DatanodeInfoWithStorage[127.0.0.1:39121,DS-0ca1a3b4-b6f4-4a0f-97d8-29e894ca8dc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1383357421-172.17.0.16-1597722270378:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39120,DS-b572e839-7560-4bbc-a58c-769a4d4e3788,DISK], DatanodeInfoWithStorage[127.0.0.1:45465,DS-337927f2-eea2-440c-a9e0-9c9d0c7de9ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37996,DS-e6aec1c9-a46a-4afb-b113-be009e21feba,DISK], DatanodeInfoWithStorage[127.0.0.1:44919,DS-b819ffeb-29a1-401f-83bf-1dfc34ebaf14,DISK], DatanodeInfoWithStorage[127.0.0.1:33479,DS-0175bd10-5e14-4bc9-9272-59bcd1d3d81f,DISK], DatanodeInfoWithStorage[127.0.0.1:37276,DS-11723d59-299c-4413-a829-97f4fdd8539f,DISK], DatanodeInfoWithStorage[127.0.0.1:37969,DS-86ff3e9e-ad85-40a5-abba-f6986e58aadd,DISK], DatanodeInfoWithStorage[127.0.0.1:39121,DS-0ca1a3b4-b6f4-4a0f-97d8-29e894ca8dc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 1800000
v2: 1800
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-47726513-172.17.0.16-1597722696483:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38687,DS-c0c7504d-a194-4851-abce-a8a7e8bb9d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:43633,DS-07eef4fb-a202-42db-984e-2640cf6fe646,DISK], DatanodeInfoWithStorage[127.0.0.1:33571,DS-e87d1658-4743-475d-84c3-da9954972761,DISK], DatanodeInfoWithStorage[127.0.0.1:34393,DS-2e7252db-ad9a-49ea-96bc-50663fcbd46e,DISK], DatanodeInfoWithStorage[127.0.0.1:35981,DS-bcc8a523-f6c4-4eb1-bf1c-8e4aafae1402,DISK], DatanodeInfoWithStorage[127.0.0.1:46738,DS-def76f68-2cba-4c99-ae98-4116bdb98588,DISK], DatanodeInfoWithStorage[127.0.0.1:39056,DS-f99e7d98-5804-49b2-a1a9-a1b12a48d855,DISK], DatanodeInfoWithStorage[127.0.0.1:33405,DS-d1f30b43-241f-4209-aaa1-fd483c586855,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-47726513-172.17.0.16-1597722696483:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38687,DS-c0c7504d-a194-4851-abce-a8a7e8bb9d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:43633,DS-07eef4fb-a202-42db-984e-2640cf6fe646,DISK], DatanodeInfoWithStorage[127.0.0.1:33571,DS-e87d1658-4743-475d-84c3-da9954972761,DISK], DatanodeInfoWithStorage[127.0.0.1:34393,DS-2e7252db-ad9a-49ea-96bc-50663fcbd46e,DISK], DatanodeInfoWithStorage[127.0.0.1:35981,DS-bcc8a523-f6c4-4eb1-bf1c-8e4aafae1402,DISK], DatanodeInfoWithStorage[127.0.0.1:46738,DS-def76f68-2cba-4c99-ae98-4116bdb98588,DISK], DatanodeInfoWithStorage[127.0.0.1:39056,DS-f99e7d98-5804-49b2-a1a9-a1b12a48d855,DISK], DatanodeInfoWithStorage[127.0.0.1:33405,DS-d1f30b43-241f-4209-aaa1-fd483c586855,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 1800000
v2: 1800
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-775779804-172.17.0.16-1597722955217:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36808,DS-1669d2dd-a4b1-4a7c-be0e-3aed7e99442c,DISK], DatanodeInfoWithStorage[127.0.0.1:40539,DS-78afba0e-6bd2-4484-a62a-546fc14c971d,DISK], DatanodeInfoWithStorage[127.0.0.1:43019,DS-a3ce3298-47b4-4d1a-a650-d1fc05688bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:39901,DS-d0968bbc-c654-4ddf-aa68-75c44c5a5520,DISK], DatanodeInfoWithStorage[127.0.0.1:33105,DS-3ec7207f-f16b-49b1-baf9-a9a011ba57d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37453,DS-e8136db7-10c2-4548-9f1d-46afc61343ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42720,DS-02501adc-bc27-4084-9b9a-36fd59b84fef,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-7e2a76f7-c81f-4b17-b5c4-996d157842b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-775779804-172.17.0.16-1597722955217:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36808,DS-1669d2dd-a4b1-4a7c-be0e-3aed7e99442c,DISK], DatanodeInfoWithStorage[127.0.0.1:40539,DS-78afba0e-6bd2-4484-a62a-546fc14c971d,DISK], DatanodeInfoWithStorage[127.0.0.1:43019,DS-a3ce3298-47b4-4d1a-a650-d1fc05688bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:39901,DS-d0968bbc-c654-4ddf-aa68-75c44c5a5520,DISK], DatanodeInfoWithStorage[127.0.0.1:33105,DS-3ec7207f-f16b-49b1-baf9-a9a011ba57d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37453,DS-e8136db7-10c2-4548-9f1d-46afc61343ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42720,DS-02501adc-bc27-4084-9b9a-36fd59b84fef,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-7e2a76f7-c81f-4b17-b5c4-996d157842b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 1800000
v2: 1800
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1957827125-172.17.0.16-1597723779315:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40554,DS-87008e9e-8d86-4ecc-a992-ab73b9594843,DISK], DatanodeInfoWithStorage[127.0.0.1:42068,DS-98b1df72-2266-4daf-aee7-4bfb81019ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:35186,DS-7bfc2606-5c2b-45de-925a-753716d2d3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44746,DS-34759551-e7d1-4db1-82c6-928d59986832,DISK], DatanodeInfoWithStorage[127.0.0.1:43478,DS-3862777f-112c-49b9-8b6c-7569c7f7b22e,DISK], DatanodeInfoWithStorage[127.0.0.1:40910,DS-c97a7edf-6e8b-49b8-9f64-492e9e3e4827,DISK], DatanodeInfoWithStorage[127.0.0.1:36273,DS-7009fc6a-1acc-4ce6-bf20-e4ff44cc6038,DISK], DatanodeInfoWithStorage[127.0.0.1:33482,DS-5bd902c7-8099-4a56-8e69-a13ad7fc9433,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1957827125-172.17.0.16-1597723779315:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40554,DS-87008e9e-8d86-4ecc-a992-ab73b9594843,DISK], DatanodeInfoWithStorage[127.0.0.1:42068,DS-98b1df72-2266-4daf-aee7-4bfb81019ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:35186,DS-7bfc2606-5c2b-45de-925a-753716d2d3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44746,DS-34759551-e7d1-4db1-82c6-928d59986832,DISK], DatanodeInfoWithStorage[127.0.0.1:43478,DS-3862777f-112c-49b9-8b6c-7569c7f7b22e,DISK], DatanodeInfoWithStorage[127.0.0.1:40910,DS-c97a7edf-6e8b-49b8-9f64-492e9e3e4827,DISK], DatanodeInfoWithStorage[127.0.0.1:36273,DS-7009fc6a-1acc-4ce6-bf20-e4ff44cc6038,DISK], DatanodeInfoWithStorage[127.0.0.1:33482,DS-5bd902c7-8099-4a56-8e69-a13ad7fc9433,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 1800000
v2: 1800
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-402967085-172.17.0.16-1597723886953:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45923,DS-d28c978c-62ff-4710-8a9e-5d95dbc9eaeb,DISK], DatanodeInfoWithStorage[127.0.0.1:39223,DS-50379180-518c-4768-ad72-a8b1519cb25d,DISK], DatanodeInfoWithStorage[127.0.0.1:39786,DS-23f45564-6389-4ce4-ab8b-010a55ad9eba,DISK], DatanodeInfoWithStorage[127.0.0.1:33126,DS-046d9de2-c088-4b4f-bef4-2f471695de39,DISK], DatanodeInfoWithStorage[127.0.0.1:44011,DS-6b401e0b-6c89-4023-b963-d05b9a3bf488,DISK], DatanodeInfoWithStorage[127.0.0.1:36866,DS-e423dd5a-9f6e-4940-a3b4-afa5cbddd03f,DISK], DatanodeInfoWithStorage[127.0.0.1:34036,DS-e0bcbf0c-f930-424b-ac0e-83cf6eccbf22,DISK], DatanodeInfoWithStorage[127.0.0.1:37994,DS-9ffbfb91-5377-4395-9105-c963de0d73c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-402967085-172.17.0.16-1597723886953:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45923,DS-d28c978c-62ff-4710-8a9e-5d95dbc9eaeb,DISK], DatanodeInfoWithStorage[127.0.0.1:39223,DS-50379180-518c-4768-ad72-a8b1519cb25d,DISK], DatanodeInfoWithStorage[127.0.0.1:39786,DS-23f45564-6389-4ce4-ab8b-010a55ad9eba,DISK], DatanodeInfoWithStorage[127.0.0.1:33126,DS-046d9de2-c088-4b4f-bef4-2f471695de39,DISK], DatanodeInfoWithStorage[127.0.0.1:44011,DS-6b401e0b-6c89-4023-b963-d05b9a3bf488,DISK], DatanodeInfoWithStorage[127.0.0.1:36866,DS-e423dd5a-9f6e-4940-a3b4-afa5cbddd03f,DISK], DatanodeInfoWithStorage[127.0.0.1:34036,DS-e0bcbf0c-f930-424b-ac0e-83cf6eccbf22,DISK], DatanodeInfoWithStorage[127.0.0.1:37994,DS-9ffbfb91-5377-4395-9105-c963de0d73c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 5 out of 50
result: might be true error
Total execution time in seconds : 5556
