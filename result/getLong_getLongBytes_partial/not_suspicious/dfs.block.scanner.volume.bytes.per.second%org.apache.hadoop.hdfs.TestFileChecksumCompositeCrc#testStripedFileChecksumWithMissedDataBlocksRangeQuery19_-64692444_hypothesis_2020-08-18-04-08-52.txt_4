reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-559328980-172.17.0.21-1597724080582:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44733,DS-31d48a0d-0821-4274-b974-b7cb092d3036,DISK], DatanodeInfoWithStorage[127.0.0.1:34381,DS-c54397da-ce86-45d2-b941-832e2d882eea,DISK], DatanodeInfoWithStorage[127.0.0.1:43353,DS-6d4bad16-5175-4337-90a4-2cf0c451efdc,DISK], DatanodeInfoWithStorage[127.0.0.1:43952,DS-7c412f5f-31ef-4db7-a86c-e9aca7b54a30,DISK], DatanodeInfoWithStorage[127.0.0.1:38317,DS-72cc0c1b-18e9-489b-bfa8-ae545f24cf07,DISK], DatanodeInfoWithStorage[127.0.0.1:37280,DS-90074cd6-dac4-4d4f-a95c-2824400cff2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37667,DS-c1e3ebca-1660-4408-bfd4-7cd0c467c66b,DISK], DatanodeInfoWithStorage[127.0.0.1:40088,DS-f260016c-e50b-4bba-a43f-46414a34b682,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-559328980-172.17.0.21-1597724080582:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44733,DS-31d48a0d-0821-4274-b974-b7cb092d3036,DISK], DatanodeInfoWithStorage[127.0.0.1:34381,DS-c54397da-ce86-45d2-b941-832e2d882eea,DISK], DatanodeInfoWithStorage[127.0.0.1:43353,DS-6d4bad16-5175-4337-90a4-2cf0c451efdc,DISK], DatanodeInfoWithStorage[127.0.0.1:43952,DS-7c412f5f-31ef-4db7-a86c-e9aca7b54a30,DISK], DatanodeInfoWithStorage[127.0.0.1:38317,DS-72cc0c1b-18e9-489b-bfa8-ae545f24cf07,DISK], DatanodeInfoWithStorage[127.0.0.1:37280,DS-90074cd6-dac4-4d4f-a95c-2824400cff2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37667,DS-c1e3ebca-1660-4408-bfd4-7cd0c467c66b,DISK], DatanodeInfoWithStorage[127.0.0.1:40088,DS-f260016c-e50b-4bba-a43f-46414a34b682,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2066880610-172.17.0.21-1597724377625:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42870,DS-523b7c7e-d0aa-4720-bb40-933cc65499f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46404,DS-c4ef68a2-7781-412e-94f8-480b6f442f40,DISK], DatanodeInfoWithStorage[127.0.0.1:39916,DS-381188de-123c-4006-aaa0-589e92f1df35,DISK], DatanodeInfoWithStorage[127.0.0.1:38885,DS-6c4e05ec-fb03-4560-a28e-e2a0fa66d37b,DISK], DatanodeInfoWithStorage[127.0.0.1:43464,DS-2a120b27-f462-4c75-87cc-72a4a95a899e,DISK], DatanodeInfoWithStorage[127.0.0.1:45849,DS-51a4b652-0ef0-405c-90d0-cd2c35cb647f,DISK], DatanodeInfoWithStorage[127.0.0.1:41522,DS-b8aa8659-0066-4b63-a6f2-2c35d7c88170,DISK], DatanodeInfoWithStorage[127.0.0.1:33824,DS-57680ae6-2a39-4384-a5d0-847066ea440d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2066880610-172.17.0.21-1597724377625:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42870,DS-523b7c7e-d0aa-4720-bb40-933cc65499f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46404,DS-c4ef68a2-7781-412e-94f8-480b6f442f40,DISK], DatanodeInfoWithStorage[127.0.0.1:39916,DS-381188de-123c-4006-aaa0-589e92f1df35,DISK], DatanodeInfoWithStorage[127.0.0.1:38885,DS-6c4e05ec-fb03-4560-a28e-e2a0fa66d37b,DISK], DatanodeInfoWithStorage[127.0.0.1:43464,DS-2a120b27-f462-4c75-87cc-72a4a95a899e,DISK], DatanodeInfoWithStorage[127.0.0.1:45849,DS-51a4b652-0ef0-405c-90d0-cd2c35cb647f,DISK], DatanodeInfoWithStorage[127.0.0.1:41522,DS-b8aa8659-0066-4b63-a6f2-2c35d7c88170,DISK], DatanodeInfoWithStorage[127.0.0.1:33824,DS-57680ae6-2a39-4384-a5d0-847066ea440d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1939259073-172.17.0.21-1597724597314:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41867,DS-2af10008-f296-4aa0-b035-0dd33ae4fa5a,DISK], DatanodeInfoWithStorage[127.0.0.1:44205,DS-2838a58f-c5a4-4a54-b09a-d9727ffe8c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42525,DS-362d8097-c20e-4675-8293-a9b8e05c1fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:36742,DS-892e9bfa-bc70-4169-ab95-67c036937c75,DISK], DatanodeInfoWithStorage[127.0.0.1:40990,DS-39316ac4-135c-4d3b-ac68-55382ee67f65,DISK], DatanodeInfoWithStorage[127.0.0.1:42848,DS-132d3602-cb4c-4d3d-ba25-16998692972d,DISK], DatanodeInfoWithStorage[127.0.0.1:44575,DS-5a2e3dc5-a70d-469a-8242-b7addb952be5,DISK], DatanodeInfoWithStorage[127.0.0.1:42883,DS-358d1f09-2a51-43ea-81bf-bb331fc72bb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1939259073-172.17.0.21-1597724597314:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41867,DS-2af10008-f296-4aa0-b035-0dd33ae4fa5a,DISK], DatanodeInfoWithStorage[127.0.0.1:44205,DS-2838a58f-c5a4-4a54-b09a-d9727ffe8c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42525,DS-362d8097-c20e-4675-8293-a9b8e05c1fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:36742,DS-892e9bfa-bc70-4169-ab95-67c036937c75,DISK], DatanodeInfoWithStorage[127.0.0.1:40990,DS-39316ac4-135c-4d3b-ac68-55382ee67f65,DISK], DatanodeInfoWithStorage[127.0.0.1:42848,DS-132d3602-cb4c-4d3d-ba25-16998692972d,DISK], DatanodeInfoWithStorage[127.0.0.1:44575,DS-5a2e3dc5-a70d-469a-8242-b7addb952be5,DISK], DatanodeInfoWithStorage[127.0.0.1:42883,DS-358d1f09-2a51-43ea-81bf-bb331fc72bb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1216553591-172.17.0.21-1597724636856:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43481,DS-195a1ac7-54bb-4ded-8f85-ac585dc9f567,DISK], DatanodeInfoWithStorage[127.0.0.1:34727,DS-0f9ce05f-52e7-4f3b-9259-46701fab9e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:33600,DS-77c3e2f6-51f7-4e8f-bbf0-8ce0eaf8008d,DISK], DatanodeInfoWithStorage[127.0.0.1:35733,DS-3f4f4135-c3e4-49de-b8de-21acd58d716f,DISK], DatanodeInfoWithStorage[127.0.0.1:45599,DS-d3e092dc-4098-451a-a613-ad34c927d4d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41532,DS-b7dbaf7c-6d45-4479-8371-8a71c9a5b37b,DISK], DatanodeInfoWithStorage[127.0.0.1:37933,DS-edc29840-1d8e-47b2-b2de-bb3d277947f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41838,DS-2a3136db-a1b5-4064-8ffc-10bf50da6c05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1216553591-172.17.0.21-1597724636856:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43481,DS-195a1ac7-54bb-4ded-8f85-ac585dc9f567,DISK], DatanodeInfoWithStorage[127.0.0.1:34727,DS-0f9ce05f-52e7-4f3b-9259-46701fab9e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:33600,DS-77c3e2f6-51f7-4e8f-bbf0-8ce0eaf8008d,DISK], DatanodeInfoWithStorage[127.0.0.1:35733,DS-3f4f4135-c3e4-49de-b8de-21acd58d716f,DISK], DatanodeInfoWithStorage[127.0.0.1:45599,DS-d3e092dc-4098-451a-a613-ad34c927d4d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41532,DS-b7dbaf7c-6d45-4479-8371-8a71c9a5b37b,DISK], DatanodeInfoWithStorage[127.0.0.1:37933,DS-edc29840-1d8e-47b2-b2de-bb3d277947f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41838,DS-2a3136db-a1b5-4064-8ffc-10bf50da6c05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1477503018-172.17.0.21-1597725059789:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33790,DS-1a948c06-2940-4bb3-956a-139e32f18d76,DISK], DatanodeInfoWithStorage[127.0.0.1:45573,DS-a6d15115-5973-4b7a-9b0a-03306d1aafc5,DISK], DatanodeInfoWithStorage[127.0.0.1:37669,DS-95786c23-72b2-43f9-b686-237c5bc04497,DISK], DatanodeInfoWithStorage[127.0.0.1:46838,DS-d263c793-de49-4c4d-9d2d-c8f48cca6174,DISK], DatanodeInfoWithStorage[127.0.0.1:43514,DS-ea55dd9e-f56d-4453-a76b-13d35f280509,DISK], DatanodeInfoWithStorage[127.0.0.1:42144,DS-807d331d-eca1-46b5-a987-7c20b304f5e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43552,DS-8fa03e19-8dd3-4383-ab97-328db9ab7647,DISK], DatanodeInfoWithStorage[127.0.0.1:34833,DS-1e794a4d-0537-4a2c-8e95-74835164f692,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1477503018-172.17.0.21-1597725059789:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33790,DS-1a948c06-2940-4bb3-956a-139e32f18d76,DISK], DatanodeInfoWithStorage[127.0.0.1:45573,DS-a6d15115-5973-4b7a-9b0a-03306d1aafc5,DISK], DatanodeInfoWithStorage[127.0.0.1:37669,DS-95786c23-72b2-43f9-b686-237c5bc04497,DISK], DatanodeInfoWithStorage[127.0.0.1:46838,DS-d263c793-de49-4c4d-9d2d-c8f48cca6174,DISK], DatanodeInfoWithStorage[127.0.0.1:43514,DS-ea55dd9e-f56d-4453-a76b-13d35f280509,DISK], DatanodeInfoWithStorage[127.0.0.1:42144,DS-807d331d-eca1-46b5-a987-7c20b304f5e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43552,DS-8fa03e19-8dd3-4383-ab97-328db9ab7647,DISK], DatanodeInfoWithStorage[127.0.0.1:34833,DS-1e794a4d-0537-4a2c-8e95-74835164f692,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1241443479-172.17.0.21-1597725202659:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45936,DS-28960280-21ce-4207-8d1f-55448f44de1b,DISK], DatanodeInfoWithStorage[127.0.0.1:40380,DS-b19aee05-bb3c-4ca2-9383-52be408e3e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:40670,DS-bad2c2d4-eeee-4b01-906d-6078dc52e842,DISK], DatanodeInfoWithStorage[127.0.0.1:42712,DS-1df3e0f6-6ac1-4704-994d-106e2755bd5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34080,DS-df64f814-e9b2-4a1a-a9ee-6141019e8b92,DISK], DatanodeInfoWithStorage[127.0.0.1:44804,DS-4ceeb66e-f6b9-4ef4-8dc9-7fdf816756e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37814,DS-9929a656-a56c-40bb-b9a0-cbfe983e6403,DISK], DatanodeInfoWithStorage[127.0.0.1:44961,DS-915563cd-5255-4db1-be48-e942e6984260,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1241443479-172.17.0.21-1597725202659:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45936,DS-28960280-21ce-4207-8d1f-55448f44de1b,DISK], DatanodeInfoWithStorage[127.0.0.1:40380,DS-b19aee05-bb3c-4ca2-9383-52be408e3e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:40670,DS-bad2c2d4-eeee-4b01-906d-6078dc52e842,DISK], DatanodeInfoWithStorage[127.0.0.1:42712,DS-1df3e0f6-6ac1-4704-994d-106e2755bd5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34080,DS-df64f814-e9b2-4a1a-a9ee-6141019e8b92,DISK], DatanodeInfoWithStorage[127.0.0.1:44804,DS-4ceeb66e-f6b9-4ef4-8dc9-7fdf816756e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37814,DS-9929a656-a56c-40bb-b9a0-cbfe983e6403,DISK], DatanodeInfoWithStorage[127.0.0.1:44961,DS-915563cd-5255-4db1-be48-e942e6984260,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-508937718-172.17.0.21-1597725647811:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37093,DS-ac8fde6f-9239-49e5-97a2-3e8ad85a37e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40330,DS-2d051e5c-7925-4dba-b7ab-8bc5e63d33e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38313,DS-41f107ed-41a1-4ed1-a47d-5af3c3fa89e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45305,DS-93d2a9b8-3286-4f2c-a2de-df11a45146b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34876,DS-1ceff07d-87b9-45cc-bdd9-6aab272bb105,DISK], DatanodeInfoWithStorage[127.0.0.1:33394,DS-56d48e2a-c9dc-4556-93c6-f30ecc2cdc8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33420,DS-a72b5f97-1565-4c76-8315-a95f0959e903,DISK], DatanodeInfoWithStorage[127.0.0.1:33977,DS-f0fca7ab-a17d-416d-b26e-fe8c02ef2152,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-508937718-172.17.0.21-1597725647811:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37093,DS-ac8fde6f-9239-49e5-97a2-3e8ad85a37e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40330,DS-2d051e5c-7925-4dba-b7ab-8bc5e63d33e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38313,DS-41f107ed-41a1-4ed1-a47d-5af3c3fa89e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45305,DS-93d2a9b8-3286-4f2c-a2de-df11a45146b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34876,DS-1ceff07d-87b9-45cc-bdd9-6aab272bb105,DISK], DatanodeInfoWithStorage[127.0.0.1:33394,DS-56d48e2a-c9dc-4556-93c6-f30ecc2cdc8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33420,DS-a72b5f97-1565-4c76-8315-a95f0959e903,DISK], DatanodeInfoWithStorage[127.0.0.1:33977,DS-f0fca7ab-a17d-416d-b26e-fe8c02ef2152,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-643206392-172.17.0.21-1597725985692:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43266,DS-81b2539f-be1e-4a40-ba1f-78a424d5da9c,DISK], DatanodeInfoWithStorage[127.0.0.1:36682,DS-c3d4cf43-b0d9-409e-81da-d1f940f248d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34024,DS-a6dbe4f6-6264-4555-b33a-0cfb4d38c2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35509,DS-7f58a7f4-2029-40f6-8619-436b98ddd78b,DISK], DatanodeInfoWithStorage[127.0.0.1:41452,DS-424b6bb7-4120-4619-bcfa-d66f29cd4232,DISK], DatanodeInfoWithStorage[127.0.0.1:38423,DS-12fc3036-c997-4e87-a702-5dc14db6e343,DISK], DatanodeInfoWithStorage[127.0.0.1:37856,DS-238aba2f-5531-425b-995a-06ffdb6c8ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:39279,DS-d7b9f225-d709-473c-adcc-c87ebb9374c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-643206392-172.17.0.21-1597725985692:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43266,DS-81b2539f-be1e-4a40-ba1f-78a424d5da9c,DISK], DatanodeInfoWithStorage[127.0.0.1:36682,DS-c3d4cf43-b0d9-409e-81da-d1f940f248d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34024,DS-a6dbe4f6-6264-4555-b33a-0cfb4d38c2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35509,DS-7f58a7f4-2029-40f6-8619-436b98ddd78b,DISK], DatanodeInfoWithStorage[127.0.0.1:41452,DS-424b6bb7-4120-4619-bcfa-d66f29cd4232,DISK], DatanodeInfoWithStorage[127.0.0.1:38423,DS-12fc3036-c997-4e87-a702-5dc14db6e343,DISK], DatanodeInfoWithStorage[127.0.0.1:37856,DS-238aba2f-5531-425b-995a-06ffdb6c8ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:39279,DS-d7b9f225-d709-473c-adcc-c87ebb9374c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1312511175-172.17.0.21-1597726121392:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41915,DS-09a1348d-7782-4185-a8cb-e9cb31b8b7c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34313,DS-641e1e8a-0a0b-4d72-8b26-8e3df6feee20,DISK], DatanodeInfoWithStorage[127.0.0.1:37770,DS-17c8a600-e492-47b1-903b-26f6d24f5ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:46738,DS-0dbb9dcd-00ce-41ad-8ab4-e628842600f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45991,DS-ab80186b-f2bb-4c02-8065-dee6806a7bce,DISK], DatanodeInfoWithStorage[127.0.0.1:38058,DS-74c01bbc-b859-4648-94c3-77ff87c570e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45375,DS-d61b26be-da3d-4d8b-a035-9d3a9a62a87f,DISK], DatanodeInfoWithStorage[127.0.0.1:46170,DS-8abec1bd-d61f-4de3-b0bd-1bfe7be29de0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1312511175-172.17.0.21-1597726121392:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41915,DS-09a1348d-7782-4185-a8cb-e9cb31b8b7c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34313,DS-641e1e8a-0a0b-4d72-8b26-8e3df6feee20,DISK], DatanodeInfoWithStorage[127.0.0.1:37770,DS-17c8a600-e492-47b1-903b-26f6d24f5ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:46738,DS-0dbb9dcd-00ce-41ad-8ab4-e628842600f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45991,DS-ab80186b-f2bb-4c02-8065-dee6806a7bce,DISK], DatanodeInfoWithStorage[127.0.0.1:38058,DS-74c01bbc-b859-4648-94c3-77ff87c570e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45375,DS-d61b26be-da3d-4d8b-a035-9d3a9a62a87f,DISK], DatanodeInfoWithStorage[127.0.0.1:46170,DS-8abec1bd-d61f-4de3-b0bd-1bfe7be29de0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-612310094-172.17.0.21-1597726238774:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45303,DS-39e55372-d096-4bec-9836-64729365df07,DISK], DatanodeInfoWithStorage[127.0.0.1:37781,DS-a53c545b-a294-42a1-a2b4-9254d8d0f68b,DISK], DatanodeInfoWithStorage[127.0.0.1:41475,DS-62f07e1e-9166-41d1-a904-5102002181f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35808,DS-437a6031-3a0d-4bac-8dca-91ff2af6f126,DISK], DatanodeInfoWithStorage[127.0.0.1:40430,DS-bbf92bf3-6557-4f17-bf3d-8418ea527173,DISK], DatanodeInfoWithStorage[127.0.0.1:42124,DS-08bbf835-74ef-46a7-8040-d7bf6c023251,DISK], DatanodeInfoWithStorage[127.0.0.1:46467,DS-0341dc3e-3649-40f0-8404-cae643614c90,DISK], DatanodeInfoWithStorage[127.0.0.1:43142,DS-28a41ada-536d-41e6-b00f-2a999580a1c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-612310094-172.17.0.21-1597726238774:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45303,DS-39e55372-d096-4bec-9836-64729365df07,DISK], DatanodeInfoWithStorage[127.0.0.1:37781,DS-a53c545b-a294-42a1-a2b4-9254d8d0f68b,DISK], DatanodeInfoWithStorage[127.0.0.1:41475,DS-62f07e1e-9166-41d1-a904-5102002181f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35808,DS-437a6031-3a0d-4bac-8dca-91ff2af6f126,DISK], DatanodeInfoWithStorage[127.0.0.1:40430,DS-bbf92bf3-6557-4f17-bf3d-8418ea527173,DISK], DatanodeInfoWithStorage[127.0.0.1:42124,DS-08bbf835-74ef-46a7-8040-d7bf6c023251,DISK], DatanodeInfoWithStorage[127.0.0.1:46467,DS-0341dc3e-3649-40f0-8404-cae643614c90,DISK], DatanodeInfoWithStorage[127.0.0.1:43142,DS-28a41ada-536d-41e6-b00f-2a999580a1c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-315671775-172.17.0.21-1597726868111:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35637,DS-47746282-c694-471e-84ee-ca2805d53aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:39373,DS-4eca189b-f5cf-403b-b0d0-b459085348f1,DISK], DatanodeInfoWithStorage[127.0.0.1:32998,DS-1451076e-2342-401e-b4b5-bdb82e2c6f39,DISK], DatanodeInfoWithStorage[127.0.0.1:33732,DS-06b2e3db-7af3-4bf2-9656-15816d996d14,DISK], DatanodeInfoWithStorage[127.0.0.1:45224,DS-1e70b4ce-1ddd-4ca6-807a-7489c0458e78,DISK], DatanodeInfoWithStorage[127.0.0.1:38458,DS-1a782f07-8614-4b92-b585-1c8b565851ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41274,DS-9f41e491-6261-4e88-a37c-972d61fe80a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39257,DS-ea2c6fe4-6a74-4d2c-85dd-886b5742a85e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-315671775-172.17.0.21-1597726868111:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35637,DS-47746282-c694-471e-84ee-ca2805d53aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:39373,DS-4eca189b-f5cf-403b-b0d0-b459085348f1,DISK], DatanodeInfoWithStorage[127.0.0.1:32998,DS-1451076e-2342-401e-b4b5-bdb82e2c6f39,DISK], DatanodeInfoWithStorage[127.0.0.1:33732,DS-06b2e3db-7af3-4bf2-9656-15816d996d14,DISK], DatanodeInfoWithStorage[127.0.0.1:45224,DS-1e70b4ce-1ddd-4ca6-807a-7489c0458e78,DISK], DatanodeInfoWithStorage[127.0.0.1:38458,DS-1a782f07-8614-4b92-b585-1c8b565851ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41274,DS-9f41e491-6261-4e88-a37c-972d61fe80a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39257,DS-ea2c6fe4-6a74-4d2c-85dd-886b5742a85e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-513869355-172.17.0.21-1597727161133:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41113,DS-9987c7af-2350-4c08-98b5-21b1d7352626,DISK], DatanodeInfoWithStorage[127.0.0.1:45416,DS-cb0ee04b-ea53-4c19-bf0f-0f2a6b627a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:46847,DS-b36c386a-529e-4b58-a8d3-af69e4c1e83a,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-127d448b-e858-4708-99dd-688845ea45ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34113,DS-92722ef2-7bb4-43d6-a41d-d322454e3e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:45130,DS-a2442662-edda-4f2e-ba67-a314e5318a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33766,DS-b34bf116-3d03-41bc-8f3d-5e31dc0d62e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36688,DS-f1197138-cc03-4e42-8cbc-c401b925eeca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-513869355-172.17.0.21-1597727161133:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41113,DS-9987c7af-2350-4c08-98b5-21b1d7352626,DISK], DatanodeInfoWithStorage[127.0.0.1:45416,DS-cb0ee04b-ea53-4c19-bf0f-0f2a6b627a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:46847,DS-b36c386a-529e-4b58-a8d3-af69e4c1e83a,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-127d448b-e858-4708-99dd-688845ea45ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34113,DS-92722ef2-7bb4-43d6-a41d-d322454e3e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:45130,DS-a2442662-edda-4f2e-ba67-a314e5318a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33766,DS-b34bf116-3d03-41bc-8f3d-5e31dc0d62e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36688,DS-f1197138-cc03-4e42-8cbc-c401b925eeca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1240115929-172.17.0.21-1597727195880:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43526,DS-0d94cd92-7319-49a7-a38a-61c06c49827d,DISK], DatanodeInfoWithStorage[127.0.0.1:40048,DS-a6a90dc8-cb43-4732-92c0-7f288f330cce,DISK], DatanodeInfoWithStorage[127.0.0.1:44605,DS-8c9efd0f-e1ee-408e-9392-7b05e9edd721,DISK], DatanodeInfoWithStorage[127.0.0.1:34739,DS-a0c10e4e-d95a-404f-a026-c97a4c1c26f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36300,DS-f1e30b25-60fc-45aa-99e9-4ab3c1bdd686,DISK], DatanodeInfoWithStorage[127.0.0.1:39927,DS-171e73a8-16e2-45e1-b1d3-c5d806290d09,DISK], DatanodeInfoWithStorage[127.0.0.1:40978,DS-1aba52e4-592c-4e93-b232-7f6abaa1e47d,DISK], DatanodeInfoWithStorage[127.0.0.1:41594,DS-e1038432-8f5a-404c-be90-83c2d59929c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1240115929-172.17.0.21-1597727195880:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43526,DS-0d94cd92-7319-49a7-a38a-61c06c49827d,DISK], DatanodeInfoWithStorage[127.0.0.1:40048,DS-a6a90dc8-cb43-4732-92c0-7f288f330cce,DISK], DatanodeInfoWithStorage[127.0.0.1:44605,DS-8c9efd0f-e1ee-408e-9392-7b05e9edd721,DISK], DatanodeInfoWithStorage[127.0.0.1:34739,DS-a0c10e4e-d95a-404f-a026-c97a4c1c26f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36300,DS-f1e30b25-60fc-45aa-99e9-4ab3c1bdd686,DISK], DatanodeInfoWithStorage[127.0.0.1:39927,DS-171e73a8-16e2-45e1-b1d3-c5d806290d09,DISK], DatanodeInfoWithStorage[127.0.0.1:40978,DS-1aba52e4-592c-4e93-b232-7f6abaa1e47d,DISK], DatanodeInfoWithStorage[127.0.0.1:41594,DS-e1038432-8f5a-404c-be90-83c2d59929c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2061697940-172.17.0.21-1597727571333:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33396,DS-d217409f-a5f9-4c84-b35a-b1c420a2d747,DISK], DatanodeInfoWithStorage[127.0.0.1:42799,DS-ee2b6b0b-94b0-4df1-a7bb-9543d64e7dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:42871,DS-fc0c1ce3-f12d-44e9-ac48-4a43b18fc429,DISK], DatanodeInfoWithStorage[127.0.0.1:38818,DS-1c5f0be2-9724-4b36-ab63-6dba6be0c080,DISK], DatanodeInfoWithStorage[127.0.0.1:42702,DS-12b279f2-e71a-4cf0-bf52-69080c3a9710,DISK], DatanodeInfoWithStorage[127.0.0.1:33740,DS-84c2ddaa-1fe7-4411-b560-518134f314ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43653,DS-1853f208-ba78-4c9d-ba00-994f80dd0271,DISK], DatanodeInfoWithStorage[127.0.0.1:40676,DS-69caea45-8b54-443d-96a1-b161a3410514,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2061697940-172.17.0.21-1597727571333:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33396,DS-d217409f-a5f9-4c84-b35a-b1c420a2d747,DISK], DatanodeInfoWithStorage[127.0.0.1:42799,DS-ee2b6b0b-94b0-4df1-a7bb-9543d64e7dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:42871,DS-fc0c1ce3-f12d-44e9-ac48-4a43b18fc429,DISK], DatanodeInfoWithStorage[127.0.0.1:38818,DS-1c5f0be2-9724-4b36-ab63-6dba6be0c080,DISK], DatanodeInfoWithStorage[127.0.0.1:42702,DS-12b279f2-e71a-4cf0-bf52-69080c3a9710,DISK], DatanodeInfoWithStorage[127.0.0.1:33740,DS-84c2ddaa-1fe7-4411-b560-518134f314ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43653,DS-1853f208-ba78-4c9d-ba00-994f80dd0271,DISK], DatanodeInfoWithStorage[127.0.0.1:40676,DS-69caea45-8b54-443d-96a1-b161a3410514,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-991209077-172.17.0.21-1597727853164:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36538,DS-7cf8fa2c-6c77-4a9e-aeed-c50ddaf6f9d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41250,DS-1fc21bee-a9c7-48f7-8b9c-acb8bcbef695,DISK], DatanodeInfoWithStorage[127.0.0.1:41205,DS-dc588db4-7821-473c-8613-0cefa98068ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35393,DS-a9f95b51-ef11-4a69-83d8-4dd10e0b0d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33005,DS-6a9fb8f7-8eb2-49f7-8aab-10f3ce941c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42932,DS-63018285-a540-437b-af01-b1880ad67fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:41805,DS-b8dab377-59fb-451d-8a5e-9bd9dd996598,DISK], DatanodeInfoWithStorage[127.0.0.1:41217,DS-50711f61-ede1-4c87-871e-95281c140d73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-991209077-172.17.0.21-1597727853164:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36538,DS-7cf8fa2c-6c77-4a9e-aeed-c50ddaf6f9d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41250,DS-1fc21bee-a9c7-48f7-8b9c-acb8bcbef695,DISK], DatanodeInfoWithStorage[127.0.0.1:41205,DS-dc588db4-7821-473c-8613-0cefa98068ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35393,DS-a9f95b51-ef11-4a69-83d8-4dd10e0b0d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33005,DS-6a9fb8f7-8eb2-49f7-8aab-10f3ce941c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42932,DS-63018285-a540-437b-af01-b1880ad67fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:41805,DS-b8dab377-59fb-451d-8a5e-9bd9dd996598,DISK], DatanodeInfoWithStorage[127.0.0.1:41217,DS-50711f61-ede1-4c87-871e-95281c140d73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-3753824-172.17.0.21-1597728512647:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34435,DS-e107a26f-6017-4702-8ba0-3968e2726f07,DISK], DatanodeInfoWithStorage[127.0.0.1:38972,DS-fa8022ff-664d-4bc1-9828-f72093972521,DISK], DatanodeInfoWithStorage[127.0.0.1:42461,DS-d0602450-bb51-495f-bf33-888775d368e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44157,DS-9cd8ffb2-c6ee-47c0-9001-fb8aed0677f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33642,DS-ce58178e-18a1-4e09-a26b-feac980e01bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38966,DS-6f5f3e73-e548-467e-b351-20b5de497bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:45989,DS-40d66656-31ec-47bb-989d-cb829905fad3,DISK], DatanodeInfoWithStorage[127.0.0.1:41048,DS-fedf9207-e190-4cba-8e42-511b41f039c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-3753824-172.17.0.21-1597728512647:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34435,DS-e107a26f-6017-4702-8ba0-3968e2726f07,DISK], DatanodeInfoWithStorage[127.0.0.1:38972,DS-fa8022ff-664d-4bc1-9828-f72093972521,DISK], DatanodeInfoWithStorage[127.0.0.1:42461,DS-d0602450-bb51-495f-bf33-888775d368e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44157,DS-9cd8ffb2-c6ee-47c0-9001-fb8aed0677f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33642,DS-ce58178e-18a1-4e09-a26b-feac980e01bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38966,DS-6f5f3e73-e548-467e-b351-20b5de497bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:45989,DS-40d66656-31ec-47bb-989d-cb829905fad3,DISK], DatanodeInfoWithStorage[127.0.0.1:41048,DS-fedf9207-e190-4cba-8e42-511b41f039c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5232
