reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1311014546-172.17.0.5-1597747525515:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42055,DS-b3a09b9e-f0fa-452c-9dd0-b6b34f3762e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38675,DS-bf933795-a6bf-45f1-9732-cd7b8f4edd73,DISK], DatanodeInfoWithStorage[127.0.0.1:40200,DS-ab8d8991-b2bb-40fb-b41b-80bd498ce631,DISK], DatanodeInfoWithStorage[127.0.0.1:43049,DS-6cd8ad98-31f5-4dc3-95e7-ed5296ecbc5e,DISK], DatanodeInfoWithStorage[127.0.0.1:43114,DS-8e2d813b-ffe3-4592-8fa6-32e3c8a5f9b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38123,DS-82224f12-bbf6-420f-a059-e691aa57e9fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-5c95b2cf-2b11-443f-95dc-5ef13a7d1662,DISK], DatanodeInfoWithStorage[127.0.0.1:41874,DS-9db8aa44-4220-49ac-b24d-3b8f598f027b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1311014546-172.17.0.5-1597747525515:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42055,DS-b3a09b9e-f0fa-452c-9dd0-b6b34f3762e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38675,DS-bf933795-a6bf-45f1-9732-cd7b8f4edd73,DISK], DatanodeInfoWithStorage[127.0.0.1:40200,DS-ab8d8991-b2bb-40fb-b41b-80bd498ce631,DISK], DatanodeInfoWithStorage[127.0.0.1:43049,DS-6cd8ad98-31f5-4dc3-95e7-ed5296ecbc5e,DISK], DatanodeInfoWithStorage[127.0.0.1:43114,DS-8e2d813b-ffe3-4592-8fa6-32e3c8a5f9b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38123,DS-82224f12-bbf6-420f-a059-e691aa57e9fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-5c95b2cf-2b11-443f-95dc-5ef13a7d1662,DISK], DatanodeInfoWithStorage[127.0.0.1:41874,DS-9db8aa44-4220-49ac-b24d-3b8f598f027b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-359681533-172.17.0.5-1597747847160:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44652,DS-b08ad9dc-370a-4aab-b488-7711d007a50d,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-46e5ebf8-b907-431d-88ed-c919b71bd20b,DISK], DatanodeInfoWithStorage[127.0.0.1:33699,DS-ec8a380e-10c5-43f5-98fc-e0a5844a57c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35818,DS-fb944f18-95db-47fb-8be8-aab651c977e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34639,DS-49e47e87-1752-47f4-b67d-7fb095069e62,DISK], DatanodeInfoWithStorage[127.0.0.1:46524,DS-fc4ad376-b953-4e04-b95c-ea6a32ce84aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44026,DS-f669534a-ab08-4057-8dae-7dd8c85ee228,DISK], DatanodeInfoWithStorage[127.0.0.1:43874,DS-c1b41246-355e-44c3-a37c-8df0e1dfb384,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-359681533-172.17.0.5-1597747847160:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44652,DS-b08ad9dc-370a-4aab-b488-7711d007a50d,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-46e5ebf8-b907-431d-88ed-c919b71bd20b,DISK], DatanodeInfoWithStorage[127.0.0.1:33699,DS-ec8a380e-10c5-43f5-98fc-e0a5844a57c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35818,DS-fb944f18-95db-47fb-8be8-aab651c977e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34639,DS-49e47e87-1752-47f4-b67d-7fb095069e62,DISK], DatanodeInfoWithStorage[127.0.0.1:46524,DS-fc4ad376-b953-4e04-b95c-ea6a32ce84aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44026,DS-f669534a-ab08-4057-8dae-7dd8c85ee228,DISK], DatanodeInfoWithStorage[127.0.0.1:43874,DS-c1b41246-355e-44c3-a37c-8df0e1dfb384,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1390802210-172.17.0.5-1597748143567:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40312,DS-94004eb8-cd7f-458c-a747-f0829b77f82f,DISK], DatanodeInfoWithStorage[127.0.0.1:44576,DS-71b4d6e3-dc41-423c-b4e4-22f4bb00e95c,DISK], DatanodeInfoWithStorage[127.0.0.1:40695,DS-e84e9724-81e6-4a15-871f-7aca9247e440,DISK], DatanodeInfoWithStorage[127.0.0.1:35950,DS-31a1c041-0a99-4986-a05b-57b97863a939,DISK], DatanodeInfoWithStorage[127.0.0.1:33290,DS-2c87b125-3b6a-4c24-8f7d-755fe514cd93,DISK], DatanodeInfoWithStorage[127.0.0.1:46691,DS-b02ec3a5-3dc7-4c52-a2ca-9343109e2fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:37786,DS-fb7cb118-2272-4b4c-b982-44f1acf53e55,DISK], DatanodeInfoWithStorage[127.0.0.1:42451,DS-b5ad2101-cf06-4fdb-a4a1-6bb01ed58b17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1390802210-172.17.0.5-1597748143567:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40312,DS-94004eb8-cd7f-458c-a747-f0829b77f82f,DISK], DatanodeInfoWithStorage[127.0.0.1:44576,DS-71b4d6e3-dc41-423c-b4e4-22f4bb00e95c,DISK], DatanodeInfoWithStorage[127.0.0.1:40695,DS-e84e9724-81e6-4a15-871f-7aca9247e440,DISK], DatanodeInfoWithStorage[127.0.0.1:35950,DS-31a1c041-0a99-4986-a05b-57b97863a939,DISK], DatanodeInfoWithStorage[127.0.0.1:33290,DS-2c87b125-3b6a-4c24-8f7d-755fe514cd93,DISK], DatanodeInfoWithStorage[127.0.0.1:46691,DS-b02ec3a5-3dc7-4c52-a2ca-9343109e2fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:37786,DS-fb7cb118-2272-4b4c-b982-44f1acf53e55,DISK], DatanodeInfoWithStorage[127.0.0.1:42451,DS-b5ad2101-cf06-4fdb-a4a1-6bb01ed58b17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1614610522-172.17.0.5-1597748407228:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41222,DS-4520fa77-694c-46a9-9d25-d380669b535e,DISK], DatanodeInfoWithStorage[127.0.0.1:37351,DS-08d68f42-3294-4256-951b-048a00348444,DISK], DatanodeInfoWithStorage[127.0.0.1:39131,DS-7c3720dd-2bdb-4d34-9978-fcf1455f61a1,DISK], DatanodeInfoWithStorage[127.0.0.1:32828,DS-c18c5c0e-7829-4aed-9967-c76a84b5e7fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40808,DS-d60ec9a7-23dc-495d-8abd-e660b48a90f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35786,DS-66e04d1e-e07d-4f3f-8cc6-9215d9d6e31b,DISK], DatanodeInfoWithStorage[127.0.0.1:44340,DS-718a2923-3220-46a3-89ee-75a6284ed989,DISK], DatanodeInfoWithStorage[127.0.0.1:44081,DS-efb2c118-29bf-4734-83d4-e73ec348243b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1614610522-172.17.0.5-1597748407228:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41222,DS-4520fa77-694c-46a9-9d25-d380669b535e,DISK], DatanodeInfoWithStorage[127.0.0.1:37351,DS-08d68f42-3294-4256-951b-048a00348444,DISK], DatanodeInfoWithStorage[127.0.0.1:39131,DS-7c3720dd-2bdb-4d34-9978-fcf1455f61a1,DISK], DatanodeInfoWithStorage[127.0.0.1:32828,DS-c18c5c0e-7829-4aed-9967-c76a84b5e7fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40808,DS-d60ec9a7-23dc-495d-8abd-e660b48a90f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35786,DS-66e04d1e-e07d-4f3f-8cc6-9215d9d6e31b,DISK], DatanodeInfoWithStorage[127.0.0.1:44340,DS-718a2923-3220-46a3-89ee-75a6284ed989,DISK], DatanodeInfoWithStorage[127.0.0.1:44081,DS-efb2c118-29bf-4734-83d4-e73ec348243b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1345712188-172.17.0.5-1597748478602:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37774,DS-47c95ea7-4b83-4a12-bc23-8991769071b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46602,DS-2ac41a6d-f3ca-4f52-a9d0-87c89461eecc,DISK], DatanodeInfoWithStorage[127.0.0.1:39293,DS-7c3f61d8-f954-40b6-a10e-340dc5f8f427,DISK], DatanodeInfoWithStorage[127.0.0.1:38031,DS-9c034bc7-fcc7-4cff-920b-be0861f75083,DISK], DatanodeInfoWithStorage[127.0.0.1:34015,DS-17f47245-8838-4dce-91e4-886da31e8c23,DISK], DatanodeInfoWithStorage[127.0.0.1:33834,DS-75f9b6de-1b7a-43e9-9eab-414e993229ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39650,DS-ecc11759-ceda-46fb-898a-c9d7e32d20df,DISK], DatanodeInfoWithStorage[127.0.0.1:39057,DS-f11dca98-2475-472f-84da-435fe002a4e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1345712188-172.17.0.5-1597748478602:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37774,DS-47c95ea7-4b83-4a12-bc23-8991769071b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46602,DS-2ac41a6d-f3ca-4f52-a9d0-87c89461eecc,DISK], DatanodeInfoWithStorage[127.0.0.1:39293,DS-7c3f61d8-f954-40b6-a10e-340dc5f8f427,DISK], DatanodeInfoWithStorage[127.0.0.1:38031,DS-9c034bc7-fcc7-4cff-920b-be0861f75083,DISK], DatanodeInfoWithStorage[127.0.0.1:34015,DS-17f47245-8838-4dce-91e4-886da31e8c23,DISK], DatanodeInfoWithStorage[127.0.0.1:33834,DS-75f9b6de-1b7a-43e9-9eab-414e993229ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39650,DS-ecc11759-ceda-46fb-898a-c9d7e32d20df,DISK], DatanodeInfoWithStorage[127.0.0.1:39057,DS-f11dca98-2475-472f-84da-435fe002a4e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-638797100-172.17.0.5-1597748891603:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43123,DS-f4402e09-9057-447e-973c-ddf2f7152f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38568,DS-3616a92f-3cfd-4d92-987c-7945c89cfce2,DISK], DatanodeInfoWithStorage[127.0.0.1:34246,DS-16d83906-d9a2-4e4d-888a-cf50a7b9e59f,DISK], DatanodeInfoWithStorage[127.0.0.1:35027,DS-5c4bdae3-31ef-4521-9240-494efe11f90f,DISK], DatanodeInfoWithStorage[127.0.0.1:35121,DS-83641707-9405-407e-8a99-f069e22dcc5a,DISK], DatanodeInfoWithStorage[127.0.0.1:44898,DS-e1a9b8a6-8b5f-4372-b506-f7149bfc79bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42496,DS-1686fc6c-335c-48f3-8ac8-769a21facd73,DISK], DatanodeInfoWithStorage[127.0.0.1:41214,DS-d9a75dd5-9ccb-43a0-8a38-091cf5854f3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-638797100-172.17.0.5-1597748891603:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43123,DS-f4402e09-9057-447e-973c-ddf2f7152f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38568,DS-3616a92f-3cfd-4d92-987c-7945c89cfce2,DISK], DatanodeInfoWithStorage[127.0.0.1:34246,DS-16d83906-d9a2-4e4d-888a-cf50a7b9e59f,DISK], DatanodeInfoWithStorage[127.0.0.1:35027,DS-5c4bdae3-31ef-4521-9240-494efe11f90f,DISK], DatanodeInfoWithStorage[127.0.0.1:35121,DS-83641707-9405-407e-8a99-f069e22dcc5a,DISK], DatanodeInfoWithStorage[127.0.0.1:44898,DS-e1a9b8a6-8b5f-4372-b506-f7149bfc79bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42496,DS-1686fc6c-335c-48f3-8ac8-769a21facd73,DISK], DatanodeInfoWithStorage[127.0.0.1:41214,DS-d9a75dd5-9ccb-43a0-8a38-091cf5854f3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2126891453-172.17.0.5-1597749152629:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44196,DS-a16a5e1f-cb49-404b-82e9-5edd315e1bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:41322,DS-50e60d85-b27f-4e7d-a5a8-cfb023edea72,DISK], DatanodeInfoWithStorage[127.0.0.1:33689,DS-3bceef22-e718-4a1e-a4f3-e898c7cd4880,DISK], DatanodeInfoWithStorage[127.0.0.1:39565,DS-e53d115a-3dab-4180-8d74-c2f3211a8f87,DISK], DatanodeInfoWithStorage[127.0.0.1:36726,DS-39af59c2-35e2-43c2-a454-5b007f7bfc18,DISK], DatanodeInfoWithStorage[127.0.0.1:43917,DS-ae6dc98c-9175-420d-ac16-845e4f99cc21,DISK], DatanodeInfoWithStorage[127.0.0.1:38768,DS-dee39c7c-2bcb-4157-a0c0-783aaf4ddf13,DISK], DatanodeInfoWithStorage[127.0.0.1:44441,DS-e6d5f284-3322-47b3-b636-1d135bf5b542,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2126891453-172.17.0.5-1597749152629:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44196,DS-a16a5e1f-cb49-404b-82e9-5edd315e1bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:41322,DS-50e60d85-b27f-4e7d-a5a8-cfb023edea72,DISK], DatanodeInfoWithStorage[127.0.0.1:33689,DS-3bceef22-e718-4a1e-a4f3-e898c7cd4880,DISK], DatanodeInfoWithStorage[127.0.0.1:39565,DS-e53d115a-3dab-4180-8d74-c2f3211a8f87,DISK], DatanodeInfoWithStorage[127.0.0.1:36726,DS-39af59c2-35e2-43c2-a454-5b007f7bfc18,DISK], DatanodeInfoWithStorage[127.0.0.1:43917,DS-ae6dc98c-9175-420d-ac16-845e4f99cc21,DISK], DatanodeInfoWithStorage[127.0.0.1:38768,DS-dee39c7c-2bcb-4157-a0c0-783aaf4ddf13,DISK], DatanodeInfoWithStorage[127.0.0.1:44441,DS-e6d5f284-3322-47b3-b636-1d135bf5b542,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1876854261-172.17.0.5-1597749716927:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35478,DS-3e754290-3e1e-489f-a208-97d78744df4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42325,DS-076839c5-8628-4353-9c49-c85e57d64b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:41933,DS-c7af38f8-f9c2-4e7b-90c8-ad32641124f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37082,DS-2b66329c-200a-423f-ae7e-08aae08346bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42769,DS-ef6cb8e1-c7d5-461e-900b-26bcbe06972c,DISK], DatanodeInfoWithStorage[127.0.0.1:41586,DS-c398f4ec-570f-47b7-8abe-118b2d03acdc,DISK], DatanodeInfoWithStorage[127.0.0.1:35859,DS-3fc94d9b-cc16-4fbd-94cd-22c98ea9fc86,DISK], DatanodeInfoWithStorage[127.0.0.1:36655,DS-b12cfe2c-9fa0-403b-b3e6-a6d1cf090113,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1876854261-172.17.0.5-1597749716927:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35478,DS-3e754290-3e1e-489f-a208-97d78744df4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42325,DS-076839c5-8628-4353-9c49-c85e57d64b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:41933,DS-c7af38f8-f9c2-4e7b-90c8-ad32641124f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37082,DS-2b66329c-200a-423f-ae7e-08aae08346bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42769,DS-ef6cb8e1-c7d5-461e-900b-26bcbe06972c,DISK], DatanodeInfoWithStorage[127.0.0.1:41586,DS-c398f4ec-570f-47b7-8abe-118b2d03acdc,DISK], DatanodeInfoWithStorage[127.0.0.1:35859,DS-3fc94d9b-cc16-4fbd-94cd-22c98ea9fc86,DISK], DatanodeInfoWithStorage[127.0.0.1:36655,DS-b12cfe2c-9fa0-403b-b3e6-a6d1cf090113,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-862748768-172.17.0.5-1597749899442:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41300,DS-2647665b-8468-43a0-a3d0-d6188dbc3b39,DISK], DatanodeInfoWithStorage[127.0.0.1:41171,DS-7aaa7b38-1604-4cc5-a84e-d5a5c8d8b68a,DISK], DatanodeInfoWithStorage[127.0.0.1:42093,DS-36aaca3f-2cb4-4720-a3d8-a84fa943e89d,DISK], DatanodeInfoWithStorage[127.0.0.1:40110,DS-a254b867-1ed0-4cec-b03d-d5902f53b9af,DISK], DatanodeInfoWithStorage[127.0.0.1:38595,DS-5c5cc6b6-1598-49cd-9172-d516b8d449ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38663,DS-ce0811cb-b0ee-4a3f-85e1-cf3c1d05b158,DISK], DatanodeInfoWithStorage[127.0.0.1:33161,DS-03439476-1e00-47ee-951b-6af5ac7dfce0,DISK], DatanodeInfoWithStorage[127.0.0.1:39030,DS-6ffa95e6-8b0d-461e-be02-bf4658e1882e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-862748768-172.17.0.5-1597749899442:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41300,DS-2647665b-8468-43a0-a3d0-d6188dbc3b39,DISK], DatanodeInfoWithStorage[127.0.0.1:41171,DS-7aaa7b38-1604-4cc5-a84e-d5a5c8d8b68a,DISK], DatanodeInfoWithStorage[127.0.0.1:42093,DS-36aaca3f-2cb4-4720-a3d8-a84fa943e89d,DISK], DatanodeInfoWithStorage[127.0.0.1:40110,DS-a254b867-1ed0-4cec-b03d-d5902f53b9af,DISK], DatanodeInfoWithStorage[127.0.0.1:38595,DS-5c5cc6b6-1598-49cd-9172-d516b8d449ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38663,DS-ce0811cb-b0ee-4a3f-85e1-cf3c1d05b158,DISK], DatanodeInfoWithStorage[127.0.0.1:33161,DS-03439476-1e00-47ee-951b-6af5ac7dfce0,DISK], DatanodeInfoWithStorage[127.0.0.1:39030,DS-6ffa95e6-8b0d-461e-be02-bf4658e1882e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-12628196-172.17.0.5-1597750791816:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43251,DS-e97f8f36-b2fa-4c97-a619-4394763b2dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:46235,DS-ebe52808-8c7a-40c3-a1c6-0eade789dfc5,DISK], DatanodeInfoWithStorage[127.0.0.1:39411,DS-44ac3f32-a531-49ae-ac2a-39bb3328a90f,DISK], DatanodeInfoWithStorage[127.0.0.1:38448,DS-c815b5b6-d69a-4c81-9ba4-2757b7b2243e,DISK], DatanodeInfoWithStorage[127.0.0.1:43012,DS-4352978e-d73f-4b88-944e-459cbb2ae0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34173,DS-724d7dbd-8997-43ee-9559-5761481e1bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:45584,DS-b2f10167-d512-43b4-9e69-abd97359a655,DISK], DatanodeInfoWithStorage[127.0.0.1:46280,DS-62d4027c-c3f1-438b-b90a-3206eecc47ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-12628196-172.17.0.5-1597750791816:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43251,DS-e97f8f36-b2fa-4c97-a619-4394763b2dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:46235,DS-ebe52808-8c7a-40c3-a1c6-0eade789dfc5,DISK], DatanodeInfoWithStorage[127.0.0.1:39411,DS-44ac3f32-a531-49ae-ac2a-39bb3328a90f,DISK], DatanodeInfoWithStorage[127.0.0.1:38448,DS-c815b5b6-d69a-4c81-9ba4-2757b7b2243e,DISK], DatanodeInfoWithStorage[127.0.0.1:43012,DS-4352978e-d73f-4b88-944e-459cbb2ae0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34173,DS-724d7dbd-8997-43ee-9559-5761481e1bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:45584,DS-b2f10167-d512-43b4-9e69-abd97359a655,DISK], DatanodeInfoWithStorage[127.0.0.1:46280,DS-62d4027c-c3f1-438b-b90a-3206eecc47ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 4 out of 50
result: might be true error
Total execution time in seconds : 5515
