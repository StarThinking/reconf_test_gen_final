reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-943744831-172.17.0.14-1597751851850:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44991,DS-0d1391f2-430b-44c9-8e70-7767d2f88991,DISK], DatanodeInfoWithStorage[127.0.0.1:43304,DS-3c15553d-fa50-4a49-aef6-e2e642238c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:45936,DS-3bfeb377-e339-47b5-9170-4ac92ee26394,DISK], DatanodeInfoWithStorage[127.0.0.1:46296,DS-79b67ebe-d4fb-4d27-95bf-d6ba821888e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42975,DS-c1b2b669-00c8-4559-a2ce-afcfa068a130,DISK], DatanodeInfoWithStorage[127.0.0.1:39746,DS-7c7d6274-7308-4401-833a-d8c690fd31b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39549,DS-f5cfd1c9-12f8-4cc3-8b92-bb84460a2dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:41263,DS-14b1ae32-644f-4b5b-b090-7f0d88fe1fb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-943744831-172.17.0.14-1597751851850:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44991,DS-0d1391f2-430b-44c9-8e70-7767d2f88991,DISK], DatanodeInfoWithStorage[127.0.0.1:43304,DS-3c15553d-fa50-4a49-aef6-e2e642238c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:45936,DS-3bfeb377-e339-47b5-9170-4ac92ee26394,DISK], DatanodeInfoWithStorage[127.0.0.1:46296,DS-79b67ebe-d4fb-4d27-95bf-d6ba821888e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42975,DS-c1b2b669-00c8-4559-a2ce-afcfa068a130,DISK], DatanodeInfoWithStorage[127.0.0.1:39746,DS-7c7d6274-7308-4401-833a-d8c690fd31b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39549,DS-f5cfd1c9-12f8-4cc3-8b92-bb84460a2dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:41263,DS-14b1ae32-644f-4b5b-b090-7f0d88fe1fb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1612006287-172.17.0.14-1597752125694:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33225,DS-0b05acc2-22ca-454b-a848-f4cc14c2555f,DISK], DatanodeInfoWithStorage[127.0.0.1:40997,DS-2615b69b-f30d-4844-bd76-120c53f10324,DISK], DatanodeInfoWithStorage[127.0.0.1:34110,DS-1491c7ed-af97-4bb6-881b-949ccd4f2d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39940,DS-4f24c9c8-de42-4de1-bbfd-932c0e57e896,DISK], DatanodeInfoWithStorage[127.0.0.1:35076,DS-391d1d33-87ed-45d8-afdb-995bdee09a37,DISK], DatanodeInfoWithStorage[127.0.0.1:38920,DS-13925d0d-c5ff-4a93-830a-e3bbde4c4a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:46332,DS-fc450ad4-7c5b-4280-a8fe-dda5409558a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44780,DS-d891442a-331a-4cd3-8f61-7e4118d41824,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1612006287-172.17.0.14-1597752125694:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33225,DS-0b05acc2-22ca-454b-a848-f4cc14c2555f,DISK], DatanodeInfoWithStorage[127.0.0.1:40997,DS-2615b69b-f30d-4844-bd76-120c53f10324,DISK], DatanodeInfoWithStorage[127.0.0.1:34110,DS-1491c7ed-af97-4bb6-881b-949ccd4f2d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39940,DS-4f24c9c8-de42-4de1-bbfd-932c0e57e896,DISK], DatanodeInfoWithStorage[127.0.0.1:35076,DS-391d1d33-87ed-45d8-afdb-995bdee09a37,DISK], DatanodeInfoWithStorage[127.0.0.1:38920,DS-13925d0d-c5ff-4a93-830a-e3bbde4c4a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:46332,DS-fc450ad4-7c5b-4280-a8fe-dda5409558a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44780,DS-d891442a-331a-4cd3-8f61-7e4118d41824,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-640051184-172.17.0.14-1597752639968:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35259,DS-0dddb506-e4d8-44f3-92db-a441436191d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34137,DS-186f2aff-989e-43ac-b09c-e73f639161ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38864,DS-33e20254-2ab7-4beb-bc44-4690274b9972,DISK], DatanodeInfoWithStorage[127.0.0.1:46473,DS-1e88eeaf-48bd-44af-8a1d-6db7ddba6cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:33913,DS-84176b89-cc0b-415a-954f-786e32c7999a,DISK], DatanodeInfoWithStorage[127.0.0.1:44096,DS-50f9ab19-c206-4631-ab08-95414b6b346e,DISK], DatanodeInfoWithStorage[127.0.0.1:43607,DS-298c0537-b0b9-4ea7-bbb3-8022e4c91a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:36870,DS-31a6caf6-45f4-4daf-b691-e22ceabdd475,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-640051184-172.17.0.14-1597752639968:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35259,DS-0dddb506-e4d8-44f3-92db-a441436191d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34137,DS-186f2aff-989e-43ac-b09c-e73f639161ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38864,DS-33e20254-2ab7-4beb-bc44-4690274b9972,DISK], DatanodeInfoWithStorage[127.0.0.1:46473,DS-1e88eeaf-48bd-44af-8a1d-6db7ddba6cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:33913,DS-84176b89-cc0b-415a-954f-786e32c7999a,DISK], DatanodeInfoWithStorage[127.0.0.1:44096,DS-50f9ab19-c206-4631-ab08-95414b6b346e,DISK], DatanodeInfoWithStorage[127.0.0.1:43607,DS-298c0537-b0b9-4ea7-bbb3-8022e4c91a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:36870,DS-31a6caf6-45f4-4daf-b691-e22ceabdd475,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-69853602-172.17.0.14-1597753232568:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35741,DS-036c7c88-17e6-4a51-8bee-5e001c82929a,DISK], DatanodeInfoWithStorage[127.0.0.1:33133,DS-089acd8d-3e6b-49e2-b4ab-8bb68b92cf70,DISK], DatanodeInfoWithStorage[127.0.0.1:42109,DS-fbd5d5a9-d05c-47f6-9080-e693f74b8d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:37769,DS-0724493e-170d-4be1-a0e0-bbd1624964fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34422,DS-0d52009a-68b7-47e7-a5e1-aac53ae68247,DISK], DatanodeInfoWithStorage[127.0.0.1:35039,DS-171d733a-2bc9-4ba8-8f84-a7b649e4018b,DISK], DatanodeInfoWithStorage[127.0.0.1:42076,DS-0e8ad4af-a158-4040-98ba-ca1f4a7a98b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46707,DS-5cc0a5a8-14f0-4644-872f-c2a9e96d96ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-69853602-172.17.0.14-1597753232568:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35741,DS-036c7c88-17e6-4a51-8bee-5e001c82929a,DISK], DatanodeInfoWithStorage[127.0.0.1:33133,DS-089acd8d-3e6b-49e2-b4ab-8bb68b92cf70,DISK], DatanodeInfoWithStorage[127.0.0.1:42109,DS-fbd5d5a9-d05c-47f6-9080-e693f74b8d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:37769,DS-0724493e-170d-4be1-a0e0-bbd1624964fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34422,DS-0d52009a-68b7-47e7-a5e1-aac53ae68247,DISK], DatanodeInfoWithStorage[127.0.0.1:35039,DS-171d733a-2bc9-4ba8-8f84-a7b649e4018b,DISK], DatanodeInfoWithStorage[127.0.0.1:42076,DS-0e8ad4af-a158-4040-98ba-ca1f4a7a98b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46707,DS-5cc0a5a8-14f0-4644-872f-c2a9e96d96ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-806060153-172.17.0.14-1597753337974:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41096,DS-7739dd13-97fd-420a-a5ad-db7dd91841da,DISK], DatanodeInfoWithStorage[127.0.0.1:43305,DS-a59579da-9c61-48aa-a225-9f0fce49dd05,DISK], DatanodeInfoWithStorage[127.0.0.1:35455,DS-4645e70f-beb9-43b1-905e-e38e4dabdd99,DISK], DatanodeInfoWithStorage[127.0.0.1:38018,DS-0f8092c3-19d9-45df-bc26-cb9d7d3116a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41866,DS-031972a5-fdf9-4d45-9cc2-790aa5f192dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44767,DS-10cc3494-ecd9-4b12-8d10-e6d682a39236,DISK], DatanodeInfoWithStorage[127.0.0.1:33699,DS-e9906f05-be02-480f-a5e1-b174992dc475,DISK], DatanodeInfoWithStorage[127.0.0.1:45322,DS-8f3eb273-992f-4fb8-b919-e4444def0e57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-806060153-172.17.0.14-1597753337974:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41096,DS-7739dd13-97fd-420a-a5ad-db7dd91841da,DISK], DatanodeInfoWithStorage[127.0.0.1:43305,DS-a59579da-9c61-48aa-a225-9f0fce49dd05,DISK], DatanodeInfoWithStorage[127.0.0.1:35455,DS-4645e70f-beb9-43b1-905e-e38e4dabdd99,DISK], DatanodeInfoWithStorage[127.0.0.1:38018,DS-0f8092c3-19d9-45df-bc26-cb9d7d3116a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41866,DS-031972a5-fdf9-4d45-9cc2-790aa5f192dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44767,DS-10cc3494-ecd9-4b12-8d10-e6d682a39236,DISK], DatanodeInfoWithStorage[127.0.0.1:33699,DS-e9906f05-be02-480f-a5e1-b174992dc475,DISK], DatanodeInfoWithStorage[127.0.0.1:45322,DS-8f3eb273-992f-4fb8-b919-e4444def0e57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1273547939-172.17.0.14-1597753477240:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38569,DS-5afc923a-0c4c-40e9-85d4-5df1ec22cfce,DISK], DatanodeInfoWithStorage[127.0.0.1:35158,DS-e23fa3cc-51c4-4f40-ad80-6e8b0396fa03,DISK], DatanodeInfoWithStorage[127.0.0.1:33274,DS-3f003b46-5bee-4736-875c-4e0c780cc607,DISK], DatanodeInfoWithStorage[127.0.0.1:36086,DS-ba7a5d7b-f345-42fc-abe3-186cfbe86a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39366,DS-2ddfce1d-afca-48ea-b636-9ac6b5322e07,DISK], DatanodeInfoWithStorage[127.0.0.1:45973,DS-e834b32f-246d-481d-a4b7-70b850997b79,DISK], DatanodeInfoWithStorage[127.0.0.1:46795,DS-3bec3a13-d671-4c4d-90da-aa424819e31c,DISK], DatanodeInfoWithStorage[127.0.0.1:33706,DS-247873c2-2e52-4a2b-b45d-d2f80a5eb2b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1273547939-172.17.0.14-1597753477240:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38569,DS-5afc923a-0c4c-40e9-85d4-5df1ec22cfce,DISK], DatanodeInfoWithStorage[127.0.0.1:35158,DS-e23fa3cc-51c4-4f40-ad80-6e8b0396fa03,DISK], DatanodeInfoWithStorage[127.0.0.1:33274,DS-3f003b46-5bee-4736-875c-4e0c780cc607,DISK], DatanodeInfoWithStorage[127.0.0.1:36086,DS-ba7a5d7b-f345-42fc-abe3-186cfbe86a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39366,DS-2ddfce1d-afca-48ea-b636-9ac6b5322e07,DISK], DatanodeInfoWithStorage[127.0.0.1:45973,DS-e834b32f-246d-481d-a4b7-70b850997b79,DISK], DatanodeInfoWithStorage[127.0.0.1:46795,DS-3bec3a13-d671-4c4d-90da-aa424819e31c,DISK], DatanodeInfoWithStorage[127.0.0.1:33706,DS-247873c2-2e52-4a2b-b45d-d2f80a5eb2b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-931265595-172.17.0.14-1597754380743:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36598,DS-a47faef1-f885-451b-b3b9-a0daace37047,DISK], DatanodeInfoWithStorage[127.0.0.1:35248,DS-18b9f171-4911-4821-8ab6-971d5ab574dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37079,DS-f5cd1c27-673d-46f9-923a-c0fec40eac84,DISK], DatanodeInfoWithStorage[127.0.0.1:46240,DS-1be2e1b7-f19f-43fe-a3e1-ee935ca4c989,DISK], DatanodeInfoWithStorage[127.0.0.1:36286,DS-b86839ce-1c08-43f7-9394-5cd9c5930491,DISK], DatanodeInfoWithStorage[127.0.0.1:35938,DS-f2173cee-6142-4183-97a7-7c610d6c692a,DISK], DatanodeInfoWithStorage[127.0.0.1:42493,DS-1a7e7225-a113-48bf-ae05-029615593b83,DISK], DatanodeInfoWithStorage[127.0.0.1:35833,DS-266780c5-83e9-473e-9731-2e81b78f1e6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-931265595-172.17.0.14-1597754380743:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36598,DS-a47faef1-f885-451b-b3b9-a0daace37047,DISK], DatanodeInfoWithStorage[127.0.0.1:35248,DS-18b9f171-4911-4821-8ab6-971d5ab574dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37079,DS-f5cd1c27-673d-46f9-923a-c0fec40eac84,DISK], DatanodeInfoWithStorage[127.0.0.1:46240,DS-1be2e1b7-f19f-43fe-a3e1-ee935ca4c989,DISK], DatanodeInfoWithStorage[127.0.0.1:36286,DS-b86839ce-1c08-43f7-9394-5cd9c5930491,DISK], DatanodeInfoWithStorage[127.0.0.1:35938,DS-f2173cee-6142-4183-97a7-7c610d6c692a,DISK], DatanodeInfoWithStorage[127.0.0.1:42493,DS-1a7e7225-a113-48bf-ae05-029615593b83,DISK], DatanodeInfoWithStorage[127.0.0.1:35833,DS-266780c5-83e9-473e-9731-2e81b78f1e6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1485318338-172.17.0.14-1597754486771:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38299,DS-0e4ed0c2-2a5d-4669-9d15-a2c2d7f6ea60,DISK], DatanodeInfoWithStorage[127.0.0.1:41179,DS-9370e374-916a-4538-a724-4c80cf2a65e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45575,DS-4a746e91-b918-4b10-8273-6b4374b02c15,DISK], DatanodeInfoWithStorage[127.0.0.1:40088,DS-864b19f0-dad5-49ad-ab05-5796f05642f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45367,DS-c2da0070-a1dc-4838-bc83-d60e8aa7c30f,DISK], DatanodeInfoWithStorage[127.0.0.1:46730,DS-bd438820-0b11-468b-9608-43ba151f3195,DISK], DatanodeInfoWithStorage[127.0.0.1:44581,DS-b4ff891b-60ea-4e39-9cc4-039b7ebcacf2,DISK], DatanodeInfoWithStorage[127.0.0.1:44933,DS-d938b7c9-a26a-42da-8ba3-a7f59b2d5f31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1485318338-172.17.0.14-1597754486771:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38299,DS-0e4ed0c2-2a5d-4669-9d15-a2c2d7f6ea60,DISK], DatanodeInfoWithStorage[127.0.0.1:41179,DS-9370e374-916a-4538-a724-4c80cf2a65e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45575,DS-4a746e91-b918-4b10-8273-6b4374b02c15,DISK], DatanodeInfoWithStorage[127.0.0.1:40088,DS-864b19f0-dad5-49ad-ab05-5796f05642f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45367,DS-c2da0070-a1dc-4838-bc83-d60e8aa7c30f,DISK], DatanodeInfoWithStorage[127.0.0.1:46730,DS-bd438820-0b11-468b-9608-43ba151f3195,DISK], DatanodeInfoWithStorage[127.0.0.1:44581,DS-b4ff891b-60ea-4e39-9cc4-039b7ebcacf2,DISK], DatanodeInfoWithStorage[127.0.0.1:44933,DS-d938b7c9-a26a-42da-8ba3-a7f59b2d5f31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-345542761-172.17.0.14-1597755511785:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37020,DS-786e974f-5fe8-44e3-8afd-3dda4b4d21a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45721,DS-7ecf2c83-32aa-4d64-8ab9-cd50a6a7f085,DISK], DatanodeInfoWithStorage[127.0.0.1:46058,DS-248a6316-03f0-48b9-ae69-30aeebe42b15,DISK], DatanodeInfoWithStorage[127.0.0.1:44536,DS-b403ddb7-9154-4479-96b9-f1a5c317f320,DISK], DatanodeInfoWithStorage[127.0.0.1:35108,DS-73e5a4f3-9665-4d44-aeb4-6642a0341a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43468,DS-ad9b1b0c-5644-4bdc-b93d-1a3e4f93cefe,DISK], DatanodeInfoWithStorage[127.0.0.1:44723,DS-9007d1c7-0d1a-4bb2-a593-6461d4c76fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:34433,DS-043b108d-da68-46ea-98d6-03d20a471ca0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-345542761-172.17.0.14-1597755511785:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37020,DS-786e974f-5fe8-44e3-8afd-3dda4b4d21a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45721,DS-7ecf2c83-32aa-4d64-8ab9-cd50a6a7f085,DISK], DatanodeInfoWithStorage[127.0.0.1:46058,DS-248a6316-03f0-48b9-ae69-30aeebe42b15,DISK], DatanodeInfoWithStorage[127.0.0.1:44536,DS-b403ddb7-9154-4479-96b9-f1a5c317f320,DISK], DatanodeInfoWithStorage[127.0.0.1:35108,DS-73e5a4f3-9665-4d44-aeb4-6642a0341a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43468,DS-ad9b1b0c-5644-4bdc-b93d-1a3e4f93cefe,DISK], DatanodeInfoWithStorage[127.0.0.1:44723,DS-9007d1c7-0d1a-4bb2-a593-6461d4c76fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:34433,DS-043b108d-da68-46ea-98d6-03d20a471ca0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-180857581-172.17.0.14-1597755625226:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37094,DS-fd1f113f-0860-43de-aaf4-70a899ad7f67,DISK], DatanodeInfoWithStorage[127.0.0.1:45065,DS-e2ce75a6-ae19-4681-bbc0-fe92680754ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36645,DS-4319cba5-7b79-43da-83da-e05685838e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42518,DS-739ada8d-43e6-4a5f-9501-8f893b1091a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39269,DS-5782b6b3-6a38-4174-8b77-54c79a94454b,DISK], DatanodeInfoWithStorage[127.0.0.1:35768,DS-82fefef1-6de6-49e5-89af-bafda95591bc,DISK], DatanodeInfoWithStorage[127.0.0.1:32869,DS-46543904-f68e-480f-8d69-02b7938aab79,DISK], DatanodeInfoWithStorage[127.0.0.1:33055,DS-8fc5c322-e2b8-490c-a007-e5ac1fc5afa6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-180857581-172.17.0.14-1597755625226:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37094,DS-fd1f113f-0860-43de-aaf4-70a899ad7f67,DISK], DatanodeInfoWithStorage[127.0.0.1:45065,DS-e2ce75a6-ae19-4681-bbc0-fe92680754ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36645,DS-4319cba5-7b79-43da-83da-e05685838e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42518,DS-739ada8d-43e6-4a5f-9501-8f893b1091a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39269,DS-5782b6b3-6a38-4174-8b77-54c79a94454b,DISK], DatanodeInfoWithStorage[127.0.0.1:35768,DS-82fefef1-6de6-49e5-89af-bafda95591bc,DISK], DatanodeInfoWithStorage[127.0.0.1:32869,DS-46543904-f68e-480f-8d69-02b7938aab79,DISK], DatanodeInfoWithStorage[127.0.0.1:33055,DS-8fc5c322-e2b8-490c-a007-e5ac1fc5afa6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1071496406-172.17.0.14-1597755735213:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37045,DS-6aed3877-2257-4430-8df2-de4f3718a344,DISK], DatanodeInfoWithStorage[127.0.0.1:41868,DS-f40b503d-be44-4a37-a1e7-cbd18fa7a178,DISK], DatanodeInfoWithStorage[127.0.0.1:33368,DS-7828960e-5f12-44b6-9c6d-d590e388ce77,DISK], DatanodeInfoWithStorage[127.0.0.1:42671,DS-38af3c14-7b53-4463-a5ea-5f15574230e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40567,DS-9d6c5fd5-e8c5-45d2-9880-18d771a62c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44364,DS-034fc46a-d73b-4acc-b3ca-6f5d1abcb5d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43865,DS-7df65e1e-109d-4771-84ff-ad0eb58cc1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41822,DS-b0c812a8-e02e-433e-b150-fa31d7c6311b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1071496406-172.17.0.14-1597755735213:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37045,DS-6aed3877-2257-4430-8df2-de4f3718a344,DISK], DatanodeInfoWithStorage[127.0.0.1:41868,DS-f40b503d-be44-4a37-a1e7-cbd18fa7a178,DISK], DatanodeInfoWithStorage[127.0.0.1:33368,DS-7828960e-5f12-44b6-9c6d-d590e388ce77,DISK], DatanodeInfoWithStorage[127.0.0.1:42671,DS-38af3c14-7b53-4463-a5ea-5f15574230e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40567,DS-9d6c5fd5-e8c5-45d2-9880-18d771a62c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44364,DS-034fc46a-d73b-4acc-b3ca-6f5d1abcb5d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43865,DS-7df65e1e-109d-4771-84ff-ad0eb58cc1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41822,DS-b0c812a8-e02e-433e-b150-fa31d7c6311b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-172964322-172.17.0.14-1597755774465:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34588,DS-0d71e22c-b558-428b-817d-c0a6621ebb96,DISK], DatanodeInfoWithStorage[127.0.0.1:42664,DS-50159086-abf5-46ba-aae6-9e4428b3ad46,DISK], DatanodeInfoWithStorage[127.0.0.1:33123,DS-c3b559f5-de08-4970-9e19-8aed333d86ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38409,DS-d35c82b1-a81f-4e7d-8031-e091719a75f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33558,DS-8e120417-fbfc-4ec0-a8ed-935101239297,DISK], DatanodeInfoWithStorage[127.0.0.1:42666,DS-8d7ab7d5-f320-48cd-b8b8-08865ade4f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:44014,DS-9d974c3e-6e48-4302-a608-e32b99810f24,DISK], DatanodeInfoWithStorage[127.0.0.1:46205,DS-9e1f6a6b-6817-4679-87ae-9cfe39fbdaad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-172964322-172.17.0.14-1597755774465:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34588,DS-0d71e22c-b558-428b-817d-c0a6621ebb96,DISK], DatanodeInfoWithStorage[127.0.0.1:42664,DS-50159086-abf5-46ba-aae6-9e4428b3ad46,DISK], DatanodeInfoWithStorage[127.0.0.1:33123,DS-c3b559f5-de08-4970-9e19-8aed333d86ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38409,DS-d35c82b1-a81f-4e7d-8031-e091719a75f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33558,DS-8e120417-fbfc-4ec0-a8ed-935101239297,DISK], DatanodeInfoWithStorage[127.0.0.1:42666,DS-8d7ab7d5-f320-48cd-b8b8-08865ade4f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:44014,DS-9d974c3e-6e48-4302-a608-e32b99810f24,DISK], DatanodeInfoWithStorage[127.0.0.1:46205,DS-9e1f6a6b-6817-4679-87ae-9cfe39fbdaad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-186161136-172.17.0.14-1597755846881:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41539,DS-5e7e068f-55f4-42e6-80b2-f88fe0e59a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:34574,DS-2be95e20-2940-4fa6-bc4b-6f9ae30e8ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:34467,DS-95d02399-887c-47bb-b643-1f17d136af97,DISK], DatanodeInfoWithStorage[127.0.0.1:36383,DS-d5b238ca-59d3-42b0-978f-194fbfa51e05,DISK], DatanodeInfoWithStorage[127.0.0.1:44397,DS-d1e225f2-a4bf-43dd-89f4-7ed46d88edad,DISK], DatanodeInfoWithStorage[127.0.0.1:42585,DS-9215aa90-ee1f-446d-a68a-eb2f19baaffa,DISK], DatanodeInfoWithStorage[127.0.0.1:41886,DS-0c30201d-9197-404e-b439-af68472f4d25,DISK], DatanodeInfoWithStorage[127.0.0.1:34621,DS-6def4fde-d047-4d89-b190-9d4a6bcb0ccf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-186161136-172.17.0.14-1597755846881:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41539,DS-5e7e068f-55f4-42e6-80b2-f88fe0e59a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:34574,DS-2be95e20-2940-4fa6-bc4b-6f9ae30e8ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:34467,DS-95d02399-887c-47bb-b643-1f17d136af97,DISK], DatanodeInfoWithStorage[127.0.0.1:36383,DS-d5b238ca-59d3-42b0-978f-194fbfa51e05,DISK], DatanodeInfoWithStorage[127.0.0.1:44397,DS-d1e225f2-a4bf-43dd-89f4-7ed46d88edad,DISK], DatanodeInfoWithStorage[127.0.0.1:42585,DS-9215aa90-ee1f-446d-a68a-eb2f19baaffa,DISK], DatanodeInfoWithStorage[127.0.0.1:41886,DS-0c30201d-9197-404e-b439-af68472f4d25,DISK], DatanodeInfoWithStorage[127.0.0.1:34621,DS-6def4fde-d047-4d89-b190-9d4a6bcb0ccf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2050174519-172.17.0.14-1597755965784:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43282,DS-6afbfc5b-1dbc-4db1-a42b-7da64cda13d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45165,DS-8ff4a7e1-d796-481b-ac24-93fa0eb30504,DISK], DatanodeInfoWithStorage[127.0.0.1:37067,DS-0773d329-6128-4859-a549-9f99ec576665,DISK], DatanodeInfoWithStorage[127.0.0.1:34279,DS-d3630af5-5484-4002-832c-a35f78b0b486,DISK], DatanodeInfoWithStorage[127.0.0.1:39788,DS-4dc347d5-c7d0-4ad0-bc5d-7df00adb15f9,DISK], DatanodeInfoWithStorage[127.0.0.1:32769,DS-7e5b45db-4322-4745-90d9-3ba925251ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:44294,DS-93e4eea2-5769-4d15-a10a-6d7d8cf6733f,DISK], DatanodeInfoWithStorage[127.0.0.1:34931,DS-11a1e536-ad1a-4294-98d1-d49be29d7a45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2050174519-172.17.0.14-1597755965784:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43282,DS-6afbfc5b-1dbc-4db1-a42b-7da64cda13d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45165,DS-8ff4a7e1-d796-481b-ac24-93fa0eb30504,DISK], DatanodeInfoWithStorage[127.0.0.1:37067,DS-0773d329-6128-4859-a549-9f99ec576665,DISK], DatanodeInfoWithStorage[127.0.0.1:34279,DS-d3630af5-5484-4002-832c-a35f78b0b486,DISK], DatanodeInfoWithStorage[127.0.0.1:39788,DS-4dc347d5-c7d0-4ad0-bc5d-7df00adb15f9,DISK], DatanodeInfoWithStorage[127.0.0.1:32769,DS-7e5b45db-4322-4745-90d9-3ba925251ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:44294,DS-93e4eea2-5769-4d15-a10a-6d7d8cf6733f,DISK], DatanodeInfoWithStorage[127.0.0.1:34931,DS-11a1e536-ad1a-4294-98d1-d49be29d7a45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-152222676-172.17.0.14-1597756257787:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41029,DS-130677bf-2075-47d2-b273-e53aaf3d8be4,DISK], DatanodeInfoWithStorage[127.0.0.1:45496,DS-65c09c08-a69d-4978-a2b3-d3d5627756e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39579,DS-751668e7-a770-4f3e-881e-88784a488c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33803,DS-1722b1cf-7b6e-445d-8c68-7ee2b618530f,DISK], DatanodeInfoWithStorage[127.0.0.1:45790,DS-ea01301a-2958-4493-a72d-c88e1cd49851,DISK], DatanodeInfoWithStorage[127.0.0.1:42794,DS-65b6b2ce-69d5-4c68-b086-b0469678ac70,DISK], DatanodeInfoWithStorage[127.0.0.1:46624,DS-c90efdab-2935-423b-9102-565dfc78ca3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34498,DS-74f64ee0-7953-4d6f-b0da-5cff11a426e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-152222676-172.17.0.14-1597756257787:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41029,DS-130677bf-2075-47d2-b273-e53aaf3d8be4,DISK], DatanodeInfoWithStorage[127.0.0.1:45496,DS-65c09c08-a69d-4978-a2b3-d3d5627756e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39579,DS-751668e7-a770-4f3e-881e-88784a488c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33803,DS-1722b1cf-7b6e-445d-8c68-7ee2b618530f,DISK], DatanodeInfoWithStorage[127.0.0.1:45790,DS-ea01301a-2958-4493-a72d-c88e1cd49851,DISK], DatanodeInfoWithStorage[127.0.0.1:42794,DS-65b6b2ce-69d5-4c68-b086-b0469678ac70,DISK], DatanodeInfoWithStorage[127.0.0.1:46624,DS-c90efdab-2935-423b-9102-565dfc78ca3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34498,DS-74f64ee0-7953-4d6f-b0da-5cff11a426e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1008414683-172.17.0.14-1597756375029:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36230,DS-3841d68e-542a-4912-89b5-2d6f0d9d8f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:42766,DS-18b6e25e-01ea-47f7-8f86-eef3e251d51d,DISK], DatanodeInfoWithStorage[127.0.0.1:39042,DS-d7beba38-dca6-4912-8e69-86ecbfd44117,DISK], DatanodeInfoWithStorage[127.0.0.1:36181,DS-3ea97caf-5419-4069-b086-30d88567d01c,DISK], DatanodeInfoWithStorage[127.0.0.1:32856,DS-cdf915a8-7054-4db1-98bd-e4168a04906b,DISK], DatanodeInfoWithStorage[127.0.0.1:36172,DS-41546c1e-f69d-41da-8afc-91b992665ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:44575,DS-10cc269f-5775-4642-b050-4fd920b6ff13,DISK], DatanodeInfoWithStorage[127.0.0.1:41393,DS-270c6032-0cdc-44b1-8226-daf27edb64dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1008414683-172.17.0.14-1597756375029:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36230,DS-3841d68e-542a-4912-89b5-2d6f0d9d8f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:42766,DS-18b6e25e-01ea-47f7-8f86-eef3e251d51d,DISK], DatanodeInfoWithStorage[127.0.0.1:39042,DS-d7beba38-dca6-4912-8e69-86ecbfd44117,DISK], DatanodeInfoWithStorage[127.0.0.1:36181,DS-3ea97caf-5419-4069-b086-30d88567d01c,DISK], DatanodeInfoWithStorage[127.0.0.1:32856,DS-cdf915a8-7054-4db1-98bd-e4168a04906b,DISK], DatanodeInfoWithStorage[127.0.0.1:36172,DS-41546c1e-f69d-41da-8afc-91b992665ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:44575,DS-10cc269f-5775-4642-b050-4fd920b6ff13,DISK], DatanodeInfoWithStorage[127.0.0.1:41393,DS-270c6032-0cdc-44b1-8226-daf27edb64dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1896541426-172.17.0.14-1597756618902:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46854,DS-3df2ba2a-01ff-4464-ad63-8790719e9748,DISK], DatanodeInfoWithStorage[127.0.0.1:46580,DS-911faa6a-ccdd-4451-b2c1-0d6ac107e45e,DISK], DatanodeInfoWithStorage[127.0.0.1:40006,DS-2157e402-0781-4e98-a163-c25a54e6e38d,DISK], DatanodeInfoWithStorage[127.0.0.1:34576,DS-3dfe0240-20a4-4e17-8262-16c59570d8c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44990,DS-2b8b69ca-400d-444d-9063-947d37b9b288,DISK], DatanodeInfoWithStorage[127.0.0.1:41304,DS-082ecabe-b829-4c29-9743-31c16b6f8304,DISK], DatanodeInfoWithStorage[127.0.0.1:36839,DS-01086e58-9e2b-4212-8128-d56e2c41eb6e,DISK], DatanodeInfoWithStorage[127.0.0.1:43055,DS-93aa891b-a29d-40ec-87aa-4e37d276dbd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1896541426-172.17.0.14-1597756618902:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46854,DS-3df2ba2a-01ff-4464-ad63-8790719e9748,DISK], DatanodeInfoWithStorage[127.0.0.1:46580,DS-911faa6a-ccdd-4451-b2c1-0d6ac107e45e,DISK], DatanodeInfoWithStorage[127.0.0.1:40006,DS-2157e402-0781-4e98-a163-c25a54e6e38d,DISK], DatanodeInfoWithStorage[127.0.0.1:34576,DS-3dfe0240-20a4-4e17-8262-16c59570d8c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44990,DS-2b8b69ca-400d-444d-9063-947d37b9b288,DISK], DatanodeInfoWithStorage[127.0.0.1:41304,DS-082ecabe-b829-4c29-9743-31c16b6f8304,DISK], DatanodeInfoWithStorage[127.0.0.1:36839,DS-01086e58-9e2b-4212-8128-d56e2c41eb6e,DISK], DatanodeInfoWithStorage[127.0.0.1:43055,DS-93aa891b-a29d-40ec-87aa-4e37d276dbd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-708157925-172.17.0.14-1597757097402:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38132,DS-38538cef-0d45-4ad2-b977-fb35328f08e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43891,DS-afa55dc1-9ed0-4a68-8be5-689aceafdbe8,DISK], DatanodeInfoWithStorage[127.0.0.1:33829,DS-28ef4ad6-f138-4271-9a36-94b60224b41b,DISK], DatanodeInfoWithStorage[127.0.0.1:37460,DS-6d375aa1-1c23-460c-b00e-7a6aa15dcb5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34079,DS-ecb98294-0bd3-4352-b00a-0c83655f693b,DISK], DatanodeInfoWithStorage[127.0.0.1:43872,DS-985ae231-8f85-48f7-a6b5-cc49878a4b03,DISK], DatanodeInfoWithStorage[127.0.0.1:33337,DS-77453feb-a975-43f1-91d8-49396c20b2c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38026,DS-7423e633-c640-4d19-b0ba-e53e49ad40a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-708157925-172.17.0.14-1597757097402:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38132,DS-38538cef-0d45-4ad2-b977-fb35328f08e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43891,DS-afa55dc1-9ed0-4a68-8be5-689aceafdbe8,DISK], DatanodeInfoWithStorage[127.0.0.1:33829,DS-28ef4ad6-f138-4271-9a36-94b60224b41b,DISK], DatanodeInfoWithStorage[127.0.0.1:37460,DS-6d375aa1-1c23-460c-b00e-7a6aa15dcb5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34079,DS-ecb98294-0bd3-4352-b00a-0c83655f693b,DISK], DatanodeInfoWithStorage[127.0.0.1:43872,DS-985ae231-8f85-48f7-a6b5-cc49878a4b03,DISK], DatanodeInfoWithStorage[127.0.0.1:33337,DS-77453feb-a975-43f1-91d8-49396c20b2c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38026,DS-7423e633-c640-4d19-b0ba-e53e49ad40a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5463
