reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2142086369-172.17.0.2-1597668570493:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34178,DS-897ca190-69a6-4723-924c-f71d58250d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:44435,DS-5d9af898-2af0-4827-95ba-66410d933fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:44064,DS-73380bbf-6025-4a66-a311-520b24b2b1d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44030,DS-88e9cddb-e204-470f-addc-da0972fbe44f,DISK], DatanodeInfoWithStorage[127.0.0.1:41190,DS-154c6b70-0cae-4b89-8b91-460ad7a69a21,DISK], DatanodeInfoWithStorage[127.0.0.1:46284,DS-53b9356b-588a-486f-a2a2-44abbac02c00,DISK], DatanodeInfoWithStorage[127.0.0.1:33753,DS-c7fa8ce5-166a-41a1-8fbb-170e307cce20,DISK], DatanodeInfoWithStorage[127.0.0.1:34082,DS-0fdd099b-f1c9-479c-a1c5-3b7af530affe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2142086369-172.17.0.2-1597668570493:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34178,DS-897ca190-69a6-4723-924c-f71d58250d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:44435,DS-5d9af898-2af0-4827-95ba-66410d933fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:44064,DS-73380bbf-6025-4a66-a311-520b24b2b1d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44030,DS-88e9cddb-e204-470f-addc-da0972fbe44f,DISK], DatanodeInfoWithStorage[127.0.0.1:41190,DS-154c6b70-0cae-4b89-8b91-460ad7a69a21,DISK], DatanodeInfoWithStorage[127.0.0.1:46284,DS-53b9356b-588a-486f-a2a2-44abbac02c00,DISK], DatanodeInfoWithStorage[127.0.0.1:33753,DS-c7fa8ce5-166a-41a1-8fbb-170e307cce20,DISK], DatanodeInfoWithStorage[127.0.0.1:34082,DS-0fdd099b-f1c9-479c-a1c5-3b7af530affe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1462557380-172.17.0.2-1597668759890:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45111,DS-3bf9ec8d-718f-473c-ba84-8b68a6812958,DISK], DatanodeInfoWithStorage[127.0.0.1:38588,DS-67c89f15-22be-4489-bb1c-4e7fe45a7568,DISK], DatanodeInfoWithStorage[127.0.0.1:40579,DS-b861f226-aac0-448f-9480-e5504c0adada,DISK], DatanodeInfoWithStorage[127.0.0.1:32998,DS-1217d983-6bf5-469c-be6d-18af17d20c31,DISK], DatanodeInfoWithStorage[127.0.0.1:37675,DS-b06092bf-1fb7-45fa-8e6e-343dee1da6fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37148,DS-8742ed74-d71b-46a0-9b1b-35e59a079226,DISK], DatanodeInfoWithStorage[127.0.0.1:45148,DS-f8b7d433-6437-4ec4-9d16-516bd9fb963c,DISK], DatanodeInfoWithStorage[127.0.0.1:37337,DS-e03929c3-85e6-4acd-9538-b33bff1ee8cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1462557380-172.17.0.2-1597668759890:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45111,DS-3bf9ec8d-718f-473c-ba84-8b68a6812958,DISK], DatanodeInfoWithStorage[127.0.0.1:38588,DS-67c89f15-22be-4489-bb1c-4e7fe45a7568,DISK], DatanodeInfoWithStorage[127.0.0.1:40579,DS-b861f226-aac0-448f-9480-e5504c0adada,DISK], DatanodeInfoWithStorage[127.0.0.1:32998,DS-1217d983-6bf5-469c-be6d-18af17d20c31,DISK], DatanodeInfoWithStorage[127.0.0.1:37675,DS-b06092bf-1fb7-45fa-8e6e-343dee1da6fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37148,DS-8742ed74-d71b-46a0-9b1b-35e59a079226,DISK], DatanodeInfoWithStorage[127.0.0.1:45148,DS-f8b7d433-6437-4ec4-9d16-516bd9fb963c,DISK], DatanodeInfoWithStorage[127.0.0.1:37337,DS-e03929c3-85e6-4acd-9538-b33bff1ee8cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-720853794-172.17.0.2-1597669152063:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40383,DS-3ad49714-b5b9-45f1-8921-3f711dff7582,DISK], DatanodeInfoWithStorage[127.0.0.1:46441,DS-f6ce4e3f-9c04-4a0b-9a12-b3badd01bf95,DISK], DatanodeInfoWithStorage[127.0.0.1:35213,DS-264a922a-2314-4510-81e8-55bef01e8c20,DISK], DatanodeInfoWithStorage[127.0.0.1:39251,DS-0d8653ea-3f4f-41c6-b397-81940bfa0ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:42045,DS-9df2023f-1687-4b0e-9bdb-9a945092ba27,DISK], DatanodeInfoWithStorage[127.0.0.1:43244,DS-ce458adb-87f7-4adc-9d06-c2c78ef5d49b,DISK], DatanodeInfoWithStorage[127.0.0.1:45254,DS-7ce196f9-ee39-4ae7-80df-d15a20fc6c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39007,DS-8f110b24-6e9e-4fc1-a13b-69dbec2ec249,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-720853794-172.17.0.2-1597669152063:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40383,DS-3ad49714-b5b9-45f1-8921-3f711dff7582,DISK], DatanodeInfoWithStorage[127.0.0.1:46441,DS-f6ce4e3f-9c04-4a0b-9a12-b3badd01bf95,DISK], DatanodeInfoWithStorage[127.0.0.1:35213,DS-264a922a-2314-4510-81e8-55bef01e8c20,DISK], DatanodeInfoWithStorage[127.0.0.1:39251,DS-0d8653ea-3f4f-41c6-b397-81940bfa0ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:42045,DS-9df2023f-1687-4b0e-9bdb-9a945092ba27,DISK], DatanodeInfoWithStorage[127.0.0.1:43244,DS-ce458adb-87f7-4adc-9d06-c2c78ef5d49b,DISK], DatanodeInfoWithStorage[127.0.0.1:45254,DS-7ce196f9-ee39-4ae7-80df-d15a20fc6c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39007,DS-8f110b24-6e9e-4fc1-a13b-69dbec2ec249,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-657000642-172.17.0.2-1597669231639:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39246,DS-1424ae99-1fe9-4137-88ec-13f67e971ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:42443,DS-04b75534-808d-4dc3-adab-919baf596ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:41867,DS-448116da-6b42-44aa-93e6-8472f8cc1545,DISK], DatanodeInfoWithStorage[127.0.0.1:33663,DS-e175e4e9-9831-4fba-9e4c-bcc76c05c3e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34538,DS-c2f96a20-3424-444a-a4d4-cdbf30948981,DISK], DatanodeInfoWithStorage[127.0.0.1:33547,DS-74f3a824-2141-4e47-b8b4-353946ffda67,DISK], DatanodeInfoWithStorage[127.0.0.1:40272,DS-3b85ce5e-780c-480f-94f3-2ecca26905a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35509,DS-ef7fa05a-de9b-4100-8cb2-348f4c991436,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-657000642-172.17.0.2-1597669231639:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39246,DS-1424ae99-1fe9-4137-88ec-13f67e971ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:42443,DS-04b75534-808d-4dc3-adab-919baf596ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:41867,DS-448116da-6b42-44aa-93e6-8472f8cc1545,DISK], DatanodeInfoWithStorage[127.0.0.1:33663,DS-e175e4e9-9831-4fba-9e4c-bcc76c05c3e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34538,DS-c2f96a20-3424-444a-a4d4-cdbf30948981,DISK], DatanodeInfoWithStorage[127.0.0.1:33547,DS-74f3a824-2141-4e47-b8b4-353946ffda67,DISK], DatanodeInfoWithStorage[127.0.0.1:40272,DS-3b85ce5e-780c-480f-94f3-2ecca26905a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35509,DS-ef7fa05a-de9b-4100-8cb2-348f4c991436,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-688202895-172.17.0.2-1597669319683:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32995,DS-f9466ca0-9b1c-42d3-b708-b7c4a9478624,DISK], DatanodeInfoWithStorage[127.0.0.1:36542,DS-52884c79-d56b-4bf1-8875-962a9dd71fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:45869,DS-d3f275c9-9a7f-456f-869d-79c465c3db0a,DISK], DatanodeInfoWithStorage[127.0.0.1:39870,DS-18373668-071e-4bd9-bdb5-67f63b1da569,DISK], DatanodeInfoWithStorage[127.0.0.1:42539,DS-d4518a40-f9a6-48bd-9471-6c1d41318481,DISK], DatanodeInfoWithStorage[127.0.0.1:38043,DS-68a37c96-49ce-4065-bc98-9a3571a0fcc7,DISK], DatanodeInfoWithStorage[127.0.0.1:45424,DS-6d6a6e46-e33a-41dd-a9b6-57b267fe304b,DISK], DatanodeInfoWithStorage[127.0.0.1:35105,DS-5ce59c7d-a57d-4a00-af49-a58cf3eae1ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-688202895-172.17.0.2-1597669319683:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32995,DS-f9466ca0-9b1c-42d3-b708-b7c4a9478624,DISK], DatanodeInfoWithStorage[127.0.0.1:36542,DS-52884c79-d56b-4bf1-8875-962a9dd71fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:45869,DS-d3f275c9-9a7f-456f-869d-79c465c3db0a,DISK], DatanodeInfoWithStorage[127.0.0.1:39870,DS-18373668-071e-4bd9-bdb5-67f63b1da569,DISK], DatanodeInfoWithStorage[127.0.0.1:42539,DS-d4518a40-f9a6-48bd-9471-6c1d41318481,DISK], DatanodeInfoWithStorage[127.0.0.1:38043,DS-68a37c96-49ce-4065-bc98-9a3571a0fcc7,DISK], DatanodeInfoWithStorage[127.0.0.1:45424,DS-6d6a6e46-e33a-41dd-a9b6-57b267fe304b,DISK], DatanodeInfoWithStorage[127.0.0.1:35105,DS-5ce59c7d-a57d-4a00-af49-a58cf3eae1ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1785233777-172.17.0.2-1597669678417:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39702,DS-c4eab498-d863-402b-a2f5-b967f9ce5fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:34560,DS-75909ea9-cb40-47d9-9b51-4d2af8764cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:44804,DS-f4323908-3416-43b3-9f33-4e141b6e90f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41122,DS-5dee5ab0-0de9-437d-a6d5-552c0d7c1345,DISK], DatanodeInfoWithStorage[127.0.0.1:36917,DS-8f9a64de-0210-44d3-829e-dd1dca7ad5e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35198,DS-786a081b-478c-4f12-9e8a-5d2e735d0b20,DISK], DatanodeInfoWithStorage[127.0.0.1:44328,DS-33650644-9e17-476b-bdae-398941ef06ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38236,DS-ab636c38-81cd-4a5b-8185-14e2efd6b3b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1785233777-172.17.0.2-1597669678417:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39702,DS-c4eab498-d863-402b-a2f5-b967f9ce5fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:34560,DS-75909ea9-cb40-47d9-9b51-4d2af8764cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:44804,DS-f4323908-3416-43b3-9f33-4e141b6e90f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41122,DS-5dee5ab0-0de9-437d-a6d5-552c0d7c1345,DISK], DatanodeInfoWithStorage[127.0.0.1:36917,DS-8f9a64de-0210-44d3-829e-dd1dca7ad5e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35198,DS-786a081b-478c-4f12-9e8a-5d2e735d0b20,DISK], DatanodeInfoWithStorage[127.0.0.1:44328,DS-33650644-9e17-476b-bdae-398941ef06ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38236,DS-ab636c38-81cd-4a5b-8185-14e2efd6b3b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-744080434-172.17.0.2-1597670064997:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38433,DS-1398ffa1-4d18-4fde-b8d1-4d63f8824f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:46764,DS-7e841d51-dc70-4596-b05a-3ca4625e76fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45222,DS-ea6e25fc-5d95-4152-b57e-e65c1623bc2d,DISK], DatanodeInfoWithStorage[127.0.0.1:35187,DS-25f41976-4a45-4ec4-8784-8deb25d697f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36931,DS-48e1c304-d989-4f55-8dbb-0b488233c39f,DISK], DatanodeInfoWithStorage[127.0.0.1:38508,DS-cb70d565-382d-4940-a0db-b26288569cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:41115,DS-ba9d97f6-1302-4a3e-9226-efbdf768f84d,DISK], DatanodeInfoWithStorage[127.0.0.1:37394,DS-849c9cac-5537-4be9-92e5-8beefebab8a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-744080434-172.17.0.2-1597670064997:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38433,DS-1398ffa1-4d18-4fde-b8d1-4d63f8824f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:46764,DS-7e841d51-dc70-4596-b05a-3ca4625e76fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45222,DS-ea6e25fc-5d95-4152-b57e-e65c1623bc2d,DISK], DatanodeInfoWithStorage[127.0.0.1:35187,DS-25f41976-4a45-4ec4-8784-8deb25d697f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36931,DS-48e1c304-d989-4f55-8dbb-0b488233c39f,DISK], DatanodeInfoWithStorage[127.0.0.1:38508,DS-cb70d565-382d-4940-a0db-b26288569cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:41115,DS-ba9d97f6-1302-4a3e-9226-efbdf768f84d,DISK], DatanodeInfoWithStorage[127.0.0.1:37394,DS-849c9cac-5537-4be9-92e5-8beefebab8a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-217807614-172.17.0.2-1597670113470:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33512,DS-e3085447-b0b5-4333-b309-b9f331a05178,DISK], DatanodeInfoWithStorage[127.0.0.1:43310,DS-70be8202-e591-4b51-bc5f-c286a227dcbf,DISK], DatanodeInfoWithStorage[127.0.0.1:40931,DS-16f29b6e-a163-4593-b41e-f1ae7cf6e620,DISK], DatanodeInfoWithStorage[127.0.0.1:39241,DS-008cd2e7-7c80-4919-9666-b36fb66e90c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37241,DS-baab3f13-331f-4ff6-9d90-854176951a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35050,DS-262873b4-4d3b-4b93-98ed-8b2c602cdf07,DISK], DatanodeInfoWithStorage[127.0.0.1:44833,DS-7238b037-c95e-43c6-aea4-bc1075671a10,DISK], DatanodeInfoWithStorage[127.0.0.1:45576,DS-36bb91ad-bd5b-4731-98d4-3304a04429ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-217807614-172.17.0.2-1597670113470:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33512,DS-e3085447-b0b5-4333-b309-b9f331a05178,DISK], DatanodeInfoWithStorage[127.0.0.1:43310,DS-70be8202-e591-4b51-bc5f-c286a227dcbf,DISK], DatanodeInfoWithStorage[127.0.0.1:40931,DS-16f29b6e-a163-4593-b41e-f1ae7cf6e620,DISK], DatanodeInfoWithStorage[127.0.0.1:39241,DS-008cd2e7-7c80-4919-9666-b36fb66e90c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37241,DS-baab3f13-331f-4ff6-9d90-854176951a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35050,DS-262873b4-4d3b-4b93-98ed-8b2c602cdf07,DISK], DatanodeInfoWithStorage[127.0.0.1:44833,DS-7238b037-c95e-43c6-aea4-bc1075671a10,DISK], DatanodeInfoWithStorage[127.0.0.1:45576,DS-36bb91ad-bd5b-4731-98d4-3304a04429ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-770565906-172.17.0.2-1597670151867:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32816,DS-a8d92b5f-9c83-4003-afca-26b1634c6f01,DISK], DatanodeInfoWithStorage[127.0.0.1:36561,DS-33149910-88f2-4e88-a7e3-b8471d3e0851,DISK], DatanodeInfoWithStorage[127.0.0.1:42357,DS-ab135b1a-ce52-4a72-89b8-3b5f7cfa57bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36612,DS-8165bda1-65b3-424b-b4a4-611a1b743565,DISK], DatanodeInfoWithStorage[127.0.0.1:39187,DS-11310c49-dcf1-41ad-8eb5-dabe7b25cdc1,DISK], DatanodeInfoWithStorage[127.0.0.1:35602,DS-b243ca90-26a7-4c8d-be00-78b41f0d36e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37476,DS-b175833f-0215-427a-a58d-bffd9bc6ec6f,DISK], DatanodeInfoWithStorage[127.0.0.1:39364,DS-c4e786dc-6566-4860-851d-5f27c2a50a33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-770565906-172.17.0.2-1597670151867:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32816,DS-a8d92b5f-9c83-4003-afca-26b1634c6f01,DISK], DatanodeInfoWithStorage[127.0.0.1:36561,DS-33149910-88f2-4e88-a7e3-b8471d3e0851,DISK], DatanodeInfoWithStorage[127.0.0.1:42357,DS-ab135b1a-ce52-4a72-89b8-3b5f7cfa57bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36612,DS-8165bda1-65b3-424b-b4a4-611a1b743565,DISK], DatanodeInfoWithStorage[127.0.0.1:39187,DS-11310c49-dcf1-41ad-8eb5-dabe7b25cdc1,DISK], DatanodeInfoWithStorage[127.0.0.1:35602,DS-b243ca90-26a7-4c8d-be00-78b41f0d36e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37476,DS-b175833f-0215-427a-a58d-bffd9bc6ec6f,DISK], DatanodeInfoWithStorage[127.0.0.1:39364,DS-c4e786dc-6566-4860-851d-5f27c2a50a33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-817806890-172.17.0.2-1597670329968:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39475,DS-f708e8d4-c925-4f4e-9ec9-ce4ad23e0005,DISK], DatanodeInfoWithStorage[127.0.0.1:33175,DS-57920d7f-f449-452e-985e-960f813c3331,DISK], DatanodeInfoWithStorage[127.0.0.1:43876,DS-df29476e-b47f-45b9-bd63-9dfe7c2b60b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43030,DS-e4a225f6-433c-486e-8b5b-63bb582c6387,DISK], DatanodeInfoWithStorage[127.0.0.1:44933,DS-975d1ab0-d461-4bb0-9397-1ee4a1dd981a,DISK], DatanodeInfoWithStorage[127.0.0.1:41880,DS-a67e1b58-aea8-4181-b071-956a96bf99c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40679,DS-384fbe44-f270-4d8e-9ed2-def9ba1d60ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45284,DS-e7bf7646-0fc3-4904-adb5-8cef91c1b3ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-817806890-172.17.0.2-1597670329968:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39475,DS-f708e8d4-c925-4f4e-9ec9-ce4ad23e0005,DISK], DatanodeInfoWithStorage[127.0.0.1:33175,DS-57920d7f-f449-452e-985e-960f813c3331,DISK], DatanodeInfoWithStorage[127.0.0.1:43876,DS-df29476e-b47f-45b9-bd63-9dfe7c2b60b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43030,DS-e4a225f6-433c-486e-8b5b-63bb582c6387,DISK], DatanodeInfoWithStorage[127.0.0.1:44933,DS-975d1ab0-d461-4bb0-9397-1ee4a1dd981a,DISK], DatanodeInfoWithStorage[127.0.0.1:41880,DS-a67e1b58-aea8-4181-b071-956a96bf99c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40679,DS-384fbe44-f270-4d8e-9ed2-def9ba1d60ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45284,DS-e7bf7646-0fc3-4904-adb5-8cef91c1b3ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-731419769-172.17.0.2-1597670640372:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45395,DS-ead1f218-a93f-46db-a0be-74dc9538b3b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-347101a8-ea28-42d8-8258-7bd8b39153bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33641,DS-b666045f-7c72-4d3b-adf3-f99c53fa232b,DISK], DatanodeInfoWithStorage[127.0.0.1:39957,DS-37fc09ee-73d0-424b-a065-4dc392c713fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46136,DS-ead2f14d-80d9-47c2-8898-19a2b2bdcb28,DISK], DatanodeInfoWithStorage[127.0.0.1:42714,DS-964f1972-4a56-4d2a-927f-59a977cfd623,DISK], DatanodeInfoWithStorage[127.0.0.1:37456,DS-c2d88d64-88dc-407a-aad0-4db2fd100978,DISK], DatanodeInfoWithStorage[127.0.0.1:45945,DS-5aac8b03-520b-4103-ac7a-41ce7e20a555,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-731419769-172.17.0.2-1597670640372:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45395,DS-ead1f218-a93f-46db-a0be-74dc9538b3b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-347101a8-ea28-42d8-8258-7bd8b39153bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33641,DS-b666045f-7c72-4d3b-adf3-f99c53fa232b,DISK], DatanodeInfoWithStorage[127.0.0.1:39957,DS-37fc09ee-73d0-424b-a065-4dc392c713fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46136,DS-ead2f14d-80d9-47c2-8898-19a2b2bdcb28,DISK], DatanodeInfoWithStorage[127.0.0.1:42714,DS-964f1972-4a56-4d2a-927f-59a977cfd623,DISK], DatanodeInfoWithStorage[127.0.0.1:37456,DS-c2d88d64-88dc-407a-aad0-4db2fd100978,DISK], DatanodeInfoWithStorage[127.0.0.1:45945,DS-5aac8b03-520b-4103-ac7a-41ce7e20a555,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-991168088-172.17.0.2-1597670826074:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41142,DS-c3ad0ca3-38b6-4306-a35a-240645a43a58,DISK], DatanodeInfoWithStorage[127.0.0.1:46252,DS-dfc512a5-ee6b-4ca9-aae2-610a64e03ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:41137,DS-28a57693-c42d-4a8a-95c5-c02d270d1f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44496,DS-75c26ced-86cc-4020-8606-5dcb307186c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38452,DS-fcd399a3-00b7-4db3-bc35-6406de0a0b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41694,DS-c886ace6-5ed0-4391-95c3-a5c8ee0b0fce,DISK], DatanodeInfoWithStorage[127.0.0.1:41728,DS-fbec0a89-709d-40fa-aba7-480d553fb832,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-8b78f9be-3475-4cc1-a5bc-df7155504f7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-991168088-172.17.0.2-1597670826074:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41142,DS-c3ad0ca3-38b6-4306-a35a-240645a43a58,DISK], DatanodeInfoWithStorage[127.0.0.1:46252,DS-dfc512a5-ee6b-4ca9-aae2-610a64e03ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:41137,DS-28a57693-c42d-4a8a-95c5-c02d270d1f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44496,DS-75c26ced-86cc-4020-8606-5dcb307186c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38452,DS-fcd399a3-00b7-4db3-bc35-6406de0a0b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41694,DS-c886ace6-5ed0-4391-95c3-a5c8ee0b0fce,DISK], DatanodeInfoWithStorage[127.0.0.1:41728,DS-fbec0a89-709d-40fa-aba7-480d553fb832,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-8b78f9be-3475-4cc1-a5bc-df7155504f7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1231323961-172.17.0.2-1597671050055:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39931,DS-c97bb85b-43f7-4533-92bc-5336a486e7e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46856,DS-d156168f-2ee0-4b92-ab45-080dda4c1545,DISK], DatanodeInfoWithStorage[127.0.0.1:34466,DS-a14578a2-8fd6-4d02-a81e-9c7b0e938fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:44358,DS-2097a270-f7f3-4208-b175-e2d2e3260575,DISK], DatanodeInfoWithStorage[127.0.0.1:37756,DS-1ca3147c-a71a-454f-b5b3-929f64830c01,DISK], DatanodeInfoWithStorage[127.0.0.1:45594,DS-0eb9ef06-063a-4343-b366-8e32e9b71c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42693,DS-9667c369-9fe1-473c-914a-0f6ae4bcbf8e,DISK], DatanodeInfoWithStorage[127.0.0.1:34604,DS-0e5005b4-a338-4d8a-8747-18f6f860f4b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1231323961-172.17.0.2-1597671050055:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39931,DS-c97bb85b-43f7-4533-92bc-5336a486e7e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46856,DS-d156168f-2ee0-4b92-ab45-080dda4c1545,DISK], DatanodeInfoWithStorage[127.0.0.1:34466,DS-a14578a2-8fd6-4d02-a81e-9c7b0e938fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:44358,DS-2097a270-f7f3-4208-b175-e2d2e3260575,DISK], DatanodeInfoWithStorage[127.0.0.1:37756,DS-1ca3147c-a71a-454f-b5b3-929f64830c01,DISK], DatanodeInfoWithStorage[127.0.0.1:45594,DS-0eb9ef06-063a-4343-b366-8e32e9b71c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42693,DS-9667c369-9fe1-473c-914a-0f6ae4bcbf8e,DISK], DatanodeInfoWithStorage[127.0.0.1:34604,DS-0e5005b4-a338-4d8a-8747-18f6f860f4b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1082069175-172.17.0.2-1597671186355:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41623,DS-66b66a5f-1e34-44ff-a616-1ae4fde18d83,DISK], DatanodeInfoWithStorage[127.0.0.1:46305,DS-9600182e-c02b-4feb-bb7e-8a6557ee9b98,DISK], DatanodeInfoWithStorage[127.0.0.1:39903,DS-878d0d42-d757-4b02-9099-ce8d0aaadac4,DISK], DatanodeInfoWithStorage[127.0.0.1:45406,DS-c90ead6d-8ad4-45da-a3cb-713f775ee933,DISK], DatanodeInfoWithStorage[127.0.0.1:34561,DS-3ef1a58f-6701-4f18-b885-cba83aaf3153,DISK], DatanodeInfoWithStorage[127.0.0.1:32783,DS-4d89833d-6987-4de5-8662-81822a9e42f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41342,DS-a2f4f4fe-b2da-4c7e-92c8-9113b5a57def,DISK], DatanodeInfoWithStorage[127.0.0.1:40591,DS-919be021-3876-4539-badf-e5cfc9be3c9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1082069175-172.17.0.2-1597671186355:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41623,DS-66b66a5f-1e34-44ff-a616-1ae4fde18d83,DISK], DatanodeInfoWithStorage[127.0.0.1:46305,DS-9600182e-c02b-4feb-bb7e-8a6557ee9b98,DISK], DatanodeInfoWithStorage[127.0.0.1:39903,DS-878d0d42-d757-4b02-9099-ce8d0aaadac4,DISK], DatanodeInfoWithStorage[127.0.0.1:45406,DS-c90ead6d-8ad4-45da-a3cb-713f775ee933,DISK], DatanodeInfoWithStorage[127.0.0.1:34561,DS-3ef1a58f-6701-4f18-b885-cba83aaf3153,DISK], DatanodeInfoWithStorage[127.0.0.1:32783,DS-4d89833d-6987-4de5-8662-81822a9e42f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41342,DS-a2f4f4fe-b2da-4c7e-92c8-9113b5a57def,DISK], DatanodeInfoWithStorage[127.0.0.1:40591,DS-919be021-3876-4539-badf-e5cfc9be3c9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1505362692-172.17.0.2-1597672059930:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41039,DS-576053f0-7df3-44a2-9347-b24c90f383df,DISK], DatanodeInfoWithStorage[127.0.0.1:37052,DS-d83fed49-bf70-46f2-aa08-81ab675e2c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:42685,DS-d0391ccc-7094-48ff-bab3-4272248b282d,DISK], DatanodeInfoWithStorage[127.0.0.1:38877,DS-df596c2a-a167-489a-aebc-8e8d37bb153f,DISK], DatanodeInfoWithStorage[127.0.0.1:39510,DS-b2319b5b-ff89-4626-85d4-10d45911a7d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41157,DS-f8131b7d-0e54-4b46-8a56-a71bb40350cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37370,DS-054a6327-aff1-45f2-886b-77efe7d0b5ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38527,DS-b86be27f-a8a0-4a4a-aa50-755e489336da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1505362692-172.17.0.2-1597672059930:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41039,DS-576053f0-7df3-44a2-9347-b24c90f383df,DISK], DatanodeInfoWithStorage[127.0.0.1:37052,DS-d83fed49-bf70-46f2-aa08-81ab675e2c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:42685,DS-d0391ccc-7094-48ff-bab3-4272248b282d,DISK], DatanodeInfoWithStorage[127.0.0.1:38877,DS-df596c2a-a167-489a-aebc-8e8d37bb153f,DISK], DatanodeInfoWithStorage[127.0.0.1:39510,DS-b2319b5b-ff89-4626-85d4-10d45911a7d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41157,DS-f8131b7d-0e54-4b46-8a56-a71bb40350cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37370,DS-054a6327-aff1-45f2-886b-77efe7d0b5ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38527,DS-b86be27f-a8a0-4a4a-aa50-755e489336da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1337471766-172.17.0.2-1597672269721:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39538,DS-71c8d198-0657-4313-87eb-f8ca437de27d,DISK], DatanodeInfoWithStorage[127.0.0.1:37159,DS-e4d46a20-c30d-4034-8931-1b30626d49d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38080,DS-217f9345-4026-43ab-9293-bfc18b9cdba4,DISK], DatanodeInfoWithStorage[127.0.0.1:38686,DS-06c734e8-3f5f-4152-ad9a-5ed4f027b016,DISK], DatanodeInfoWithStorage[127.0.0.1:35184,DS-ff16ff18-f166-4930-bded-e6057c7745eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45899,DS-4f5d9058-2bc6-4bb9-97b7-a708283843ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39205,DS-6225ae4d-711f-4096-be98-c371aa7c7e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:46713,DS-2b44d169-517e-4726-8fef-d8360416eb5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1337471766-172.17.0.2-1597672269721:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39538,DS-71c8d198-0657-4313-87eb-f8ca437de27d,DISK], DatanodeInfoWithStorage[127.0.0.1:37159,DS-e4d46a20-c30d-4034-8931-1b30626d49d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38080,DS-217f9345-4026-43ab-9293-bfc18b9cdba4,DISK], DatanodeInfoWithStorage[127.0.0.1:38686,DS-06c734e8-3f5f-4152-ad9a-5ed4f027b016,DISK], DatanodeInfoWithStorage[127.0.0.1:35184,DS-ff16ff18-f166-4930-bded-e6057c7745eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45899,DS-4f5d9058-2bc6-4bb9-97b7-a708283843ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39205,DS-6225ae4d-711f-4096-be98-c371aa7c7e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:46713,DS-2b44d169-517e-4726-8fef-d8360416eb5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-520640981-172.17.0.2-1597672395787:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33272,DS-b465551f-3fd7-44d7-ad30-798668d02206,DISK], DatanodeInfoWithStorage[127.0.0.1:33666,DS-249a79de-7c12-44c7-a97c-704ca6e1d4c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33800,DS-c5ee19b3-2093-419b-9b8f-5c3f2cdd7b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:42531,DS-83a4e08a-dbf3-4013-9ab6-3ba36c6a13bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41367,DS-50fe6433-b1c4-4905-8279-78a8ac83151f,DISK], DatanodeInfoWithStorage[127.0.0.1:44331,DS-eefe1bf1-3002-4783-b21d-297bb41c33b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42240,DS-bcf53635-8348-42ba-b83b-4cdabfa0b951,DISK], DatanodeInfoWithStorage[127.0.0.1:44983,DS-21ba4ede-5ada-4ab2-b869-08596c511185,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-520640981-172.17.0.2-1597672395787:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33272,DS-b465551f-3fd7-44d7-ad30-798668d02206,DISK], DatanodeInfoWithStorage[127.0.0.1:33666,DS-249a79de-7c12-44c7-a97c-704ca6e1d4c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33800,DS-c5ee19b3-2093-419b-9b8f-5c3f2cdd7b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:42531,DS-83a4e08a-dbf3-4013-9ab6-3ba36c6a13bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41367,DS-50fe6433-b1c4-4905-8279-78a8ac83151f,DISK], DatanodeInfoWithStorage[127.0.0.1:44331,DS-eefe1bf1-3002-4783-b21d-297bb41c33b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42240,DS-bcf53635-8348-42ba-b83b-4cdabfa0b951,DISK], DatanodeInfoWithStorage[127.0.0.1:44983,DS-21ba4ede-5ada-4ab2-b869-08596c511185,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1761237254-172.17.0.2-1597674019896:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44418,DS-d5b0fe1b-05ce-4ab6-bf93-396fbd1241a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35921,DS-09831b04-f5b1-456e-ae41-e2090e0698fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33973,DS-0863d211-7174-44a1-821f-9829114d8866,DISK], DatanodeInfoWithStorage[127.0.0.1:46741,DS-c58310bf-cc39-4717-b10e-acf535efc966,DISK], DatanodeInfoWithStorage[127.0.0.1:41586,DS-30de61de-1105-4177-af58-38d2187a1883,DISK], DatanodeInfoWithStorage[127.0.0.1:34053,DS-6cee0871-61d4-4a52-997a-1e56ca07cb2d,DISK], DatanodeInfoWithStorage[127.0.0.1:43210,DS-8be14c08-702b-49d6-a60e-e8382df3e5eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35696,DS-408f67d1-f8cd-4076-ae6b-55e6503d91f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1761237254-172.17.0.2-1597674019896:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44418,DS-d5b0fe1b-05ce-4ab6-bf93-396fbd1241a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35921,DS-09831b04-f5b1-456e-ae41-e2090e0698fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33973,DS-0863d211-7174-44a1-821f-9829114d8866,DISK], DatanodeInfoWithStorage[127.0.0.1:46741,DS-c58310bf-cc39-4717-b10e-acf535efc966,DISK], DatanodeInfoWithStorage[127.0.0.1:41586,DS-30de61de-1105-4177-af58-38d2187a1883,DISK], DatanodeInfoWithStorage[127.0.0.1:34053,DS-6cee0871-61d4-4a52-997a-1e56ca07cb2d,DISK], DatanodeInfoWithStorage[127.0.0.1:43210,DS-8be14c08-702b-49d6-a60e-e8382df3e5eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35696,DS-408f67d1-f8cd-4076-ae6b-55e6503d91f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1972967836-172.17.0.2-1597674381318:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33072,DS-7a8f191b-f11f-443d-b0c6-a0f7a835fb26,DISK], DatanodeInfoWithStorage[127.0.0.1:39755,DS-04f9f44e-4ff0-44ac-ad44-e10d19e15d45,DISK], DatanodeInfoWithStorage[127.0.0.1:41134,DS-dce4f8aa-6591-4b7b-93fe-2d98f46773a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39731,DS-76e7d567-31a6-4c25-ac6a-5d84c518e579,DISK], DatanodeInfoWithStorage[127.0.0.1:45159,DS-3dd33017-3eb5-4c48-937e-edd158cc5a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:37290,DS-8b56af27-a308-4a89-82cd-d230f9d41f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:34986,DS-917c28fe-2636-43e2-8fee-6e14374cd91a,DISK], DatanodeInfoWithStorage[127.0.0.1:45579,DS-b88eeedf-e5dc-4acf-9806-5852b66699e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1972967836-172.17.0.2-1597674381318:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33072,DS-7a8f191b-f11f-443d-b0c6-a0f7a835fb26,DISK], DatanodeInfoWithStorage[127.0.0.1:39755,DS-04f9f44e-4ff0-44ac-ad44-e10d19e15d45,DISK], DatanodeInfoWithStorage[127.0.0.1:41134,DS-dce4f8aa-6591-4b7b-93fe-2d98f46773a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39731,DS-76e7d567-31a6-4c25-ac6a-5d84c518e579,DISK], DatanodeInfoWithStorage[127.0.0.1:45159,DS-3dd33017-3eb5-4c48-937e-edd158cc5a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:37290,DS-8b56af27-a308-4a89-82cd-d230f9d41f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:34986,DS-917c28fe-2636-43e2-8fee-6e14374cd91a,DISK], DatanodeInfoWithStorage[127.0.0.1:45579,DS-b88eeedf-e5dc-4acf-9806-5852b66699e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-575913138-172.17.0.2-1597674820750:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41602,DS-12264171-e8fb-4b4d-abab-43db2fedcb9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36609,DS-6acc2bd5-eca4-4e54-b682-f862476e947b,DISK], DatanodeInfoWithStorage[127.0.0.1:41184,DS-856ad1a8-5d27-48cb-b4bf-4787213fc192,DISK], DatanodeInfoWithStorage[127.0.0.1:40740,DS-a504220d-5ae8-448f-b52f-be03be5fd5ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37965,DS-b62bbce7-1931-4048-acf4-4f435c38d180,DISK], DatanodeInfoWithStorage[127.0.0.1:38785,DS-b9acf5d3-5b4b-45f2-94d4-384333dfe64c,DISK], DatanodeInfoWithStorage[127.0.0.1:38053,DS-c2010d9f-bdeb-41da-adc1-410fb314906c,DISK], DatanodeInfoWithStorage[127.0.0.1:43218,DS-cb9254d1-943e-4e56-9f02-21c2858400cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-575913138-172.17.0.2-1597674820750:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41602,DS-12264171-e8fb-4b4d-abab-43db2fedcb9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36609,DS-6acc2bd5-eca4-4e54-b682-f862476e947b,DISK], DatanodeInfoWithStorage[127.0.0.1:41184,DS-856ad1a8-5d27-48cb-b4bf-4787213fc192,DISK], DatanodeInfoWithStorage[127.0.0.1:40740,DS-a504220d-5ae8-448f-b52f-be03be5fd5ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37965,DS-b62bbce7-1931-4048-acf4-4f435c38d180,DISK], DatanodeInfoWithStorage[127.0.0.1:38785,DS-b9acf5d3-5b4b-45f2-94d4-384333dfe64c,DISK], DatanodeInfoWithStorage[127.0.0.1:38053,DS-c2010d9f-bdeb-41da-adc1-410fb314906c,DISK], DatanodeInfoWithStorage[127.0.0.1:43218,DS-cb9254d1-943e-4e56-9f02-21c2858400cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 6604
