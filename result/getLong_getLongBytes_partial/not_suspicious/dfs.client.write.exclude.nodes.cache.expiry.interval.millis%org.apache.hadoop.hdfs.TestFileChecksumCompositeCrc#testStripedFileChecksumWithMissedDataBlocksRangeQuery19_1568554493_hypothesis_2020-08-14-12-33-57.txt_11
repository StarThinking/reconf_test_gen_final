reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1544265191-172.17.0.13-1597408637777:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44490,DS-198a4cf0-30dd-4289-ba81-d87cc9499a84,DISK], DatanodeInfoWithStorage[127.0.0.1:38838,DS-b7248020-6145-4788-b4a6-3d7ae8843d10,DISK], DatanodeInfoWithStorage[127.0.0.1:33894,DS-64d49873-a619-4291-8480-a0a29cfe7132,DISK], DatanodeInfoWithStorage[127.0.0.1:32971,DS-8fa2f682-f8f2-4aa2-8b18-ac733b7ebba2,DISK], DatanodeInfoWithStorage[127.0.0.1:39612,DS-b073aaee-6839-4971-b0fd-daa07f427bad,DISK], DatanodeInfoWithStorage[127.0.0.1:42532,DS-6a571738-05b7-41c2-9d7d-a87276414b40,DISK], DatanodeInfoWithStorage[127.0.0.1:40358,DS-87ec3311-5075-4dd4-a918-aea57970e4fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37422,DS-931ad4e8-9373-4359-aa6a-e216577c439c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1544265191-172.17.0.13-1597408637777:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44490,DS-198a4cf0-30dd-4289-ba81-d87cc9499a84,DISK], DatanodeInfoWithStorage[127.0.0.1:38838,DS-b7248020-6145-4788-b4a6-3d7ae8843d10,DISK], DatanodeInfoWithStorage[127.0.0.1:33894,DS-64d49873-a619-4291-8480-a0a29cfe7132,DISK], DatanodeInfoWithStorage[127.0.0.1:32971,DS-8fa2f682-f8f2-4aa2-8b18-ac733b7ebba2,DISK], DatanodeInfoWithStorage[127.0.0.1:39612,DS-b073aaee-6839-4971-b0fd-daa07f427bad,DISK], DatanodeInfoWithStorage[127.0.0.1:42532,DS-6a571738-05b7-41c2-9d7d-a87276414b40,DISK], DatanodeInfoWithStorage[127.0.0.1:40358,DS-87ec3311-5075-4dd4-a918-aea57970e4fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37422,DS-931ad4e8-9373-4359-aa6a-e216577c439c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-819808829-172.17.0.13-1597409467126:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34840,DS-771565a0-85f2-4166-b843-5ffef61a3503,DISK], DatanodeInfoWithStorage[127.0.0.1:41538,DS-32caef03-95fe-4236-8381-6a697eb23b32,DISK], DatanodeInfoWithStorage[127.0.0.1:32938,DS-e580c9c7-bb21-4e18-8b03-93b8cd8409d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44477,DS-766e9f93-b5e1-4e7c-9496-8ebc7d4063d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46652,DS-b05f86fc-95ae-41ec-8231-a55b6e82ccc5,DISK], DatanodeInfoWithStorage[127.0.0.1:39507,DS-7419d979-57ec-46ca-b8e3-1eeb9d400b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44789,DS-89381fa9-a8a7-4c29-ba12-01c55b332ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:43476,DS-26f51ea6-a920-46e2-b6cb-b33a7ed67e03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-819808829-172.17.0.13-1597409467126:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34840,DS-771565a0-85f2-4166-b843-5ffef61a3503,DISK], DatanodeInfoWithStorage[127.0.0.1:41538,DS-32caef03-95fe-4236-8381-6a697eb23b32,DISK], DatanodeInfoWithStorage[127.0.0.1:32938,DS-e580c9c7-bb21-4e18-8b03-93b8cd8409d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44477,DS-766e9f93-b5e1-4e7c-9496-8ebc7d4063d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46652,DS-b05f86fc-95ae-41ec-8231-a55b6e82ccc5,DISK], DatanodeInfoWithStorage[127.0.0.1:39507,DS-7419d979-57ec-46ca-b8e3-1eeb9d400b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44789,DS-89381fa9-a8a7-4c29-ba12-01c55b332ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:43476,DS-26f51ea6-a920-46e2-b6cb-b33a7ed67e03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1134877899-172.17.0.13-1597409877535:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35734,DS-8d6da94b-ed31-4537-a994-b4429e80872e,DISK], DatanodeInfoWithStorage[127.0.0.1:45794,DS-508c593a-1819-4ecf-b79e-785dca3a5b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:40543,DS-de4e6d7d-4b0d-4ac8-85bf-0adbb7daa1cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40532,DS-6670d24f-e917-4d61-97f4-3a754dbe4327,DISK], DatanodeInfoWithStorage[127.0.0.1:33275,DS-6db24423-1f8a-482e-96ea-526ba727c136,DISK], DatanodeInfoWithStorage[127.0.0.1:38519,DS-9e864b0d-9486-450f-8f95-925b7442bff2,DISK], DatanodeInfoWithStorage[127.0.0.1:46492,DS-4b63ab1d-d2ea-484e-a244-55f055de03aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37767,DS-ddf875d0-50fb-4515-95e4-ec5de1efdb5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1134877899-172.17.0.13-1597409877535:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35734,DS-8d6da94b-ed31-4537-a994-b4429e80872e,DISK], DatanodeInfoWithStorage[127.0.0.1:45794,DS-508c593a-1819-4ecf-b79e-785dca3a5b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:40543,DS-de4e6d7d-4b0d-4ac8-85bf-0adbb7daa1cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40532,DS-6670d24f-e917-4d61-97f4-3a754dbe4327,DISK], DatanodeInfoWithStorage[127.0.0.1:33275,DS-6db24423-1f8a-482e-96ea-526ba727c136,DISK], DatanodeInfoWithStorage[127.0.0.1:38519,DS-9e864b0d-9486-450f-8f95-925b7442bff2,DISK], DatanodeInfoWithStorage[127.0.0.1:46492,DS-4b63ab1d-d2ea-484e-a244-55f055de03aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37767,DS-ddf875d0-50fb-4515-95e4-ec5de1efdb5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-146215200-172.17.0.13-1597410025680:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42733,DS-7b8b7905-e6f2-466d-95d9-3254e97671ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42174,DS-bd913b07-b17b-4522-a774-f626ae0dbdf6,DISK], DatanodeInfoWithStorage[127.0.0.1:33400,DS-723d02c8-9477-4325-9abb-7fc834c5ab3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45550,DS-96f2e648-6306-4b9c-b23a-9155114515a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43886,DS-9cd816e1-2c07-4dfc-aec5-c213a5a9aa7e,DISK], DatanodeInfoWithStorage[127.0.0.1:41702,DS-a5e4ab34-bffe-4cc3-961d-2710db5a072e,DISK], DatanodeInfoWithStorage[127.0.0.1:34793,DS-6fec3725-5bb7-4438-8652-c10e142685b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33432,DS-d9d69ea6-bca6-4e57-8f3c-bb5b48e2693f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-146215200-172.17.0.13-1597410025680:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42733,DS-7b8b7905-e6f2-466d-95d9-3254e97671ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42174,DS-bd913b07-b17b-4522-a774-f626ae0dbdf6,DISK], DatanodeInfoWithStorage[127.0.0.1:33400,DS-723d02c8-9477-4325-9abb-7fc834c5ab3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45550,DS-96f2e648-6306-4b9c-b23a-9155114515a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43886,DS-9cd816e1-2c07-4dfc-aec5-c213a5a9aa7e,DISK], DatanodeInfoWithStorage[127.0.0.1:41702,DS-a5e4ab34-bffe-4cc3-961d-2710db5a072e,DISK], DatanodeInfoWithStorage[127.0.0.1:34793,DS-6fec3725-5bb7-4438-8652-c10e142685b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33432,DS-d9d69ea6-bca6-4e57-8f3c-bb5b48e2693f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-74669214-172.17.0.13-1597410062019:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38995,DS-453ec1f4-3c7b-4286-87c4-b9c1b6ef4942,DISK], DatanodeInfoWithStorage[127.0.0.1:35870,DS-7fc94c23-e542-4cfb-b5d8-fc25165aed7c,DISK], DatanodeInfoWithStorage[127.0.0.1:34504,DS-38361115-29d9-4b6c-b721-b1f860b152d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40164,DS-c87b3f11-14fd-43fb-a35b-b35dbb8f9860,DISK], DatanodeInfoWithStorage[127.0.0.1:42084,DS-22f2641e-8344-4f00-b621-447770bf5e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39966,DS-3edb3e4c-748b-4b76-b249-cb87ff01ff3c,DISK], DatanodeInfoWithStorage[127.0.0.1:46533,DS-ae456cfd-b17c-479c-ad1e-23cd159827fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46415,DS-e4181a92-066f-429d-b8ea-8b8400706e5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-74669214-172.17.0.13-1597410062019:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38995,DS-453ec1f4-3c7b-4286-87c4-b9c1b6ef4942,DISK], DatanodeInfoWithStorage[127.0.0.1:35870,DS-7fc94c23-e542-4cfb-b5d8-fc25165aed7c,DISK], DatanodeInfoWithStorage[127.0.0.1:34504,DS-38361115-29d9-4b6c-b721-b1f860b152d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40164,DS-c87b3f11-14fd-43fb-a35b-b35dbb8f9860,DISK], DatanodeInfoWithStorage[127.0.0.1:42084,DS-22f2641e-8344-4f00-b621-447770bf5e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39966,DS-3edb3e4c-748b-4b76-b249-cb87ff01ff3c,DISK], DatanodeInfoWithStorage[127.0.0.1:46533,DS-ae456cfd-b17c-479c-ad1e-23cd159827fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46415,DS-e4181a92-066f-429d-b8ea-8b8400706e5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1404081267-172.17.0.13-1597410388691:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46359,DS-d941699c-74db-43ec-ac5b-ffe166ad8e78,DISK], DatanodeInfoWithStorage[127.0.0.1:45745,DS-5ebddd79-60e0-4eda-8489-e30008bb1922,DISK], DatanodeInfoWithStorage[127.0.0.1:38345,DS-7b1aa22e-bacd-4153-ae52-4b4ab3b34f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:44136,DS-d819ea88-3914-49e1-a929-aba4f34b7878,DISK], DatanodeInfoWithStorage[127.0.0.1:42890,DS-4871e053-d906-4d63-97de-1edf835e8d04,DISK], DatanodeInfoWithStorage[127.0.0.1:41389,DS-b788119c-6f86-4594-8778-5973df67e85e,DISK], DatanodeInfoWithStorage[127.0.0.1:44690,DS-1cccab73-4b33-4cd7-978e-0f9e8dce073c,DISK], DatanodeInfoWithStorage[127.0.0.1:43407,DS-161b6ed5-c0b1-4e90-8702-98c3492162ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1404081267-172.17.0.13-1597410388691:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46359,DS-d941699c-74db-43ec-ac5b-ffe166ad8e78,DISK], DatanodeInfoWithStorage[127.0.0.1:45745,DS-5ebddd79-60e0-4eda-8489-e30008bb1922,DISK], DatanodeInfoWithStorage[127.0.0.1:38345,DS-7b1aa22e-bacd-4153-ae52-4b4ab3b34f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:44136,DS-d819ea88-3914-49e1-a929-aba4f34b7878,DISK], DatanodeInfoWithStorage[127.0.0.1:42890,DS-4871e053-d906-4d63-97de-1edf835e8d04,DISK], DatanodeInfoWithStorage[127.0.0.1:41389,DS-b788119c-6f86-4594-8778-5973df67e85e,DISK], DatanodeInfoWithStorage[127.0.0.1:44690,DS-1cccab73-4b33-4cd7-978e-0f9e8dce073c,DISK], DatanodeInfoWithStorage[127.0.0.1:43407,DS-161b6ed5-c0b1-4e90-8702-98c3492162ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-784180910-172.17.0.13-1597410604091:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42124,DS-39ac5e2c-e871-4503-b976-56acd2069ace,DISK], DatanodeInfoWithStorage[127.0.0.1:41811,DS-828e838e-f548-42b0-b909-deae8442fbc5,DISK], DatanodeInfoWithStorage[127.0.0.1:43503,DS-7a323e26-5b5d-4b76-9c02-8c1f67a9b655,DISK], DatanodeInfoWithStorage[127.0.0.1:45475,DS-ef149037-007c-4b3a-a9c8-9ad92a40245f,DISK], DatanodeInfoWithStorage[127.0.0.1:41128,DS-3ef60e17-c7fa-49aa-ad4a-9fa46c8601d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40324,DS-f7d70056-00cb-4c8a-a311-55b32de5d204,DISK], DatanodeInfoWithStorage[127.0.0.1:35798,DS-a3a2be97-c5d1-42bd-8a39-be9bbcec45dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43867,DS-49db382e-9f99-439e-88c0-fa4172fc9c95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-784180910-172.17.0.13-1597410604091:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42124,DS-39ac5e2c-e871-4503-b976-56acd2069ace,DISK], DatanodeInfoWithStorage[127.0.0.1:41811,DS-828e838e-f548-42b0-b909-deae8442fbc5,DISK], DatanodeInfoWithStorage[127.0.0.1:43503,DS-7a323e26-5b5d-4b76-9c02-8c1f67a9b655,DISK], DatanodeInfoWithStorage[127.0.0.1:45475,DS-ef149037-007c-4b3a-a9c8-9ad92a40245f,DISK], DatanodeInfoWithStorage[127.0.0.1:41128,DS-3ef60e17-c7fa-49aa-ad4a-9fa46c8601d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40324,DS-f7d70056-00cb-4c8a-a311-55b32de5d204,DISK], DatanodeInfoWithStorage[127.0.0.1:35798,DS-a3a2be97-c5d1-42bd-8a39-be9bbcec45dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43867,DS-49db382e-9f99-439e-88c0-fa4172fc9c95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-850157625-172.17.0.13-1597410658849:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43354,DS-2b5307d1-5e9f-442d-963d-9b7220dd5436,DISK], DatanodeInfoWithStorage[127.0.0.1:44573,DS-f5858f2b-0ad0-4d3c-9f8f-bdccbb3a1dba,DISK], DatanodeInfoWithStorage[127.0.0.1:42572,DS-8c2ea1b9-e89b-407b-8df9-65d3719244b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42599,DS-86477d20-f9fc-43eb-a6dd-bcb6d2b12067,DISK], DatanodeInfoWithStorage[127.0.0.1:34842,DS-9c56dacb-d7f4-4b4d-92ed-50dff872e7e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38854,DS-05aa718f-5610-4f9f-abfb-36b6ceb322c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45037,DS-0dbe99bf-523a-423c-8687-c7007746aacd,DISK], DatanodeInfoWithStorage[127.0.0.1:40477,DS-1cef3fd9-3dab-4672-ba46-9f94155d6144,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-850157625-172.17.0.13-1597410658849:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43354,DS-2b5307d1-5e9f-442d-963d-9b7220dd5436,DISK], DatanodeInfoWithStorage[127.0.0.1:44573,DS-f5858f2b-0ad0-4d3c-9f8f-bdccbb3a1dba,DISK], DatanodeInfoWithStorage[127.0.0.1:42572,DS-8c2ea1b9-e89b-407b-8df9-65d3719244b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42599,DS-86477d20-f9fc-43eb-a6dd-bcb6d2b12067,DISK], DatanodeInfoWithStorage[127.0.0.1:34842,DS-9c56dacb-d7f4-4b4d-92ed-50dff872e7e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38854,DS-05aa718f-5610-4f9f-abfb-36b6ceb322c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45037,DS-0dbe99bf-523a-423c-8687-c7007746aacd,DISK], DatanodeInfoWithStorage[127.0.0.1:40477,DS-1cef3fd9-3dab-4672-ba46-9f94155d6144,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1177431330-172.17.0.13-1597411127743:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40389,DS-8f590f8c-9ea7-45b4-9fb8-c29e0b21bb1b,DISK], DatanodeInfoWithStorage[127.0.0.1:41578,DS-c53353be-03a2-4859-8b5e-b30cf740ac44,DISK], DatanodeInfoWithStorage[127.0.0.1:35680,DS-425bd74e-e7fa-467c-a525-739f15e85d06,DISK], DatanodeInfoWithStorage[127.0.0.1:35776,DS-ba74b103-247a-4372-a4d4-f4635dfe0cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:45915,DS-855995cb-b36b-482e-affe-5d1a278915e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40712,DS-f972b73b-483f-454a-8c80-c36081c9c4af,DISK], DatanodeInfoWithStorage[127.0.0.1:40814,DS-ace70d57-5ff1-4a82-ada9-2a1511d5fa03,DISK], DatanodeInfoWithStorage[127.0.0.1:37426,DS-9a516f5e-1004-4271-a496-6b0197933259,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1177431330-172.17.0.13-1597411127743:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40389,DS-8f590f8c-9ea7-45b4-9fb8-c29e0b21bb1b,DISK], DatanodeInfoWithStorage[127.0.0.1:41578,DS-c53353be-03a2-4859-8b5e-b30cf740ac44,DISK], DatanodeInfoWithStorage[127.0.0.1:35680,DS-425bd74e-e7fa-467c-a525-739f15e85d06,DISK], DatanodeInfoWithStorage[127.0.0.1:35776,DS-ba74b103-247a-4372-a4d4-f4635dfe0cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:45915,DS-855995cb-b36b-482e-affe-5d1a278915e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40712,DS-f972b73b-483f-454a-8c80-c36081c9c4af,DISK], DatanodeInfoWithStorage[127.0.0.1:40814,DS-ace70d57-5ff1-4a82-ada9-2a1511d5fa03,DISK], DatanodeInfoWithStorage[127.0.0.1:37426,DS-9a516f5e-1004-4271-a496-6b0197933259,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-183071889-172.17.0.13-1597411496796:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45114,DS-1a823e8d-8e0c-43b3-b697-4518e565f312,DISK], DatanodeInfoWithStorage[127.0.0.1:43873,DS-92f06dbe-e165-42dc-ad0d-a7f1e6761768,DISK], DatanodeInfoWithStorage[127.0.0.1:39067,DS-f1c40569-649f-45c9-b599-bc99a3a9c205,DISK], DatanodeInfoWithStorage[127.0.0.1:33656,DS-925bbeef-99d2-456b-9488-6afa290413df,DISK], DatanodeInfoWithStorage[127.0.0.1:38790,DS-e16f1fa9-399c-4be5-aa35-1f1b2d283447,DISK], DatanodeInfoWithStorage[127.0.0.1:42668,DS-1b5a0db7-74ed-46ae-8e31-2b2a5fa64946,DISK], DatanodeInfoWithStorage[127.0.0.1:35971,DS-768910be-0d69-4c71-90df-6c861e400409,DISK], DatanodeInfoWithStorage[127.0.0.1:35190,DS-863d6807-8bdc-40bf-8478-d111a3b88c0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-183071889-172.17.0.13-1597411496796:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45114,DS-1a823e8d-8e0c-43b3-b697-4518e565f312,DISK], DatanodeInfoWithStorage[127.0.0.1:43873,DS-92f06dbe-e165-42dc-ad0d-a7f1e6761768,DISK], DatanodeInfoWithStorage[127.0.0.1:39067,DS-f1c40569-649f-45c9-b599-bc99a3a9c205,DISK], DatanodeInfoWithStorage[127.0.0.1:33656,DS-925bbeef-99d2-456b-9488-6afa290413df,DISK], DatanodeInfoWithStorage[127.0.0.1:38790,DS-e16f1fa9-399c-4be5-aa35-1f1b2d283447,DISK], DatanodeInfoWithStorage[127.0.0.1:42668,DS-1b5a0db7-74ed-46ae-8e31-2b2a5fa64946,DISK], DatanodeInfoWithStorage[127.0.0.1:35971,DS-768910be-0d69-4c71-90df-6c861e400409,DISK], DatanodeInfoWithStorage[127.0.0.1:35190,DS-863d6807-8bdc-40bf-8478-d111a3b88c0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1279901569-172.17.0.13-1597411960718:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44894,DS-014ec92b-c845-4274-bdd0-65cf934a1ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:37512,DS-045f7051-27d9-4014-8f91-f26a77dde00b,DISK], DatanodeInfoWithStorage[127.0.0.1:38489,DS-bd2ef2bb-3582-4590-9cee-18d31488ba97,DISK], DatanodeInfoWithStorage[127.0.0.1:33920,DS-d7a089ee-7c53-4abb-823a-98b3a07a961c,DISK], DatanodeInfoWithStorage[127.0.0.1:38528,DS-907e9cdf-8095-4d84-8667-75b021574f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-292cb0d8-3fa3-4bc9-825e-1899ff0346cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39607,DS-bd5028f9-41da-403c-902f-cbc85a4efbb8,DISK], DatanodeInfoWithStorage[127.0.0.1:35669,DS-601e1855-a8d1-4ddd-b7df-282199cbc83b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1279901569-172.17.0.13-1597411960718:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44894,DS-014ec92b-c845-4274-bdd0-65cf934a1ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:37512,DS-045f7051-27d9-4014-8f91-f26a77dde00b,DISK], DatanodeInfoWithStorage[127.0.0.1:38489,DS-bd2ef2bb-3582-4590-9cee-18d31488ba97,DISK], DatanodeInfoWithStorage[127.0.0.1:33920,DS-d7a089ee-7c53-4abb-823a-98b3a07a961c,DISK], DatanodeInfoWithStorage[127.0.0.1:38528,DS-907e9cdf-8095-4d84-8667-75b021574f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-292cb0d8-3fa3-4bc9-825e-1899ff0346cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39607,DS-bd5028f9-41da-403c-902f-cbc85a4efbb8,DISK], DatanodeInfoWithStorage[127.0.0.1:35669,DS-601e1855-a8d1-4ddd-b7df-282199cbc83b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1647135634-172.17.0.13-1597412631359:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40662,DS-78818d70-d681-4649-8664-92d6e7a79742,DISK], DatanodeInfoWithStorage[127.0.0.1:38498,DS-c530eb13-5d42-4018-bb87-308c2a7d28dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42797,DS-ed987baf-53a2-467b-b5e0-853ab2d99ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:39461,DS-730575b4-2c65-4f4d-bf94-38cb4dd04f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43504,DS-a7683ac6-3975-4432-a6ac-f42ea006f3fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36267,DS-d998d14e-baeb-4e41-8a32-d5a79ebcac9e,DISK], DatanodeInfoWithStorage[127.0.0.1:36017,DS-dcb1133a-217c-4bf7-a23b-90937f3f81fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40204,DS-f97731ba-c11c-4097-8e92-4fdb853f3b7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1647135634-172.17.0.13-1597412631359:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40662,DS-78818d70-d681-4649-8664-92d6e7a79742,DISK], DatanodeInfoWithStorage[127.0.0.1:38498,DS-c530eb13-5d42-4018-bb87-308c2a7d28dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42797,DS-ed987baf-53a2-467b-b5e0-853ab2d99ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:39461,DS-730575b4-2c65-4f4d-bf94-38cb4dd04f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43504,DS-a7683ac6-3975-4432-a6ac-f42ea006f3fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36267,DS-d998d14e-baeb-4e41-8a32-d5a79ebcac9e,DISK], DatanodeInfoWithStorage[127.0.0.1:36017,DS-dcb1133a-217c-4bf7-a23b-90937f3f81fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40204,DS-f97731ba-c11c-4097-8e92-4fdb853f3b7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-228085293-172.17.0.13-1597412725292:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38022,DS-b4752742-5f95-49c7-b9e2-0fa110bbb4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35609,DS-103a2667-683e-4e58-b606-e75b4bc3d6b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36021,DS-5507be69-0752-41fb-b232-1c46a41ee0de,DISK], DatanodeInfoWithStorage[127.0.0.1:37498,DS-61c4b18d-8807-4b36-97d9-d14aa7779101,DISK], DatanodeInfoWithStorage[127.0.0.1:36807,DS-31c9a5c6-212a-4d35-90d8-cb6d6151b2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36448,DS-fc7829ae-aa6e-47d7-84a5-cea03e688a07,DISK], DatanodeInfoWithStorage[127.0.0.1:41644,DS-fa480b7a-553b-4586-bfdc-3c6a8f62c5a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40196,DS-3e3423b1-5755-4477-a266-67a12da73a7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-228085293-172.17.0.13-1597412725292:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38022,DS-b4752742-5f95-49c7-b9e2-0fa110bbb4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35609,DS-103a2667-683e-4e58-b606-e75b4bc3d6b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36021,DS-5507be69-0752-41fb-b232-1c46a41ee0de,DISK], DatanodeInfoWithStorage[127.0.0.1:37498,DS-61c4b18d-8807-4b36-97d9-d14aa7779101,DISK], DatanodeInfoWithStorage[127.0.0.1:36807,DS-31c9a5c6-212a-4d35-90d8-cb6d6151b2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36448,DS-fc7829ae-aa6e-47d7-84a5-cea03e688a07,DISK], DatanodeInfoWithStorage[127.0.0.1:41644,DS-fa480b7a-553b-4586-bfdc-3c6a8f62c5a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40196,DS-3e3423b1-5755-4477-a266-67a12da73a7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-687371966-172.17.0.13-1597412906809:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43743,DS-1e05b180-6673-4bca-af23-7a3a4110aa52,DISK], DatanodeInfoWithStorage[127.0.0.1:41631,DS-165e14f3-7379-4bad-bfc9-5420575e8ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:34200,DS-76c04939-dd39-4ba9-9198-aab4e4747749,DISK], DatanodeInfoWithStorage[127.0.0.1:36942,DS-2cb1b8c6-1627-42bb-9c31-0ef08e6052d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43426,DS-d354989f-f839-403a-9348-3ac2b32c396e,DISK], DatanodeInfoWithStorage[127.0.0.1:44985,DS-bfa40b1a-80be-471a-a8dd-96c8f7b638e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36753,DS-ee1ae961-faa2-492c-a831-87d5a04c0e27,DISK], DatanodeInfoWithStorage[127.0.0.1:40517,DS-03f4ad5e-6a65-48bf-ad7e-06374406e0b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-687371966-172.17.0.13-1597412906809:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43743,DS-1e05b180-6673-4bca-af23-7a3a4110aa52,DISK], DatanodeInfoWithStorage[127.0.0.1:41631,DS-165e14f3-7379-4bad-bfc9-5420575e8ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:34200,DS-76c04939-dd39-4ba9-9198-aab4e4747749,DISK], DatanodeInfoWithStorage[127.0.0.1:36942,DS-2cb1b8c6-1627-42bb-9c31-0ef08e6052d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43426,DS-d354989f-f839-403a-9348-3ac2b32c396e,DISK], DatanodeInfoWithStorage[127.0.0.1:44985,DS-bfa40b1a-80be-471a-a8dd-96c8f7b638e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36753,DS-ee1ae961-faa2-492c-a831-87d5a04c0e27,DISK], DatanodeInfoWithStorage[127.0.0.1:40517,DS-03f4ad5e-6a65-48bf-ad7e-06374406e0b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-442650681-172.17.0.13-1597413266799:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33716,DS-b492307c-43f6-4be0-9b5a-f841be2d9cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:45181,DS-7eed8791-7882-4846-a6ec-23fe87d81d42,DISK], DatanodeInfoWithStorage[127.0.0.1:40701,DS-770d868f-43fe-4eee-9f2e-d96cd2ba3e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44438,DS-25847c83-dec4-4664-bc03-9b42033ad487,DISK], DatanodeInfoWithStorage[127.0.0.1:40058,DS-fa80cffb-932a-4abb-a404-1475af0a56c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43895,DS-8bb0d274-289e-4135-98d9-e4eb1d929ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:40495,DS-c6807ce8-4cab-4d3d-a375-cac79153f1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35058,DS-299627be-b26b-4523-95f3-4fe35af9caa6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-442650681-172.17.0.13-1597413266799:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33716,DS-b492307c-43f6-4be0-9b5a-f841be2d9cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:45181,DS-7eed8791-7882-4846-a6ec-23fe87d81d42,DISK], DatanodeInfoWithStorage[127.0.0.1:40701,DS-770d868f-43fe-4eee-9f2e-d96cd2ba3e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44438,DS-25847c83-dec4-4664-bc03-9b42033ad487,DISK], DatanodeInfoWithStorage[127.0.0.1:40058,DS-fa80cffb-932a-4abb-a404-1475af0a56c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43895,DS-8bb0d274-289e-4135-98d9-e4eb1d929ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:40495,DS-c6807ce8-4cab-4d3d-a375-cac79153f1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35058,DS-299627be-b26b-4523-95f3-4fe35af9caa6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-281514984-172.17.0.13-1597414322574:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41340,DS-6312a3a6-0fe8-443e-a3ae-8d9a0a5ad176,DISK], DatanodeInfoWithStorage[127.0.0.1:37070,DS-8cbb6fa1-8564-4808-8ae1-6798bb1ca71a,DISK], DatanodeInfoWithStorage[127.0.0.1:36289,DS-1ecddb36-0eae-4333-b413-da681d61d578,DISK], DatanodeInfoWithStorage[127.0.0.1:38222,DS-b995de41-4c8f-4040-b191-c8183b738fce,DISK], DatanodeInfoWithStorage[127.0.0.1:41078,DS-3fe450fe-3827-4d84-b648-c38350b15ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:41486,DS-677c72fb-a9ac-4706-aeb1-706a09da898f,DISK], DatanodeInfoWithStorage[127.0.0.1:44109,DS-d844a77f-dfd3-46b9-bb1d-a3b34caf1a83,DISK], DatanodeInfoWithStorage[127.0.0.1:40991,DS-32920d2a-b80a-4e40-b906-d6d9706e2c51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-281514984-172.17.0.13-1597414322574:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41340,DS-6312a3a6-0fe8-443e-a3ae-8d9a0a5ad176,DISK], DatanodeInfoWithStorage[127.0.0.1:37070,DS-8cbb6fa1-8564-4808-8ae1-6798bb1ca71a,DISK], DatanodeInfoWithStorage[127.0.0.1:36289,DS-1ecddb36-0eae-4333-b413-da681d61d578,DISK], DatanodeInfoWithStorage[127.0.0.1:38222,DS-b995de41-4c8f-4040-b191-c8183b738fce,DISK], DatanodeInfoWithStorage[127.0.0.1:41078,DS-3fe450fe-3827-4d84-b648-c38350b15ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:41486,DS-677c72fb-a9ac-4706-aeb1-706a09da898f,DISK], DatanodeInfoWithStorage[127.0.0.1:44109,DS-d844a77f-dfd3-46b9-bb1d-a3b34caf1a83,DISK], DatanodeInfoWithStorage[127.0.0.1:40991,DS-32920d2a-b80a-4e40-b906-d6d9706e2c51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2071987813-172.17.0.13-1597414488944:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38753,DS-afadff2a-a8b9-409a-93d1-4a0d26ad2acd,DISK], DatanodeInfoWithStorage[127.0.0.1:43781,DS-a278f2d5-f905-4de5-823a-e612d264e1de,DISK], DatanodeInfoWithStorage[127.0.0.1:34341,DS-66448789-9fc1-404a-af73-694a5433bef3,DISK], DatanodeInfoWithStorage[127.0.0.1:45064,DS-6a395033-b4cb-4290-adc2-a564cd44ebaa,DISK], DatanodeInfoWithStorage[127.0.0.1:35198,DS-b6480142-7f7f-4a26-8b8d-354d21205b29,DISK], DatanodeInfoWithStorage[127.0.0.1:35386,DS-099d94b1-1e30-4311-a2e5-6f0ad9fa953f,DISK], DatanodeInfoWithStorage[127.0.0.1:42392,DS-03713241-8028-4325-93af-6c96395fca9c,DISK], DatanodeInfoWithStorage[127.0.0.1:42606,DS-00ae785e-6c7a-4e17-8e54-5bac1f7baf5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2071987813-172.17.0.13-1597414488944:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38753,DS-afadff2a-a8b9-409a-93d1-4a0d26ad2acd,DISK], DatanodeInfoWithStorage[127.0.0.1:43781,DS-a278f2d5-f905-4de5-823a-e612d264e1de,DISK], DatanodeInfoWithStorage[127.0.0.1:34341,DS-66448789-9fc1-404a-af73-694a5433bef3,DISK], DatanodeInfoWithStorage[127.0.0.1:45064,DS-6a395033-b4cb-4290-adc2-a564cd44ebaa,DISK], DatanodeInfoWithStorage[127.0.0.1:35198,DS-b6480142-7f7f-4a26-8b8d-354d21205b29,DISK], DatanodeInfoWithStorage[127.0.0.1:35386,DS-099d94b1-1e30-4311-a2e5-6f0ad9fa953f,DISK], DatanodeInfoWithStorage[127.0.0.1:42392,DS-03713241-8028-4325-93af-6c96395fca9c,DISK], DatanodeInfoWithStorage[127.0.0.1:42606,DS-00ae785e-6c7a-4e17-8e54-5bac1f7baf5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1899694567-172.17.0.13-1597415107630:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39086,DS-6082fc68-302b-4c28-a985-057bcdb2f47a,DISK], DatanodeInfoWithStorage[127.0.0.1:42361,DS-660392b3-8f69-4b57-8c18-b157d3684372,DISK], DatanodeInfoWithStorage[127.0.0.1:41123,DS-d6e6aa08-5d77-4b76-95ae-50634f34f1b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46423,DS-d8a537e7-ee11-40e1-89fa-1b9f69707269,DISK], DatanodeInfoWithStorage[127.0.0.1:33281,DS-58c3357a-a6a3-410d-8ede-f4747433378a,DISK], DatanodeInfoWithStorage[127.0.0.1:36461,DS-63da9862-c29a-48c7-878e-b6a9b3653ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:39096,DS-7fdae8b7-8af9-4bbb-b73c-79d844f783d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40656,DS-18b750b7-9ed5-4d54-a7b0-9f772e610d0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1899694567-172.17.0.13-1597415107630:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39086,DS-6082fc68-302b-4c28-a985-057bcdb2f47a,DISK], DatanodeInfoWithStorage[127.0.0.1:42361,DS-660392b3-8f69-4b57-8c18-b157d3684372,DISK], DatanodeInfoWithStorage[127.0.0.1:41123,DS-d6e6aa08-5d77-4b76-95ae-50634f34f1b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46423,DS-d8a537e7-ee11-40e1-89fa-1b9f69707269,DISK], DatanodeInfoWithStorage[127.0.0.1:33281,DS-58c3357a-a6a3-410d-8ede-f4747433378a,DISK], DatanodeInfoWithStorage[127.0.0.1:36461,DS-63da9862-c29a-48c7-878e-b6a9b3653ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:39096,DS-7fdae8b7-8af9-4bbb-b73c-79d844f783d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40656,DS-18b750b7-9ed5-4d54-a7b0-9f772e610d0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1585317791-172.17.0.13-1597415241209:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41109,DS-a840560f-d981-40fd-8921-a076c57bc28a,DISK], DatanodeInfoWithStorage[127.0.0.1:42902,DS-72661049-08bb-404e-8723-fd31a2b06f33,DISK], DatanodeInfoWithStorage[127.0.0.1:45255,DS-050acc0a-f998-4c50-b4c4-5eb248140527,DISK], DatanodeInfoWithStorage[127.0.0.1:45481,DS-debce751-ee7f-4a4e-8cdc-710f8de65b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:39009,DS-bfcef922-1489-433a-8712-8c2ce4852b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:34887,DS-b8ece4f1-e35d-4a87-9dce-26de6167731e,DISK], DatanodeInfoWithStorage[127.0.0.1:41022,DS-5919e2b7-21b8-43cb-bf9d-0590c69ad01c,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-f4c3811d-1c12-4de3-954b-e35be5d1d188,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1585317791-172.17.0.13-1597415241209:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41109,DS-a840560f-d981-40fd-8921-a076c57bc28a,DISK], DatanodeInfoWithStorage[127.0.0.1:42902,DS-72661049-08bb-404e-8723-fd31a2b06f33,DISK], DatanodeInfoWithStorage[127.0.0.1:45255,DS-050acc0a-f998-4c50-b4c4-5eb248140527,DISK], DatanodeInfoWithStorage[127.0.0.1:45481,DS-debce751-ee7f-4a4e-8cdc-710f8de65b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:39009,DS-bfcef922-1489-433a-8712-8c2ce4852b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:34887,DS-b8ece4f1-e35d-4a87-9dce-26de6167731e,DISK], DatanodeInfoWithStorage[127.0.0.1:41022,DS-5919e2b7-21b8-43cb-bf9d-0590c69ad01c,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-f4c3811d-1c12-4de3-954b-e35be5d1d188,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 6828
