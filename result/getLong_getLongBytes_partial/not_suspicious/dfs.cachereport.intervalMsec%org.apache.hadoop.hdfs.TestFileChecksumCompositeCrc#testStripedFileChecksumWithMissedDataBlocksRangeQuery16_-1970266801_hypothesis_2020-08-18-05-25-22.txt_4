reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-41605212-172.17.0.8-1597728478274:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37719,DS-bea60694-0f92-4d37-b903-f2ebe236cdcc,DISK], DatanodeInfoWithStorage[127.0.0.1:35632,DS-db01310d-5934-49b8-ba76-0578533c9e54,DISK], DatanodeInfoWithStorage[127.0.0.1:43269,DS-21487074-9147-4f82-b697-d84698b7fc4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38029,DS-d6c868ed-7b80-4675-9215-46c9a7902e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:45136,DS-3465cad9-44fd-4480-a9ab-7cffa5e8f001,DISK], DatanodeInfoWithStorage[127.0.0.1:41273,DS-aa093417-f275-477b-8190-c61ef1a2739c,DISK], DatanodeInfoWithStorage[127.0.0.1:36872,DS-eec8b0bb-364b-46df-b7c5-d7759f5fa3af,DISK], DatanodeInfoWithStorage[127.0.0.1:36500,DS-1d670e26-e7b6-4628-9b44-15bb3b25e40b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-41605212-172.17.0.8-1597728478274:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37719,DS-bea60694-0f92-4d37-b903-f2ebe236cdcc,DISK], DatanodeInfoWithStorage[127.0.0.1:35632,DS-db01310d-5934-49b8-ba76-0578533c9e54,DISK], DatanodeInfoWithStorage[127.0.0.1:43269,DS-21487074-9147-4f82-b697-d84698b7fc4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38029,DS-d6c868ed-7b80-4675-9215-46c9a7902e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:45136,DS-3465cad9-44fd-4480-a9ab-7cffa5e8f001,DISK], DatanodeInfoWithStorage[127.0.0.1:41273,DS-aa093417-f275-477b-8190-c61ef1a2739c,DISK], DatanodeInfoWithStorage[127.0.0.1:36872,DS-eec8b0bb-364b-46df-b7c5-d7759f5fa3af,DISK], DatanodeInfoWithStorage[127.0.0.1:36500,DS-1d670e26-e7b6-4628-9b44-15bb3b25e40b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-68352635-172.17.0.8-1597728804997:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44817,DS-469793da-4a6b-44ea-a20e-daa495dd857a,DISK], DatanodeInfoWithStorage[127.0.0.1:40956,DS-56389724-68f0-4845-94c4-90d47690e9e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46235,DS-b421aadb-7a4c-43af-b84f-9c54ce1d1c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:33388,DS-b46914ba-8b3d-42e7-b594-aa33ba263357,DISK], DatanodeInfoWithStorage[127.0.0.1:45220,DS-d4da48ae-35bd-4ed6-8635-a12cfff0bb2e,DISK], DatanodeInfoWithStorage[127.0.0.1:45615,DS-1c98e15f-dc92-4e10-8933-e55b93ee9e99,DISK], DatanodeInfoWithStorage[127.0.0.1:33447,DS-18de4ea5-a624-415a-87de-f0e79ec96340,DISK], DatanodeInfoWithStorage[127.0.0.1:43792,DS-b969e4bb-b908-4e7b-ad29-ec274b0963da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-68352635-172.17.0.8-1597728804997:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44817,DS-469793da-4a6b-44ea-a20e-daa495dd857a,DISK], DatanodeInfoWithStorage[127.0.0.1:40956,DS-56389724-68f0-4845-94c4-90d47690e9e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46235,DS-b421aadb-7a4c-43af-b84f-9c54ce1d1c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:33388,DS-b46914ba-8b3d-42e7-b594-aa33ba263357,DISK], DatanodeInfoWithStorage[127.0.0.1:45220,DS-d4da48ae-35bd-4ed6-8635-a12cfff0bb2e,DISK], DatanodeInfoWithStorage[127.0.0.1:45615,DS-1c98e15f-dc92-4e10-8933-e55b93ee9e99,DISK], DatanodeInfoWithStorage[127.0.0.1:33447,DS-18de4ea5-a624-415a-87de-f0e79ec96340,DISK], DatanodeInfoWithStorage[127.0.0.1:43792,DS-b969e4bb-b908-4e7b-ad29-ec274b0963da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-559882759-172.17.0.8-1597729069583:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34226,DS-791c7ef0-5862-43d9-aad9-02348c3d8e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37832,DS-e04719a1-b0dd-4e2a-b67b-f516ac1e8c27,DISK], DatanodeInfoWithStorage[127.0.0.1:36680,DS-9857070b-2036-4031-8d8f-56ad85687197,DISK], DatanodeInfoWithStorage[127.0.0.1:39514,DS-40e86b71-11c2-4d59-9b2f-ae552e7548c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42257,DS-f50e31df-a0fb-4891-9094-a1e39e5dc77b,DISK], DatanodeInfoWithStorage[127.0.0.1:36120,DS-5fcab919-2214-42d5-bb44-e2a411bd809d,DISK], DatanodeInfoWithStorage[127.0.0.1:42706,DS-6c0fcddc-d2c0-4b2a-8054-5eab35eec2bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41520,DS-f48020cf-40d7-4e6e-8d74-321c74e1fd0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-559882759-172.17.0.8-1597729069583:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34226,DS-791c7ef0-5862-43d9-aad9-02348c3d8e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37832,DS-e04719a1-b0dd-4e2a-b67b-f516ac1e8c27,DISK], DatanodeInfoWithStorage[127.0.0.1:36680,DS-9857070b-2036-4031-8d8f-56ad85687197,DISK], DatanodeInfoWithStorage[127.0.0.1:39514,DS-40e86b71-11c2-4d59-9b2f-ae552e7548c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42257,DS-f50e31df-a0fb-4891-9094-a1e39e5dc77b,DISK], DatanodeInfoWithStorage[127.0.0.1:36120,DS-5fcab919-2214-42d5-bb44-e2a411bd809d,DISK], DatanodeInfoWithStorage[127.0.0.1:42706,DS-6c0fcddc-d2c0-4b2a-8054-5eab35eec2bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41520,DS-f48020cf-40d7-4e6e-8d74-321c74e1fd0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1299959255-172.17.0.8-1597729202361:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43385,DS-77c0d7bc-afe1-447e-875b-7efc89884cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:33618,DS-5c92babb-0758-475f-974e-8a8a1c4b9da8,DISK], DatanodeInfoWithStorage[127.0.0.1:44100,DS-d7fc236c-cec3-410e-b0cd-86f588003987,DISK], DatanodeInfoWithStorage[127.0.0.1:36203,DS-85611a11-9d6e-4461-84f0-a91ca371fdbf,DISK], DatanodeInfoWithStorage[127.0.0.1:34517,DS-e993fe89-2d5c-4a9f-8c75-202d6b6121b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44029,DS-f5901232-192a-4767-a5b7-0f6f0561f59a,DISK], DatanodeInfoWithStorage[127.0.0.1:37569,DS-de599acb-fa90-4e55-9263-595702d6ba5d,DISK], DatanodeInfoWithStorage[127.0.0.1:37530,DS-cec5e735-eb1f-4b8d-ad35-0d1f4719ae9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1299959255-172.17.0.8-1597729202361:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43385,DS-77c0d7bc-afe1-447e-875b-7efc89884cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:33618,DS-5c92babb-0758-475f-974e-8a8a1c4b9da8,DISK], DatanodeInfoWithStorage[127.0.0.1:44100,DS-d7fc236c-cec3-410e-b0cd-86f588003987,DISK], DatanodeInfoWithStorage[127.0.0.1:36203,DS-85611a11-9d6e-4461-84f0-a91ca371fdbf,DISK], DatanodeInfoWithStorage[127.0.0.1:34517,DS-e993fe89-2d5c-4a9f-8c75-202d6b6121b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44029,DS-f5901232-192a-4767-a5b7-0f6f0561f59a,DISK], DatanodeInfoWithStorage[127.0.0.1:37569,DS-de599acb-fa90-4e55-9263-595702d6ba5d,DISK], DatanodeInfoWithStorage[127.0.0.1:37530,DS-cec5e735-eb1f-4b8d-ad35-0d1f4719ae9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-503936987-172.17.0.8-1597729266328:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36679,DS-d22ef61d-b94a-4ad1-a4e7-c5cea739aef1,DISK], DatanodeInfoWithStorage[127.0.0.1:41197,DS-7e2f84da-a27a-4e74-89ad-b5bd5a114ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:44155,DS-a3726f86-fea2-4f34-b8d6-37462cdb264b,DISK], DatanodeInfoWithStorage[127.0.0.1:33118,DS-83bbf25e-a738-48be-86af-b15d1c40c1aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37001,DS-e4e526f7-1cca-4329-ad27-4d639bd12002,DISK], DatanodeInfoWithStorage[127.0.0.1:34915,DS-d2d0c9b7-b8c7-4e18-baa1-bdd9a6bd92ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44524,DS-27075de4-8a18-467b-8a8b-9a575dddce26,DISK], DatanodeInfoWithStorage[127.0.0.1:37245,DS-9f9295fb-a4f7-4d26-9b25-d567316fe4fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-503936987-172.17.0.8-1597729266328:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36679,DS-d22ef61d-b94a-4ad1-a4e7-c5cea739aef1,DISK], DatanodeInfoWithStorage[127.0.0.1:41197,DS-7e2f84da-a27a-4e74-89ad-b5bd5a114ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:44155,DS-a3726f86-fea2-4f34-b8d6-37462cdb264b,DISK], DatanodeInfoWithStorage[127.0.0.1:33118,DS-83bbf25e-a738-48be-86af-b15d1c40c1aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37001,DS-e4e526f7-1cca-4329-ad27-4d639bd12002,DISK], DatanodeInfoWithStorage[127.0.0.1:34915,DS-d2d0c9b7-b8c7-4e18-baa1-bdd9a6bd92ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44524,DS-27075de4-8a18-467b-8a8b-9a575dddce26,DISK], DatanodeInfoWithStorage[127.0.0.1:37245,DS-9f9295fb-a4f7-4d26-9b25-d567316fe4fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1236220866-172.17.0.8-1597729333921:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37802,DS-c653e4ae-7ed3-4372-b8ed-7053bd14a34f,DISK], DatanodeInfoWithStorage[127.0.0.1:41330,DS-85f0c89d-4352-4dd5-b028-10da82db7307,DISK], DatanodeInfoWithStorage[127.0.0.1:43204,DS-a5eba3d2-df57-4eee-b17e-bbb48a937359,DISK], DatanodeInfoWithStorage[127.0.0.1:36674,DS-9260803f-56b8-4e6b-9689-26dc457ba32d,DISK], DatanodeInfoWithStorage[127.0.0.1:34107,DS-af1a1e31-3805-47cd-8f61-cc03e8e1473b,DISK], DatanodeInfoWithStorage[127.0.0.1:33784,DS-e596cc37-b648-4c25-a209-b5bdd8be7e26,DISK], DatanodeInfoWithStorage[127.0.0.1:46169,DS-a227575f-d4c6-4c3d-82d6-b8ebd0d3679b,DISK], DatanodeInfoWithStorage[127.0.0.1:45743,DS-2bd63d5e-ff48-499c-9d77-7557da207489,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1236220866-172.17.0.8-1597729333921:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37802,DS-c653e4ae-7ed3-4372-b8ed-7053bd14a34f,DISK], DatanodeInfoWithStorage[127.0.0.1:41330,DS-85f0c89d-4352-4dd5-b028-10da82db7307,DISK], DatanodeInfoWithStorage[127.0.0.1:43204,DS-a5eba3d2-df57-4eee-b17e-bbb48a937359,DISK], DatanodeInfoWithStorage[127.0.0.1:36674,DS-9260803f-56b8-4e6b-9689-26dc457ba32d,DISK], DatanodeInfoWithStorage[127.0.0.1:34107,DS-af1a1e31-3805-47cd-8f61-cc03e8e1473b,DISK], DatanodeInfoWithStorage[127.0.0.1:33784,DS-e596cc37-b648-4c25-a209-b5bdd8be7e26,DISK], DatanodeInfoWithStorage[127.0.0.1:46169,DS-a227575f-d4c6-4c3d-82d6-b8ebd0d3679b,DISK], DatanodeInfoWithStorage[127.0.0.1:45743,DS-2bd63d5e-ff48-499c-9d77-7557da207489,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1796652828-172.17.0.8-1597729468651:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41930,DS-29587a93-aec5-4053-9b6f-333f3944fcd5,DISK], DatanodeInfoWithStorage[127.0.0.1:36347,DS-2092ea92-b7fa-4584-899e-7b9786767caa,DISK], DatanodeInfoWithStorage[127.0.0.1:42110,DS-297b163f-17d4-48ad-b7e9-9bcc4aa7c421,DISK], DatanodeInfoWithStorage[127.0.0.1:46680,DS-534cd2b2-dd71-4008-b5ac-2067cccf4893,DISK], DatanodeInfoWithStorage[127.0.0.1:38320,DS-e01eb304-4e6a-49a1-9e17-2532d9826b06,DISK], DatanodeInfoWithStorage[127.0.0.1:39962,DS-fd9275a8-7960-4f0d-8d43-98ceec9bb17f,DISK], DatanodeInfoWithStorage[127.0.0.1:41685,DS-13c2fcb1-199f-4ced-b27b-b49d4ff7973d,DISK], DatanodeInfoWithStorage[127.0.0.1:41407,DS-e0bb812e-8d9c-46e8-9901-6eaa7a653571,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1796652828-172.17.0.8-1597729468651:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41930,DS-29587a93-aec5-4053-9b6f-333f3944fcd5,DISK], DatanodeInfoWithStorage[127.0.0.1:36347,DS-2092ea92-b7fa-4584-899e-7b9786767caa,DISK], DatanodeInfoWithStorage[127.0.0.1:42110,DS-297b163f-17d4-48ad-b7e9-9bcc4aa7c421,DISK], DatanodeInfoWithStorage[127.0.0.1:46680,DS-534cd2b2-dd71-4008-b5ac-2067cccf4893,DISK], DatanodeInfoWithStorage[127.0.0.1:38320,DS-e01eb304-4e6a-49a1-9e17-2532d9826b06,DISK], DatanodeInfoWithStorage[127.0.0.1:39962,DS-fd9275a8-7960-4f0d-8d43-98ceec9bb17f,DISK], DatanodeInfoWithStorage[127.0.0.1:41685,DS-13c2fcb1-199f-4ced-b27b-b49d4ff7973d,DISK], DatanodeInfoWithStorage[127.0.0.1:41407,DS-e0bb812e-8d9c-46e8-9901-6eaa7a653571,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1841040264-172.17.0.8-1597729693868:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41591,DS-bd36f5b8-1faf-4956-b995-bd4387d6a648,DISK], DatanodeInfoWithStorage[127.0.0.1:46860,DS-67fc931a-5015-4e3d-8461-ab15db853013,DISK], DatanodeInfoWithStorage[127.0.0.1:45899,DS-0d09b7e2-e29a-4039-a067-42760ed8c141,DISK], DatanodeInfoWithStorage[127.0.0.1:43606,DS-18972abf-ee57-44a3-801d-a1e9fd375709,DISK], DatanodeInfoWithStorage[127.0.0.1:45355,DS-35ccd113-34a4-49d0-9c56-100a97a99716,DISK], DatanodeInfoWithStorage[127.0.0.1:41483,DS-47fb69c6-e123-4fa7-9ad6-87b28afb6489,DISK], DatanodeInfoWithStorage[127.0.0.1:40555,DS-80bc7f15-f62c-47dd-8b95-aaced8ca35b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45210,DS-16cdaa0f-ad4a-4418-90ee-241cf60091b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1841040264-172.17.0.8-1597729693868:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41591,DS-bd36f5b8-1faf-4956-b995-bd4387d6a648,DISK], DatanodeInfoWithStorage[127.0.0.1:46860,DS-67fc931a-5015-4e3d-8461-ab15db853013,DISK], DatanodeInfoWithStorage[127.0.0.1:45899,DS-0d09b7e2-e29a-4039-a067-42760ed8c141,DISK], DatanodeInfoWithStorage[127.0.0.1:43606,DS-18972abf-ee57-44a3-801d-a1e9fd375709,DISK], DatanodeInfoWithStorage[127.0.0.1:45355,DS-35ccd113-34a4-49d0-9c56-100a97a99716,DISK], DatanodeInfoWithStorage[127.0.0.1:41483,DS-47fb69c6-e123-4fa7-9ad6-87b28afb6489,DISK], DatanodeInfoWithStorage[127.0.0.1:40555,DS-80bc7f15-f62c-47dd-8b95-aaced8ca35b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45210,DS-16cdaa0f-ad4a-4418-90ee-241cf60091b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1243524379-172.17.0.8-1597729731783:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38769,DS-f1ad65a1-359e-4767-8fa3-23c50b74f8f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44564,DS-ff2381ae-958c-4661-94c0-913b6b28ae8d,DISK], DatanodeInfoWithStorage[127.0.0.1:43306,DS-6390dc87-2ef3-4d24-b6a7-4f30fe29a588,DISK], DatanodeInfoWithStorage[127.0.0.1:34327,DS-91e1563a-0545-4249-8173-b886eef29e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:37925,DS-868f449f-9392-4dce-9947-ae15d6a369b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42846,DS-b22d5be8-1dd4-4c9c-a2da-7eecabfaabf1,DISK], DatanodeInfoWithStorage[127.0.0.1:40760,DS-379cf8eb-dade-47eb-a705-89e4fda6ec87,DISK], DatanodeInfoWithStorage[127.0.0.1:35799,DS-3d0cfc68-1314-4e25-9d7d-26cfaac6b7c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1243524379-172.17.0.8-1597729731783:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38769,DS-f1ad65a1-359e-4767-8fa3-23c50b74f8f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44564,DS-ff2381ae-958c-4661-94c0-913b6b28ae8d,DISK], DatanodeInfoWithStorage[127.0.0.1:43306,DS-6390dc87-2ef3-4d24-b6a7-4f30fe29a588,DISK], DatanodeInfoWithStorage[127.0.0.1:34327,DS-91e1563a-0545-4249-8173-b886eef29e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:37925,DS-868f449f-9392-4dce-9947-ae15d6a369b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42846,DS-b22d5be8-1dd4-4c9c-a2da-7eecabfaabf1,DISK], DatanodeInfoWithStorage[127.0.0.1:40760,DS-379cf8eb-dade-47eb-a705-89e4fda6ec87,DISK], DatanodeInfoWithStorage[127.0.0.1:35799,DS-3d0cfc68-1314-4e25-9d7d-26cfaac6b7c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-375744232-172.17.0.8-1597729859513:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41656,DS-dad64652-d3c0-480d-b726-c82a6414e06f,DISK], DatanodeInfoWithStorage[127.0.0.1:33525,DS-374cc727-67fb-4726-a487-a9e49f008673,DISK], DatanodeInfoWithStorage[127.0.0.1:43896,DS-a804a2cd-1cea-40cd-bcbe-3d834bc658b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42722,DS-9c17347e-c33a-4adc-83b8-6690172043c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41459,DS-646fad24-8125-4405-94fb-c7cca5fa75dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43705,DS-4f27b71d-a54e-45e9-8751-25946b46969c,DISK], DatanodeInfoWithStorage[127.0.0.1:35849,DS-4dd51f44-a813-489f-9cc6-8087a2b07afc,DISK], DatanodeInfoWithStorage[127.0.0.1:33700,DS-1477acfb-d04f-4d2d-8259-b8d8e74f2ff4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-375744232-172.17.0.8-1597729859513:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41656,DS-dad64652-d3c0-480d-b726-c82a6414e06f,DISK], DatanodeInfoWithStorage[127.0.0.1:33525,DS-374cc727-67fb-4726-a487-a9e49f008673,DISK], DatanodeInfoWithStorage[127.0.0.1:43896,DS-a804a2cd-1cea-40cd-bcbe-3d834bc658b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42722,DS-9c17347e-c33a-4adc-83b8-6690172043c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41459,DS-646fad24-8125-4405-94fb-c7cca5fa75dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43705,DS-4f27b71d-a54e-45e9-8751-25946b46969c,DISK], DatanodeInfoWithStorage[127.0.0.1:35849,DS-4dd51f44-a813-489f-9cc6-8087a2b07afc,DISK], DatanodeInfoWithStorage[127.0.0.1:33700,DS-1477acfb-d04f-4d2d-8259-b8d8e74f2ff4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-342027916-172.17.0.8-1597730363838:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37038,DS-83d58234-4642-406e-b388-bee1241e54da,DISK], DatanodeInfoWithStorage[127.0.0.1:35638,DS-005ed8c6-7dee-4e95-aed8-f1b54577c2f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36789,DS-7db3198b-fd41-4e32-b32a-11a84be68c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:39278,DS-2737fb13-18b7-4397-b29b-d10600397aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:33653,DS-3e9156b8-1ff5-4ec4-bc4e-253d2097a5ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37772,DS-a794d315-bf36-465f-8063-c460cbfc955a,DISK], DatanodeInfoWithStorage[127.0.0.1:46275,DS-dfe35ca3-5d4d-4aba-9f4b-30072e617a61,DISK], DatanodeInfoWithStorage[127.0.0.1:34609,DS-30e5e181-9eb8-49be-8dc1-0644d4557e8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-342027916-172.17.0.8-1597730363838:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37038,DS-83d58234-4642-406e-b388-bee1241e54da,DISK], DatanodeInfoWithStorage[127.0.0.1:35638,DS-005ed8c6-7dee-4e95-aed8-f1b54577c2f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36789,DS-7db3198b-fd41-4e32-b32a-11a84be68c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:39278,DS-2737fb13-18b7-4397-b29b-d10600397aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:33653,DS-3e9156b8-1ff5-4ec4-bc4e-253d2097a5ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37772,DS-a794d315-bf36-465f-8063-c460cbfc955a,DISK], DatanodeInfoWithStorage[127.0.0.1:46275,DS-dfe35ca3-5d4d-4aba-9f4b-30072e617a61,DISK], DatanodeInfoWithStorage[127.0.0.1:34609,DS-30e5e181-9eb8-49be-8dc1-0644d4557e8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2014107402-172.17.0.8-1597730536756:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39184,DS-c3911432-6865-449b-add6-e4c4cdbae331,DISK], DatanodeInfoWithStorage[127.0.0.1:34519,DS-52698295-3e4a-4907-a381-02a7233c52fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44044,DS-7407bfd9-7838-49f7-afcd-ab74cb895c67,DISK], DatanodeInfoWithStorage[127.0.0.1:35983,DS-35b21ecd-fde6-4db0-8258-f87e20fefe57,DISK], DatanodeInfoWithStorage[127.0.0.1:41407,DS-01cbaf5b-d9a4-4806-898c-cca19a377c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:45899,DS-ae2fae9b-edca-424f-99b1-f5abca7b753c,DISK], DatanodeInfoWithStorage[127.0.0.1:44854,DS-1ad8b3de-9c0b-46f0-9972-503e02eb727d,DISK], DatanodeInfoWithStorage[127.0.0.1:35654,DS-0a59a3ae-163c-42c9-87f7-4fce197cdf10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2014107402-172.17.0.8-1597730536756:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39184,DS-c3911432-6865-449b-add6-e4c4cdbae331,DISK], DatanodeInfoWithStorage[127.0.0.1:34519,DS-52698295-3e4a-4907-a381-02a7233c52fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44044,DS-7407bfd9-7838-49f7-afcd-ab74cb895c67,DISK], DatanodeInfoWithStorage[127.0.0.1:35983,DS-35b21ecd-fde6-4db0-8258-f87e20fefe57,DISK], DatanodeInfoWithStorage[127.0.0.1:41407,DS-01cbaf5b-d9a4-4806-898c-cca19a377c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:45899,DS-ae2fae9b-edca-424f-99b1-f5abca7b753c,DISK], DatanodeInfoWithStorage[127.0.0.1:44854,DS-1ad8b3de-9c0b-46f0-9972-503e02eb727d,DISK], DatanodeInfoWithStorage[127.0.0.1:35654,DS-0a59a3ae-163c-42c9-87f7-4fce197cdf10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1098604819-172.17.0.8-1597730570695:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42752,DS-11e5d27b-9e0b-4627-b435-1a1e31950074,DISK], DatanodeInfoWithStorage[127.0.0.1:39126,DS-0f7a5a38-2228-4161-a3bd-f22911064719,DISK], DatanodeInfoWithStorage[127.0.0.1:38213,DS-8cc045e0-37cb-43e8-be73-9af14104e7fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38776,DS-028e589a-6552-4372-b307-b7abbbeab06e,DISK], DatanodeInfoWithStorage[127.0.0.1:45098,DS-7e0ccb0c-a660-40c1-ab29-f5262b00ec94,DISK], DatanodeInfoWithStorage[127.0.0.1:35451,DS-a5aea8fa-20cb-4632-8807-292ce2acdb96,DISK], DatanodeInfoWithStorage[127.0.0.1:34684,DS-14a25884-d203-4d37-9113-7f1f650beb63,DISK], DatanodeInfoWithStorage[127.0.0.1:46771,DS-27275466-7880-4368-b92e-2ab954625a36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1098604819-172.17.0.8-1597730570695:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42752,DS-11e5d27b-9e0b-4627-b435-1a1e31950074,DISK], DatanodeInfoWithStorage[127.0.0.1:39126,DS-0f7a5a38-2228-4161-a3bd-f22911064719,DISK], DatanodeInfoWithStorage[127.0.0.1:38213,DS-8cc045e0-37cb-43e8-be73-9af14104e7fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38776,DS-028e589a-6552-4372-b307-b7abbbeab06e,DISK], DatanodeInfoWithStorage[127.0.0.1:45098,DS-7e0ccb0c-a660-40c1-ab29-f5262b00ec94,DISK], DatanodeInfoWithStorage[127.0.0.1:35451,DS-a5aea8fa-20cb-4632-8807-292ce2acdb96,DISK], DatanodeInfoWithStorage[127.0.0.1:34684,DS-14a25884-d203-4d37-9113-7f1f650beb63,DISK], DatanodeInfoWithStorage[127.0.0.1:46771,DS-27275466-7880-4368-b92e-2ab954625a36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1896376052-172.17.0.8-1597730778748:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44829,DS-fd0230fe-c5fd-45ff-95dc-3c78bc2edcdf,DISK], DatanodeInfoWithStorage[127.0.0.1:39616,DS-751267a0-405d-4aa0-85cc-ae727b50f2d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34236,DS-7e645c42-3a84-4650-b425-da12d2ac1a44,DISK], DatanodeInfoWithStorage[127.0.0.1:43948,DS-fbad61fe-eff8-4d35-b2e4-d4db948a99c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37534,DS-68876712-927b-46dd-9c17-c7f2435573a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44871,DS-693f9d64-25ed-45a3-9541-284d0c993365,DISK], DatanodeInfoWithStorage[127.0.0.1:43911,DS-c4a7d507-7a82-4d84-b6c5-74598f597b87,DISK], DatanodeInfoWithStorage[127.0.0.1:35021,DS-74d3c922-a5aa-4fdc-b154-cc9328c66294,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1896376052-172.17.0.8-1597730778748:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44829,DS-fd0230fe-c5fd-45ff-95dc-3c78bc2edcdf,DISK], DatanodeInfoWithStorage[127.0.0.1:39616,DS-751267a0-405d-4aa0-85cc-ae727b50f2d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34236,DS-7e645c42-3a84-4650-b425-da12d2ac1a44,DISK], DatanodeInfoWithStorage[127.0.0.1:43948,DS-fbad61fe-eff8-4d35-b2e4-d4db948a99c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37534,DS-68876712-927b-46dd-9c17-c7f2435573a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44871,DS-693f9d64-25ed-45a3-9541-284d0c993365,DISK], DatanodeInfoWithStorage[127.0.0.1:43911,DS-c4a7d507-7a82-4d84-b6c5-74598f597b87,DISK], DatanodeInfoWithStorage[127.0.0.1:35021,DS-74d3c922-a5aa-4fdc-b154-cc9328c66294,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-452626103-172.17.0.8-1597731052945:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41042,DS-7a32f1c6-5fd9-4834-86c0-b890b9466f08,DISK], DatanodeInfoWithStorage[127.0.0.1:46206,DS-e40ead8c-1dc4-44a1-b1ba-5ace92364cef,DISK], DatanodeInfoWithStorage[127.0.0.1:34776,DS-2499bc62-53f1-4de1-aee0-d02b7c56455d,DISK], DatanodeInfoWithStorage[127.0.0.1:38850,DS-95e66f12-5667-4462-a164-344b78e9564f,DISK], DatanodeInfoWithStorage[127.0.0.1:33039,DS-9e3beb3d-d821-4bea-a9e7-a2e28ed53184,DISK], DatanodeInfoWithStorage[127.0.0.1:36345,DS-ebaa032c-3007-4a71-a884-128259e0403d,DISK], DatanodeInfoWithStorage[127.0.0.1:35111,DS-8d8d9458-c6b2-4024-a9d9-f736d554eb44,DISK], DatanodeInfoWithStorage[127.0.0.1:42561,DS-7eed9c40-98e3-4c60-9678-8e7206784c5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-452626103-172.17.0.8-1597731052945:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41042,DS-7a32f1c6-5fd9-4834-86c0-b890b9466f08,DISK], DatanodeInfoWithStorage[127.0.0.1:46206,DS-e40ead8c-1dc4-44a1-b1ba-5ace92364cef,DISK], DatanodeInfoWithStorage[127.0.0.1:34776,DS-2499bc62-53f1-4de1-aee0-d02b7c56455d,DISK], DatanodeInfoWithStorage[127.0.0.1:38850,DS-95e66f12-5667-4462-a164-344b78e9564f,DISK], DatanodeInfoWithStorage[127.0.0.1:33039,DS-9e3beb3d-d821-4bea-a9e7-a2e28ed53184,DISK], DatanodeInfoWithStorage[127.0.0.1:36345,DS-ebaa032c-3007-4a71-a884-128259e0403d,DISK], DatanodeInfoWithStorage[127.0.0.1:35111,DS-8d8d9458-c6b2-4024-a9d9-f736d554eb44,DISK], DatanodeInfoWithStorage[127.0.0.1:42561,DS-7eed9c40-98e3-4c60-9678-8e7206784c5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1775313887-172.17.0.8-1597731089851:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35054,DS-68c3888d-3468-4cd6-843c-9542597e676f,DISK], DatanodeInfoWithStorage[127.0.0.1:42790,DS-be3841b8-2148-463a-a0fd-b506e406346d,DISK], DatanodeInfoWithStorage[127.0.0.1:39377,DS-877b6d3c-2a46-4c9f-a810-90b03fd5aa2f,DISK], DatanodeInfoWithStorage[127.0.0.1:35394,DS-cdccf591-e984-4f2a-975e-5202db382363,DISK], DatanodeInfoWithStorage[127.0.0.1:41287,DS-0191eacb-ebb8-4d1e-871e-114782ded563,DISK], DatanodeInfoWithStorage[127.0.0.1:44457,DS-cd9104ea-a54a-4290-a394-34c56795874b,DISK], DatanodeInfoWithStorage[127.0.0.1:36312,DS-6ba8b55c-ad04-4103-8b55-334f097b046e,DISK], DatanodeInfoWithStorage[127.0.0.1:44214,DS-674efa5e-616d-4dca-bc63-028d334977f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1775313887-172.17.0.8-1597731089851:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35054,DS-68c3888d-3468-4cd6-843c-9542597e676f,DISK], DatanodeInfoWithStorage[127.0.0.1:42790,DS-be3841b8-2148-463a-a0fd-b506e406346d,DISK], DatanodeInfoWithStorage[127.0.0.1:39377,DS-877b6d3c-2a46-4c9f-a810-90b03fd5aa2f,DISK], DatanodeInfoWithStorage[127.0.0.1:35394,DS-cdccf591-e984-4f2a-975e-5202db382363,DISK], DatanodeInfoWithStorage[127.0.0.1:41287,DS-0191eacb-ebb8-4d1e-871e-114782ded563,DISK], DatanodeInfoWithStorage[127.0.0.1:44457,DS-cd9104ea-a54a-4290-a394-34c56795874b,DISK], DatanodeInfoWithStorage[127.0.0.1:36312,DS-6ba8b55c-ad04-4103-8b55-334f097b046e,DISK], DatanodeInfoWithStorage[127.0.0.1:44214,DS-674efa5e-616d-4dca-bc63-028d334977f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1939753065-172.17.0.8-1597731203861:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42828,DS-22de12c8-10f8-4473-8390-0a0889d3c16c,DISK], DatanodeInfoWithStorage[127.0.0.1:37280,DS-32f4489c-5087-43a4-89cf-dd7e86930c81,DISK], DatanodeInfoWithStorage[127.0.0.1:42504,DS-1f480859-b94f-4e16-b9d6-3b147d9633e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45468,DS-dd1996b1-7a7f-4262-a358-f1df05518064,DISK], DatanodeInfoWithStorage[127.0.0.1:40717,DS-083cf5e6-5e7a-4532-b8aa-2f9473caf8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42488,DS-7842d425-bcbc-481b-904b-5c97d1f614ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38373,DS-023d319c-f32c-458b-a1ac-9aa82bc08a57,DISK], DatanodeInfoWithStorage[127.0.0.1:37482,DS-b32f6732-c772-4f0c-8755-da7edacf4517,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1939753065-172.17.0.8-1597731203861:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42828,DS-22de12c8-10f8-4473-8390-0a0889d3c16c,DISK], DatanodeInfoWithStorage[127.0.0.1:37280,DS-32f4489c-5087-43a4-89cf-dd7e86930c81,DISK], DatanodeInfoWithStorage[127.0.0.1:42504,DS-1f480859-b94f-4e16-b9d6-3b147d9633e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45468,DS-dd1996b1-7a7f-4262-a358-f1df05518064,DISK], DatanodeInfoWithStorage[127.0.0.1:40717,DS-083cf5e6-5e7a-4532-b8aa-2f9473caf8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42488,DS-7842d425-bcbc-481b-904b-5c97d1f614ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38373,DS-023d319c-f32c-458b-a1ac-9aa82bc08a57,DISK], DatanodeInfoWithStorage[127.0.0.1:37482,DS-b32f6732-c772-4f0c-8755-da7edacf4517,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-626434399-172.17.0.8-1597732525273:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32782,DS-1a37c6fb-1644-4f9e-acd1-dce768348b39,DISK], DatanodeInfoWithStorage[127.0.0.1:36181,DS-08d54c33-146b-46f2-ac19-3a05c616cfd2,DISK], DatanodeInfoWithStorage[127.0.0.1:45740,DS-bd7e5448-48ee-4449-9b23-afd3568ded70,DISK], DatanodeInfoWithStorage[127.0.0.1:36111,DS-b403c5e6-c4fc-4aee-be9a-c40005e12836,DISK], DatanodeInfoWithStorage[127.0.0.1:40509,DS-c09e9c22-1419-4df5-8825-5c3629585994,DISK], DatanodeInfoWithStorage[127.0.0.1:35445,DS-992f01e7-b32b-4d91-8e0e-63d91f381ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:34771,DS-f8e8ce17-52bb-4624-a127-e82325097410,DISK], DatanodeInfoWithStorage[127.0.0.1:46759,DS-258af142-d338-46c0-ba4c-1b3752903f8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-626434399-172.17.0.8-1597732525273:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32782,DS-1a37c6fb-1644-4f9e-acd1-dce768348b39,DISK], DatanodeInfoWithStorage[127.0.0.1:36181,DS-08d54c33-146b-46f2-ac19-3a05c616cfd2,DISK], DatanodeInfoWithStorage[127.0.0.1:45740,DS-bd7e5448-48ee-4449-9b23-afd3568ded70,DISK], DatanodeInfoWithStorage[127.0.0.1:36111,DS-b403c5e6-c4fc-4aee-be9a-c40005e12836,DISK], DatanodeInfoWithStorage[127.0.0.1:40509,DS-c09e9c22-1419-4df5-8825-5c3629585994,DISK], DatanodeInfoWithStorage[127.0.0.1:35445,DS-992f01e7-b32b-4d91-8e0e-63d91f381ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:34771,DS-f8e8ce17-52bb-4624-a127-e82325097410,DISK], DatanodeInfoWithStorage[127.0.0.1:46759,DS-258af142-d338-46c0-ba4c-1b3752903f8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1265850567-172.17.0.8-1597732875060:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33997,DS-f325941f-bfeb-4709-88b3-cfc00b75acd6,DISK], DatanodeInfoWithStorage[127.0.0.1:44398,DS-b089d76d-85ad-4937-a5d2-6f58450fb602,DISK], DatanodeInfoWithStorage[127.0.0.1:38933,DS-082fb947-22a4-40b6-9ed4-4e2826a7ab01,DISK], DatanodeInfoWithStorage[127.0.0.1:41307,DS-0285afb5-5d2e-49d2-b0a1-eff0fc23162d,DISK], DatanodeInfoWithStorage[127.0.0.1:36128,DS-7840b648-5d48-4032-bd5f-93e0afdd594a,DISK], DatanodeInfoWithStorage[127.0.0.1:44019,DS-68f0132e-082b-48ca-a43b-0e00dd9b6b72,DISK], DatanodeInfoWithStorage[127.0.0.1:36571,DS-4a41a3d2-fab4-48c1-9cd5-a7b75dc08d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:36238,DS-7fb09a2a-58de-447d-82c4-3d25befc36f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1265850567-172.17.0.8-1597732875060:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33997,DS-f325941f-bfeb-4709-88b3-cfc00b75acd6,DISK], DatanodeInfoWithStorage[127.0.0.1:44398,DS-b089d76d-85ad-4937-a5d2-6f58450fb602,DISK], DatanodeInfoWithStorage[127.0.0.1:38933,DS-082fb947-22a4-40b6-9ed4-4e2826a7ab01,DISK], DatanodeInfoWithStorage[127.0.0.1:41307,DS-0285afb5-5d2e-49d2-b0a1-eff0fc23162d,DISK], DatanodeInfoWithStorage[127.0.0.1:36128,DS-7840b648-5d48-4032-bd5f-93e0afdd594a,DISK], DatanodeInfoWithStorage[127.0.0.1:44019,DS-68f0132e-082b-48ca-a43b-0e00dd9b6b72,DISK], DatanodeInfoWithStorage[127.0.0.1:36571,DS-4a41a3d2-fab4-48c1-9cd5-a7b75dc08d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:36238,DS-7fb09a2a-58de-447d-82c4-3d25befc36f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1588438929-172.17.0.8-1597732942123:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43841,DS-bf3e6490-6f7f-4dc9-847c-e2520203981a,DISK], DatanodeInfoWithStorage[127.0.0.1:41701,DS-d006d3fa-6eb9-4242-9a69-62f6d8202443,DISK], DatanodeInfoWithStorage[127.0.0.1:37148,DS-ffe1c694-057b-4528-b91e-24df3c1fc1a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33976,DS-fa113e65-2f6f-4e6a-8218-5c2271640d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:46631,DS-1b5d7eaa-1475-472f-96f5-851a2aed4589,DISK], DatanodeInfoWithStorage[127.0.0.1:37183,DS-70a8e352-c44b-4d30-b602-ac41818cf78e,DISK], DatanodeInfoWithStorage[127.0.0.1:34727,DS-cea935ed-7801-455b-b0e6-c6c6a2dede9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45107,DS-99d20155-bf58-4931-9c97-2dabba573932,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1588438929-172.17.0.8-1597732942123:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43841,DS-bf3e6490-6f7f-4dc9-847c-e2520203981a,DISK], DatanodeInfoWithStorage[127.0.0.1:41701,DS-d006d3fa-6eb9-4242-9a69-62f6d8202443,DISK], DatanodeInfoWithStorage[127.0.0.1:37148,DS-ffe1c694-057b-4528-b91e-24df3c1fc1a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33976,DS-fa113e65-2f6f-4e6a-8218-5c2271640d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:46631,DS-1b5d7eaa-1475-472f-96f5-851a2aed4589,DISK], DatanodeInfoWithStorage[127.0.0.1:37183,DS-70a8e352-c44b-4d30-b602-ac41818cf78e,DISK], DatanodeInfoWithStorage[127.0.0.1:34727,DS-cea935ed-7801-455b-b0e6-c6c6a2dede9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45107,DS-99d20155-bf58-4931-9c97-2dabba573932,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5124
