reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-186664704-172.17.0.21-1597675605405:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46700,DS-93c96c6a-9bf9-4b6e-8448-8c5ffc82de43,DISK], DatanodeInfoWithStorage[127.0.0.1:37701,DS-ed710ab0-c6f9-4971-916e-c0dd6ac81f16,DISK], DatanodeInfoWithStorage[127.0.0.1:44615,DS-acaa3aa6-3809-4607-8f79-bf77deaec17e,DISK], DatanodeInfoWithStorage[127.0.0.1:46636,DS-c29264cb-5b18-4a5a-a514-1093f71dc798,DISK], DatanodeInfoWithStorage[127.0.0.1:38127,DS-5744fd00-c16d-4866-b0e6-c4be10c61500,DISK], DatanodeInfoWithStorage[127.0.0.1:43648,DS-74efe2fb-4744-4b5f-bd52-82fb2d422241,DISK], DatanodeInfoWithStorage[127.0.0.1:37964,DS-162fbb58-09e5-4efc-aee9-2eb5e1ba8d48,DISK], DatanodeInfoWithStorage[127.0.0.1:34804,DS-ebc43bc9-acfe-46b6-8702-6964d1720045,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-186664704-172.17.0.21-1597675605405:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46700,DS-93c96c6a-9bf9-4b6e-8448-8c5ffc82de43,DISK], DatanodeInfoWithStorage[127.0.0.1:37701,DS-ed710ab0-c6f9-4971-916e-c0dd6ac81f16,DISK], DatanodeInfoWithStorage[127.0.0.1:44615,DS-acaa3aa6-3809-4607-8f79-bf77deaec17e,DISK], DatanodeInfoWithStorage[127.0.0.1:46636,DS-c29264cb-5b18-4a5a-a514-1093f71dc798,DISK], DatanodeInfoWithStorage[127.0.0.1:38127,DS-5744fd00-c16d-4866-b0e6-c4be10c61500,DISK], DatanodeInfoWithStorage[127.0.0.1:43648,DS-74efe2fb-4744-4b5f-bd52-82fb2d422241,DISK], DatanodeInfoWithStorage[127.0.0.1:37964,DS-162fbb58-09e5-4efc-aee9-2eb5e1ba8d48,DISK], DatanodeInfoWithStorage[127.0.0.1:34804,DS-ebc43bc9-acfe-46b6-8702-6964d1720045,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1724631760-172.17.0.21-1597675720028:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44975,DS-dab0aa94-9adf-4e94-9f0e-fe3a0cc35e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36133,DS-ac3fa611-ccac-433b-8b28-dc27cd179e36,DISK], DatanodeInfoWithStorage[127.0.0.1:42313,DS-41bf78b0-b699-40c0-9280-5554bcf7b0bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35481,DS-1c57f280-832a-412c-9f94-7c9408eb826c,DISK], DatanodeInfoWithStorage[127.0.0.1:46670,DS-2ce69a25-2418-4586-a704-74af9a424c57,DISK], DatanodeInfoWithStorage[127.0.0.1:33307,DS-88932221-7d70-4ebe-8ce5-326ae503c9bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46296,DS-1a15fb48-c123-45ef-b4f7-0b93785d716a,DISK], DatanodeInfoWithStorage[127.0.0.1:42334,DS-738caceb-d5a9-4dbd-8e40-fb7b4f4fe08a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1724631760-172.17.0.21-1597675720028:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44975,DS-dab0aa94-9adf-4e94-9f0e-fe3a0cc35e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36133,DS-ac3fa611-ccac-433b-8b28-dc27cd179e36,DISK], DatanodeInfoWithStorage[127.0.0.1:42313,DS-41bf78b0-b699-40c0-9280-5554bcf7b0bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35481,DS-1c57f280-832a-412c-9f94-7c9408eb826c,DISK], DatanodeInfoWithStorage[127.0.0.1:46670,DS-2ce69a25-2418-4586-a704-74af9a424c57,DISK], DatanodeInfoWithStorage[127.0.0.1:33307,DS-88932221-7d70-4ebe-8ce5-326ae503c9bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46296,DS-1a15fb48-c123-45ef-b4f7-0b93785d716a,DISK], DatanodeInfoWithStorage[127.0.0.1:42334,DS-738caceb-d5a9-4dbd-8e40-fb7b4f4fe08a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-683406860-172.17.0.21-1597676017841:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34678,DS-8acd027f-e2a3-4eac-8bf3-15847ad3e32d,DISK], DatanodeInfoWithStorage[127.0.0.1:42954,DS-ed7aa1ea-5561-4e5f-af67-8daf7bd118e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36824,DS-a2fb63e9-cd4f-471a-8f13-9211b290ca56,DISK], DatanodeInfoWithStorage[127.0.0.1:35410,DS-6153a73f-c800-4356-a9f8-c2b116ede02c,DISK], DatanodeInfoWithStorage[127.0.0.1:41616,DS-23c4ae1f-02c2-4859-a401-8b7de8c58424,DISK], DatanodeInfoWithStorage[127.0.0.1:44319,DS-1a8be25c-8328-47d6-9972-8b64280f1f33,DISK], DatanodeInfoWithStorage[127.0.0.1:36982,DS-c6c1ed19-ae80-4c05-9e4d-55e7c5568262,DISK], DatanodeInfoWithStorage[127.0.0.1:40535,DS-80826a1e-f346-438d-b0fd-6186d1f67d6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-683406860-172.17.0.21-1597676017841:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34678,DS-8acd027f-e2a3-4eac-8bf3-15847ad3e32d,DISK], DatanodeInfoWithStorage[127.0.0.1:42954,DS-ed7aa1ea-5561-4e5f-af67-8daf7bd118e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36824,DS-a2fb63e9-cd4f-471a-8f13-9211b290ca56,DISK], DatanodeInfoWithStorage[127.0.0.1:35410,DS-6153a73f-c800-4356-a9f8-c2b116ede02c,DISK], DatanodeInfoWithStorage[127.0.0.1:41616,DS-23c4ae1f-02c2-4859-a401-8b7de8c58424,DISK], DatanodeInfoWithStorage[127.0.0.1:44319,DS-1a8be25c-8328-47d6-9972-8b64280f1f33,DISK], DatanodeInfoWithStorage[127.0.0.1:36982,DS-c6c1ed19-ae80-4c05-9e4d-55e7c5568262,DISK], DatanodeInfoWithStorage[127.0.0.1:40535,DS-80826a1e-f346-438d-b0fd-6186d1f67d6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-257086159-172.17.0.21-1597676153780:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46480,DS-98ab874e-716c-4649-b1c5-3a7b8829e73b,DISK], DatanodeInfoWithStorage[127.0.0.1:38633,DS-81c67350-9ea2-4746-ae7f-032c211a9370,DISK], DatanodeInfoWithStorage[127.0.0.1:46186,DS-26f93c93-5840-46e9-8b89-566ddd5b22bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35865,DS-86bb4582-5683-440d-bb54-8229584b8544,DISK], DatanodeInfoWithStorage[127.0.0.1:46065,DS-231dfa21-72e1-4d08-b92f-686593595cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:34605,DS-1bcea246-e08c-4fa9-8eac-b1a95c6a136b,DISK], DatanodeInfoWithStorage[127.0.0.1:38623,DS-6fa96a20-7e37-4f94-b5c5-6bd0992777e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41494,DS-66b81914-8c0b-430c-abda-487fe953fa30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-257086159-172.17.0.21-1597676153780:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46480,DS-98ab874e-716c-4649-b1c5-3a7b8829e73b,DISK], DatanodeInfoWithStorage[127.0.0.1:38633,DS-81c67350-9ea2-4746-ae7f-032c211a9370,DISK], DatanodeInfoWithStorage[127.0.0.1:46186,DS-26f93c93-5840-46e9-8b89-566ddd5b22bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35865,DS-86bb4582-5683-440d-bb54-8229584b8544,DISK], DatanodeInfoWithStorage[127.0.0.1:46065,DS-231dfa21-72e1-4d08-b92f-686593595cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:34605,DS-1bcea246-e08c-4fa9-8eac-b1a95c6a136b,DISK], DatanodeInfoWithStorage[127.0.0.1:38623,DS-6fa96a20-7e37-4f94-b5c5-6bd0992777e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41494,DS-66b81914-8c0b-430c-abda-487fe953fa30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1591693338-172.17.0.21-1597676249723:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39479,DS-e3ebaa2c-b101-4804-bf0c-683879f33499,DISK], DatanodeInfoWithStorage[127.0.0.1:38445,DS-e8aa19f1-83ac-49bd-af7f-05ac95ac4295,DISK], DatanodeInfoWithStorage[127.0.0.1:44972,DS-aa71093d-d651-467f-804a-b0b59cfcab26,DISK], DatanodeInfoWithStorage[127.0.0.1:35113,DS-fa459fc3-fa04-4446-8f0c-4360786ee744,DISK], DatanodeInfoWithStorage[127.0.0.1:38486,DS-19b3bcbd-9ffc-4cbb-b72f-0b486ca97d99,DISK], DatanodeInfoWithStorage[127.0.0.1:43734,DS-f5a8673d-cbc9-4525-9908-baf07612bbf5,DISK], DatanodeInfoWithStorage[127.0.0.1:34737,DS-76a1530c-4d0a-4616-b14b-dba7c9a687ec,DISK], DatanodeInfoWithStorage[127.0.0.1:32772,DS-9bc4db62-7991-4f67-86cd-f79b0400af9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1591693338-172.17.0.21-1597676249723:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39479,DS-e3ebaa2c-b101-4804-bf0c-683879f33499,DISK], DatanodeInfoWithStorage[127.0.0.1:38445,DS-e8aa19f1-83ac-49bd-af7f-05ac95ac4295,DISK], DatanodeInfoWithStorage[127.0.0.1:44972,DS-aa71093d-d651-467f-804a-b0b59cfcab26,DISK], DatanodeInfoWithStorage[127.0.0.1:35113,DS-fa459fc3-fa04-4446-8f0c-4360786ee744,DISK], DatanodeInfoWithStorage[127.0.0.1:38486,DS-19b3bcbd-9ffc-4cbb-b72f-0b486ca97d99,DISK], DatanodeInfoWithStorage[127.0.0.1:43734,DS-f5a8673d-cbc9-4525-9908-baf07612bbf5,DISK], DatanodeInfoWithStorage[127.0.0.1:34737,DS-76a1530c-4d0a-4616-b14b-dba7c9a687ec,DISK], DatanodeInfoWithStorage[127.0.0.1:32772,DS-9bc4db62-7991-4f67-86cd-f79b0400af9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1797279994-172.17.0.21-1597676573935:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45875,DS-5b5de3b0-2f0f-4205-94d3-c28d8a79745d,DISK], DatanodeInfoWithStorage[127.0.0.1:33753,DS-5c0a3e3e-efd5-4357-8e2b-397382ed7b11,DISK], DatanodeInfoWithStorage[127.0.0.1:40599,DS-8ac9c293-e5d8-44a4-9157-988bc41e13a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45418,DS-331393be-0b18-41c9-93da-c93fcd33ee83,DISK], DatanodeInfoWithStorage[127.0.0.1:39257,DS-775ab041-7564-4c1b-91d7-f80a38a5dbab,DISK], DatanodeInfoWithStorage[127.0.0.1:46858,DS-6ed58526-15fb-4bc8-888a-4bc151d9bad7,DISK], DatanodeInfoWithStorage[127.0.0.1:39870,DS-66b158d2-e39f-422d-a1c8-8e84ba6155cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35283,DS-8b6524e7-8171-438a-9805-efa3b7cc0d97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1797279994-172.17.0.21-1597676573935:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45875,DS-5b5de3b0-2f0f-4205-94d3-c28d8a79745d,DISK], DatanodeInfoWithStorage[127.0.0.1:33753,DS-5c0a3e3e-efd5-4357-8e2b-397382ed7b11,DISK], DatanodeInfoWithStorage[127.0.0.1:40599,DS-8ac9c293-e5d8-44a4-9157-988bc41e13a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45418,DS-331393be-0b18-41c9-93da-c93fcd33ee83,DISK], DatanodeInfoWithStorage[127.0.0.1:39257,DS-775ab041-7564-4c1b-91d7-f80a38a5dbab,DISK], DatanodeInfoWithStorage[127.0.0.1:46858,DS-6ed58526-15fb-4bc8-888a-4bc151d9bad7,DISK], DatanodeInfoWithStorage[127.0.0.1:39870,DS-66b158d2-e39f-422d-a1c8-8e84ba6155cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35283,DS-8b6524e7-8171-438a-9805-efa3b7cc0d97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-253815988-172.17.0.21-1597676685345:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36221,DS-1d6f7c01-4cd6-4fd3-bbf1-5a752a306c10,DISK], DatanodeInfoWithStorage[127.0.0.1:34817,DS-a2b1951f-e680-41b6-9410-5b7df714812d,DISK], DatanodeInfoWithStorage[127.0.0.1:45681,DS-a9e46dbe-5561-4cbe-8009-723dd1234e65,DISK], DatanodeInfoWithStorage[127.0.0.1:45547,DS-c771e55c-4415-4119-8534-1e65614129bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33387,DS-5335e940-654d-48e6-848f-baa7111b9681,DISK], DatanodeInfoWithStorage[127.0.0.1:33711,DS-9468d584-1708-4da8-91bf-ec8956ce82e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37155,DS-0b62f480-f2f8-4ac3-a2b0-304fc99fe83c,DISK], DatanodeInfoWithStorage[127.0.0.1:35972,DS-85ae8315-9c59-4589-a5ef-6852a7090eb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-253815988-172.17.0.21-1597676685345:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36221,DS-1d6f7c01-4cd6-4fd3-bbf1-5a752a306c10,DISK], DatanodeInfoWithStorage[127.0.0.1:34817,DS-a2b1951f-e680-41b6-9410-5b7df714812d,DISK], DatanodeInfoWithStorage[127.0.0.1:45681,DS-a9e46dbe-5561-4cbe-8009-723dd1234e65,DISK], DatanodeInfoWithStorage[127.0.0.1:45547,DS-c771e55c-4415-4119-8534-1e65614129bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33387,DS-5335e940-654d-48e6-848f-baa7111b9681,DISK], DatanodeInfoWithStorage[127.0.0.1:33711,DS-9468d584-1708-4da8-91bf-ec8956ce82e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37155,DS-0b62f480-f2f8-4ac3-a2b0-304fc99fe83c,DISK], DatanodeInfoWithStorage[127.0.0.1:35972,DS-85ae8315-9c59-4589-a5ef-6852a7090eb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1638195228-172.17.0.21-1597676718878:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42951,DS-0b5e70cc-eafa-4ac0-ba27-f1638e11d840,DISK], DatanodeInfoWithStorage[127.0.0.1:41355,DS-1c054ae8-78dd-43f8-8069-cdae4109f5ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42206,DS-49e5f748-aad6-4f2d-a874-ba259267a635,DISK], DatanodeInfoWithStorage[127.0.0.1:44105,DS-dbb3c420-e031-42da-a5fd-22912952e910,DISK], DatanodeInfoWithStorage[127.0.0.1:41315,DS-b15521c1-8ad6-4a75-b085-01c6c4156c99,DISK], DatanodeInfoWithStorage[127.0.0.1:39018,DS-fb6b69a9-dd2f-4aa7-a64c-06abe5a22968,DISK], DatanodeInfoWithStorage[127.0.0.1:38181,DS-96fac10c-70c7-4a4e-a9ac-dd5e76f89d77,DISK], DatanodeInfoWithStorage[127.0.0.1:33508,DS-64356a69-dc93-4261-b260-f340a3c51621,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1638195228-172.17.0.21-1597676718878:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42951,DS-0b5e70cc-eafa-4ac0-ba27-f1638e11d840,DISK], DatanodeInfoWithStorage[127.0.0.1:41355,DS-1c054ae8-78dd-43f8-8069-cdae4109f5ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42206,DS-49e5f748-aad6-4f2d-a874-ba259267a635,DISK], DatanodeInfoWithStorage[127.0.0.1:44105,DS-dbb3c420-e031-42da-a5fd-22912952e910,DISK], DatanodeInfoWithStorage[127.0.0.1:41315,DS-b15521c1-8ad6-4a75-b085-01c6c4156c99,DISK], DatanodeInfoWithStorage[127.0.0.1:39018,DS-fb6b69a9-dd2f-4aa7-a64c-06abe5a22968,DISK], DatanodeInfoWithStorage[127.0.0.1:38181,DS-96fac10c-70c7-4a4e-a9ac-dd5e76f89d77,DISK], DatanodeInfoWithStorage[127.0.0.1:33508,DS-64356a69-dc93-4261-b260-f340a3c51621,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1782002675-172.17.0.21-1597678519553:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36502,DS-cc3528cf-ffd6-4b08-8bc1-3b067417c632,DISK], DatanodeInfoWithStorage[127.0.0.1:42577,DS-88fb5ea4-2bbe-461c-a6d1-b63406345c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:33917,DS-3d771da2-7c78-4ac7-a898-925292aee021,DISK], DatanodeInfoWithStorage[127.0.0.1:41761,DS-62672f77-fe68-479e-bc0b-2f1931714478,DISK], DatanodeInfoWithStorage[127.0.0.1:37286,DS-eab09a67-8e0d-4b74-86d7-2da480c23556,DISK], DatanodeInfoWithStorage[127.0.0.1:32975,DS-27a7698b-b226-4ca6-8502-5fd7f9f68247,DISK], DatanodeInfoWithStorage[127.0.0.1:38412,DS-5ba7882f-c32d-4a3d-929f-052a902cb4db,DISK], DatanodeInfoWithStorage[127.0.0.1:45786,DS-e3bafb86-a32d-4b42-95df-d4fd58de0b01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1782002675-172.17.0.21-1597678519553:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36502,DS-cc3528cf-ffd6-4b08-8bc1-3b067417c632,DISK], DatanodeInfoWithStorage[127.0.0.1:42577,DS-88fb5ea4-2bbe-461c-a6d1-b63406345c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:33917,DS-3d771da2-7c78-4ac7-a898-925292aee021,DISK], DatanodeInfoWithStorage[127.0.0.1:41761,DS-62672f77-fe68-479e-bc0b-2f1931714478,DISK], DatanodeInfoWithStorage[127.0.0.1:37286,DS-eab09a67-8e0d-4b74-86d7-2da480c23556,DISK], DatanodeInfoWithStorage[127.0.0.1:32975,DS-27a7698b-b226-4ca6-8502-5fd7f9f68247,DISK], DatanodeInfoWithStorage[127.0.0.1:38412,DS-5ba7882f-c32d-4a3d-929f-052a902cb4db,DISK], DatanodeInfoWithStorage[127.0.0.1:45786,DS-e3bafb86-a32d-4b42-95df-d4fd58de0b01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-148221415-172.17.0.21-1597678755083:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43950,DS-a39f3b07-1c34-4d9f-b1ed-25249bc8f08c,DISK], DatanodeInfoWithStorage[127.0.0.1:38519,DS-241a066d-d424-4609-ab66-aa300493979b,DISK], DatanodeInfoWithStorage[127.0.0.1:45599,DS-4fc7e9b1-c724-4f4b-9a57-63ffed4b9322,DISK], DatanodeInfoWithStorage[127.0.0.1:41023,DS-b74e9d45-618b-4ea0-9957-44b2c54f6fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:43852,DS-5cc58a7f-fc82-4420-9f60-13c435e8c1bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42447,DS-67b95d3c-7d2b-498b-a8e8-f6fb21096c72,DISK], DatanodeInfoWithStorage[127.0.0.1:42683,DS-5a3620dc-75bf-41dd-a536-17a5b82616a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39556,DS-23124210-8e0b-4d78-aceb-f24ca7f18a88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-148221415-172.17.0.21-1597678755083:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43950,DS-a39f3b07-1c34-4d9f-b1ed-25249bc8f08c,DISK], DatanodeInfoWithStorage[127.0.0.1:38519,DS-241a066d-d424-4609-ab66-aa300493979b,DISK], DatanodeInfoWithStorage[127.0.0.1:45599,DS-4fc7e9b1-c724-4f4b-9a57-63ffed4b9322,DISK], DatanodeInfoWithStorage[127.0.0.1:41023,DS-b74e9d45-618b-4ea0-9957-44b2c54f6fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:43852,DS-5cc58a7f-fc82-4420-9f60-13c435e8c1bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42447,DS-67b95d3c-7d2b-498b-a8e8-f6fb21096c72,DISK], DatanodeInfoWithStorage[127.0.0.1:42683,DS-5a3620dc-75bf-41dd-a536-17a5b82616a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39556,DS-23124210-8e0b-4d78-aceb-f24ca7f18a88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1677622115-172.17.0.21-1597678796691:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41131,DS-b947a5f5-9b5a-4b02-bdac-e671f3939408,DISK], DatanodeInfoWithStorage[127.0.0.1:44528,DS-cfed6978-905c-4aba-8d88-b52e8c67500e,DISK], DatanodeInfoWithStorage[127.0.0.1:34181,DS-23407b78-ef66-46ab-a99b-d7e9055ded3c,DISK], DatanodeInfoWithStorage[127.0.0.1:39732,DS-37bf5eed-0005-49e4-8e0d-63e1d8649dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:36944,DS-4b723a04-2a62-4cd0-9e4e-6df076572783,DISK], DatanodeInfoWithStorage[127.0.0.1:43715,DS-81a17a97-18b7-48c4-a9bf-d7e82a0e0147,DISK], DatanodeInfoWithStorage[127.0.0.1:42779,DS-7c5d3270-2921-415e-8b8e-4d3e61f69dab,DISK], DatanodeInfoWithStorage[127.0.0.1:41724,DS-40f98650-fc50-42cf-8239-1e62d696a119,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1677622115-172.17.0.21-1597678796691:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41131,DS-b947a5f5-9b5a-4b02-bdac-e671f3939408,DISK], DatanodeInfoWithStorage[127.0.0.1:44528,DS-cfed6978-905c-4aba-8d88-b52e8c67500e,DISK], DatanodeInfoWithStorage[127.0.0.1:34181,DS-23407b78-ef66-46ab-a99b-d7e9055ded3c,DISK], DatanodeInfoWithStorage[127.0.0.1:39732,DS-37bf5eed-0005-49e4-8e0d-63e1d8649dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:36944,DS-4b723a04-2a62-4cd0-9e4e-6df076572783,DISK], DatanodeInfoWithStorage[127.0.0.1:43715,DS-81a17a97-18b7-48c4-a9bf-d7e82a0e0147,DISK], DatanodeInfoWithStorage[127.0.0.1:42779,DS-7c5d3270-2921-415e-8b8e-4d3e61f69dab,DISK], DatanodeInfoWithStorage[127.0.0.1:41724,DS-40f98650-fc50-42cf-8239-1e62d696a119,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2059121805-172.17.0.21-1597679018264:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44378,DS-c068c2d7-8a00-4e7a-a33e-9ca6c53b7cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:34376,DS-702a6230-93fd-41f3-9033-6c52f2204536,DISK], DatanodeInfoWithStorage[127.0.0.1:34705,DS-435b4854-25f0-463b-9f46-26c0fbd9a63e,DISK], DatanodeInfoWithStorage[127.0.0.1:42620,DS-fd4d67ac-7ca8-4a50-affe-8525f7f53fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:33602,DS-a18c70ee-b56d-4ab5-b9d0-5c72058b8cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:35426,DS-80f19bd7-833b-4df3-af4b-615314ad7166,DISK], DatanodeInfoWithStorage[127.0.0.1:33347,DS-d698b41e-2bb2-4c89-9f42-b93ffc77f854,DISK], DatanodeInfoWithStorage[127.0.0.1:35337,DS-f5b83842-1bd7-4421-b398-57d44d319ccf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2059121805-172.17.0.21-1597679018264:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44378,DS-c068c2d7-8a00-4e7a-a33e-9ca6c53b7cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:34376,DS-702a6230-93fd-41f3-9033-6c52f2204536,DISK], DatanodeInfoWithStorage[127.0.0.1:34705,DS-435b4854-25f0-463b-9f46-26c0fbd9a63e,DISK], DatanodeInfoWithStorage[127.0.0.1:42620,DS-fd4d67ac-7ca8-4a50-affe-8525f7f53fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:33602,DS-a18c70ee-b56d-4ab5-b9d0-5c72058b8cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:35426,DS-80f19bd7-833b-4df3-af4b-615314ad7166,DISK], DatanodeInfoWithStorage[127.0.0.1:33347,DS-d698b41e-2bb2-4c89-9f42-b93ffc77f854,DISK], DatanodeInfoWithStorage[127.0.0.1:35337,DS-f5b83842-1bd7-4421-b398-57d44d319ccf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-371051575-172.17.0.21-1597679500978:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43189,DS-d97ea519-bda0-4b14-9d91-4d110439eaca,DISK], DatanodeInfoWithStorage[127.0.0.1:46272,DS-bed2f53a-452e-41fb-897d-44255e343b54,DISK], DatanodeInfoWithStorage[127.0.0.1:43059,DS-ca3bbbec-1666-4961-8acb-91e3cd477082,DISK], DatanodeInfoWithStorage[127.0.0.1:41591,DS-32e75acc-71a3-4d1b-aecd-f60c2298386d,DISK], DatanodeInfoWithStorage[127.0.0.1:33826,DS-731af96d-b04a-4aaa-a5f8-5450d6ab8ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:45302,DS-d69de4ca-a91f-4bbe-aac0-b479e6cfa72a,DISK], DatanodeInfoWithStorage[127.0.0.1:36132,DS-6b731b5a-4ff9-4eac-a978-daaee26c5fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:37240,DS-ae9eef32-5d87-42de-8e8c-526c41602f75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-371051575-172.17.0.21-1597679500978:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43189,DS-d97ea519-bda0-4b14-9d91-4d110439eaca,DISK], DatanodeInfoWithStorage[127.0.0.1:46272,DS-bed2f53a-452e-41fb-897d-44255e343b54,DISK], DatanodeInfoWithStorage[127.0.0.1:43059,DS-ca3bbbec-1666-4961-8acb-91e3cd477082,DISK], DatanodeInfoWithStorage[127.0.0.1:41591,DS-32e75acc-71a3-4d1b-aecd-f60c2298386d,DISK], DatanodeInfoWithStorage[127.0.0.1:33826,DS-731af96d-b04a-4aaa-a5f8-5450d6ab8ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:45302,DS-d69de4ca-a91f-4bbe-aac0-b479e6cfa72a,DISK], DatanodeInfoWithStorage[127.0.0.1:36132,DS-6b731b5a-4ff9-4eac-a978-daaee26c5fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:37240,DS-ae9eef32-5d87-42de-8e8c-526c41602f75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1420350079-172.17.0.21-1597679899204:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46072,DS-d6647489-10b2-4fc0-933e-b464bececcf6,DISK], DatanodeInfoWithStorage[127.0.0.1:36882,DS-bbf1365b-6ae0-49d2-a2c8-b78dc7907728,DISK], DatanodeInfoWithStorage[127.0.0.1:43495,DS-5ffa02c0-b0f0-41d9-adf6-588d3dced732,DISK], DatanodeInfoWithStorage[127.0.0.1:42518,DS-c5c0fbe3-015d-4637-93bd-754f8deee276,DISK], DatanodeInfoWithStorage[127.0.0.1:39287,DS-e55bbe06-7d37-4869-8317-61c7b12fde39,DISK], DatanodeInfoWithStorage[127.0.0.1:45184,DS-a06a154e-dac0-41b7-ae52-2e6c3a02e162,DISK], DatanodeInfoWithStorage[127.0.0.1:37265,DS-b36a8cdf-68b5-457c-b240-a7b206df3823,DISK], DatanodeInfoWithStorage[127.0.0.1:37572,DS-62b08ee6-69fe-4653-ad26-59a9947ab4b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1420350079-172.17.0.21-1597679899204:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46072,DS-d6647489-10b2-4fc0-933e-b464bececcf6,DISK], DatanodeInfoWithStorage[127.0.0.1:36882,DS-bbf1365b-6ae0-49d2-a2c8-b78dc7907728,DISK], DatanodeInfoWithStorage[127.0.0.1:43495,DS-5ffa02c0-b0f0-41d9-adf6-588d3dced732,DISK], DatanodeInfoWithStorage[127.0.0.1:42518,DS-c5c0fbe3-015d-4637-93bd-754f8deee276,DISK], DatanodeInfoWithStorage[127.0.0.1:39287,DS-e55bbe06-7d37-4869-8317-61c7b12fde39,DISK], DatanodeInfoWithStorage[127.0.0.1:45184,DS-a06a154e-dac0-41b7-ae52-2e6c3a02e162,DISK], DatanodeInfoWithStorage[127.0.0.1:37265,DS-b36a8cdf-68b5-457c-b240-a7b206df3823,DISK], DatanodeInfoWithStorage[127.0.0.1:37572,DS-62b08ee6-69fe-4653-ad26-59a9947ab4b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-788615966-172.17.0.21-1597679932473:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41764,DS-396bf097-2361-4a7c-be4d-80a593c5df3e,DISK], DatanodeInfoWithStorage[127.0.0.1:35003,DS-e11041e8-5b54-4602-9f8d-7879260d62b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36493,DS-e16d49ac-e482-4b32-8c82-743f66d8e7c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42531,DS-50fc015f-d06c-4430-90fc-3ac354caef71,DISK], DatanodeInfoWithStorage[127.0.0.1:40034,DS-3d606e38-49de-4138-8955-9afebe007a25,DISK], DatanodeInfoWithStorage[127.0.0.1:33764,DS-03bb61ec-0cff-48c4-974c-a91b74dd07e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45256,DS-1e990e3d-a478-4aaf-8de0-582cb016c651,DISK], DatanodeInfoWithStorage[127.0.0.1:44597,DS-edcf5007-8c39-4789-b7f6-2cf3871a02e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-788615966-172.17.0.21-1597679932473:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41764,DS-396bf097-2361-4a7c-be4d-80a593c5df3e,DISK], DatanodeInfoWithStorage[127.0.0.1:35003,DS-e11041e8-5b54-4602-9f8d-7879260d62b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36493,DS-e16d49ac-e482-4b32-8c82-743f66d8e7c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42531,DS-50fc015f-d06c-4430-90fc-3ac354caef71,DISK], DatanodeInfoWithStorage[127.0.0.1:40034,DS-3d606e38-49de-4138-8955-9afebe007a25,DISK], DatanodeInfoWithStorage[127.0.0.1:33764,DS-03bb61ec-0cff-48c4-974c-a91b74dd07e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45256,DS-1e990e3d-a478-4aaf-8de0-582cb016c651,DISK], DatanodeInfoWithStorage[127.0.0.1:44597,DS-edcf5007-8c39-4789-b7f6-2cf3871a02e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2042476173-172.17.0.21-1597680268440:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42600,DS-1edb228e-f138-46d4-beec-49c7edc72fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:43075,DS-30202cf4-c1f6-471c-9340-761064595a79,DISK], DatanodeInfoWithStorage[127.0.0.1:45828,DS-9d0a0e39-fd3a-49f1-a9a5-2727003b7240,DISK], DatanodeInfoWithStorage[127.0.0.1:45403,DS-c46e7de2-a152-424a-8b98-738feb8a137d,DISK], DatanodeInfoWithStorage[127.0.0.1:42599,DS-4009e241-3bdd-408e-8635-710a9447ed65,DISK], DatanodeInfoWithStorage[127.0.0.1:37349,DS-8d35b2e0-5663-4d81-97b8-6a0151efc75c,DISK], DatanodeInfoWithStorage[127.0.0.1:43618,DS-27eed43b-b67b-4be8-8109-7ef55b469827,DISK], DatanodeInfoWithStorage[127.0.0.1:35249,DS-0182c3e6-4ec2-42e2-bbcb-265461f4a744,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2042476173-172.17.0.21-1597680268440:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42600,DS-1edb228e-f138-46d4-beec-49c7edc72fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:43075,DS-30202cf4-c1f6-471c-9340-761064595a79,DISK], DatanodeInfoWithStorage[127.0.0.1:45828,DS-9d0a0e39-fd3a-49f1-a9a5-2727003b7240,DISK], DatanodeInfoWithStorage[127.0.0.1:45403,DS-c46e7de2-a152-424a-8b98-738feb8a137d,DISK], DatanodeInfoWithStorage[127.0.0.1:42599,DS-4009e241-3bdd-408e-8635-710a9447ed65,DISK], DatanodeInfoWithStorage[127.0.0.1:37349,DS-8d35b2e0-5663-4d81-97b8-6a0151efc75c,DISK], DatanodeInfoWithStorage[127.0.0.1:43618,DS-27eed43b-b67b-4be8-8109-7ef55b469827,DISK], DatanodeInfoWithStorage[127.0.0.1:35249,DS-0182c3e6-4ec2-42e2-bbcb-265461f4a744,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1445181721-172.17.0.21-1597680441656:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42272,DS-226d06ef-c84d-4cc0-b685-ae1517975c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:38831,DS-1e3cbd34-e96b-4f08-bb06-f42ab478c16f,DISK], DatanodeInfoWithStorage[127.0.0.1:46765,DS-bf2bfd92-ec37-49fa-ad8e-ef16c56a6f44,DISK], DatanodeInfoWithStorage[127.0.0.1:46399,DS-0a7ba0f8-9ffe-4979-af46-e6b38411ced6,DISK], DatanodeInfoWithStorage[127.0.0.1:33972,DS-421c1bf0-2bf2-4ee5-bc0b-45bc2de7b11a,DISK], DatanodeInfoWithStorage[127.0.0.1:45407,DS-73df377c-ab46-4c1a-908a-bd87f7fc7dca,DISK], DatanodeInfoWithStorage[127.0.0.1:43203,DS-aa10e500-2784-4622-8410-6fef2669f312,DISK], DatanodeInfoWithStorage[127.0.0.1:34812,DS-fc5dddae-03b0-42b4-adbd-f3a52c057168,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1445181721-172.17.0.21-1597680441656:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42272,DS-226d06ef-c84d-4cc0-b685-ae1517975c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:38831,DS-1e3cbd34-e96b-4f08-bb06-f42ab478c16f,DISK], DatanodeInfoWithStorage[127.0.0.1:46765,DS-bf2bfd92-ec37-49fa-ad8e-ef16c56a6f44,DISK], DatanodeInfoWithStorage[127.0.0.1:46399,DS-0a7ba0f8-9ffe-4979-af46-e6b38411ced6,DISK], DatanodeInfoWithStorage[127.0.0.1:33972,DS-421c1bf0-2bf2-4ee5-bc0b-45bc2de7b11a,DISK], DatanodeInfoWithStorage[127.0.0.1:45407,DS-73df377c-ab46-4c1a-908a-bd87f7fc7dca,DISK], DatanodeInfoWithStorage[127.0.0.1:43203,DS-aa10e500-2784-4622-8410-6fef2669f312,DISK], DatanodeInfoWithStorage[127.0.0.1:34812,DS-fc5dddae-03b0-42b4-adbd-f3a52c057168,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-294490088-172.17.0.21-1597680516741:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44155,DS-e75e9e75-75f3-42bc-a781-3269e0121e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41200,DS-07bee037-3fed-46b3-8907-ce8aaa912b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:33516,DS-7a2dee4e-cca3-4d7b-9fac-5cf32f852ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:37905,DS-61b07cef-562d-43a0-b536-f1375df8b4fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37545,DS-17628d07-a755-4032-9b3b-dcc218919ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:33018,DS-90059ea3-cccc-4d32-b622-f1aa8d43fea3,DISK], DatanodeInfoWithStorage[127.0.0.1:36063,DS-af26470e-ae89-4136-a566-7ea68d58762b,DISK], DatanodeInfoWithStorage[127.0.0.1:35603,DS-96533559-77ae-47bf-8721-55b831948149,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-294490088-172.17.0.21-1597680516741:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44155,DS-e75e9e75-75f3-42bc-a781-3269e0121e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41200,DS-07bee037-3fed-46b3-8907-ce8aaa912b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:33516,DS-7a2dee4e-cca3-4d7b-9fac-5cf32f852ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:37905,DS-61b07cef-562d-43a0-b536-f1375df8b4fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37545,DS-17628d07-a755-4032-9b3b-dcc218919ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:33018,DS-90059ea3-cccc-4d32-b622-f1aa8d43fea3,DISK], DatanodeInfoWithStorage[127.0.0.1:36063,DS-af26470e-ae89-4136-a566-7ea68d58762b,DISK], DatanodeInfoWithStorage[127.0.0.1:35603,DS-96533559-77ae-47bf-8721-55b831948149,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5350
