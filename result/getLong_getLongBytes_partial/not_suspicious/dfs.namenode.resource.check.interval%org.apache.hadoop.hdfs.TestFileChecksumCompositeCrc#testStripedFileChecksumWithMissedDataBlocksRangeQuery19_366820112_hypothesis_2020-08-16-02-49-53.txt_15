reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-458397041-172.17.0.17-1597546508311:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45802,DS-8c5a60e5-e50a-412e-926b-40c5de518179,DISK], DatanodeInfoWithStorage[127.0.0.1:34715,DS-24c6a353-52a0-4dfe-9b07-160fc2f4f9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44664,DS-5388bbf6-18ea-4462-a3fc-c2d6f4569864,DISK], DatanodeInfoWithStorage[127.0.0.1:33518,DS-dd4a9677-6577-4fc5-8a82-ccc3b920f1c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44921,DS-5a86d782-ab26-4847-97a7-b341818dcd85,DISK], DatanodeInfoWithStorage[127.0.0.1:36221,DS-bd646409-b2fd-46a5-a83f-24522715ab08,DISK], DatanodeInfoWithStorage[127.0.0.1:35516,DS-f0107752-5635-4822-ad05-af02a95d983a,DISK], DatanodeInfoWithStorage[127.0.0.1:42425,DS-104abae6-983b-4870-9fc2-2a9ce3eaaf4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-458397041-172.17.0.17-1597546508311:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45802,DS-8c5a60e5-e50a-412e-926b-40c5de518179,DISK], DatanodeInfoWithStorage[127.0.0.1:34715,DS-24c6a353-52a0-4dfe-9b07-160fc2f4f9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44664,DS-5388bbf6-18ea-4462-a3fc-c2d6f4569864,DISK], DatanodeInfoWithStorage[127.0.0.1:33518,DS-dd4a9677-6577-4fc5-8a82-ccc3b920f1c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44921,DS-5a86d782-ab26-4847-97a7-b341818dcd85,DISK], DatanodeInfoWithStorage[127.0.0.1:36221,DS-bd646409-b2fd-46a5-a83f-24522715ab08,DISK], DatanodeInfoWithStorage[127.0.0.1:35516,DS-f0107752-5635-4822-ad05-af02a95d983a,DISK], DatanodeInfoWithStorage[127.0.0.1:42425,DS-104abae6-983b-4870-9fc2-2a9ce3eaaf4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1937725020-172.17.0.17-1597546542098:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45700,DS-cd34b9a0-19e0-4b78-8360-475a670368e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33660,DS-daa248bb-9ccf-4cc5-bc43-c96b9cc9f15d,DISK], DatanodeInfoWithStorage[127.0.0.1:37655,DS-8af7b200-0396-4178-8709-ac0a7e35a419,DISK], DatanodeInfoWithStorage[127.0.0.1:37343,DS-2598ee38-0ba2-4b82-a164-632caf16ea4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44547,DS-cbe74691-1d96-4d03-b120-0a03dd27d553,DISK], DatanodeInfoWithStorage[127.0.0.1:34283,DS-f1870414-5bf5-406f-8be1-3a093d6a98a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41411,DS-05f2eacc-4da7-494b-85dc-ac4e04667bed,DISK], DatanodeInfoWithStorage[127.0.0.1:35197,DS-92bc8ee4-0899-433d-adb6-0301971fb672,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1937725020-172.17.0.17-1597546542098:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45700,DS-cd34b9a0-19e0-4b78-8360-475a670368e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33660,DS-daa248bb-9ccf-4cc5-bc43-c96b9cc9f15d,DISK], DatanodeInfoWithStorage[127.0.0.1:37655,DS-8af7b200-0396-4178-8709-ac0a7e35a419,DISK], DatanodeInfoWithStorage[127.0.0.1:37343,DS-2598ee38-0ba2-4b82-a164-632caf16ea4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44547,DS-cbe74691-1d96-4d03-b120-0a03dd27d553,DISK], DatanodeInfoWithStorage[127.0.0.1:34283,DS-f1870414-5bf5-406f-8be1-3a093d6a98a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41411,DS-05f2eacc-4da7-494b-85dc-ac4e04667bed,DISK], DatanodeInfoWithStorage[127.0.0.1:35197,DS-92bc8ee4-0899-433d-adb6-0301971fb672,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-458907121-172.17.0.17-1597546709709:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39086,DS-a40cbdbb-64e5-4a89-843c-a526e4893cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:41550,DS-c47c6e60-5c0a-415e-987e-256d1faa3b09,DISK], DatanodeInfoWithStorage[127.0.0.1:40054,DS-f2379a03-1ad9-4607-a2d8-e279b12da3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37711,DS-7be156d9-e119-49dc-a2d1-e4d9c1aa1936,DISK], DatanodeInfoWithStorage[127.0.0.1:35825,DS-8fff11e8-b230-4090-8f62-cf2b04267aba,DISK], DatanodeInfoWithStorage[127.0.0.1:44079,DS-ccc126b6-dec4-4341-b315-3ac55ef567a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40294,DS-3c6d1bf2-2518-47fd-be6c-cc40ee22cd46,DISK], DatanodeInfoWithStorage[127.0.0.1:33981,DS-4fd663ab-503b-44ce-afdc-f62e29cbc40c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-458907121-172.17.0.17-1597546709709:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39086,DS-a40cbdbb-64e5-4a89-843c-a526e4893cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:41550,DS-c47c6e60-5c0a-415e-987e-256d1faa3b09,DISK], DatanodeInfoWithStorage[127.0.0.1:40054,DS-f2379a03-1ad9-4607-a2d8-e279b12da3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37711,DS-7be156d9-e119-49dc-a2d1-e4d9c1aa1936,DISK], DatanodeInfoWithStorage[127.0.0.1:35825,DS-8fff11e8-b230-4090-8f62-cf2b04267aba,DISK], DatanodeInfoWithStorage[127.0.0.1:44079,DS-ccc126b6-dec4-4341-b315-3ac55ef567a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40294,DS-3c6d1bf2-2518-47fd-be6c-cc40ee22cd46,DISK], DatanodeInfoWithStorage[127.0.0.1:33981,DS-4fd663ab-503b-44ce-afdc-f62e29cbc40c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2145689609-172.17.0.17-1597547024949:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41601,DS-7b256366-d4b8-4172-be18-807ea87c7e69,DISK], DatanodeInfoWithStorage[127.0.0.1:43331,DS-bcb52554-3f9b-491d-b5d1-0237aadcd672,DISK], DatanodeInfoWithStorage[127.0.0.1:38761,DS-004d2f97-6f55-449b-b8e3-8c7633dd2f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39531,DS-6fa4c12c-d9eb-4c80-9e23-2b2d57adb635,DISK], DatanodeInfoWithStorage[127.0.0.1:43097,DS-22c7a921-e323-4861-a366-490e514de810,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-34b4f166-3f89-4c45-9af0-685ff7e01cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:41082,DS-caf22000-3464-4c2e-af1c-974fc80ca2d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40233,DS-7039b590-5857-47d2-a0b1-dab783e68f80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2145689609-172.17.0.17-1597547024949:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41601,DS-7b256366-d4b8-4172-be18-807ea87c7e69,DISK], DatanodeInfoWithStorage[127.0.0.1:43331,DS-bcb52554-3f9b-491d-b5d1-0237aadcd672,DISK], DatanodeInfoWithStorage[127.0.0.1:38761,DS-004d2f97-6f55-449b-b8e3-8c7633dd2f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39531,DS-6fa4c12c-d9eb-4c80-9e23-2b2d57adb635,DISK], DatanodeInfoWithStorage[127.0.0.1:43097,DS-22c7a921-e323-4861-a366-490e514de810,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-34b4f166-3f89-4c45-9af0-685ff7e01cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:41082,DS-caf22000-3464-4c2e-af1c-974fc80ca2d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40233,DS-7039b590-5857-47d2-a0b1-dab783e68f80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-103493856-172.17.0.17-1597547303488:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37117,DS-774bc6f9-da26-4505-8ce8-866cfe5f61d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45410,DS-ec218397-04c4-4601-8aa7-9901403c709a,DISK], DatanodeInfoWithStorage[127.0.0.1:32795,DS-f6d19013-025c-4712-b011-577fcce291d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38812,DS-621cb381-8a64-4e7a-a2c9-683e18429188,DISK], DatanodeInfoWithStorage[127.0.0.1:38179,DS-d0ecdae9-7d0a-43f4-9a12-8ae0fae0134b,DISK], DatanodeInfoWithStorage[127.0.0.1:37811,DS-94880cf7-ca47-49b0-867f-89d0c3773c99,DISK], DatanodeInfoWithStorage[127.0.0.1:40759,DS-d96360ed-de30-409c-ab5c-aebce75876a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45274,DS-754d4d4f-599c-46d9-a516-e31512ed4541,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-103493856-172.17.0.17-1597547303488:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37117,DS-774bc6f9-da26-4505-8ce8-866cfe5f61d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45410,DS-ec218397-04c4-4601-8aa7-9901403c709a,DISK], DatanodeInfoWithStorage[127.0.0.1:32795,DS-f6d19013-025c-4712-b011-577fcce291d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38812,DS-621cb381-8a64-4e7a-a2c9-683e18429188,DISK], DatanodeInfoWithStorage[127.0.0.1:38179,DS-d0ecdae9-7d0a-43f4-9a12-8ae0fae0134b,DISK], DatanodeInfoWithStorage[127.0.0.1:37811,DS-94880cf7-ca47-49b0-867f-89d0c3773c99,DISK], DatanodeInfoWithStorage[127.0.0.1:40759,DS-d96360ed-de30-409c-ab5c-aebce75876a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45274,DS-754d4d4f-599c-46d9-a516-e31512ed4541,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1589760275-172.17.0.17-1597547784375:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43146,DS-bb3ac4bd-8959-456e-90d2-2cb235f4bf45,DISK], DatanodeInfoWithStorage[127.0.0.1:33590,DS-eb6fcddd-a187-4ff5-af02-d7c88755fff6,DISK], DatanodeInfoWithStorage[127.0.0.1:44507,DS-c6b7699d-e9b9-4444-90ea-4fa10958d106,DISK], DatanodeInfoWithStorage[127.0.0.1:35036,DS-10fe2e2c-05a2-4ee2-acaf-e33938e61f14,DISK], DatanodeInfoWithStorage[127.0.0.1:39715,DS-e46901c9-c2b0-4c8b-9b6d-299b0eab1b74,DISK], DatanodeInfoWithStorage[127.0.0.1:46357,DS-b03ed529-e2f8-4405-a162-008eaedef5c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38866,DS-6938b101-1f31-409d-98f9-c93085145587,DISK], DatanodeInfoWithStorage[127.0.0.1:41598,DS-be07d5be-3ea5-4ad4-9c6f-2fdc48dcdcec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1589760275-172.17.0.17-1597547784375:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43146,DS-bb3ac4bd-8959-456e-90d2-2cb235f4bf45,DISK], DatanodeInfoWithStorage[127.0.0.1:33590,DS-eb6fcddd-a187-4ff5-af02-d7c88755fff6,DISK], DatanodeInfoWithStorage[127.0.0.1:44507,DS-c6b7699d-e9b9-4444-90ea-4fa10958d106,DISK], DatanodeInfoWithStorage[127.0.0.1:35036,DS-10fe2e2c-05a2-4ee2-acaf-e33938e61f14,DISK], DatanodeInfoWithStorage[127.0.0.1:39715,DS-e46901c9-c2b0-4c8b-9b6d-299b0eab1b74,DISK], DatanodeInfoWithStorage[127.0.0.1:46357,DS-b03ed529-e2f8-4405-a162-008eaedef5c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38866,DS-6938b101-1f31-409d-98f9-c93085145587,DISK], DatanodeInfoWithStorage[127.0.0.1:41598,DS-be07d5be-3ea5-4ad4-9c6f-2fdc48dcdcec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1537766579-172.17.0.17-1597548099176:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45932,DS-9c2697d7-691d-4a2f-9304-34c0314edf15,DISK], DatanodeInfoWithStorage[127.0.0.1:44603,DS-10b86801-133b-4e43-b886-8a178e035eab,DISK], DatanodeInfoWithStorage[127.0.0.1:46491,DS-4db1a8bf-271f-4a05-9895-77dcfccfc1e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44871,DS-502e3aa8-0af0-4c37-b454-708a50466da5,DISK], DatanodeInfoWithStorage[127.0.0.1:41188,DS-cb1e58e5-2159-493e-822f-29d2d33492ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37923,DS-6e591b3c-695d-4284-86cb-8ccb5abd1011,DISK], DatanodeInfoWithStorage[127.0.0.1:35551,DS-18fac5b5-a1d8-4228-9eb4-069e44d64445,DISK], DatanodeInfoWithStorage[127.0.0.1:34561,DS-8dc592ad-5994-4fb1-a43f-a646426d9a49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1537766579-172.17.0.17-1597548099176:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45932,DS-9c2697d7-691d-4a2f-9304-34c0314edf15,DISK], DatanodeInfoWithStorage[127.0.0.1:44603,DS-10b86801-133b-4e43-b886-8a178e035eab,DISK], DatanodeInfoWithStorage[127.0.0.1:46491,DS-4db1a8bf-271f-4a05-9895-77dcfccfc1e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44871,DS-502e3aa8-0af0-4c37-b454-708a50466da5,DISK], DatanodeInfoWithStorage[127.0.0.1:41188,DS-cb1e58e5-2159-493e-822f-29d2d33492ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37923,DS-6e591b3c-695d-4284-86cb-8ccb5abd1011,DISK], DatanodeInfoWithStorage[127.0.0.1:35551,DS-18fac5b5-a1d8-4228-9eb4-069e44d64445,DISK], DatanodeInfoWithStorage[127.0.0.1:34561,DS-8dc592ad-5994-4fb1-a43f-a646426d9a49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1093223627-172.17.0.17-1597548283867:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45155,DS-a65209a7-2e6b-4a1f-9fdb-9d273d5faeca,DISK], DatanodeInfoWithStorage[127.0.0.1:33770,DS-1edc82d4-4884-4ea1-a455-e6e5efdc3cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:41939,DS-a19c02b8-1d29-4efa-8c23-963627abe476,DISK], DatanodeInfoWithStorage[127.0.0.1:37809,DS-de375a42-eb54-4796-975c-e7cfcc62f42d,DISK], DatanodeInfoWithStorage[127.0.0.1:40909,DS-e9328b6b-3171-472a-bee1-d379bdefb731,DISK], DatanodeInfoWithStorage[127.0.0.1:45957,DS-3b0ad029-992b-4d36-b237-05d4316d11a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41026,DS-03c521e2-d011-4c89-b167-75ea5ec7397f,DISK], DatanodeInfoWithStorage[127.0.0.1:35433,DS-4001d52f-9b23-4732-a919-491a7d5b8293,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1093223627-172.17.0.17-1597548283867:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45155,DS-a65209a7-2e6b-4a1f-9fdb-9d273d5faeca,DISK], DatanodeInfoWithStorage[127.0.0.1:33770,DS-1edc82d4-4884-4ea1-a455-e6e5efdc3cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:41939,DS-a19c02b8-1d29-4efa-8c23-963627abe476,DISK], DatanodeInfoWithStorage[127.0.0.1:37809,DS-de375a42-eb54-4796-975c-e7cfcc62f42d,DISK], DatanodeInfoWithStorage[127.0.0.1:40909,DS-e9328b6b-3171-472a-bee1-d379bdefb731,DISK], DatanodeInfoWithStorage[127.0.0.1:45957,DS-3b0ad029-992b-4d36-b237-05d4316d11a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41026,DS-03c521e2-d011-4c89-b167-75ea5ec7397f,DISK], DatanodeInfoWithStorage[127.0.0.1:35433,DS-4001d52f-9b23-4732-a919-491a7d5b8293,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1405914964-172.17.0.17-1597548416478:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38125,DS-585a77fc-72d0-420b-b97f-d44d65e0cde5,DISK], DatanodeInfoWithStorage[127.0.0.1:36052,DS-186b05dc-ba2e-4fdf-8131-9475d8c6ee4a,DISK], DatanodeInfoWithStorage[127.0.0.1:39968,DS-4924765c-f6cb-411a-b8af-09606ffe0fea,DISK], DatanodeInfoWithStorage[127.0.0.1:33721,DS-4ed2c4b2-d7cd-4332-94cf-5c0c1ebdbbae,DISK], DatanodeInfoWithStorage[127.0.0.1:43931,DS-729b8187-f0e2-4716-8f49-7e24a6563c35,DISK], DatanodeInfoWithStorage[127.0.0.1:46825,DS-34f27498-3c3b-4f74-a3f2-e7140d537f99,DISK], DatanodeInfoWithStorage[127.0.0.1:45916,DS-e8141632-2150-4fdb-b57a-987cea365135,DISK], DatanodeInfoWithStorage[127.0.0.1:42999,DS-40870140-fbf9-40b1-bf94-d43b36bfe4db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1405914964-172.17.0.17-1597548416478:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38125,DS-585a77fc-72d0-420b-b97f-d44d65e0cde5,DISK], DatanodeInfoWithStorage[127.0.0.1:36052,DS-186b05dc-ba2e-4fdf-8131-9475d8c6ee4a,DISK], DatanodeInfoWithStorage[127.0.0.1:39968,DS-4924765c-f6cb-411a-b8af-09606ffe0fea,DISK], DatanodeInfoWithStorage[127.0.0.1:33721,DS-4ed2c4b2-d7cd-4332-94cf-5c0c1ebdbbae,DISK], DatanodeInfoWithStorage[127.0.0.1:43931,DS-729b8187-f0e2-4716-8f49-7e24a6563c35,DISK], DatanodeInfoWithStorage[127.0.0.1:46825,DS-34f27498-3c3b-4f74-a3f2-e7140d537f99,DISK], DatanodeInfoWithStorage[127.0.0.1:45916,DS-e8141632-2150-4fdb-b57a-987cea365135,DISK], DatanodeInfoWithStorage[127.0.0.1:42999,DS-40870140-fbf9-40b1-bf94-d43b36bfe4db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1729696788-172.17.0.17-1597548455787:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37452,DS-c2482704-7a79-4076-ad8b-8707b9880e13,DISK], DatanodeInfoWithStorage[127.0.0.1:45373,DS-d3eefaa5-bdb1-4c28-82b7-d4d2884db748,DISK], DatanodeInfoWithStorage[127.0.0.1:39407,DS-e0438e3a-d755-4a17-b457-29608aa297ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41751,DS-cb878cb3-ce37-4283-92d2-9287ebbd6286,DISK], DatanodeInfoWithStorage[127.0.0.1:37473,DS-545c583e-8ac0-4b04-8067-7a5d5b4c4c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:36317,DS-a00ab3ae-0c95-4251-8fa9-4aa5446b7089,DISK], DatanodeInfoWithStorage[127.0.0.1:34843,DS-3662b4b7-2eaa-4478-a645-0912c91f8248,DISK], DatanodeInfoWithStorage[127.0.0.1:45113,DS-5a944d98-9e12-497d-8d02-8730a7a5214d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1729696788-172.17.0.17-1597548455787:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37452,DS-c2482704-7a79-4076-ad8b-8707b9880e13,DISK], DatanodeInfoWithStorage[127.0.0.1:45373,DS-d3eefaa5-bdb1-4c28-82b7-d4d2884db748,DISK], DatanodeInfoWithStorage[127.0.0.1:39407,DS-e0438e3a-d755-4a17-b457-29608aa297ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41751,DS-cb878cb3-ce37-4283-92d2-9287ebbd6286,DISK], DatanodeInfoWithStorage[127.0.0.1:37473,DS-545c583e-8ac0-4b04-8067-7a5d5b4c4c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:36317,DS-a00ab3ae-0c95-4251-8fa9-4aa5446b7089,DISK], DatanodeInfoWithStorage[127.0.0.1:34843,DS-3662b4b7-2eaa-4478-a645-0912c91f8248,DISK], DatanodeInfoWithStorage[127.0.0.1:45113,DS-5a944d98-9e12-497d-8d02-8730a7a5214d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1054099958-172.17.0.17-1597548629981:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36835,DS-7e3b3df7-cebb-410f-8630-a877732dfb30,DISK], DatanodeInfoWithStorage[127.0.0.1:39451,DS-270d5ae6-cfe4-4733-9a29-8d09398eefc2,DISK], DatanodeInfoWithStorage[127.0.0.1:35270,DS-06034113-c9aa-488f-a0f0-de15635d610e,DISK], DatanodeInfoWithStorage[127.0.0.1:44413,DS-ed5fb7b3-cc3e-4f33-8cd8-fe10679f2788,DISK], DatanodeInfoWithStorage[127.0.0.1:35898,DS-9a1cabfe-a649-437e-b1b9-b2293135ce8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45218,DS-00edfd66-488e-4322-81fa-a0bd2f1142c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46071,DS-0393aa1a-de80-4c29-939f-e26ae3045829,DISK], DatanodeInfoWithStorage[127.0.0.1:35913,DS-5bf2e53a-bb98-4537-b936-09d9118931d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1054099958-172.17.0.17-1597548629981:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36835,DS-7e3b3df7-cebb-410f-8630-a877732dfb30,DISK], DatanodeInfoWithStorage[127.0.0.1:39451,DS-270d5ae6-cfe4-4733-9a29-8d09398eefc2,DISK], DatanodeInfoWithStorage[127.0.0.1:35270,DS-06034113-c9aa-488f-a0f0-de15635d610e,DISK], DatanodeInfoWithStorage[127.0.0.1:44413,DS-ed5fb7b3-cc3e-4f33-8cd8-fe10679f2788,DISK], DatanodeInfoWithStorage[127.0.0.1:35898,DS-9a1cabfe-a649-437e-b1b9-b2293135ce8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45218,DS-00edfd66-488e-4322-81fa-a0bd2f1142c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46071,DS-0393aa1a-de80-4c29-939f-e26ae3045829,DISK], DatanodeInfoWithStorage[127.0.0.1:35913,DS-5bf2e53a-bb98-4537-b936-09d9118931d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-205815089-172.17.0.17-1597548943505:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40909,DS-489ec037-02c5-4dbd-92e9-4f4728705029,DISK], DatanodeInfoWithStorage[127.0.0.1:37626,DS-081748c7-6a82-4e20-91cb-61aa2dd19165,DISK], DatanodeInfoWithStorage[127.0.0.1:45756,DS-6018693f-45fe-465f-a133-70503c9c7f14,DISK], DatanodeInfoWithStorage[127.0.0.1:33869,DS-c5530317-d949-4d11-8b8f-22f5aa75db85,DISK], DatanodeInfoWithStorage[127.0.0.1:43920,DS-26abd9d0-8579-4222-835b-c5af1bbd127e,DISK], DatanodeInfoWithStorage[127.0.0.1:37111,DS-299adfb7-7658-4cb8-bf1c-369d2e3f4544,DISK], DatanodeInfoWithStorage[127.0.0.1:45549,DS-c3e6e235-db35-4078-b7be-8b2c6ec6cd30,DISK], DatanodeInfoWithStorage[127.0.0.1:40832,DS-81ea3879-1f2b-4241-9810-8b14e1c80337,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-205815089-172.17.0.17-1597548943505:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40909,DS-489ec037-02c5-4dbd-92e9-4f4728705029,DISK], DatanodeInfoWithStorage[127.0.0.1:37626,DS-081748c7-6a82-4e20-91cb-61aa2dd19165,DISK], DatanodeInfoWithStorage[127.0.0.1:45756,DS-6018693f-45fe-465f-a133-70503c9c7f14,DISK], DatanodeInfoWithStorage[127.0.0.1:33869,DS-c5530317-d949-4d11-8b8f-22f5aa75db85,DISK], DatanodeInfoWithStorage[127.0.0.1:43920,DS-26abd9d0-8579-4222-835b-c5af1bbd127e,DISK], DatanodeInfoWithStorage[127.0.0.1:37111,DS-299adfb7-7658-4cb8-bf1c-369d2e3f4544,DISK], DatanodeInfoWithStorage[127.0.0.1:45549,DS-c3e6e235-db35-4078-b7be-8b2c6ec6cd30,DISK], DatanodeInfoWithStorage[127.0.0.1:40832,DS-81ea3879-1f2b-4241-9810-8b14e1c80337,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1412810556-172.17.0.17-1597549016343:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36987,DS-6db8372f-0502-4458-b339-f1cddd11b8ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39405,DS-b0f757e1-c39c-40aa-8ab0-23922e4cae24,DISK], DatanodeInfoWithStorage[127.0.0.1:33685,DS-fd881aaf-1af1-4891-a95f-9750e3f73734,DISK], DatanodeInfoWithStorage[127.0.0.1:41614,DS-73d83e26-71c1-4592-9a66-53c9755b6198,DISK], DatanodeInfoWithStorage[127.0.0.1:42326,DS-89fe2d08-145f-4db6-931d-5f932e9079e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35252,DS-b796e70a-8961-4f43-bf0d-e4e267cc73b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40466,DS-882d291f-40d7-4361-8f9c-83b13fd9e0f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38100,DS-d9bbf02a-bf8e-46e8-8f59-6cc30df2830b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1412810556-172.17.0.17-1597549016343:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36987,DS-6db8372f-0502-4458-b339-f1cddd11b8ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39405,DS-b0f757e1-c39c-40aa-8ab0-23922e4cae24,DISK], DatanodeInfoWithStorage[127.0.0.1:33685,DS-fd881aaf-1af1-4891-a95f-9750e3f73734,DISK], DatanodeInfoWithStorage[127.0.0.1:41614,DS-73d83e26-71c1-4592-9a66-53c9755b6198,DISK], DatanodeInfoWithStorage[127.0.0.1:42326,DS-89fe2d08-145f-4db6-931d-5f932e9079e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35252,DS-b796e70a-8961-4f43-bf0d-e4e267cc73b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40466,DS-882d291f-40d7-4361-8f9c-83b13fd9e0f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38100,DS-d9bbf02a-bf8e-46e8-8f59-6cc30df2830b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1027878158-172.17.0.17-1597549476371:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44345,DS-7a0c197c-43fa-4340-aa8c-c811112dc623,DISK], DatanodeInfoWithStorage[127.0.0.1:33125,DS-6187cadd-069b-448e-82be-475b790ec84a,DISK], DatanodeInfoWithStorage[127.0.0.1:35913,DS-bab03bee-0f33-4d53-9339-14700a8de488,DISK], DatanodeInfoWithStorage[127.0.0.1:44755,DS-21929b61-7ff5-4606-b531-b9805cbc6741,DISK], DatanodeInfoWithStorage[127.0.0.1:44018,DS-023f504c-0aea-45f5-9120-485a2742f772,DISK], DatanodeInfoWithStorage[127.0.0.1:43759,DS-cb5e678b-4eca-4939-95a3-f495346b1b30,DISK], DatanodeInfoWithStorage[127.0.0.1:38988,DS-a2d2bef7-8cb4-4465-9001-2bb39f5565c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38144,DS-9c8449b9-52da-4b4a-a43b-711ac1908636,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1027878158-172.17.0.17-1597549476371:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44345,DS-7a0c197c-43fa-4340-aa8c-c811112dc623,DISK], DatanodeInfoWithStorage[127.0.0.1:33125,DS-6187cadd-069b-448e-82be-475b790ec84a,DISK], DatanodeInfoWithStorage[127.0.0.1:35913,DS-bab03bee-0f33-4d53-9339-14700a8de488,DISK], DatanodeInfoWithStorage[127.0.0.1:44755,DS-21929b61-7ff5-4606-b531-b9805cbc6741,DISK], DatanodeInfoWithStorage[127.0.0.1:44018,DS-023f504c-0aea-45f5-9120-485a2742f772,DISK], DatanodeInfoWithStorage[127.0.0.1:43759,DS-cb5e678b-4eca-4939-95a3-f495346b1b30,DISK], DatanodeInfoWithStorage[127.0.0.1:38988,DS-a2d2bef7-8cb4-4465-9001-2bb39f5565c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38144,DS-9c8449b9-52da-4b4a-a43b-711ac1908636,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1676483677-172.17.0.17-1597550560084:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36418,DS-d2a0a7e1-53a7-4139-9e25-f430fc606657,DISK], DatanodeInfoWithStorage[127.0.0.1:43400,DS-2896bf1a-12f7-4585-907b-1e1bc4ecbdf2,DISK], DatanodeInfoWithStorage[127.0.0.1:40471,DS-793a0c22-9574-45a7-bf4d-36d277dfc490,DISK], DatanodeInfoWithStorage[127.0.0.1:33582,DS-3badabe1-c791-422d-ab9f-08cd5b7a4394,DISK], DatanodeInfoWithStorage[127.0.0.1:44670,DS-34a11758-b760-45f6-9222-7f48cd6b1e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:41522,DS-1ad5fabd-3b09-4892-8cb2-902ca22ba739,DISK], DatanodeInfoWithStorage[127.0.0.1:46729,DS-6d6ca7de-9a0c-4087-ab8c-88b12cd107d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40598,DS-43006d13-3a60-4ff4-996f-729bb4a88b13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1676483677-172.17.0.17-1597550560084:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36418,DS-d2a0a7e1-53a7-4139-9e25-f430fc606657,DISK], DatanodeInfoWithStorage[127.0.0.1:43400,DS-2896bf1a-12f7-4585-907b-1e1bc4ecbdf2,DISK], DatanodeInfoWithStorage[127.0.0.1:40471,DS-793a0c22-9574-45a7-bf4d-36d277dfc490,DISK], DatanodeInfoWithStorage[127.0.0.1:33582,DS-3badabe1-c791-422d-ab9f-08cd5b7a4394,DISK], DatanodeInfoWithStorage[127.0.0.1:44670,DS-34a11758-b760-45f6-9222-7f48cd6b1e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:41522,DS-1ad5fabd-3b09-4892-8cb2-902ca22ba739,DISK], DatanodeInfoWithStorage[127.0.0.1:46729,DS-6d6ca7de-9a0c-4087-ab8c-88b12cd107d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40598,DS-43006d13-3a60-4ff4-996f-729bb4a88b13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-670075203-172.17.0.17-1597550884160:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46111,DS-683928e5-6631-4c64-805c-bd694e9de926,DISK], DatanodeInfoWithStorage[127.0.0.1:38137,DS-662ae0f6-f60c-4154-a8d7-aaed90703818,DISK], DatanodeInfoWithStorage[127.0.0.1:44202,DS-814a6bb4-3644-4cf3-bd50-76208d722db8,DISK], DatanodeInfoWithStorage[127.0.0.1:45243,DS-cf127ca4-5248-42e2-87d2-3a2813892431,DISK], DatanodeInfoWithStorage[127.0.0.1:42159,DS-0eb18f33-046c-4de3-90a5-4798ff9a2cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:33102,DS-833186f9-b084-44c2-8e24-bd1bb0620a53,DISK], DatanodeInfoWithStorage[127.0.0.1:43258,DS-09090a6e-884d-4aaf-b4ab-17b3577a73cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37500,DS-ecf5c9a3-9f0b-4c83-b24f-178d16cd9577,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-670075203-172.17.0.17-1597550884160:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46111,DS-683928e5-6631-4c64-805c-bd694e9de926,DISK], DatanodeInfoWithStorage[127.0.0.1:38137,DS-662ae0f6-f60c-4154-a8d7-aaed90703818,DISK], DatanodeInfoWithStorage[127.0.0.1:44202,DS-814a6bb4-3644-4cf3-bd50-76208d722db8,DISK], DatanodeInfoWithStorage[127.0.0.1:45243,DS-cf127ca4-5248-42e2-87d2-3a2813892431,DISK], DatanodeInfoWithStorage[127.0.0.1:42159,DS-0eb18f33-046c-4de3-90a5-4798ff9a2cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:33102,DS-833186f9-b084-44c2-8e24-bd1bb0620a53,DISK], DatanodeInfoWithStorage[127.0.0.1:43258,DS-09090a6e-884d-4aaf-b4ab-17b3577a73cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37500,DS-ecf5c9a3-9f0b-4c83-b24f-178d16cd9577,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-371364314-172.17.0.17-1597550917731:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38813,DS-306f6ac3-ab01-46de-b7df-12e76f7bfed6,DISK], DatanodeInfoWithStorage[127.0.0.1:34834,DS-0d33793c-061b-447a-9580-b7efd02fc9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34436,DS-45839d01-6080-4a27-a2e3-68458eeb2e43,DISK], DatanodeInfoWithStorage[127.0.0.1:37801,DS-68ae416f-f09e-44d7-8838-5ff02032ded6,DISK], DatanodeInfoWithStorage[127.0.0.1:36396,DS-48da5a7b-6822-4a9f-97a4-5a8feb79efd8,DISK], DatanodeInfoWithStorage[127.0.0.1:34736,DS-524a65a4-078e-49b7-9c2a-5c3b35246845,DISK], DatanodeInfoWithStorage[127.0.0.1:39944,DS-6d8d30cf-4a5a-4c8f-83b4-16f59c62ee9b,DISK], DatanodeInfoWithStorage[127.0.0.1:41635,DS-c2252beb-fc35-4edf-baec-b0767e0af53c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-371364314-172.17.0.17-1597550917731:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38813,DS-306f6ac3-ab01-46de-b7df-12e76f7bfed6,DISK], DatanodeInfoWithStorage[127.0.0.1:34834,DS-0d33793c-061b-447a-9580-b7efd02fc9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34436,DS-45839d01-6080-4a27-a2e3-68458eeb2e43,DISK], DatanodeInfoWithStorage[127.0.0.1:37801,DS-68ae416f-f09e-44d7-8838-5ff02032ded6,DISK], DatanodeInfoWithStorage[127.0.0.1:36396,DS-48da5a7b-6822-4a9f-97a4-5a8feb79efd8,DISK], DatanodeInfoWithStorage[127.0.0.1:34736,DS-524a65a4-078e-49b7-9c2a-5c3b35246845,DISK], DatanodeInfoWithStorage[127.0.0.1:39944,DS-6d8d30cf-4a5a-4c8f-83b4-16f59c62ee9b,DISK], DatanodeInfoWithStorage[127.0.0.1:41635,DS-c2252beb-fc35-4edf-baec-b0767e0af53c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-732649298-172.17.0.17-1597550944944:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37173,DS-8c30f197-3b5f-4f96-9df6-09560f5d80ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33864,DS-21827c7a-71c7-423c-b7e7-b0b76df9c360,DISK], DatanodeInfoWithStorage[127.0.0.1:42467,DS-f4dbfc65-2409-4ecb-bb9d-3a655608e86c,DISK], DatanodeInfoWithStorage[127.0.0.1:33511,DS-4e693194-12c1-4853-9d3d-085db05561f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36789,DS-99479276-556f-4c8f-9fdb-478714d68b74,DISK], DatanodeInfoWithStorage[127.0.0.1:38393,DS-53c210cd-04bf-4226-a8a9-cecba2b48567,DISK], DatanodeInfoWithStorage[127.0.0.1:38951,DS-3d7b8b02-8bba-4166-952f-3c8e1a87de6b,DISK], DatanodeInfoWithStorage[127.0.0.1:39695,DS-5cf2393c-16ee-4271-93d7-c454a307d1e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-732649298-172.17.0.17-1597550944944:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37173,DS-8c30f197-3b5f-4f96-9df6-09560f5d80ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33864,DS-21827c7a-71c7-423c-b7e7-b0b76df9c360,DISK], DatanodeInfoWithStorage[127.0.0.1:42467,DS-f4dbfc65-2409-4ecb-bb9d-3a655608e86c,DISK], DatanodeInfoWithStorage[127.0.0.1:33511,DS-4e693194-12c1-4853-9d3d-085db05561f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36789,DS-99479276-556f-4c8f-9fdb-478714d68b74,DISK], DatanodeInfoWithStorage[127.0.0.1:38393,DS-53c210cd-04bf-4226-a8a9-cecba2b48567,DISK], DatanodeInfoWithStorage[127.0.0.1:38951,DS-3d7b8b02-8bba-4166-952f-3c8e1a87de6b,DISK], DatanodeInfoWithStorage[127.0.0.1:39695,DS-5cf2393c-16ee-4271-93d7-c454a307d1e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1803976142-172.17.0.17-1597551018069:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42804,DS-d426b896-80c2-40db-915b-d125c3bb71ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36769,DS-ccdb98fc-0a58-4eea-9e2d-9e2384da6508,DISK], DatanodeInfoWithStorage[127.0.0.1:46406,DS-314dfcfc-583c-4a72-a363-25df4aaa8774,DISK], DatanodeInfoWithStorage[127.0.0.1:45569,DS-a4b1f056-66a7-43e5-9f02-3275f4b9debe,DISK], DatanodeInfoWithStorage[127.0.0.1:41536,DS-84fbf55f-b89a-46f2-ba15-1dc2b1f568ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45412,DS-a956df36-3c07-4581-bdee-7abf9da84baf,DISK], DatanodeInfoWithStorage[127.0.0.1:46635,DS-733f7928-914b-4f7c-a505-7f585ff1197b,DISK], DatanodeInfoWithStorage[127.0.0.1:35906,DS-2cbbab17-6c73-47fc-aa31-36e8272e48b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1803976142-172.17.0.17-1597551018069:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42804,DS-d426b896-80c2-40db-915b-d125c3bb71ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36769,DS-ccdb98fc-0a58-4eea-9e2d-9e2384da6508,DISK], DatanodeInfoWithStorage[127.0.0.1:46406,DS-314dfcfc-583c-4a72-a363-25df4aaa8774,DISK], DatanodeInfoWithStorage[127.0.0.1:45569,DS-a4b1f056-66a7-43e5-9f02-3275f4b9debe,DISK], DatanodeInfoWithStorage[127.0.0.1:41536,DS-84fbf55f-b89a-46f2-ba15-1dc2b1f568ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45412,DS-a956df36-3c07-4581-bdee-7abf9da84baf,DISK], DatanodeInfoWithStorage[127.0.0.1:46635,DS-733f7928-914b-4f7c-a505-7f585ff1197b,DISK], DatanodeInfoWithStorage[127.0.0.1:35906,DS-2cbbab17-6c73-47fc-aa31-36e8272e48b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-601166303-172.17.0.17-1597551197969:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41519,DS-d178682b-7ffb-4975-9e86-7159e3ba9f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:35080,DS-95887df4-6ba1-43cd-ade9-78f5c7aabf12,DISK], DatanodeInfoWithStorage[127.0.0.1:32768,DS-ece6d32b-00b1-4c1a-9ae0-3dbceac0cd8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35307,DS-5bc03886-c16e-40f7-9c91-d582f1551c09,DISK], DatanodeInfoWithStorage[127.0.0.1:45560,DS-b4c4e2ab-bc79-408a-929e-d25deb102e71,DISK], DatanodeInfoWithStorage[127.0.0.1:43096,DS-be0b6105-4517-43e1-9db6-8944a8b4c806,DISK], DatanodeInfoWithStorage[127.0.0.1:38835,DS-2b147a24-5baf-4a78-a8a7-efb54c9ae9d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43156,DS-17e885f6-4438-4cae-bc77-b934c49f53e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-601166303-172.17.0.17-1597551197969:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41519,DS-d178682b-7ffb-4975-9e86-7159e3ba9f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:35080,DS-95887df4-6ba1-43cd-ade9-78f5c7aabf12,DISK], DatanodeInfoWithStorage[127.0.0.1:32768,DS-ece6d32b-00b1-4c1a-9ae0-3dbceac0cd8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35307,DS-5bc03886-c16e-40f7-9c91-d582f1551c09,DISK], DatanodeInfoWithStorage[127.0.0.1:45560,DS-b4c4e2ab-bc79-408a-929e-d25deb102e71,DISK], DatanodeInfoWithStorage[127.0.0.1:43096,DS-be0b6105-4517-43e1-9db6-8944a8b4c806,DISK], DatanodeInfoWithStorage[127.0.0.1:38835,DS-2b147a24-5baf-4a78-a8a7-efb54c9ae9d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43156,DS-17e885f6-4438-4cae-bc77-b934c49f53e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1694077868-172.17.0.17-1597551227547:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46378,DS-2fb4053a-bcdf-42b0-8684-1edd0de98a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:38765,DS-df718e27-08fb-4b08-bb9e-c04b927b8941,DISK], DatanodeInfoWithStorage[127.0.0.1:35484,DS-986f181c-e280-4dd6-bcd0-9f8604e838ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37848,DS-831e074f-bc16-4446-ae15-896919263e37,DISK], DatanodeInfoWithStorage[127.0.0.1:38317,DS-2e0c4212-2552-4361-8a57-dcac93a0effc,DISK], DatanodeInfoWithStorage[127.0.0.1:39158,DS-6748190b-5ab9-4cf8-b475-5970bb1d7005,DISK], DatanodeInfoWithStorage[127.0.0.1:33960,DS-68c4e2f2-36b3-442a-a367-dfb5d95ef747,DISK], DatanodeInfoWithStorage[127.0.0.1:46488,DS-f3ad4f83-22bc-40de-97aa-d2f115324928,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1694077868-172.17.0.17-1597551227547:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46378,DS-2fb4053a-bcdf-42b0-8684-1edd0de98a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:38765,DS-df718e27-08fb-4b08-bb9e-c04b927b8941,DISK], DatanodeInfoWithStorage[127.0.0.1:35484,DS-986f181c-e280-4dd6-bcd0-9f8604e838ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37848,DS-831e074f-bc16-4446-ae15-896919263e37,DISK], DatanodeInfoWithStorage[127.0.0.1:38317,DS-2e0c4212-2552-4361-8a57-dcac93a0effc,DISK], DatanodeInfoWithStorage[127.0.0.1:39158,DS-6748190b-5ab9-4cf8-b475-5970bb1d7005,DISK], DatanodeInfoWithStorage[127.0.0.1:33960,DS-68c4e2f2-36b3-442a-a367-dfb5d95ef747,DISK], DatanodeInfoWithStorage[127.0.0.1:46488,DS-f3ad4f83-22bc-40de-97aa-d2f115324928,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5257
