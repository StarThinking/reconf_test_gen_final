reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 500000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 500000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1808888362-172.17.0.14-1597703547118:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36128,DS-c985c724-92a0-41ab-a276-2079d714e552,DISK], DatanodeInfoWithStorage[127.0.0.1:36741,DS-9e229226-5520-4c45-8332-b3855303d29c,DISK], DatanodeInfoWithStorage[127.0.0.1:35291,DS-30091868-b656-402b-942d-5ae0b0f4b23a,DISK], DatanodeInfoWithStorage[127.0.0.1:46006,DS-f946f6f6-f9b6-4974-a969-50f967da5656,DISK], DatanodeInfoWithStorage[127.0.0.1:40783,DS-71cc4c43-cc37-4592-9c90-12e4e1a3483e,DISK], DatanodeInfoWithStorage[127.0.0.1:34006,DS-51af46ce-87a4-4b32-b5ee-e4d5d027551c,DISK], DatanodeInfoWithStorage[127.0.0.1:37835,DS-30b3fb80-2cf6-4208-b882-a00fef3891d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33749,DS-f85aeb01-cd81-42be-b548-7e29a40f29fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1808888362-172.17.0.14-1597703547118:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36128,DS-c985c724-92a0-41ab-a276-2079d714e552,DISK], DatanodeInfoWithStorage[127.0.0.1:36741,DS-9e229226-5520-4c45-8332-b3855303d29c,DISK], DatanodeInfoWithStorage[127.0.0.1:35291,DS-30091868-b656-402b-942d-5ae0b0f4b23a,DISK], DatanodeInfoWithStorage[127.0.0.1:46006,DS-f946f6f6-f9b6-4974-a969-50f967da5656,DISK], DatanodeInfoWithStorage[127.0.0.1:40783,DS-71cc4c43-cc37-4592-9c90-12e4e1a3483e,DISK], DatanodeInfoWithStorage[127.0.0.1:34006,DS-51af46ce-87a4-4b32-b5ee-e4d5d027551c,DISK], DatanodeInfoWithStorage[127.0.0.1:37835,DS-30b3fb80-2cf6-4208-b882-a00fef3891d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33749,DS-f85aeb01-cd81-42be-b548-7e29a40f29fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 500000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1608434828-172.17.0.14-1597703773233:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46192,DS-9100a787-fff2-4f26-9fd8-adb883eeae94,DISK], DatanodeInfoWithStorage[127.0.0.1:39275,DS-eda6bf0d-7add-44ab-ae84-a4be0b044ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:36605,DS-74594483-f5bc-487b-a88d-72ca75929933,DISK], DatanodeInfoWithStorage[127.0.0.1:39635,DS-6a249a40-4cc3-415b-8cb1-9d4d83aec041,DISK], DatanodeInfoWithStorage[127.0.0.1:45896,DS-416455f2-29e2-4258-902c-c488f22e2d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35982,DS-876fe97b-8ff8-4db2-a15a-80e4e1e1b706,DISK], DatanodeInfoWithStorage[127.0.0.1:42566,DS-36377e8a-4a52-42d8-9419-a2bb3fdaf7ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36931,DS-45ede901-58a6-4924-a619-c68ba843508e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1608434828-172.17.0.14-1597703773233:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46192,DS-9100a787-fff2-4f26-9fd8-adb883eeae94,DISK], DatanodeInfoWithStorage[127.0.0.1:39275,DS-eda6bf0d-7add-44ab-ae84-a4be0b044ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:36605,DS-74594483-f5bc-487b-a88d-72ca75929933,DISK], DatanodeInfoWithStorage[127.0.0.1:39635,DS-6a249a40-4cc3-415b-8cb1-9d4d83aec041,DISK], DatanodeInfoWithStorage[127.0.0.1:45896,DS-416455f2-29e2-4258-902c-c488f22e2d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35982,DS-876fe97b-8ff8-4db2-a15a-80e4e1e1b706,DISK], DatanodeInfoWithStorage[127.0.0.1:42566,DS-36377e8a-4a52-42d8-9419-a2bb3fdaf7ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36931,DS-45ede901-58a6-4924-a619-c68ba843508e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 500000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1697184490-172.17.0.14-1597703847986:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46110,DS-8ce6d592-10da-4a80-980d-943fce47544f,DISK], DatanodeInfoWithStorage[127.0.0.1:41714,DS-12c65d58-d805-4900-a2a6-45f494bd1559,DISK], DatanodeInfoWithStorage[127.0.0.1:40095,DS-a10547d4-37c0-4844-9fef-0df8632d06da,DISK], DatanodeInfoWithStorage[127.0.0.1:33993,DS-70b4a89a-f1de-478c-9b64-e01db1a29f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:35588,DS-f9b1f2e6-d67f-431c-9968-be8600e7064b,DISK], DatanodeInfoWithStorage[127.0.0.1:36939,DS-632b079f-ac7b-4cc5-8d43-1bf36b33d7ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42776,DS-2ede80c6-c999-4581-8247-8d0ad7d836e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37832,DS-a18b01b6-37e5-43bf-aaf6-57d09492988f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1697184490-172.17.0.14-1597703847986:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46110,DS-8ce6d592-10da-4a80-980d-943fce47544f,DISK], DatanodeInfoWithStorage[127.0.0.1:41714,DS-12c65d58-d805-4900-a2a6-45f494bd1559,DISK], DatanodeInfoWithStorage[127.0.0.1:40095,DS-a10547d4-37c0-4844-9fef-0df8632d06da,DISK], DatanodeInfoWithStorage[127.0.0.1:33993,DS-70b4a89a-f1de-478c-9b64-e01db1a29f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:35588,DS-f9b1f2e6-d67f-431c-9968-be8600e7064b,DISK], DatanodeInfoWithStorage[127.0.0.1:36939,DS-632b079f-ac7b-4cc5-8d43-1bf36b33d7ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42776,DS-2ede80c6-c999-4581-8247-8d0ad7d836e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37832,DS-a18b01b6-37e5-43bf-aaf6-57d09492988f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 500000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-199272577-172.17.0.14-1597704225835:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43529,DS-5d168832-7e69-412a-a4a0-9e1915c04179,DISK], DatanodeInfoWithStorage[127.0.0.1:35857,DS-0c737aaf-afdb-4a31-990a-f554d07a8f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:45521,DS-a463f661-4b20-4b34-9a43-8954bf386646,DISK], DatanodeInfoWithStorage[127.0.0.1:41571,DS-f7637a36-99bf-4fd1-884e-0df21503508c,DISK], DatanodeInfoWithStorage[127.0.0.1:41591,DS-bd83266d-eb66-450f-b650-d5d0a83e1e60,DISK], DatanodeInfoWithStorage[127.0.0.1:33613,DS-d43d664a-f138-44e8-bc77-8235d1bd286e,DISK], DatanodeInfoWithStorage[127.0.0.1:38804,DS-19147222-c7f5-4593-b6f7-a25d7ae14ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-e1f62443-fe8e-4387-9806-e9275da466d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-199272577-172.17.0.14-1597704225835:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43529,DS-5d168832-7e69-412a-a4a0-9e1915c04179,DISK], DatanodeInfoWithStorage[127.0.0.1:35857,DS-0c737aaf-afdb-4a31-990a-f554d07a8f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:45521,DS-a463f661-4b20-4b34-9a43-8954bf386646,DISK], DatanodeInfoWithStorage[127.0.0.1:41571,DS-f7637a36-99bf-4fd1-884e-0df21503508c,DISK], DatanodeInfoWithStorage[127.0.0.1:41591,DS-bd83266d-eb66-450f-b650-d5d0a83e1e60,DISK], DatanodeInfoWithStorage[127.0.0.1:33613,DS-d43d664a-f138-44e8-bc77-8235d1bd286e,DISK], DatanodeInfoWithStorage[127.0.0.1:38804,DS-19147222-c7f5-4593-b6f7-a25d7ae14ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-e1f62443-fe8e-4387-9806-e9275da466d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 500000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-363864870-172.17.0.14-1597704401493:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34264,DS-87e91038-8693-4814-9b7f-c56dad997a25,DISK], DatanodeInfoWithStorage[127.0.0.1:38442,DS-96dac5be-8d5c-4f2d-b680-dd1cd363f3e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41326,DS-e0c41a3c-fd68-48e4-a3e7-53e331fd50eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35423,DS-efea10a4-5c25-48f8-8020-4c80e2d7b276,DISK], DatanodeInfoWithStorage[127.0.0.1:42998,DS-0341edcb-0c07-4f5c-8b40-81930ffaadc7,DISK], DatanodeInfoWithStorage[127.0.0.1:36706,DS-d07281e6-90ba-4a21-941c-985ebd96a310,DISK], DatanodeInfoWithStorage[127.0.0.1:43424,DS-3225f9a6-537a-443a-8eb6-edef62ac9e51,DISK], DatanodeInfoWithStorage[127.0.0.1:33681,DS-89b96a5f-2a4d-4370-a813-0ed8d4c5eb0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-363864870-172.17.0.14-1597704401493:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34264,DS-87e91038-8693-4814-9b7f-c56dad997a25,DISK], DatanodeInfoWithStorage[127.0.0.1:38442,DS-96dac5be-8d5c-4f2d-b680-dd1cd363f3e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41326,DS-e0c41a3c-fd68-48e4-a3e7-53e331fd50eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35423,DS-efea10a4-5c25-48f8-8020-4c80e2d7b276,DISK], DatanodeInfoWithStorage[127.0.0.1:42998,DS-0341edcb-0c07-4f5c-8b40-81930ffaadc7,DISK], DatanodeInfoWithStorage[127.0.0.1:36706,DS-d07281e6-90ba-4a21-941c-985ebd96a310,DISK], DatanodeInfoWithStorage[127.0.0.1:43424,DS-3225f9a6-537a-443a-8eb6-edef62ac9e51,DISK], DatanodeInfoWithStorage[127.0.0.1:33681,DS-89b96a5f-2a4d-4370-a813-0ed8d4c5eb0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 500000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-286038613-172.17.0.14-1597704441856:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37443,DS-a83de044-d8b5-4910-99a5-8ce4683993cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35625,DS-e121c7fb-7c41-46d9-a394-5285a29d2dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:42637,DS-e22936fb-1663-4b94-ab01-bbc1d3713c59,DISK], DatanodeInfoWithStorage[127.0.0.1:33612,DS-4011e562-3870-435b-b0d7-6b18da53cd4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35269,DS-40e32ba3-8323-401b-abfb-e2940bfc5bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:39515,DS-64faaa03-b2ba-4557-80d6-a3833fcb109c,DISK], DatanodeInfoWithStorage[127.0.0.1:45616,DS-cdd16516-af13-4e1f-ba3e-2fdf3533556f,DISK], DatanodeInfoWithStorage[127.0.0.1:44919,DS-1a3ba52d-49c3-4a52-8198-804a2aa150d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-286038613-172.17.0.14-1597704441856:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37443,DS-a83de044-d8b5-4910-99a5-8ce4683993cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35625,DS-e121c7fb-7c41-46d9-a394-5285a29d2dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:42637,DS-e22936fb-1663-4b94-ab01-bbc1d3713c59,DISK], DatanodeInfoWithStorage[127.0.0.1:33612,DS-4011e562-3870-435b-b0d7-6b18da53cd4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35269,DS-40e32ba3-8323-401b-abfb-e2940bfc5bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:39515,DS-64faaa03-b2ba-4557-80d6-a3833fcb109c,DISK], DatanodeInfoWithStorage[127.0.0.1:45616,DS-cdd16516-af13-4e1f-ba3e-2fdf3533556f,DISK], DatanodeInfoWithStorage[127.0.0.1:44919,DS-1a3ba52d-49c3-4a52-8198-804a2aa150d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 500000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-351294363-172.17.0.14-1597704654412:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34232,DS-a63517bb-13e6-4aee-a7b2-913322f4d2fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44763,DS-69771762-2744-45cf-b00a-95777904fd92,DISK], DatanodeInfoWithStorage[127.0.0.1:46330,DS-79c70e8b-06ba-45ad-9e06-eb59075cd3e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34603,DS-7ef836dc-803a-4880-8285-43069ae9dcef,DISK], DatanodeInfoWithStorage[127.0.0.1:41983,DS-afba3d26-6426-4738-96bd-af4b0986ce6c,DISK], DatanodeInfoWithStorage[127.0.0.1:36306,DS-78b25c16-42a2-4a77-ba90-c6feefa34ded,DISK], DatanodeInfoWithStorage[127.0.0.1:33617,DS-29534d07-6402-4b63-b129-2e8da9786e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33511,DS-bd660552-53c8-47b3-95b6-762bbd34eab8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-351294363-172.17.0.14-1597704654412:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34232,DS-a63517bb-13e6-4aee-a7b2-913322f4d2fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44763,DS-69771762-2744-45cf-b00a-95777904fd92,DISK], DatanodeInfoWithStorage[127.0.0.1:46330,DS-79c70e8b-06ba-45ad-9e06-eb59075cd3e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34603,DS-7ef836dc-803a-4880-8285-43069ae9dcef,DISK], DatanodeInfoWithStorage[127.0.0.1:41983,DS-afba3d26-6426-4738-96bd-af4b0986ce6c,DISK], DatanodeInfoWithStorage[127.0.0.1:36306,DS-78b25c16-42a2-4a77-ba90-c6feefa34ded,DISK], DatanodeInfoWithStorage[127.0.0.1:33617,DS-29534d07-6402-4b63-b129-2e8da9786e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33511,DS-bd660552-53c8-47b3-95b6-762bbd34eab8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 500000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-39962563-172.17.0.14-1597704871834:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41150,DS-88a17a41-c06f-4723-a0c2-34d0eb825a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:40048,DS-4e1ce116-c848-4ce2-b14a-0cc1cc105792,DISK], DatanodeInfoWithStorage[127.0.0.1:38768,DS-204f5b11-e68c-4d72-b6e2-a392689be7c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42246,DS-fa7c236b-6662-4e74-a051-8c1a00d3b7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35204,DS-b17dff16-c4cf-4981-8f1e-c4efa68121bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43466,DS-95d0755e-b0b2-472a-afe7-c34edfb3e713,DISK], DatanodeInfoWithStorage[127.0.0.1:35336,DS-66278383-afbd-4db7-b736-2baa7163afb1,DISK], DatanodeInfoWithStorage[127.0.0.1:38579,DS-c7648abf-81ce-4228-be8c-a036103e06ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-39962563-172.17.0.14-1597704871834:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41150,DS-88a17a41-c06f-4723-a0c2-34d0eb825a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:40048,DS-4e1ce116-c848-4ce2-b14a-0cc1cc105792,DISK], DatanodeInfoWithStorage[127.0.0.1:38768,DS-204f5b11-e68c-4d72-b6e2-a392689be7c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42246,DS-fa7c236b-6662-4e74-a051-8c1a00d3b7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35204,DS-b17dff16-c4cf-4981-8f1e-c4efa68121bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43466,DS-95d0755e-b0b2-472a-afe7-c34edfb3e713,DISK], DatanodeInfoWithStorage[127.0.0.1:35336,DS-66278383-afbd-4db7-b736-2baa7163afb1,DISK], DatanodeInfoWithStorage[127.0.0.1:38579,DS-c7648abf-81ce-4228-be8c-a036103e06ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 500000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1860883056-172.17.0.14-1597704949342:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35963,DS-bcd73f80-2786-4205-8fcc-3f57c1e13e56,DISK], DatanodeInfoWithStorage[127.0.0.1:42005,DS-aa137063-f355-45e7-9781-ae17943301cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34064,DS-0150ca44-b29b-429f-bbb3-80c3a91af66c,DISK], DatanodeInfoWithStorage[127.0.0.1:38882,DS-4e698d20-368c-456d-b355-b7d4803c4c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37953,DS-74f546c3-b5a7-4734-830e-a53415791f36,DISK], DatanodeInfoWithStorage[127.0.0.1:44350,DS-0c148996-bacd-4197-a124-759eaca34e25,DISK], DatanodeInfoWithStorage[127.0.0.1:41126,DS-ab899393-c0e5-46a0-9be0-39d67ba448db,DISK], DatanodeInfoWithStorage[127.0.0.1:44205,DS-9e4b4002-4329-42bc-8634-3031e1c4886b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1860883056-172.17.0.14-1597704949342:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35963,DS-bcd73f80-2786-4205-8fcc-3f57c1e13e56,DISK], DatanodeInfoWithStorage[127.0.0.1:42005,DS-aa137063-f355-45e7-9781-ae17943301cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34064,DS-0150ca44-b29b-429f-bbb3-80c3a91af66c,DISK], DatanodeInfoWithStorage[127.0.0.1:38882,DS-4e698d20-368c-456d-b355-b7d4803c4c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37953,DS-74f546c3-b5a7-4734-830e-a53415791f36,DISK], DatanodeInfoWithStorage[127.0.0.1:44350,DS-0c148996-bacd-4197-a124-759eaca34e25,DISK], DatanodeInfoWithStorage[127.0.0.1:41126,DS-ab899393-c0e5-46a0-9be0-39d67ba448db,DISK], DatanodeInfoWithStorage[127.0.0.1:44205,DS-9e4b4002-4329-42bc-8634-3031e1c4886b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 500000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2039036824-172.17.0.14-1597705118921:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43062,DS-9eec531a-ab53-47f5-a94c-f1493c054ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:33012,DS-9fa4e31a-156d-4496-b990-ff3a9bfb21cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41143,DS-4eb4cae0-ba5f-4419-96c8-ddbe63229ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:41137,DS-8040e1b6-9b4f-43df-8bcd-70fbfa07d67e,DISK], DatanodeInfoWithStorage[127.0.0.1:35732,DS-16d58249-08b9-4d00-b4ac-254895165798,DISK], DatanodeInfoWithStorage[127.0.0.1:39875,DS-8ddaf528-d84d-4117-abd1-e52ce6f54d27,DISK], DatanodeInfoWithStorage[127.0.0.1:45731,DS-a9fc7ffd-78e8-451f-8b1a-f8e930dc28bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46705,DS-b99ded0c-fe0d-426a-beb8-a4c3e4dbd64e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2039036824-172.17.0.14-1597705118921:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43062,DS-9eec531a-ab53-47f5-a94c-f1493c054ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:33012,DS-9fa4e31a-156d-4496-b990-ff3a9bfb21cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41143,DS-4eb4cae0-ba5f-4419-96c8-ddbe63229ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:41137,DS-8040e1b6-9b4f-43df-8bcd-70fbfa07d67e,DISK], DatanodeInfoWithStorage[127.0.0.1:35732,DS-16d58249-08b9-4d00-b4ac-254895165798,DISK], DatanodeInfoWithStorage[127.0.0.1:39875,DS-8ddaf528-d84d-4117-abd1-e52ce6f54d27,DISK], DatanodeInfoWithStorage[127.0.0.1:45731,DS-a9fc7ffd-78e8-451f-8b1a-f8e930dc28bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46705,DS-b99ded0c-fe0d-426a-beb8-a4c3e4dbd64e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 500000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1724833238-172.17.0.14-1597705742299:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36892,DS-0e7bc4a4-0537-42f5-8960-6d921c28920a,DISK], DatanodeInfoWithStorage[127.0.0.1:38723,DS-a7388e04-40bc-4728-8772-cc9915a1d6d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45349,DS-871fba0e-2462-47ee-a8c9-5daffb06c94d,DISK], DatanodeInfoWithStorage[127.0.0.1:43275,DS-4ed689e1-abbf-4e8a-b3a2-5512802a85d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46558,DS-49bd719f-ca8a-4dee-bf81-121d3d58c6e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42381,DS-b1691a65-12d3-40b6-84da-1d17fd7c55e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41489,DS-83d6039a-7038-4367-9187-722698653dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:44131,DS-bd1b0fcb-151e-4bac-97ce-b27fe91eff27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1724833238-172.17.0.14-1597705742299:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36892,DS-0e7bc4a4-0537-42f5-8960-6d921c28920a,DISK], DatanodeInfoWithStorage[127.0.0.1:38723,DS-a7388e04-40bc-4728-8772-cc9915a1d6d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45349,DS-871fba0e-2462-47ee-a8c9-5daffb06c94d,DISK], DatanodeInfoWithStorage[127.0.0.1:43275,DS-4ed689e1-abbf-4e8a-b3a2-5512802a85d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46558,DS-49bd719f-ca8a-4dee-bf81-121d3d58c6e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42381,DS-b1691a65-12d3-40b6-84da-1d17fd7c55e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41489,DS-83d6039a-7038-4367-9187-722698653dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:44131,DS-bd1b0fcb-151e-4bac-97ce-b27fe91eff27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 500000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1647797879-172.17.0.14-1597705800520:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35276,DS-ef05cad1-360e-45c9-9db1-98325ff062a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37366,DS-0e40d3ec-b52e-4140-8d53-95918a17eafb,DISK], DatanodeInfoWithStorage[127.0.0.1:37080,DS-3378b1c1-63d5-434e-b5c8-4a6967816a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35783,DS-30a8a9bc-3d39-4a9a-afe2-f5be4ea70346,DISK], DatanodeInfoWithStorage[127.0.0.1:33911,DS-3af88bc2-9834-48fb-aa2e-871196a7c8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41366,DS-a6dd15e6-1ec4-43ec-961f-39c1498deef6,DISK], DatanodeInfoWithStorage[127.0.0.1:46618,DS-c8667c0f-1907-43aa-b6de-516fece703d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38169,DS-b805db69-2f4a-4d0c-9ffc-4b5702c93a7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1647797879-172.17.0.14-1597705800520:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35276,DS-ef05cad1-360e-45c9-9db1-98325ff062a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37366,DS-0e40d3ec-b52e-4140-8d53-95918a17eafb,DISK], DatanodeInfoWithStorage[127.0.0.1:37080,DS-3378b1c1-63d5-434e-b5c8-4a6967816a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35783,DS-30a8a9bc-3d39-4a9a-afe2-f5be4ea70346,DISK], DatanodeInfoWithStorage[127.0.0.1:33911,DS-3af88bc2-9834-48fb-aa2e-871196a7c8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41366,DS-a6dd15e6-1ec4-43ec-961f-39c1498deef6,DISK], DatanodeInfoWithStorage[127.0.0.1:46618,DS-c8667c0f-1907-43aa-b6de-516fece703d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38169,DS-b805db69-2f4a-4d0c-9ffc-4b5702c93a7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5388
