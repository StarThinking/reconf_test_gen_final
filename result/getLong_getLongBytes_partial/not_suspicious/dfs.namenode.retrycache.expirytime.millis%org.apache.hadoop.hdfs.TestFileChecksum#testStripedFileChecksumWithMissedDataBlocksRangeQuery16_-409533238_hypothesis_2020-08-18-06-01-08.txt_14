reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 1000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 1000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2135849286-172.17.0.20-1597730684245:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33303,DS-edd5c28f-fb88-4f68-9cf4-5fa20b32de9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35214,DS-f1ec988a-b4c7-4784-a538-8562044f8218,DISK], DatanodeInfoWithStorage[127.0.0.1:46424,DS-49907777-2dc4-4224-9b0a-dd09e31f5a74,DISK], DatanodeInfoWithStorage[127.0.0.1:38588,DS-6a3705b0-98a2-4d2f-9799-2ef15ef9f313,DISK], DatanodeInfoWithStorage[127.0.0.1:39050,DS-26cff176-0673-4530-a596-d48b00de2dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:43853,DS-952efbcf-ea48-4d05-aed8-eba26bea2c53,DISK], DatanodeInfoWithStorage[127.0.0.1:34742,DS-a8064258-df1a-4719-ba3c-9b8a947a8c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:43191,DS-eb3305b9-50a7-4f57-b292-97f63bf9e777,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2135849286-172.17.0.20-1597730684245:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33303,DS-edd5c28f-fb88-4f68-9cf4-5fa20b32de9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35214,DS-f1ec988a-b4c7-4784-a538-8562044f8218,DISK], DatanodeInfoWithStorage[127.0.0.1:46424,DS-49907777-2dc4-4224-9b0a-dd09e31f5a74,DISK], DatanodeInfoWithStorage[127.0.0.1:38588,DS-6a3705b0-98a2-4d2f-9799-2ef15ef9f313,DISK], DatanodeInfoWithStorage[127.0.0.1:39050,DS-26cff176-0673-4530-a596-d48b00de2dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:43853,DS-952efbcf-ea48-4d05-aed8-eba26bea2c53,DISK], DatanodeInfoWithStorage[127.0.0.1:34742,DS-a8064258-df1a-4719-ba3c-9b8a947a8c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:43191,DS-eb3305b9-50a7-4f57-b292-97f63bf9e777,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 1000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-333717737-172.17.0.20-1597730855685:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36978,DS-de6afe85-64cb-4abe-91d3-69335bdd7ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:41193,DS-58959b62-2a4c-43f4-8df5-27a9e14e670c,DISK], DatanodeInfoWithStorage[127.0.0.1:35830,DS-c3731c5a-3924-4805-a095-239dfbe51651,DISK], DatanodeInfoWithStorage[127.0.0.1:42817,DS-e4bc69fb-5aeb-43aa-90d3-9607152dac28,DISK], DatanodeInfoWithStorage[127.0.0.1:45432,DS-1c0755b3-b084-46b1-9c36-2e0e8755e669,DISK], DatanodeInfoWithStorage[127.0.0.1:40811,DS-4b07fa02-2daa-444f-8901-aa301f32d990,DISK], DatanodeInfoWithStorage[127.0.0.1:42445,DS-8e64b89b-768f-4748-be57-20544c81a1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45398,DS-7d2cf948-2776-49a9-971c-a434700c1f99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-333717737-172.17.0.20-1597730855685:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36978,DS-de6afe85-64cb-4abe-91d3-69335bdd7ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:41193,DS-58959b62-2a4c-43f4-8df5-27a9e14e670c,DISK], DatanodeInfoWithStorage[127.0.0.1:35830,DS-c3731c5a-3924-4805-a095-239dfbe51651,DISK], DatanodeInfoWithStorage[127.0.0.1:42817,DS-e4bc69fb-5aeb-43aa-90d3-9607152dac28,DISK], DatanodeInfoWithStorage[127.0.0.1:45432,DS-1c0755b3-b084-46b1-9c36-2e0e8755e669,DISK], DatanodeInfoWithStorage[127.0.0.1:40811,DS-4b07fa02-2daa-444f-8901-aa301f32d990,DISK], DatanodeInfoWithStorage[127.0.0.1:42445,DS-8e64b89b-768f-4748-be57-20544c81a1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45398,DS-7d2cf948-2776-49a9-971c-a434700c1f99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 1000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-347782990-172.17.0.20-1597731459076:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41708,DS-946bbecc-07e3-4fb4-8039-b327553b43b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44747,DS-0d7051ee-b432-4ed9-8224-324768702583,DISK], DatanodeInfoWithStorage[127.0.0.1:36638,DS-4d2b4900-a660-4a4b-b1d9-6fdb2f705445,DISK], DatanodeInfoWithStorage[127.0.0.1:44867,DS-3798ecd6-9f58-4437-a93d-222d8d472755,DISK], DatanodeInfoWithStorage[127.0.0.1:40264,DS-2625dd31-c25c-4fbe-912f-b8aafa4fa995,DISK], DatanodeInfoWithStorage[127.0.0.1:36901,DS-15e8392c-c770-4441-a279-f9b8b8343352,DISK], DatanodeInfoWithStorage[127.0.0.1:42482,DS-75fb3ee3-e035-4b37-bf80-00544d16061a,DISK], DatanodeInfoWithStorage[127.0.0.1:33907,DS-22aa6923-b3c7-48dc-aeef-a9a5e2ff678a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-347782990-172.17.0.20-1597731459076:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41708,DS-946bbecc-07e3-4fb4-8039-b327553b43b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44747,DS-0d7051ee-b432-4ed9-8224-324768702583,DISK], DatanodeInfoWithStorage[127.0.0.1:36638,DS-4d2b4900-a660-4a4b-b1d9-6fdb2f705445,DISK], DatanodeInfoWithStorage[127.0.0.1:44867,DS-3798ecd6-9f58-4437-a93d-222d8d472755,DISK], DatanodeInfoWithStorage[127.0.0.1:40264,DS-2625dd31-c25c-4fbe-912f-b8aafa4fa995,DISK], DatanodeInfoWithStorage[127.0.0.1:36901,DS-15e8392c-c770-4441-a279-f9b8b8343352,DISK], DatanodeInfoWithStorage[127.0.0.1:42482,DS-75fb3ee3-e035-4b37-bf80-00544d16061a,DISK], DatanodeInfoWithStorage[127.0.0.1:33907,DS-22aa6923-b3c7-48dc-aeef-a9a5e2ff678a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 1000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-610175960-172.17.0.20-1597731628815:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37237,DS-c5de01dc-3e24-48d7-a816-1ca96e84e2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40127,DS-5ab542e7-48e0-48b8-8883-f71c519e64a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43340,DS-4532c165-d03c-463a-9e7d-a5cd40bad230,DISK], DatanodeInfoWithStorage[127.0.0.1:34662,DS-f78340f3-64de-480e-af63-0710efb6092d,DISK], DatanodeInfoWithStorage[127.0.0.1:44468,DS-d5ce27c7-7df9-4920-8c05-ed4d08879ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:45635,DS-a8445d70-6122-42ee-a17d-4dd87804ccc5,DISK], DatanodeInfoWithStorage[127.0.0.1:42898,DS-0b7fa664-ac3a-47a0-8084-31ad57eee436,DISK], DatanodeInfoWithStorage[127.0.0.1:36784,DS-42c85323-0f75-411b-80a4-4a15d1928c4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-610175960-172.17.0.20-1597731628815:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37237,DS-c5de01dc-3e24-48d7-a816-1ca96e84e2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40127,DS-5ab542e7-48e0-48b8-8883-f71c519e64a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43340,DS-4532c165-d03c-463a-9e7d-a5cd40bad230,DISK], DatanodeInfoWithStorage[127.0.0.1:34662,DS-f78340f3-64de-480e-af63-0710efb6092d,DISK], DatanodeInfoWithStorage[127.0.0.1:44468,DS-d5ce27c7-7df9-4920-8c05-ed4d08879ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:45635,DS-a8445d70-6122-42ee-a17d-4dd87804ccc5,DISK], DatanodeInfoWithStorage[127.0.0.1:42898,DS-0b7fa664-ac3a-47a0-8084-31ad57eee436,DISK], DatanodeInfoWithStorage[127.0.0.1:36784,DS-42c85323-0f75-411b-80a4-4a15d1928c4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 1000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1917489161-172.17.0.20-1597732215036:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43574,DS-15feeaf9-7b93-4a89-9a18-3cc5c10385c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46731,DS-db8935bb-aa58-4678-9a96-bec35f17ff49,DISK], DatanodeInfoWithStorage[127.0.0.1:44009,DS-83a1eefa-2c23-4aef-939b-c664463159bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42408,DS-5f0bfb73-25e1-4837-9888-d8e1d4d5eb8b,DISK], DatanodeInfoWithStorage[127.0.0.1:40110,DS-4ba73257-e618-4ce9-8f43-78f6f996f30c,DISK], DatanodeInfoWithStorage[127.0.0.1:36073,DS-a92e95ad-1f67-47ab-96fd-b46ae92443f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39105,DS-745eb116-f279-4af8-b22e-7b112a18dec5,DISK], DatanodeInfoWithStorage[127.0.0.1:32907,DS-d1ad9303-a7e4-41f2-8665-6339f3c7e1bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1917489161-172.17.0.20-1597732215036:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43574,DS-15feeaf9-7b93-4a89-9a18-3cc5c10385c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46731,DS-db8935bb-aa58-4678-9a96-bec35f17ff49,DISK], DatanodeInfoWithStorage[127.0.0.1:44009,DS-83a1eefa-2c23-4aef-939b-c664463159bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42408,DS-5f0bfb73-25e1-4837-9888-d8e1d4d5eb8b,DISK], DatanodeInfoWithStorage[127.0.0.1:40110,DS-4ba73257-e618-4ce9-8f43-78f6f996f30c,DISK], DatanodeInfoWithStorage[127.0.0.1:36073,DS-a92e95ad-1f67-47ab-96fd-b46ae92443f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39105,DS-745eb116-f279-4af8-b22e-7b112a18dec5,DISK], DatanodeInfoWithStorage[127.0.0.1:32907,DS-d1ad9303-a7e4-41f2-8665-6339f3c7e1bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 1000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2091087707-172.17.0.20-1597733264607:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45591,DS-9df6527e-33b6-44d9-a705-ed775fe0cb42,DISK], DatanodeInfoWithStorage[127.0.0.1:36608,DS-5db3c542-5df0-4973-8e3a-073dbca7ae52,DISK], DatanodeInfoWithStorage[127.0.0.1:45271,DS-a49b1a7f-f3c1-427f-83f8-87ca7b2c0728,DISK], DatanodeInfoWithStorage[127.0.0.1:32820,DS-f47a0d7f-8945-4a09-8bff-af9b2936939b,DISK], DatanodeInfoWithStorage[127.0.0.1:42843,DS-66eb423e-c908-48ef-8295-02fccc20dcd4,DISK], DatanodeInfoWithStorage[127.0.0.1:38091,DS-c1642439-82f2-43d4-9ca1-dbeddc8bc00a,DISK], DatanodeInfoWithStorage[127.0.0.1:33693,DS-b7dde679-51a6-45e3-8ba3-3e08ebc09aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:45308,DS-6de5f047-48d2-48ba-af03-c9f81e4c1fee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2091087707-172.17.0.20-1597733264607:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45591,DS-9df6527e-33b6-44d9-a705-ed775fe0cb42,DISK], DatanodeInfoWithStorage[127.0.0.1:36608,DS-5db3c542-5df0-4973-8e3a-073dbca7ae52,DISK], DatanodeInfoWithStorage[127.0.0.1:45271,DS-a49b1a7f-f3c1-427f-83f8-87ca7b2c0728,DISK], DatanodeInfoWithStorage[127.0.0.1:32820,DS-f47a0d7f-8945-4a09-8bff-af9b2936939b,DISK], DatanodeInfoWithStorage[127.0.0.1:42843,DS-66eb423e-c908-48ef-8295-02fccc20dcd4,DISK], DatanodeInfoWithStorage[127.0.0.1:38091,DS-c1642439-82f2-43d4-9ca1-dbeddc8bc00a,DISK], DatanodeInfoWithStorage[127.0.0.1:33693,DS-b7dde679-51a6-45e3-8ba3-3e08ebc09aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:45308,DS-6de5f047-48d2-48ba-af03-c9f81e4c1fee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 1000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1697958923-172.17.0.20-1597733930996:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46682,DS-7c06450f-179c-4002-9fab-2e403f19eb47,DISK], DatanodeInfoWithStorage[127.0.0.1:33970,DS-7945e1e0-2329-4b2c-8ed2-af20143396c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34374,DS-b9e87daf-3154-435e-8aa1-9eb20d3406c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35889,DS-5be29295-bd88-4725-bbe8-1f9130b2cc26,DISK], DatanodeInfoWithStorage[127.0.0.1:40792,DS-9e59c080-c0cb-417c-952c-b4e12feb3aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:45306,DS-19759f6e-9fbc-492f-aff9-bbfef7812f5a,DISK], DatanodeInfoWithStorage[127.0.0.1:33073,DS-63baaa88-50f9-4e29-b39e-1bf940c79839,DISK], DatanodeInfoWithStorage[127.0.0.1:40547,DS-17b494ad-bfa5-42af-9654-cabcdb598bcc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1697958923-172.17.0.20-1597733930996:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46682,DS-7c06450f-179c-4002-9fab-2e403f19eb47,DISK], DatanodeInfoWithStorage[127.0.0.1:33970,DS-7945e1e0-2329-4b2c-8ed2-af20143396c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34374,DS-b9e87daf-3154-435e-8aa1-9eb20d3406c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35889,DS-5be29295-bd88-4725-bbe8-1f9130b2cc26,DISK], DatanodeInfoWithStorage[127.0.0.1:40792,DS-9e59c080-c0cb-417c-952c-b4e12feb3aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:45306,DS-19759f6e-9fbc-492f-aff9-bbfef7812f5a,DISK], DatanodeInfoWithStorage[127.0.0.1:33073,DS-63baaa88-50f9-4e29-b39e-1bf940c79839,DISK], DatanodeInfoWithStorage[127.0.0.1:40547,DS-17b494ad-bfa5-42af-9654-cabcdb598bcc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 1000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-371913228-172.17.0.20-1597733965188:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44914,DS-ceab6905-3b04-4e52-bd16-a2a2f95222b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40871,DS-6e9cfff3-a55a-4e87-8dd5-dc014e17ca81,DISK], DatanodeInfoWithStorage[127.0.0.1:45562,DS-69489842-fbb7-40ca-b262-dc838818f326,DISK], DatanodeInfoWithStorage[127.0.0.1:37030,DS-358fcd48-33de-471a-8fba-59e6936371b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36947,DS-9b1663f0-2764-40d3-9da7-1c89cd5c61b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42194,DS-6565f086-ae30-449b-8388-fb1f14674bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:39226,DS-6e50c75f-f272-4fa8-98b1-dd4fa11fcde2,DISK], DatanodeInfoWithStorage[127.0.0.1:42472,DS-a826289e-fded-4bac-9bea-d6441b550eb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-371913228-172.17.0.20-1597733965188:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44914,DS-ceab6905-3b04-4e52-bd16-a2a2f95222b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40871,DS-6e9cfff3-a55a-4e87-8dd5-dc014e17ca81,DISK], DatanodeInfoWithStorage[127.0.0.1:45562,DS-69489842-fbb7-40ca-b262-dc838818f326,DISK], DatanodeInfoWithStorage[127.0.0.1:37030,DS-358fcd48-33de-471a-8fba-59e6936371b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36947,DS-9b1663f0-2764-40d3-9da7-1c89cd5c61b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42194,DS-6565f086-ae30-449b-8388-fb1f14674bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:39226,DS-6e50c75f-f272-4fa8-98b1-dd4fa11fcde2,DISK], DatanodeInfoWithStorage[127.0.0.1:42472,DS-a826289e-fded-4bac-9bea-d6441b550eb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 1000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-400309938-172.17.0.20-1597734172171:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40880,DS-0177bdcd-d0fb-488d-a40c-efa9944702ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38712,DS-5914d990-e7f6-4c89-af45-0958bd8366e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36860,DS-6bbe31e6-9655-45d3-9f97-d8028fab3fef,DISK], DatanodeInfoWithStorage[127.0.0.1:45895,DS-72beb6c6-9578-4d31-ba01-c212a98c8487,DISK], DatanodeInfoWithStorage[127.0.0.1:38580,DS-6d714367-4ffb-4258-8ca2-fa34646f79bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43060,DS-e809626c-c5b8-477a-afdb-26ca44cdac6b,DISK], DatanodeInfoWithStorage[127.0.0.1:45426,DS-173dd1d0-6201-4ca0-b408-f434b33bc1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38341,DS-fd64ce5b-f5f2-4b92-975b-a1d3afad22c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-400309938-172.17.0.20-1597734172171:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40880,DS-0177bdcd-d0fb-488d-a40c-efa9944702ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38712,DS-5914d990-e7f6-4c89-af45-0958bd8366e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36860,DS-6bbe31e6-9655-45d3-9f97-d8028fab3fef,DISK], DatanodeInfoWithStorage[127.0.0.1:45895,DS-72beb6c6-9578-4d31-ba01-c212a98c8487,DISK], DatanodeInfoWithStorage[127.0.0.1:38580,DS-6d714367-4ffb-4258-8ca2-fa34646f79bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43060,DS-e809626c-c5b8-477a-afdb-26ca44cdac6b,DISK], DatanodeInfoWithStorage[127.0.0.1:45426,DS-173dd1d0-6201-4ca0-b408-f434b33bc1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38341,DS-fd64ce5b-f5f2-4b92-975b-a1d3afad22c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 1000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1281154556-172.17.0.20-1597734244937:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34868,DS-276b6fa4-56fe-45a8-8242-7faec6cca812,DISK], DatanodeInfoWithStorage[127.0.0.1:40629,DS-5862f951-1307-4add-9241-a0b136825309,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-62226a91-c7da-4adb-b200-1cffcd926d54,DISK], DatanodeInfoWithStorage[127.0.0.1:42151,DS-bfdc0b18-65f5-46ae-bc1e-7df544f81f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44252,DS-c839db6d-5510-4c4b-ae27-59c438a789cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43995,DS-52374de7-a846-4b5b-a9c1-eeee1a99290c,DISK], DatanodeInfoWithStorage[127.0.0.1:43325,DS-f0ff10a8-9e86-41fd-b97b-b35ad8a6f45a,DISK], DatanodeInfoWithStorage[127.0.0.1:37240,DS-2c32d3e5-b0d9-4c1a-a5ab-4aa7c19e2dec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1281154556-172.17.0.20-1597734244937:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34868,DS-276b6fa4-56fe-45a8-8242-7faec6cca812,DISK], DatanodeInfoWithStorage[127.0.0.1:40629,DS-5862f951-1307-4add-9241-a0b136825309,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-62226a91-c7da-4adb-b200-1cffcd926d54,DISK], DatanodeInfoWithStorage[127.0.0.1:42151,DS-bfdc0b18-65f5-46ae-bc1e-7df544f81f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44252,DS-c839db6d-5510-4c4b-ae27-59c438a789cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43995,DS-52374de7-a846-4b5b-a9c1-eeee1a99290c,DISK], DatanodeInfoWithStorage[127.0.0.1:43325,DS-f0ff10a8-9e86-41fd-b97b-b35ad8a6f45a,DISK], DatanodeInfoWithStorage[127.0.0.1:37240,DS-2c32d3e5-b0d9-4c1a-a5ab-4aa7c19e2dec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 1000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-921660299-172.17.0.20-1597735113012:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39184,DS-5ff03bf7-fcec-4d80-be54-83e9b7d3a720,DISK], DatanodeInfoWithStorage[127.0.0.1:34686,DS-e69bd8dc-28ad-4df9-ad30-501b7dfde998,DISK], DatanodeInfoWithStorage[127.0.0.1:45466,DS-f0fc8667-9e57-4308-ade8-e4c30b1939c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41494,DS-25ef4d3c-1f3d-4c26-b926-083a2ae0f49e,DISK], DatanodeInfoWithStorage[127.0.0.1:36210,DS-15d56455-29c7-4b61-9b10-e58d857b3fae,DISK], DatanodeInfoWithStorage[127.0.0.1:40733,DS-bbc6afd5-a803-481c-9425-25720ca5da1d,DISK], DatanodeInfoWithStorage[127.0.0.1:36984,DS-416f7158-648f-4fd2-9707-28b1942d1245,DISK], DatanodeInfoWithStorage[127.0.0.1:33495,DS-0fcd8344-617d-4660-a909-b0d73e576b9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-921660299-172.17.0.20-1597735113012:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39184,DS-5ff03bf7-fcec-4d80-be54-83e9b7d3a720,DISK], DatanodeInfoWithStorage[127.0.0.1:34686,DS-e69bd8dc-28ad-4df9-ad30-501b7dfde998,DISK], DatanodeInfoWithStorage[127.0.0.1:45466,DS-f0fc8667-9e57-4308-ade8-e4c30b1939c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41494,DS-25ef4d3c-1f3d-4c26-b926-083a2ae0f49e,DISK], DatanodeInfoWithStorage[127.0.0.1:36210,DS-15d56455-29c7-4b61-9b10-e58d857b3fae,DISK], DatanodeInfoWithStorage[127.0.0.1:40733,DS-bbc6afd5-a803-481c-9425-25720ca5da1d,DISK], DatanodeInfoWithStorage[127.0.0.1:36984,DS-416f7158-648f-4fd2-9707-28b1942d1245,DISK], DatanodeInfoWithStorage[127.0.0.1:33495,DS-0fcd8344-617d-4660-a909-b0d73e576b9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 1000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1086711963-172.17.0.20-1597735526272:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36646,DS-50ef72ef-6110-43d1-8253-2165051844bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35631,DS-8fe96932-771e-4f04-9b28-c102405e1c89,DISK], DatanodeInfoWithStorage[127.0.0.1:33379,DS-07af9f36-b1a2-494a-b0c9-1441e2b84ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:33580,DS-1510755a-4068-43d3-8c8a-d0ec75fa9e37,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-73c7cbaf-57fe-4e85-838b-13b845cdea4a,DISK], DatanodeInfoWithStorage[127.0.0.1:32957,DS-0246377d-5da5-49cb-9b6b-2758c3e91eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:35449,DS-eec8c41a-f7a6-4331-b948-32ea4e57a832,DISK], DatanodeInfoWithStorage[127.0.0.1:40612,DS-9406d8d9-e664-45ce-8853-f443ef2dce3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1086711963-172.17.0.20-1597735526272:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36646,DS-50ef72ef-6110-43d1-8253-2165051844bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35631,DS-8fe96932-771e-4f04-9b28-c102405e1c89,DISK], DatanodeInfoWithStorage[127.0.0.1:33379,DS-07af9f36-b1a2-494a-b0c9-1441e2b84ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:33580,DS-1510755a-4068-43d3-8c8a-d0ec75fa9e37,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-73c7cbaf-57fe-4e85-838b-13b845cdea4a,DISK], DatanodeInfoWithStorage[127.0.0.1:32957,DS-0246377d-5da5-49cb-9b6b-2758c3e91eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:35449,DS-eec8c41a-f7a6-4331-b948-32ea4e57a832,DISK], DatanodeInfoWithStorage[127.0.0.1:40612,DS-9406d8d9-e664-45ce-8853-f443ef2dce3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 1000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1431037927-172.17.0.20-1597735562893:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39953,DS-b6e7175e-edc2-4503-9274-11c0409c371c,DISK], DatanodeInfoWithStorage[127.0.0.1:33705,DS-e960a127-5f14-4b19-9914-b9be27b18435,DISK], DatanodeInfoWithStorage[127.0.0.1:46324,DS-4f119e6f-198f-4c17-8679-37fbceb4d0e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38397,DS-f1c56ec1-5596-4fdd-9231-b7e5420cbe55,DISK], DatanodeInfoWithStorage[127.0.0.1:34773,DS-ed4ad391-bf16-48f2-857b-cf81750ad3f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40801,DS-7ff002b8-69b0-4655-9de1-29be5a7e9b81,DISK], DatanodeInfoWithStorage[127.0.0.1:38590,DS-d8f1c40c-e88a-4cc0-ade6-064fd3cb90b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43019,DS-4653208d-8184-4637-8131-74453f9c416d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1431037927-172.17.0.20-1597735562893:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39953,DS-b6e7175e-edc2-4503-9274-11c0409c371c,DISK], DatanodeInfoWithStorage[127.0.0.1:33705,DS-e960a127-5f14-4b19-9914-b9be27b18435,DISK], DatanodeInfoWithStorage[127.0.0.1:46324,DS-4f119e6f-198f-4c17-8679-37fbceb4d0e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38397,DS-f1c56ec1-5596-4fdd-9231-b7e5420cbe55,DISK], DatanodeInfoWithStorage[127.0.0.1:34773,DS-ed4ad391-bf16-48f2-857b-cf81750ad3f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40801,DS-7ff002b8-69b0-4655-9de1-29be5a7e9b81,DISK], DatanodeInfoWithStorage[127.0.0.1:38590,DS-d8f1c40c-e88a-4cc0-ade6-064fd3cb90b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43019,DS-4653208d-8184-4637-8131-74453f9c416d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5220
