reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1531885618-172.17.0.18-1597749434399:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34781,DS-44f391ba-fdd5-47ba-b639-39c5428808f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37649,DS-83a1070d-2eec-46e6-bfd2-ba42f2318751,DISK], DatanodeInfoWithStorage[127.0.0.1:40551,DS-468fdda3-ba20-4eff-9cd0-f8e8931b5741,DISK], DatanodeInfoWithStorage[127.0.0.1:42664,DS-75aed36f-43e9-4850-9afc-8225701ef2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45718,DS-d13d9dca-7cc3-4351-a654-64db814c8039,DISK], DatanodeInfoWithStorage[127.0.0.1:44816,DS-583381d5-cd8b-4da4-a717-7da134edef4f,DISK], DatanodeInfoWithStorage[127.0.0.1:43782,DS-4e2514e6-7cf5-4177-81e0-cf610487202b,DISK], DatanodeInfoWithStorage[127.0.0.1:43184,DS-7b459290-9947-4c72-a98e-66eb9cb27dbd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1531885618-172.17.0.18-1597749434399:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34781,DS-44f391ba-fdd5-47ba-b639-39c5428808f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37649,DS-83a1070d-2eec-46e6-bfd2-ba42f2318751,DISK], DatanodeInfoWithStorage[127.0.0.1:40551,DS-468fdda3-ba20-4eff-9cd0-f8e8931b5741,DISK], DatanodeInfoWithStorage[127.0.0.1:42664,DS-75aed36f-43e9-4850-9afc-8225701ef2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45718,DS-d13d9dca-7cc3-4351-a654-64db814c8039,DISK], DatanodeInfoWithStorage[127.0.0.1:44816,DS-583381d5-cd8b-4da4-a717-7da134edef4f,DISK], DatanodeInfoWithStorage[127.0.0.1:43782,DS-4e2514e6-7cf5-4177-81e0-cf610487202b,DISK], DatanodeInfoWithStorage[127.0.0.1:43184,DS-7b459290-9947-4c72-a98e-66eb9cb27dbd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1243381587-172.17.0.18-1597750025277:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43969,DS-02a9212f-7671-4572-997d-b64703aae050,DISK], DatanodeInfoWithStorage[127.0.0.1:43961,DS-e9550ecc-8299-4400-a622-430dba502756,DISK], DatanodeInfoWithStorage[127.0.0.1:35603,DS-6f35b6b3-5913-4421-b7a0-a37d70ecd45d,DISK], DatanodeInfoWithStorage[127.0.0.1:42357,DS-3340278b-84c0-4181-9d4b-500c509218e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42324,DS-5744095a-2b18-4a2d-97d2-0d3deb854851,DISK], DatanodeInfoWithStorage[127.0.0.1:44414,DS-14a56b5b-b834-4dd9-bb78-d9b3ad2c82a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42052,DS-86242c74-b28e-4c71-b749-bf26c91ef539,DISK], DatanodeInfoWithStorage[127.0.0.1:35743,DS-bec3aa17-6fda-433b-8eb4-31dc4fc21823,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1243381587-172.17.0.18-1597750025277:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43969,DS-02a9212f-7671-4572-997d-b64703aae050,DISK], DatanodeInfoWithStorage[127.0.0.1:43961,DS-e9550ecc-8299-4400-a622-430dba502756,DISK], DatanodeInfoWithStorage[127.0.0.1:35603,DS-6f35b6b3-5913-4421-b7a0-a37d70ecd45d,DISK], DatanodeInfoWithStorage[127.0.0.1:42357,DS-3340278b-84c0-4181-9d4b-500c509218e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42324,DS-5744095a-2b18-4a2d-97d2-0d3deb854851,DISK], DatanodeInfoWithStorage[127.0.0.1:44414,DS-14a56b5b-b834-4dd9-bb78-d9b3ad2c82a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42052,DS-86242c74-b28e-4c71-b749-bf26c91ef539,DISK], DatanodeInfoWithStorage[127.0.0.1:35743,DS-bec3aa17-6fda-433b-8eb4-31dc4fc21823,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1633520507-172.17.0.18-1597750225481:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46743,DS-a91eabb4-29b6-4744-8e1d-96502b2c20f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37501,DS-850b8ea2-37e1-4635-ad34-d4e59af50027,DISK], DatanodeInfoWithStorage[127.0.0.1:36898,DS-6a37f529-63e8-4dab-bbcc-a0ef3d58319d,DISK], DatanodeInfoWithStorage[127.0.0.1:41309,DS-d54ca436-759e-4240-8150-a2943d3615f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43557,DS-050f30c2-ac09-4108-bbaf-825f21f05c24,DISK], DatanodeInfoWithStorage[127.0.0.1:32988,DS-00ccb11d-275e-4532-a0c8-a13e5b6b0919,DISK], DatanodeInfoWithStorage[127.0.0.1:37436,DS-cc8c4f34-5a29-4b02-8b30-44a8b7504707,DISK], DatanodeInfoWithStorage[127.0.0.1:43851,DS-0df25d0d-4c3e-4977-8570-02d8b8a383a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1633520507-172.17.0.18-1597750225481:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46743,DS-a91eabb4-29b6-4744-8e1d-96502b2c20f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37501,DS-850b8ea2-37e1-4635-ad34-d4e59af50027,DISK], DatanodeInfoWithStorage[127.0.0.1:36898,DS-6a37f529-63e8-4dab-bbcc-a0ef3d58319d,DISK], DatanodeInfoWithStorage[127.0.0.1:41309,DS-d54ca436-759e-4240-8150-a2943d3615f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43557,DS-050f30c2-ac09-4108-bbaf-825f21f05c24,DISK], DatanodeInfoWithStorage[127.0.0.1:32988,DS-00ccb11d-275e-4532-a0c8-a13e5b6b0919,DISK], DatanodeInfoWithStorage[127.0.0.1:37436,DS-cc8c4f34-5a29-4b02-8b30-44a8b7504707,DISK], DatanodeInfoWithStorage[127.0.0.1:43851,DS-0df25d0d-4c3e-4977-8570-02d8b8a383a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-107025246-172.17.0.18-1597750330728:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33723,DS-44bac301-c743-4176-a5ef-a546fc8165b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41110,DS-a4876d8f-1d00-4b6e-94b5-22e91f0e981d,DISK], DatanodeInfoWithStorage[127.0.0.1:39830,DS-db547e9c-f328-416d-8f3a-c5b4590f08bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41595,DS-377c06d9-c08c-4a20-a51d-d23b57777a30,DISK], DatanodeInfoWithStorage[127.0.0.1:43848,DS-dd9f641e-4c43-439a-b368-c7997ac5d107,DISK], DatanodeInfoWithStorage[127.0.0.1:40803,DS-6b659991-159a-4ee4-8276-b927fbce2478,DISK], DatanodeInfoWithStorage[127.0.0.1:41768,DS-7970fc83-a653-462a-8439-0a41a2f4d4a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36299,DS-935d136a-14b9-42fe-b67f-64ed2f6bf9d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-107025246-172.17.0.18-1597750330728:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33723,DS-44bac301-c743-4176-a5ef-a546fc8165b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41110,DS-a4876d8f-1d00-4b6e-94b5-22e91f0e981d,DISK], DatanodeInfoWithStorage[127.0.0.1:39830,DS-db547e9c-f328-416d-8f3a-c5b4590f08bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41595,DS-377c06d9-c08c-4a20-a51d-d23b57777a30,DISK], DatanodeInfoWithStorage[127.0.0.1:43848,DS-dd9f641e-4c43-439a-b368-c7997ac5d107,DISK], DatanodeInfoWithStorage[127.0.0.1:40803,DS-6b659991-159a-4ee4-8276-b927fbce2478,DISK], DatanodeInfoWithStorage[127.0.0.1:41768,DS-7970fc83-a653-462a-8439-0a41a2f4d4a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36299,DS-935d136a-14b9-42fe-b67f-64ed2f6bf9d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1986684001-172.17.0.18-1597750937729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44412,DS-96390379-a14a-49f1-9f83-fac27fcec3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40313,DS-998efb15-3777-48cf-a04c-08fbe35db633,DISK], DatanodeInfoWithStorage[127.0.0.1:37219,DS-2e484e8b-43e1-49c2-aca1-bb4fa91ac881,DISK], DatanodeInfoWithStorage[127.0.0.1:40991,DS-ef733454-547b-4365-acc9-cd9a0e2910c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38960,DS-d6e42f7d-a711-4b81-b26a-027f204a103a,DISK], DatanodeInfoWithStorage[127.0.0.1:39852,DS-3ecf10f2-0409-45e2-9e79-37377c2099d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40899,DS-aa741d75-4301-4ae7-8489-28c14dfa365a,DISK], DatanodeInfoWithStorage[127.0.0.1:45697,DS-c34dff9b-5c55-4d2f-8127-41495ff9f3a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1986684001-172.17.0.18-1597750937729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44412,DS-96390379-a14a-49f1-9f83-fac27fcec3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40313,DS-998efb15-3777-48cf-a04c-08fbe35db633,DISK], DatanodeInfoWithStorage[127.0.0.1:37219,DS-2e484e8b-43e1-49c2-aca1-bb4fa91ac881,DISK], DatanodeInfoWithStorage[127.0.0.1:40991,DS-ef733454-547b-4365-acc9-cd9a0e2910c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38960,DS-d6e42f7d-a711-4b81-b26a-027f204a103a,DISK], DatanodeInfoWithStorage[127.0.0.1:39852,DS-3ecf10f2-0409-45e2-9e79-37377c2099d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40899,DS-aa741d75-4301-4ae7-8489-28c14dfa365a,DISK], DatanodeInfoWithStorage[127.0.0.1:45697,DS-c34dff9b-5c55-4d2f-8127-41495ff9f3a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1012261398-172.17.0.18-1597751321168:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32889,DS-09c469e8-8961-40f8-898e-922fe788efa8,DISK], DatanodeInfoWithStorage[127.0.0.1:35008,DS-798d70d9-9232-4c7b-bcce-134c59806aec,DISK], DatanodeInfoWithStorage[127.0.0.1:34263,DS-759534f4-2947-46bc-b252-4d49ccf56708,DISK], DatanodeInfoWithStorage[127.0.0.1:33391,DS-6701e132-9dec-4ae1-a555-67d380710ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:36896,DS-56d57a18-569b-4767-b604-6bad45964345,DISK], DatanodeInfoWithStorage[127.0.0.1:45062,DS-70408b19-3908-423a-81cd-fd5d5a6461ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39634,DS-cf3c0043-feb8-486e-ae55-585802ff7ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:41224,DS-c2d322f7-8789-4e1e-a071-b59d8dc8d9ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1012261398-172.17.0.18-1597751321168:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32889,DS-09c469e8-8961-40f8-898e-922fe788efa8,DISK], DatanodeInfoWithStorage[127.0.0.1:35008,DS-798d70d9-9232-4c7b-bcce-134c59806aec,DISK], DatanodeInfoWithStorage[127.0.0.1:34263,DS-759534f4-2947-46bc-b252-4d49ccf56708,DISK], DatanodeInfoWithStorage[127.0.0.1:33391,DS-6701e132-9dec-4ae1-a555-67d380710ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:36896,DS-56d57a18-569b-4767-b604-6bad45964345,DISK], DatanodeInfoWithStorage[127.0.0.1:45062,DS-70408b19-3908-423a-81cd-fd5d5a6461ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39634,DS-cf3c0043-feb8-486e-ae55-585802ff7ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:41224,DS-c2d322f7-8789-4e1e-a071-b59d8dc8d9ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1501289754-172.17.0.18-1597751526135:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44265,DS-0c39fdad-3be8-4f71-a3ce-cf8f026c4138,DISK], DatanodeInfoWithStorage[127.0.0.1:35038,DS-ff899b0f-313f-4ae0-bca4-7bd2b7778aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:44581,DS-86b08a7f-aaf6-415c-8294-4dcff61d40ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42840,DS-544566d6-d4c2-4fc7-acf6-0864790afc33,DISK], DatanodeInfoWithStorage[127.0.0.1:37135,DS-ad1f336d-a3d5-437a-96aa-bcb27055447e,DISK], DatanodeInfoWithStorage[127.0.0.1:37398,DS-31ea1512-3d6b-408c-9bb8-641087d8069d,DISK], DatanodeInfoWithStorage[127.0.0.1:41702,DS-d54de525-1b9e-4dcb-9e80-924fae587483,DISK], DatanodeInfoWithStorage[127.0.0.1:45519,DS-a36fcaaa-dced-4cb8-b5fe-295b0a9dc89b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1501289754-172.17.0.18-1597751526135:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44265,DS-0c39fdad-3be8-4f71-a3ce-cf8f026c4138,DISK], DatanodeInfoWithStorage[127.0.0.1:35038,DS-ff899b0f-313f-4ae0-bca4-7bd2b7778aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:44581,DS-86b08a7f-aaf6-415c-8294-4dcff61d40ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42840,DS-544566d6-d4c2-4fc7-acf6-0864790afc33,DISK], DatanodeInfoWithStorage[127.0.0.1:37135,DS-ad1f336d-a3d5-437a-96aa-bcb27055447e,DISK], DatanodeInfoWithStorage[127.0.0.1:37398,DS-31ea1512-3d6b-408c-9bb8-641087d8069d,DISK], DatanodeInfoWithStorage[127.0.0.1:41702,DS-d54de525-1b9e-4dcb-9e80-924fae587483,DISK], DatanodeInfoWithStorage[127.0.0.1:45519,DS-a36fcaaa-dced-4cb8-b5fe-295b0a9dc89b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-930580213-172.17.0.18-1597752498520:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40557,DS-114bdfac-7211-4875-ab73-c3b45bd1f444,DISK], DatanodeInfoWithStorage[127.0.0.1:44678,DS-975fb3a8-c38b-4908-b1bc-78c6eb92e517,DISK], DatanodeInfoWithStorage[127.0.0.1:45586,DS-9237b5f4-ad56-4a7c-aaba-5dcebf1a65a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35788,DS-6e830af0-a576-4f7d-be94-c14266966526,DISK], DatanodeInfoWithStorage[127.0.0.1:40827,DS-3bb6d91a-b4a3-4bc3-b2b1-a2780164691a,DISK], DatanodeInfoWithStorage[127.0.0.1:41521,DS-048b8781-5f64-4c0a-b4f9-304949148a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:37029,DS-38893fa5-8fef-4ac4-8dba-d3a5faea58be,DISK], DatanodeInfoWithStorage[127.0.0.1:45950,DS-c48cff23-6198-424b-8122-136adbcf4210,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-930580213-172.17.0.18-1597752498520:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40557,DS-114bdfac-7211-4875-ab73-c3b45bd1f444,DISK], DatanodeInfoWithStorage[127.0.0.1:44678,DS-975fb3a8-c38b-4908-b1bc-78c6eb92e517,DISK], DatanodeInfoWithStorage[127.0.0.1:45586,DS-9237b5f4-ad56-4a7c-aaba-5dcebf1a65a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35788,DS-6e830af0-a576-4f7d-be94-c14266966526,DISK], DatanodeInfoWithStorage[127.0.0.1:40827,DS-3bb6d91a-b4a3-4bc3-b2b1-a2780164691a,DISK], DatanodeInfoWithStorage[127.0.0.1:41521,DS-048b8781-5f64-4c0a-b4f9-304949148a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:37029,DS-38893fa5-8fef-4ac4-8dba-d3a5faea58be,DISK], DatanodeInfoWithStorage[127.0.0.1:45950,DS-c48cff23-6198-424b-8122-136adbcf4210,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2091328041-172.17.0.18-1597752629066:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39119,DS-7520bb51-d101-4586-adc8-cc0c8b4dae57,DISK], DatanodeInfoWithStorage[127.0.0.1:45931,DS-f3f22e62-e167-47f6-8439-5e46514f1097,DISK], DatanodeInfoWithStorage[127.0.0.1:39384,DS-2be129b3-ca9a-4ef2-9ffd-43f797e177eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35298,DS-c2cb3af5-1f84-4b06-8525-c7cdba4f5a86,DISK], DatanodeInfoWithStorage[127.0.0.1:42830,DS-17dedd92-ae89-4f74-9b48-9e541a5d1b75,DISK], DatanodeInfoWithStorage[127.0.0.1:35195,DS-a6d2c7a1-3cdd-47c3-9f5d-042817925397,DISK], DatanodeInfoWithStorage[127.0.0.1:46042,DS-515f18e9-79cc-4f01-b9b9-fa7e1fd9ab10,DISK], DatanodeInfoWithStorage[127.0.0.1:43992,DS-0f095c91-38b3-481a-82c3-426987221e6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2091328041-172.17.0.18-1597752629066:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39119,DS-7520bb51-d101-4586-adc8-cc0c8b4dae57,DISK], DatanodeInfoWithStorage[127.0.0.1:45931,DS-f3f22e62-e167-47f6-8439-5e46514f1097,DISK], DatanodeInfoWithStorage[127.0.0.1:39384,DS-2be129b3-ca9a-4ef2-9ffd-43f797e177eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35298,DS-c2cb3af5-1f84-4b06-8525-c7cdba4f5a86,DISK], DatanodeInfoWithStorage[127.0.0.1:42830,DS-17dedd92-ae89-4f74-9b48-9e541a5d1b75,DISK], DatanodeInfoWithStorage[127.0.0.1:35195,DS-a6d2c7a1-3cdd-47c3-9f5d-042817925397,DISK], DatanodeInfoWithStorage[127.0.0.1:46042,DS-515f18e9-79cc-4f01-b9b9-fa7e1fd9ab10,DISK], DatanodeInfoWithStorage[127.0.0.1:43992,DS-0f095c91-38b3-481a-82c3-426987221e6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-42973007-172.17.0.18-1597753076704:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33076,DS-6b027c65-916e-4a95-b54e-dbb4c32f1f87,DISK], DatanodeInfoWithStorage[127.0.0.1:34197,DS-44124c69-f768-47a2-a1cb-ffeec7cbf10c,DISK], DatanodeInfoWithStorage[127.0.0.1:45608,DS-1fdc3967-9e0f-408b-9e81-6f347cef15b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38848,DS-d5fb230e-bd3d-495b-8ac5-4ded02e36f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:33498,DS-4675718f-4407-4fd6-bbd1-2560f1881d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42565,DS-4957e2ae-a5ee-4f45-8775-3842d09dbca6,DISK], DatanodeInfoWithStorage[127.0.0.1:33611,DS-a2775d07-43d8-4e97-ba1d-17bb65aa59d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45607,DS-36d62d8f-23bc-44d9-b707-a989e145d0ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-42973007-172.17.0.18-1597753076704:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33076,DS-6b027c65-916e-4a95-b54e-dbb4c32f1f87,DISK], DatanodeInfoWithStorage[127.0.0.1:34197,DS-44124c69-f768-47a2-a1cb-ffeec7cbf10c,DISK], DatanodeInfoWithStorage[127.0.0.1:45608,DS-1fdc3967-9e0f-408b-9e81-6f347cef15b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38848,DS-d5fb230e-bd3d-495b-8ac5-4ded02e36f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:33498,DS-4675718f-4407-4fd6-bbd1-2560f1881d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42565,DS-4957e2ae-a5ee-4f45-8775-3842d09dbca6,DISK], DatanodeInfoWithStorage[127.0.0.1:33611,DS-a2775d07-43d8-4e97-ba1d-17bb65aa59d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45607,DS-36d62d8f-23bc-44d9-b707-a989e145d0ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-725286870-172.17.0.18-1597753111556:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35441,DS-915002dd-b22d-41ce-906d-f42fc0f6ceb2,DISK], DatanodeInfoWithStorage[127.0.0.1:37121,DS-d07596d1-96c4-42ae-ac23-2e30ac0e0c24,DISK], DatanodeInfoWithStorage[127.0.0.1:44406,DS-6ca1742d-10e9-404b-8827-613840495eed,DISK], DatanodeInfoWithStorage[127.0.0.1:36581,DS-a97334a9-9281-4cb6-84cc-8d427ababbe8,DISK], DatanodeInfoWithStorage[127.0.0.1:39747,DS-b7d0e343-901b-4116-9b17-104da8f493cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39004,DS-057a1580-f383-4bc4-9c42-654c1b9d62f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45287,DS-772c7d48-e73f-4bee-88d5-10769f65611d,DISK], DatanodeInfoWithStorage[127.0.0.1:33817,DS-6d5fd2c0-4968-4267-95ec-9624e8745bbd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-725286870-172.17.0.18-1597753111556:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35441,DS-915002dd-b22d-41ce-906d-f42fc0f6ceb2,DISK], DatanodeInfoWithStorage[127.0.0.1:37121,DS-d07596d1-96c4-42ae-ac23-2e30ac0e0c24,DISK], DatanodeInfoWithStorage[127.0.0.1:44406,DS-6ca1742d-10e9-404b-8827-613840495eed,DISK], DatanodeInfoWithStorage[127.0.0.1:36581,DS-a97334a9-9281-4cb6-84cc-8d427ababbe8,DISK], DatanodeInfoWithStorage[127.0.0.1:39747,DS-b7d0e343-901b-4116-9b17-104da8f493cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39004,DS-057a1580-f383-4bc4-9c42-654c1b9d62f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45287,DS-772c7d48-e73f-4bee-88d5-10769f65611d,DISK], DatanodeInfoWithStorage[127.0.0.1:33817,DS-6d5fd2c0-4968-4267-95ec-9624e8745bbd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1787358203-172.17.0.18-1597753262299:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44590,DS-f83feef7-5f3e-4a78-b2c6-24d2fc9edecf,DISK], DatanodeInfoWithStorage[127.0.0.1:45095,DS-6faa59d7-96c7-441b-abf8-1135d19498e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36244,DS-a736264d-f121-4188-a9a2-bdc8361babee,DISK], DatanodeInfoWithStorage[127.0.0.1:40263,DS-5282e385-eb5d-4b8a-9155-88721b6ad9bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37698,DS-99f672ae-0ac3-4cc9-bd1c-2184b4c7a759,DISK], DatanodeInfoWithStorage[127.0.0.1:35609,DS-f0e6cb9b-9d00-421c-9ac9-c4721c1acf45,DISK], DatanodeInfoWithStorage[127.0.0.1:41310,DS-7a588962-a0ed-4219-9593-bb0e1c14d319,DISK], DatanodeInfoWithStorage[127.0.0.1:34023,DS-e6b70e4d-3cf8-41de-875c-978e89bfbbad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1787358203-172.17.0.18-1597753262299:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44590,DS-f83feef7-5f3e-4a78-b2c6-24d2fc9edecf,DISK], DatanodeInfoWithStorage[127.0.0.1:45095,DS-6faa59d7-96c7-441b-abf8-1135d19498e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36244,DS-a736264d-f121-4188-a9a2-bdc8361babee,DISK], DatanodeInfoWithStorage[127.0.0.1:40263,DS-5282e385-eb5d-4b8a-9155-88721b6ad9bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37698,DS-99f672ae-0ac3-4cc9-bd1c-2184b4c7a759,DISK], DatanodeInfoWithStorage[127.0.0.1:35609,DS-f0e6cb9b-9d00-421c-9ac9-c4721c1acf45,DISK], DatanodeInfoWithStorage[127.0.0.1:41310,DS-7a588962-a0ed-4219-9593-bb0e1c14d319,DISK], DatanodeInfoWithStorage[127.0.0.1:34023,DS-e6b70e4d-3cf8-41de-875c-978e89bfbbad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1572774327-172.17.0.18-1597753412794:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45393,DS-781db4f0-97a9-414a-9172-792c4ca17273,DISK], DatanodeInfoWithStorage[127.0.0.1:32964,DS-462e8cce-4423-4693-9f1e-93d8154f5ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:46146,DS-9955ed93-464e-45e8-9ac2-0745b7602db8,DISK], DatanodeInfoWithStorage[127.0.0.1:43855,DS-a8ccad1e-f0d2-4e28-b408-308e1fbbb05d,DISK], DatanodeInfoWithStorage[127.0.0.1:34314,DS-d714251f-d7cd-439b-bf8c-7b3a28cfecea,DISK], DatanodeInfoWithStorage[127.0.0.1:34384,DS-1248cc1f-6012-489a-b629-e8847529ace2,DISK], DatanodeInfoWithStorage[127.0.0.1:42687,DS-e58bae57-3ce0-4b32-bfa3-5e1dc9115b79,DISK], DatanodeInfoWithStorage[127.0.0.1:41025,DS-a51725f7-e67f-4faf-9803-03ee0da42432,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1572774327-172.17.0.18-1597753412794:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45393,DS-781db4f0-97a9-414a-9172-792c4ca17273,DISK], DatanodeInfoWithStorage[127.0.0.1:32964,DS-462e8cce-4423-4693-9f1e-93d8154f5ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:46146,DS-9955ed93-464e-45e8-9ac2-0745b7602db8,DISK], DatanodeInfoWithStorage[127.0.0.1:43855,DS-a8ccad1e-f0d2-4e28-b408-308e1fbbb05d,DISK], DatanodeInfoWithStorage[127.0.0.1:34314,DS-d714251f-d7cd-439b-bf8c-7b3a28cfecea,DISK], DatanodeInfoWithStorage[127.0.0.1:34384,DS-1248cc1f-6012-489a-b629-e8847529ace2,DISK], DatanodeInfoWithStorage[127.0.0.1:42687,DS-e58bae57-3ce0-4b32-bfa3-5e1dc9115b79,DISK], DatanodeInfoWithStorage[127.0.0.1:41025,DS-a51725f7-e67f-4faf-9803-03ee0da42432,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-939401600-172.17.0.18-1597753882909:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35875,DS-c3c94f73-5b9d-4a93-a9e8-9832d97038a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46753,DS-a42b4e8b-2012-4e56-99cd-94edd67f5110,DISK], DatanodeInfoWithStorage[127.0.0.1:33858,DS-29a23779-87b0-4a05-90c1-87bcfd4335a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39512,DS-c67813f4-6599-41f7-a611-ae6b8dbba2cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42706,DS-ad21dc58-b087-44ba-b719-1e43b97499ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45764,DS-86276d50-a21b-40e6-aee8-246bbfb38ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:44759,DS-a33ef2aa-f5ff-4530-a52d-5287613bc624,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-117d1766-409d-4d94-8054-c05943da9872,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-939401600-172.17.0.18-1597753882909:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35875,DS-c3c94f73-5b9d-4a93-a9e8-9832d97038a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46753,DS-a42b4e8b-2012-4e56-99cd-94edd67f5110,DISK], DatanodeInfoWithStorage[127.0.0.1:33858,DS-29a23779-87b0-4a05-90c1-87bcfd4335a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39512,DS-c67813f4-6599-41f7-a611-ae6b8dbba2cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42706,DS-ad21dc58-b087-44ba-b719-1e43b97499ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45764,DS-86276d50-a21b-40e6-aee8-246bbfb38ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:44759,DS-a33ef2aa-f5ff-4530-a52d-5287613bc624,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-117d1766-409d-4d94-8054-c05943da9872,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1148016783-172.17.0.18-1597754026444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36245,DS-d9a8ecfe-20fa-48bd-a733-f5aecaf5c466,DISK], DatanodeInfoWithStorage[127.0.0.1:45494,DS-7321e81a-a4b6-44ec-ab35-5b54a1149d07,DISK], DatanodeInfoWithStorage[127.0.0.1:46273,DS-37b75af2-231d-4765-ac25-b2df8c2a8526,DISK], DatanodeInfoWithStorage[127.0.0.1:38929,DS-bfa50018-fd87-4265-a4ea-672068908948,DISK], DatanodeInfoWithStorage[127.0.0.1:43380,DS-ebd0bf11-3255-4d3c-9f51-e53063ed4bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:35152,DS-b5a3e4ec-065a-4748-af21-af9eb8f9909e,DISK], DatanodeInfoWithStorage[127.0.0.1:33982,DS-449cf5b5-f2fa-4ed3-9080-8837db0f96f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46761,DS-3c401488-4151-4b91-8f2f-92884d84218f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1148016783-172.17.0.18-1597754026444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36245,DS-d9a8ecfe-20fa-48bd-a733-f5aecaf5c466,DISK], DatanodeInfoWithStorage[127.0.0.1:45494,DS-7321e81a-a4b6-44ec-ab35-5b54a1149d07,DISK], DatanodeInfoWithStorage[127.0.0.1:46273,DS-37b75af2-231d-4765-ac25-b2df8c2a8526,DISK], DatanodeInfoWithStorage[127.0.0.1:38929,DS-bfa50018-fd87-4265-a4ea-672068908948,DISK], DatanodeInfoWithStorage[127.0.0.1:43380,DS-ebd0bf11-3255-4d3c-9f51-e53063ed4bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:35152,DS-b5a3e4ec-065a-4748-af21-af9eb8f9909e,DISK], DatanodeInfoWithStorage[127.0.0.1:33982,DS-449cf5b5-f2fa-4ed3-9080-8837db0f96f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46761,DS-3c401488-4151-4b91-8f2f-92884d84218f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1769610930-172.17.0.18-1597754325121:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46289,DS-fd3221f2-abac-42bd-bc52-546676730ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:43177,DS-a31fe567-dacc-435e-82ef-3cc0f51ead3b,DISK], DatanodeInfoWithStorage[127.0.0.1:34899,DS-b7967903-9316-45af-ab93-eedc6571b527,DISK], DatanodeInfoWithStorage[127.0.0.1:39258,DS-68d9b79c-bcd9-4acc-8541-e46e45835572,DISK], DatanodeInfoWithStorage[127.0.0.1:33209,DS-ba2b49ac-bd54-4446-931a-d12eddf13e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38964,DS-d1095f46-605e-4ffc-b6da-46acd262f71b,DISK], DatanodeInfoWithStorage[127.0.0.1:35827,DS-b02d7a6e-c9a9-41fc-bffe-484032efb777,DISK], DatanodeInfoWithStorage[127.0.0.1:44697,DS-ff16abca-da72-4864-add1-68dc4fa5afda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1769610930-172.17.0.18-1597754325121:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46289,DS-fd3221f2-abac-42bd-bc52-546676730ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:43177,DS-a31fe567-dacc-435e-82ef-3cc0f51ead3b,DISK], DatanodeInfoWithStorage[127.0.0.1:34899,DS-b7967903-9316-45af-ab93-eedc6571b527,DISK], DatanodeInfoWithStorage[127.0.0.1:39258,DS-68d9b79c-bcd9-4acc-8541-e46e45835572,DISK], DatanodeInfoWithStorage[127.0.0.1:33209,DS-ba2b49ac-bd54-4446-931a-d12eddf13e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38964,DS-d1095f46-605e-4ffc-b6da-46acd262f71b,DISK], DatanodeInfoWithStorage[127.0.0.1:35827,DS-b02d7a6e-c9a9-41fc-bffe-484032efb777,DISK], DatanodeInfoWithStorage[127.0.0.1:44697,DS-ff16abca-da72-4864-add1-68dc4fa5afda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5337
