reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1569057784-172.17.0.8-1597647700117:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37117,DS-cee03e2a-18b6-4dcb-b5b0-8f9c5d5273c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45159,DS-2b0b003c-8fe5-461b-b28e-4e66d970833f,DISK], DatanodeInfoWithStorage[127.0.0.1:40435,DS-6f0fe806-3b00-4fe7-bccd-9f75cada7d11,DISK], DatanodeInfoWithStorage[127.0.0.1:39936,DS-83e3cbf5-be39-4961-b7dd-61fe85518168,DISK], DatanodeInfoWithStorage[127.0.0.1:38104,DS-786f048b-375f-4a8f-8114-b5448fab5038,DISK], DatanodeInfoWithStorage[127.0.0.1:44418,DS-ed21fe8e-c812-45ef-9c28-eed3348db00e,DISK], DatanodeInfoWithStorage[127.0.0.1:45114,DS-49fb2779-df40-452b-a89b-8a2bf5cb5d32,DISK], DatanodeInfoWithStorage[127.0.0.1:34418,DS-5d8a816c-a60c-45e0-beb4-3d342237cf57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1569057784-172.17.0.8-1597647700117:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37117,DS-cee03e2a-18b6-4dcb-b5b0-8f9c5d5273c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45159,DS-2b0b003c-8fe5-461b-b28e-4e66d970833f,DISK], DatanodeInfoWithStorage[127.0.0.1:40435,DS-6f0fe806-3b00-4fe7-bccd-9f75cada7d11,DISK], DatanodeInfoWithStorage[127.0.0.1:39936,DS-83e3cbf5-be39-4961-b7dd-61fe85518168,DISK], DatanodeInfoWithStorage[127.0.0.1:38104,DS-786f048b-375f-4a8f-8114-b5448fab5038,DISK], DatanodeInfoWithStorage[127.0.0.1:44418,DS-ed21fe8e-c812-45ef-9c28-eed3348db00e,DISK], DatanodeInfoWithStorage[127.0.0.1:45114,DS-49fb2779-df40-452b-a89b-8a2bf5cb5d32,DISK], DatanodeInfoWithStorage[127.0.0.1:34418,DS-5d8a816c-a60c-45e0-beb4-3d342237cf57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1101493855-172.17.0.8-1597647775964:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37627,DS-d7714266-222d-4537-9ebb-26fc603f0a48,DISK], DatanodeInfoWithStorage[127.0.0.1:43031,DS-145c4851-5f88-4d89-b086-80169bd6b247,DISK], DatanodeInfoWithStorage[127.0.0.1:33488,DS-666551e1-00ea-4213-9ff7-045d7f5d211a,DISK], DatanodeInfoWithStorage[127.0.0.1:34242,DS-432cea98-0970-416b-82e1-e450551156d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46134,DS-6edcfa13-eac7-4357-923a-3ae88eaecfde,DISK], DatanodeInfoWithStorage[127.0.0.1:44703,DS-3c914c21-8553-454d-a7f1-80eb8e94088f,DISK], DatanodeInfoWithStorage[127.0.0.1:36119,DS-2706a928-3b65-4864-b424-22a3a1779623,DISK], DatanodeInfoWithStorage[127.0.0.1:38717,DS-14400a96-003c-41d1-8628-04093d007363,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1101493855-172.17.0.8-1597647775964:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37627,DS-d7714266-222d-4537-9ebb-26fc603f0a48,DISK], DatanodeInfoWithStorage[127.0.0.1:43031,DS-145c4851-5f88-4d89-b086-80169bd6b247,DISK], DatanodeInfoWithStorage[127.0.0.1:33488,DS-666551e1-00ea-4213-9ff7-045d7f5d211a,DISK], DatanodeInfoWithStorage[127.0.0.1:34242,DS-432cea98-0970-416b-82e1-e450551156d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46134,DS-6edcfa13-eac7-4357-923a-3ae88eaecfde,DISK], DatanodeInfoWithStorage[127.0.0.1:44703,DS-3c914c21-8553-454d-a7f1-80eb8e94088f,DISK], DatanodeInfoWithStorage[127.0.0.1:36119,DS-2706a928-3b65-4864-b424-22a3a1779623,DISK], DatanodeInfoWithStorage[127.0.0.1:38717,DS-14400a96-003c-41d1-8628-04093d007363,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-713890095-172.17.0.8-1597647885722:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36066,DS-df4279cb-5e79-48e8-b76d-4b02b26f12a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39878,DS-e474008f-ef41-48cf-be97-ae033441edae,DISK], DatanodeInfoWithStorage[127.0.0.1:42914,DS-ff36af60-8319-4c8c-a49a-0f243e2a8488,DISK], DatanodeInfoWithStorage[127.0.0.1:37130,DS-311c1564-9f07-4b5d-9974-8f93eebb593d,DISK], DatanodeInfoWithStorage[127.0.0.1:43965,DS-1d399fd7-9d17-4446-9fb1-de17082089f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36402,DS-7e5e1e2c-d314-48f3-8a53-c70a2baad39f,DISK], DatanodeInfoWithStorage[127.0.0.1:36830,DS-f8ed59c4-5a8d-42fd-ac1a-a0ff952500b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36539,DS-f03d41e3-f367-499f-8465-ce71019fef20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-713890095-172.17.0.8-1597647885722:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36066,DS-df4279cb-5e79-48e8-b76d-4b02b26f12a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39878,DS-e474008f-ef41-48cf-be97-ae033441edae,DISK], DatanodeInfoWithStorage[127.0.0.1:42914,DS-ff36af60-8319-4c8c-a49a-0f243e2a8488,DISK], DatanodeInfoWithStorage[127.0.0.1:37130,DS-311c1564-9f07-4b5d-9974-8f93eebb593d,DISK], DatanodeInfoWithStorage[127.0.0.1:43965,DS-1d399fd7-9d17-4446-9fb1-de17082089f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36402,DS-7e5e1e2c-d314-48f3-8a53-c70a2baad39f,DISK], DatanodeInfoWithStorage[127.0.0.1:36830,DS-f8ed59c4-5a8d-42fd-ac1a-a0ff952500b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36539,DS-f03d41e3-f367-499f-8465-ce71019fef20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1993232620-172.17.0.8-1597648456638:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35968,DS-660f85a5-6306-4d16-b4dd-56c3fad0573a,DISK], DatanodeInfoWithStorage[127.0.0.1:43766,DS-6b1e8d60-cbd9-452c-a8fc-8e5c86ebe912,DISK], DatanodeInfoWithStorage[127.0.0.1:44917,DS-78b86e39-2dd2-480f-b342-55c16048c78c,DISK], DatanodeInfoWithStorage[127.0.0.1:42566,DS-d9df13aa-bd8f-4eb9-a4ad-ea07865af02b,DISK], DatanodeInfoWithStorage[127.0.0.1:46839,DS-61bda2ca-3f08-4050-beb1-44653ced16f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45582,DS-7a88af8e-ac5e-459b-86c9-0fd7b771106c,DISK], DatanodeInfoWithStorage[127.0.0.1:46493,DS-1c972e1e-d082-4376-873a-b3d522ddee80,DISK], DatanodeInfoWithStorage[127.0.0.1:42661,DS-776a3839-8208-4ff4-a41f-3b5f5dcfc28d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1993232620-172.17.0.8-1597648456638:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35968,DS-660f85a5-6306-4d16-b4dd-56c3fad0573a,DISK], DatanodeInfoWithStorage[127.0.0.1:43766,DS-6b1e8d60-cbd9-452c-a8fc-8e5c86ebe912,DISK], DatanodeInfoWithStorage[127.0.0.1:44917,DS-78b86e39-2dd2-480f-b342-55c16048c78c,DISK], DatanodeInfoWithStorage[127.0.0.1:42566,DS-d9df13aa-bd8f-4eb9-a4ad-ea07865af02b,DISK], DatanodeInfoWithStorage[127.0.0.1:46839,DS-61bda2ca-3f08-4050-beb1-44653ced16f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45582,DS-7a88af8e-ac5e-459b-86c9-0fd7b771106c,DISK], DatanodeInfoWithStorage[127.0.0.1:46493,DS-1c972e1e-d082-4376-873a-b3d522ddee80,DISK], DatanodeInfoWithStorage[127.0.0.1:42661,DS-776a3839-8208-4ff4-a41f-3b5f5dcfc28d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2079624538-172.17.0.8-1597648683896:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40859,DS-7ab1f575-16ea-41e6-b57f-2d2243ea6a41,DISK], DatanodeInfoWithStorage[127.0.0.1:35076,DS-7f96c78d-4fc3-4af1-863b-02078e5f43ef,DISK], DatanodeInfoWithStorage[127.0.0.1:32867,DS-4b6431a4-2bf9-4044-b8e0-49c01f8dfb3b,DISK], DatanodeInfoWithStorage[127.0.0.1:44885,DS-3ade6d70-bafd-44a9-a806-b158a188f3d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45740,DS-33d1f4db-a7d8-442e-a599-5658fe9f9b39,DISK], DatanodeInfoWithStorage[127.0.0.1:44765,DS-f200881d-22aa-4d8f-b6f5-d05c1c614902,DISK], DatanodeInfoWithStorage[127.0.0.1:42052,DS-83d7d236-63e1-437f-8e9c-1d19c269e6da,DISK], DatanodeInfoWithStorage[127.0.0.1:42172,DS-16ee4693-34a0-4cb3-b53a-4c644b05b069,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2079624538-172.17.0.8-1597648683896:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40859,DS-7ab1f575-16ea-41e6-b57f-2d2243ea6a41,DISK], DatanodeInfoWithStorage[127.0.0.1:35076,DS-7f96c78d-4fc3-4af1-863b-02078e5f43ef,DISK], DatanodeInfoWithStorage[127.0.0.1:32867,DS-4b6431a4-2bf9-4044-b8e0-49c01f8dfb3b,DISK], DatanodeInfoWithStorage[127.0.0.1:44885,DS-3ade6d70-bafd-44a9-a806-b158a188f3d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45740,DS-33d1f4db-a7d8-442e-a599-5658fe9f9b39,DISK], DatanodeInfoWithStorage[127.0.0.1:44765,DS-f200881d-22aa-4d8f-b6f5-d05c1c614902,DISK], DatanodeInfoWithStorage[127.0.0.1:42052,DS-83d7d236-63e1-437f-8e9c-1d19c269e6da,DISK], DatanodeInfoWithStorage[127.0.0.1:42172,DS-16ee4693-34a0-4cb3-b53a-4c644b05b069,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-782903952-172.17.0.8-1597648831748:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33891,DS-00d8d0b8-b104-46f0-8424-e031bdddb1b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39163,DS-2a6827af-d605-4255-800a-2a2e3e9046eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45966,DS-838d207b-9850-407d-840c-b9a4d9f61497,DISK], DatanodeInfoWithStorage[127.0.0.1:38013,DS-66c62071-e397-41ff-821e-c759e9195bff,DISK], DatanodeInfoWithStorage[127.0.0.1:43437,DS-5420c172-887a-4075-9962-722bc17d4934,DISK], DatanodeInfoWithStorage[127.0.0.1:42122,DS-89cb7173-8bd7-416a-ad3e-2e7f4dd47954,DISK], DatanodeInfoWithStorage[127.0.0.1:41991,DS-72923141-6cc5-4763-aeb1-f5fbcf1f043e,DISK], DatanodeInfoWithStorage[127.0.0.1:43650,DS-1fabf8ec-8771-4685-a06d-d99dc1f85dfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-782903952-172.17.0.8-1597648831748:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33891,DS-00d8d0b8-b104-46f0-8424-e031bdddb1b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39163,DS-2a6827af-d605-4255-800a-2a2e3e9046eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45966,DS-838d207b-9850-407d-840c-b9a4d9f61497,DISK], DatanodeInfoWithStorage[127.0.0.1:38013,DS-66c62071-e397-41ff-821e-c759e9195bff,DISK], DatanodeInfoWithStorage[127.0.0.1:43437,DS-5420c172-887a-4075-9962-722bc17d4934,DISK], DatanodeInfoWithStorage[127.0.0.1:42122,DS-89cb7173-8bd7-416a-ad3e-2e7f4dd47954,DISK], DatanodeInfoWithStorage[127.0.0.1:41991,DS-72923141-6cc5-4763-aeb1-f5fbcf1f043e,DISK], DatanodeInfoWithStorage[127.0.0.1:43650,DS-1fabf8ec-8771-4685-a06d-d99dc1f85dfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1173708396-172.17.0.8-1597649160450:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32922,DS-e4a0af56-115e-426d-b9d7-7f89264163eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37462,DS-4b437374-aae4-4b9a-93ed-ab1b327c8bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:38809,DS-472a21d3-7b8b-4464-873f-cecf21395cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:33630,DS-93e6a77b-328e-4742-8a88-e72fd934733c,DISK], DatanodeInfoWithStorage[127.0.0.1:40846,DS-ba3f8220-286d-47cb-a7ac-32788d4969b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45503,DS-5b676686-9d3d-4275-9a74-947bd1b332b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33994,DS-20b4ab54-a2ad-49a8-9787-1574cad60986,DISK], DatanodeInfoWithStorage[127.0.0.1:40833,DS-f3fc6792-040a-4709-9fa9-d963f8f91694,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1173708396-172.17.0.8-1597649160450:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32922,DS-e4a0af56-115e-426d-b9d7-7f89264163eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37462,DS-4b437374-aae4-4b9a-93ed-ab1b327c8bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:38809,DS-472a21d3-7b8b-4464-873f-cecf21395cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:33630,DS-93e6a77b-328e-4742-8a88-e72fd934733c,DISK], DatanodeInfoWithStorage[127.0.0.1:40846,DS-ba3f8220-286d-47cb-a7ac-32788d4969b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45503,DS-5b676686-9d3d-4275-9a74-947bd1b332b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33994,DS-20b4ab54-a2ad-49a8-9787-1574cad60986,DISK], DatanodeInfoWithStorage[127.0.0.1:40833,DS-f3fc6792-040a-4709-9fa9-d963f8f91694,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-949437665-172.17.0.8-1597650218663:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33785,DS-bd041116-eabd-4637-9d03-f5112094ee98,DISK], DatanodeInfoWithStorage[127.0.0.1:36365,DS-a833d7d7-922e-429f-b15f-c4842d827f54,DISK], DatanodeInfoWithStorage[127.0.0.1:40877,DS-a507bb59-7021-405b-9caa-0db8d41e9ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:38128,DS-e00fe132-f66b-4507-ae88-af4cd33ebf54,DISK], DatanodeInfoWithStorage[127.0.0.1:38939,DS-ad6c57c7-edc5-4f9b-809f-aa87ebce5b20,DISK], DatanodeInfoWithStorage[127.0.0.1:34764,DS-124606e4-7f48-48a7-8a5d-6db1591f3394,DISK], DatanodeInfoWithStorage[127.0.0.1:35410,DS-c21de1a4-12a7-4db8-8f44-35c64fbd415c,DISK], DatanodeInfoWithStorage[127.0.0.1:46300,DS-8089a64d-ce66-4554-89f1-e12700c3a738,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-949437665-172.17.0.8-1597650218663:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33785,DS-bd041116-eabd-4637-9d03-f5112094ee98,DISK], DatanodeInfoWithStorage[127.0.0.1:36365,DS-a833d7d7-922e-429f-b15f-c4842d827f54,DISK], DatanodeInfoWithStorage[127.0.0.1:40877,DS-a507bb59-7021-405b-9caa-0db8d41e9ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:38128,DS-e00fe132-f66b-4507-ae88-af4cd33ebf54,DISK], DatanodeInfoWithStorage[127.0.0.1:38939,DS-ad6c57c7-edc5-4f9b-809f-aa87ebce5b20,DISK], DatanodeInfoWithStorage[127.0.0.1:34764,DS-124606e4-7f48-48a7-8a5d-6db1591f3394,DISK], DatanodeInfoWithStorage[127.0.0.1:35410,DS-c21de1a4-12a7-4db8-8f44-35c64fbd415c,DISK], DatanodeInfoWithStorage[127.0.0.1:46300,DS-8089a64d-ce66-4554-89f1-e12700c3a738,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-951149349-172.17.0.8-1597650835030:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36522,DS-5ae20e97-4bcf-4185-880f-54cfe88cc057,DISK], DatanodeInfoWithStorage[127.0.0.1:44341,DS-1cbfe24a-939b-4ff0-86c0-8399d9073c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:40260,DS-e5257500-7bcf-4290-89a3-e9f51502b3ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46144,DS-e98ec46e-4394-4498-95c0-8a42689d35e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46563,DS-d3090f05-42e8-46bc-aa62-d9c2b200310b,DISK], DatanodeInfoWithStorage[127.0.0.1:34131,DS-a842658c-ba0d-4580-b3ce-ad2d0b9bfde7,DISK], DatanodeInfoWithStorage[127.0.0.1:44865,DS-5c9b023c-9549-4bd6-ab21-720cc000ff1b,DISK], DatanodeInfoWithStorage[127.0.0.1:36463,DS-b5336d76-0d8e-4181-ac74-36d0c0a8f9aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-951149349-172.17.0.8-1597650835030:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36522,DS-5ae20e97-4bcf-4185-880f-54cfe88cc057,DISK], DatanodeInfoWithStorage[127.0.0.1:44341,DS-1cbfe24a-939b-4ff0-86c0-8399d9073c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:40260,DS-e5257500-7bcf-4290-89a3-e9f51502b3ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46144,DS-e98ec46e-4394-4498-95c0-8a42689d35e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46563,DS-d3090f05-42e8-46bc-aa62-d9c2b200310b,DISK], DatanodeInfoWithStorage[127.0.0.1:34131,DS-a842658c-ba0d-4580-b3ce-ad2d0b9bfde7,DISK], DatanodeInfoWithStorage[127.0.0.1:44865,DS-5c9b023c-9549-4bd6-ab21-720cc000ff1b,DISK], DatanodeInfoWithStorage[127.0.0.1:36463,DS-b5336d76-0d8e-4181-ac74-36d0c0a8f9aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-649487970-172.17.0.8-1597650901080:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34766,DS-3ccf2404-1880-4b8f-b3a2-b76e59bafe3a,DISK], DatanodeInfoWithStorage[127.0.0.1:45160,DS-aeb1864b-e0c4-423b-a104-7128cd38a128,DISK], DatanodeInfoWithStorage[127.0.0.1:36373,DS-98802e29-5e4b-4833-85aa-97d8887c5cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:40227,DS-02b90fa8-8908-4d44-8e66-0b48bfe83806,DISK], DatanodeInfoWithStorage[127.0.0.1:34286,DS-6e04c8f4-8d7b-47f7-abec-d5e1a13b648b,DISK], DatanodeInfoWithStorage[127.0.0.1:38276,DS-b4aa8c51-eb9f-429d-a24c-65335eac336b,DISK], DatanodeInfoWithStorage[127.0.0.1:33088,DS-5e471a23-28f6-4007-9b1b-8c0977c1213d,DISK], DatanodeInfoWithStorage[127.0.0.1:33351,DS-e17bc696-bc10-4f8d-9b73-476c2b9262a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-649487970-172.17.0.8-1597650901080:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34766,DS-3ccf2404-1880-4b8f-b3a2-b76e59bafe3a,DISK], DatanodeInfoWithStorage[127.0.0.1:45160,DS-aeb1864b-e0c4-423b-a104-7128cd38a128,DISK], DatanodeInfoWithStorage[127.0.0.1:36373,DS-98802e29-5e4b-4833-85aa-97d8887c5cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:40227,DS-02b90fa8-8908-4d44-8e66-0b48bfe83806,DISK], DatanodeInfoWithStorage[127.0.0.1:34286,DS-6e04c8f4-8d7b-47f7-abec-d5e1a13b648b,DISK], DatanodeInfoWithStorage[127.0.0.1:38276,DS-b4aa8c51-eb9f-429d-a24c-65335eac336b,DISK], DatanodeInfoWithStorage[127.0.0.1:33088,DS-5e471a23-28f6-4007-9b1b-8c0977c1213d,DISK], DatanodeInfoWithStorage[127.0.0.1:33351,DS-e17bc696-bc10-4f8d-9b73-476c2b9262a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1349611344-172.17.0.8-1597651169192:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46089,DS-1ee52a6d-288d-45c2-b324-569a38e9bb83,DISK], DatanodeInfoWithStorage[127.0.0.1:42315,DS-fb0177b6-971d-4540-b257-396eebb5d204,DISK], DatanodeInfoWithStorage[127.0.0.1:43593,DS-351613d2-d280-4fe6-a47e-b173b09a3812,DISK], DatanodeInfoWithStorage[127.0.0.1:43554,DS-d9f80b10-fcb4-4bab-a206-a499a00d7aac,DISK], DatanodeInfoWithStorage[127.0.0.1:39190,DS-dbca66fc-092f-4076-964e-1b83b89586c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34533,DS-f4de4a11-f021-40ba-8238-60abcb51031e,DISK], DatanodeInfoWithStorage[127.0.0.1:42524,DS-23c35778-25ac-45be-9117-812bce774712,DISK], DatanodeInfoWithStorage[127.0.0.1:37866,DS-b081daca-cc42-4b1d-acf5-b85f2df3a3de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1349611344-172.17.0.8-1597651169192:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46089,DS-1ee52a6d-288d-45c2-b324-569a38e9bb83,DISK], DatanodeInfoWithStorage[127.0.0.1:42315,DS-fb0177b6-971d-4540-b257-396eebb5d204,DISK], DatanodeInfoWithStorage[127.0.0.1:43593,DS-351613d2-d280-4fe6-a47e-b173b09a3812,DISK], DatanodeInfoWithStorage[127.0.0.1:43554,DS-d9f80b10-fcb4-4bab-a206-a499a00d7aac,DISK], DatanodeInfoWithStorage[127.0.0.1:39190,DS-dbca66fc-092f-4076-964e-1b83b89586c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34533,DS-f4de4a11-f021-40ba-8238-60abcb51031e,DISK], DatanodeInfoWithStorage[127.0.0.1:42524,DS-23c35778-25ac-45be-9117-812bce774712,DISK], DatanodeInfoWithStorage[127.0.0.1:37866,DS-b081daca-cc42-4b1d-acf5-b85f2df3a3de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1411862103-172.17.0.8-1597651573000:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43307,DS-210c4974-aa0a-4495-84e3-e59db97ca525,DISK], DatanodeInfoWithStorage[127.0.0.1:43421,DS-187f3d51-e1c9-4f07-b595-e5f3bf670097,DISK], DatanodeInfoWithStorage[127.0.0.1:43312,DS-85e07ae6-f47e-4571-85c7-4d2e6195aef7,DISK], DatanodeInfoWithStorage[127.0.0.1:37076,DS-eb14147e-8511-4db7-889f-5da7c1cbf773,DISK], DatanodeInfoWithStorage[127.0.0.1:34489,DS-cf32872e-8cec-4be9-a467-a0cdc43a7952,DISK], DatanodeInfoWithStorage[127.0.0.1:39631,DS-25370b3b-634a-40e8-94f3-2a2f39c4a7fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43501,DS-5747552b-3066-4478-abae-237007396c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-5e1b3e18-6d1e-46d0-8939-fc8053b4a033,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1411862103-172.17.0.8-1597651573000:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43307,DS-210c4974-aa0a-4495-84e3-e59db97ca525,DISK], DatanodeInfoWithStorage[127.0.0.1:43421,DS-187f3d51-e1c9-4f07-b595-e5f3bf670097,DISK], DatanodeInfoWithStorage[127.0.0.1:43312,DS-85e07ae6-f47e-4571-85c7-4d2e6195aef7,DISK], DatanodeInfoWithStorage[127.0.0.1:37076,DS-eb14147e-8511-4db7-889f-5da7c1cbf773,DISK], DatanodeInfoWithStorage[127.0.0.1:34489,DS-cf32872e-8cec-4be9-a467-a0cdc43a7952,DISK], DatanodeInfoWithStorage[127.0.0.1:39631,DS-25370b3b-634a-40e8-94f3-2a2f39c4a7fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43501,DS-5747552b-3066-4478-abae-237007396c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-5e1b3e18-6d1e-46d0-8939-fc8053b4a033,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-297240039-172.17.0.8-1597652115539:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39436,DS-894155c9-140a-4acb-bc5e-3f7cbf780f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43827,DS-60ffabbb-5a98-4990-a667-429fc47186c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44664,DS-e36a7f53-d16d-4a89-8abd-b1699548415d,DISK], DatanodeInfoWithStorage[127.0.0.1:43006,DS-b02a1cb0-6a6a-4f30-aded-dc4c0ecd48ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45999,DS-920150c3-43d2-414c-bcfa-fcc903a1e211,DISK], DatanodeInfoWithStorage[127.0.0.1:39652,DS-4f4b47c1-9d01-422e-9df4-a78fb8736aec,DISK], DatanodeInfoWithStorage[127.0.0.1:41168,DS-ce8daed7-9f77-481e-a257-6de6a34517d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34849,DS-8c97b217-c7ce-4fc0-8d82-933aa49d4c07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-297240039-172.17.0.8-1597652115539:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39436,DS-894155c9-140a-4acb-bc5e-3f7cbf780f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43827,DS-60ffabbb-5a98-4990-a667-429fc47186c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44664,DS-e36a7f53-d16d-4a89-8abd-b1699548415d,DISK], DatanodeInfoWithStorage[127.0.0.1:43006,DS-b02a1cb0-6a6a-4f30-aded-dc4c0ecd48ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45999,DS-920150c3-43d2-414c-bcfa-fcc903a1e211,DISK], DatanodeInfoWithStorage[127.0.0.1:39652,DS-4f4b47c1-9d01-422e-9df4-a78fb8736aec,DISK], DatanodeInfoWithStorage[127.0.0.1:41168,DS-ce8daed7-9f77-481e-a257-6de6a34517d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34849,DS-8c97b217-c7ce-4fc0-8d82-933aa49d4c07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-369331823-172.17.0.8-1597652765171:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36627,DS-f2ef326b-e28a-4a21-becf-e8a4e1a38ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:38388,DS-35e3acbb-e5af-4138-a0f0-07d188d1a7de,DISK], DatanodeInfoWithStorage[127.0.0.1:45157,DS-2fc23ded-8962-4a5a-a49f-b5bacacf07f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39540,DS-7d62a2db-c114-404a-ac7c-9c0d2158258f,DISK], DatanodeInfoWithStorage[127.0.0.1:37969,DS-717ebf32-3f2e-437c-b1c3-4c63d14073a4,DISK], DatanodeInfoWithStorage[127.0.0.1:46217,DS-0603e1a8-4f65-4f28-a36b-de00ca9d6fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:46149,DS-ac6ec679-5f97-44b8-9e7b-a2c73dfb3a09,DISK], DatanodeInfoWithStorage[127.0.0.1:35221,DS-af0f40de-c70b-4e79-bb63-052cc439cd1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-369331823-172.17.0.8-1597652765171:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36627,DS-f2ef326b-e28a-4a21-becf-e8a4e1a38ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:38388,DS-35e3acbb-e5af-4138-a0f0-07d188d1a7de,DISK], DatanodeInfoWithStorage[127.0.0.1:45157,DS-2fc23ded-8962-4a5a-a49f-b5bacacf07f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39540,DS-7d62a2db-c114-404a-ac7c-9c0d2158258f,DISK], DatanodeInfoWithStorage[127.0.0.1:37969,DS-717ebf32-3f2e-437c-b1c3-4c63d14073a4,DISK], DatanodeInfoWithStorage[127.0.0.1:46217,DS-0603e1a8-4f65-4f28-a36b-de00ca9d6fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:46149,DS-ac6ec679-5f97-44b8-9e7b-a2c73dfb3a09,DISK], DatanodeInfoWithStorage[127.0.0.1:35221,DS-af0f40de-c70b-4e79-bb63-052cc439cd1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5471
