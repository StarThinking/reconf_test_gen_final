reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-314371398-172.17.0.10-1597536206732:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39667,DS-7a10fb7c-111e-4b4c-bd6a-2c8d871ffef6,DISK], DatanodeInfoWithStorage[127.0.0.1:46437,DS-3a3fedcd-e099-4cab-bd56-3761153c1879,DISK], DatanodeInfoWithStorage[127.0.0.1:40528,DS-cbfae8fe-b75c-428c-b523-f086b71e9974,DISK], DatanodeInfoWithStorage[127.0.0.1:34045,DS-0c0ac716-2fdd-4294-8fc5-926b9602fe8c,DISK], DatanodeInfoWithStorage[127.0.0.1:42499,DS-d16c4259-447c-418b-8727-84a5b2ea6dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:39313,DS-50144c84-e21a-4739-9ec4-6691bccfef1f,DISK], DatanodeInfoWithStorage[127.0.0.1:38670,DS-88a77321-b468-423b-8340-05d34e31e9d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38379,DS-bab7c876-7570-45e2-8c81-b4e13703eacb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-314371398-172.17.0.10-1597536206732:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39667,DS-7a10fb7c-111e-4b4c-bd6a-2c8d871ffef6,DISK], DatanodeInfoWithStorage[127.0.0.1:46437,DS-3a3fedcd-e099-4cab-bd56-3761153c1879,DISK], DatanodeInfoWithStorage[127.0.0.1:40528,DS-cbfae8fe-b75c-428c-b523-f086b71e9974,DISK], DatanodeInfoWithStorage[127.0.0.1:34045,DS-0c0ac716-2fdd-4294-8fc5-926b9602fe8c,DISK], DatanodeInfoWithStorage[127.0.0.1:42499,DS-d16c4259-447c-418b-8727-84a5b2ea6dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:39313,DS-50144c84-e21a-4739-9ec4-6691bccfef1f,DISK], DatanodeInfoWithStorage[127.0.0.1:38670,DS-88a77321-b468-423b-8340-05d34e31e9d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38379,DS-bab7c876-7570-45e2-8c81-b4e13703eacb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-423805843-172.17.0.10-1597536319375:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34823,DS-962b07c2-b03f-4573-b959-1b63a2d9a3fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36231,DS-7037e0c2-38c4-4a38-a2a4-c4eeecb84933,DISK], DatanodeInfoWithStorage[127.0.0.1:40373,DS-3b83194d-1075-490c-a4b0-9c732b999642,DISK], DatanodeInfoWithStorage[127.0.0.1:44282,DS-5714266b-229d-48f0-94f7-b87da17f53b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39435,DS-1a5d0dad-db8e-4398-bb91-3d513472994d,DISK], DatanodeInfoWithStorage[127.0.0.1:33565,DS-420671d3-5f8f-4356-a7e1-152fa9415928,DISK], DatanodeInfoWithStorage[127.0.0.1:35763,DS-7bd942f1-299f-49ea-a621-1feb41bb3036,DISK], DatanodeInfoWithStorage[127.0.0.1:39257,DS-169a4dfd-e21e-4215-8eca-ba4b386823b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-423805843-172.17.0.10-1597536319375:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34823,DS-962b07c2-b03f-4573-b959-1b63a2d9a3fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36231,DS-7037e0c2-38c4-4a38-a2a4-c4eeecb84933,DISK], DatanodeInfoWithStorage[127.0.0.1:40373,DS-3b83194d-1075-490c-a4b0-9c732b999642,DISK], DatanodeInfoWithStorage[127.0.0.1:44282,DS-5714266b-229d-48f0-94f7-b87da17f53b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39435,DS-1a5d0dad-db8e-4398-bb91-3d513472994d,DISK], DatanodeInfoWithStorage[127.0.0.1:33565,DS-420671d3-5f8f-4356-a7e1-152fa9415928,DISK], DatanodeInfoWithStorage[127.0.0.1:35763,DS-7bd942f1-299f-49ea-a621-1feb41bb3036,DISK], DatanodeInfoWithStorage[127.0.0.1:39257,DS-169a4dfd-e21e-4215-8eca-ba4b386823b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-72108868-172.17.0.10-1597536692296:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46808,DS-f10a00aa-c5be-4668-a1f7-9e748bb04c89,DISK], DatanodeInfoWithStorage[127.0.0.1:46528,DS-a62d1ece-dd1a-4bbb-bcca-0cc3ef525f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42041,DS-f816a59b-1dd3-4bfe-a58b-fd0f8a560f28,DISK], DatanodeInfoWithStorage[127.0.0.1:38186,DS-9221d301-0f05-4202-af70-ad09b39d6559,DISK], DatanodeInfoWithStorage[127.0.0.1:38421,DS-6f781fba-4291-4ccc-8ff0-6576bdd14a93,DISK], DatanodeInfoWithStorage[127.0.0.1:34960,DS-c7a5c083-b37e-4cf0-b296-91b60c01e697,DISK], DatanodeInfoWithStorage[127.0.0.1:35663,DS-98245125-ccaf-4f75-bd12-08a8ed5f36ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43995,DS-8941665d-7a01-40cc-8d24-44d5e167fd54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-72108868-172.17.0.10-1597536692296:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46808,DS-f10a00aa-c5be-4668-a1f7-9e748bb04c89,DISK], DatanodeInfoWithStorage[127.0.0.1:46528,DS-a62d1ece-dd1a-4bbb-bcca-0cc3ef525f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42041,DS-f816a59b-1dd3-4bfe-a58b-fd0f8a560f28,DISK], DatanodeInfoWithStorage[127.0.0.1:38186,DS-9221d301-0f05-4202-af70-ad09b39d6559,DISK], DatanodeInfoWithStorage[127.0.0.1:38421,DS-6f781fba-4291-4ccc-8ff0-6576bdd14a93,DISK], DatanodeInfoWithStorage[127.0.0.1:34960,DS-c7a5c083-b37e-4cf0-b296-91b60c01e697,DISK], DatanodeInfoWithStorage[127.0.0.1:35663,DS-98245125-ccaf-4f75-bd12-08a8ed5f36ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43995,DS-8941665d-7a01-40cc-8d24-44d5e167fd54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-296413174-172.17.0.10-1597537500464:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42535,DS-c7306e5e-0bcb-49d5-bba5-9bcfb4f23729,DISK], DatanodeInfoWithStorage[127.0.0.1:40246,DS-1b1755c4-87b0-4af8-baa6-d274e4170e60,DISK], DatanodeInfoWithStorage[127.0.0.1:34524,DS-e02d47a6-aa69-4f17-877c-759fd664e6ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43980,DS-9dcac415-653a-417a-82af-2fe73a9d244e,DISK], DatanodeInfoWithStorage[127.0.0.1:38745,DS-7dc9367e-b96d-4bdd-8c0e-d67873cc8296,DISK], DatanodeInfoWithStorage[127.0.0.1:37119,DS-7e6213dc-0d5f-4a3d-a42a-c6c287f81a49,DISK], DatanodeInfoWithStorage[127.0.0.1:38968,DS-ba884913-aca2-4a19-817c-917a13a69a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38736,DS-2c49e5fb-47ca-46fd-aaf1-257fe1649902,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-296413174-172.17.0.10-1597537500464:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42535,DS-c7306e5e-0bcb-49d5-bba5-9bcfb4f23729,DISK], DatanodeInfoWithStorage[127.0.0.1:40246,DS-1b1755c4-87b0-4af8-baa6-d274e4170e60,DISK], DatanodeInfoWithStorage[127.0.0.1:34524,DS-e02d47a6-aa69-4f17-877c-759fd664e6ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43980,DS-9dcac415-653a-417a-82af-2fe73a9d244e,DISK], DatanodeInfoWithStorage[127.0.0.1:38745,DS-7dc9367e-b96d-4bdd-8c0e-d67873cc8296,DISK], DatanodeInfoWithStorage[127.0.0.1:37119,DS-7e6213dc-0d5f-4a3d-a42a-c6c287f81a49,DISK], DatanodeInfoWithStorage[127.0.0.1:38968,DS-ba884913-aca2-4a19-817c-917a13a69a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38736,DS-2c49e5fb-47ca-46fd-aaf1-257fe1649902,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-204481178-172.17.0.10-1597537762522:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36323,DS-ff52d3db-7c99-4d78-b9a9-83627c453250,DISK], DatanodeInfoWithStorage[127.0.0.1:44927,DS-c0ff79a0-4f05-4d29-aca3-eaa5b10f79fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39822,DS-8b20ff4a-39a9-47f2-a325-76016ca7c5bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41500,DS-8fa7aa85-75a4-44bc-9060-17bb2d950ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:40769,DS-97cc9bdf-fc71-4448-a184-ff9af810cf8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40247,DS-04b68357-a8a6-4280-8e53-275848b19ac0,DISK], DatanodeInfoWithStorage[127.0.0.1:42821,DS-143a7324-3cce-4036-8942-c7ad27821d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:45966,DS-2b133dde-3594-43ab-8a7b-8cc8c45beee7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-204481178-172.17.0.10-1597537762522:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36323,DS-ff52d3db-7c99-4d78-b9a9-83627c453250,DISK], DatanodeInfoWithStorage[127.0.0.1:44927,DS-c0ff79a0-4f05-4d29-aca3-eaa5b10f79fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39822,DS-8b20ff4a-39a9-47f2-a325-76016ca7c5bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41500,DS-8fa7aa85-75a4-44bc-9060-17bb2d950ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:40769,DS-97cc9bdf-fc71-4448-a184-ff9af810cf8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40247,DS-04b68357-a8a6-4280-8e53-275848b19ac0,DISK], DatanodeInfoWithStorage[127.0.0.1:42821,DS-143a7324-3cce-4036-8942-c7ad27821d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:45966,DS-2b133dde-3594-43ab-8a7b-8cc8c45beee7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1927301319-172.17.0.10-1597538061586:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39837,DS-d84dd9fe-2682-4f70-b902-2bc33982bf4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40328,DS-9fc1aefe-f48e-484b-b717-211700777ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:35288,DS-a98380fb-80bf-45b8-9c7e-4ff75db5142a,DISK], DatanodeInfoWithStorage[127.0.0.1:35779,DS-dbea6b76-e37b-40dd-9861-1029c3d93be0,DISK], DatanodeInfoWithStorage[127.0.0.1:45974,DS-c4d6dc5b-ab9c-4363-8954-5737beb49532,DISK], DatanodeInfoWithStorage[127.0.0.1:44334,DS-0954d8e7-d82e-41d4-930f-1f6f14c61dda,DISK], DatanodeInfoWithStorage[127.0.0.1:40496,DS-d5865b05-2988-4594-b18f-ae410978dbe7,DISK], DatanodeInfoWithStorage[127.0.0.1:39502,DS-5ed55bf3-865d-4d09-a43c-8b5c92fdf476,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1927301319-172.17.0.10-1597538061586:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39837,DS-d84dd9fe-2682-4f70-b902-2bc33982bf4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40328,DS-9fc1aefe-f48e-484b-b717-211700777ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:35288,DS-a98380fb-80bf-45b8-9c7e-4ff75db5142a,DISK], DatanodeInfoWithStorage[127.0.0.1:35779,DS-dbea6b76-e37b-40dd-9861-1029c3d93be0,DISK], DatanodeInfoWithStorage[127.0.0.1:45974,DS-c4d6dc5b-ab9c-4363-8954-5737beb49532,DISK], DatanodeInfoWithStorage[127.0.0.1:44334,DS-0954d8e7-d82e-41d4-930f-1f6f14c61dda,DISK], DatanodeInfoWithStorage[127.0.0.1:40496,DS-d5865b05-2988-4594-b18f-ae410978dbe7,DISK], DatanodeInfoWithStorage[127.0.0.1:39502,DS-5ed55bf3-865d-4d09-a43c-8b5c92fdf476,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-114915927-172.17.0.10-1597538884575:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42426,DS-8ee81ee9-a791-4755-9b04-37c3f7f324bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46852,DS-e49f7e57-d727-4b5d-add5-ca1fb00d034d,DISK], DatanodeInfoWithStorage[127.0.0.1:43586,DS-5c106ae6-af07-45bf-8222-29f397732e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:34593,DS-ce27c2c8-af7e-4f50-a74c-fccbc0bb06a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40402,DS-196b99f6-68b3-45ae-a8b6-2ac9c2d2e65b,DISK], DatanodeInfoWithStorage[127.0.0.1:45934,DS-2a73208a-b46b-4271-b24d-20631617f516,DISK], DatanodeInfoWithStorage[127.0.0.1:45545,DS-da5b16f9-53b6-42ef-b781-b966f522718d,DISK], DatanodeInfoWithStorage[127.0.0.1:35772,DS-dca4646b-c10d-43f7-b095-42f073bc0558,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-114915927-172.17.0.10-1597538884575:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42426,DS-8ee81ee9-a791-4755-9b04-37c3f7f324bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46852,DS-e49f7e57-d727-4b5d-add5-ca1fb00d034d,DISK], DatanodeInfoWithStorage[127.0.0.1:43586,DS-5c106ae6-af07-45bf-8222-29f397732e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:34593,DS-ce27c2c8-af7e-4f50-a74c-fccbc0bb06a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40402,DS-196b99f6-68b3-45ae-a8b6-2ac9c2d2e65b,DISK], DatanodeInfoWithStorage[127.0.0.1:45934,DS-2a73208a-b46b-4271-b24d-20631617f516,DISK], DatanodeInfoWithStorage[127.0.0.1:45545,DS-da5b16f9-53b6-42ef-b781-b966f522718d,DISK], DatanodeInfoWithStorage[127.0.0.1:35772,DS-dca4646b-c10d-43f7-b095-42f073bc0558,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-801592775-172.17.0.10-1597539455394:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41767,DS-8af2b3e4-3d0d-4ae1-a7b9-18f1be66abd2,DISK], DatanodeInfoWithStorage[127.0.0.1:38333,DS-d8ed4be0-8a93-4c05-b1ff-2b4587b6fb96,DISK], DatanodeInfoWithStorage[127.0.0.1:43494,DS-8042f1e5-5c21-447c-9774-b3adef8d3a28,DISK], DatanodeInfoWithStorage[127.0.0.1:43389,DS-8ab777ea-ffb6-4207-868b-6be0c8e023f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36105,DS-9425088f-0422-45ee-9bee-a2cfa7daf407,DISK], DatanodeInfoWithStorage[127.0.0.1:38484,DS-48a7ed60-1a36-4591-a75c-d661269f5841,DISK], DatanodeInfoWithStorage[127.0.0.1:32834,DS-2c92465e-4cb7-4e3f-a1d6-0cee351a500d,DISK], DatanodeInfoWithStorage[127.0.0.1:36714,DS-f2416278-2cd2-4c57-a7d4-e06835220243,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-801592775-172.17.0.10-1597539455394:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41767,DS-8af2b3e4-3d0d-4ae1-a7b9-18f1be66abd2,DISK], DatanodeInfoWithStorage[127.0.0.1:38333,DS-d8ed4be0-8a93-4c05-b1ff-2b4587b6fb96,DISK], DatanodeInfoWithStorage[127.0.0.1:43494,DS-8042f1e5-5c21-447c-9774-b3adef8d3a28,DISK], DatanodeInfoWithStorage[127.0.0.1:43389,DS-8ab777ea-ffb6-4207-868b-6be0c8e023f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36105,DS-9425088f-0422-45ee-9bee-a2cfa7daf407,DISK], DatanodeInfoWithStorage[127.0.0.1:38484,DS-48a7ed60-1a36-4591-a75c-d661269f5841,DISK], DatanodeInfoWithStorage[127.0.0.1:32834,DS-2c92465e-4cb7-4e3f-a1d6-0cee351a500d,DISK], DatanodeInfoWithStorage[127.0.0.1:36714,DS-f2416278-2cd2-4c57-a7d4-e06835220243,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1538487111-172.17.0.10-1597539754777:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44421,DS-608bb357-6346-4f4e-86ee-f4d007789e64,DISK], DatanodeInfoWithStorage[127.0.0.1:44330,DS-0945c47d-83c0-4d1b-a3d5-bcb63a5ea6aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46708,DS-8e82f043-729c-46d7-b974-3b12192013a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35966,DS-c5739b4b-2675-45e6-b6a6-36e9d633d10c,DISK], DatanodeInfoWithStorage[127.0.0.1:36828,DS-10d43746-96a9-4227-8d76-35e259fdc81c,DISK], DatanodeInfoWithStorage[127.0.0.1:42538,DS-53d6e2c3-06d6-4911-aa3a-5fddd73d2878,DISK], DatanodeInfoWithStorage[127.0.0.1:46532,DS-34f46be1-7d82-4b5f-97c6-8e62b4f1583b,DISK], DatanodeInfoWithStorage[127.0.0.1:42595,DS-e123a946-ab5f-481a-8cdb-c4f57dabf70d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1538487111-172.17.0.10-1597539754777:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44421,DS-608bb357-6346-4f4e-86ee-f4d007789e64,DISK], DatanodeInfoWithStorage[127.0.0.1:44330,DS-0945c47d-83c0-4d1b-a3d5-bcb63a5ea6aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46708,DS-8e82f043-729c-46d7-b974-3b12192013a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35966,DS-c5739b4b-2675-45e6-b6a6-36e9d633d10c,DISK], DatanodeInfoWithStorage[127.0.0.1:36828,DS-10d43746-96a9-4227-8d76-35e259fdc81c,DISK], DatanodeInfoWithStorage[127.0.0.1:42538,DS-53d6e2c3-06d6-4911-aa3a-5fddd73d2878,DISK], DatanodeInfoWithStorage[127.0.0.1:46532,DS-34f46be1-7d82-4b5f-97c6-8e62b4f1583b,DISK], DatanodeInfoWithStorage[127.0.0.1:42595,DS-e123a946-ab5f-481a-8cdb-c4f57dabf70d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-633000715-172.17.0.10-1597539928437:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41786,DS-f52e21db-8533-4a1c-9544-550d3570b97a,DISK], DatanodeInfoWithStorage[127.0.0.1:33584,DS-7620d730-15ee-45d4-ab05-bab62a13baef,DISK], DatanodeInfoWithStorage[127.0.0.1:40779,DS-3d3fbef7-e158-4bae-b5f0-f39b8bcb615e,DISK], DatanodeInfoWithStorage[127.0.0.1:38405,DS-34f04379-3371-4683-8654-07bd88b657ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36810,DS-6ebc8f0d-22a6-475c-9fc0-dca3343b8f70,DISK], DatanodeInfoWithStorage[127.0.0.1:43438,DS-58125e67-633b-441d-a7e0-2d097d5b6c05,DISK], DatanodeInfoWithStorage[127.0.0.1:33617,DS-81850893-a283-4a34-9efa-e7302f037398,DISK], DatanodeInfoWithStorage[127.0.0.1:38572,DS-ab9943ad-8574-413c-8591-39cedcb82889,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-633000715-172.17.0.10-1597539928437:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41786,DS-f52e21db-8533-4a1c-9544-550d3570b97a,DISK], DatanodeInfoWithStorage[127.0.0.1:33584,DS-7620d730-15ee-45d4-ab05-bab62a13baef,DISK], DatanodeInfoWithStorage[127.0.0.1:40779,DS-3d3fbef7-e158-4bae-b5f0-f39b8bcb615e,DISK], DatanodeInfoWithStorage[127.0.0.1:38405,DS-34f04379-3371-4683-8654-07bd88b657ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36810,DS-6ebc8f0d-22a6-475c-9fc0-dca3343b8f70,DISK], DatanodeInfoWithStorage[127.0.0.1:43438,DS-58125e67-633b-441d-a7e0-2d097d5b6c05,DISK], DatanodeInfoWithStorage[127.0.0.1:33617,DS-81850893-a283-4a34-9efa-e7302f037398,DISK], DatanodeInfoWithStorage[127.0.0.1:38572,DS-ab9943ad-8574-413c-8591-39cedcb82889,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2027288089-172.17.0.10-1597540156685:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38426,DS-9674ea90-23a1-4438-a139-0cc7d6ab5caf,DISK], DatanodeInfoWithStorage[127.0.0.1:35397,DS-432250e2-e741-4342-a6d3-31465c34cd18,DISK], DatanodeInfoWithStorage[127.0.0.1:43699,DS-9fc4173c-eb20-479f-a5fe-ff055da70073,DISK], DatanodeInfoWithStorage[127.0.0.1:40451,DS-23c41a61-b9b1-4633-b1f4-1c19da80641a,DISK], DatanodeInfoWithStorage[127.0.0.1:41105,DS-849ca373-bb6f-4225-82a8-28130492421f,DISK], DatanodeInfoWithStorage[127.0.0.1:37103,DS-7bd9db71-61ff-410c-ae6b-d43bb786ce7e,DISK], DatanodeInfoWithStorage[127.0.0.1:38418,DS-51b2d19a-c4d7-4524-8e86-a25e9f622298,DISK], DatanodeInfoWithStorage[127.0.0.1:41631,DS-65938de4-961b-49c7-9103-8c775c52f3de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2027288089-172.17.0.10-1597540156685:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38426,DS-9674ea90-23a1-4438-a139-0cc7d6ab5caf,DISK], DatanodeInfoWithStorage[127.0.0.1:35397,DS-432250e2-e741-4342-a6d3-31465c34cd18,DISK], DatanodeInfoWithStorage[127.0.0.1:43699,DS-9fc4173c-eb20-479f-a5fe-ff055da70073,DISK], DatanodeInfoWithStorage[127.0.0.1:40451,DS-23c41a61-b9b1-4633-b1f4-1c19da80641a,DISK], DatanodeInfoWithStorage[127.0.0.1:41105,DS-849ca373-bb6f-4225-82a8-28130492421f,DISK], DatanodeInfoWithStorage[127.0.0.1:37103,DS-7bd9db71-61ff-410c-ae6b-d43bb786ce7e,DISK], DatanodeInfoWithStorage[127.0.0.1:38418,DS-51b2d19a-c4d7-4524-8e86-a25e9f622298,DISK], DatanodeInfoWithStorage[127.0.0.1:41631,DS-65938de4-961b-49c7-9103-8c775c52f3de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1754262404-172.17.0.10-1597540522765:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46472,DS-dd0d071b-7423-497d-b229-56e1ced6c541,DISK], DatanodeInfoWithStorage[127.0.0.1:35426,DS-68706014-06df-4fdc-aa4b-6251ff89b35d,DISK], DatanodeInfoWithStorage[127.0.0.1:38969,DS-c29285c3-8a63-48f8-8f6a-63dc1e6d582f,DISK], DatanodeInfoWithStorage[127.0.0.1:39537,DS-cc09530d-20ed-4b4d-a00a-670a5a987867,DISK], DatanodeInfoWithStorage[127.0.0.1:43182,DS-8df76f1c-f349-4442-be9b-dc860f61774e,DISK], DatanodeInfoWithStorage[127.0.0.1:43464,DS-08892e71-551f-4173-91e8-dafe4107047f,DISK], DatanodeInfoWithStorage[127.0.0.1:46612,DS-1b99c5b9-eaf4-4259-bc9a-98ccf859e2cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35894,DS-cf35c471-f749-4a59-a5f8-d5740b6d8e30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1754262404-172.17.0.10-1597540522765:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46472,DS-dd0d071b-7423-497d-b229-56e1ced6c541,DISK], DatanodeInfoWithStorage[127.0.0.1:35426,DS-68706014-06df-4fdc-aa4b-6251ff89b35d,DISK], DatanodeInfoWithStorage[127.0.0.1:38969,DS-c29285c3-8a63-48f8-8f6a-63dc1e6d582f,DISK], DatanodeInfoWithStorage[127.0.0.1:39537,DS-cc09530d-20ed-4b4d-a00a-670a5a987867,DISK], DatanodeInfoWithStorage[127.0.0.1:43182,DS-8df76f1c-f349-4442-be9b-dc860f61774e,DISK], DatanodeInfoWithStorage[127.0.0.1:43464,DS-08892e71-551f-4173-91e8-dafe4107047f,DISK], DatanodeInfoWithStorage[127.0.0.1:46612,DS-1b99c5b9-eaf4-4259-bc9a-98ccf859e2cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35894,DS-cf35c471-f749-4a59-a5f8-d5740b6d8e30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-994616948-172.17.0.10-1597540628054:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42972,DS-b7bad54e-f457-4368-90d1-255007920236,DISK], DatanodeInfoWithStorage[127.0.0.1:46633,DS-552f6683-74c1-40cc-8212-035cac6e4797,DISK], DatanodeInfoWithStorage[127.0.0.1:33572,DS-d5fd880f-4112-4282-8eec-2cc43cf578c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42860,DS-0fb406cd-4b7d-4db0-bc80-f25325685d02,DISK], DatanodeInfoWithStorage[127.0.0.1:37252,DS-6aa969cb-4ecd-4b28-a1d6-bf3c28a84490,DISK], DatanodeInfoWithStorage[127.0.0.1:36549,DS-93cf17c4-aa7a-45f3-abcf-cc40afa2da80,DISK], DatanodeInfoWithStorage[127.0.0.1:41496,DS-209438ba-4f40-49a0-964c-ae3008201e82,DISK], DatanodeInfoWithStorage[127.0.0.1:35774,DS-26a55823-85a7-481e-96ec-a033b5b42489,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-994616948-172.17.0.10-1597540628054:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42972,DS-b7bad54e-f457-4368-90d1-255007920236,DISK], DatanodeInfoWithStorage[127.0.0.1:46633,DS-552f6683-74c1-40cc-8212-035cac6e4797,DISK], DatanodeInfoWithStorage[127.0.0.1:33572,DS-d5fd880f-4112-4282-8eec-2cc43cf578c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42860,DS-0fb406cd-4b7d-4db0-bc80-f25325685d02,DISK], DatanodeInfoWithStorage[127.0.0.1:37252,DS-6aa969cb-4ecd-4b28-a1d6-bf3c28a84490,DISK], DatanodeInfoWithStorage[127.0.0.1:36549,DS-93cf17c4-aa7a-45f3-abcf-cc40afa2da80,DISK], DatanodeInfoWithStorage[127.0.0.1:41496,DS-209438ba-4f40-49a0-964c-ae3008201e82,DISK], DatanodeInfoWithStorage[127.0.0.1:35774,DS-26a55823-85a7-481e-96ec-a033b5b42489,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-588995483-172.17.0.10-1597540959431:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39595,DS-d772132b-d54b-4dd1-8fd4-5a857abd8c41,DISK], DatanodeInfoWithStorage[127.0.0.1:37962,DS-31f3c450-8f0d-442d-8741-e7eb1ffedcc5,DISK], DatanodeInfoWithStorage[127.0.0.1:39465,DS-0a82a7b6-69bd-4b7a-82f1-dfbc29ab0acd,DISK], DatanodeInfoWithStorage[127.0.0.1:44388,DS-63f7dabb-6756-4cf6-9ff7-9527d5f50229,DISK], DatanodeInfoWithStorage[127.0.0.1:45412,DS-54a75cc5-8fee-4801-af35-72df93a15e49,DISK], DatanodeInfoWithStorage[127.0.0.1:43624,DS-bd46472b-39a3-4eec-bc81-ad8915add9b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33369,DS-ff5a874c-0799-4263-91d5-1452adc77fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:37843,DS-bb761cac-238d-4365-b9be-783fe3d3c3c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-588995483-172.17.0.10-1597540959431:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39595,DS-d772132b-d54b-4dd1-8fd4-5a857abd8c41,DISK], DatanodeInfoWithStorage[127.0.0.1:37962,DS-31f3c450-8f0d-442d-8741-e7eb1ffedcc5,DISK], DatanodeInfoWithStorage[127.0.0.1:39465,DS-0a82a7b6-69bd-4b7a-82f1-dfbc29ab0acd,DISK], DatanodeInfoWithStorage[127.0.0.1:44388,DS-63f7dabb-6756-4cf6-9ff7-9527d5f50229,DISK], DatanodeInfoWithStorage[127.0.0.1:45412,DS-54a75cc5-8fee-4801-af35-72df93a15e49,DISK], DatanodeInfoWithStorage[127.0.0.1:43624,DS-bd46472b-39a3-4eec-bc81-ad8915add9b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33369,DS-ff5a874c-0799-4263-91d5-1452adc77fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:37843,DS-bb761cac-238d-4365-b9be-783fe3d3c3c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-51200522-172.17.0.10-1597541421705:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35371,DS-f4cffac3-81f7-4bd2-8679-70d17678c5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34900,DS-b3ebf87f-cc1c-4c8e-b15c-bc993268a85b,DISK], DatanodeInfoWithStorage[127.0.0.1:43976,DS-5acb6ca3-3fd6-46cd-9a20-ffb6b45610f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36295,DS-fd311124-c96a-4a0c-961a-529a09cd6cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:44630,DS-85d31d15-8c22-432d-9155-5a2691f0d4ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36284,DS-649dc095-00fa-410f-9935-c3adc91569be,DISK], DatanodeInfoWithStorage[127.0.0.1:37276,DS-e2f32ee9-8c06-4c09-801f-bf4973d0542e,DISK], DatanodeInfoWithStorage[127.0.0.1:36699,DS-07910080-83d6-4230-b579-d54a07e3a92d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-51200522-172.17.0.10-1597541421705:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35371,DS-f4cffac3-81f7-4bd2-8679-70d17678c5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34900,DS-b3ebf87f-cc1c-4c8e-b15c-bc993268a85b,DISK], DatanodeInfoWithStorage[127.0.0.1:43976,DS-5acb6ca3-3fd6-46cd-9a20-ffb6b45610f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36295,DS-fd311124-c96a-4a0c-961a-529a09cd6cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:44630,DS-85d31d15-8c22-432d-9155-5a2691f0d4ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36284,DS-649dc095-00fa-410f-9935-c3adc91569be,DISK], DatanodeInfoWithStorage[127.0.0.1:37276,DS-e2f32ee9-8c06-4c09-801f-bf4973d0542e,DISK], DatanodeInfoWithStorage[127.0.0.1:36699,DS-07910080-83d6-4230-b579-d54a07e3a92d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5583
