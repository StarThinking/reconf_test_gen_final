reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-971943940-172.17.0.6-1597356656365:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36594,DS-23300e17-19ae-41ff-828e-d5a77d273ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:33870,DS-ee7ce1a9-b20f-405b-8e6e-3e4fbac0f81b,DISK], DatanodeInfoWithStorage[127.0.0.1:43854,DS-5a40575d-1372-43d8-b2b4-088a13c6a2ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35398,DS-60ad387b-e175-48d2-b9c4-59b80e73ff70,DISK], DatanodeInfoWithStorage[127.0.0.1:40704,DS-5979151a-b873-49b3-9310-9cae3f32954b,DISK], DatanodeInfoWithStorage[127.0.0.1:39020,DS-a232eec0-36e3-4784-a675-6fde40b4f52b,DISK], DatanodeInfoWithStorage[127.0.0.1:44115,DS-79602688-f186-4c8e-b795-fa3e59a2cb85,DISK], DatanodeInfoWithStorage[127.0.0.1:44870,DS-a1ee0515-4fa2-4be9-9ba9-0b8b969494be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-971943940-172.17.0.6-1597356656365:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36594,DS-23300e17-19ae-41ff-828e-d5a77d273ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:33870,DS-ee7ce1a9-b20f-405b-8e6e-3e4fbac0f81b,DISK], DatanodeInfoWithStorage[127.0.0.1:43854,DS-5a40575d-1372-43d8-b2b4-088a13c6a2ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35398,DS-60ad387b-e175-48d2-b9c4-59b80e73ff70,DISK], DatanodeInfoWithStorage[127.0.0.1:40704,DS-5979151a-b873-49b3-9310-9cae3f32954b,DISK], DatanodeInfoWithStorage[127.0.0.1:39020,DS-a232eec0-36e3-4784-a675-6fde40b4f52b,DISK], DatanodeInfoWithStorage[127.0.0.1:44115,DS-79602688-f186-4c8e-b795-fa3e59a2cb85,DISK], DatanodeInfoWithStorage[127.0.0.1:44870,DS-a1ee0515-4fa2-4be9-9ba9-0b8b969494be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1421549404-172.17.0.6-1597356685122:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45618,DS-b55373b9-542f-4959-bdde-13f4445818b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41649,DS-bf425ad5-93d9-4cc6-90e3-71f0d3e921b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46553,DS-c8ccb515-d068-477d-8cb7-bc1d4f54b182,DISK], DatanodeInfoWithStorage[127.0.0.1:35417,DS-e6469f40-5304-4dc1-9f84-e5211bbb7e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36679,DS-b1bf5e02-05df-42da-83f2-5c9cb0d72200,DISK], DatanodeInfoWithStorage[127.0.0.1:38906,DS-65395888-e149-4345-9e25-9e1aa0ce462f,DISK], DatanodeInfoWithStorage[127.0.0.1:40880,DS-5a7836ae-a28d-4635-bdd3-cd0bc25effd7,DISK], DatanodeInfoWithStorage[127.0.0.1:39650,DS-ef9a9a25-660e-48f6-b918-f1ba65771421,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1421549404-172.17.0.6-1597356685122:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45618,DS-b55373b9-542f-4959-bdde-13f4445818b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41649,DS-bf425ad5-93d9-4cc6-90e3-71f0d3e921b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46553,DS-c8ccb515-d068-477d-8cb7-bc1d4f54b182,DISK], DatanodeInfoWithStorage[127.0.0.1:35417,DS-e6469f40-5304-4dc1-9f84-e5211bbb7e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36679,DS-b1bf5e02-05df-42da-83f2-5c9cb0d72200,DISK], DatanodeInfoWithStorage[127.0.0.1:38906,DS-65395888-e149-4345-9e25-9e1aa0ce462f,DISK], DatanodeInfoWithStorage[127.0.0.1:40880,DS-5a7836ae-a28d-4635-bdd3-cd0bc25effd7,DISK], DatanodeInfoWithStorage[127.0.0.1:39650,DS-ef9a9a25-660e-48f6-b918-f1ba65771421,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-781307003-172.17.0.6-1597357249120:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41750,DS-a91c9714-a520-456d-8376-c12858a4ad6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43790,DS-02b898b2-5da7-496f-a126-9502c19b64a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42693,DS-4e361e83-3048-4dc0-bb62-72eaf21b6432,DISK], DatanodeInfoWithStorage[127.0.0.1:41713,DS-2d0b9164-6926-4795-8946-dc52e55769ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39458,DS-bc0aaa3a-436a-4f7b-b26c-5e136d7119e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44246,DS-b2ffbb8b-5b27-4829-bc32-520b74bf4624,DISK], DatanodeInfoWithStorage[127.0.0.1:35355,DS-f9533c91-a6d5-4692-a8cb-7626a43e2efd,DISK], DatanodeInfoWithStorage[127.0.0.1:33032,DS-fa5590d4-9768-486e-a27f-a3f1ffe78f02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-781307003-172.17.0.6-1597357249120:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41750,DS-a91c9714-a520-456d-8376-c12858a4ad6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43790,DS-02b898b2-5da7-496f-a126-9502c19b64a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42693,DS-4e361e83-3048-4dc0-bb62-72eaf21b6432,DISK], DatanodeInfoWithStorage[127.0.0.1:41713,DS-2d0b9164-6926-4795-8946-dc52e55769ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39458,DS-bc0aaa3a-436a-4f7b-b26c-5e136d7119e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44246,DS-b2ffbb8b-5b27-4829-bc32-520b74bf4624,DISK], DatanodeInfoWithStorage[127.0.0.1:35355,DS-f9533c91-a6d5-4692-a8cb-7626a43e2efd,DISK], DatanodeInfoWithStorage[127.0.0.1:33032,DS-fa5590d4-9768-486e-a27f-a3f1ffe78f02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-88148414-172.17.0.6-1597357428424:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46306,DS-3ba5c250-e232-4d7d-866d-c8be68aa8ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:35756,DS-4e2e115f-2b31-4ac5-94f3-622f6434dfb0,DISK], DatanodeInfoWithStorage[127.0.0.1:34450,DS-75fe290a-fd3a-406e-a780-173f154dbd0e,DISK], DatanodeInfoWithStorage[127.0.0.1:46750,DS-4848fed2-8c17-4da0-8361-f91a202e1a26,DISK], DatanodeInfoWithStorage[127.0.0.1:44021,DS-ff8ecc9c-7910-439f-a92b-f1bcd9666408,DISK], DatanodeInfoWithStorage[127.0.0.1:46005,DS-8c9d5381-e858-4902-8083-de040d911ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:36997,DS-bd43f08e-cd69-42c0-90de-ef8a2884ec27,DISK], DatanodeInfoWithStorage[127.0.0.1:35601,DS-e5d88980-2169-4362-a384-07acd9fcf727,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-88148414-172.17.0.6-1597357428424:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46306,DS-3ba5c250-e232-4d7d-866d-c8be68aa8ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:35756,DS-4e2e115f-2b31-4ac5-94f3-622f6434dfb0,DISK], DatanodeInfoWithStorage[127.0.0.1:34450,DS-75fe290a-fd3a-406e-a780-173f154dbd0e,DISK], DatanodeInfoWithStorage[127.0.0.1:46750,DS-4848fed2-8c17-4da0-8361-f91a202e1a26,DISK], DatanodeInfoWithStorage[127.0.0.1:44021,DS-ff8ecc9c-7910-439f-a92b-f1bcd9666408,DISK], DatanodeInfoWithStorage[127.0.0.1:46005,DS-8c9d5381-e858-4902-8083-de040d911ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:36997,DS-bd43f08e-cd69-42c0-90de-ef8a2884ec27,DISK], DatanodeInfoWithStorage[127.0.0.1:35601,DS-e5d88980-2169-4362-a384-07acd9fcf727,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-10976445-172.17.0.6-1597357620536:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40436,DS-4f245599-63bf-4249-a5e5-200ca6ebe7e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36939,DS-37e914ff-ca7b-48a6-a49f-f761a2da45e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44641,DS-d806dc81-19bc-4d25-9f03-a9533505d179,DISK], DatanodeInfoWithStorage[127.0.0.1:40794,DS-02355ce3-0079-44da-8413-b4583964ae68,DISK], DatanodeInfoWithStorage[127.0.0.1:42544,DS-2e03c647-aca8-40b5-94de-5aea67b76c92,DISK], DatanodeInfoWithStorage[127.0.0.1:45958,DS-7b995681-c218-43e9-bd0e-d71a36546d42,DISK], DatanodeInfoWithStorage[127.0.0.1:44843,DS-0ea88f1b-8fda-4eba-bd7b-f87c59f6e5ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38225,DS-6fa2dd03-438d-46fa-aa4d-6ca94e9347de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-10976445-172.17.0.6-1597357620536:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40436,DS-4f245599-63bf-4249-a5e5-200ca6ebe7e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36939,DS-37e914ff-ca7b-48a6-a49f-f761a2da45e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44641,DS-d806dc81-19bc-4d25-9f03-a9533505d179,DISK], DatanodeInfoWithStorage[127.0.0.1:40794,DS-02355ce3-0079-44da-8413-b4583964ae68,DISK], DatanodeInfoWithStorage[127.0.0.1:42544,DS-2e03c647-aca8-40b5-94de-5aea67b76c92,DISK], DatanodeInfoWithStorage[127.0.0.1:45958,DS-7b995681-c218-43e9-bd0e-d71a36546d42,DISK], DatanodeInfoWithStorage[127.0.0.1:44843,DS-0ea88f1b-8fda-4eba-bd7b-f87c59f6e5ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38225,DS-6fa2dd03-438d-46fa-aa4d-6ca94e9347de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2069882886-172.17.0.6-1597358036727:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41665,DS-780dd904-e90c-4d3c-913b-3e3fd1f9d9df,DISK], DatanodeInfoWithStorage[127.0.0.1:32895,DS-53cb61fc-62d3-496c-b505-11122b087a38,DISK], DatanodeInfoWithStorage[127.0.0.1:41503,DS-fc71323d-305f-4b4f-b772-d5113a2c190f,DISK], DatanodeInfoWithStorage[127.0.0.1:46506,DS-e300093e-95a0-47fe-8436-9dc0d8bb8a01,DISK], DatanodeInfoWithStorage[127.0.0.1:41075,DS-95e4aad8-5ff1-44b8-904e-70253f028e18,DISK], DatanodeInfoWithStorage[127.0.0.1:38638,DS-5e2f2bcf-a6c3-41a9-901a-ea772f84b121,DISK], DatanodeInfoWithStorage[127.0.0.1:41875,DS-7f14c115-3d1e-4214-93f7-180773387320,DISK], DatanodeInfoWithStorage[127.0.0.1:41336,DS-678b5c61-78fc-4c68-8b7b-934a53dce84f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2069882886-172.17.0.6-1597358036727:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41665,DS-780dd904-e90c-4d3c-913b-3e3fd1f9d9df,DISK], DatanodeInfoWithStorage[127.0.0.1:32895,DS-53cb61fc-62d3-496c-b505-11122b087a38,DISK], DatanodeInfoWithStorage[127.0.0.1:41503,DS-fc71323d-305f-4b4f-b772-d5113a2c190f,DISK], DatanodeInfoWithStorage[127.0.0.1:46506,DS-e300093e-95a0-47fe-8436-9dc0d8bb8a01,DISK], DatanodeInfoWithStorage[127.0.0.1:41075,DS-95e4aad8-5ff1-44b8-904e-70253f028e18,DISK], DatanodeInfoWithStorage[127.0.0.1:38638,DS-5e2f2bcf-a6c3-41a9-901a-ea772f84b121,DISK], DatanodeInfoWithStorage[127.0.0.1:41875,DS-7f14c115-3d1e-4214-93f7-180773387320,DISK], DatanodeInfoWithStorage[127.0.0.1:41336,DS-678b5c61-78fc-4c68-8b7b-934a53dce84f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1867103793-172.17.0.6-1597358372648:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43798,DS-441fe5d8-9b51-41ca-b9c7-3d58db9c9f46,DISK], DatanodeInfoWithStorage[127.0.0.1:43531,DS-dc2276ad-342b-4cbf-8e82-a2554b3b94fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35304,DS-0b1b56d5-8fdf-410a-a593-f1eb6556c3e7,DISK], DatanodeInfoWithStorage[127.0.0.1:32778,DS-b406d5c0-c2e9-4561-89c8-c871b6199628,DISK], DatanodeInfoWithStorage[127.0.0.1:39395,DS-e534a07b-1359-4756-94b5-1cd0db34827d,DISK], DatanodeInfoWithStorage[127.0.0.1:41027,DS-d63b04d4-aee1-43af-ba20-e479af04e6f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34190,DS-78490695-e0a9-4710-9a8d-a09c5df29604,DISK], DatanodeInfoWithStorage[127.0.0.1:37401,DS-4b7755f5-f410-4608-8fb1-16852a2e59fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1867103793-172.17.0.6-1597358372648:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43798,DS-441fe5d8-9b51-41ca-b9c7-3d58db9c9f46,DISK], DatanodeInfoWithStorage[127.0.0.1:43531,DS-dc2276ad-342b-4cbf-8e82-a2554b3b94fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35304,DS-0b1b56d5-8fdf-410a-a593-f1eb6556c3e7,DISK], DatanodeInfoWithStorage[127.0.0.1:32778,DS-b406d5c0-c2e9-4561-89c8-c871b6199628,DISK], DatanodeInfoWithStorage[127.0.0.1:39395,DS-e534a07b-1359-4756-94b5-1cd0db34827d,DISK], DatanodeInfoWithStorage[127.0.0.1:41027,DS-d63b04d4-aee1-43af-ba20-e479af04e6f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34190,DS-78490695-e0a9-4710-9a8d-a09c5df29604,DISK], DatanodeInfoWithStorage[127.0.0.1:37401,DS-4b7755f5-f410-4608-8fb1-16852a2e59fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-45031570-172.17.0.6-1597358446172:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36196,DS-bb2d0a0a-c238-45ce-aca0-33a4f741da64,DISK], DatanodeInfoWithStorage[127.0.0.1:39590,DS-099b9286-b401-4f5e-b26e-c78097f02627,DISK], DatanodeInfoWithStorage[127.0.0.1:45736,DS-219bdcf2-f5d3-4937-aa1c-26b6c8e1a2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44168,DS-f59724a9-9d4d-4fd4-aa08-5a3e07b2d53f,DISK], DatanodeInfoWithStorage[127.0.0.1:34048,DS-218ec66e-e17b-4829-9558-dec4f0404713,DISK], DatanodeInfoWithStorage[127.0.0.1:37186,DS-ff73dfd2-a2c1-45f6-a5d2-52dd0ea137ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34592,DS-59f8b6ae-225d-435a-93cf-a20e249fde7f,DISK], DatanodeInfoWithStorage[127.0.0.1:33305,DS-e1204aa5-f749-4e61-9ca6-c3b0650d8cdf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-45031570-172.17.0.6-1597358446172:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36196,DS-bb2d0a0a-c238-45ce-aca0-33a4f741da64,DISK], DatanodeInfoWithStorage[127.0.0.1:39590,DS-099b9286-b401-4f5e-b26e-c78097f02627,DISK], DatanodeInfoWithStorage[127.0.0.1:45736,DS-219bdcf2-f5d3-4937-aa1c-26b6c8e1a2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44168,DS-f59724a9-9d4d-4fd4-aa08-5a3e07b2d53f,DISK], DatanodeInfoWithStorage[127.0.0.1:34048,DS-218ec66e-e17b-4829-9558-dec4f0404713,DISK], DatanodeInfoWithStorage[127.0.0.1:37186,DS-ff73dfd2-a2c1-45f6-a5d2-52dd0ea137ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34592,DS-59f8b6ae-225d-435a-93cf-a20e249fde7f,DISK], DatanodeInfoWithStorage[127.0.0.1:33305,DS-e1204aa5-f749-4e61-9ca6-c3b0650d8cdf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-76603888-172.17.0.6-1597358557953:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39834,DS-7a864c57-5b72-47aa-81c6-215c16c9acf1,DISK], DatanodeInfoWithStorage[127.0.0.1:38433,DS-66f111f1-c6a5-4cae-b29e-0bd33e84dbb5,DISK], DatanodeInfoWithStorage[127.0.0.1:45783,DS-3fb195ea-ae0d-4cf1-9c8a-61e74bddb5a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46733,DS-b644647a-2032-44be-8ab9-d9bd50ffc9a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44770,DS-12f07f3b-db04-4f4b-8593-db8f82389f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:43899,DS-e944d75d-917e-43e9-95b9-18dd88a97aad,DISK], DatanodeInfoWithStorage[127.0.0.1:35947,DS-b7085af9-c64f-4610-8f33-2b139b36c3c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46243,DS-70cc460b-2598-476f-92d4-a578b446be23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-76603888-172.17.0.6-1597358557953:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39834,DS-7a864c57-5b72-47aa-81c6-215c16c9acf1,DISK], DatanodeInfoWithStorage[127.0.0.1:38433,DS-66f111f1-c6a5-4cae-b29e-0bd33e84dbb5,DISK], DatanodeInfoWithStorage[127.0.0.1:45783,DS-3fb195ea-ae0d-4cf1-9c8a-61e74bddb5a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46733,DS-b644647a-2032-44be-8ab9-d9bd50ffc9a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44770,DS-12f07f3b-db04-4f4b-8593-db8f82389f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:43899,DS-e944d75d-917e-43e9-95b9-18dd88a97aad,DISK], DatanodeInfoWithStorage[127.0.0.1:35947,DS-b7085af9-c64f-4610-8f33-2b139b36c3c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46243,DS-70cc460b-2598-476f-92d4-a578b446be23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1464238976-172.17.0.6-1597358654916:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35823,DS-af59847e-010d-4e9f-b268-e4addd2b6c55,DISK], DatanodeInfoWithStorage[127.0.0.1:44548,DS-b186a268-5caa-4bec-85d1-2c937333475b,DISK], DatanodeInfoWithStorage[127.0.0.1:37364,DS-19804a33-f5b9-4203-9776-5946d4e2b91d,DISK], DatanodeInfoWithStorage[127.0.0.1:37354,DS-5620e2c7-58cb-41cb-849e-d9e1f620bf2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37131,DS-6490fad1-5284-492f-a638-1b405f0c1602,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-135f5597-e217-4a45-be7c-4c05a7819dac,DISK], DatanodeInfoWithStorage[127.0.0.1:41085,DS-f318a9bc-9ed1-442e-bc32-1a4168d10cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:41823,DS-b5733466-ebe5-4449-9410-d1d10dc05c65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1464238976-172.17.0.6-1597358654916:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35823,DS-af59847e-010d-4e9f-b268-e4addd2b6c55,DISK], DatanodeInfoWithStorage[127.0.0.1:44548,DS-b186a268-5caa-4bec-85d1-2c937333475b,DISK], DatanodeInfoWithStorage[127.0.0.1:37364,DS-19804a33-f5b9-4203-9776-5946d4e2b91d,DISK], DatanodeInfoWithStorage[127.0.0.1:37354,DS-5620e2c7-58cb-41cb-849e-d9e1f620bf2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37131,DS-6490fad1-5284-492f-a638-1b405f0c1602,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-135f5597-e217-4a45-be7c-4c05a7819dac,DISK], DatanodeInfoWithStorage[127.0.0.1:41085,DS-f318a9bc-9ed1-442e-bc32-1a4168d10cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:41823,DS-b5733466-ebe5-4449-9410-d1d10dc05c65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1088095564-172.17.0.6-1597358834533:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40068,DS-c379730f-c6f2-4558-acf1-441033ef2f67,DISK], DatanodeInfoWithStorage[127.0.0.1:44799,DS-b895f8b7-63fd-4880-b3d1-a1cd01022865,DISK], DatanodeInfoWithStorage[127.0.0.1:38406,DS-f9d06a92-3e29-4c82-8aed-3d61daf48d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:37105,DS-19c751a8-8c5f-4f78-b55a-af45795b3446,DISK], DatanodeInfoWithStorage[127.0.0.1:34002,DS-bfc8e7f3-350e-4257-bc30-8c5acdf759f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42642,DS-6750bce4-e7df-49cd-9037-9a545b915fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:45645,DS-15a57780-7363-473b-9120-4cc0886631bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38076,DS-82e026b4-df6c-47a0-8210-5abfee4c7a16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1088095564-172.17.0.6-1597358834533:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40068,DS-c379730f-c6f2-4558-acf1-441033ef2f67,DISK], DatanodeInfoWithStorage[127.0.0.1:44799,DS-b895f8b7-63fd-4880-b3d1-a1cd01022865,DISK], DatanodeInfoWithStorage[127.0.0.1:38406,DS-f9d06a92-3e29-4c82-8aed-3d61daf48d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:37105,DS-19c751a8-8c5f-4f78-b55a-af45795b3446,DISK], DatanodeInfoWithStorage[127.0.0.1:34002,DS-bfc8e7f3-350e-4257-bc30-8c5acdf759f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42642,DS-6750bce4-e7df-49cd-9037-9a545b915fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:45645,DS-15a57780-7363-473b-9120-4cc0886631bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38076,DS-82e026b4-df6c-47a0-8210-5abfee4c7a16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-611653700-172.17.0.6-1597358980083:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40712,DS-49da1f02-578e-4e95-88f9-b677752b6084,DISK], DatanodeInfoWithStorage[127.0.0.1:42246,DS-eca303a6-7af7-445e-864a-4b0d2f99df31,DISK], DatanodeInfoWithStorage[127.0.0.1:45328,DS-3c5eb509-c64f-44d9-b636-fbf1300060f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41622,DS-11353523-fecc-4000-ab66-3d8931c0cbb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42710,DS-b095b60c-ff77-4e83-a902-eb8d567f81c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43512,DS-4ced4ed1-9d5d-4ca8-b7d2-90ed3ed35755,DISK], DatanodeInfoWithStorage[127.0.0.1:43881,DS-b09ae879-f77d-4127-9287-1eb5340096f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37062,DS-f80f709f-2256-4d80-8d04-5c682b8743f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-611653700-172.17.0.6-1597358980083:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40712,DS-49da1f02-578e-4e95-88f9-b677752b6084,DISK], DatanodeInfoWithStorage[127.0.0.1:42246,DS-eca303a6-7af7-445e-864a-4b0d2f99df31,DISK], DatanodeInfoWithStorage[127.0.0.1:45328,DS-3c5eb509-c64f-44d9-b636-fbf1300060f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41622,DS-11353523-fecc-4000-ab66-3d8931c0cbb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42710,DS-b095b60c-ff77-4e83-a902-eb8d567f81c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43512,DS-4ced4ed1-9d5d-4ca8-b7d2-90ed3ed35755,DISK], DatanodeInfoWithStorage[127.0.0.1:43881,DS-b09ae879-f77d-4127-9287-1eb5340096f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37062,DS-f80f709f-2256-4d80-8d04-5c682b8743f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1329585938-172.17.0.6-1597359583662:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36663,DS-47b92d75-de0b-46eb-91f1-c695cd9d2d71,DISK], DatanodeInfoWithStorage[127.0.0.1:32959,DS-08c4a61f-4f5f-4a92-b510-c8f565d16982,DISK], DatanodeInfoWithStorage[127.0.0.1:44647,DS-53866994-43d9-4011-8697-f92776c52ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:41534,DS-65759a5b-e855-4688-a721-f3deb6188725,DISK], DatanodeInfoWithStorage[127.0.0.1:39443,DS-4f6965a1-f45a-40df-8481-268f47d19f94,DISK], DatanodeInfoWithStorage[127.0.0.1:33024,DS-33655e51-175f-4385-9703-32617b982814,DISK], DatanodeInfoWithStorage[127.0.0.1:46648,DS-dcc4e445-e86d-4cb7-90c9-a10f6c06d959,DISK], DatanodeInfoWithStorage[127.0.0.1:43004,DS-e59993c1-2d30-4919-9ec5-abe166ae8562,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1329585938-172.17.0.6-1597359583662:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36663,DS-47b92d75-de0b-46eb-91f1-c695cd9d2d71,DISK], DatanodeInfoWithStorage[127.0.0.1:32959,DS-08c4a61f-4f5f-4a92-b510-c8f565d16982,DISK], DatanodeInfoWithStorage[127.0.0.1:44647,DS-53866994-43d9-4011-8697-f92776c52ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:41534,DS-65759a5b-e855-4688-a721-f3deb6188725,DISK], DatanodeInfoWithStorage[127.0.0.1:39443,DS-4f6965a1-f45a-40df-8481-268f47d19f94,DISK], DatanodeInfoWithStorage[127.0.0.1:33024,DS-33655e51-175f-4385-9703-32617b982814,DISK], DatanodeInfoWithStorage[127.0.0.1:46648,DS-dcc4e445-e86d-4cb7-90c9-a10f6c06d959,DISK], DatanodeInfoWithStorage[127.0.0.1:43004,DS-e59993c1-2d30-4919-9ec5-abe166ae8562,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-720396620-172.17.0.6-1597360403478:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34561,DS-3561664e-88d7-49d2-92ae-1c1c83192ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:45451,DS-55d27f42-6b75-4829-ac3a-aa5e2f681661,DISK], DatanodeInfoWithStorage[127.0.0.1:46354,DS-1c7ccd73-ffbb-4a63-adf6-c3d49da25d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38051,DS-4aa4c34b-f4b0-4e82-9689-1dbe7f1881d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43912,DS-7a8b3a33-ebff-44a8-902a-ec7edcd4514c,DISK], DatanodeInfoWithStorage[127.0.0.1:32995,DS-ecf40293-ca0e-4a18-8158-fb77e5299a82,DISK], DatanodeInfoWithStorage[127.0.0.1:36836,DS-be082485-07d9-4f78-a25b-de689c43e23b,DISK], DatanodeInfoWithStorage[127.0.0.1:45188,DS-55a88954-1e9e-4203-af1d-5bf75fbf7af6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-720396620-172.17.0.6-1597360403478:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34561,DS-3561664e-88d7-49d2-92ae-1c1c83192ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:45451,DS-55d27f42-6b75-4829-ac3a-aa5e2f681661,DISK], DatanodeInfoWithStorage[127.0.0.1:46354,DS-1c7ccd73-ffbb-4a63-adf6-c3d49da25d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38051,DS-4aa4c34b-f4b0-4e82-9689-1dbe7f1881d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43912,DS-7a8b3a33-ebff-44a8-902a-ec7edcd4514c,DISK], DatanodeInfoWithStorage[127.0.0.1:32995,DS-ecf40293-ca0e-4a18-8158-fb77e5299a82,DISK], DatanodeInfoWithStorage[127.0.0.1:36836,DS-be082485-07d9-4f78-a25b-de689c43e23b,DISK], DatanodeInfoWithStorage[127.0.0.1:45188,DS-55a88954-1e9e-4203-af1d-5bf75fbf7af6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1397227574-172.17.0.6-1597361113610:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44838,DS-a4ecc2bf-a4ad-401b-8ce0-082d44d8c232,DISK], DatanodeInfoWithStorage[127.0.0.1:35115,DS-63701776-4b1b-40a6-9e0f-9971dd708a08,DISK], DatanodeInfoWithStorage[127.0.0.1:45848,DS-e33bc7dc-9c91-4407-9773-97e9c457c004,DISK], DatanodeInfoWithStorage[127.0.0.1:35655,DS-c5d499e9-8c4b-4ef4-afaf-480e62dc02f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45877,DS-0eb3b1fc-434d-4043-aac7-652b577f4937,DISK], DatanodeInfoWithStorage[127.0.0.1:43166,DS-b909c65a-8368-4eef-9626-9e5d27ad334a,DISK], DatanodeInfoWithStorage[127.0.0.1:32833,DS-d36c7498-a1c8-459b-ab5f-c10291b59894,DISK], DatanodeInfoWithStorage[127.0.0.1:40264,DS-0377d7de-f838-4dba-aead-cf20e46b8cd5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1397227574-172.17.0.6-1597361113610:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44838,DS-a4ecc2bf-a4ad-401b-8ce0-082d44d8c232,DISK], DatanodeInfoWithStorage[127.0.0.1:35115,DS-63701776-4b1b-40a6-9e0f-9971dd708a08,DISK], DatanodeInfoWithStorage[127.0.0.1:45848,DS-e33bc7dc-9c91-4407-9773-97e9c457c004,DISK], DatanodeInfoWithStorage[127.0.0.1:35655,DS-c5d499e9-8c4b-4ef4-afaf-480e62dc02f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45877,DS-0eb3b1fc-434d-4043-aac7-652b577f4937,DISK], DatanodeInfoWithStorage[127.0.0.1:43166,DS-b909c65a-8368-4eef-9626-9e5d27ad334a,DISK], DatanodeInfoWithStorage[127.0.0.1:32833,DS-d36c7498-a1c8-459b-ab5f-c10291b59894,DISK], DatanodeInfoWithStorage[127.0.0.1:40264,DS-0377d7de-f838-4dba-aead-cf20e46b8cd5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1316990290-172.17.0.6-1597361312290:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40141,DS-4290a5d2-7223-4cc9-b475-44d274614066,DISK], DatanodeInfoWithStorage[127.0.0.1:44604,DS-2de03ea2-2c78-417a-8389-c60f2cbb6023,DISK], DatanodeInfoWithStorage[127.0.0.1:42402,DS-9091ee77-52a0-467d-8fc6-d71fb66ddc39,DISK], DatanodeInfoWithStorage[127.0.0.1:41496,DS-9308f024-f8c7-494f-a7e1-9d1573a95a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:46236,DS-1046c267-c57a-4fd0-8c1a-f62d4670ab9e,DISK], DatanodeInfoWithStorage[127.0.0.1:37257,DS-5adedc33-b561-4208-b9a8-312b3a24d37d,DISK], DatanodeInfoWithStorage[127.0.0.1:42778,DS-69515919-d1e4-4956-9332-1d130d7a5aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:36795,DS-2215d62d-3800-4185-950c-2dc30c914aac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1316990290-172.17.0.6-1597361312290:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40141,DS-4290a5d2-7223-4cc9-b475-44d274614066,DISK], DatanodeInfoWithStorage[127.0.0.1:44604,DS-2de03ea2-2c78-417a-8389-c60f2cbb6023,DISK], DatanodeInfoWithStorage[127.0.0.1:42402,DS-9091ee77-52a0-467d-8fc6-d71fb66ddc39,DISK], DatanodeInfoWithStorage[127.0.0.1:41496,DS-9308f024-f8c7-494f-a7e1-9d1573a95a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:46236,DS-1046c267-c57a-4fd0-8c1a-f62d4670ab9e,DISK], DatanodeInfoWithStorage[127.0.0.1:37257,DS-5adedc33-b561-4208-b9a8-312b3a24d37d,DISK], DatanodeInfoWithStorage[127.0.0.1:42778,DS-69515919-d1e4-4956-9332-1d130d7a5aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:36795,DS-2215d62d-3800-4185-950c-2dc30c914aac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-164455605-172.17.0.6-1597361590878:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35763,DS-4ffbf717-a8b6-470d-984a-f5600472508a,DISK], DatanodeInfoWithStorage[127.0.0.1:40750,DS-53180f19-006e-4de1-a42f-0a0db91b45e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41618,DS-8b830c61-4136-40c8-af5d-f4f75307ec12,DISK], DatanodeInfoWithStorage[127.0.0.1:38865,DS-aa102d7b-f3a6-494e-b255-d6fbdd9da99d,DISK], DatanodeInfoWithStorage[127.0.0.1:36993,DS-55af784a-e8f2-45f9-b741-91c77a8f741d,DISK], DatanodeInfoWithStorage[127.0.0.1:34500,DS-5735e927-15e0-48c5-bc55-0aee0ce02d99,DISK], DatanodeInfoWithStorage[127.0.0.1:39707,DS-c714f935-5016-4372-a5fb-7475d497d1f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39342,DS-22b54263-7b56-42c3-b847-9d48029414b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-164455605-172.17.0.6-1597361590878:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35763,DS-4ffbf717-a8b6-470d-984a-f5600472508a,DISK], DatanodeInfoWithStorage[127.0.0.1:40750,DS-53180f19-006e-4de1-a42f-0a0db91b45e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41618,DS-8b830c61-4136-40c8-af5d-f4f75307ec12,DISK], DatanodeInfoWithStorage[127.0.0.1:38865,DS-aa102d7b-f3a6-494e-b255-d6fbdd9da99d,DISK], DatanodeInfoWithStorage[127.0.0.1:36993,DS-55af784a-e8f2-45f9-b741-91c77a8f741d,DISK], DatanodeInfoWithStorage[127.0.0.1:34500,DS-5735e927-15e0-48c5-bc55-0aee0ce02d99,DISK], DatanodeInfoWithStorage[127.0.0.1:39707,DS-c714f935-5016-4372-a5fb-7475d497d1f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39342,DS-22b54263-7b56-42c3-b847-9d48029414b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5335
