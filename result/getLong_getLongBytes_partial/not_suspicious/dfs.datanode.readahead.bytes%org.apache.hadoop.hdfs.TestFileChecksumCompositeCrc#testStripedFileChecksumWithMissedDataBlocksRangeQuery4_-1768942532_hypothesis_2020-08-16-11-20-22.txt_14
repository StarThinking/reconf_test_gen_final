reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-614776929-172.17.0.14-1597577526406:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34823,DS-db301aaa-7e73-49b9-ad14-32100b9b6303,DISK], DatanodeInfoWithStorage[127.0.0.1:45078,DS-6c901df6-c6e2-4653-9156-62818e0a971d,DISK], DatanodeInfoWithStorage[127.0.0.1:45322,DS-e32fb9a9-5407-4916-89c7-c9e13cb18e96,DISK], DatanodeInfoWithStorage[127.0.0.1:36097,DS-77d8f41f-e3ad-4fdc-bc4b-8d5ff27cbd32,DISK], DatanodeInfoWithStorage[127.0.0.1:39290,DS-c53f1490-e47a-42e9-8366-f05fb1a4b689,DISK], DatanodeInfoWithStorage[127.0.0.1:41841,DS-dc608979-ff94-479d-aca3-362886006017,DISK], DatanodeInfoWithStorage[127.0.0.1:46397,DS-72721793-bbb8-4d1a-85ac-44cd2e16cb12,DISK], DatanodeInfoWithStorage[127.0.0.1:41740,DS-e2553af1-d6b1-4bac-9068-eef527ebc431,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-614776929-172.17.0.14-1597577526406:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34823,DS-db301aaa-7e73-49b9-ad14-32100b9b6303,DISK], DatanodeInfoWithStorage[127.0.0.1:45078,DS-6c901df6-c6e2-4653-9156-62818e0a971d,DISK], DatanodeInfoWithStorage[127.0.0.1:45322,DS-e32fb9a9-5407-4916-89c7-c9e13cb18e96,DISK], DatanodeInfoWithStorage[127.0.0.1:36097,DS-77d8f41f-e3ad-4fdc-bc4b-8d5ff27cbd32,DISK], DatanodeInfoWithStorage[127.0.0.1:39290,DS-c53f1490-e47a-42e9-8366-f05fb1a4b689,DISK], DatanodeInfoWithStorage[127.0.0.1:41841,DS-dc608979-ff94-479d-aca3-362886006017,DISK], DatanodeInfoWithStorage[127.0.0.1:46397,DS-72721793-bbb8-4d1a-85ac-44cd2e16cb12,DISK], DatanodeInfoWithStorage[127.0.0.1:41740,DS-e2553af1-d6b1-4bac-9068-eef527ebc431,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1872413016-172.17.0.14-1597577957200:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34111,DS-7c0a4cff-8562-4705-88ac-49ea22589c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:38476,DS-ac05e291-fe9e-422f-b9a2-c35832669912,DISK], DatanodeInfoWithStorage[127.0.0.1:39211,DS-78f9c047-ec5c-4608-bfdc-1be509e5935e,DISK], DatanodeInfoWithStorage[127.0.0.1:43061,DS-f780ce46-4b08-4284-8f2f-d72a17ff43f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41228,DS-31355dfe-b0dd-481b-9e39-37107a9def2f,DISK], DatanodeInfoWithStorage[127.0.0.1:41568,DS-e8315e6f-ec2b-46f8-9e14-d6b69ef4391f,DISK], DatanodeInfoWithStorage[127.0.0.1:43909,DS-ef08cf1f-4479-4b09-bc7b-d5bf0b14dffd,DISK], DatanodeInfoWithStorage[127.0.0.1:45712,DS-e4643b65-f8d3-4462-8dca-d931ad9fa8c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1872413016-172.17.0.14-1597577957200:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34111,DS-7c0a4cff-8562-4705-88ac-49ea22589c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:38476,DS-ac05e291-fe9e-422f-b9a2-c35832669912,DISK], DatanodeInfoWithStorage[127.0.0.1:39211,DS-78f9c047-ec5c-4608-bfdc-1be509e5935e,DISK], DatanodeInfoWithStorage[127.0.0.1:43061,DS-f780ce46-4b08-4284-8f2f-d72a17ff43f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41228,DS-31355dfe-b0dd-481b-9e39-37107a9def2f,DISK], DatanodeInfoWithStorage[127.0.0.1:41568,DS-e8315e6f-ec2b-46f8-9e14-d6b69ef4391f,DISK], DatanodeInfoWithStorage[127.0.0.1:43909,DS-ef08cf1f-4479-4b09-bc7b-d5bf0b14dffd,DISK], DatanodeInfoWithStorage[127.0.0.1:45712,DS-e4643b65-f8d3-4462-8dca-d931ad9fa8c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-386634371-172.17.0.14-1597578241172:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36051,DS-ba7dfcb6-0b0b-45f2-b803-74f047f4d821,DISK], DatanodeInfoWithStorage[127.0.0.1:45546,DS-ac649198-3f1f-473a-a603-e69e166de6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37534,DS-76986927-7fe5-4407-8f2c-df0cbd43603b,DISK], DatanodeInfoWithStorage[127.0.0.1:37495,DS-f9b3f14c-6bec-45ab-9453-448c194d031b,DISK], DatanodeInfoWithStorage[127.0.0.1:39593,DS-c0b57cd6-02ab-49e5-8b65-14cae0743f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:41649,DS-72fc222a-4a7f-4943-853d-104b8f42f6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46275,DS-0e0bad9d-0b4b-459f-87c5-c4d4e3d1ac4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42074,DS-a7cdbbd9-0686-4e31-a1e2-2f5fd9f9ed80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-386634371-172.17.0.14-1597578241172:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36051,DS-ba7dfcb6-0b0b-45f2-b803-74f047f4d821,DISK], DatanodeInfoWithStorage[127.0.0.1:45546,DS-ac649198-3f1f-473a-a603-e69e166de6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37534,DS-76986927-7fe5-4407-8f2c-df0cbd43603b,DISK], DatanodeInfoWithStorage[127.0.0.1:37495,DS-f9b3f14c-6bec-45ab-9453-448c194d031b,DISK], DatanodeInfoWithStorage[127.0.0.1:39593,DS-c0b57cd6-02ab-49e5-8b65-14cae0743f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:41649,DS-72fc222a-4a7f-4943-853d-104b8f42f6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46275,DS-0e0bad9d-0b4b-459f-87c5-c4d4e3d1ac4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42074,DS-a7cdbbd9-0686-4e31-a1e2-2f5fd9f9ed80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-729170995-172.17.0.14-1597578604481:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45956,DS-8e8175c0-5cd8-4ee4-865c-65c04a761ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:41739,DS-4340e31c-ff22-41d3-8bc4-9c8af4a0eb27,DISK], DatanodeInfoWithStorage[127.0.0.1:39018,DS-d2efef1c-7767-4aca-b485-70f21c393f90,DISK], DatanodeInfoWithStorage[127.0.0.1:33554,DS-c6182951-a463-4102-bd37-d014d60842d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44579,DS-b3baa08c-96cf-4e41-b65e-72bc3455452a,DISK], DatanodeInfoWithStorage[127.0.0.1:38062,DS-90d70d31-577a-4a78-8615-f2dd88e03d58,DISK], DatanodeInfoWithStorage[127.0.0.1:38529,DS-87910d91-33a0-4668-a77f-0cd710740798,DISK], DatanodeInfoWithStorage[127.0.0.1:44511,DS-4e53257e-88a4-41cc-8832-ad5283614425,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-729170995-172.17.0.14-1597578604481:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45956,DS-8e8175c0-5cd8-4ee4-865c-65c04a761ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:41739,DS-4340e31c-ff22-41d3-8bc4-9c8af4a0eb27,DISK], DatanodeInfoWithStorage[127.0.0.1:39018,DS-d2efef1c-7767-4aca-b485-70f21c393f90,DISK], DatanodeInfoWithStorage[127.0.0.1:33554,DS-c6182951-a463-4102-bd37-d014d60842d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44579,DS-b3baa08c-96cf-4e41-b65e-72bc3455452a,DISK], DatanodeInfoWithStorage[127.0.0.1:38062,DS-90d70d31-577a-4a78-8615-f2dd88e03d58,DISK], DatanodeInfoWithStorage[127.0.0.1:38529,DS-87910d91-33a0-4668-a77f-0cd710740798,DISK], DatanodeInfoWithStorage[127.0.0.1:44511,DS-4e53257e-88a4-41cc-8832-ad5283614425,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1216140926-172.17.0.14-1597578806317:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41724,DS-f10c6034-8a9c-4324-956a-95ae0244d32c,DISK], DatanodeInfoWithStorage[127.0.0.1:38344,DS-12c4e4bb-deba-4ac5-94b1-ccbd3908df5c,DISK], DatanodeInfoWithStorage[127.0.0.1:44937,DS-dcab27b7-7726-412d-8231-399c7cb13784,DISK], DatanodeInfoWithStorage[127.0.0.1:34312,DS-4db8ac5d-1927-4cf6-aa54-91bc5ad8adf2,DISK], DatanodeInfoWithStorage[127.0.0.1:40323,DS-96e624f3-61df-4e61-a22f-5fdb13325665,DISK], DatanodeInfoWithStorage[127.0.0.1:46727,DS-4a84b952-ebfe-42b3-a645-5fe9a715194f,DISK], DatanodeInfoWithStorage[127.0.0.1:38479,DS-d5ca4628-4fef-40b5-86cb-ee5c1f118b53,DISK], DatanodeInfoWithStorage[127.0.0.1:41615,DS-70b39a81-8acc-4777-b3b4-3e1dc7735122,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1216140926-172.17.0.14-1597578806317:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41724,DS-f10c6034-8a9c-4324-956a-95ae0244d32c,DISK], DatanodeInfoWithStorage[127.0.0.1:38344,DS-12c4e4bb-deba-4ac5-94b1-ccbd3908df5c,DISK], DatanodeInfoWithStorage[127.0.0.1:44937,DS-dcab27b7-7726-412d-8231-399c7cb13784,DISK], DatanodeInfoWithStorage[127.0.0.1:34312,DS-4db8ac5d-1927-4cf6-aa54-91bc5ad8adf2,DISK], DatanodeInfoWithStorage[127.0.0.1:40323,DS-96e624f3-61df-4e61-a22f-5fdb13325665,DISK], DatanodeInfoWithStorage[127.0.0.1:46727,DS-4a84b952-ebfe-42b3-a645-5fe9a715194f,DISK], DatanodeInfoWithStorage[127.0.0.1:38479,DS-d5ca4628-4fef-40b5-86cb-ee5c1f118b53,DISK], DatanodeInfoWithStorage[127.0.0.1:41615,DS-70b39a81-8acc-4777-b3b4-3e1dc7735122,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-742288946-172.17.0.14-1597578849376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39800,DS-f934096e-3ace-4a81-8f4b-f2256f9999fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44066,DS-ae7329b7-799c-466e-956a-5850aa81257f,DISK], DatanodeInfoWithStorage[127.0.0.1:44942,DS-f11cb2f7-b793-4b02-9457-1d641460aea5,DISK], DatanodeInfoWithStorage[127.0.0.1:35826,DS-019fd86e-deeb-4ff3-bffc-4ac5084bf6fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44014,DS-4bb0d348-749d-43e8-a02e-5484c5ec9177,DISK], DatanodeInfoWithStorage[127.0.0.1:34575,DS-6b6c977a-96e6-48ee-8942-3d94bf92d629,DISK], DatanodeInfoWithStorage[127.0.0.1:42246,DS-143775b3-268f-4549-8965-27cc410d51ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45946,DS-7fd89ed1-0741-41ea-92c7-835cfcabdd81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-742288946-172.17.0.14-1597578849376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39800,DS-f934096e-3ace-4a81-8f4b-f2256f9999fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44066,DS-ae7329b7-799c-466e-956a-5850aa81257f,DISK], DatanodeInfoWithStorage[127.0.0.1:44942,DS-f11cb2f7-b793-4b02-9457-1d641460aea5,DISK], DatanodeInfoWithStorage[127.0.0.1:35826,DS-019fd86e-deeb-4ff3-bffc-4ac5084bf6fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44014,DS-4bb0d348-749d-43e8-a02e-5484c5ec9177,DISK], DatanodeInfoWithStorage[127.0.0.1:34575,DS-6b6c977a-96e6-48ee-8942-3d94bf92d629,DISK], DatanodeInfoWithStorage[127.0.0.1:42246,DS-143775b3-268f-4549-8965-27cc410d51ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45946,DS-7fd89ed1-0741-41ea-92c7-835cfcabdd81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1515630187-172.17.0.14-1597579001995:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36607,DS-83933b26-9f1c-4849-8ba1-76a0120765af,DISK], DatanodeInfoWithStorage[127.0.0.1:38218,DS-00aee8c0-fa8c-42be-8155-9335d5490381,DISK], DatanodeInfoWithStorage[127.0.0.1:34203,DS-b4001601-41e7-4674-84c7-a576a2166be1,DISK], DatanodeInfoWithStorage[127.0.0.1:33850,DS-7a403d93-d257-4858-a0e9-9cdb12ee01cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37863,DS-9a6c351b-092e-4c4f-8da1-564f9d03a320,DISK], DatanodeInfoWithStorage[127.0.0.1:46423,DS-a501de72-b865-47b4-bc44-d4ee438de834,DISK], DatanodeInfoWithStorage[127.0.0.1:37671,DS-95586113-64fb-44a8-9553-fa48fae6ffee,DISK], DatanodeInfoWithStorage[127.0.0.1:46015,DS-eac180f5-25c9-429d-905a-68f638f0b9bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1515630187-172.17.0.14-1597579001995:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36607,DS-83933b26-9f1c-4849-8ba1-76a0120765af,DISK], DatanodeInfoWithStorage[127.0.0.1:38218,DS-00aee8c0-fa8c-42be-8155-9335d5490381,DISK], DatanodeInfoWithStorage[127.0.0.1:34203,DS-b4001601-41e7-4674-84c7-a576a2166be1,DISK], DatanodeInfoWithStorage[127.0.0.1:33850,DS-7a403d93-d257-4858-a0e9-9cdb12ee01cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37863,DS-9a6c351b-092e-4c4f-8da1-564f9d03a320,DISK], DatanodeInfoWithStorage[127.0.0.1:46423,DS-a501de72-b865-47b4-bc44-d4ee438de834,DISK], DatanodeInfoWithStorage[127.0.0.1:37671,DS-95586113-64fb-44a8-9553-fa48fae6ffee,DISK], DatanodeInfoWithStorage[127.0.0.1:46015,DS-eac180f5-25c9-429d-905a-68f638f0b9bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1474464973-172.17.0.14-1597580009300:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44218,DS-1c225c9d-cf17-4bee-82e0-004e246cd5fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37276,DS-fbd91ff6-57b2-48bd-8877-f9908e43b313,DISK], DatanodeInfoWithStorage[127.0.0.1:46240,DS-2811d888-84c0-4904-9082-21b8cf0c119a,DISK], DatanodeInfoWithStorage[127.0.0.1:42053,DS-90d7747c-9071-4096-8311-c3366c5ca16f,DISK], DatanodeInfoWithStorage[127.0.0.1:35267,DS-0f567e02-cb24-460a-b57a-3a4abe96927a,DISK], DatanodeInfoWithStorage[127.0.0.1:35276,DS-8de8513b-fcc4-4423-af99-a39d8b604d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35262,DS-aad94752-478a-4f80-a57a-ca67afb65d39,DISK], DatanodeInfoWithStorage[127.0.0.1:45447,DS-b70443bf-515e-4a02-a1dc-a272e596a7a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1474464973-172.17.0.14-1597580009300:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44218,DS-1c225c9d-cf17-4bee-82e0-004e246cd5fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37276,DS-fbd91ff6-57b2-48bd-8877-f9908e43b313,DISK], DatanodeInfoWithStorage[127.0.0.1:46240,DS-2811d888-84c0-4904-9082-21b8cf0c119a,DISK], DatanodeInfoWithStorage[127.0.0.1:42053,DS-90d7747c-9071-4096-8311-c3366c5ca16f,DISK], DatanodeInfoWithStorage[127.0.0.1:35267,DS-0f567e02-cb24-460a-b57a-3a4abe96927a,DISK], DatanodeInfoWithStorage[127.0.0.1:35276,DS-8de8513b-fcc4-4423-af99-a39d8b604d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35262,DS-aad94752-478a-4f80-a57a-ca67afb65d39,DISK], DatanodeInfoWithStorage[127.0.0.1:45447,DS-b70443bf-515e-4a02-a1dc-a272e596a7a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-202514797-172.17.0.14-1597580092044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37740,DS-8a623bd8-8663-46a6-b7d6-88e81d66c1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38738,DS-1846b7ab-c324-4cb9-aa10-1cfea900bff6,DISK], DatanodeInfoWithStorage[127.0.0.1:44428,DS-bff98e67-dc6f-4143-a4c8-5c9f7bf9bc2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39692,DS-7797f675-e08a-45d0-8b63-61d35d6ad29c,DISK], DatanodeInfoWithStorage[127.0.0.1:46699,DS-edb01ff7-4011-4af5-8254-b7009e1c5c04,DISK], DatanodeInfoWithStorage[127.0.0.1:36595,DS-597c233d-6aaf-4b00-ab04-73ceb65f9a26,DISK], DatanodeInfoWithStorage[127.0.0.1:37241,DS-987bc1cf-63a7-4262-a1a5-1f3c2d9103ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33881,DS-6f0a3448-16af-4798-b9ef-7e413d4dff8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-202514797-172.17.0.14-1597580092044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37740,DS-8a623bd8-8663-46a6-b7d6-88e81d66c1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38738,DS-1846b7ab-c324-4cb9-aa10-1cfea900bff6,DISK], DatanodeInfoWithStorage[127.0.0.1:44428,DS-bff98e67-dc6f-4143-a4c8-5c9f7bf9bc2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39692,DS-7797f675-e08a-45d0-8b63-61d35d6ad29c,DISK], DatanodeInfoWithStorage[127.0.0.1:46699,DS-edb01ff7-4011-4af5-8254-b7009e1c5c04,DISK], DatanodeInfoWithStorage[127.0.0.1:36595,DS-597c233d-6aaf-4b00-ab04-73ceb65f9a26,DISK], DatanodeInfoWithStorage[127.0.0.1:37241,DS-987bc1cf-63a7-4262-a1a5-1f3c2d9103ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33881,DS-6f0a3448-16af-4798-b9ef-7e413d4dff8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-737998995-172.17.0.14-1597580361967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44225,DS-5db68b69-441f-4d95-a61b-84af78197699,DISK], DatanodeInfoWithStorage[127.0.0.1:44855,DS-20491e9e-b594-4663-a2ac-267a873e6a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:43686,DS-60e85f8e-1dbd-4df6-bd17-cb849a097a73,DISK], DatanodeInfoWithStorage[127.0.0.1:38091,DS-2f389a16-e299-4b2d-adb2-59f971733d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43722,DS-bbbd9d31-cdfa-47f6-9512-7c5498151a08,DISK], DatanodeInfoWithStorage[127.0.0.1:43182,DS-c5a25c92-70ac-489c-a666-046e615d8398,DISK], DatanodeInfoWithStorage[127.0.0.1:39053,DS-ff393c6e-b435-441d-92c8-c0b58da593ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44554,DS-e31952df-42b0-4c38-a17e-23a485693a32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-737998995-172.17.0.14-1597580361967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44225,DS-5db68b69-441f-4d95-a61b-84af78197699,DISK], DatanodeInfoWithStorage[127.0.0.1:44855,DS-20491e9e-b594-4663-a2ac-267a873e6a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:43686,DS-60e85f8e-1dbd-4df6-bd17-cb849a097a73,DISK], DatanodeInfoWithStorage[127.0.0.1:38091,DS-2f389a16-e299-4b2d-adb2-59f971733d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43722,DS-bbbd9d31-cdfa-47f6-9512-7c5498151a08,DISK], DatanodeInfoWithStorage[127.0.0.1:43182,DS-c5a25c92-70ac-489c-a666-046e615d8398,DISK], DatanodeInfoWithStorage[127.0.0.1:39053,DS-ff393c6e-b435-441d-92c8-c0b58da593ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44554,DS-e31952df-42b0-4c38-a17e-23a485693a32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-724183072-172.17.0.14-1597580413316:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40274,DS-bd1c78aa-e96f-451c-b6d8-abddf7e224c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35444,DS-3bc4b97d-f60d-40b9-825f-b3bdc30327dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35031,DS-6720adcf-d80b-4f21-ac08-dfc7e6158c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:38817,DS-525dd01a-8e1c-4315-b38d-1ea50ffb13a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41543,DS-44eddd6b-888e-4d47-a18d-afeffc504977,DISK], DatanodeInfoWithStorage[127.0.0.1:46370,DS-466cc82a-08ab-46d8-b7c4-e6c3fb05e456,DISK], DatanodeInfoWithStorage[127.0.0.1:41975,DS-4e2774a0-6047-4f45-b396-cf55fbac715b,DISK], DatanodeInfoWithStorage[127.0.0.1:44655,DS-7c673466-06a1-4c35-8075-498afe119c1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-724183072-172.17.0.14-1597580413316:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40274,DS-bd1c78aa-e96f-451c-b6d8-abddf7e224c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35444,DS-3bc4b97d-f60d-40b9-825f-b3bdc30327dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35031,DS-6720adcf-d80b-4f21-ac08-dfc7e6158c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:38817,DS-525dd01a-8e1c-4315-b38d-1ea50ffb13a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41543,DS-44eddd6b-888e-4d47-a18d-afeffc504977,DISK], DatanodeInfoWithStorage[127.0.0.1:46370,DS-466cc82a-08ab-46d8-b7c4-e6c3fb05e456,DISK], DatanodeInfoWithStorage[127.0.0.1:41975,DS-4e2774a0-6047-4f45-b396-cf55fbac715b,DISK], DatanodeInfoWithStorage[127.0.0.1:44655,DS-7c673466-06a1-4c35-8075-498afe119c1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1411950484-172.17.0.14-1597580447163:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43282,DS-1fbb6f20-f94b-4e72-970a-e03d672109da,DISK], DatanodeInfoWithStorage[127.0.0.1:36442,DS-e594625f-1240-4e38-aa04-4186b5e9c388,DISK], DatanodeInfoWithStorage[127.0.0.1:39936,DS-116a9f10-b5d3-4d27-ad9b-46f38a0b8c03,DISK], DatanodeInfoWithStorage[127.0.0.1:33903,DS-a09cc8c7-e8f9-4290-b356-58be62fd7b81,DISK], DatanodeInfoWithStorage[127.0.0.1:37195,DS-7291a8d3-19a6-4911-bd65-447476356f87,DISK], DatanodeInfoWithStorage[127.0.0.1:36511,DS-b8970557-8bfe-4240-9dce-f5a5d4e8e133,DISK], DatanodeInfoWithStorage[127.0.0.1:40692,DS-e40b42d1-286e-4504-aca4-99c1a095b29c,DISK], DatanodeInfoWithStorage[127.0.0.1:46778,DS-2fe0a05f-607e-40fe-b5bd-58f37930b79a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1411950484-172.17.0.14-1597580447163:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43282,DS-1fbb6f20-f94b-4e72-970a-e03d672109da,DISK], DatanodeInfoWithStorage[127.0.0.1:36442,DS-e594625f-1240-4e38-aa04-4186b5e9c388,DISK], DatanodeInfoWithStorage[127.0.0.1:39936,DS-116a9f10-b5d3-4d27-ad9b-46f38a0b8c03,DISK], DatanodeInfoWithStorage[127.0.0.1:33903,DS-a09cc8c7-e8f9-4290-b356-58be62fd7b81,DISK], DatanodeInfoWithStorage[127.0.0.1:37195,DS-7291a8d3-19a6-4911-bd65-447476356f87,DISK], DatanodeInfoWithStorage[127.0.0.1:36511,DS-b8970557-8bfe-4240-9dce-f5a5d4e8e133,DISK], DatanodeInfoWithStorage[127.0.0.1:40692,DS-e40b42d1-286e-4504-aca4-99c1a095b29c,DISK], DatanodeInfoWithStorage[127.0.0.1:46778,DS-2fe0a05f-607e-40fe-b5bd-58f37930b79a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-417127714-172.17.0.14-1597580913011:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41965,DS-2f4b0c13-3a5a-4e9d-a46c-4aa1874c8ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:40179,DS-7cabf00b-1fcb-4929-9d2a-d6d2bf93bb7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37762,DS-bab421b8-60f3-4c5b-916f-e1c35c87d71b,DISK], DatanodeInfoWithStorage[127.0.0.1:37522,DS-ffdaec6a-5aed-4c93-8588-e524011000ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41345,DS-10837889-097f-4812-a2b8-456011f57d33,DISK], DatanodeInfoWithStorage[127.0.0.1:37307,DS-38cf4fe8-864e-4e0b-8ea5-20acd4e67d19,DISK], DatanodeInfoWithStorage[127.0.0.1:39881,DS-2942adb1-ff32-4c0d-b9f1-c91f89a01d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:34887,DS-0e9c2c82-0d57-4868-a563-633b8911c637,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-417127714-172.17.0.14-1597580913011:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41965,DS-2f4b0c13-3a5a-4e9d-a46c-4aa1874c8ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:40179,DS-7cabf00b-1fcb-4929-9d2a-d6d2bf93bb7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37762,DS-bab421b8-60f3-4c5b-916f-e1c35c87d71b,DISK], DatanodeInfoWithStorage[127.0.0.1:37522,DS-ffdaec6a-5aed-4c93-8588-e524011000ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41345,DS-10837889-097f-4812-a2b8-456011f57d33,DISK], DatanodeInfoWithStorage[127.0.0.1:37307,DS-38cf4fe8-864e-4e0b-8ea5-20acd4e67d19,DISK], DatanodeInfoWithStorage[127.0.0.1:39881,DS-2942adb1-ff32-4c0d-b9f1-c91f89a01d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:34887,DS-0e9c2c82-0d57-4868-a563-633b8911c637,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 1 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 4101
