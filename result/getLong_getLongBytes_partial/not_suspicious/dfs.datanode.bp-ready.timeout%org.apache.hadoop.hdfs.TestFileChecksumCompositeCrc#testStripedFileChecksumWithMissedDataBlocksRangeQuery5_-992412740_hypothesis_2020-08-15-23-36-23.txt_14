reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-759281530-172.17.0.11-1597534600686:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44191,DS-bb3e0d32-2a40-44b9-838e-74048de3bb02,DISK], DatanodeInfoWithStorage[127.0.0.1:38549,DS-60c5210d-3e2e-4a75-b600-bae4d6522e91,DISK], DatanodeInfoWithStorage[127.0.0.1:43392,DS-95548683-57f2-491f-9846-74c88b6ac39a,DISK], DatanodeInfoWithStorage[127.0.0.1:44398,DS-931a4f9a-190e-406d-9e35-dbcce89e7f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:39525,DS-02a2ee08-5c50-4b02-8c90-0c67d680a5af,DISK], DatanodeInfoWithStorage[127.0.0.1:44772,DS-4be8c70f-02ca-4ceb-80c3-28e0ce28292e,DISK], DatanodeInfoWithStorage[127.0.0.1:41737,DS-81b595b3-22ff-4db3-bc84-ec7ecf3d477d,DISK], DatanodeInfoWithStorage[127.0.0.1:43639,DS-b32255d8-b2a7-41f4-8740-4a6e128d3f93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-759281530-172.17.0.11-1597534600686:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44191,DS-bb3e0d32-2a40-44b9-838e-74048de3bb02,DISK], DatanodeInfoWithStorage[127.0.0.1:38549,DS-60c5210d-3e2e-4a75-b600-bae4d6522e91,DISK], DatanodeInfoWithStorage[127.0.0.1:43392,DS-95548683-57f2-491f-9846-74c88b6ac39a,DISK], DatanodeInfoWithStorage[127.0.0.1:44398,DS-931a4f9a-190e-406d-9e35-dbcce89e7f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:39525,DS-02a2ee08-5c50-4b02-8c90-0c67d680a5af,DISK], DatanodeInfoWithStorage[127.0.0.1:44772,DS-4be8c70f-02ca-4ceb-80c3-28e0ce28292e,DISK], DatanodeInfoWithStorage[127.0.0.1:41737,DS-81b595b3-22ff-4db3-bc84-ec7ecf3d477d,DISK], DatanodeInfoWithStorage[127.0.0.1:43639,DS-b32255d8-b2a7-41f4-8740-4a6e128d3f93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-202807674-172.17.0.11-1597535006932:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40200,DS-428df293-b225-4128-a153-69715656a022,DISK], DatanodeInfoWithStorage[127.0.0.1:34526,DS-15048eea-229c-4d4a-bca8-5251a0b88e7c,DISK], DatanodeInfoWithStorage[127.0.0.1:44518,DS-97237a7e-4bbf-40a4-ab29-e36ba48893e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35201,DS-407aaa1f-7ffc-4d69-b960-0acb8ff52d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38962,DS-b9c282ec-8339-47d4-9194-bfae0fad3d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:37993,DS-0c5322c0-34ea-4f8c-9894-e02d898b9f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:42770,DS-505f3514-a1ec-4513-893a-7572300270e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38472,DS-214929db-1a20-433e-9a03-67c9e1e24e5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-202807674-172.17.0.11-1597535006932:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40200,DS-428df293-b225-4128-a153-69715656a022,DISK], DatanodeInfoWithStorage[127.0.0.1:34526,DS-15048eea-229c-4d4a-bca8-5251a0b88e7c,DISK], DatanodeInfoWithStorage[127.0.0.1:44518,DS-97237a7e-4bbf-40a4-ab29-e36ba48893e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35201,DS-407aaa1f-7ffc-4d69-b960-0acb8ff52d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38962,DS-b9c282ec-8339-47d4-9194-bfae0fad3d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:37993,DS-0c5322c0-34ea-4f8c-9894-e02d898b9f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:42770,DS-505f3514-a1ec-4513-893a-7572300270e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38472,DS-214929db-1a20-433e-9a03-67c9e1e24e5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1701570439-172.17.0.11-1597535078807:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42966,DS-d510959c-19f8-42f0-a938-94d8bc23434f,DISK], DatanodeInfoWithStorage[127.0.0.1:37366,DS-f23d78d2-9024-481a-9c1d-7c019a372f20,DISK], DatanodeInfoWithStorage[127.0.0.1:39327,DS-6f1ff2e6-ad2e-411a-8f35-672269d8cf0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42600,DS-8f1321b9-511a-40a7-90ca-e3fc18128da7,DISK], DatanodeInfoWithStorage[127.0.0.1:34485,DS-aaee1673-8c15-4bba-85c2-9483c63c44c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46722,DS-30871576-d554-43be-b218-791561fb49aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34493,DS-a5dffe22-ec68-44f5-bf9c-5837647612d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33125,DS-e1a5d4a3-c731-4ded-b09e-c2f28e429e0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1701570439-172.17.0.11-1597535078807:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42966,DS-d510959c-19f8-42f0-a938-94d8bc23434f,DISK], DatanodeInfoWithStorage[127.0.0.1:37366,DS-f23d78d2-9024-481a-9c1d-7c019a372f20,DISK], DatanodeInfoWithStorage[127.0.0.1:39327,DS-6f1ff2e6-ad2e-411a-8f35-672269d8cf0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42600,DS-8f1321b9-511a-40a7-90ca-e3fc18128da7,DISK], DatanodeInfoWithStorage[127.0.0.1:34485,DS-aaee1673-8c15-4bba-85c2-9483c63c44c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46722,DS-30871576-d554-43be-b218-791561fb49aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34493,DS-a5dffe22-ec68-44f5-bf9c-5837647612d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33125,DS-e1a5d4a3-c731-4ded-b09e-c2f28e429e0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2073755709-172.17.0.11-1597535383681:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43017,DS-b2c018a6-4ef2-481e-aed6-b4a650afc20a,DISK], DatanodeInfoWithStorage[127.0.0.1:33861,DS-aa1efc19-8337-4647-a5e9-c30566f0a452,DISK], DatanodeInfoWithStorage[127.0.0.1:40867,DS-3cb8c156-3a77-4de9-97a9-95494483c4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34114,DS-6adc66fd-c965-4f18-8ae2-05db103eea56,DISK], DatanodeInfoWithStorage[127.0.0.1:41539,DS-665970e7-fd44-4619-8c79-08b6ad346be8,DISK], DatanodeInfoWithStorage[127.0.0.1:44619,DS-2acbb9fd-851c-4e71-8b2e-8131f84d4e87,DISK], DatanodeInfoWithStorage[127.0.0.1:38651,DS-98e680f8-ef36-4ae2-b404-9b6c50051ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:41380,DS-a640d75f-ee9e-4dda-8ec2-111317b3ea77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2073755709-172.17.0.11-1597535383681:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43017,DS-b2c018a6-4ef2-481e-aed6-b4a650afc20a,DISK], DatanodeInfoWithStorage[127.0.0.1:33861,DS-aa1efc19-8337-4647-a5e9-c30566f0a452,DISK], DatanodeInfoWithStorage[127.0.0.1:40867,DS-3cb8c156-3a77-4de9-97a9-95494483c4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34114,DS-6adc66fd-c965-4f18-8ae2-05db103eea56,DISK], DatanodeInfoWithStorage[127.0.0.1:41539,DS-665970e7-fd44-4619-8c79-08b6ad346be8,DISK], DatanodeInfoWithStorage[127.0.0.1:44619,DS-2acbb9fd-851c-4e71-8b2e-8131f84d4e87,DISK], DatanodeInfoWithStorage[127.0.0.1:38651,DS-98e680f8-ef36-4ae2-b404-9b6c50051ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:41380,DS-a640d75f-ee9e-4dda-8ec2-111317b3ea77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1394764424-172.17.0.11-1597535997523:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42751,DS-9a94bb48-04ec-42ba-94c4-a038cd469dc1,DISK], DatanodeInfoWithStorage[127.0.0.1:38586,DS-1dffc4d5-1d89-434c-be18-6a1e3af22d30,DISK], DatanodeInfoWithStorage[127.0.0.1:42303,DS-658b818b-1345-44a3-90b6-328c5cd9fbec,DISK], DatanodeInfoWithStorage[127.0.0.1:40079,DS-ee97bdd5-a79b-4564-9c98-78363b90235d,DISK], DatanodeInfoWithStorage[127.0.0.1:46046,DS-8114cb70-0c50-4b5e-b4af-02ad4ac4ab3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37714,DS-dbab7d92-4225-4b34-af06-836311b34619,DISK], DatanodeInfoWithStorage[127.0.0.1:38805,DS-32a772fa-df34-4d41-9e61-472a2e95cd53,DISK], DatanodeInfoWithStorage[127.0.0.1:41073,DS-af7c46b8-d19a-4310-88e0-d0344e058a6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1394764424-172.17.0.11-1597535997523:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42751,DS-9a94bb48-04ec-42ba-94c4-a038cd469dc1,DISK], DatanodeInfoWithStorage[127.0.0.1:38586,DS-1dffc4d5-1d89-434c-be18-6a1e3af22d30,DISK], DatanodeInfoWithStorage[127.0.0.1:42303,DS-658b818b-1345-44a3-90b6-328c5cd9fbec,DISK], DatanodeInfoWithStorage[127.0.0.1:40079,DS-ee97bdd5-a79b-4564-9c98-78363b90235d,DISK], DatanodeInfoWithStorage[127.0.0.1:46046,DS-8114cb70-0c50-4b5e-b4af-02ad4ac4ab3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37714,DS-dbab7d92-4225-4b34-af06-836311b34619,DISK], DatanodeInfoWithStorage[127.0.0.1:38805,DS-32a772fa-df34-4d41-9e61-472a2e95cd53,DISK], DatanodeInfoWithStorage[127.0.0.1:41073,DS-af7c46b8-d19a-4310-88e0-d0344e058a6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2106408201-172.17.0.11-1597536310798:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43559,DS-1ca13693-cc98-4352-b790-f585971a70f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41590,DS-1227c514-8701-43f6-b535-f4198fdbccb5,DISK], DatanodeInfoWithStorage[127.0.0.1:36690,DS-1d3447d7-ccfc-4aff-bee0-352dfa338bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:39642,DS-99ee2f2f-fe78-40e4-b73f-1c295e6fd223,DISK], DatanodeInfoWithStorage[127.0.0.1:38137,DS-d3ce188a-3c7d-4067-a974-fd4d6495acdb,DISK], DatanodeInfoWithStorage[127.0.0.1:41214,DS-0d25c96c-b162-404b-af2d-e8cc15166ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:43089,DS-84112415-a926-40f9-836f-093b8865f6b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35766,DS-8d64d061-f053-4194-b8e1-84c14eebdcc4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2106408201-172.17.0.11-1597536310798:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43559,DS-1ca13693-cc98-4352-b790-f585971a70f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41590,DS-1227c514-8701-43f6-b535-f4198fdbccb5,DISK], DatanodeInfoWithStorage[127.0.0.1:36690,DS-1d3447d7-ccfc-4aff-bee0-352dfa338bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:39642,DS-99ee2f2f-fe78-40e4-b73f-1c295e6fd223,DISK], DatanodeInfoWithStorage[127.0.0.1:38137,DS-d3ce188a-3c7d-4067-a974-fd4d6495acdb,DISK], DatanodeInfoWithStorage[127.0.0.1:41214,DS-0d25c96c-b162-404b-af2d-e8cc15166ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:43089,DS-84112415-a926-40f9-836f-093b8865f6b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35766,DS-8d64d061-f053-4194-b8e1-84c14eebdcc4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-304424002-172.17.0.11-1597536458982:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32932,DS-032e28f4-f0b2-4bdf-b22a-b68a690aa0bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41377,DS-e40b2b64-4743-40c1-aff8-fef94f5dcfa4,DISK], DatanodeInfoWithStorage[127.0.0.1:43566,DS-3ce12149-5c32-470d-bcbf-7028fb8c2b42,DISK], DatanodeInfoWithStorage[127.0.0.1:42260,DS-4821130b-14a7-4c19-af6c-67890321d22d,DISK], DatanodeInfoWithStorage[127.0.0.1:37306,DS-c7e7c09f-03c8-4e8e-8d1f-9bedbeb1cb46,DISK], DatanodeInfoWithStorage[127.0.0.1:34018,DS-0f181214-219f-4c4d-a7a0-e08eaf409b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:39246,DS-21d18d5f-cc64-4c49-9da5-da4f13cb965a,DISK], DatanodeInfoWithStorage[127.0.0.1:44620,DS-249e05dc-4d87-464e-9e69-f10fbfb2f936,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-304424002-172.17.0.11-1597536458982:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32932,DS-032e28f4-f0b2-4bdf-b22a-b68a690aa0bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41377,DS-e40b2b64-4743-40c1-aff8-fef94f5dcfa4,DISK], DatanodeInfoWithStorage[127.0.0.1:43566,DS-3ce12149-5c32-470d-bcbf-7028fb8c2b42,DISK], DatanodeInfoWithStorage[127.0.0.1:42260,DS-4821130b-14a7-4c19-af6c-67890321d22d,DISK], DatanodeInfoWithStorage[127.0.0.1:37306,DS-c7e7c09f-03c8-4e8e-8d1f-9bedbeb1cb46,DISK], DatanodeInfoWithStorage[127.0.0.1:34018,DS-0f181214-219f-4c4d-a7a0-e08eaf409b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:39246,DS-21d18d5f-cc64-4c49-9da5-da4f13cb965a,DISK], DatanodeInfoWithStorage[127.0.0.1:44620,DS-249e05dc-4d87-464e-9e69-f10fbfb2f936,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-480002439-172.17.0.11-1597536498993:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40317,DS-94abbb1c-9194-4291-be85-1d4fbd234515,DISK], DatanodeInfoWithStorage[127.0.0.1:38424,DS-c4d9255f-16aa-447d-aaaf-95bcfa5eeca2,DISK], DatanodeInfoWithStorage[127.0.0.1:39442,DS-ab53fd5c-09e0-4d85-a217-906f548e63e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41435,DS-a1521ee7-b42a-4f8d-a068-416011629375,DISK], DatanodeInfoWithStorage[127.0.0.1:38185,DS-89a7084d-3f21-4e02-8b77-efd6553bdb6f,DISK], DatanodeInfoWithStorage[127.0.0.1:45348,DS-0b9a71f1-c26c-43e6-af94-80fea4a39800,DISK], DatanodeInfoWithStorage[127.0.0.1:36607,DS-09fc9771-5ff4-4a30-9012-63c683711320,DISK], DatanodeInfoWithStorage[127.0.0.1:42999,DS-fa376481-b5d4-4988-afb5-a51e819cbd69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-480002439-172.17.0.11-1597536498993:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40317,DS-94abbb1c-9194-4291-be85-1d4fbd234515,DISK], DatanodeInfoWithStorage[127.0.0.1:38424,DS-c4d9255f-16aa-447d-aaaf-95bcfa5eeca2,DISK], DatanodeInfoWithStorage[127.0.0.1:39442,DS-ab53fd5c-09e0-4d85-a217-906f548e63e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41435,DS-a1521ee7-b42a-4f8d-a068-416011629375,DISK], DatanodeInfoWithStorage[127.0.0.1:38185,DS-89a7084d-3f21-4e02-8b77-efd6553bdb6f,DISK], DatanodeInfoWithStorage[127.0.0.1:45348,DS-0b9a71f1-c26c-43e6-af94-80fea4a39800,DISK], DatanodeInfoWithStorage[127.0.0.1:36607,DS-09fc9771-5ff4-4a30-9012-63c683711320,DISK], DatanodeInfoWithStorage[127.0.0.1:42999,DS-fa376481-b5d4-4988-afb5-a51e819cbd69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1792004098-172.17.0.11-1597536535633:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43296,DS-86b79527-22ac-49f6-b24e-12175512b2c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38302,DS-7d5f5268-888c-4aa8-9232-f66c2aa98d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:41639,DS-4993ae60-8785-4b38-8cab-c77fe6910ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:44423,DS-71f786d3-ad0e-4e0e-90c0-c28768cee270,DISK], DatanodeInfoWithStorage[127.0.0.1:37078,DS-c205d1a2-2210-4a2d-b74f-d67580c827b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38397,DS-fddd8289-c7ac-4f0b-95d1-0248c75d25a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39610,DS-c278ea4d-cedd-4c8e-bc43-567cf5be171d,DISK], DatanodeInfoWithStorage[127.0.0.1:35382,DS-046fb0de-6cd4-43c7-9d99-d27ed4a3b938,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1792004098-172.17.0.11-1597536535633:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43296,DS-86b79527-22ac-49f6-b24e-12175512b2c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38302,DS-7d5f5268-888c-4aa8-9232-f66c2aa98d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:41639,DS-4993ae60-8785-4b38-8cab-c77fe6910ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:44423,DS-71f786d3-ad0e-4e0e-90c0-c28768cee270,DISK], DatanodeInfoWithStorage[127.0.0.1:37078,DS-c205d1a2-2210-4a2d-b74f-d67580c827b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38397,DS-fddd8289-c7ac-4f0b-95d1-0248c75d25a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39610,DS-c278ea4d-cedd-4c8e-bc43-567cf5be171d,DISK], DatanodeInfoWithStorage[127.0.0.1:35382,DS-046fb0de-6cd4-43c7-9d99-d27ed4a3b938,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-616702276-172.17.0.11-1597536609067:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45006,DS-8953c098-8b9e-41d0-8ef4-0546f8f19828,DISK], DatanodeInfoWithStorage[127.0.0.1:44087,DS-032e8bc3-e19b-4cd7-b751-954eabb6f106,DISK], DatanodeInfoWithStorage[127.0.0.1:45388,DS-cf10792a-dc07-46e2-93a9-9501eb8e61ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41382,DS-99d7eaa8-fbb1-407c-9897-a1358374f481,DISK], DatanodeInfoWithStorage[127.0.0.1:40106,DS-b158ca87-cdcf-4773-81fd-11ee1e3d4072,DISK], DatanodeInfoWithStorage[127.0.0.1:33824,DS-39d56e6c-e701-4b80-9b1e-96120670a3f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39924,DS-27602f22-c97b-4b94-8b7b-de1caf1187af,DISK], DatanodeInfoWithStorage[127.0.0.1:36782,DS-5d8c97b1-e7ac-49d5-897d-e77f1099b2b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-616702276-172.17.0.11-1597536609067:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45006,DS-8953c098-8b9e-41d0-8ef4-0546f8f19828,DISK], DatanodeInfoWithStorage[127.0.0.1:44087,DS-032e8bc3-e19b-4cd7-b751-954eabb6f106,DISK], DatanodeInfoWithStorage[127.0.0.1:45388,DS-cf10792a-dc07-46e2-93a9-9501eb8e61ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41382,DS-99d7eaa8-fbb1-407c-9897-a1358374f481,DISK], DatanodeInfoWithStorage[127.0.0.1:40106,DS-b158ca87-cdcf-4773-81fd-11ee1e3d4072,DISK], DatanodeInfoWithStorage[127.0.0.1:33824,DS-39d56e6c-e701-4b80-9b1e-96120670a3f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39924,DS-27602f22-c97b-4b94-8b7b-de1caf1187af,DISK], DatanodeInfoWithStorage[127.0.0.1:36782,DS-5d8c97b1-e7ac-49d5-897d-e77f1099b2b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1050503570-172.17.0.11-1597537033733:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36302,DS-c4ddf31e-9cd3-4a8c-8a18-3dc5bed2d732,DISK], DatanodeInfoWithStorage[127.0.0.1:33640,DS-4e76b61e-df8a-45e8-a090-faf7802b80d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35248,DS-0bc50de3-ab4b-4b5e-b610-b97ec6b3ac31,DISK], DatanodeInfoWithStorage[127.0.0.1:38343,DS-d87a41e0-ba6c-405f-81e5-76a1fbb2d7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33599,DS-cb46a799-1cec-4347-b2a3-c90032709fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:46365,DS-4d807751-45f3-484e-9d13-4ad792b8588e,DISK], DatanodeInfoWithStorage[127.0.0.1:34288,DS-8e3cbb72-8d64-45ed-beb2-9fdfabc43ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:46257,DS-61b4c23a-16df-49a4-aca0-e1a3cc2b9df3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1050503570-172.17.0.11-1597537033733:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36302,DS-c4ddf31e-9cd3-4a8c-8a18-3dc5bed2d732,DISK], DatanodeInfoWithStorage[127.0.0.1:33640,DS-4e76b61e-df8a-45e8-a090-faf7802b80d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35248,DS-0bc50de3-ab4b-4b5e-b610-b97ec6b3ac31,DISK], DatanodeInfoWithStorage[127.0.0.1:38343,DS-d87a41e0-ba6c-405f-81e5-76a1fbb2d7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33599,DS-cb46a799-1cec-4347-b2a3-c90032709fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:46365,DS-4d807751-45f3-484e-9d13-4ad792b8588e,DISK], DatanodeInfoWithStorage[127.0.0.1:34288,DS-8e3cbb72-8d64-45ed-beb2-9fdfabc43ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:46257,DS-61b4c23a-16df-49a4-aca0-e1a3cc2b9df3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-589450379-172.17.0.11-1597537144515:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33258,DS-a14298d9-11b1-417a-8f72-a128a65252ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45649,DS-b8fa01ff-f8e8-4463-91d4-1436bb25fb8b,DISK], DatanodeInfoWithStorage[127.0.0.1:38294,DS-a242269c-ab14-43ed-b444-2b96925e35df,DISK], DatanodeInfoWithStorage[127.0.0.1:32933,DS-259b8246-41c6-488f-a72d-60d6b758381a,DISK], DatanodeInfoWithStorage[127.0.0.1:34862,DS-7a214f9e-5471-4d16-90f6-00da5b0cc472,DISK], DatanodeInfoWithStorage[127.0.0.1:40884,DS-017482d4-6abd-4f66-a4ed-b8ed2d4ebfc1,DISK], DatanodeInfoWithStorage[127.0.0.1:44969,DS-da8db7b0-8436-47b9-9711-be6ae0f989cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34473,DS-2d5e0ba7-27da-4949-acf3-ca5d7dde8dc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-589450379-172.17.0.11-1597537144515:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33258,DS-a14298d9-11b1-417a-8f72-a128a65252ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45649,DS-b8fa01ff-f8e8-4463-91d4-1436bb25fb8b,DISK], DatanodeInfoWithStorage[127.0.0.1:38294,DS-a242269c-ab14-43ed-b444-2b96925e35df,DISK], DatanodeInfoWithStorage[127.0.0.1:32933,DS-259b8246-41c6-488f-a72d-60d6b758381a,DISK], DatanodeInfoWithStorage[127.0.0.1:34862,DS-7a214f9e-5471-4d16-90f6-00da5b0cc472,DISK], DatanodeInfoWithStorage[127.0.0.1:40884,DS-017482d4-6abd-4f66-a4ed-b8ed2d4ebfc1,DISK], DatanodeInfoWithStorage[127.0.0.1:44969,DS-da8db7b0-8436-47b9-9711-be6ae0f989cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34473,DS-2d5e0ba7-27da-4949-acf3-ca5d7dde8dc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1199001045-172.17.0.11-1597537334716:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42881,DS-752a5c11-c84d-4880-9c95-ccebb0975fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:33116,DS-b27ea4e8-d5a9-4e7e-8baa-c2d07554ab05,DISK], DatanodeInfoWithStorage[127.0.0.1:43990,DS-af568e83-468c-4459-9a24-1595cb048ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:46604,DS-dc7eea0c-a9b9-4d35-b927-1a080035c8a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46192,DS-c20b1fa4-f235-4598-9fa4-aa3fc0a9ad15,DISK], DatanodeInfoWithStorage[127.0.0.1:44399,DS-8bf8c190-a5dc-471d-9153-6b95e3643f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40941,DS-1e46471d-518c-463d-9d81-72724f047585,DISK], DatanodeInfoWithStorage[127.0.0.1:34693,DS-7f642648-88b6-4da2-80af-fb78097ebca1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1199001045-172.17.0.11-1597537334716:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42881,DS-752a5c11-c84d-4880-9c95-ccebb0975fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:33116,DS-b27ea4e8-d5a9-4e7e-8baa-c2d07554ab05,DISK], DatanodeInfoWithStorage[127.0.0.1:43990,DS-af568e83-468c-4459-9a24-1595cb048ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:46604,DS-dc7eea0c-a9b9-4d35-b927-1a080035c8a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46192,DS-c20b1fa4-f235-4598-9fa4-aa3fc0a9ad15,DISK], DatanodeInfoWithStorage[127.0.0.1:44399,DS-8bf8c190-a5dc-471d-9153-6b95e3643f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40941,DS-1e46471d-518c-463d-9d81-72724f047585,DISK], DatanodeInfoWithStorage[127.0.0.1:34693,DS-7f642648-88b6-4da2-80af-fb78097ebca1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-648231842-172.17.0.11-1597537456707:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44734,DS-215ca7f2-b53d-42cd-8fec-11be8d0fa7b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42295,DS-f01545dc-daf1-4a92-a53d-17f183e5faac,DISK], DatanodeInfoWithStorage[127.0.0.1:38968,DS-e85bf4c2-d678-47ff-9c67-48a7ef5aa006,DISK], DatanodeInfoWithStorage[127.0.0.1:37048,DS-28265d17-6b87-4f87-8858-71a513a66888,DISK], DatanodeInfoWithStorage[127.0.0.1:33825,DS-a373761b-864d-4d40-8a70-6657f46d7b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38937,DS-6ecaf8bc-dca7-431a-b023-947fe51da72a,DISK], DatanodeInfoWithStorage[127.0.0.1:45440,DS-13d6f83b-1c03-4c94-bfcd-53f915d24dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:38723,DS-4100b13f-2f93-4e18-a414-f41b4a3377cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-648231842-172.17.0.11-1597537456707:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44734,DS-215ca7f2-b53d-42cd-8fec-11be8d0fa7b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42295,DS-f01545dc-daf1-4a92-a53d-17f183e5faac,DISK], DatanodeInfoWithStorage[127.0.0.1:38968,DS-e85bf4c2-d678-47ff-9c67-48a7ef5aa006,DISK], DatanodeInfoWithStorage[127.0.0.1:37048,DS-28265d17-6b87-4f87-8858-71a513a66888,DISK], DatanodeInfoWithStorage[127.0.0.1:33825,DS-a373761b-864d-4d40-8a70-6657f46d7b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38937,DS-6ecaf8bc-dca7-431a-b023-947fe51da72a,DISK], DatanodeInfoWithStorage[127.0.0.1:45440,DS-13d6f83b-1c03-4c94-bfcd-53f915d24dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:38723,DS-4100b13f-2f93-4e18-a414-f41b4a3377cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1600935727-172.17.0.11-1597537496690:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34749,DS-8da3cc79-23c3-4607-bc8d-9f12f078bc34,DISK], DatanodeInfoWithStorage[127.0.0.1:38481,DS-9ee5940a-7857-47e1-8dec-3e13b39b1573,DISK], DatanodeInfoWithStorage[127.0.0.1:40262,DS-65896126-03b2-49f1-90bc-06c31d36f85f,DISK], DatanodeInfoWithStorage[127.0.0.1:42198,DS-db1a6783-b2cd-4753-ae15-a29ca187408c,DISK], DatanodeInfoWithStorage[127.0.0.1:44707,DS-72c2318a-f3d0-4096-89a3-88b21eba3152,DISK], DatanodeInfoWithStorage[127.0.0.1:40192,DS-88d0cf45-4a91-406f-aade-53549b9213ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35935,DS-6c2d0d03-eb9b-4b06-8cd5-c2f396e316d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35808,DS-7e0d2ba5-aa9b-41dc-af37-e5d42fec9aa7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1600935727-172.17.0.11-1597537496690:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34749,DS-8da3cc79-23c3-4607-bc8d-9f12f078bc34,DISK], DatanodeInfoWithStorage[127.0.0.1:38481,DS-9ee5940a-7857-47e1-8dec-3e13b39b1573,DISK], DatanodeInfoWithStorage[127.0.0.1:40262,DS-65896126-03b2-49f1-90bc-06c31d36f85f,DISK], DatanodeInfoWithStorage[127.0.0.1:42198,DS-db1a6783-b2cd-4753-ae15-a29ca187408c,DISK], DatanodeInfoWithStorage[127.0.0.1:44707,DS-72c2318a-f3d0-4096-89a3-88b21eba3152,DISK], DatanodeInfoWithStorage[127.0.0.1:40192,DS-88d0cf45-4a91-406f-aade-53549b9213ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35935,DS-6c2d0d03-eb9b-4b06-8cd5-c2f396e316d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35808,DS-7e0d2ba5-aa9b-41dc-af37-e5d42fec9aa7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-756787859-172.17.0.11-1597537978086:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40894,DS-5b2db6eb-9661-490e-ae68-30d7a44580bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33227,DS-73caa4e4-e97f-468b-bf28-37f75d8991a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41970,DS-1f33c574-6e3f-4640-8669-9560e14ce126,DISK], DatanodeInfoWithStorage[127.0.0.1:45491,DS-625cb625-b5b0-4c64-8177-a81497682d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36238,DS-0d9a095b-10e8-482e-8e86-32d33f540845,DISK], DatanodeInfoWithStorage[127.0.0.1:45026,DS-07ff8864-90fd-4664-bffa-78815ab537a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44861,DS-f5f27613-ba58-4437-b676-e7d104ddcaa0,DISK], DatanodeInfoWithStorage[127.0.0.1:37818,DS-5ea9cb10-aa25-41c8-8703-0c50b30663bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-756787859-172.17.0.11-1597537978086:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40894,DS-5b2db6eb-9661-490e-ae68-30d7a44580bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33227,DS-73caa4e4-e97f-468b-bf28-37f75d8991a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41970,DS-1f33c574-6e3f-4640-8669-9560e14ce126,DISK], DatanodeInfoWithStorage[127.0.0.1:45491,DS-625cb625-b5b0-4c64-8177-a81497682d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36238,DS-0d9a095b-10e8-482e-8e86-32d33f540845,DISK], DatanodeInfoWithStorage[127.0.0.1:45026,DS-07ff8864-90fd-4664-bffa-78815ab537a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44861,DS-f5f27613-ba58-4437-b676-e7d104ddcaa0,DISK], DatanodeInfoWithStorage[127.0.0.1:37818,DS-5ea9cb10-aa25-41c8-8703-0c50b30663bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1340670587-172.17.0.11-1597538327329:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46119,DS-a1ea51bc-b092-4073-8021-6834911e1015,DISK], DatanodeInfoWithStorage[127.0.0.1:45918,DS-658cd4b7-624c-4197-a1ac-8a13d4d170c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46397,DS-4dd874fa-a43e-4be7-9f4d-f3d3e8064ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:36235,DS-091e6264-e7d8-4418-977d-9f1c696c8021,DISK], DatanodeInfoWithStorage[127.0.0.1:36099,DS-f8cfd6f1-ac2e-47b5-88b1-8be3fdc63561,DISK], DatanodeInfoWithStorage[127.0.0.1:43554,DS-16693e69-ff02-4c42-8376-3567f1f33130,DISK], DatanodeInfoWithStorage[127.0.0.1:38863,DS-311feb73-242e-47df-ab8b-56386f0751cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35608,DS-5d3a7f8a-c070-4753-a453-b13967c1d216,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1340670587-172.17.0.11-1597538327329:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46119,DS-a1ea51bc-b092-4073-8021-6834911e1015,DISK], DatanodeInfoWithStorage[127.0.0.1:45918,DS-658cd4b7-624c-4197-a1ac-8a13d4d170c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46397,DS-4dd874fa-a43e-4be7-9f4d-f3d3e8064ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:36235,DS-091e6264-e7d8-4418-977d-9f1c696c8021,DISK], DatanodeInfoWithStorage[127.0.0.1:36099,DS-f8cfd6f1-ac2e-47b5-88b1-8be3fdc63561,DISK], DatanodeInfoWithStorage[127.0.0.1:43554,DS-16693e69-ff02-4c42-8376-3567f1f33130,DISK], DatanodeInfoWithStorage[127.0.0.1:38863,DS-311feb73-242e-47df-ab8b-56386f0751cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35608,DS-5d3a7f8a-c070-4753-a453-b13967c1d216,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1115719908-172.17.0.11-1597538737104:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43140,DS-92f93f65-880b-440f-bd34-8ca2ca8e3fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:45509,DS-701706f4-e225-4ec8-84c6-bbf1d7500da6,DISK], DatanodeInfoWithStorage[127.0.0.1:45338,DS-f378ce8e-d5ff-4e85-bde8-78f90f29596e,DISK], DatanodeInfoWithStorage[127.0.0.1:32953,DS-c46747a5-531a-4a1c-800d-99ecb8b3a60a,DISK], DatanodeInfoWithStorage[127.0.0.1:36007,DS-a3a0b04a-6b9d-43d2-a448-a1645dde3aad,DISK], DatanodeInfoWithStorage[127.0.0.1:40629,DS-dbfaab94-dec0-45ba-96db-711eb3e5eb1e,DISK], DatanodeInfoWithStorage[127.0.0.1:39265,DS-5c357300-fb40-4ec7-8320-555db7c93bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:33832,DS-e35daf81-2f21-4048-99f1-89ed40dbff5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1115719908-172.17.0.11-1597538737104:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43140,DS-92f93f65-880b-440f-bd34-8ca2ca8e3fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:45509,DS-701706f4-e225-4ec8-84c6-bbf1d7500da6,DISK], DatanodeInfoWithStorage[127.0.0.1:45338,DS-f378ce8e-d5ff-4e85-bde8-78f90f29596e,DISK], DatanodeInfoWithStorage[127.0.0.1:32953,DS-c46747a5-531a-4a1c-800d-99ecb8b3a60a,DISK], DatanodeInfoWithStorage[127.0.0.1:36007,DS-a3a0b04a-6b9d-43d2-a448-a1645dde3aad,DISK], DatanodeInfoWithStorage[127.0.0.1:40629,DS-dbfaab94-dec0-45ba-96db-711eb3e5eb1e,DISK], DatanodeInfoWithStorage[127.0.0.1:39265,DS-5c357300-fb40-4ec7-8320-555db7c93bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:33832,DS-e35daf81-2f21-4048-99f1-89ed40dbff5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1376385979-172.17.0.11-1597539853591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32825,DS-d3647b72-b5ba-4c94-8023-6931f7cbee2f,DISK], DatanodeInfoWithStorage[127.0.0.1:36985,DS-67a95fb8-39aa-4bef-b994-6fcc16f8f056,DISK], DatanodeInfoWithStorage[127.0.0.1:37430,DS-cf7f2da5-bd96-4a7f-9e2c-139339ff4903,DISK], DatanodeInfoWithStorage[127.0.0.1:40558,DS-40b7af98-6bc6-4287-aa83-c2277e8815fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40770,DS-f1265fc3-9ab0-4c37-8040-6fa095e1b564,DISK], DatanodeInfoWithStorage[127.0.0.1:41410,DS-d5a8a214-c64c-4427-9e21-36b8396a47d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34214,DS-9d107654-89e3-4491-81f9-0612e272fbf4,DISK], DatanodeInfoWithStorage[127.0.0.1:40802,DS-f3704285-673d-4dbf-a244-e5fcbf34f36c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1376385979-172.17.0.11-1597539853591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32825,DS-d3647b72-b5ba-4c94-8023-6931f7cbee2f,DISK], DatanodeInfoWithStorage[127.0.0.1:36985,DS-67a95fb8-39aa-4bef-b994-6fcc16f8f056,DISK], DatanodeInfoWithStorage[127.0.0.1:37430,DS-cf7f2da5-bd96-4a7f-9e2c-139339ff4903,DISK], DatanodeInfoWithStorage[127.0.0.1:40558,DS-40b7af98-6bc6-4287-aa83-c2277e8815fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40770,DS-f1265fc3-9ab0-4c37-8040-6fa095e1b564,DISK], DatanodeInfoWithStorage[127.0.0.1:41410,DS-d5a8a214-c64c-4427-9e21-36b8396a47d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34214,DS-9d107654-89e3-4491-81f9-0612e272fbf4,DISK], DatanodeInfoWithStorage[127.0.0.1:40802,DS-f3704285-673d-4dbf-a244-e5fcbf34f36c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-641796440-172.17.0.11-1597540119574:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46546,DS-bf78c200-ca0b-4b97-b84d-aebc19d990db,DISK], DatanodeInfoWithStorage[127.0.0.1:34854,DS-b319988d-f7f2-4bd7-beb8-6bef38458eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:44109,DS-dd788f77-a02c-4125-bea2-0e47ecd2c811,DISK], DatanodeInfoWithStorage[127.0.0.1:37209,DS-5f6d022e-75bd-4dff-ac53-c6eb8ac8b83d,DISK], DatanodeInfoWithStorage[127.0.0.1:35552,DS-f00a7461-18b5-490d-a9c1-28c6d0186c13,DISK], DatanodeInfoWithStorage[127.0.0.1:41806,DS-72b7da17-3115-4baf-9a6a-b6bf404c739f,DISK], DatanodeInfoWithStorage[127.0.0.1:45658,DS-c2aa95db-f57c-4f47-9589-5aef2e26396e,DISK], DatanodeInfoWithStorage[127.0.0.1:45374,DS-fcfa7dd1-5377-491f-a9af-c5217c77e47e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-641796440-172.17.0.11-1597540119574:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46546,DS-bf78c200-ca0b-4b97-b84d-aebc19d990db,DISK], DatanodeInfoWithStorage[127.0.0.1:34854,DS-b319988d-f7f2-4bd7-beb8-6bef38458eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:44109,DS-dd788f77-a02c-4125-bea2-0e47ecd2c811,DISK], DatanodeInfoWithStorage[127.0.0.1:37209,DS-5f6d022e-75bd-4dff-ac53-c6eb8ac8b83d,DISK], DatanodeInfoWithStorage[127.0.0.1:35552,DS-f00a7461-18b5-490d-a9c1-28c6d0186c13,DISK], DatanodeInfoWithStorage[127.0.0.1:41806,DS-72b7da17-3115-4baf-9a6a-b6bf404c739f,DISK], DatanodeInfoWithStorage[127.0.0.1:45658,DS-c2aa95db-f57c-4f47-9589-5aef2e26396e,DISK], DatanodeInfoWithStorage[127.0.0.1:45374,DS-fcfa7dd1-5377-491f-a9af-c5217c77e47e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-227680342-172.17.0.11-1597540163859:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40182,DS-3f94f4d6-90f3-457b-838a-6cf25e5fcf47,DISK], DatanodeInfoWithStorage[127.0.0.1:44359,DS-a30b5fea-d2d1-4e66-92b5-c3cab583c156,DISK], DatanodeInfoWithStorage[127.0.0.1:45702,DS-909f289b-e595-4c2c-8b83-f09e2ffbbdb7,DISK], DatanodeInfoWithStorage[127.0.0.1:34333,DS-1d61dbf4-7807-40ad-82d7-7832b5af2eef,DISK], DatanodeInfoWithStorage[127.0.0.1:32910,DS-0e60a275-016c-4780-9056-56ff0c8bc6d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45127,DS-433c1d00-c71b-4e5c-a05e-8284e800dd42,DISK], DatanodeInfoWithStorage[127.0.0.1:46165,DS-f289622e-3bae-493e-b5f9-eaf6f173d8a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35659,DS-9338c1e2-582c-40e3-986f-bae470982483,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-227680342-172.17.0.11-1597540163859:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40182,DS-3f94f4d6-90f3-457b-838a-6cf25e5fcf47,DISK], DatanodeInfoWithStorage[127.0.0.1:44359,DS-a30b5fea-d2d1-4e66-92b5-c3cab583c156,DISK], DatanodeInfoWithStorage[127.0.0.1:45702,DS-909f289b-e595-4c2c-8b83-f09e2ffbbdb7,DISK], DatanodeInfoWithStorage[127.0.0.1:34333,DS-1d61dbf4-7807-40ad-82d7-7832b5af2eef,DISK], DatanodeInfoWithStorage[127.0.0.1:32910,DS-0e60a275-016c-4780-9056-56ff0c8bc6d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45127,DS-433c1d00-c71b-4e5c-a05e-8284e800dd42,DISK], DatanodeInfoWithStorage[127.0.0.1:46165,DS-f289622e-3bae-493e-b5f9-eaf6f173d8a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35659,DS-9338c1e2-582c-40e3-986f-bae470982483,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5634
