reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 16384
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 16384
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-418011894-172.17.0.13-1597680529821:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33490,DS-aa054b93-9d9f-48a2-8ce2-980d2d15ef19,DISK], DatanodeInfoWithStorage[127.0.0.1:42063,DS-46dcec56-7157-48bd-8293-d8fea95d2ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:43251,DS-d53a2b54-bd6a-4683-9b74-9c97daf051c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43314,DS-b6613dab-e138-4d59-abab-69d70710324b,DISK], DatanodeInfoWithStorage[127.0.0.1:39354,DS-32596070-2d0c-467e-b941-2ef2994350b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37310,DS-acc66fe5-0db2-4da9-94bb-73ec6c8bb9e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41249,DS-1cc65296-683c-4d7f-a8a7-94bd12d31b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44220,DS-9335875f-4bc4-49d1-9954-b2a9bff0ae34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-418011894-172.17.0.13-1597680529821:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33490,DS-aa054b93-9d9f-48a2-8ce2-980d2d15ef19,DISK], DatanodeInfoWithStorage[127.0.0.1:42063,DS-46dcec56-7157-48bd-8293-d8fea95d2ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:43251,DS-d53a2b54-bd6a-4683-9b74-9c97daf051c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43314,DS-b6613dab-e138-4d59-abab-69d70710324b,DISK], DatanodeInfoWithStorage[127.0.0.1:39354,DS-32596070-2d0c-467e-b941-2ef2994350b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37310,DS-acc66fe5-0db2-4da9-94bb-73ec6c8bb9e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41249,DS-1cc65296-683c-4d7f-a8a7-94bd12d31b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44220,DS-9335875f-4bc4-49d1-9954-b2a9bff0ae34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 16384
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-857172839-172.17.0.13-1597681255866:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34051,DS-52f8d09f-5a8a-41b1-bf6a-bfa5daccbddd,DISK], DatanodeInfoWithStorage[127.0.0.1:33675,DS-c31d4308-db7b-4799-b65d-5b737935e378,DISK], DatanodeInfoWithStorage[127.0.0.1:45865,DS-72c538ff-60aa-4638-ac6b-0f8793cc9cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:43940,DS-4530289c-80cc-4359-be62-8b7d7dd441b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35554,DS-e15743d5-38f5-44af-a2e8-3bdd10f1d006,DISK], DatanodeInfoWithStorage[127.0.0.1:43587,DS-96c2104b-48d1-4b0b-bd78-223a7d96ea28,DISK], DatanodeInfoWithStorage[127.0.0.1:44804,DS-57410241-ffde-4f09-bdde-82764a3a4f38,DISK], DatanodeInfoWithStorage[127.0.0.1:43224,DS-e27d511f-65e8-4618-9de0-9a3066830a6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-857172839-172.17.0.13-1597681255866:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34051,DS-52f8d09f-5a8a-41b1-bf6a-bfa5daccbddd,DISK], DatanodeInfoWithStorage[127.0.0.1:33675,DS-c31d4308-db7b-4799-b65d-5b737935e378,DISK], DatanodeInfoWithStorage[127.0.0.1:45865,DS-72c538ff-60aa-4638-ac6b-0f8793cc9cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:43940,DS-4530289c-80cc-4359-be62-8b7d7dd441b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35554,DS-e15743d5-38f5-44af-a2e8-3bdd10f1d006,DISK], DatanodeInfoWithStorage[127.0.0.1:43587,DS-96c2104b-48d1-4b0b-bd78-223a7d96ea28,DISK], DatanodeInfoWithStorage[127.0.0.1:44804,DS-57410241-ffde-4f09-bdde-82764a3a4f38,DISK], DatanodeInfoWithStorage[127.0.0.1:43224,DS-e27d511f-65e8-4618-9de0-9a3066830a6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 16384
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-631679398-172.17.0.13-1597681293801:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34455,DS-1a072155-4809-467a-9019-fab44e90028e,DISK], DatanodeInfoWithStorage[127.0.0.1:36113,DS-16d1f26a-6713-497f-8af1-dd32974c5bac,DISK], DatanodeInfoWithStorage[127.0.0.1:42884,DS-0703e673-2a26-49b9-a874-3e5374b0d806,DISK], DatanodeInfoWithStorage[127.0.0.1:35533,DS-4780cd2e-49b6-48c0-b072-8faae6c344a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46419,DS-0b8213b4-a229-4969-8990-acb40b669e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35061,DS-a429470b-f2be-4b5a-8e61-eb65c34b5b88,DISK], DatanodeInfoWithStorage[127.0.0.1:40420,DS-0e51a2be-786c-4c70-9c05-355386686abf,DISK], DatanodeInfoWithStorage[127.0.0.1:35281,DS-fe59cf74-03df-4446-865c-8a175ba4144a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-631679398-172.17.0.13-1597681293801:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34455,DS-1a072155-4809-467a-9019-fab44e90028e,DISK], DatanodeInfoWithStorage[127.0.0.1:36113,DS-16d1f26a-6713-497f-8af1-dd32974c5bac,DISK], DatanodeInfoWithStorage[127.0.0.1:42884,DS-0703e673-2a26-49b9-a874-3e5374b0d806,DISK], DatanodeInfoWithStorage[127.0.0.1:35533,DS-4780cd2e-49b6-48c0-b072-8faae6c344a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46419,DS-0b8213b4-a229-4969-8990-acb40b669e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35061,DS-a429470b-f2be-4b5a-8e61-eb65c34b5b88,DISK], DatanodeInfoWithStorage[127.0.0.1:40420,DS-0e51a2be-786c-4c70-9c05-355386686abf,DISK], DatanodeInfoWithStorage[127.0.0.1:35281,DS-fe59cf74-03df-4446-865c-8a175ba4144a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 16384
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-518774500-172.17.0.13-1597681458738:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42001,DS-3207fa2d-50eb-4b50-bb5f-0cbae3c0e61a,DISK], DatanodeInfoWithStorage[127.0.0.1:45956,DS-3900c75a-dd7b-4157-85d7-3e811e9a11bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34808,DS-fccfe9e6-a6c0-4fa3-aed5-3c8437a59596,DISK], DatanodeInfoWithStorage[127.0.0.1:43719,DS-2c6d9124-8ebb-4084-af7e-4b45f01dd445,DISK], DatanodeInfoWithStorage[127.0.0.1:40386,DS-4672488c-6bdd-4bf9-9373-993178600cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:35430,DS-25ea9cbe-c419-434f-a881-a7fad581b35e,DISK], DatanodeInfoWithStorage[127.0.0.1:45466,DS-2a441824-3804-421a-aaa6-46793ff6f12a,DISK], DatanodeInfoWithStorage[127.0.0.1:34790,DS-4ec4be5a-fd10-48b9-8e45-cd1f68b04180,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-518774500-172.17.0.13-1597681458738:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42001,DS-3207fa2d-50eb-4b50-bb5f-0cbae3c0e61a,DISK], DatanodeInfoWithStorage[127.0.0.1:45956,DS-3900c75a-dd7b-4157-85d7-3e811e9a11bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34808,DS-fccfe9e6-a6c0-4fa3-aed5-3c8437a59596,DISK], DatanodeInfoWithStorage[127.0.0.1:43719,DS-2c6d9124-8ebb-4084-af7e-4b45f01dd445,DISK], DatanodeInfoWithStorage[127.0.0.1:40386,DS-4672488c-6bdd-4bf9-9373-993178600cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:35430,DS-25ea9cbe-c419-434f-a881-a7fad581b35e,DISK], DatanodeInfoWithStorage[127.0.0.1:45466,DS-2a441824-3804-421a-aaa6-46793ff6f12a,DISK], DatanodeInfoWithStorage[127.0.0.1:34790,DS-4ec4be5a-fd10-48b9-8e45-cd1f68b04180,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 16384
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1157389927-172.17.0.13-1597681891086:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38534,DS-b4429be2-33e8-4f9a-8c56-49a0687e5055,DISK], DatanodeInfoWithStorage[127.0.0.1:37258,DS-f6a4af2b-92f9-45b8-8908-e1da0851c96e,DISK], DatanodeInfoWithStorage[127.0.0.1:38311,DS-4c73cc74-5c56-4901-86dd-47a6a5544f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:43697,DS-a90ef9f5-344f-4a2c-beb7-202b410d5d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:42903,DS-140f2b1a-7944-4269-8eff-defeeeaf9f63,DISK], DatanodeInfoWithStorage[127.0.0.1:45268,DS-7720e232-261a-4e20-97ff-833e32711aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:33679,DS-2021a236-64fe-4c1c-90bd-c96d4c3d71fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41678,DS-0f9af586-d1cc-4921-a295-1e76640de857,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1157389927-172.17.0.13-1597681891086:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38534,DS-b4429be2-33e8-4f9a-8c56-49a0687e5055,DISK], DatanodeInfoWithStorage[127.0.0.1:37258,DS-f6a4af2b-92f9-45b8-8908-e1da0851c96e,DISK], DatanodeInfoWithStorage[127.0.0.1:38311,DS-4c73cc74-5c56-4901-86dd-47a6a5544f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:43697,DS-a90ef9f5-344f-4a2c-beb7-202b410d5d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:42903,DS-140f2b1a-7944-4269-8eff-defeeeaf9f63,DISK], DatanodeInfoWithStorage[127.0.0.1:45268,DS-7720e232-261a-4e20-97ff-833e32711aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:33679,DS-2021a236-64fe-4c1c-90bd-c96d4c3d71fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41678,DS-0f9af586-d1cc-4921-a295-1e76640de857,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 16384
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1938585678-172.17.0.13-1597682154478:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45817,DS-ac726a36-4aaa-4f94-b034-06b4413b5cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:34579,DS-9bf158d5-237e-49ff-8c59-3d9922b2a1af,DISK], DatanodeInfoWithStorage[127.0.0.1:40928,DS-86c6354b-9298-4f1e-a729-91f8c9b3b2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36293,DS-05a0729f-8dab-43fd-8d73-41db905f1981,DISK], DatanodeInfoWithStorage[127.0.0.1:45066,DS-7621a6ce-329a-49e9-a747-87918a6a59c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42541,DS-5c12a073-2e3c-4955-8a12-c2cebcf6fcf3,DISK], DatanodeInfoWithStorage[127.0.0.1:44705,DS-edfa4be7-bea7-4f41-bfc2-0d1a03e33942,DISK], DatanodeInfoWithStorage[127.0.0.1:45888,DS-43fdce6c-2ae6-41ad-8ccf-e89f069b3dfb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1938585678-172.17.0.13-1597682154478:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45817,DS-ac726a36-4aaa-4f94-b034-06b4413b5cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:34579,DS-9bf158d5-237e-49ff-8c59-3d9922b2a1af,DISK], DatanodeInfoWithStorage[127.0.0.1:40928,DS-86c6354b-9298-4f1e-a729-91f8c9b3b2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36293,DS-05a0729f-8dab-43fd-8d73-41db905f1981,DISK], DatanodeInfoWithStorage[127.0.0.1:45066,DS-7621a6ce-329a-49e9-a747-87918a6a59c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42541,DS-5c12a073-2e3c-4955-8a12-c2cebcf6fcf3,DISK], DatanodeInfoWithStorage[127.0.0.1:44705,DS-edfa4be7-bea7-4f41-bfc2-0d1a03e33942,DISK], DatanodeInfoWithStorage[127.0.0.1:45888,DS-43fdce6c-2ae6-41ad-8ccf-e89f069b3dfb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 16384
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-869550287-172.17.0.13-1597683080960:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41362,DS-ac0efe29-d50b-4eb0-9eaf-2729f3aabdc4,DISK], DatanodeInfoWithStorage[127.0.0.1:38262,DS-523c1158-caee-4489-8399-04c07f16573e,DISK], DatanodeInfoWithStorage[127.0.0.1:35553,DS-640466dc-5910-42ce-a17d-dc99c3827b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:40954,DS-050974b1-4939-4011-a07d-7ad32a929cac,DISK], DatanodeInfoWithStorage[127.0.0.1:39497,DS-69998c6c-fde0-42b5-80fe-c3fa493dd040,DISK], DatanodeInfoWithStorage[127.0.0.1:34359,DS-42d48528-1d41-4357-833f-9caeca60257a,DISK], DatanodeInfoWithStorage[127.0.0.1:46765,DS-152996a1-08d0-4236-9cdc-afcfaf0a8983,DISK], DatanodeInfoWithStorage[127.0.0.1:44909,DS-8dc3c92d-3999-420b-ab71-6c607a928392,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-869550287-172.17.0.13-1597683080960:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41362,DS-ac0efe29-d50b-4eb0-9eaf-2729f3aabdc4,DISK], DatanodeInfoWithStorage[127.0.0.1:38262,DS-523c1158-caee-4489-8399-04c07f16573e,DISK], DatanodeInfoWithStorage[127.0.0.1:35553,DS-640466dc-5910-42ce-a17d-dc99c3827b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:40954,DS-050974b1-4939-4011-a07d-7ad32a929cac,DISK], DatanodeInfoWithStorage[127.0.0.1:39497,DS-69998c6c-fde0-42b5-80fe-c3fa493dd040,DISK], DatanodeInfoWithStorage[127.0.0.1:34359,DS-42d48528-1d41-4357-833f-9caeca60257a,DISK], DatanodeInfoWithStorage[127.0.0.1:46765,DS-152996a1-08d0-4236-9cdc-afcfaf0a8983,DISK], DatanodeInfoWithStorage[127.0.0.1:44909,DS-8dc3c92d-3999-420b-ab71-6c607a928392,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 16384
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1967179055-172.17.0.13-1597683435410:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44405,DS-118a1633-bc8e-4c3a-b4d4-c22c5a4e8aec,DISK], DatanodeInfoWithStorage[127.0.0.1:38624,DS-50a4323f-ab7a-4ca8-8f27-1b38242becc8,DISK], DatanodeInfoWithStorage[127.0.0.1:38505,DS-00e83349-dc59-4b9e-8ebf-4a67e0d6cf48,DISK], DatanodeInfoWithStorage[127.0.0.1:37866,DS-bbacc076-dea0-4030-982e-a1dd6ef1e6de,DISK], DatanodeInfoWithStorage[127.0.0.1:37732,DS-c14c6f2b-6bd8-413a-b908-733c6c391876,DISK], DatanodeInfoWithStorage[127.0.0.1:46597,DS-69d63d9c-0126-465a-8221-77af65d18fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:44322,DS-14ca9523-1d0e-4a73-973b-2be08e352576,DISK], DatanodeInfoWithStorage[127.0.0.1:33247,DS-4e83bc27-0f60-4578-8df9-908e16234e9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1967179055-172.17.0.13-1597683435410:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44405,DS-118a1633-bc8e-4c3a-b4d4-c22c5a4e8aec,DISK], DatanodeInfoWithStorage[127.0.0.1:38624,DS-50a4323f-ab7a-4ca8-8f27-1b38242becc8,DISK], DatanodeInfoWithStorage[127.0.0.1:38505,DS-00e83349-dc59-4b9e-8ebf-4a67e0d6cf48,DISK], DatanodeInfoWithStorage[127.0.0.1:37866,DS-bbacc076-dea0-4030-982e-a1dd6ef1e6de,DISK], DatanodeInfoWithStorage[127.0.0.1:37732,DS-c14c6f2b-6bd8-413a-b908-733c6c391876,DISK], DatanodeInfoWithStorage[127.0.0.1:46597,DS-69d63d9c-0126-465a-8221-77af65d18fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:44322,DS-14ca9523-1d0e-4a73-973b-2be08e352576,DISK], DatanodeInfoWithStorage[127.0.0.1:33247,DS-4e83bc27-0f60-4578-8df9-908e16234e9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 16384
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2061172133-172.17.0.13-1597683593629:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35957,DS-10b27de9-3ed0-4f6f-aac2-6996e1feba87,DISK], DatanodeInfoWithStorage[127.0.0.1:35211,DS-ec31f163-ab62-4aaf-ace4-14992d6b2bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:42011,DS-82458a3a-9ff8-40df-84cc-0a5e26995204,DISK], DatanodeInfoWithStorage[127.0.0.1:41293,DS-80a8c6d9-11b2-45af-9798-ccc3f1776014,DISK], DatanodeInfoWithStorage[127.0.0.1:37897,DS-92a28cc7-e089-48df-94c3-6eadcfd6d616,DISK], DatanodeInfoWithStorage[127.0.0.1:44426,DS-39bf4330-66df-4b0c-8276-a7a290a24175,DISK], DatanodeInfoWithStorage[127.0.0.1:36043,DS-52dd09e6-7937-4a55-ae80-f69226a97f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40205,DS-3c1544ff-0e52-4b42-ad6e-6fa70de09221,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2061172133-172.17.0.13-1597683593629:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35957,DS-10b27de9-3ed0-4f6f-aac2-6996e1feba87,DISK], DatanodeInfoWithStorage[127.0.0.1:35211,DS-ec31f163-ab62-4aaf-ace4-14992d6b2bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:42011,DS-82458a3a-9ff8-40df-84cc-0a5e26995204,DISK], DatanodeInfoWithStorage[127.0.0.1:41293,DS-80a8c6d9-11b2-45af-9798-ccc3f1776014,DISK], DatanodeInfoWithStorage[127.0.0.1:37897,DS-92a28cc7-e089-48df-94c3-6eadcfd6d616,DISK], DatanodeInfoWithStorage[127.0.0.1:44426,DS-39bf4330-66df-4b0c-8276-a7a290a24175,DISK], DatanodeInfoWithStorage[127.0.0.1:36043,DS-52dd09e6-7937-4a55-ae80-f69226a97f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40205,DS-3c1544ff-0e52-4b42-ad6e-6fa70de09221,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 16384
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1781267340-172.17.0.13-1597684016571:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43494,DS-e580e0a6-92ce-4f4c-bcdd-d1af3a2fd83a,DISK], DatanodeInfoWithStorage[127.0.0.1:37185,DS-701cee33-1f26-4b15-b9b9-0b606243f08b,DISK], DatanodeInfoWithStorage[127.0.0.1:44575,DS-4d68a240-493d-4b1f-85bd-bb9aa4cd715e,DISK], DatanodeInfoWithStorage[127.0.0.1:45586,DS-04a8a13e-cbe4-4246-be1d-f3e9629ed048,DISK], DatanodeInfoWithStorage[127.0.0.1:34305,DS-604fe4fc-a8e9-4c5e-97b5-d1f0ef726d20,DISK], DatanodeInfoWithStorage[127.0.0.1:43432,DS-1e963d18-5b23-4404-9e60-49e2101ce023,DISK], DatanodeInfoWithStorage[127.0.0.1:46686,DS-cf3e9de7-9da5-4919-9cf9-93b87aac56e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36878,DS-db647bbf-cc3e-442d-9b3d-6babf2e1f422,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1781267340-172.17.0.13-1597684016571:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43494,DS-e580e0a6-92ce-4f4c-bcdd-d1af3a2fd83a,DISK], DatanodeInfoWithStorage[127.0.0.1:37185,DS-701cee33-1f26-4b15-b9b9-0b606243f08b,DISK], DatanodeInfoWithStorage[127.0.0.1:44575,DS-4d68a240-493d-4b1f-85bd-bb9aa4cd715e,DISK], DatanodeInfoWithStorage[127.0.0.1:45586,DS-04a8a13e-cbe4-4246-be1d-f3e9629ed048,DISK], DatanodeInfoWithStorage[127.0.0.1:34305,DS-604fe4fc-a8e9-4c5e-97b5-d1f0ef726d20,DISK], DatanodeInfoWithStorage[127.0.0.1:43432,DS-1e963d18-5b23-4404-9e60-49e2101ce023,DISK], DatanodeInfoWithStorage[127.0.0.1:46686,DS-cf3e9de7-9da5-4919-9cf9-93b87aac56e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36878,DS-db647bbf-cc3e-442d-9b3d-6babf2e1f422,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 16384
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1723399191-172.17.0.13-1597684095239:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39113,DS-c5b1d11f-b76d-467b-859b-697cf1e40993,DISK], DatanodeInfoWithStorage[127.0.0.1:44247,DS-24a62430-13a4-442b-a120-2364d6e3155b,DISK], DatanodeInfoWithStorage[127.0.0.1:35630,DS-99560837-47b5-4eca-92ad-d3e2818aa619,DISK], DatanodeInfoWithStorage[127.0.0.1:42226,DS-92c7a8d1-12e4-4f91-937b-8b05d0c545d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46329,DS-b8ea89f2-4201-4662-8190-8ddf9104784e,DISK], DatanodeInfoWithStorage[127.0.0.1:41139,DS-6378d5ff-f134-49ce-90b3-f6c3a5d11524,DISK], DatanodeInfoWithStorage[127.0.0.1:35984,DS-a0d1e084-e6a9-455b-a048-69986b34681d,DISK], DatanodeInfoWithStorage[127.0.0.1:37169,DS-b7c2b589-9bf0-4703-8f4f-3ec8160d0695,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1723399191-172.17.0.13-1597684095239:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39113,DS-c5b1d11f-b76d-467b-859b-697cf1e40993,DISK], DatanodeInfoWithStorage[127.0.0.1:44247,DS-24a62430-13a4-442b-a120-2364d6e3155b,DISK], DatanodeInfoWithStorage[127.0.0.1:35630,DS-99560837-47b5-4eca-92ad-d3e2818aa619,DISK], DatanodeInfoWithStorage[127.0.0.1:42226,DS-92c7a8d1-12e4-4f91-937b-8b05d0c545d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46329,DS-b8ea89f2-4201-4662-8190-8ddf9104784e,DISK], DatanodeInfoWithStorage[127.0.0.1:41139,DS-6378d5ff-f134-49ce-90b3-f6c3a5d11524,DISK], DatanodeInfoWithStorage[127.0.0.1:35984,DS-a0d1e084-e6a9-455b-a048-69986b34681d,DISK], DatanodeInfoWithStorage[127.0.0.1:37169,DS-b7c2b589-9bf0-4703-8f4f-3ec8160d0695,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 16384
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-275945112-172.17.0.13-1597684137354:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44435,DS-f5c1207c-e2a9-4bbd-893e-8b75c1cea10d,DISK], DatanodeInfoWithStorage[127.0.0.1:42886,DS-1d97a8ae-527c-4b53-9383-e0e259d10da5,DISK], DatanodeInfoWithStorage[127.0.0.1:40415,DS-cd17eb48-85dc-426a-bb7e-5e962e706638,DISK], DatanodeInfoWithStorage[127.0.0.1:37392,DS-5465b0b4-214f-4c3a-9d09-aa279a1845f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33050,DS-0a0e2a88-0268-4868-9231-634feb000d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:32834,DS-dfc32f5e-dd87-4cdb-a4e5-67d43e179a55,DISK], DatanodeInfoWithStorage[127.0.0.1:34214,DS-d2b5d114-8683-4598-b133-e85721fbdb27,DISK], DatanodeInfoWithStorage[127.0.0.1:35905,DS-b8c4dee9-da0d-495a-a25c-a13cdcdd1e3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-275945112-172.17.0.13-1597684137354:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44435,DS-f5c1207c-e2a9-4bbd-893e-8b75c1cea10d,DISK], DatanodeInfoWithStorage[127.0.0.1:42886,DS-1d97a8ae-527c-4b53-9383-e0e259d10da5,DISK], DatanodeInfoWithStorage[127.0.0.1:40415,DS-cd17eb48-85dc-426a-bb7e-5e962e706638,DISK], DatanodeInfoWithStorage[127.0.0.1:37392,DS-5465b0b4-214f-4c3a-9d09-aa279a1845f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33050,DS-0a0e2a88-0268-4868-9231-634feb000d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:32834,DS-dfc32f5e-dd87-4cdb-a4e5-67d43e179a55,DISK], DatanodeInfoWithStorage[127.0.0.1:34214,DS-d2b5d114-8683-4598-b133-e85721fbdb27,DISK], DatanodeInfoWithStorage[127.0.0.1:35905,DS-b8c4dee9-da0d-495a-a25c-a13cdcdd1e3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 16384
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-848847363-172.17.0.13-1597684749382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34662,DS-39555e9b-99af-431e-953f-400a113ee407,DISK], DatanodeInfoWithStorage[127.0.0.1:46150,DS-2b7c23b4-ae3e-41d0-9367-7f45baea7fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:38713,DS-bdb74637-46cb-46ca-9a3b-34caf972316d,DISK], DatanodeInfoWithStorage[127.0.0.1:37734,DS-21add9cd-b649-4220-9439-064b4c674012,DISK], DatanodeInfoWithStorage[127.0.0.1:35452,DS-c6c7b365-a5c4-4083-a724-30c9c59b2552,DISK], DatanodeInfoWithStorage[127.0.0.1:38738,DS-6feb090b-6131-43ea-bdc9-558773e12488,DISK], DatanodeInfoWithStorage[127.0.0.1:33167,DS-b74280c1-13f3-4291-9838-44a79fcfd954,DISK], DatanodeInfoWithStorage[127.0.0.1:35058,DS-8215c2cc-1e50-4cf6-b842-9f82e2bbd75c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-848847363-172.17.0.13-1597684749382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34662,DS-39555e9b-99af-431e-953f-400a113ee407,DISK], DatanodeInfoWithStorage[127.0.0.1:46150,DS-2b7c23b4-ae3e-41d0-9367-7f45baea7fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:38713,DS-bdb74637-46cb-46ca-9a3b-34caf972316d,DISK], DatanodeInfoWithStorage[127.0.0.1:37734,DS-21add9cd-b649-4220-9439-064b4c674012,DISK], DatanodeInfoWithStorage[127.0.0.1:35452,DS-c6c7b365-a5c4-4083-a724-30c9c59b2552,DISK], DatanodeInfoWithStorage[127.0.0.1:38738,DS-6feb090b-6131-43ea-bdc9-558773e12488,DISK], DatanodeInfoWithStorage[127.0.0.1:33167,DS-b74280c1-13f3-4291-9838-44a79fcfd954,DISK], DatanodeInfoWithStorage[127.0.0.1:35058,DS-8215c2cc-1e50-4cf6-b842-9f82e2bbd75c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 16384
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-819702164-172.17.0.13-1597684924473:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43204,DS-8973850f-6a02-4012-b3c7-35cc1cf8aa5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37039,DS-8d0f38b7-4cc9-4341-a673-d8f97bb4017b,DISK], DatanodeInfoWithStorage[127.0.0.1:42306,DS-d1e7d052-fd39-424a-bcaa-d156248134e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45032,DS-3318eb72-5543-4806-b48b-f3f560f5a190,DISK], DatanodeInfoWithStorage[127.0.0.1:34345,DS-f442dff3-dcd1-4354-8fb8-e8a2a051521d,DISK], DatanodeInfoWithStorage[127.0.0.1:33593,DS-eff025c2-5248-44fb-8303-f7bc6d61a020,DISK], DatanodeInfoWithStorage[127.0.0.1:40716,DS-ed4595bd-0246-40ba-a9d6-90dd8b394fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:43548,DS-b4a2c5f6-5021-4e81-b033-a4ed1a0653dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-819702164-172.17.0.13-1597684924473:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43204,DS-8973850f-6a02-4012-b3c7-35cc1cf8aa5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37039,DS-8d0f38b7-4cc9-4341-a673-d8f97bb4017b,DISK], DatanodeInfoWithStorage[127.0.0.1:42306,DS-d1e7d052-fd39-424a-bcaa-d156248134e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45032,DS-3318eb72-5543-4806-b48b-f3f560f5a190,DISK], DatanodeInfoWithStorage[127.0.0.1:34345,DS-f442dff3-dcd1-4354-8fb8-e8a2a051521d,DISK], DatanodeInfoWithStorage[127.0.0.1:33593,DS-eff025c2-5248-44fb-8303-f7bc6d61a020,DISK], DatanodeInfoWithStorage[127.0.0.1:40716,DS-ed4595bd-0246-40ba-a9d6-90dd8b394fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:43548,DS-b4a2c5f6-5021-4e81-b033-a4ed1a0653dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 16384
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2145818990-172.17.0.13-1597685030545:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43701,DS-9b93f987-9fa4-4e80-bdf8-730da38f4964,DISK], DatanodeInfoWithStorage[127.0.0.1:42251,DS-bf84e1e2-17f7-415f-ad63-72706800a788,DISK], DatanodeInfoWithStorage[127.0.0.1:46686,DS-524841eb-62a6-43f0-b5ba-8722cb698d11,DISK], DatanodeInfoWithStorage[127.0.0.1:38707,DS-c4eed247-bb5f-4d21-a910-b6b6a9bf2ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:44331,DS-38d5279d-8f66-4159-9b19-9593ca5642a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38157,DS-ab563ca9-69d8-444d-8ea4-0cec38454f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45110,DS-9ec5af79-f335-4ea9-884a-b972bf776668,DISK], DatanodeInfoWithStorage[127.0.0.1:41474,DS-445077e7-d885-47c9-bfe8-d956020e5cd9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2145818990-172.17.0.13-1597685030545:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43701,DS-9b93f987-9fa4-4e80-bdf8-730da38f4964,DISK], DatanodeInfoWithStorage[127.0.0.1:42251,DS-bf84e1e2-17f7-415f-ad63-72706800a788,DISK], DatanodeInfoWithStorage[127.0.0.1:46686,DS-524841eb-62a6-43f0-b5ba-8722cb698d11,DISK], DatanodeInfoWithStorage[127.0.0.1:38707,DS-c4eed247-bb5f-4d21-a910-b6b6a9bf2ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:44331,DS-38d5279d-8f66-4159-9b19-9593ca5642a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38157,DS-ab563ca9-69d8-444d-8ea4-0cec38454f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45110,DS-9ec5af79-f335-4ea9-884a-b972bf776668,DISK], DatanodeInfoWithStorage[127.0.0.1:41474,DS-445077e7-d885-47c9-bfe8-d956020e5cd9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 16384
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1867634825-172.17.0.13-1597685699672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35781,DS-09f16a76-bc5d-4a1d-bd58-fb13633c7523,DISK], DatanodeInfoWithStorage[127.0.0.1:34689,DS-4cd08e3b-b343-4287-a09e-ff124aa3f762,DISK], DatanodeInfoWithStorage[127.0.0.1:41933,DS-e1d92452-1873-477b-bfa9-c7e646faedd4,DISK], DatanodeInfoWithStorage[127.0.0.1:33903,DS-71bd7801-a174-4c86-9bd1-bfa26ff9e3a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35097,DS-adb4e3c3-d431-42f7-a6eb-161355497d61,DISK], DatanodeInfoWithStorage[127.0.0.1:36592,DS-32c4d21c-0828-421d-847f-efb859c99c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33126,DS-915c4984-20d8-4c83-ad8c-314c0739167a,DISK], DatanodeInfoWithStorage[127.0.0.1:36136,DS-74214539-e86e-489a-8d88-378629456f8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1867634825-172.17.0.13-1597685699672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35781,DS-09f16a76-bc5d-4a1d-bd58-fb13633c7523,DISK], DatanodeInfoWithStorage[127.0.0.1:34689,DS-4cd08e3b-b343-4287-a09e-ff124aa3f762,DISK], DatanodeInfoWithStorage[127.0.0.1:41933,DS-e1d92452-1873-477b-bfa9-c7e646faedd4,DISK], DatanodeInfoWithStorage[127.0.0.1:33903,DS-71bd7801-a174-4c86-9bd1-bfa26ff9e3a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35097,DS-adb4e3c3-d431-42f7-a6eb-161355497d61,DISK], DatanodeInfoWithStorage[127.0.0.1:36592,DS-32c4d21c-0828-421d-847f-efb859c99c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33126,DS-915c4984-20d8-4c83-ad8c-314c0739167a,DISK], DatanodeInfoWithStorage[127.0.0.1:36136,DS-74214539-e86e-489a-8d88-378629456f8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5828
