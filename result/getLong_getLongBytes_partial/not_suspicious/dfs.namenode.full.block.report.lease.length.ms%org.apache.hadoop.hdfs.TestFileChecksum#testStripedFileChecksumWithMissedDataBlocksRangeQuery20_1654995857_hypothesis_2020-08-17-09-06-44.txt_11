reconf_parameter: dfs.namenode.full.block.report.lease.length.ms
component: hdfs:NameNode
v1: 400000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.full.block.report.lease.length.ms
component: hdfs:NameNode
v1: 400000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1635581290-172.17.0.3-1597655221134:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34212,DS-385e8479-103a-4f7a-bb0d-8d123995a321,DISK], DatanodeInfoWithStorage[127.0.0.1:39614,DS-2e18149b-e50e-45af-a25d-cba386ca77f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44572,DS-aa18d04f-3b5e-454e-9ca1-3688e49d67f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37280,DS-a222606e-9e3d-40d9-b600-bd1908c0fe50,DISK], DatanodeInfoWithStorage[127.0.0.1:41269,DS-761ace2c-ffde-4a64-9842-01eaebf7a93e,DISK], DatanodeInfoWithStorage[127.0.0.1:34797,DS-974cf16b-147a-413a-b845-13b5f5444668,DISK], DatanodeInfoWithStorage[127.0.0.1:36951,DS-9a0704e2-cb37-4096-b07e-e51c6d6c88b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38134,DS-142031e0-60bd-4733-9e16-fa3d6826fd16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1635581290-172.17.0.3-1597655221134:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34212,DS-385e8479-103a-4f7a-bb0d-8d123995a321,DISK], DatanodeInfoWithStorage[127.0.0.1:39614,DS-2e18149b-e50e-45af-a25d-cba386ca77f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44572,DS-aa18d04f-3b5e-454e-9ca1-3688e49d67f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37280,DS-a222606e-9e3d-40d9-b600-bd1908c0fe50,DISK], DatanodeInfoWithStorage[127.0.0.1:41269,DS-761ace2c-ffde-4a64-9842-01eaebf7a93e,DISK], DatanodeInfoWithStorage[127.0.0.1:34797,DS-974cf16b-147a-413a-b845-13b5f5444668,DISK], DatanodeInfoWithStorage[127.0.0.1:36951,DS-9a0704e2-cb37-4096-b07e-e51c6d6c88b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38134,DS-142031e0-60bd-4733-9e16-fa3d6826fd16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.full.block.report.lease.length.ms
component: hdfs:NameNode
v1: 400000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-314106725-172.17.0.3-1597655356283:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34478,DS-37ac1d38-d015-42ff-8e0e-5006335f26ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35361,DS-c56cfba2-8837-4573-acec-e7f5db1063ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34167,DS-a011fcc3-79a2-4432-838c-685376e6b2a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41683,DS-a925aead-b10f-4747-84ff-56356be1c686,DISK], DatanodeInfoWithStorage[127.0.0.1:41483,DS-4e1949bf-7f31-4d54-823f-dcd56191974e,DISK], DatanodeInfoWithStorage[127.0.0.1:36847,DS-5c94ac96-5deb-47a4-a07b-ce49a8a06977,DISK], DatanodeInfoWithStorage[127.0.0.1:34735,DS-47d3f7c5-5b61-4368-8348-7761fc61bfe7,DISK], DatanodeInfoWithStorage[127.0.0.1:45679,DS-68a86d5d-2960-4698-998b-66b7fa1dbe6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-314106725-172.17.0.3-1597655356283:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34478,DS-37ac1d38-d015-42ff-8e0e-5006335f26ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35361,DS-c56cfba2-8837-4573-acec-e7f5db1063ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34167,DS-a011fcc3-79a2-4432-838c-685376e6b2a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41683,DS-a925aead-b10f-4747-84ff-56356be1c686,DISK], DatanodeInfoWithStorage[127.0.0.1:41483,DS-4e1949bf-7f31-4d54-823f-dcd56191974e,DISK], DatanodeInfoWithStorage[127.0.0.1:36847,DS-5c94ac96-5deb-47a4-a07b-ce49a8a06977,DISK], DatanodeInfoWithStorage[127.0.0.1:34735,DS-47d3f7c5-5b61-4368-8348-7761fc61bfe7,DISK], DatanodeInfoWithStorage[127.0.0.1:45679,DS-68a86d5d-2960-4698-998b-66b7fa1dbe6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.full.block.report.lease.length.ms
component: hdfs:NameNode
v1: 400000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-986698049-172.17.0.3-1597655510800:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43386,DS-0d5e5b77-424f-45b5-83c3-dcc8ceb21f69,DISK], DatanodeInfoWithStorage[127.0.0.1:36058,DS-cafc2472-9eb8-4adf-8d22-b7a34ed04ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:41090,DS-45dbadeb-2c17-4b58-a71d-536c8f8319d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45190,DS-4e57e02a-e951-41d1-b702-0e6d14fcf78c,DISK], DatanodeInfoWithStorage[127.0.0.1:37083,DS-a06b629e-c8b6-42bf-9776-20855ddd2f85,DISK], DatanodeInfoWithStorage[127.0.0.1:41872,DS-e48c2db1-8608-4ddc-aa65-6b976f62a40c,DISK], DatanodeInfoWithStorage[127.0.0.1:36596,DS-9d765d10-0cbb-4ebe-a5dc-31e1ced540af,DISK], DatanodeInfoWithStorage[127.0.0.1:36700,DS-34a0fc44-ce05-4085-95e7-d677a6abf9a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-986698049-172.17.0.3-1597655510800:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43386,DS-0d5e5b77-424f-45b5-83c3-dcc8ceb21f69,DISK], DatanodeInfoWithStorage[127.0.0.1:36058,DS-cafc2472-9eb8-4adf-8d22-b7a34ed04ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:41090,DS-45dbadeb-2c17-4b58-a71d-536c8f8319d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45190,DS-4e57e02a-e951-41d1-b702-0e6d14fcf78c,DISK], DatanodeInfoWithStorage[127.0.0.1:37083,DS-a06b629e-c8b6-42bf-9776-20855ddd2f85,DISK], DatanodeInfoWithStorage[127.0.0.1:41872,DS-e48c2db1-8608-4ddc-aa65-6b976f62a40c,DISK], DatanodeInfoWithStorage[127.0.0.1:36596,DS-9d765d10-0cbb-4ebe-a5dc-31e1ced540af,DISK], DatanodeInfoWithStorage[127.0.0.1:36700,DS-34a0fc44-ce05-4085-95e7-d677a6abf9a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.full.block.report.lease.length.ms
component: hdfs:NameNode
v1: 400000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1837425041-172.17.0.3-1597655557058:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32946,DS-1fef16b7-8b08-42dc-bc60-c45c6954f007,DISK], DatanodeInfoWithStorage[127.0.0.1:40444,DS-8e21627e-5e7c-41a8-a2bb-5be44e89bb76,DISK], DatanodeInfoWithStorage[127.0.0.1:39734,DS-b3b9a946-e056-4d3f-9e61-9ebf86d505b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33132,DS-baa053b5-beb3-4fc7-9a03-fcd441809a65,DISK], DatanodeInfoWithStorage[127.0.0.1:39509,DS-61c539f3-0951-45eb-a765-82f56161625f,DISK], DatanodeInfoWithStorage[127.0.0.1:39446,DS-203484bb-d9ee-4fd3-9395-9e56bf896062,DISK], DatanodeInfoWithStorage[127.0.0.1:34044,DS-1c6f5c68-0de1-4419-b052-6b0fd1ece9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36795,DS-e0ebbd0a-ba9a-48c9-807e-62e771f479cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1837425041-172.17.0.3-1597655557058:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32946,DS-1fef16b7-8b08-42dc-bc60-c45c6954f007,DISK], DatanodeInfoWithStorage[127.0.0.1:40444,DS-8e21627e-5e7c-41a8-a2bb-5be44e89bb76,DISK], DatanodeInfoWithStorage[127.0.0.1:39734,DS-b3b9a946-e056-4d3f-9e61-9ebf86d505b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33132,DS-baa053b5-beb3-4fc7-9a03-fcd441809a65,DISK], DatanodeInfoWithStorage[127.0.0.1:39509,DS-61c539f3-0951-45eb-a765-82f56161625f,DISK], DatanodeInfoWithStorage[127.0.0.1:39446,DS-203484bb-d9ee-4fd3-9395-9e56bf896062,DISK], DatanodeInfoWithStorage[127.0.0.1:34044,DS-1c6f5c68-0de1-4419-b052-6b0fd1ece9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36795,DS-e0ebbd0a-ba9a-48c9-807e-62e771f479cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.full.block.report.lease.length.ms
component: hdfs:NameNode
v1: 400000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1640759416-172.17.0.3-1597656311176:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36514,DS-7174f736-ba98-4f34-976e-4a8752a44c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44232,DS-18faec96-7a18-4e7d-88cc-45f29a49b727,DISK], DatanodeInfoWithStorage[127.0.0.1:33414,DS-f5990abc-646c-46c7-8ae6-88ebe0377ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:36670,DS-07d2fe73-8b14-4acd-a16b-08d2988cf98b,DISK], DatanodeInfoWithStorage[127.0.0.1:44524,DS-4e8ece12-81b3-4b91-9f23-de5879ab85b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45317,DS-8bedbadb-58e0-4836-b733-ad465b41de0e,DISK], DatanodeInfoWithStorage[127.0.0.1:46092,DS-1bcd654e-6f9e-4856-9060-50c6538430f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33671,DS-3eaebdf9-6237-4360-8581-ea8dd78e02de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1640759416-172.17.0.3-1597656311176:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36514,DS-7174f736-ba98-4f34-976e-4a8752a44c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44232,DS-18faec96-7a18-4e7d-88cc-45f29a49b727,DISK], DatanodeInfoWithStorage[127.0.0.1:33414,DS-f5990abc-646c-46c7-8ae6-88ebe0377ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:36670,DS-07d2fe73-8b14-4acd-a16b-08d2988cf98b,DISK], DatanodeInfoWithStorage[127.0.0.1:44524,DS-4e8ece12-81b3-4b91-9f23-de5879ab85b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45317,DS-8bedbadb-58e0-4836-b733-ad465b41de0e,DISK], DatanodeInfoWithStorage[127.0.0.1:46092,DS-1bcd654e-6f9e-4856-9060-50c6538430f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33671,DS-3eaebdf9-6237-4360-8581-ea8dd78e02de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.full.block.report.lease.length.ms
component: hdfs:NameNode
v1: 400000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1444319641-172.17.0.3-1597656639877:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41700,DS-a7d8bc65-c944-40ff-8515-1b9ff0f1dca1,DISK], DatanodeInfoWithStorage[127.0.0.1:45727,DS-dcb0adeb-9747-4079-a22b-0791ca240bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:43935,DS-375490d7-a4af-49de-a73d-4da742d4588a,DISK], DatanodeInfoWithStorage[127.0.0.1:39811,DS-e36cbc60-8f39-40e9-8888-fa24f356745b,DISK], DatanodeInfoWithStorage[127.0.0.1:45516,DS-9c9b077f-71f1-4801-bcfa-d681f9aafe8c,DISK], DatanodeInfoWithStorage[127.0.0.1:43038,DS-298a80b2-5117-4b85-b583-80f83f1c1e55,DISK], DatanodeInfoWithStorage[127.0.0.1:35630,DS-78b7977b-8fae-43eb-8e97-f7e2c7aa99b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35520,DS-6b56975a-dd64-4da4-8cf9-328cd4ac791c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1444319641-172.17.0.3-1597656639877:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41700,DS-a7d8bc65-c944-40ff-8515-1b9ff0f1dca1,DISK], DatanodeInfoWithStorage[127.0.0.1:45727,DS-dcb0adeb-9747-4079-a22b-0791ca240bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:43935,DS-375490d7-a4af-49de-a73d-4da742d4588a,DISK], DatanodeInfoWithStorage[127.0.0.1:39811,DS-e36cbc60-8f39-40e9-8888-fa24f356745b,DISK], DatanodeInfoWithStorage[127.0.0.1:45516,DS-9c9b077f-71f1-4801-bcfa-d681f9aafe8c,DISK], DatanodeInfoWithStorage[127.0.0.1:43038,DS-298a80b2-5117-4b85-b583-80f83f1c1e55,DISK], DatanodeInfoWithStorage[127.0.0.1:35630,DS-78b7977b-8fae-43eb-8e97-f7e2c7aa99b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35520,DS-6b56975a-dd64-4da4-8cf9-328cd4ac791c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.full.block.report.lease.length.ms
component: hdfs:NameNode
v1: 400000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2037770997-172.17.0.3-1597656918441:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39115,DS-d7481f2c-02c5-4df7-a4bc-b1518322a61e,DISK], DatanodeInfoWithStorage[127.0.0.1:40968,DS-db009bcd-30ec-4455-83c4-a550acaeca08,DISK], DatanodeInfoWithStorage[127.0.0.1:37409,DS-eaaa6789-eeac-4632-8c11-8efbe325c14d,DISK], DatanodeInfoWithStorage[127.0.0.1:35656,DS-a5d63b9b-a6e3-4583-a96b-68b3482ce1f3,DISK], DatanodeInfoWithStorage[127.0.0.1:32951,DS-10d5ba12-3cbe-4582-8c52-48d8c769d494,DISK], DatanodeInfoWithStorage[127.0.0.1:36399,DS-fdb329a7-d9d7-44bf-ba97-e99cbdb541f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39561,DS-85a2fd00-8166-48e9-b968-ffb14db3b75b,DISK], DatanodeInfoWithStorage[127.0.0.1:37880,DS-6d465d33-4dac-4c6b-8625-f96f5ce64b2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2037770997-172.17.0.3-1597656918441:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39115,DS-d7481f2c-02c5-4df7-a4bc-b1518322a61e,DISK], DatanodeInfoWithStorage[127.0.0.1:40968,DS-db009bcd-30ec-4455-83c4-a550acaeca08,DISK], DatanodeInfoWithStorage[127.0.0.1:37409,DS-eaaa6789-eeac-4632-8c11-8efbe325c14d,DISK], DatanodeInfoWithStorage[127.0.0.1:35656,DS-a5d63b9b-a6e3-4583-a96b-68b3482ce1f3,DISK], DatanodeInfoWithStorage[127.0.0.1:32951,DS-10d5ba12-3cbe-4582-8c52-48d8c769d494,DISK], DatanodeInfoWithStorage[127.0.0.1:36399,DS-fdb329a7-d9d7-44bf-ba97-e99cbdb541f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39561,DS-85a2fd00-8166-48e9-b968-ffb14db3b75b,DISK], DatanodeInfoWithStorage[127.0.0.1:37880,DS-6d465d33-4dac-4c6b-8625-f96f5ce64b2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.full.block.report.lease.length.ms
component: hdfs:NameNode
v1: 400000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-603512754-172.17.0.3-1597658148075:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39361,DS-4154a707-3641-4a10-b0f4-fc0d837c672c,DISK], DatanodeInfoWithStorage[127.0.0.1:42281,DS-8ae6c66d-68b7-45c2-9d33-5e6c6a2cd495,DISK], DatanodeInfoWithStorage[127.0.0.1:38609,DS-bfcfe613-9fc7-4628-b512-d7c898fe475c,DISK], DatanodeInfoWithStorage[127.0.0.1:45766,DS-4bce0c00-2350-40b6-8614-02d3376b05be,DISK], DatanodeInfoWithStorage[127.0.0.1:35174,DS-f898ca3c-e211-4949-9d27-d6c64c5ade14,DISK], DatanodeInfoWithStorage[127.0.0.1:44092,DS-ff22f2bb-5ad3-46bb-9071-427b385223c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39547,DS-04341b4f-bffd-47b7-831a-218ba3a77bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:32899,DS-3762c343-1b47-45dd-88fd-a12c8715130d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-603512754-172.17.0.3-1597658148075:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39361,DS-4154a707-3641-4a10-b0f4-fc0d837c672c,DISK], DatanodeInfoWithStorage[127.0.0.1:42281,DS-8ae6c66d-68b7-45c2-9d33-5e6c6a2cd495,DISK], DatanodeInfoWithStorage[127.0.0.1:38609,DS-bfcfe613-9fc7-4628-b512-d7c898fe475c,DISK], DatanodeInfoWithStorage[127.0.0.1:45766,DS-4bce0c00-2350-40b6-8614-02d3376b05be,DISK], DatanodeInfoWithStorage[127.0.0.1:35174,DS-f898ca3c-e211-4949-9d27-d6c64c5ade14,DISK], DatanodeInfoWithStorage[127.0.0.1:44092,DS-ff22f2bb-5ad3-46bb-9071-427b385223c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39547,DS-04341b4f-bffd-47b7-831a-218ba3a77bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:32899,DS-3762c343-1b47-45dd-88fd-a12c8715130d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.full.block.report.lease.length.ms
component: hdfs:NameNode
v1: 400000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-70899529-172.17.0.3-1597658191954:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35499,DS-a97bced3-37c0-4c59-bc2b-ecbe887ac4d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43675,DS-d64f083d-4d9a-4c0a-90e7-a42fc54d7d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38569,DS-98678728-420a-4bdc-b7a9-5a40397d28fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38189,DS-7d27b7fe-66cf-4c52-a67f-863751817bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:36646,DS-2a57a0b9-b37e-4ab3-a889-686dac90772f,DISK], DatanodeInfoWithStorage[127.0.0.1:44849,DS-351cce26-5e39-4788-b509-96f8e1f1f9d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41449,DS-a0f59c8f-eafe-460a-81d0-8bd54ba3649a,DISK], DatanodeInfoWithStorage[127.0.0.1:40344,DS-60309be3-1ff4-4576-83a7-b5bee7855848,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-70899529-172.17.0.3-1597658191954:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35499,DS-a97bced3-37c0-4c59-bc2b-ecbe887ac4d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43675,DS-d64f083d-4d9a-4c0a-90e7-a42fc54d7d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38569,DS-98678728-420a-4bdc-b7a9-5a40397d28fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38189,DS-7d27b7fe-66cf-4c52-a67f-863751817bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:36646,DS-2a57a0b9-b37e-4ab3-a889-686dac90772f,DISK], DatanodeInfoWithStorage[127.0.0.1:44849,DS-351cce26-5e39-4788-b509-96f8e1f1f9d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41449,DS-a0f59c8f-eafe-460a-81d0-8bd54ba3649a,DISK], DatanodeInfoWithStorage[127.0.0.1:40344,DS-60309be3-1ff4-4576-83a7-b5bee7855848,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.full.block.report.lease.length.ms
component: hdfs:NameNode
v1: 400000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2141757340-172.17.0.3-1597658976706:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38268,DS-120b6f55-51ea-4db7-94c4-fb1a6e3356ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44742,DS-763c599d-c9f7-428d-bb71-5a7a4027f447,DISK], DatanodeInfoWithStorage[127.0.0.1:44420,DS-6927662d-4dfd-4a94-b8d8-c6c26a533337,DISK], DatanodeInfoWithStorage[127.0.0.1:41585,DS-b87614c9-295a-4192-8b8a-f2b7353d6c90,DISK], DatanodeInfoWithStorage[127.0.0.1:43534,DS-097f4a06-8a79-4cb5-be72-ee61e400cd94,DISK], DatanodeInfoWithStorage[127.0.0.1:40483,DS-09f17a91-57ee-4fd1-8047-36874c90ae8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38940,DS-7a9a2da8-9816-42f9-8bae-cd113f5efae6,DISK], DatanodeInfoWithStorage[127.0.0.1:39953,DS-9a7a77be-cb46-460a-b4a9-f4dcd30793ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2141757340-172.17.0.3-1597658976706:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38268,DS-120b6f55-51ea-4db7-94c4-fb1a6e3356ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44742,DS-763c599d-c9f7-428d-bb71-5a7a4027f447,DISK], DatanodeInfoWithStorage[127.0.0.1:44420,DS-6927662d-4dfd-4a94-b8d8-c6c26a533337,DISK], DatanodeInfoWithStorage[127.0.0.1:41585,DS-b87614c9-295a-4192-8b8a-f2b7353d6c90,DISK], DatanodeInfoWithStorage[127.0.0.1:43534,DS-097f4a06-8a79-4cb5-be72-ee61e400cd94,DISK], DatanodeInfoWithStorage[127.0.0.1:40483,DS-09f17a91-57ee-4fd1-8047-36874c90ae8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38940,DS-7a9a2da8-9816-42f9-8bae-cd113f5efae6,DISK], DatanodeInfoWithStorage[127.0.0.1:39953,DS-9a7a77be-cb46-460a-b4a9-f4dcd30793ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.full.block.report.lease.length.ms
component: hdfs:NameNode
v1: 400000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2027098192-172.17.0.3-1597659484635:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37577,DS-f9902571-b015-4c0c-bf5a-85a13f2c4ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:33680,DS-156ace73-96e0-476a-aac8-5f17545b944a,DISK], DatanodeInfoWithStorage[127.0.0.1:38693,DS-324d1a61-e217-421c-9e76-2f7fd5bead47,DISK], DatanodeInfoWithStorage[127.0.0.1:35704,DS-8c60b1a8-c8a8-4766-9692-f6be90cf4bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:38790,DS-996868a5-ea90-4a04-bbae-fb6e58351c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38994,DS-1bccdae5-07a9-4aac-b6f9-55794deea040,DISK], DatanodeInfoWithStorage[127.0.0.1:40480,DS-1e5a7d12-7bae-420e-b26d-736da458fe34,DISK], DatanodeInfoWithStorage[127.0.0.1:39933,DS-6b95008f-f53f-4676-9a37-ce2e4d93c6d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2027098192-172.17.0.3-1597659484635:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37577,DS-f9902571-b015-4c0c-bf5a-85a13f2c4ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:33680,DS-156ace73-96e0-476a-aac8-5f17545b944a,DISK], DatanodeInfoWithStorage[127.0.0.1:38693,DS-324d1a61-e217-421c-9e76-2f7fd5bead47,DISK], DatanodeInfoWithStorage[127.0.0.1:35704,DS-8c60b1a8-c8a8-4766-9692-f6be90cf4bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:38790,DS-996868a5-ea90-4a04-bbae-fb6e58351c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38994,DS-1bccdae5-07a9-4aac-b6f9-55794deea040,DISK], DatanodeInfoWithStorage[127.0.0.1:40480,DS-1e5a7d12-7bae-420e-b26d-736da458fe34,DISK], DatanodeInfoWithStorage[127.0.0.1:39933,DS-6b95008f-f53f-4676-9a37-ce2e4d93c6d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.full.block.report.lease.length.ms
component: hdfs:NameNode
v1: 400000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1255851432-172.17.0.3-1597659704718:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44927,DS-7f5d982f-d102-4f40-ba97-5195a02cbf87,DISK], DatanodeInfoWithStorage[127.0.0.1:41024,DS-51fa0935-b112-4546-b9d9-1b417c916b54,DISK], DatanodeInfoWithStorage[127.0.0.1:40110,DS-497379b2-03a7-4046-ae4a-1c9c0dbf950d,DISK], DatanodeInfoWithStorage[127.0.0.1:33397,DS-d5b33618-426f-4ec3-be11-130337cdae4e,DISK], DatanodeInfoWithStorage[127.0.0.1:46027,DS-9bc1fa16-7886-4f34-9772-088207e1de64,DISK], DatanodeInfoWithStorage[127.0.0.1:46624,DS-15fdce28-4090-4d96-86b9-6d4cae410210,DISK], DatanodeInfoWithStorage[127.0.0.1:34551,DS-1393f0ab-c8b2-43aa-a9bc-a9f0f4c00fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:32857,DS-df330ee9-c800-46f7-a317-f0698cf2728a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1255851432-172.17.0.3-1597659704718:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44927,DS-7f5d982f-d102-4f40-ba97-5195a02cbf87,DISK], DatanodeInfoWithStorage[127.0.0.1:41024,DS-51fa0935-b112-4546-b9d9-1b417c916b54,DISK], DatanodeInfoWithStorage[127.0.0.1:40110,DS-497379b2-03a7-4046-ae4a-1c9c0dbf950d,DISK], DatanodeInfoWithStorage[127.0.0.1:33397,DS-d5b33618-426f-4ec3-be11-130337cdae4e,DISK], DatanodeInfoWithStorage[127.0.0.1:46027,DS-9bc1fa16-7886-4f34-9772-088207e1de64,DISK], DatanodeInfoWithStorage[127.0.0.1:46624,DS-15fdce28-4090-4d96-86b9-6d4cae410210,DISK], DatanodeInfoWithStorage[127.0.0.1:34551,DS-1393f0ab-c8b2-43aa-a9bc-a9f0f4c00fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:32857,DS-df330ee9-c800-46f7-a317-f0698cf2728a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.full.block.report.lease.length.ms
component: hdfs:NameNode
v1: 400000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-972951332-172.17.0.3-1597659807289:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41471,DS-0954dcc1-360e-412d-b7ed-5e7f7c224216,DISK], DatanodeInfoWithStorage[127.0.0.1:35703,DS-36b47516-99ee-42c9-9c50-d9e0cb11ffc3,DISK], DatanodeInfoWithStorage[127.0.0.1:41557,DS-481b0f22-3bdc-486d-92e5-a04a7e9936a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33842,DS-6c188be8-bb13-4333-b724-87bcb754ad93,DISK], DatanodeInfoWithStorage[127.0.0.1:36009,DS-a2b7bfcd-6494-437b-b64d-cf5047a3cff7,DISK], DatanodeInfoWithStorage[127.0.0.1:43830,DS-fa66dd73-bdcf-49a8-b12c-b9be500e196f,DISK], DatanodeInfoWithStorage[127.0.0.1:38508,DS-7d49bfb4-7e25-432e-b61f-b1fd93a0e475,DISK], DatanodeInfoWithStorage[127.0.0.1:34619,DS-38b6114c-2fd5-4556-9686-5661813af255,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-972951332-172.17.0.3-1597659807289:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41471,DS-0954dcc1-360e-412d-b7ed-5e7f7c224216,DISK], DatanodeInfoWithStorage[127.0.0.1:35703,DS-36b47516-99ee-42c9-9c50-d9e0cb11ffc3,DISK], DatanodeInfoWithStorage[127.0.0.1:41557,DS-481b0f22-3bdc-486d-92e5-a04a7e9936a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33842,DS-6c188be8-bb13-4333-b724-87bcb754ad93,DISK], DatanodeInfoWithStorage[127.0.0.1:36009,DS-a2b7bfcd-6494-437b-b64d-cf5047a3cff7,DISK], DatanodeInfoWithStorage[127.0.0.1:43830,DS-fa66dd73-bdcf-49a8-b12c-b9be500e196f,DISK], DatanodeInfoWithStorage[127.0.0.1:38508,DS-7d49bfb4-7e25-432e-b61f-b1fd93a0e475,DISK], DatanodeInfoWithStorage[127.0.0.1:34619,DS-38b6114c-2fd5-4556-9686-5661813af255,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.full.block.report.lease.length.ms
component: hdfs:NameNode
v1: 400000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-304157933-172.17.0.3-1597660069604:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42114,DS-f5ed748f-a669-4c73-99e0-df6619352485,DISK], DatanodeInfoWithStorage[127.0.0.1:41481,DS-dfc238e5-a9fb-499e-9eff-152f217a1934,DISK], DatanodeInfoWithStorage[127.0.0.1:45113,DS-8c45ca23-8f37-44a4-a070-8f8a1e4522e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36641,DS-2ada125c-88b9-4fa1-97b0-282f68e61b49,DISK], DatanodeInfoWithStorage[127.0.0.1:39034,DS-6fca08d6-0808-4a1d-9d50-67e091174554,DISK], DatanodeInfoWithStorage[127.0.0.1:42842,DS-1b032dd2-3dfe-4a97-b45d-0ac6e18ffdab,DISK], DatanodeInfoWithStorage[127.0.0.1:35863,DS-b634be39-1568-4f2c-92bf-ec96f322e2de,DISK], DatanodeInfoWithStorage[127.0.0.1:34613,DS-1ca51b69-cf8f-4c36-b6f8-bd881145f05c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-304157933-172.17.0.3-1597660069604:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42114,DS-f5ed748f-a669-4c73-99e0-df6619352485,DISK], DatanodeInfoWithStorage[127.0.0.1:41481,DS-dfc238e5-a9fb-499e-9eff-152f217a1934,DISK], DatanodeInfoWithStorage[127.0.0.1:45113,DS-8c45ca23-8f37-44a4-a070-8f8a1e4522e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36641,DS-2ada125c-88b9-4fa1-97b0-282f68e61b49,DISK], DatanodeInfoWithStorage[127.0.0.1:39034,DS-6fca08d6-0808-4a1d-9d50-67e091174554,DISK], DatanodeInfoWithStorage[127.0.0.1:42842,DS-1b032dd2-3dfe-4a97-b45d-0ac6e18ffdab,DISK], DatanodeInfoWithStorage[127.0.0.1:35863,DS-b634be39-1568-4f2c-92bf-ec96f322e2de,DISK], DatanodeInfoWithStorage[127.0.0.1:34613,DS-1ca51b69-cf8f-4c36-b6f8-bd881145f05c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.full.block.report.lease.length.ms
component: hdfs:NameNode
v1: 400000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1208384696-172.17.0.3-1597661183807:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46367,DS-85020231-ba76-4752-ba4e-7a216b65a5d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43047,DS-126b0733-5d40-4408-b361-04501c32fdea,DISK], DatanodeInfoWithStorage[127.0.0.1:34661,DS-15b67e08-7d25-4bf1-95e0-783fd1c7319f,DISK], DatanodeInfoWithStorage[127.0.0.1:40047,DS-3bb85881-8b73-43c5-a366-d6a311a1f049,DISK], DatanodeInfoWithStorage[127.0.0.1:45648,DS-d55e3a3b-88cb-4e8a-8ed8-d3ed90c67376,DISK], DatanodeInfoWithStorage[127.0.0.1:35075,DS-2cbfdaa9-cd8d-4bcc-aac6-6d7579b78ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:37546,DS-6ece522b-c429-4595-9a51-521f1f11597d,DISK], DatanodeInfoWithStorage[127.0.0.1:46716,DS-a732c36f-0395-4ba8-ba73-73e6da5b3037,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1208384696-172.17.0.3-1597661183807:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46367,DS-85020231-ba76-4752-ba4e-7a216b65a5d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43047,DS-126b0733-5d40-4408-b361-04501c32fdea,DISK], DatanodeInfoWithStorage[127.0.0.1:34661,DS-15b67e08-7d25-4bf1-95e0-783fd1c7319f,DISK], DatanodeInfoWithStorage[127.0.0.1:40047,DS-3bb85881-8b73-43c5-a366-d6a311a1f049,DISK], DatanodeInfoWithStorage[127.0.0.1:45648,DS-d55e3a3b-88cb-4e8a-8ed8-d3ed90c67376,DISK], DatanodeInfoWithStorage[127.0.0.1:35075,DS-2cbfdaa9-cd8d-4bcc-aac6-6d7579b78ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:37546,DS-6ece522b-c429-4595-9a51-521f1f11597d,DISK], DatanodeInfoWithStorage[127.0.0.1:46716,DS-a732c36f-0395-4ba8-ba73-73e6da5b3037,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.full.block.report.lease.length.ms
component: hdfs:NameNode
v1: 400000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-180771718-172.17.0.3-1597661267628:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39704,DS-79fd1d2b-4fec-44b1-a4d7-5a3f5bac3a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:37229,DS-f4e14114-95a0-4d69-bd0e-cb509006de59,DISK], DatanodeInfoWithStorage[127.0.0.1:46035,DS-8a74a1e9-ce43-4293-a92e-a9e2ea1b57bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36775,DS-90cf530a-ba96-483b-bf39-f9ad67bb8a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:37132,DS-22a44f9e-8cfb-4bd1-9130-91e297270fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:32768,DS-4fc0e750-d047-4932-8f68-cb68af6c2a93,DISK], DatanodeInfoWithStorage[127.0.0.1:34881,DS-895ed2e2-43e4-4785-8a99-895e74c1554b,DISK], DatanodeInfoWithStorage[127.0.0.1:34225,DS-61ffa795-4839-4357-8735-02d7d0077ef7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-180771718-172.17.0.3-1597661267628:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39704,DS-79fd1d2b-4fec-44b1-a4d7-5a3f5bac3a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:37229,DS-f4e14114-95a0-4d69-bd0e-cb509006de59,DISK], DatanodeInfoWithStorage[127.0.0.1:46035,DS-8a74a1e9-ce43-4293-a92e-a9e2ea1b57bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36775,DS-90cf530a-ba96-483b-bf39-f9ad67bb8a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:37132,DS-22a44f9e-8cfb-4bd1-9130-91e297270fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:32768,DS-4fc0e750-d047-4932-8f68-cb68af6c2a93,DISK], DatanodeInfoWithStorage[127.0.0.1:34881,DS-895ed2e2-43e4-4785-8a99-895e74c1554b,DISK], DatanodeInfoWithStorage[127.0.0.1:34225,DS-61ffa795-4839-4357-8735-02d7d0077ef7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.full.block.report.lease.length.ms
component: hdfs:NameNode
v1: 400000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-618465373-172.17.0.3-1597661391981:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43821,DS-92ef1786-3cbc-4af6-b0f0-7ee09ba9f061,DISK], DatanodeInfoWithStorage[127.0.0.1:33147,DS-4bfb16b3-b2a9-4444-b52a-937ae3ee263e,DISK], DatanodeInfoWithStorage[127.0.0.1:45169,DS-5ce012ae-4a0d-4cf5-b6e1-cad00143358e,DISK], DatanodeInfoWithStorage[127.0.0.1:35492,DS-1b2c5b43-2300-4ef4-a003-960fe02159b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43820,DS-66d345d1-0e7d-4a0a-a14c-a0f1ad59a0fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38560,DS-8b83a587-2545-4e33-bc0e-0204cec0d91d,DISK], DatanodeInfoWithStorage[127.0.0.1:44825,DS-86813fcc-7141-489e-9526-53893bd62c47,DISK], DatanodeInfoWithStorage[127.0.0.1:41960,DS-fdbc8c50-4340-41c9-a124-0b0b9f1bcc12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-618465373-172.17.0.3-1597661391981:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43821,DS-92ef1786-3cbc-4af6-b0f0-7ee09ba9f061,DISK], DatanodeInfoWithStorage[127.0.0.1:33147,DS-4bfb16b3-b2a9-4444-b52a-937ae3ee263e,DISK], DatanodeInfoWithStorage[127.0.0.1:45169,DS-5ce012ae-4a0d-4cf5-b6e1-cad00143358e,DISK], DatanodeInfoWithStorage[127.0.0.1:35492,DS-1b2c5b43-2300-4ef4-a003-960fe02159b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43820,DS-66d345d1-0e7d-4a0a-a14c-a0f1ad59a0fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38560,DS-8b83a587-2545-4e33-bc0e-0204cec0d91d,DISK], DatanodeInfoWithStorage[127.0.0.1:44825,DS-86813fcc-7141-489e-9526-53893bd62c47,DISK], DatanodeInfoWithStorage[127.0.0.1:41960,DS-fdbc8c50-4340-41c9-a124-0b0b9f1bcc12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: might be true error
Total execution time in seconds : 6837
