reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1034549873-172.17.0.19-1597694290632:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45411,DS-8eb8741d-7b55-411f-a427-eccf0e874692,DISK], DatanodeInfoWithStorage[127.0.0.1:33964,DS-146d8fae-c736-4a8a-8da2-6effff9fdb3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43912,DS-5f32ec50-9a97-4018-a297-57d858b3ddf1,DISK], DatanodeInfoWithStorage[127.0.0.1:44698,DS-a0c835f7-f22b-47dc-9eed-1be2714bb0b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33227,DS-d0b2f095-e618-494f-aee0-28b2d76cf707,DISK], DatanodeInfoWithStorage[127.0.0.1:34630,DS-cfc0e6b9-e77f-4b17-9290-a8de7f039297,DISK], DatanodeInfoWithStorage[127.0.0.1:40563,DS-8da9f1ac-5251-404c-8a92-fce60eeaa905,DISK], DatanodeInfoWithStorage[127.0.0.1:35882,DS-0a4b6832-4cdb-45cf-9456-9b66a13ae09b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1034549873-172.17.0.19-1597694290632:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45411,DS-8eb8741d-7b55-411f-a427-eccf0e874692,DISK], DatanodeInfoWithStorage[127.0.0.1:33964,DS-146d8fae-c736-4a8a-8da2-6effff9fdb3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43912,DS-5f32ec50-9a97-4018-a297-57d858b3ddf1,DISK], DatanodeInfoWithStorage[127.0.0.1:44698,DS-a0c835f7-f22b-47dc-9eed-1be2714bb0b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33227,DS-d0b2f095-e618-494f-aee0-28b2d76cf707,DISK], DatanodeInfoWithStorage[127.0.0.1:34630,DS-cfc0e6b9-e77f-4b17-9290-a8de7f039297,DISK], DatanodeInfoWithStorage[127.0.0.1:40563,DS-8da9f1ac-5251-404c-8a92-fce60eeaa905,DISK], DatanodeInfoWithStorage[127.0.0.1:35882,DS-0a4b6832-4cdb-45cf-9456-9b66a13ae09b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-885301481-172.17.0.19-1597694859888:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37552,DS-aea5ce37-a3fb-4457-91b4-92707f12d32e,DISK], DatanodeInfoWithStorage[127.0.0.1:39428,DS-3a98674f-3eed-4a3a-aa13-69fc6b7b367d,DISK], DatanodeInfoWithStorage[127.0.0.1:44403,DS-1c0a8c0b-4098-40f9-9bdf-beb0130079b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35458,DS-66e6c0a0-c15b-4f6d-818d-0ac8bf7b3ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:45453,DS-2079c115-3792-4ece-8b13-8dabf62d7da9,DISK], DatanodeInfoWithStorage[127.0.0.1:35084,DS-b153472e-18bf-4561-bb84-8906859c3af0,DISK], DatanodeInfoWithStorage[127.0.0.1:33699,DS-1e9745a6-7341-47a2-8d84-ffe4c375ddf2,DISK], DatanodeInfoWithStorage[127.0.0.1:45540,DS-5bcf6c1e-023c-4092-b093-4a203bfe9548,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-885301481-172.17.0.19-1597694859888:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37552,DS-aea5ce37-a3fb-4457-91b4-92707f12d32e,DISK], DatanodeInfoWithStorage[127.0.0.1:39428,DS-3a98674f-3eed-4a3a-aa13-69fc6b7b367d,DISK], DatanodeInfoWithStorage[127.0.0.1:44403,DS-1c0a8c0b-4098-40f9-9bdf-beb0130079b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35458,DS-66e6c0a0-c15b-4f6d-818d-0ac8bf7b3ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:45453,DS-2079c115-3792-4ece-8b13-8dabf62d7da9,DISK], DatanodeInfoWithStorage[127.0.0.1:35084,DS-b153472e-18bf-4561-bb84-8906859c3af0,DISK], DatanodeInfoWithStorage[127.0.0.1:33699,DS-1e9745a6-7341-47a2-8d84-ffe4c375ddf2,DISK], DatanodeInfoWithStorage[127.0.0.1:45540,DS-5bcf6c1e-023c-4092-b093-4a203bfe9548,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-784897974-172.17.0.19-1597694974082:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41739,DS-3e4f1a04-bb03-404d-ae9d-749db1b2181b,DISK], DatanodeInfoWithStorage[127.0.0.1:35426,DS-cae2c89f-a2ac-45b6-b36b-22044353ef2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42510,DS-0c904d56-02c7-4040-bd36-ab1c7ddd9461,DISK], DatanodeInfoWithStorage[127.0.0.1:35894,DS-9dc52620-86e4-4987-a1bd-2d26c06d8f63,DISK], DatanodeInfoWithStorage[127.0.0.1:38653,DS-ffeaeb71-2832-42b1-90a7-66d7b216ff7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35609,DS-3188b2dd-1c22-4d17-93b8-44423a9c3330,DISK], DatanodeInfoWithStorage[127.0.0.1:46626,DS-a23a5280-72f5-4b24-8784-830fbd689ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:38055,DS-899a5e1e-91d9-4b4f-8445-24bffd05bb93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-784897974-172.17.0.19-1597694974082:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41739,DS-3e4f1a04-bb03-404d-ae9d-749db1b2181b,DISK], DatanodeInfoWithStorage[127.0.0.1:35426,DS-cae2c89f-a2ac-45b6-b36b-22044353ef2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42510,DS-0c904d56-02c7-4040-bd36-ab1c7ddd9461,DISK], DatanodeInfoWithStorage[127.0.0.1:35894,DS-9dc52620-86e4-4987-a1bd-2d26c06d8f63,DISK], DatanodeInfoWithStorage[127.0.0.1:38653,DS-ffeaeb71-2832-42b1-90a7-66d7b216ff7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35609,DS-3188b2dd-1c22-4d17-93b8-44423a9c3330,DISK], DatanodeInfoWithStorage[127.0.0.1:46626,DS-a23a5280-72f5-4b24-8784-830fbd689ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:38055,DS-899a5e1e-91d9-4b4f-8445-24bffd05bb93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-309853910-172.17.0.19-1597695235376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40326,DS-a5113a5c-e7e4-4bb6-b1d7-295bdc9bb296,DISK], DatanodeInfoWithStorage[127.0.0.1:41318,DS-0eb3a621-fb04-49c2-b35f-925d00686b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:40343,DS-adf66909-8046-4c6a-b9ca-82602b39c356,DISK], DatanodeInfoWithStorage[127.0.0.1:39705,DS-ee1d0c15-5f59-4211-8f4d-b510086f2711,DISK], DatanodeInfoWithStorage[127.0.0.1:37797,DS-fe53752c-c9f0-460a-945e-536dac1f343d,DISK], DatanodeInfoWithStorage[127.0.0.1:46562,DS-fc99e978-489c-418c-9f2b-00c5f2b9d946,DISK], DatanodeInfoWithStorage[127.0.0.1:39033,DS-275ac3fe-48d3-4333-889e-9248c8ece6bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36752,DS-2a7d74e4-65b5-48c6-963e-e18067ed93c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-309853910-172.17.0.19-1597695235376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40326,DS-a5113a5c-e7e4-4bb6-b1d7-295bdc9bb296,DISK], DatanodeInfoWithStorage[127.0.0.1:41318,DS-0eb3a621-fb04-49c2-b35f-925d00686b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:40343,DS-adf66909-8046-4c6a-b9ca-82602b39c356,DISK], DatanodeInfoWithStorage[127.0.0.1:39705,DS-ee1d0c15-5f59-4211-8f4d-b510086f2711,DISK], DatanodeInfoWithStorage[127.0.0.1:37797,DS-fe53752c-c9f0-460a-945e-536dac1f343d,DISK], DatanodeInfoWithStorage[127.0.0.1:46562,DS-fc99e978-489c-418c-9f2b-00c5f2b9d946,DISK], DatanodeInfoWithStorage[127.0.0.1:39033,DS-275ac3fe-48d3-4333-889e-9248c8ece6bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36752,DS-2a7d74e4-65b5-48c6-963e-e18067ed93c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1199644151-172.17.0.19-1597695536990:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38608,DS-e87bd92b-bc67-459b-bc87-2a494e9d0461,DISK], DatanodeInfoWithStorage[127.0.0.1:46018,DS-966818bf-243e-4e5b-abf4-d1d41addb6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35723,DS-db7eeea2-e6df-4dba-bc13-29a66a096a57,DISK], DatanodeInfoWithStorage[127.0.0.1:32981,DS-adc6dd67-14f4-445d-ab27-56e13b7cb718,DISK], DatanodeInfoWithStorage[127.0.0.1:35637,DS-2d116213-d1f1-45fc-b386-ece655a91ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:45764,DS-7cc0d2eb-c170-4661-b4d3-5de13bc2b111,DISK], DatanodeInfoWithStorage[127.0.0.1:36035,DS-e607a6de-d342-4133-83dc-035ce5dea57d,DISK], DatanodeInfoWithStorage[127.0.0.1:33240,DS-b657cc1d-7595-4b8b-9714-0b41fcbd0246,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1199644151-172.17.0.19-1597695536990:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38608,DS-e87bd92b-bc67-459b-bc87-2a494e9d0461,DISK], DatanodeInfoWithStorage[127.0.0.1:46018,DS-966818bf-243e-4e5b-abf4-d1d41addb6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35723,DS-db7eeea2-e6df-4dba-bc13-29a66a096a57,DISK], DatanodeInfoWithStorage[127.0.0.1:32981,DS-adc6dd67-14f4-445d-ab27-56e13b7cb718,DISK], DatanodeInfoWithStorage[127.0.0.1:35637,DS-2d116213-d1f1-45fc-b386-ece655a91ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:45764,DS-7cc0d2eb-c170-4661-b4d3-5de13bc2b111,DISK], DatanodeInfoWithStorage[127.0.0.1:36035,DS-e607a6de-d342-4133-83dc-035ce5dea57d,DISK], DatanodeInfoWithStorage[127.0.0.1:33240,DS-b657cc1d-7595-4b8b-9714-0b41fcbd0246,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1478356913-172.17.0.19-1597695690038:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43282,DS-041d8ea5-8865-4dce-b1d8-231744c45fed,DISK], DatanodeInfoWithStorage[127.0.0.1:34073,DS-b19c2770-b677-44ce-a65d-412059fdfec7,DISK], DatanodeInfoWithStorage[127.0.0.1:44691,DS-9940933f-d5aa-49c6-b8a2-65c31ee87cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:33047,DS-f8d8b422-c9b4-41fa-b166-11a6509250ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40743,DS-2afa5a9a-1633-4efa-aa13-811b3255ab4c,DISK], DatanodeInfoWithStorage[127.0.0.1:40133,DS-b2979693-b044-4d5e-b6f0-4021d01ffbad,DISK], DatanodeInfoWithStorage[127.0.0.1:44659,DS-fea0da57-cee7-4c42-9b44-2834f8fca868,DISK], DatanodeInfoWithStorage[127.0.0.1:33071,DS-5680b6d3-0366-4b8e-a214-7146143d5b76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1478356913-172.17.0.19-1597695690038:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43282,DS-041d8ea5-8865-4dce-b1d8-231744c45fed,DISK], DatanodeInfoWithStorage[127.0.0.1:34073,DS-b19c2770-b677-44ce-a65d-412059fdfec7,DISK], DatanodeInfoWithStorage[127.0.0.1:44691,DS-9940933f-d5aa-49c6-b8a2-65c31ee87cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:33047,DS-f8d8b422-c9b4-41fa-b166-11a6509250ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40743,DS-2afa5a9a-1633-4efa-aa13-811b3255ab4c,DISK], DatanodeInfoWithStorage[127.0.0.1:40133,DS-b2979693-b044-4d5e-b6f0-4021d01ffbad,DISK], DatanodeInfoWithStorage[127.0.0.1:44659,DS-fea0da57-cee7-4c42-9b44-2834f8fca868,DISK], DatanodeInfoWithStorage[127.0.0.1:33071,DS-5680b6d3-0366-4b8e-a214-7146143d5b76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-947028291-172.17.0.19-1597696240031:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40238,DS-8d7b9209-da8a-494a-a425-0a3af8f9b7c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40820,DS-f57e3155-2811-423b-81fd-b2753a6e10ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33507,DS-cff41785-27c0-4735-bc16-d1b24c3d345f,DISK], DatanodeInfoWithStorage[127.0.0.1:45444,DS-bda82c4f-d9a5-4aad-a998-5131d1620a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:46288,DS-2a1b7883-2c08-4f3e-87a3-ee24eb1ca0cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44316,DS-75d51ab7-ff82-43eb-8c12-992edbc6c0cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46858,DS-459e2c8f-f5aa-4358-a2c2-b318fe896801,DISK], DatanodeInfoWithStorage[127.0.0.1:45677,DS-dff36a2e-26d7-4596-bc61-016847a226b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-947028291-172.17.0.19-1597696240031:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40238,DS-8d7b9209-da8a-494a-a425-0a3af8f9b7c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40820,DS-f57e3155-2811-423b-81fd-b2753a6e10ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33507,DS-cff41785-27c0-4735-bc16-d1b24c3d345f,DISK], DatanodeInfoWithStorage[127.0.0.1:45444,DS-bda82c4f-d9a5-4aad-a998-5131d1620a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:46288,DS-2a1b7883-2c08-4f3e-87a3-ee24eb1ca0cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44316,DS-75d51ab7-ff82-43eb-8c12-992edbc6c0cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46858,DS-459e2c8f-f5aa-4358-a2c2-b318fe896801,DISK], DatanodeInfoWithStorage[127.0.0.1:45677,DS-dff36a2e-26d7-4596-bc61-016847a226b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-642490874-172.17.0.19-1597696322239:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37881,DS-4d25de51-0dd4-45b8-a736-bdf9898a34aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36065,DS-65685b41-a606-476b-b7b4-3dde31174691,DISK], DatanodeInfoWithStorage[127.0.0.1:35909,DS-c60efc75-11cd-4b10-a8fa-cff866dda5a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39537,DS-aa3f4955-88be-4b4b-916e-0221a6bdd759,DISK], DatanodeInfoWithStorage[127.0.0.1:41580,DS-ff104add-9351-4f9a-815f-d771ef7efeac,DISK], DatanodeInfoWithStorage[127.0.0.1:44241,DS-f8bfbe18-9c15-48e5-b181-d4e90ba1b8fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34052,DS-23587844-6891-466f-9ac1-c3bf8645b2f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36236,DS-2c9865f4-ac83-4ae3-ba46-f8a716056fc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-642490874-172.17.0.19-1597696322239:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37881,DS-4d25de51-0dd4-45b8-a736-bdf9898a34aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36065,DS-65685b41-a606-476b-b7b4-3dde31174691,DISK], DatanodeInfoWithStorage[127.0.0.1:35909,DS-c60efc75-11cd-4b10-a8fa-cff866dda5a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39537,DS-aa3f4955-88be-4b4b-916e-0221a6bdd759,DISK], DatanodeInfoWithStorage[127.0.0.1:41580,DS-ff104add-9351-4f9a-815f-d771ef7efeac,DISK], DatanodeInfoWithStorage[127.0.0.1:44241,DS-f8bfbe18-9c15-48e5-b181-d4e90ba1b8fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34052,DS-23587844-6891-466f-9ac1-c3bf8645b2f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36236,DS-2c9865f4-ac83-4ae3-ba46-f8a716056fc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-570029925-172.17.0.19-1597696498657:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37288,DS-08cbaa23-bbe8-45c3-ae07-0fb2ae415d39,DISK], DatanodeInfoWithStorage[127.0.0.1:42412,DS-7f222128-7acd-4f8d-9c8a-a9d80ac4df4c,DISK], DatanodeInfoWithStorage[127.0.0.1:37239,DS-7922599f-a104-401f-aed3-f53800a397a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34154,DS-2e54affd-79c4-4203-a33b-a0231c8e3997,DISK], DatanodeInfoWithStorage[127.0.0.1:46856,DS-da9367e6-0f39-42b3-9eb4-f968bfb7e0ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44773,DS-689a8fdd-567b-464f-9295-35d684f86091,DISK], DatanodeInfoWithStorage[127.0.0.1:32949,DS-d881f2d8-5c19-4dd6-ac61-f41dbedce526,DISK], DatanodeInfoWithStorage[127.0.0.1:40152,DS-dc18497c-d644-4d79-8b03-8b0348ae78d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-570029925-172.17.0.19-1597696498657:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37288,DS-08cbaa23-bbe8-45c3-ae07-0fb2ae415d39,DISK], DatanodeInfoWithStorage[127.0.0.1:42412,DS-7f222128-7acd-4f8d-9c8a-a9d80ac4df4c,DISK], DatanodeInfoWithStorage[127.0.0.1:37239,DS-7922599f-a104-401f-aed3-f53800a397a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34154,DS-2e54affd-79c4-4203-a33b-a0231c8e3997,DISK], DatanodeInfoWithStorage[127.0.0.1:46856,DS-da9367e6-0f39-42b3-9eb4-f968bfb7e0ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44773,DS-689a8fdd-567b-464f-9295-35d684f86091,DISK], DatanodeInfoWithStorage[127.0.0.1:32949,DS-d881f2d8-5c19-4dd6-ac61-f41dbedce526,DISK], DatanodeInfoWithStorage[127.0.0.1:40152,DS-dc18497c-d644-4d79-8b03-8b0348ae78d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-540220215-172.17.0.19-1597696827048:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40100,DS-97b18ad5-0c36-42d8-8818-3fd00e9ba898,DISK], DatanodeInfoWithStorage[127.0.0.1:33262,DS-4fc7ee43-aa86-40fd-b2e4-d5084ff2f115,DISK], DatanodeInfoWithStorage[127.0.0.1:44307,DS-472713cc-d7b1-4464-94fe-253b33dd1fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:39516,DS-83484066-3d9e-42cd-b089-377900bda51c,DISK], DatanodeInfoWithStorage[127.0.0.1:35507,DS-36b631c4-d42a-4668-8d28-20ec24d17d00,DISK], DatanodeInfoWithStorage[127.0.0.1:45148,DS-b055fa5f-0ca0-4bf7-9a0b-03bc1281f996,DISK], DatanodeInfoWithStorage[127.0.0.1:43204,DS-6f3240e8-21f1-495a-931b-675cc622b760,DISK], DatanodeInfoWithStorage[127.0.0.1:35665,DS-196efc89-b374-4dca-9cc9-99f287e4ff7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-540220215-172.17.0.19-1597696827048:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40100,DS-97b18ad5-0c36-42d8-8818-3fd00e9ba898,DISK], DatanodeInfoWithStorage[127.0.0.1:33262,DS-4fc7ee43-aa86-40fd-b2e4-d5084ff2f115,DISK], DatanodeInfoWithStorage[127.0.0.1:44307,DS-472713cc-d7b1-4464-94fe-253b33dd1fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:39516,DS-83484066-3d9e-42cd-b089-377900bda51c,DISK], DatanodeInfoWithStorage[127.0.0.1:35507,DS-36b631c4-d42a-4668-8d28-20ec24d17d00,DISK], DatanodeInfoWithStorage[127.0.0.1:45148,DS-b055fa5f-0ca0-4bf7-9a0b-03bc1281f996,DISK], DatanodeInfoWithStorage[127.0.0.1:43204,DS-6f3240e8-21f1-495a-931b-675cc622b760,DISK], DatanodeInfoWithStorage[127.0.0.1:35665,DS-196efc89-b374-4dca-9cc9-99f287e4ff7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1240515803-172.17.0.19-1597697266516:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32910,DS-62fc5314-b720-44bb-b57e-c3ca30178209,DISK], DatanodeInfoWithStorage[127.0.0.1:42112,DS-92c34d1b-b8cf-4895-9ec8-0db65b7788d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39461,DS-defb21f5-ae73-4ec9-894c-e6846c392e86,DISK], DatanodeInfoWithStorage[127.0.0.1:33936,DS-d7afecf0-5dad-41f9-bc57-774ef78e0f53,DISK], DatanodeInfoWithStorage[127.0.0.1:44830,DS-075ae2f2-31f9-44aa-8354-5aa6aadf79d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37839,DS-c2f18139-c12b-4388-96c3-e703f21b7848,DISK], DatanodeInfoWithStorage[127.0.0.1:39421,DS-5d53bbcc-16d8-4cd0-962e-5ae1999b7bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:42139,DS-56027f0d-bc1f-482d-bd75-eb276f34f0de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1240515803-172.17.0.19-1597697266516:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32910,DS-62fc5314-b720-44bb-b57e-c3ca30178209,DISK], DatanodeInfoWithStorage[127.0.0.1:42112,DS-92c34d1b-b8cf-4895-9ec8-0db65b7788d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39461,DS-defb21f5-ae73-4ec9-894c-e6846c392e86,DISK], DatanodeInfoWithStorage[127.0.0.1:33936,DS-d7afecf0-5dad-41f9-bc57-774ef78e0f53,DISK], DatanodeInfoWithStorage[127.0.0.1:44830,DS-075ae2f2-31f9-44aa-8354-5aa6aadf79d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37839,DS-c2f18139-c12b-4388-96c3-e703f21b7848,DISK], DatanodeInfoWithStorage[127.0.0.1:39421,DS-5d53bbcc-16d8-4cd0-962e-5ae1999b7bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:42139,DS-56027f0d-bc1f-482d-bd75-eb276f34f0de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1367739131-172.17.0.19-1597697305135:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35036,DS-3e87c5b7-c2e6-4802-a5d9-607dea2a8d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:43251,DS-3a4acbb2-361d-4af5-aba3-e3c4533338d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42374,DS-20848af0-5cca-4881-a24a-ed54fe87ee08,DISK], DatanodeInfoWithStorage[127.0.0.1:41290,DS-926a015d-3852-4b92-a996-4c5c7a8113e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35695,DS-a1dd81db-49ea-49dc-bccf-0afbc42f805a,DISK], DatanodeInfoWithStorage[127.0.0.1:33556,DS-c7f1ac56-0025-4eb9-b00d-bb35e1ebd2ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45598,DS-dc5ba30b-c6ce-48df-94ef-2ab3bc675d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:41456,DS-dde4c879-7562-4b50-98b1-6f83ec8d28ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1367739131-172.17.0.19-1597697305135:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35036,DS-3e87c5b7-c2e6-4802-a5d9-607dea2a8d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:43251,DS-3a4acbb2-361d-4af5-aba3-e3c4533338d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42374,DS-20848af0-5cca-4881-a24a-ed54fe87ee08,DISK], DatanodeInfoWithStorage[127.0.0.1:41290,DS-926a015d-3852-4b92-a996-4c5c7a8113e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35695,DS-a1dd81db-49ea-49dc-bccf-0afbc42f805a,DISK], DatanodeInfoWithStorage[127.0.0.1:33556,DS-c7f1ac56-0025-4eb9-b00d-bb35e1ebd2ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45598,DS-dc5ba30b-c6ce-48df-94ef-2ab3bc675d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:41456,DS-dde4c879-7562-4b50-98b1-6f83ec8d28ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5686
