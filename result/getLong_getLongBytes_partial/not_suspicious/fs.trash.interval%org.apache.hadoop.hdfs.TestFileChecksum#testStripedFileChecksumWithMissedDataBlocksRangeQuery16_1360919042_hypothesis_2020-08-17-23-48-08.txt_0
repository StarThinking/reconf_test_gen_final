reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2059172843-172.17.0.13-1597708493360:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32893,DS-73c30cd2-0d84-47b0-98e4-fe9d84cb2b38,DISK], DatanodeInfoWithStorage[127.0.0.1:37758,DS-ac943570-34db-414d-b462-246eab199840,DISK], DatanodeInfoWithStorage[127.0.0.1:43842,DS-d10452e9-c6d1-4687-a574-ba13c8a8bd7e,DISK], DatanodeInfoWithStorage[127.0.0.1:38766,DS-1d81ac8a-944b-45cf-810e-7c9963f0ba12,DISK], DatanodeInfoWithStorage[127.0.0.1:44285,DS-879b4197-6d18-4b40-abd2-7374e0d04613,DISK], DatanodeInfoWithStorage[127.0.0.1:41518,DS-e1413ffd-d853-4cc0-b284-661dbf324cea,DISK], DatanodeInfoWithStorage[127.0.0.1:46630,DS-1b1488e5-a04f-4ac3-893a-78b84204f781,DISK], DatanodeInfoWithStorage[127.0.0.1:37927,DS-ad63beaa-6c5a-4fbe-9f79-a320519f3085,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2059172843-172.17.0.13-1597708493360:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32893,DS-73c30cd2-0d84-47b0-98e4-fe9d84cb2b38,DISK], DatanodeInfoWithStorage[127.0.0.1:37758,DS-ac943570-34db-414d-b462-246eab199840,DISK], DatanodeInfoWithStorage[127.0.0.1:43842,DS-d10452e9-c6d1-4687-a574-ba13c8a8bd7e,DISK], DatanodeInfoWithStorage[127.0.0.1:38766,DS-1d81ac8a-944b-45cf-810e-7c9963f0ba12,DISK], DatanodeInfoWithStorage[127.0.0.1:44285,DS-879b4197-6d18-4b40-abd2-7374e0d04613,DISK], DatanodeInfoWithStorage[127.0.0.1:41518,DS-e1413ffd-d853-4cc0-b284-661dbf324cea,DISK], DatanodeInfoWithStorage[127.0.0.1:46630,DS-1b1488e5-a04f-4ac3-893a-78b84204f781,DISK], DatanodeInfoWithStorage[127.0.0.1:37927,DS-ad63beaa-6c5a-4fbe-9f79-a320519f3085,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1870640682-172.17.0.13-1597709118797:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35954,DS-f3ac4073-5987-4865-885c-fe98850d7c26,DISK], DatanodeInfoWithStorage[127.0.0.1:33489,DS-9d079372-8ed2-4b21-9e04-cbd5efc698cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42560,DS-825660a1-434d-488e-8181-632489a019c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41541,DS-ff1bbd19-9a78-4098-a4b0-d627ce9b28e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42732,DS-10356aba-2505-466e-a30c-28fabc52a10f,DISK], DatanodeInfoWithStorage[127.0.0.1:38385,DS-36c70d31-279f-4ca4-aca8-c5f7cd735d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44876,DS-5d0cc7ed-82d7-4ef1-af23-e7e3c356a0f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45251,DS-e24db889-d2b8-4a17-aba1-6a80b0f4e6d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1870640682-172.17.0.13-1597709118797:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35954,DS-f3ac4073-5987-4865-885c-fe98850d7c26,DISK], DatanodeInfoWithStorage[127.0.0.1:33489,DS-9d079372-8ed2-4b21-9e04-cbd5efc698cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42560,DS-825660a1-434d-488e-8181-632489a019c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41541,DS-ff1bbd19-9a78-4098-a4b0-d627ce9b28e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42732,DS-10356aba-2505-466e-a30c-28fabc52a10f,DISK], DatanodeInfoWithStorage[127.0.0.1:38385,DS-36c70d31-279f-4ca4-aca8-c5f7cd735d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44876,DS-5d0cc7ed-82d7-4ef1-af23-e7e3c356a0f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45251,DS-e24db889-d2b8-4a17-aba1-6a80b0f4e6d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-550564914-172.17.0.13-1597709347546:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35982,DS-53a6e67b-a089-4e58-80ac-edc51a7cb934,DISK], DatanodeInfoWithStorage[127.0.0.1:43612,DS-c884c62c-2bc3-4507-923f-33f7fcaa31ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43148,DS-c28623d4-0efc-40a3-b75d-453d9826c811,DISK], DatanodeInfoWithStorage[127.0.0.1:46260,DS-77c33fc3-b4eb-4f88-b8e6-f3f75036df74,DISK], DatanodeInfoWithStorage[127.0.0.1:39321,DS-9efe0d3d-d507-4f55-a784-912b2e6dfd1b,DISK], DatanodeInfoWithStorage[127.0.0.1:40654,DS-f97a9446-9d1b-4936-a3da-48cdc3175f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38272,DS-49f65d0d-6722-4b0e-8c9d-48b744d78c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:37229,DS-56a1e102-7b97-492d-806b-a3fd20ebd9f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-550564914-172.17.0.13-1597709347546:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35982,DS-53a6e67b-a089-4e58-80ac-edc51a7cb934,DISK], DatanodeInfoWithStorage[127.0.0.1:43612,DS-c884c62c-2bc3-4507-923f-33f7fcaa31ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43148,DS-c28623d4-0efc-40a3-b75d-453d9826c811,DISK], DatanodeInfoWithStorage[127.0.0.1:46260,DS-77c33fc3-b4eb-4f88-b8e6-f3f75036df74,DISK], DatanodeInfoWithStorage[127.0.0.1:39321,DS-9efe0d3d-d507-4f55-a784-912b2e6dfd1b,DISK], DatanodeInfoWithStorage[127.0.0.1:40654,DS-f97a9446-9d1b-4936-a3da-48cdc3175f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38272,DS-49f65d0d-6722-4b0e-8c9d-48b744d78c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:37229,DS-56a1e102-7b97-492d-806b-a3fd20ebd9f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1369528547-172.17.0.13-1597709424085:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44803,DS-c40cbf18-f548-4ea4-b814-28da1d5996c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39938,DS-b5aaad36-fbd1-4142-a60e-16636b7149f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38090,DS-09f6d842-dd9b-4031-802b-ff3f6bc4404e,DISK], DatanodeInfoWithStorage[127.0.0.1:35301,DS-ee57c182-979e-4413-9880-e2fdc37b7ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:43135,DS-89983350-147e-40f3-9186-aeb480a670a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35359,DS-a47c9906-6ce4-425d-a978-e4aee4236166,DISK], DatanodeInfoWithStorage[127.0.0.1:32997,DS-f8bf26aa-9694-4cfc-8741-9ffa7f6fe514,DISK], DatanodeInfoWithStorage[127.0.0.1:34862,DS-94fbb12b-6b6f-4bd9-a8bf-a0e0b9b0178d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1369528547-172.17.0.13-1597709424085:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44803,DS-c40cbf18-f548-4ea4-b814-28da1d5996c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39938,DS-b5aaad36-fbd1-4142-a60e-16636b7149f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38090,DS-09f6d842-dd9b-4031-802b-ff3f6bc4404e,DISK], DatanodeInfoWithStorage[127.0.0.1:35301,DS-ee57c182-979e-4413-9880-e2fdc37b7ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:43135,DS-89983350-147e-40f3-9186-aeb480a670a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35359,DS-a47c9906-6ce4-425d-a978-e4aee4236166,DISK], DatanodeInfoWithStorage[127.0.0.1:32997,DS-f8bf26aa-9694-4cfc-8741-9ffa7f6fe514,DISK], DatanodeInfoWithStorage[127.0.0.1:34862,DS-94fbb12b-6b6f-4bd9-a8bf-a0e0b9b0178d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1673475290-172.17.0.13-1597709466312:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33535,DS-5636759e-98fe-43c6-b2d7-cf86a114b412,DISK], DatanodeInfoWithStorage[127.0.0.1:45454,DS-8dab59b7-0f18-4f90-a13a-b44f28e4fb36,DISK], DatanodeInfoWithStorage[127.0.0.1:32990,DS-0ed05f7e-3667-4f1c-ba33-45bb7856ce08,DISK], DatanodeInfoWithStorage[127.0.0.1:43718,DS-104e2bc4-c7cd-47e0-a1d1-a780597d97b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45726,DS-330dd9d3-e755-413f-af9a-92a03e41358f,DISK], DatanodeInfoWithStorage[127.0.0.1:37945,DS-f461201f-e3ae-4548-92d1-b322b07ec6d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45682,DS-bcbc36b7-328a-4545-8166-f1234840b4f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45460,DS-a1d3cba8-11a5-4b65-9d15-6220253db1c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1673475290-172.17.0.13-1597709466312:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33535,DS-5636759e-98fe-43c6-b2d7-cf86a114b412,DISK], DatanodeInfoWithStorage[127.0.0.1:45454,DS-8dab59b7-0f18-4f90-a13a-b44f28e4fb36,DISK], DatanodeInfoWithStorage[127.0.0.1:32990,DS-0ed05f7e-3667-4f1c-ba33-45bb7856ce08,DISK], DatanodeInfoWithStorage[127.0.0.1:43718,DS-104e2bc4-c7cd-47e0-a1d1-a780597d97b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45726,DS-330dd9d3-e755-413f-af9a-92a03e41358f,DISK], DatanodeInfoWithStorage[127.0.0.1:37945,DS-f461201f-e3ae-4548-92d1-b322b07ec6d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45682,DS-bcbc36b7-328a-4545-8166-f1234840b4f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45460,DS-a1d3cba8-11a5-4b65-9d15-6220253db1c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1807942084-172.17.0.13-1597709499194:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40904,DS-bd046653-757a-4431-b6c6-d6c912fb0e02,DISK], DatanodeInfoWithStorage[127.0.0.1:41522,DS-11a3c59b-d654-45c4-ac7f-163f147f63b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-6bb49dc6-24f9-40a5-9d86-0f8443303b02,DISK], DatanodeInfoWithStorage[127.0.0.1:33881,DS-0d53d9a4-7090-4e90-b2e5-b9ff17c1a310,DISK], DatanodeInfoWithStorage[127.0.0.1:35179,DS-3d134fe2-e908-4f94-a248-1628169b2531,DISK], DatanodeInfoWithStorage[127.0.0.1:39256,DS-b029a08e-f926-4562-a0ad-95e8f9a0ff4b,DISK], DatanodeInfoWithStorage[127.0.0.1:41656,DS-b433108a-33d5-4b37-a731-efa5dfbd7117,DISK], DatanodeInfoWithStorage[127.0.0.1:32880,DS-822d883a-5b08-42f6-8cc1-90d413feae29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1807942084-172.17.0.13-1597709499194:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40904,DS-bd046653-757a-4431-b6c6-d6c912fb0e02,DISK], DatanodeInfoWithStorage[127.0.0.1:41522,DS-11a3c59b-d654-45c4-ac7f-163f147f63b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-6bb49dc6-24f9-40a5-9d86-0f8443303b02,DISK], DatanodeInfoWithStorage[127.0.0.1:33881,DS-0d53d9a4-7090-4e90-b2e5-b9ff17c1a310,DISK], DatanodeInfoWithStorage[127.0.0.1:35179,DS-3d134fe2-e908-4f94-a248-1628169b2531,DISK], DatanodeInfoWithStorage[127.0.0.1:39256,DS-b029a08e-f926-4562-a0ad-95e8f9a0ff4b,DISK], DatanodeInfoWithStorage[127.0.0.1:41656,DS-b433108a-33d5-4b37-a731-efa5dfbd7117,DISK], DatanodeInfoWithStorage[127.0.0.1:32880,DS-822d883a-5b08-42f6-8cc1-90d413feae29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-52795696-172.17.0.13-1597709772414:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46862,DS-42a54cd0-a843-4b49-91e5-a3ca3c548c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:34426,DS-e45d7f2d-36ef-49eb-ac02-15e2b3392986,DISK], DatanodeInfoWithStorage[127.0.0.1:42972,DS-a05e039d-3367-43ec-94bd-292e915aa3d9,DISK], DatanodeInfoWithStorage[127.0.0.1:32882,DS-cd761e02-2d05-4ad6-b529-c3258f9825f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45200,DS-51904dbe-ab28-47c2-9182-57c4b1b58c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:36000,DS-6ea0c5a9-302f-453f-b6fe-1507240fc65d,DISK], DatanodeInfoWithStorage[127.0.0.1:37440,DS-f5699781-8feb-4963-a4fa-14c1dd280929,DISK], DatanodeInfoWithStorage[127.0.0.1:42669,DS-87ad8fa4-aea6-42ee-a2a5-ee2b161f6bdf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-52795696-172.17.0.13-1597709772414:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46862,DS-42a54cd0-a843-4b49-91e5-a3ca3c548c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:34426,DS-e45d7f2d-36ef-49eb-ac02-15e2b3392986,DISK], DatanodeInfoWithStorage[127.0.0.1:42972,DS-a05e039d-3367-43ec-94bd-292e915aa3d9,DISK], DatanodeInfoWithStorage[127.0.0.1:32882,DS-cd761e02-2d05-4ad6-b529-c3258f9825f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45200,DS-51904dbe-ab28-47c2-9182-57c4b1b58c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:36000,DS-6ea0c5a9-302f-453f-b6fe-1507240fc65d,DISK], DatanodeInfoWithStorage[127.0.0.1:37440,DS-f5699781-8feb-4963-a4fa-14c1dd280929,DISK], DatanodeInfoWithStorage[127.0.0.1:42669,DS-87ad8fa4-aea6-42ee-a2a5-ee2b161f6bdf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1995198630-172.17.0.13-1597709898347:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36722,DS-3510854c-6003-4ab3-91ab-ea520dec9b30,DISK], DatanodeInfoWithStorage[127.0.0.1:42180,DS-cebbd4bb-746d-4c9c-beec-68fbcaf251cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39812,DS-c0bde7c2-fe4b-4d6e-a9b0-c0269caf470a,DISK], DatanodeInfoWithStorage[127.0.0.1:36736,DS-30b32965-6a5e-42b5-a245-24a1eafa3e49,DISK], DatanodeInfoWithStorage[127.0.0.1:46534,DS-8196efd7-7ad2-4c05-8e12-aab39f34d849,DISK], DatanodeInfoWithStorage[127.0.0.1:39586,DS-442ab47f-b4d1-4046-8926-c604fcd39574,DISK], DatanodeInfoWithStorage[127.0.0.1:43952,DS-a0a97b34-fe8b-4255-b69e-0a3cb5a0f888,DISK], DatanodeInfoWithStorage[127.0.0.1:44559,DS-090d3656-76c4-42e2-8eb1-737364f078cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1995198630-172.17.0.13-1597709898347:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36722,DS-3510854c-6003-4ab3-91ab-ea520dec9b30,DISK], DatanodeInfoWithStorage[127.0.0.1:42180,DS-cebbd4bb-746d-4c9c-beec-68fbcaf251cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39812,DS-c0bde7c2-fe4b-4d6e-a9b0-c0269caf470a,DISK], DatanodeInfoWithStorage[127.0.0.1:36736,DS-30b32965-6a5e-42b5-a245-24a1eafa3e49,DISK], DatanodeInfoWithStorage[127.0.0.1:46534,DS-8196efd7-7ad2-4c05-8e12-aab39f34d849,DISK], DatanodeInfoWithStorage[127.0.0.1:39586,DS-442ab47f-b4d1-4046-8926-c604fcd39574,DISK], DatanodeInfoWithStorage[127.0.0.1:43952,DS-a0a97b34-fe8b-4255-b69e-0a3cb5a0f888,DISK], DatanodeInfoWithStorage[127.0.0.1:44559,DS-090d3656-76c4-42e2-8eb1-737364f078cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1290438523-172.17.0.13-1597709940640:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35111,DS-a7ee2bec-4d10-4ec3-9f0a-bbbfd3be461f,DISK], DatanodeInfoWithStorage[127.0.0.1:44082,DS-7ad4f620-ca4b-4e2a-9469-fb3f8aa23786,DISK], DatanodeInfoWithStorage[127.0.0.1:39620,DS-f531fec4-2fdb-4533-890b-132271b8ef7c,DISK], DatanodeInfoWithStorage[127.0.0.1:36315,DS-c8eaf1e7-6637-49e8-9ae9-fc59c0dc387e,DISK], DatanodeInfoWithStorage[127.0.0.1:41219,DS-9f05baee-e6a8-4369-ac9d-19aa28930ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:36500,DS-2383b3d0-083a-4998-9312-33ff401b03fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37262,DS-b3ac3f59-298b-4e53-953f-eaab6420e57a,DISK], DatanodeInfoWithStorage[127.0.0.1:38458,DS-4a75737f-7fb7-46da-8c2e-909b1de932d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1290438523-172.17.0.13-1597709940640:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35111,DS-a7ee2bec-4d10-4ec3-9f0a-bbbfd3be461f,DISK], DatanodeInfoWithStorage[127.0.0.1:44082,DS-7ad4f620-ca4b-4e2a-9469-fb3f8aa23786,DISK], DatanodeInfoWithStorage[127.0.0.1:39620,DS-f531fec4-2fdb-4533-890b-132271b8ef7c,DISK], DatanodeInfoWithStorage[127.0.0.1:36315,DS-c8eaf1e7-6637-49e8-9ae9-fc59c0dc387e,DISK], DatanodeInfoWithStorage[127.0.0.1:41219,DS-9f05baee-e6a8-4369-ac9d-19aa28930ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:36500,DS-2383b3d0-083a-4998-9312-33ff401b03fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37262,DS-b3ac3f59-298b-4e53-953f-eaab6420e57a,DISK], DatanodeInfoWithStorage[127.0.0.1:38458,DS-4a75737f-7fb7-46da-8c2e-909b1de932d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1987892188-172.17.0.13-1597710196660:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36809,DS-36d30bce-44aa-43a8-862d-8553d152069c,DISK], DatanodeInfoWithStorage[127.0.0.1:46210,DS-266d9422-0d15-4d81-8bee-9edf24c24c33,DISK], DatanodeInfoWithStorage[127.0.0.1:35982,DS-f864cd7b-e630-45c5-a47a-267d9036a3bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38999,DS-938f74bc-d6b7-4600-ae7a-2ab7369e7e11,DISK], DatanodeInfoWithStorage[127.0.0.1:39461,DS-d56b1dec-b63a-4b7c-83df-5a5450943816,DISK], DatanodeInfoWithStorage[127.0.0.1:39822,DS-ce61b76d-da22-4ab1-a676-68c5fa583169,DISK], DatanodeInfoWithStorage[127.0.0.1:41423,DS-b0032154-5b25-4b26-afe8-2a17510d2eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:42546,DS-a22e8234-ce5b-4aff-b035-498c5293ca1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1987892188-172.17.0.13-1597710196660:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36809,DS-36d30bce-44aa-43a8-862d-8553d152069c,DISK], DatanodeInfoWithStorage[127.0.0.1:46210,DS-266d9422-0d15-4d81-8bee-9edf24c24c33,DISK], DatanodeInfoWithStorage[127.0.0.1:35982,DS-f864cd7b-e630-45c5-a47a-267d9036a3bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38999,DS-938f74bc-d6b7-4600-ae7a-2ab7369e7e11,DISK], DatanodeInfoWithStorage[127.0.0.1:39461,DS-d56b1dec-b63a-4b7c-83df-5a5450943816,DISK], DatanodeInfoWithStorage[127.0.0.1:39822,DS-ce61b76d-da22-4ab1-a676-68c5fa583169,DISK], DatanodeInfoWithStorage[127.0.0.1:41423,DS-b0032154-5b25-4b26-afe8-2a17510d2eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:42546,DS-a22e8234-ce5b-4aff-b035-498c5293ca1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-270385885-172.17.0.13-1597710235220:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34603,DS-aade7e8f-d822-466b-8f33-6216a4f5d1a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36214,DS-80e1be59-f998-4368-ad79-5ec418885b04,DISK], DatanodeInfoWithStorage[127.0.0.1:40202,DS-b809e50f-9a34-40d2-8b0b-6a4b3f1e11ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44206,DS-855592bd-7809-4af4-8657-2da17b320901,DISK], DatanodeInfoWithStorage[127.0.0.1:38160,DS-fa17c2d9-5cf7-4d9a-8df1-82c8ea8cacaf,DISK], DatanodeInfoWithStorage[127.0.0.1:46761,DS-551af65a-5ee4-4bac-88ee-45e2e16aaae1,DISK], DatanodeInfoWithStorage[127.0.0.1:39369,DS-dd2b1c9a-2a27-44ca-b050-3522e6718f22,DISK], DatanodeInfoWithStorage[127.0.0.1:46495,DS-82c9755c-d436-44a9-835e-974e02dacbb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-270385885-172.17.0.13-1597710235220:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34603,DS-aade7e8f-d822-466b-8f33-6216a4f5d1a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36214,DS-80e1be59-f998-4368-ad79-5ec418885b04,DISK], DatanodeInfoWithStorage[127.0.0.1:40202,DS-b809e50f-9a34-40d2-8b0b-6a4b3f1e11ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44206,DS-855592bd-7809-4af4-8657-2da17b320901,DISK], DatanodeInfoWithStorage[127.0.0.1:38160,DS-fa17c2d9-5cf7-4d9a-8df1-82c8ea8cacaf,DISK], DatanodeInfoWithStorage[127.0.0.1:46761,DS-551af65a-5ee4-4bac-88ee-45e2e16aaae1,DISK], DatanodeInfoWithStorage[127.0.0.1:39369,DS-dd2b1c9a-2a27-44ca-b050-3522e6718f22,DISK], DatanodeInfoWithStorage[127.0.0.1:46495,DS-82c9755c-d436-44a9-835e-974e02dacbb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1475561017-172.17.0.13-1597710355947:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37319,DS-aae4b3d2-3ba4-4a27-85e7-2de99d016c46,DISK], DatanodeInfoWithStorage[127.0.0.1:37979,DS-8c9c9c8b-3a4d-4f53-909f-eb42f936ff6f,DISK], DatanodeInfoWithStorage[127.0.0.1:45693,DS-3d3e50c2-b9f7-4e67-9c33-d7775c1b1630,DISK], DatanodeInfoWithStorage[127.0.0.1:37210,DS-cf4dcd7c-6d7b-4b04-9403-fe8d30c10b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37696,DS-61eafc01-5fcb-40dd-a97b-19da760d9f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40305,DS-4a3ab3fa-1d5d-46f5-8e8c-07517bd6ceb7,DISK], DatanodeInfoWithStorage[127.0.0.1:39645,DS-0b01dff2-ee4f-4963-85e0-a369a3f1a91a,DISK], DatanodeInfoWithStorage[127.0.0.1:42741,DS-cf8326db-d9de-425f-9801-f202d81a3a72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1475561017-172.17.0.13-1597710355947:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37319,DS-aae4b3d2-3ba4-4a27-85e7-2de99d016c46,DISK], DatanodeInfoWithStorage[127.0.0.1:37979,DS-8c9c9c8b-3a4d-4f53-909f-eb42f936ff6f,DISK], DatanodeInfoWithStorage[127.0.0.1:45693,DS-3d3e50c2-b9f7-4e67-9c33-d7775c1b1630,DISK], DatanodeInfoWithStorage[127.0.0.1:37210,DS-cf4dcd7c-6d7b-4b04-9403-fe8d30c10b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37696,DS-61eafc01-5fcb-40dd-a97b-19da760d9f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40305,DS-4a3ab3fa-1d5d-46f5-8e8c-07517bd6ceb7,DISK], DatanodeInfoWithStorage[127.0.0.1:39645,DS-0b01dff2-ee4f-4963-85e0-a369a3f1a91a,DISK], DatanodeInfoWithStorage[127.0.0.1:42741,DS-cf8326db-d9de-425f-9801-f202d81a3a72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-989604195-172.17.0.13-1597710632195:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43787,DS-a7df0f14-e757-4081-b44c-ade3409cb731,DISK], DatanodeInfoWithStorage[127.0.0.1:46089,DS-4a2941c4-1f57-4b3f-b14c-ae58fe1f000b,DISK], DatanodeInfoWithStorage[127.0.0.1:33603,DS-40a3c64b-c0d6-44b9-aa55-0e37d3cb4b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:34164,DS-7d375ba6-1674-4d85-9cbf-f74192869a66,DISK], DatanodeInfoWithStorage[127.0.0.1:34526,DS-dc6f4d0e-fd5c-4924-9dda-9dd64c93c842,DISK], DatanodeInfoWithStorage[127.0.0.1:39708,DS-ef8500a1-b09f-45a9-b022-40cf3e764b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:45110,DS-ecf44a5a-0a67-4e03-a07b-478e891c1206,DISK], DatanodeInfoWithStorage[127.0.0.1:40903,DS-967277c8-8977-49c3-a952-d86873efc2b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-989604195-172.17.0.13-1597710632195:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43787,DS-a7df0f14-e757-4081-b44c-ade3409cb731,DISK], DatanodeInfoWithStorage[127.0.0.1:46089,DS-4a2941c4-1f57-4b3f-b14c-ae58fe1f000b,DISK], DatanodeInfoWithStorage[127.0.0.1:33603,DS-40a3c64b-c0d6-44b9-aa55-0e37d3cb4b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:34164,DS-7d375ba6-1674-4d85-9cbf-f74192869a66,DISK], DatanodeInfoWithStorage[127.0.0.1:34526,DS-dc6f4d0e-fd5c-4924-9dda-9dd64c93c842,DISK], DatanodeInfoWithStorage[127.0.0.1:39708,DS-ef8500a1-b09f-45a9-b022-40cf3e764b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:45110,DS-ecf44a5a-0a67-4e03-a07b-478e891c1206,DISK], DatanodeInfoWithStorage[127.0.0.1:40903,DS-967277c8-8977-49c3-a952-d86873efc2b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1303254301-172.17.0.13-1597711111822:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36317,DS-f5a4be17-5be9-414c-9fea-a0fc1af41b62,DISK], DatanodeInfoWithStorage[127.0.0.1:33582,DS-bb6170fa-9a79-4c2a-94d0-b373784fc5b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35905,DS-f5ed71e5-f0fa-4100-b1bd-edea3c144fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:34175,DS-7978ec59-fe5a-4baf-bc77-981295dad74d,DISK], DatanodeInfoWithStorage[127.0.0.1:36671,DS-2625cc55-a083-4c7f-9ecb-9f61461cc774,DISK], DatanodeInfoWithStorage[127.0.0.1:46550,DS-175cbd86-853a-4913-a340-71bbc61ff3f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-b905fccd-fd81-467d-a05f-e0fd394fdb86,DISK], DatanodeInfoWithStorage[127.0.0.1:42019,DS-9236149d-5453-40d3-a2c9-d5c86477619f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1303254301-172.17.0.13-1597711111822:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36317,DS-f5a4be17-5be9-414c-9fea-a0fc1af41b62,DISK], DatanodeInfoWithStorage[127.0.0.1:33582,DS-bb6170fa-9a79-4c2a-94d0-b373784fc5b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35905,DS-f5ed71e5-f0fa-4100-b1bd-edea3c144fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:34175,DS-7978ec59-fe5a-4baf-bc77-981295dad74d,DISK], DatanodeInfoWithStorage[127.0.0.1:36671,DS-2625cc55-a083-4c7f-9ecb-9f61461cc774,DISK], DatanodeInfoWithStorage[127.0.0.1:46550,DS-175cbd86-853a-4913-a340-71bbc61ff3f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-b905fccd-fd81-467d-a05f-e0fd394fdb86,DISK], DatanodeInfoWithStorage[127.0.0.1:42019,DS-9236149d-5453-40d3-a2c9-d5c86477619f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1242493872-172.17.0.13-1597711460344:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44089,DS-88cfbbea-f3da-4d19-a131-42da3bfd6488,DISK], DatanodeInfoWithStorage[127.0.0.1:40482,DS-f8ead3bf-e96a-4ad2-b918-bcb809dbcc3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46435,DS-9f49b6ed-f719-4dec-bb3f-3be569c6f44f,DISK], DatanodeInfoWithStorage[127.0.0.1:33510,DS-68c421f6-593e-4872-aed6-37c8ba525184,DISK], DatanodeInfoWithStorage[127.0.0.1:40192,DS-7c2c731c-0e3c-47e1-bcc6-3e007101c8e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39538,DS-04397cf8-ce40-4ab7-a793-591e28d3b53e,DISK], DatanodeInfoWithStorage[127.0.0.1:44620,DS-eac35cf7-887c-4b1c-995e-6fc386afdae5,DISK], DatanodeInfoWithStorage[127.0.0.1:39802,DS-ff9ded6c-b730-4aa8-b394-0aae8f893ea7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1242493872-172.17.0.13-1597711460344:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44089,DS-88cfbbea-f3da-4d19-a131-42da3bfd6488,DISK], DatanodeInfoWithStorage[127.0.0.1:40482,DS-f8ead3bf-e96a-4ad2-b918-bcb809dbcc3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46435,DS-9f49b6ed-f719-4dec-bb3f-3be569c6f44f,DISK], DatanodeInfoWithStorage[127.0.0.1:33510,DS-68c421f6-593e-4872-aed6-37c8ba525184,DISK], DatanodeInfoWithStorage[127.0.0.1:40192,DS-7c2c731c-0e3c-47e1-bcc6-3e007101c8e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39538,DS-04397cf8-ce40-4ab7-a793-591e28d3b53e,DISK], DatanodeInfoWithStorage[127.0.0.1:44620,DS-eac35cf7-887c-4b1c-995e-6fc386afdae5,DISK], DatanodeInfoWithStorage[127.0.0.1:39802,DS-ff9ded6c-b730-4aa8-b394-0aae8f893ea7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1496334073-172.17.0.13-1597711691224:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39375,DS-9c34c8e8-d422-4184-ae76-63578f261f66,DISK], DatanodeInfoWithStorage[127.0.0.1:37010,DS-832ca278-b320-4b6c-962e-caf5632f6b28,DISK], DatanodeInfoWithStorage[127.0.0.1:37211,DS-c2b2172c-9c95-4898-a5d1-848189bff724,DISK], DatanodeInfoWithStorage[127.0.0.1:38020,DS-5d402a1f-f789-41f7-8af2-74453959afbe,DISK], DatanodeInfoWithStorage[127.0.0.1:35942,DS-c3229f79-6e78-4014-a540-0d5fc522674b,DISK], DatanodeInfoWithStorage[127.0.0.1:33319,DS-b1fd00c0-b34b-4436-9db3-5186d0c77249,DISK], DatanodeInfoWithStorage[127.0.0.1:38950,DS-240b2db8-637e-409e-94d3-5187538eb68f,DISK], DatanodeInfoWithStorage[127.0.0.1:40889,DS-0d0e9b90-e1d2-413f-aa75-b856a1d19871,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1496334073-172.17.0.13-1597711691224:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39375,DS-9c34c8e8-d422-4184-ae76-63578f261f66,DISK], DatanodeInfoWithStorage[127.0.0.1:37010,DS-832ca278-b320-4b6c-962e-caf5632f6b28,DISK], DatanodeInfoWithStorage[127.0.0.1:37211,DS-c2b2172c-9c95-4898-a5d1-848189bff724,DISK], DatanodeInfoWithStorage[127.0.0.1:38020,DS-5d402a1f-f789-41f7-8af2-74453959afbe,DISK], DatanodeInfoWithStorage[127.0.0.1:35942,DS-c3229f79-6e78-4014-a540-0d5fc522674b,DISK], DatanodeInfoWithStorage[127.0.0.1:33319,DS-b1fd00c0-b34b-4436-9db3-5186d0c77249,DISK], DatanodeInfoWithStorage[127.0.0.1:38950,DS-240b2db8-637e-409e-94d3-5187538eb68f,DISK], DatanodeInfoWithStorage[127.0.0.1:40889,DS-0d0e9b90-e1d2-413f-aa75-b856a1d19871,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-341522468-172.17.0.13-1597711833679:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46866,DS-5589b8ff-a5df-4861-bef1-216bdf6dabf6,DISK], DatanodeInfoWithStorage[127.0.0.1:44002,DS-3efcf144-9e79-4f8b-98b5-a34399864d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34414,DS-7b210e8b-89f8-490d-b0c3-3b730b9a63b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43343,DS-164840dc-c88f-4510-a4d7-615c44a1e5cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41529,DS-8a3cbbaa-2aaa-40fc-a337-190f5068887b,DISK], DatanodeInfoWithStorage[127.0.0.1:35228,DS-1528480d-0fb6-4253-83a9-898125bae4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44532,DS-37b6f285-fdcc-44cc-8294-f46cc30b800d,DISK], DatanodeInfoWithStorage[127.0.0.1:38982,DS-37c2f606-c93e-4e1d-8ed0-f5ced1da1bba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-341522468-172.17.0.13-1597711833679:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46866,DS-5589b8ff-a5df-4861-bef1-216bdf6dabf6,DISK], DatanodeInfoWithStorage[127.0.0.1:44002,DS-3efcf144-9e79-4f8b-98b5-a34399864d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34414,DS-7b210e8b-89f8-490d-b0c3-3b730b9a63b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43343,DS-164840dc-c88f-4510-a4d7-615c44a1e5cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41529,DS-8a3cbbaa-2aaa-40fc-a337-190f5068887b,DISK], DatanodeInfoWithStorage[127.0.0.1:35228,DS-1528480d-0fb6-4253-83a9-898125bae4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44532,DS-37b6f285-fdcc-44cc-8294-f46cc30b800d,DISK], DatanodeInfoWithStorage[127.0.0.1:38982,DS-37c2f606-c93e-4e1d-8ed0-f5ced1da1bba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-631235785-172.17.0.13-1597711943919:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45636,DS-d4a12535-99a9-49f1-9036-92efa03c16bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44253,DS-81485856-0801-4aa8-9e2c-9be30fa74003,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-0a1a3361-9747-47cd-b7be-838581b63dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:33326,DS-9864dd17-3157-4197-8162-44992987b5c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44544,DS-87f14e3d-8c64-48c8-9dad-0ed2425895dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39336,DS-efe4896b-5d6f-43e9-88f2-98bad5294240,DISK], DatanodeInfoWithStorage[127.0.0.1:43914,DS-12bf6997-1a42-4eae-a8d9-94e64ee034b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46743,DS-f5bc16e5-dd16-4ae1-a51c-6d5b057064c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-631235785-172.17.0.13-1597711943919:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45636,DS-d4a12535-99a9-49f1-9036-92efa03c16bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44253,DS-81485856-0801-4aa8-9e2c-9be30fa74003,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-0a1a3361-9747-47cd-b7be-838581b63dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:33326,DS-9864dd17-3157-4197-8162-44992987b5c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44544,DS-87f14e3d-8c64-48c8-9dad-0ed2425895dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39336,DS-efe4896b-5d6f-43e9-88f2-98bad5294240,DISK], DatanodeInfoWithStorage[127.0.0.1:43914,DS-12bf6997-1a42-4eae-a8d9-94e64ee034b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46743,DS-f5bc16e5-dd16-4ae1-a51c-6d5b057064c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2145081937-172.17.0.13-1597712237261:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43831,DS-02e89340-9597-45a1-a959-ec5525f14c18,DISK], DatanodeInfoWithStorage[127.0.0.1:39867,DS-a39befe8-073c-4496-9109-74fbfc3d24d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38284,DS-92b99845-d230-40e0-9e9c-3a8a51cbc022,DISK], DatanodeInfoWithStorage[127.0.0.1:33750,DS-be6e6f04-4595-48de-97ac-e6c09ab7fcf2,DISK], DatanodeInfoWithStorage[127.0.0.1:40487,DS-d5c7733c-371b-475d-abb0-9f6221250b52,DISK], DatanodeInfoWithStorage[127.0.0.1:36354,DS-8e6735b4-5251-4cc0-9a82-eb98d22a0309,DISK], DatanodeInfoWithStorage[127.0.0.1:38968,DS-862b98da-98d3-46c7-b1ff-c0afc0ed055d,DISK], DatanodeInfoWithStorage[127.0.0.1:46662,DS-28078c8d-90aa-4d16-ad75-cb0de338e5eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2145081937-172.17.0.13-1597712237261:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43831,DS-02e89340-9597-45a1-a959-ec5525f14c18,DISK], DatanodeInfoWithStorage[127.0.0.1:39867,DS-a39befe8-073c-4496-9109-74fbfc3d24d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38284,DS-92b99845-d230-40e0-9e9c-3a8a51cbc022,DISK], DatanodeInfoWithStorage[127.0.0.1:33750,DS-be6e6f04-4595-48de-97ac-e6c09ab7fcf2,DISK], DatanodeInfoWithStorage[127.0.0.1:40487,DS-d5c7733c-371b-475d-abb0-9f6221250b52,DISK], DatanodeInfoWithStorage[127.0.0.1:36354,DS-8e6735b4-5251-4cc0-9a82-eb98d22a0309,DISK], DatanodeInfoWithStorage[127.0.0.1:38968,DS-862b98da-98d3-46c7-b1ff-c0afc0ed055d,DISK], DatanodeInfoWithStorage[127.0.0.1:46662,DS-28078c8d-90aa-4d16-ad75-cb0de338e5eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1905498296-172.17.0.13-1597712955759:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36735,DS-528d94e9-5df3-46c3-8636-09322b9849d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37904,DS-a3d27e43-4d37-45a0-a8bd-cce1a464866b,DISK], DatanodeInfoWithStorage[127.0.0.1:39952,DS-e26ac331-0b21-4a16-ba07-64783b0e5ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:42955,DS-4d62f790-d159-4a34-a966-f6bd6f36cfc2,DISK], DatanodeInfoWithStorage[127.0.0.1:33723,DS-2c954fb5-835b-450d-beeb-f157436240f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42716,DS-f537948d-276b-4ed1-8ab2-0052f8584d81,DISK], DatanodeInfoWithStorage[127.0.0.1:40101,DS-1f0aaf6b-1622-4a5d-8ec9-e016b67a0fca,DISK], DatanodeInfoWithStorage[127.0.0.1:45973,DS-c64e3129-11ce-4d48-ba22-ad330b76b6e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1905498296-172.17.0.13-1597712955759:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36735,DS-528d94e9-5df3-46c3-8636-09322b9849d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37904,DS-a3d27e43-4d37-45a0-a8bd-cce1a464866b,DISK], DatanodeInfoWithStorage[127.0.0.1:39952,DS-e26ac331-0b21-4a16-ba07-64783b0e5ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:42955,DS-4d62f790-d159-4a34-a966-f6bd6f36cfc2,DISK], DatanodeInfoWithStorage[127.0.0.1:33723,DS-2c954fb5-835b-450d-beeb-f157436240f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42716,DS-f537948d-276b-4ed1-8ab2-0052f8584d81,DISK], DatanodeInfoWithStorage[127.0.0.1:40101,DS-1f0aaf6b-1622-4a5d-8ec9-e016b67a0fca,DISK], DatanodeInfoWithStorage[127.0.0.1:45973,DS-c64e3129-11ce-4d48-ba22-ad330b76b6e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-140007561-172.17.0.13-1597713375495:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38816,DS-91c10ccc-d586-4949-a66e-8eb6450ae065,DISK], DatanodeInfoWithStorage[127.0.0.1:42036,DS-b4e42a25-d96f-4068-9a7f-2ac6016bd4ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42959,DS-d0172064-d6c1-4d59-9125-316dca06b091,DISK], DatanodeInfoWithStorage[127.0.0.1:39573,DS-32fbfe91-742e-4f3c-983d-5291f71cc2c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44638,DS-c035a78b-9e38-414b-85f0-d3c9515de51f,DISK], DatanodeInfoWithStorage[127.0.0.1:34599,DS-44a18bf0-0cb0-4b43-9837-3fd4545b256f,DISK], DatanodeInfoWithStorage[127.0.0.1:34433,DS-25d713ef-e402-4433-870b-e732b0319dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:45882,DS-33a50d78-6d46-475f-b89e-cb196f8b9c98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-140007561-172.17.0.13-1597713375495:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38816,DS-91c10ccc-d586-4949-a66e-8eb6450ae065,DISK], DatanodeInfoWithStorage[127.0.0.1:42036,DS-b4e42a25-d96f-4068-9a7f-2ac6016bd4ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42959,DS-d0172064-d6c1-4d59-9125-316dca06b091,DISK], DatanodeInfoWithStorage[127.0.0.1:39573,DS-32fbfe91-742e-4f3c-983d-5291f71cc2c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44638,DS-c035a78b-9e38-414b-85f0-d3c9515de51f,DISK], DatanodeInfoWithStorage[127.0.0.1:34599,DS-44a18bf0-0cb0-4b43-9837-3fd4545b256f,DISK], DatanodeInfoWithStorage[127.0.0.1:34433,DS-25d713ef-e402-4433-870b-e732b0319dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:45882,DS-33a50d78-6d46-475f-b89e-cb196f8b9c98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-631928731-172.17.0.13-1597713408402:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35191,DS-d2b99f1d-fb6c-40f2-88e7-93c64f31f93e,DISK], DatanodeInfoWithStorage[127.0.0.1:35268,DS-d591973f-65d6-4f02-800e-5b9f26a5ac60,DISK], DatanodeInfoWithStorage[127.0.0.1:37192,DS-51c41ae1-18cc-4cfd-ba87-a3b2a20d953c,DISK], DatanodeInfoWithStorage[127.0.0.1:43093,DS-aa3288a9-210e-4ebf-84dd-fadeac54680b,DISK], DatanodeInfoWithStorage[127.0.0.1:37190,DS-ca5eefa6-966c-45c7-982d-d3b62c2b8933,DISK], DatanodeInfoWithStorage[127.0.0.1:37634,DS-8035afa5-4e97-45f5-ac9b-3cb5c50c2ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:38177,DS-29de54ba-51a7-413f-ad06-6f14784ace59,DISK], DatanodeInfoWithStorage[127.0.0.1:42877,DS-e94d18a6-4e3f-4c9b-9762-4a0c68f2c5fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-631928731-172.17.0.13-1597713408402:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35191,DS-d2b99f1d-fb6c-40f2-88e7-93c64f31f93e,DISK], DatanodeInfoWithStorage[127.0.0.1:35268,DS-d591973f-65d6-4f02-800e-5b9f26a5ac60,DISK], DatanodeInfoWithStorage[127.0.0.1:37192,DS-51c41ae1-18cc-4cfd-ba87-a3b2a20d953c,DISK], DatanodeInfoWithStorage[127.0.0.1:43093,DS-aa3288a9-210e-4ebf-84dd-fadeac54680b,DISK], DatanodeInfoWithStorage[127.0.0.1:37190,DS-ca5eefa6-966c-45c7-982d-d3b62c2b8933,DISK], DatanodeInfoWithStorage[127.0.0.1:37634,DS-8035afa5-4e97-45f5-ac9b-3cb5c50c2ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:38177,DS-29de54ba-51a7-413f-ad06-6f14784ace59,DISK], DatanodeInfoWithStorage[127.0.0.1:42877,DS-e94d18a6-4e3f-4c9b-9762-4a0c68f2c5fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1662955148-172.17.0.13-1597713485088:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44080,DS-fa47aab6-112e-48c0-b92f-bf69270493da,DISK], DatanodeInfoWithStorage[127.0.0.1:45189,DS-e5378f32-6af7-4647-95f1-36603f8dff5a,DISK], DatanodeInfoWithStorage[127.0.0.1:41010,DS-1a3857b5-1b04-41c2-bbeb-f50b731a975b,DISK], DatanodeInfoWithStorage[127.0.0.1:41058,DS-c8db4782-b02d-4686-9eaa-27188a32b8f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39760,DS-c7ee1abd-63c2-4f3a-af90-5372b49705d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37143,DS-114d0a2c-6c85-48a7-ade8-8ef9be027dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:40899,DS-a646d985-ec71-43bf-b5e9-b1d970365173,DISK], DatanodeInfoWithStorage[127.0.0.1:36962,DS-2f6e998d-719c-4abd-ab4a-5a707b3266df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1662955148-172.17.0.13-1597713485088:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44080,DS-fa47aab6-112e-48c0-b92f-bf69270493da,DISK], DatanodeInfoWithStorage[127.0.0.1:45189,DS-e5378f32-6af7-4647-95f1-36603f8dff5a,DISK], DatanodeInfoWithStorage[127.0.0.1:41010,DS-1a3857b5-1b04-41c2-bbeb-f50b731a975b,DISK], DatanodeInfoWithStorage[127.0.0.1:41058,DS-c8db4782-b02d-4686-9eaa-27188a32b8f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39760,DS-c7ee1abd-63c2-4f3a-af90-5372b49705d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37143,DS-114d0a2c-6c85-48a7-ade8-8ef9be027dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:40899,DS-a646d985-ec71-43bf-b5e9-b1d970365173,DISK], DatanodeInfoWithStorage[127.0.0.1:36962,DS-2f6e998d-719c-4abd-ab4a-5a707b3266df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5562
