reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-95030363-172.17.0.13-1597455648450:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39729,DS-ebb2c3af-c647-4e49-b72e-f118b65c20f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41979,DS-8d92b8bf-9786-49af-a7c6-0a8cb83ba64f,DISK], DatanodeInfoWithStorage[127.0.0.1:41133,DS-87df796b-77b0-49d1-a41b-a0a3afbc55cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46178,DS-4fceedb3-9361-403f-9bf0-9cc9998a3384,DISK], DatanodeInfoWithStorage[127.0.0.1:37805,DS-048a433d-aab7-4ae8-8b87-13a78529df88,DISK], DatanodeInfoWithStorage[127.0.0.1:42045,DS-60d450de-4765-43d7-a072-a6fe3a429e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44606,DS-f89069c8-49bd-4c11-bf6b-d4203eb12b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:39624,DS-365931be-32e8-4812-a5ef-5622814d5c15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-95030363-172.17.0.13-1597455648450:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39729,DS-ebb2c3af-c647-4e49-b72e-f118b65c20f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41979,DS-8d92b8bf-9786-49af-a7c6-0a8cb83ba64f,DISK], DatanodeInfoWithStorage[127.0.0.1:41133,DS-87df796b-77b0-49d1-a41b-a0a3afbc55cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46178,DS-4fceedb3-9361-403f-9bf0-9cc9998a3384,DISK], DatanodeInfoWithStorage[127.0.0.1:37805,DS-048a433d-aab7-4ae8-8b87-13a78529df88,DISK], DatanodeInfoWithStorage[127.0.0.1:42045,DS-60d450de-4765-43d7-a072-a6fe3a429e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44606,DS-f89069c8-49bd-4c11-bf6b-d4203eb12b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:39624,DS-365931be-32e8-4812-a5ef-5622814d5c15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1211846162-172.17.0.13-1597456245636:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35633,DS-eece171c-8714-4fd8-b71b-2a93e89a8f41,DISK], DatanodeInfoWithStorage[127.0.0.1:35548,DS-d4e95201-fdf0-425f-a292-3ee94958556e,DISK], DatanodeInfoWithStorage[127.0.0.1:45091,DS-2b2e78d0-9af3-4f13-aaa5-265dc47bc997,DISK], DatanodeInfoWithStorage[127.0.0.1:33462,DS-b891aeef-c66f-4581-bba0-6151c539efbb,DISK], DatanodeInfoWithStorage[127.0.0.1:40918,DS-38aeddd0-71a4-4d39-8323-895f6fa02770,DISK], DatanodeInfoWithStorage[127.0.0.1:45512,DS-30bc7014-9a97-4e9f-b500-66fb1260187a,DISK], DatanodeInfoWithStorage[127.0.0.1:44336,DS-253fde1d-ec50-4809-b60c-95da0c17937e,DISK], DatanodeInfoWithStorage[127.0.0.1:36652,DS-31a8f610-0879-4caa-852f-218a138a5b16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1211846162-172.17.0.13-1597456245636:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35633,DS-eece171c-8714-4fd8-b71b-2a93e89a8f41,DISK], DatanodeInfoWithStorage[127.0.0.1:35548,DS-d4e95201-fdf0-425f-a292-3ee94958556e,DISK], DatanodeInfoWithStorage[127.0.0.1:45091,DS-2b2e78d0-9af3-4f13-aaa5-265dc47bc997,DISK], DatanodeInfoWithStorage[127.0.0.1:33462,DS-b891aeef-c66f-4581-bba0-6151c539efbb,DISK], DatanodeInfoWithStorage[127.0.0.1:40918,DS-38aeddd0-71a4-4d39-8323-895f6fa02770,DISK], DatanodeInfoWithStorage[127.0.0.1:45512,DS-30bc7014-9a97-4e9f-b500-66fb1260187a,DISK], DatanodeInfoWithStorage[127.0.0.1:44336,DS-253fde1d-ec50-4809-b60c-95da0c17937e,DISK], DatanodeInfoWithStorage[127.0.0.1:36652,DS-31a8f610-0879-4caa-852f-218a138a5b16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1177343584-172.17.0.13-1597456889706:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36101,DS-c61930b0-4059-4950-9e27-1940e3ec0d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43318,DS-acdf40fd-58ed-42af-b368-b48dc6d1723d,DISK], DatanodeInfoWithStorage[127.0.0.1:40307,DS-f5c47dfd-a0c8-45d5-ad61-635d91bbc09b,DISK], DatanodeInfoWithStorage[127.0.0.1:39256,DS-7b171185-7406-4ffd-80de-74cae368ab4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45356,DS-8e795403-7ea6-48d1-8b07-38a25d62a887,DISK], DatanodeInfoWithStorage[127.0.0.1:36229,DS-c2c40660-bb3d-487b-ba72-06032a1fbb96,DISK], DatanodeInfoWithStorage[127.0.0.1:43185,DS-be845c0c-41d4-45f2-addf-ba0d54e74a65,DISK], DatanodeInfoWithStorage[127.0.0.1:39451,DS-576fa855-8787-4918-88c0-f3a47035061b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1177343584-172.17.0.13-1597456889706:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36101,DS-c61930b0-4059-4950-9e27-1940e3ec0d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43318,DS-acdf40fd-58ed-42af-b368-b48dc6d1723d,DISK], DatanodeInfoWithStorage[127.0.0.1:40307,DS-f5c47dfd-a0c8-45d5-ad61-635d91bbc09b,DISK], DatanodeInfoWithStorage[127.0.0.1:39256,DS-7b171185-7406-4ffd-80de-74cae368ab4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45356,DS-8e795403-7ea6-48d1-8b07-38a25d62a887,DISK], DatanodeInfoWithStorage[127.0.0.1:36229,DS-c2c40660-bb3d-487b-ba72-06032a1fbb96,DISK], DatanodeInfoWithStorage[127.0.0.1:43185,DS-be845c0c-41d4-45f2-addf-ba0d54e74a65,DISK], DatanodeInfoWithStorage[127.0.0.1:39451,DS-576fa855-8787-4918-88c0-f3a47035061b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1337924204-172.17.0.13-1597457515569:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34711,DS-cbc7479a-3ae6-4ec2-8325-390999f1537c,DISK], DatanodeInfoWithStorage[127.0.0.1:35129,DS-52015a78-cd61-453e-9433-a36b4237b419,DISK], DatanodeInfoWithStorage[127.0.0.1:38530,DS-f7e8488c-6f03-4f6f-9132-b881f9cf2f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:43394,DS-f854b12b-e5ff-4c11-aad8-cb571698ea19,DISK], DatanodeInfoWithStorage[127.0.0.1:46532,DS-a450a4b5-cb27-4b70-b828-c437bb2d314a,DISK], DatanodeInfoWithStorage[127.0.0.1:44956,DS-7bb41568-d876-4e93-bc33-815f3487b791,DISK], DatanodeInfoWithStorage[127.0.0.1:33204,DS-22319067-ba83-4711-803c-ea0884049a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:46167,DS-f7e2edbe-13f0-4419-b9cc-e9264d5bbaf3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1337924204-172.17.0.13-1597457515569:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34711,DS-cbc7479a-3ae6-4ec2-8325-390999f1537c,DISK], DatanodeInfoWithStorage[127.0.0.1:35129,DS-52015a78-cd61-453e-9433-a36b4237b419,DISK], DatanodeInfoWithStorage[127.0.0.1:38530,DS-f7e8488c-6f03-4f6f-9132-b881f9cf2f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:43394,DS-f854b12b-e5ff-4c11-aad8-cb571698ea19,DISK], DatanodeInfoWithStorage[127.0.0.1:46532,DS-a450a4b5-cb27-4b70-b828-c437bb2d314a,DISK], DatanodeInfoWithStorage[127.0.0.1:44956,DS-7bb41568-d876-4e93-bc33-815f3487b791,DISK], DatanodeInfoWithStorage[127.0.0.1:33204,DS-22319067-ba83-4711-803c-ea0884049a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:46167,DS-f7e2edbe-13f0-4419-b9cc-e9264d5bbaf3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1718210579-172.17.0.13-1597457697376:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41399,DS-5c6bf16f-651a-443e-9e3a-f2b00457ddcd,DISK], DatanodeInfoWithStorage[127.0.0.1:36926,DS-45b3fd5d-7021-47a9-bd3e-6f46b2ad3363,DISK], DatanodeInfoWithStorage[127.0.0.1:46556,DS-e9b65cbf-2b40-42d9-a5bd-1002280ee3ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36558,DS-5aaf0265-ee42-4141-92c1-a69cdd28f175,DISK], DatanodeInfoWithStorage[127.0.0.1:33191,DS-d3068991-f872-4191-ac17-ead49e4d16a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44208,DS-6e69660a-3340-4d40-b361-c3a2cb9e89c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46420,DS-7244d7ae-d043-42bd-82e4-4078d9f5ea50,DISK], DatanodeInfoWithStorage[127.0.0.1:45475,DS-a3989521-b064-439e-b4dd-31eb7bf0f84a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1718210579-172.17.0.13-1597457697376:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41399,DS-5c6bf16f-651a-443e-9e3a-f2b00457ddcd,DISK], DatanodeInfoWithStorage[127.0.0.1:36926,DS-45b3fd5d-7021-47a9-bd3e-6f46b2ad3363,DISK], DatanodeInfoWithStorage[127.0.0.1:46556,DS-e9b65cbf-2b40-42d9-a5bd-1002280ee3ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36558,DS-5aaf0265-ee42-4141-92c1-a69cdd28f175,DISK], DatanodeInfoWithStorage[127.0.0.1:33191,DS-d3068991-f872-4191-ac17-ead49e4d16a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44208,DS-6e69660a-3340-4d40-b361-c3a2cb9e89c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46420,DS-7244d7ae-d043-42bd-82e4-4078d9f5ea50,DISK], DatanodeInfoWithStorage[127.0.0.1:45475,DS-a3989521-b064-439e-b4dd-31eb7bf0f84a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2021008528-172.17.0.13-1597457786249:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46021,DS-6e21f716-352f-4f91-99aa-713679ecdce8,DISK], DatanodeInfoWithStorage[127.0.0.1:36087,DS-d7c31260-5e1d-41f9-9651-965d647c692a,DISK], DatanodeInfoWithStorage[127.0.0.1:33091,DS-47c286da-f1ae-48bf-9b73-33bfab671227,DISK], DatanodeInfoWithStorage[127.0.0.1:45506,DS-aad97f16-c45e-43be-9865-c900dd9be0e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40379,DS-57e301e7-9c0d-438f-a502-b208ef0ed5e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37023,DS-cd7538d0-d435-4464-94a1-9c8a8e13441f,DISK], DatanodeInfoWithStorage[127.0.0.1:43439,DS-332603ea-c201-49ea-b12e-8d44f618eb8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44748,DS-c14e8318-aed0-4680-81f3-01486a161146,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2021008528-172.17.0.13-1597457786249:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46021,DS-6e21f716-352f-4f91-99aa-713679ecdce8,DISK], DatanodeInfoWithStorage[127.0.0.1:36087,DS-d7c31260-5e1d-41f9-9651-965d647c692a,DISK], DatanodeInfoWithStorage[127.0.0.1:33091,DS-47c286da-f1ae-48bf-9b73-33bfab671227,DISK], DatanodeInfoWithStorage[127.0.0.1:45506,DS-aad97f16-c45e-43be-9865-c900dd9be0e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40379,DS-57e301e7-9c0d-438f-a502-b208ef0ed5e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37023,DS-cd7538d0-d435-4464-94a1-9c8a8e13441f,DISK], DatanodeInfoWithStorage[127.0.0.1:43439,DS-332603ea-c201-49ea-b12e-8d44f618eb8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44748,DS-c14e8318-aed0-4680-81f3-01486a161146,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-123844411-172.17.0.13-1597457828130:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38318,DS-5f038a3e-7434-4479-9886-8f1c987597f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42050,DS-b29d1be3-8a0a-4c99-be4c-60a990aaaf5d,DISK], DatanodeInfoWithStorage[127.0.0.1:38219,DS-09f391f7-90b5-45d2-89d4-b13498d73168,DISK], DatanodeInfoWithStorage[127.0.0.1:42565,DS-2a355a23-c98e-4efa-ac46-e33afd229c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:34162,DS-068667df-5f82-4ddb-bbe8-681c86a7ab2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33876,DS-5bc7ef4b-8875-4ffd-b8d3-ded48e61f405,DISK], DatanodeInfoWithStorage[127.0.0.1:44972,DS-ae9de29c-9f7e-413b-9471-2129ef2fe8b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34437,DS-6301c4f9-1d36-4ee7-82eb-cd783baaac71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-123844411-172.17.0.13-1597457828130:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38318,DS-5f038a3e-7434-4479-9886-8f1c987597f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42050,DS-b29d1be3-8a0a-4c99-be4c-60a990aaaf5d,DISK], DatanodeInfoWithStorage[127.0.0.1:38219,DS-09f391f7-90b5-45d2-89d4-b13498d73168,DISK], DatanodeInfoWithStorage[127.0.0.1:42565,DS-2a355a23-c98e-4efa-ac46-e33afd229c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:34162,DS-068667df-5f82-4ddb-bbe8-681c86a7ab2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33876,DS-5bc7ef4b-8875-4ffd-b8d3-ded48e61f405,DISK], DatanodeInfoWithStorage[127.0.0.1:44972,DS-ae9de29c-9f7e-413b-9471-2129ef2fe8b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34437,DS-6301c4f9-1d36-4ee7-82eb-cd783baaac71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-871544386-172.17.0.13-1597457990101:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37648,DS-2646b474-ef4d-4ac4-966a-61ca4a544588,DISK], DatanodeInfoWithStorage[127.0.0.1:37431,DS-33c5f76c-67c8-4da5-b2eb-829a03fd4107,DISK], DatanodeInfoWithStorage[127.0.0.1:45439,DS-4d440ee1-7124-4c7a-bb1b-f9b552d8c768,DISK], DatanodeInfoWithStorage[127.0.0.1:44794,DS-c99cc69f-c7f3-4f59-bba7-aa4394061c81,DISK], DatanodeInfoWithStorage[127.0.0.1:41519,DS-109a24b3-4f31-41a2-b6d1-dded83d68ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:33119,DS-25d7d923-a7bd-4eb7-9110-02add6a06008,DISK], DatanodeInfoWithStorage[127.0.0.1:45589,DS-72fddfa5-4644-475b-94da-d3cd799f05d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38198,DS-552fa5b4-466d-48ab-9427-2fb6591bd8af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-871544386-172.17.0.13-1597457990101:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37648,DS-2646b474-ef4d-4ac4-966a-61ca4a544588,DISK], DatanodeInfoWithStorage[127.0.0.1:37431,DS-33c5f76c-67c8-4da5-b2eb-829a03fd4107,DISK], DatanodeInfoWithStorage[127.0.0.1:45439,DS-4d440ee1-7124-4c7a-bb1b-f9b552d8c768,DISK], DatanodeInfoWithStorage[127.0.0.1:44794,DS-c99cc69f-c7f3-4f59-bba7-aa4394061c81,DISK], DatanodeInfoWithStorage[127.0.0.1:41519,DS-109a24b3-4f31-41a2-b6d1-dded83d68ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:33119,DS-25d7d923-a7bd-4eb7-9110-02add6a06008,DISK], DatanodeInfoWithStorage[127.0.0.1:45589,DS-72fddfa5-4644-475b-94da-d3cd799f05d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38198,DS-552fa5b4-466d-48ab-9427-2fb6591bd8af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1636508807-172.17.0.13-1597458334540:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33642,DS-e98f119c-a091-4168-8ac1-41a5aed82176,DISK], DatanodeInfoWithStorage[127.0.0.1:35784,DS-4db87223-5359-40f1-b944-c0b308561ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:37676,DS-885b797c-b1c0-4768-99fe-154d95d6e61b,DISK], DatanodeInfoWithStorage[127.0.0.1:37958,DS-04091325-4c3f-4aec-9e45-4627c2d400ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39321,DS-38abc4b9-e092-489d-9e23-c9e105309f51,DISK], DatanodeInfoWithStorage[127.0.0.1:42334,DS-de61375d-6a77-4b84-ad46-f5e3e8b5f17b,DISK], DatanodeInfoWithStorage[127.0.0.1:35838,DS-febc72d5-78dd-4d54-ac99-1f60db36fefa,DISK], DatanodeInfoWithStorage[127.0.0.1:36902,DS-c7959807-7445-4891-9a5f-2f7a315e26cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1636508807-172.17.0.13-1597458334540:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33642,DS-e98f119c-a091-4168-8ac1-41a5aed82176,DISK], DatanodeInfoWithStorage[127.0.0.1:35784,DS-4db87223-5359-40f1-b944-c0b308561ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:37676,DS-885b797c-b1c0-4768-99fe-154d95d6e61b,DISK], DatanodeInfoWithStorage[127.0.0.1:37958,DS-04091325-4c3f-4aec-9e45-4627c2d400ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39321,DS-38abc4b9-e092-489d-9e23-c9e105309f51,DISK], DatanodeInfoWithStorage[127.0.0.1:42334,DS-de61375d-6a77-4b84-ad46-f5e3e8b5f17b,DISK], DatanodeInfoWithStorage[127.0.0.1:35838,DS-febc72d5-78dd-4d54-ac99-1f60db36fefa,DISK], DatanodeInfoWithStorage[127.0.0.1:36902,DS-c7959807-7445-4891-9a5f-2f7a315e26cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-929522733-172.17.0.13-1597458553550:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39768,DS-4cc357b0-890b-44fb-8b47-92679eaed565,DISK], DatanodeInfoWithStorage[127.0.0.1:45201,DS-56915525-9fe3-4439-b2a2-d61b08a03cce,DISK], DatanodeInfoWithStorage[127.0.0.1:35162,DS-08ec6538-c4fd-4c34-826c-e8a2be306bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:45529,DS-1745ed5f-ea0a-4d32-8462-1f61918e9034,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-456c3ed2-3fce-4c4e-beb0-778a17d3ef5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36334,DS-430c5918-a9b4-4336-b178-07c4bab31d05,DISK], DatanodeInfoWithStorage[127.0.0.1:33491,DS-ff49c3fc-dacb-4f7c-8b37-028115dec1bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38331,DS-df7fb42e-61ac-46a8-8ddd-e7fe5d3ae4e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-929522733-172.17.0.13-1597458553550:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39768,DS-4cc357b0-890b-44fb-8b47-92679eaed565,DISK], DatanodeInfoWithStorage[127.0.0.1:45201,DS-56915525-9fe3-4439-b2a2-d61b08a03cce,DISK], DatanodeInfoWithStorage[127.0.0.1:35162,DS-08ec6538-c4fd-4c34-826c-e8a2be306bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:45529,DS-1745ed5f-ea0a-4d32-8462-1f61918e9034,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-456c3ed2-3fce-4c4e-beb0-778a17d3ef5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36334,DS-430c5918-a9b4-4336-b178-07c4bab31d05,DISK], DatanodeInfoWithStorage[127.0.0.1:33491,DS-ff49c3fc-dacb-4f7c-8b37-028115dec1bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38331,DS-df7fb42e-61ac-46a8-8ddd-e7fe5d3ae4e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2079485561-172.17.0.13-1597459121395:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36474,DS-5e555c98-5d9d-4ae6-b61e-ec898d23299d,DISK], DatanodeInfoWithStorage[127.0.0.1:39530,DS-30495131-53f2-421b-87a2-6e0308c13a92,DISK], DatanodeInfoWithStorage[127.0.0.1:42719,DS-eadf7361-772a-4d54-986a-f5fa64bd2137,DISK], DatanodeInfoWithStorage[127.0.0.1:38795,DS-3a3029b1-7b3c-4074-96d5-f6fd8c95eb54,DISK], DatanodeInfoWithStorage[127.0.0.1:37672,DS-f32d85ed-158c-4ce6-9ec7-7713193853ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40383,DS-fdca6817-df08-4009-ad2f-204da4f197f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39204,DS-c8e26ef0-8947-41e6-b343-c200b7d248ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46552,DS-7070dc5e-655e-44b8-9183-ffa95e4d7440,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2079485561-172.17.0.13-1597459121395:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36474,DS-5e555c98-5d9d-4ae6-b61e-ec898d23299d,DISK], DatanodeInfoWithStorage[127.0.0.1:39530,DS-30495131-53f2-421b-87a2-6e0308c13a92,DISK], DatanodeInfoWithStorage[127.0.0.1:42719,DS-eadf7361-772a-4d54-986a-f5fa64bd2137,DISK], DatanodeInfoWithStorage[127.0.0.1:38795,DS-3a3029b1-7b3c-4074-96d5-f6fd8c95eb54,DISK], DatanodeInfoWithStorage[127.0.0.1:37672,DS-f32d85ed-158c-4ce6-9ec7-7713193853ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40383,DS-fdca6817-df08-4009-ad2f-204da4f197f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39204,DS-c8e26ef0-8947-41e6-b343-c200b7d248ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46552,DS-7070dc5e-655e-44b8-9183-ffa95e4d7440,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-620239949-172.17.0.13-1597459325933:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35316,DS-dabbc7f2-c017-4a38-860b-6cce64332e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:42980,DS-74595bf0-9c3f-49f7-95be-e8f78bfbbba0,DISK], DatanodeInfoWithStorage[127.0.0.1:34510,DS-c1dd8d13-f1de-425c-9c82-e042b3c8a954,DISK], DatanodeInfoWithStorage[127.0.0.1:38802,DS-37f59654-27ac-4154-8b8b-d1a678e67d28,DISK], DatanodeInfoWithStorage[127.0.0.1:33506,DS-31927091-8ec9-4797-add7-c85710640a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44455,DS-a6a4cb65-bcc0-4460-8684-65b1273bc29a,DISK], DatanodeInfoWithStorage[127.0.0.1:36323,DS-7dcc40ba-a705-4352-9212-bd9a07c36891,DISK], DatanodeInfoWithStorage[127.0.0.1:42462,DS-7dc7484c-0b4e-4be4-b59e-1f88a27b6c32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-620239949-172.17.0.13-1597459325933:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35316,DS-dabbc7f2-c017-4a38-860b-6cce64332e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:42980,DS-74595bf0-9c3f-49f7-95be-e8f78bfbbba0,DISK], DatanodeInfoWithStorage[127.0.0.1:34510,DS-c1dd8d13-f1de-425c-9c82-e042b3c8a954,DISK], DatanodeInfoWithStorage[127.0.0.1:38802,DS-37f59654-27ac-4154-8b8b-d1a678e67d28,DISK], DatanodeInfoWithStorage[127.0.0.1:33506,DS-31927091-8ec9-4797-add7-c85710640a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44455,DS-a6a4cb65-bcc0-4460-8684-65b1273bc29a,DISK], DatanodeInfoWithStorage[127.0.0.1:36323,DS-7dcc40ba-a705-4352-9212-bd9a07c36891,DISK], DatanodeInfoWithStorage[127.0.0.1:42462,DS-7dc7484c-0b4e-4be4-b59e-1f88a27b6c32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-589225558-172.17.0.13-1597459766248:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39717,DS-b05bf090-750c-4602-86b8-01459cdee5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43382,DS-39390680-1d16-4522-906d-fc5ed75df4c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37496,DS-13212218-a2b3-47fb-9360-80944131a38b,DISK], DatanodeInfoWithStorage[127.0.0.1:37297,DS-41001e53-493d-4b7d-898c-609aa24f4f18,DISK], DatanodeInfoWithStorage[127.0.0.1:35093,DS-ba43772f-f92b-4888-ac0e-1e919b0612eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46277,DS-ccf30da9-825b-427a-91a8-f754fa744887,DISK], DatanodeInfoWithStorage[127.0.0.1:33018,DS-54d8a609-81f4-4bb7-8e79-9c92f7775611,DISK], DatanodeInfoWithStorage[127.0.0.1:36753,DS-166c59a6-d42a-4e33-9e6e-b2f9a7e475f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-589225558-172.17.0.13-1597459766248:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39717,DS-b05bf090-750c-4602-86b8-01459cdee5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43382,DS-39390680-1d16-4522-906d-fc5ed75df4c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37496,DS-13212218-a2b3-47fb-9360-80944131a38b,DISK], DatanodeInfoWithStorage[127.0.0.1:37297,DS-41001e53-493d-4b7d-898c-609aa24f4f18,DISK], DatanodeInfoWithStorage[127.0.0.1:35093,DS-ba43772f-f92b-4888-ac0e-1e919b0612eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46277,DS-ccf30da9-825b-427a-91a8-f754fa744887,DISK], DatanodeInfoWithStorage[127.0.0.1:33018,DS-54d8a609-81f4-4bb7-8e79-9c92f7775611,DISK], DatanodeInfoWithStorage[127.0.0.1:36753,DS-166c59a6-d42a-4e33-9e6e-b2f9a7e475f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-821227789-172.17.0.13-1597461456518:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37590,DS-ca62dda5-9975-4523-922a-32d3d410a852,DISK], DatanodeInfoWithStorage[127.0.0.1:35109,DS-2915fb03-dafc-493c-ac35-7a61eaefabe6,DISK], DatanodeInfoWithStorage[127.0.0.1:33445,DS-cada5da2-68bb-4c9b-8e17-299d3fc154a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44682,DS-a92faaa4-5551-4e38-b2fa-f5403185a2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:32920,DS-c0a6c84f-7fca-4254-beee-3edf6d00a434,DISK], DatanodeInfoWithStorage[127.0.0.1:33511,DS-6d8f50d7-550b-47d1-b207-01cd051fc56c,DISK], DatanodeInfoWithStorage[127.0.0.1:43093,DS-8168519a-b8fa-45e9-9d79-42a107dd75b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45697,DS-4100a945-4d76-4f00-946b-bd3f3cb132d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-821227789-172.17.0.13-1597461456518:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37590,DS-ca62dda5-9975-4523-922a-32d3d410a852,DISK], DatanodeInfoWithStorage[127.0.0.1:35109,DS-2915fb03-dafc-493c-ac35-7a61eaefabe6,DISK], DatanodeInfoWithStorage[127.0.0.1:33445,DS-cada5da2-68bb-4c9b-8e17-299d3fc154a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44682,DS-a92faaa4-5551-4e38-b2fa-f5403185a2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:32920,DS-c0a6c84f-7fca-4254-beee-3edf6d00a434,DISK], DatanodeInfoWithStorage[127.0.0.1:33511,DS-6d8f50d7-550b-47d1-b207-01cd051fc56c,DISK], DatanodeInfoWithStorage[127.0.0.1:43093,DS-8168519a-b8fa-45e9-9d79-42a107dd75b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45697,DS-4100a945-4d76-4f00-946b-bd3f3cb132d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1007514423-172.17.0.13-1597461594504:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43503,DS-9b94e81b-eb44-4290-bbd1-4cb627fc917c,DISK], DatanodeInfoWithStorage[127.0.0.1:39140,DS-7f870c3c-8d5a-43c1-83d4-1bcbb038ff68,DISK], DatanodeInfoWithStorage[127.0.0.1:40437,DS-7551659e-a784-48de-b842-f8a2245ba46a,DISK], DatanodeInfoWithStorage[127.0.0.1:38081,DS-fab3fd3f-75d5-4361-b391-a430b672a971,DISK], DatanodeInfoWithStorage[127.0.0.1:42078,DS-b15159b7-a91a-40d7-989e-450de08f81eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45127,DS-d869c472-d7f8-41fc-a47c-e12084e86161,DISK], DatanodeInfoWithStorage[127.0.0.1:42521,DS-c742fb81-22ba-40af-92fc-63452f37b4c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36012,DS-3c8c5eb2-c5a0-4775-8111-00f0c682f4e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1007514423-172.17.0.13-1597461594504:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43503,DS-9b94e81b-eb44-4290-bbd1-4cb627fc917c,DISK], DatanodeInfoWithStorage[127.0.0.1:39140,DS-7f870c3c-8d5a-43c1-83d4-1bcbb038ff68,DISK], DatanodeInfoWithStorage[127.0.0.1:40437,DS-7551659e-a784-48de-b842-f8a2245ba46a,DISK], DatanodeInfoWithStorage[127.0.0.1:38081,DS-fab3fd3f-75d5-4361-b391-a430b672a971,DISK], DatanodeInfoWithStorage[127.0.0.1:42078,DS-b15159b7-a91a-40d7-989e-450de08f81eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45127,DS-d869c472-d7f8-41fc-a47c-e12084e86161,DISK], DatanodeInfoWithStorage[127.0.0.1:42521,DS-c742fb81-22ba-40af-92fc-63452f37b4c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36012,DS-3c8c5eb2-c5a0-4775-8111-00f0c682f4e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 6725
