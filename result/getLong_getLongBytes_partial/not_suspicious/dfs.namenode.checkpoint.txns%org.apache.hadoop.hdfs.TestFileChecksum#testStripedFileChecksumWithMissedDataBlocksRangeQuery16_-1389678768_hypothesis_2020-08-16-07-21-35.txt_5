reconf_parameter: dfs.namenode.checkpoint.txns
component: hdfs:NameNode
v1: 1000000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.txns
component: hdfs:NameNode
v1: 1000000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1007138796-172.17.0.3-1597562549732:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40692,DS-1879b7d7-6ec8-48d0-a57e-09adce7058ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38428,DS-13105416-fa10-42c8-94a5-4f226c3b3963,DISK], DatanodeInfoWithStorage[127.0.0.1:33218,DS-88f22a2c-dd21-4c3b-a9dc-cf6d26918c60,DISK], DatanodeInfoWithStorage[127.0.0.1:38616,DS-3fec6fa9-57ea-421a-8216-9b4a2a306a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44115,DS-e7b94f1d-eb11-477f-a651-d3a66d016532,DISK], DatanodeInfoWithStorage[127.0.0.1:35343,DS-bf16bfab-43d2-461a-a522-0a40e4f6702b,DISK], DatanodeInfoWithStorage[127.0.0.1:35061,DS-494f91c8-cd2b-490d-a6a5-60ab15d89492,DISK], DatanodeInfoWithStorage[127.0.0.1:37814,DS-4ca76247-dba5-439f-a638-449c0a2438d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1007138796-172.17.0.3-1597562549732:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40692,DS-1879b7d7-6ec8-48d0-a57e-09adce7058ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38428,DS-13105416-fa10-42c8-94a5-4f226c3b3963,DISK], DatanodeInfoWithStorage[127.0.0.1:33218,DS-88f22a2c-dd21-4c3b-a9dc-cf6d26918c60,DISK], DatanodeInfoWithStorage[127.0.0.1:38616,DS-3fec6fa9-57ea-421a-8216-9b4a2a306a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44115,DS-e7b94f1d-eb11-477f-a651-d3a66d016532,DISK], DatanodeInfoWithStorage[127.0.0.1:35343,DS-bf16bfab-43d2-461a-a522-0a40e4f6702b,DISK], DatanodeInfoWithStorage[127.0.0.1:35061,DS-494f91c8-cd2b-490d-a6a5-60ab15d89492,DISK], DatanodeInfoWithStorage[127.0.0.1:37814,DS-4ca76247-dba5-439f-a638-449c0a2438d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.txns
component: hdfs:NameNode
v1: 1000000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-402151485-172.17.0.3-1597562852801:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38210,DS-5bbd612e-ebfc-4888-ab6c-9e83a5234e21,DISK], DatanodeInfoWithStorage[127.0.0.1:33128,DS-abbc9bd7-1683-459f-8a97-bb0b8b5a9e98,DISK], DatanodeInfoWithStorage[127.0.0.1:37179,DS-ebc6afb0-5879-4c46-a11a-b5051c8906db,DISK], DatanodeInfoWithStorage[127.0.0.1:36634,DS-3e45a904-9c3b-4d97-8b35-2cc5c41ecb54,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-47a0cdbf-c870-4196-b788-80047d5f82bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46023,DS-6da6a17f-194f-44f6-a439-28fc90c85a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:34594,DS-a3952847-9cbc-4e77-8c2c-9b5e46f505f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38061,DS-9151fa70-f952-4bf5-b00c-cfb8f56cda4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-402151485-172.17.0.3-1597562852801:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38210,DS-5bbd612e-ebfc-4888-ab6c-9e83a5234e21,DISK], DatanodeInfoWithStorage[127.0.0.1:33128,DS-abbc9bd7-1683-459f-8a97-bb0b8b5a9e98,DISK], DatanodeInfoWithStorage[127.0.0.1:37179,DS-ebc6afb0-5879-4c46-a11a-b5051c8906db,DISK], DatanodeInfoWithStorage[127.0.0.1:36634,DS-3e45a904-9c3b-4d97-8b35-2cc5c41ecb54,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-47a0cdbf-c870-4196-b788-80047d5f82bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46023,DS-6da6a17f-194f-44f6-a439-28fc90c85a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:34594,DS-a3952847-9cbc-4e77-8c2c-9b5e46f505f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38061,DS-9151fa70-f952-4bf5-b00c-cfb8f56cda4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.txns
component: hdfs:NameNode
v1: 1000000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1723208990-172.17.0.3-1597563179530:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38806,DS-2f800366-3c03-44d7-af0c-78fda542402f,DISK], DatanodeInfoWithStorage[127.0.0.1:39956,DS-b893805d-a0cc-4d46-b949-5d52e5ad7d73,DISK], DatanodeInfoWithStorage[127.0.0.1:36686,DS-d8778811-0520-4655-bf15-20175795e068,DISK], DatanodeInfoWithStorage[127.0.0.1:36614,DS-192c5cc6-590a-4260-b8e7-f8288bafbd4e,DISK], DatanodeInfoWithStorage[127.0.0.1:44012,DS-d00e6c44-f30e-4f68-adaf-9a591fa697ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41634,DS-72b54fbf-87ce-4724-813c-2d187de9a64c,DISK], DatanodeInfoWithStorage[127.0.0.1:36508,DS-a383a498-0b32-46f8-a8e1-383a4c78a40f,DISK], DatanodeInfoWithStorage[127.0.0.1:38317,DS-6594877d-d250-4c87-91bb-c6e3bec73d76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1723208990-172.17.0.3-1597563179530:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38806,DS-2f800366-3c03-44d7-af0c-78fda542402f,DISK], DatanodeInfoWithStorage[127.0.0.1:39956,DS-b893805d-a0cc-4d46-b949-5d52e5ad7d73,DISK], DatanodeInfoWithStorage[127.0.0.1:36686,DS-d8778811-0520-4655-bf15-20175795e068,DISK], DatanodeInfoWithStorage[127.0.0.1:36614,DS-192c5cc6-590a-4260-b8e7-f8288bafbd4e,DISK], DatanodeInfoWithStorage[127.0.0.1:44012,DS-d00e6c44-f30e-4f68-adaf-9a591fa697ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41634,DS-72b54fbf-87ce-4724-813c-2d187de9a64c,DISK], DatanodeInfoWithStorage[127.0.0.1:36508,DS-a383a498-0b32-46f8-a8e1-383a4c78a40f,DISK], DatanodeInfoWithStorage[127.0.0.1:38317,DS-6594877d-d250-4c87-91bb-c6e3bec73d76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.txns
component: hdfs:NameNode
v1: 1000000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1446678145-172.17.0.3-1597563212840:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42014,DS-b06da27a-b007-446c-af57-41a6b488781e,DISK], DatanodeInfoWithStorage[127.0.0.1:39906,DS-10f46ac5-f43f-4b2f-acce-5614c4f355bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35334,DS-78c9370b-8867-412a-a303-dc59e2cc0070,DISK], DatanodeInfoWithStorage[127.0.0.1:34624,DS-0e756fb6-141d-46d5-bc2c-00b0ddcf041b,DISK], DatanodeInfoWithStorage[127.0.0.1:39239,DS-1751faf7-ced1-4999-b080-a78c65baed23,DISK], DatanodeInfoWithStorage[127.0.0.1:44520,DS-e1f4c60f-bb5f-411d-ba2a-f09fe4a2756c,DISK], DatanodeInfoWithStorage[127.0.0.1:41420,DS-2bbaf6be-f40e-4251-a2a6-103df2064333,DISK], DatanodeInfoWithStorage[127.0.0.1:45530,DS-9c56f1c7-ee72-4c78-aaae-b7f73257f4a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1446678145-172.17.0.3-1597563212840:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42014,DS-b06da27a-b007-446c-af57-41a6b488781e,DISK], DatanodeInfoWithStorage[127.0.0.1:39906,DS-10f46ac5-f43f-4b2f-acce-5614c4f355bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35334,DS-78c9370b-8867-412a-a303-dc59e2cc0070,DISK], DatanodeInfoWithStorage[127.0.0.1:34624,DS-0e756fb6-141d-46d5-bc2c-00b0ddcf041b,DISK], DatanodeInfoWithStorage[127.0.0.1:39239,DS-1751faf7-ced1-4999-b080-a78c65baed23,DISK], DatanodeInfoWithStorage[127.0.0.1:44520,DS-e1f4c60f-bb5f-411d-ba2a-f09fe4a2756c,DISK], DatanodeInfoWithStorage[127.0.0.1:41420,DS-2bbaf6be-f40e-4251-a2a6-103df2064333,DISK], DatanodeInfoWithStorage[127.0.0.1:45530,DS-9c56f1c7-ee72-4c78-aaae-b7f73257f4a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.txns
component: hdfs:NameNode
v1: 1000000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-518840603-172.17.0.3-1597563360443:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41217,DS-06c41288-b469-438c-92a0-0e1bb0768809,DISK], DatanodeInfoWithStorage[127.0.0.1:33779,DS-d421c95b-c737-4291-afc1-f439ccfea496,DISK], DatanodeInfoWithStorage[127.0.0.1:41936,DS-046b2ff9-6b2f-468a-8242-4bc7b3f4f249,DISK], DatanodeInfoWithStorage[127.0.0.1:36532,DS-69a7e10b-a4b7-4db5-9dd0-e3e72acc1b89,DISK], DatanodeInfoWithStorage[127.0.0.1:46813,DS-a7d70c43-1304-4fab-a70e-99ec0e107250,DISK], DatanodeInfoWithStorage[127.0.0.1:37366,DS-c5854bdd-3001-4c0d-a728-82dbda0a1914,DISK], DatanodeInfoWithStorage[127.0.0.1:40696,DS-038396e4-4ec8-4465-b370-541dc0bfd70b,DISK], DatanodeInfoWithStorage[127.0.0.1:42687,DS-615538ac-f04f-48b4-8f33-da04e4ec4ea8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-518840603-172.17.0.3-1597563360443:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41217,DS-06c41288-b469-438c-92a0-0e1bb0768809,DISK], DatanodeInfoWithStorage[127.0.0.1:33779,DS-d421c95b-c737-4291-afc1-f439ccfea496,DISK], DatanodeInfoWithStorage[127.0.0.1:41936,DS-046b2ff9-6b2f-468a-8242-4bc7b3f4f249,DISK], DatanodeInfoWithStorage[127.0.0.1:36532,DS-69a7e10b-a4b7-4db5-9dd0-e3e72acc1b89,DISK], DatanodeInfoWithStorage[127.0.0.1:46813,DS-a7d70c43-1304-4fab-a70e-99ec0e107250,DISK], DatanodeInfoWithStorage[127.0.0.1:37366,DS-c5854bdd-3001-4c0d-a728-82dbda0a1914,DISK], DatanodeInfoWithStorage[127.0.0.1:40696,DS-038396e4-4ec8-4465-b370-541dc0bfd70b,DISK], DatanodeInfoWithStorage[127.0.0.1:42687,DS-615538ac-f04f-48b4-8f33-da04e4ec4ea8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.txns
component: hdfs:NameNode
v1: 1000000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1035810554-172.17.0.3-1597563587671:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32776,DS-ecb87832-de3b-4485-b73e-7db925acf428,DISK], DatanodeInfoWithStorage[127.0.0.1:45372,DS-ad82aef6-a0fb-464f-b31a-1e10ab117d49,DISK], DatanodeInfoWithStorage[127.0.0.1:34022,DS-cf68374f-32e0-4f6e-8597-3ea439825e61,DISK], DatanodeInfoWithStorage[127.0.0.1:37468,DS-6a04c785-e7ed-408c-9615-5e2e01263a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43870,DS-05240ceb-1599-422e-88bf-f23abfedaabb,DISK], DatanodeInfoWithStorage[127.0.0.1:34146,DS-48c4eb12-41fb-4f0d-8705-b0efc8146417,DISK], DatanodeInfoWithStorage[127.0.0.1:43185,DS-b177b6bd-9744-4f51-8147-42e615d9bd21,DISK], DatanodeInfoWithStorage[127.0.0.1:34216,DS-8a6ee008-f853-49ee-a542-d39f981aab69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1035810554-172.17.0.3-1597563587671:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32776,DS-ecb87832-de3b-4485-b73e-7db925acf428,DISK], DatanodeInfoWithStorage[127.0.0.1:45372,DS-ad82aef6-a0fb-464f-b31a-1e10ab117d49,DISK], DatanodeInfoWithStorage[127.0.0.1:34022,DS-cf68374f-32e0-4f6e-8597-3ea439825e61,DISK], DatanodeInfoWithStorage[127.0.0.1:37468,DS-6a04c785-e7ed-408c-9615-5e2e01263a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43870,DS-05240ceb-1599-422e-88bf-f23abfedaabb,DISK], DatanodeInfoWithStorage[127.0.0.1:34146,DS-48c4eb12-41fb-4f0d-8705-b0efc8146417,DISK], DatanodeInfoWithStorage[127.0.0.1:43185,DS-b177b6bd-9744-4f51-8147-42e615d9bd21,DISK], DatanodeInfoWithStorage[127.0.0.1:34216,DS-8a6ee008-f853-49ee-a542-d39f981aab69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.txns
component: hdfs:NameNode
v1: 1000000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2140552327-172.17.0.3-1597563728495:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42636,DS-7ccbe98b-8a9a-4823-9302-977fd6aff212,DISK], DatanodeInfoWithStorage[127.0.0.1:39386,DS-36f52287-06f7-4529-894f-32ad54c812be,DISK], DatanodeInfoWithStorage[127.0.0.1:40604,DS-eb667377-40a2-4d14-8fcd-464f8e248a37,DISK], DatanodeInfoWithStorage[127.0.0.1:37683,DS-496d4a3a-6133-485d-9dfe-70e23913b730,DISK], DatanodeInfoWithStorage[127.0.0.1:44262,DS-5fef7e54-8210-4690-b5d7-603de43cbb54,DISK], DatanodeInfoWithStorage[127.0.0.1:43581,DS-09082a4e-790c-412a-a9b9-0be0fc3819bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33039,DS-ef2395bc-a371-43c0-a4f3-352cdcf94d51,DISK], DatanodeInfoWithStorage[127.0.0.1:44189,DS-31b0bb21-1573-4279-bec2-eb9305feacf5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2140552327-172.17.0.3-1597563728495:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42636,DS-7ccbe98b-8a9a-4823-9302-977fd6aff212,DISK], DatanodeInfoWithStorage[127.0.0.1:39386,DS-36f52287-06f7-4529-894f-32ad54c812be,DISK], DatanodeInfoWithStorage[127.0.0.1:40604,DS-eb667377-40a2-4d14-8fcd-464f8e248a37,DISK], DatanodeInfoWithStorage[127.0.0.1:37683,DS-496d4a3a-6133-485d-9dfe-70e23913b730,DISK], DatanodeInfoWithStorage[127.0.0.1:44262,DS-5fef7e54-8210-4690-b5d7-603de43cbb54,DISK], DatanodeInfoWithStorage[127.0.0.1:43581,DS-09082a4e-790c-412a-a9b9-0be0fc3819bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33039,DS-ef2395bc-a371-43c0-a4f3-352cdcf94d51,DISK], DatanodeInfoWithStorage[127.0.0.1:44189,DS-31b0bb21-1573-4279-bec2-eb9305feacf5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.txns
component: hdfs:NameNode
v1: 1000000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-50048594-172.17.0.3-1597564775235:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34972,DS-cb6d0f38-de14-4ff8-8af5-604c76031bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:36138,DS-3ce347c9-c045-4334-a3c6-e04add78c815,DISK], DatanodeInfoWithStorage[127.0.0.1:36251,DS-be0ccd22-1b8c-4aff-8c29-a3a84271d464,DISK], DatanodeInfoWithStorage[127.0.0.1:44252,DS-2a186ff8-5d56-4d7c-a4dc-301411d7770f,DISK], DatanodeInfoWithStorage[127.0.0.1:33264,DS-a5c0a25b-fa75-4c60-a446-a0a30a38d6a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42517,DS-ad337ec3-07fb-4596-acf5-11833f9bb114,DISK], DatanodeInfoWithStorage[127.0.0.1:35223,DS-c17f37e0-92b5-4469-9df9-87a9267500dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37585,DS-ecbfcaae-2a3f-4e24-b21d-671cba8895f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-50048594-172.17.0.3-1597564775235:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34972,DS-cb6d0f38-de14-4ff8-8af5-604c76031bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:36138,DS-3ce347c9-c045-4334-a3c6-e04add78c815,DISK], DatanodeInfoWithStorage[127.0.0.1:36251,DS-be0ccd22-1b8c-4aff-8c29-a3a84271d464,DISK], DatanodeInfoWithStorage[127.0.0.1:44252,DS-2a186ff8-5d56-4d7c-a4dc-301411d7770f,DISK], DatanodeInfoWithStorage[127.0.0.1:33264,DS-a5c0a25b-fa75-4c60-a446-a0a30a38d6a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42517,DS-ad337ec3-07fb-4596-acf5-11833f9bb114,DISK], DatanodeInfoWithStorage[127.0.0.1:35223,DS-c17f37e0-92b5-4469-9df9-87a9267500dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37585,DS-ecbfcaae-2a3f-4e24-b21d-671cba8895f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.txns
component: hdfs:NameNode
v1: 1000000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2134554366-172.17.0.3-1597564926115:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36081,DS-c37e4e6e-e76b-4d97-b5a6-30f0e719bdee,DISK], DatanodeInfoWithStorage[127.0.0.1:40727,DS-a5d50500-68d8-4e93-8138-512d7e4a91c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45922,DS-8aaea8a4-ae18-4980-9dc0-b3e20ee2aedd,DISK], DatanodeInfoWithStorage[127.0.0.1:42981,DS-4b562cc1-0afe-490d-8c28-c8b6c25edba7,DISK], DatanodeInfoWithStorage[127.0.0.1:39225,DS-aa27c978-1387-44fb-9c97-4d243749c71e,DISK], DatanodeInfoWithStorage[127.0.0.1:33786,DS-6871dbaf-d314-48e9-aaf8-625049039e85,DISK], DatanodeInfoWithStorage[127.0.0.1:41628,DS-6affe48a-6d7e-4f53-a942-c3924cbfd749,DISK], DatanodeInfoWithStorage[127.0.0.1:35066,DS-1074dc09-7d5b-44fd-a702-e355f201bbad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2134554366-172.17.0.3-1597564926115:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36081,DS-c37e4e6e-e76b-4d97-b5a6-30f0e719bdee,DISK], DatanodeInfoWithStorage[127.0.0.1:40727,DS-a5d50500-68d8-4e93-8138-512d7e4a91c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45922,DS-8aaea8a4-ae18-4980-9dc0-b3e20ee2aedd,DISK], DatanodeInfoWithStorage[127.0.0.1:42981,DS-4b562cc1-0afe-490d-8c28-c8b6c25edba7,DISK], DatanodeInfoWithStorage[127.0.0.1:39225,DS-aa27c978-1387-44fb-9c97-4d243749c71e,DISK], DatanodeInfoWithStorage[127.0.0.1:33786,DS-6871dbaf-d314-48e9-aaf8-625049039e85,DISK], DatanodeInfoWithStorage[127.0.0.1:41628,DS-6affe48a-6d7e-4f53-a942-c3924cbfd749,DISK], DatanodeInfoWithStorage[127.0.0.1:35066,DS-1074dc09-7d5b-44fd-a702-e355f201bbad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.txns
component: hdfs:NameNode
v1: 1000000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-961546120-172.17.0.3-1597565573764:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38089,DS-2c4ed70d-d8c9-4b66-aa3c-cdac231edaa1,DISK], DatanodeInfoWithStorage[127.0.0.1:39044,DS-bb2d5ed9-3c2a-4fd3-b7ca-bc913f19ec39,DISK], DatanodeInfoWithStorage[127.0.0.1:37653,DS-ef2e48aa-e07e-422b-809b-52e342c84fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:41299,DS-df76975f-668e-4265-85a9-8b8628e23631,DISK], DatanodeInfoWithStorage[127.0.0.1:40570,DS-9ffdc03c-977c-488c-9b7e-b73abc426eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:35558,DS-cc7e77c0-0ec8-4d7e-93e4-697c02a73be7,DISK], DatanodeInfoWithStorage[127.0.0.1:35807,DS-c8443a40-acff-45f9-8dbf-6e92819181ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45343,DS-b4ff1393-214a-4a68-ac2e-deb6dad89fb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-961546120-172.17.0.3-1597565573764:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38089,DS-2c4ed70d-d8c9-4b66-aa3c-cdac231edaa1,DISK], DatanodeInfoWithStorage[127.0.0.1:39044,DS-bb2d5ed9-3c2a-4fd3-b7ca-bc913f19ec39,DISK], DatanodeInfoWithStorage[127.0.0.1:37653,DS-ef2e48aa-e07e-422b-809b-52e342c84fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:41299,DS-df76975f-668e-4265-85a9-8b8628e23631,DISK], DatanodeInfoWithStorage[127.0.0.1:40570,DS-9ffdc03c-977c-488c-9b7e-b73abc426eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:35558,DS-cc7e77c0-0ec8-4d7e-93e4-697c02a73be7,DISK], DatanodeInfoWithStorage[127.0.0.1:35807,DS-c8443a40-acff-45f9-8dbf-6e92819181ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45343,DS-b4ff1393-214a-4a68-ac2e-deb6dad89fb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.txns
component: hdfs:NameNode
v1: 1000000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-732097352-172.17.0.3-1597565760143:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43216,DS-66acf570-673b-4f6e-be15-ff91f40f9057,DISK], DatanodeInfoWithStorage[127.0.0.1:33840,DS-a13c4660-669b-484b-9773-66a4f2d26a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:41081,DS-c5f00243-8507-4dba-b0c4-b053c76f789e,DISK], DatanodeInfoWithStorage[127.0.0.1:38838,DS-a18d2a43-077b-4203-aec4-9eda3eb3d961,DISK], DatanodeInfoWithStorage[127.0.0.1:41523,DS-d810bf0b-3a11-4c95-a46e-80581c7cf145,DISK], DatanodeInfoWithStorage[127.0.0.1:45897,DS-48698b5f-668d-43d8-b379-059bcbbb90d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43024,DS-2caa111d-03cb-4477-b4b4-46180bfd4430,DISK], DatanodeInfoWithStorage[127.0.0.1:43666,DS-502f9d31-92a4-42c7-a506-8e951d738201,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-732097352-172.17.0.3-1597565760143:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43216,DS-66acf570-673b-4f6e-be15-ff91f40f9057,DISK], DatanodeInfoWithStorage[127.0.0.1:33840,DS-a13c4660-669b-484b-9773-66a4f2d26a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:41081,DS-c5f00243-8507-4dba-b0c4-b053c76f789e,DISK], DatanodeInfoWithStorage[127.0.0.1:38838,DS-a18d2a43-077b-4203-aec4-9eda3eb3d961,DISK], DatanodeInfoWithStorage[127.0.0.1:41523,DS-d810bf0b-3a11-4c95-a46e-80581c7cf145,DISK], DatanodeInfoWithStorage[127.0.0.1:45897,DS-48698b5f-668d-43d8-b379-059bcbbb90d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43024,DS-2caa111d-03cb-4477-b4b4-46180bfd4430,DISK], DatanodeInfoWithStorage[127.0.0.1:43666,DS-502f9d31-92a4-42c7-a506-8e951d738201,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.txns
component: hdfs:NameNode
v1: 1000000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-416943869-172.17.0.3-1597565916337:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45441,DS-71967d4e-3225-43e6-b641-f6fef1fdcb43,DISK], DatanodeInfoWithStorage[127.0.0.1:46678,DS-494a5146-71c2-4372-bd5f-12fcc26598e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40801,DS-94b2c69c-4656-42a1-811b-be99a1acf603,DISK], DatanodeInfoWithStorage[127.0.0.1:44549,DS-d24d31ce-8ebb-4e8f-80f7-57eafb035986,DISK], DatanodeInfoWithStorage[127.0.0.1:46303,DS-c5d1f333-2009-4088-a127-ea3510d8b741,DISK], DatanodeInfoWithStorage[127.0.0.1:46571,DS-fcc29abb-27b8-4f7f-8d6f-59277f114679,DISK], DatanodeInfoWithStorage[127.0.0.1:41693,DS-e06a80fa-9390-4ffb-affd-660e708ddc51,DISK], DatanodeInfoWithStorage[127.0.0.1:43337,DS-cf573f0e-d1a0-4ea6-b4c2-32b637a8adc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-416943869-172.17.0.3-1597565916337:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45441,DS-71967d4e-3225-43e6-b641-f6fef1fdcb43,DISK], DatanodeInfoWithStorage[127.0.0.1:46678,DS-494a5146-71c2-4372-bd5f-12fcc26598e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40801,DS-94b2c69c-4656-42a1-811b-be99a1acf603,DISK], DatanodeInfoWithStorage[127.0.0.1:44549,DS-d24d31ce-8ebb-4e8f-80f7-57eafb035986,DISK], DatanodeInfoWithStorage[127.0.0.1:46303,DS-c5d1f333-2009-4088-a127-ea3510d8b741,DISK], DatanodeInfoWithStorage[127.0.0.1:46571,DS-fcc29abb-27b8-4f7f-8d6f-59277f114679,DISK], DatanodeInfoWithStorage[127.0.0.1:41693,DS-e06a80fa-9390-4ffb-affd-660e708ddc51,DISK], DatanodeInfoWithStorage[127.0.0.1:43337,DS-cf573f0e-d1a0-4ea6-b4c2-32b637a8adc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.txns
component: hdfs:NameNode
v1: 1000000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-849453926-172.17.0.3-1597566062909:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35325,DS-20f9d917-3227-4eaa-8d70-ba58602db015,DISK], DatanodeInfoWithStorage[127.0.0.1:40922,DS-b1beca72-ed40-4ba2-a057-30c2a3634b01,DISK], DatanodeInfoWithStorage[127.0.0.1:46840,DS-176d7792-5ee2-439d-b367-cd1411ed92cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37108,DS-18749d13-dad4-43c1-8c5b-6d71b25fa561,DISK], DatanodeInfoWithStorage[127.0.0.1:40182,DS-6189aebd-f401-4cc6-955a-0f7915d31e01,DISK], DatanodeInfoWithStorage[127.0.0.1:34247,DS-f6c20aca-87ac-4b1c-9a4f-9ae93affe7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46511,DS-d8b5c667-c634-462f-a5e5-90df44aaeba3,DISK], DatanodeInfoWithStorage[127.0.0.1:43146,DS-d2edffe8-e3f1-4de6-af2a-90f1a2b21846,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-849453926-172.17.0.3-1597566062909:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35325,DS-20f9d917-3227-4eaa-8d70-ba58602db015,DISK], DatanodeInfoWithStorage[127.0.0.1:40922,DS-b1beca72-ed40-4ba2-a057-30c2a3634b01,DISK], DatanodeInfoWithStorage[127.0.0.1:46840,DS-176d7792-5ee2-439d-b367-cd1411ed92cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37108,DS-18749d13-dad4-43c1-8c5b-6d71b25fa561,DISK], DatanodeInfoWithStorage[127.0.0.1:40182,DS-6189aebd-f401-4cc6-955a-0f7915d31e01,DISK], DatanodeInfoWithStorage[127.0.0.1:34247,DS-f6c20aca-87ac-4b1c-9a4f-9ae93affe7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46511,DS-d8b5c667-c634-462f-a5e5-90df44aaeba3,DISK], DatanodeInfoWithStorage[127.0.0.1:43146,DS-d2edffe8-e3f1-4de6-af2a-90f1a2b21846,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.txns
component: hdfs:NameNode
v1: 1000000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-88218839-172.17.0.3-1597567115881:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33528,DS-6acd9d89-b434-4b47-9090-6d03e52f9ced,DISK], DatanodeInfoWithStorage[127.0.0.1:34307,DS-3e29bfd8-4e77-4902-b7ec-dcb6e956f102,DISK], DatanodeInfoWithStorage[127.0.0.1:36293,DS-b8793f1b-0f5a-49d7-ae47-c3953d18f5c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45968,DS-a31fc2e3-f728-4b8f-8869-472554c8e6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38215,DS-ffeef5b7-3848-46b0-b223-82050307d909,DISK], DatanodeInfoWithStorage[127.0.0.1:36978,DS-bed43f88-5bc9-4e73-ae79-cb3cf0c3a0fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45612,DS-567a891f-f0f3-4c3f-b5e7-f681cfadd40b,DISK], DatanodeInfoWithStorage[127.0.0.1:45694,DS-a9b8966b-813c-4f51-8704-8523f1053129,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-88218839-172.17.0.3-1597567115881:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33528,DS-6acd9d89-b434-4b47-9090-6d03e52f9ced,DISK], DatanodeInfoWithStorage[127.0.0.1:34307,DS-3e29bfd8-4e77-4902-b7ec-dcb6e956f102,DISK], DatanodeInfoWithStorage[127.0.0.1:36293,DS-b8793f1b-0f5a-49d7-ae47-c3953d18f5c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45968,DS-a31fc2e3-f728-4b8f-8869-472554c8e6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38215,DS-ffeef5b7-3848-46b0-b223-82050307d909,DISK], DatanodeInfoWithStorage[127.0.0.1:36978,DS-bed43f88-5bc9-4e73-ae79-cb3cf0c3a0fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45612,DS-567a891f-f0f3-4c3f-b5e7-f681cfadd40b,DISK], DatanodeInfoWithStorage[127.0.0.1:45694,DS-a9b8966b-813c-4f51-8704-8523f1053129,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.txns
component: hdfs:NameNode
v1: 1000000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-465138727-172.17.0.3-1597567336699:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39260,DS-bb16443f-7018-492d-aa3e-7facd26363f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33046,DS-324575ac-6e7e-485d-b4c1-2931a6e0a78c,DISK], DatanodeInfoWithStorage[127.0.0.1:44944,DS-6c6dbfc4-5f47-466c-9c6b-496cd84084af,DISK], DatanodeInfoWithStorage[127.0.0.1:37054,DS-1816aa48-2f06-40e7-b645-b686974720f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36169,DS-4bdea499-8491-43c5-b07f-a83b30ab4ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:42487,DS-fc6d36c3-fef6-49aa-9eaa-9885ec0d469b,DISK], DatanodeInfoWithStorage[127.0.0.1:43702,DS-2fd1a99c-cc95-4f1f-ada0-05bfd087ab17,DISK], DatanodeInfoWithStorage[127.0.0.1:33500,DS-4b735b72-f869-42c0-875f-1970fc1e9739,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-465138727-172.17.0.3-1597567336699:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39260,DS-bb16443f-7018-492d-aa3e-7facd26363f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33046,DS-324575ac-6e7e-485d-b4c1-2931a6e0a78c,DISK], DatanodeInfoWithStorage[127.0.0.1:44944,DS-6c6dbfc4-5f47-466c-9c6b-496cd84084af,DISK], DatanodeInfoWithStorage[127.0.0.1:37054,DS-1816aa48-2f06-40e7-b645-b686974720f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36169,DS-4bdea499-8491-43c5-b07f-a83b30ab4ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:42487,DS-fc6d36c3-fef6-49aa-9eaa-9885ec0d469b,DISK], DatanodeInfoWithStorage[127.0.0.1:43702,DS-2fd1a99c-cc95-4f1f-ada0-05bfd087ab17,DISK], DatanodeInfoWithStorage[127.0.0.1:33500,DS-4b735b72-f869-42c0-875f-1970fc1e9739,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.txns
component: hdfs:NameNode
v1: 1000000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1373880479-172.17.0.3-1597567810957:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44122,DS-74669a9c-60ba-4302-976d-4f417e2e9a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44114,DS-c4a39cba-a8a3-4861-8572-cc2fe0075137,DISK], DatanodeInfoWithStorage[127.0.0.1:46066,DS-60572d09-e27e-4d07-adf0-53e8aec16cca,DISK], DatanodeInfoWithStorage[127.0.0.1:34760,DS-feedcb68-c698-4b40-b277-efb19c24a044,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-a3a8fd20-f541-4dfa-9dca-70c0846211b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35486,DS-736eba22-0a0a-4ca3-870d-3c68a4093dda,DISK], DatanodeInfoWithStorage[127.0.0.1:43964,DS-433cc9d7-400a-4add-80f7-5f447e27e997,DISK], DatanodeInfoWithStorage[127.0.0.1:36592,DS-09cc4154-c033-4bd9-9acf-7c6e15116ae0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1373880479-172.17.0.3-1597567810957:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44122,DS-74669a9c-60ba-4302-976d-4f417e2e9a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44114,DS-c4a39cba-a8a3-4861-8572-cc2fe0075137,DISK], DatanodeInfoWithStorage[127.0.0.1:46066,DS-60572d09-e27e-4d07-adf0-53e8aec16cca,DISK], DatanodeInfoWithStorage[127.0.0.1:34760,DS-feedcb68-c698-4b40-b277-efb19c24a044,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-a3a8fd20-f541-4dfa-9dca-70c0846211b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35486,DS-736eba22-0a0a-4ca3-870d-3c68a4093dda,DISK], DatanodeInfoWithStorage[127.0.0.1:43964,DS-433cc9d7-400a-4add-80f7-5f447e27e997,DISK], DatanodeInfoWithStorage[127.0.0.1:36592,DS-09cc4154-c033-4bd9-9acf-7c6e15116ae0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5450
