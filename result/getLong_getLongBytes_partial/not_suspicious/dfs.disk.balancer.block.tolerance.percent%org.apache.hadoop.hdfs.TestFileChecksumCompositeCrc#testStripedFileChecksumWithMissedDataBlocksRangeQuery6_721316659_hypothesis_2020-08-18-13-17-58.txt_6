reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 99
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 99
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-459470483-172.17.0.7-1597756746542:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40686,DS-f7d0df33-75a9-47cc-9fa5-1f06a30bb156,DISK], DatanodeInfoWithStorage[127.0.0.1:46020,DS-39b63f5d-f1aa-4322-bde7-0ae9aefa1a72,DISK], DatanodeInfoWithStorage[127.0.0.1:39397,DS-74af0a88-338b-4a71-87e7-272c9b74390b,DISK], DatanodeInfoWithStorage[127.0.0.1:46493,DS-c403c8c3-bd93-42e4-88b4-ba9094ce959d,DISK], DatanodeInfoWithStorage[127.0.0.1:35834,DS-a026f099-c82a-4888-a2d8-61867804f657,DISK], DatanodeInfoWithStorage[127.0.0.1:35523,DS-8b2f0276-9568-484f-8c94-479f84e2b699,DISK], DatanodeInfoWithStorage[127.0.0.1:35629,DS-396b8ed1-4f6e-4bdb-9931-8886a5877bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:39294,DS-29e2488b-cabb-4ae1-99c9-86711af8eb91,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-459470483-172.17.0.7-1597756746542:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40686,DS-f7d0df33-75a9-47cc-9fa5-1f06a30bb156,DISK], DatanodeInfoWithStorage[127.0.0.1:46020,DS-39b63f5d-f1aa-4322-bde7-0ae9aefa1a72,DISK], DatanodeInfoWithStorage[127.0.0.1:39397,DS-74af0a88-338b-4a71-87e7-272c9b74390b,DISK], DatanodeInfoWithStorage[127.0.0.1:46493,DS-c403c8c3-bd93-42e4-88b4-ba9094ce959d,DISK], DatanodeInfoWithStorage[127.0.0.1:35834,DS-a026f099-c82a-4888-a2d8-61867804f657,DISK], DatanodeInfoWithStorage[127.0.0.1:35523,DS-8b2f0276-9568-484f-8c94-479f84e2b699,DISK], DatanodeInfoWithStorage[127.0.0.1:35629,DS-396b8ed1-4f6e-4bdb-9931-8886a5877bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:39294,DS-29e2488b-cabb-4ae1-99c9-86711af8eb91,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 99
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1691863143-172.17.0.7-1597756799159:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44906,DS-87dba05b-7d68-4ce6-9e7e-04bdc81ff544,DISK], DatanodeInfoWithStorage[127.0.0.1:42840,DS-2b3bb22e-503d-4d98-9a79-dc29b176ac81,DISK], DatanodeInfoWithStorage[127.0.0.1:37797,DS-812498bd-cb81-4e60-a88f-0e81ecf9ffaa,DISK], DatanodeInfoWithStorage[127.0.0.1:42357,DS-52bca46a-1e99-4494-a66e-7df1e7033129,DISK], DatanodeInfoWithStorage[127.0.0.1:35284,DS-5ce226c8-2675-454d-ae60-fb86bdd6a62e,DISK], DatanodeInfoWithStorage[127.0.0.1:43445,DS-18b0c51d-9554-459d-b1ef-976295440f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45676,DS-9e5679bf-5c0e-4ac1-9583-fd7625445801,DISK], DatanodeInfoWithStorage[127.0.0.1:34499,DS-879ab0e9-c4f6-4bd5-905e-c83a0771bd1c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1691863143-172.17.0.7-1597756799159:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44906,DS-87dba05b-7d68-4ce6-9e7e-04bdc81ff544,DISK], DatanodeInfoWithStorage[127.0.0.1:42840,DS-2b3bb22e-503d-4d98-9a79-dc29b176ac81,DISK], DatanodeInfoWithStorage[127.0.0.1:37797,DS-812498bd-cb81-4e60-a88f-0e81ecf9ffaa,DISK], DatanodeInfoWithStorage[127.0.0.1:42357,DS-52bca46a-1e99-4494-a66e-7df1e7033129,DISK], DatanodeInfoWithStorage[127.0.0.1:35284,DS-5ce226c8-2675-454d-ae60-fb86bdd6a62e,DISK], DatanodeInfoWithStorage[127.0.0.1:43445,DS-18b0c51d-9554-459d-b1ef-976295440f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45676,DS-9e5679bf-5c0e-4ac1-9583-fd7625445801,DISK], DatanodeInfoWithStorage[127.0.0.1:34499,DS-879ab0e9-c4f6-4bd5-905e-c83a0771bd1c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 99
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-286168728-172.17.0.7-1597757092471:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44663,DS-e5a2e34a-c6f2-4ce8-8098-bd0f6ccb8a68,DISK], DatanodeInfoWithStorage[127.0.0.1:42168,DS-f4675c1f-2135-427c-aad7-4cd6daa85686,DISK], DatanodeInfoWithStorage[127.0.0.1:46746,DS-63d113a5-594f-4949-bee6-b96879079e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:42823,DS-25c7dabd-80d0-4b86-9194-6d7857e50cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:42906,DS-afee343c-09da-4b1f-9740-49fe1a4b4276,DISK], DatanodeInfoWithStorage[127.0.0.1:45300,DS-0d076bc5-bf52-4bfa-bb03-49dc538e0c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:38970,DS-18eefcb2-fec2-4b4e-8c5a-dcbe40fbcd43,DISK], DatanodeInfoWithStorage[127.0.0.1:36512,DS-f83e7327-4a87-4201-8dfe-d4a538007fae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-286168728-172.17.0.7-1597757092471:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44663,DS-e5a2e34a-c6f2-4ce8-8098-bd0f6ccb8a68,DISK], DatanodeInfoWithStorage[127.0.0.1:42168,DS-f4675c1f-2135-427c-aad7-4cd6daa85686,DISK], DatanodeInfoWithStorage[127.0.0.1:46746,DS-63d113a5-594f-4949-bee6-b96879079e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:42823,DS-25c7dabd-80d0-4b86-9194-6d7857e50cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:42906,DS-afee343c-09da-4b1f-9740-49fe1a4b4276,DISK], DatanodeInfoWithStorage[127.0.0.1:45300,DS-0d076bc5-bf52-4bfa-bb03-49dc538e0c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:38970,DS-18eefcb2-fec2-4b4e-8c5a-dcbe40fbcd43,DISK], DatanodeInfoWithStorage[127.0.0.1:36512,DS-f83e7327-4a87-4201-8dfe-d4a538007fae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 99
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-74589068-172.17.0.7-1597757418285:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43286,DS-e65e11cb-6d6a-49ee-a0de-1acf5c349615,DISK], DatanodeInfoWithStorage[127.0.0.1:36164,DS-3b945447-722c-4f40-a403-95a6b859a208,DISK], DatanodeInfoWithStorage[127.0.0.1:46383,DS-b553eda9-1abc-467f-bf35-8d6626adff6e,DISK], DatanodeInfoWithStorage[127.0.0.1:35024,DS-c631da5c-88c1-4d6a-a4f8-665e11e75560,DISK], DatanodeInfoWithStorage[127.0.0.1:37304,DS-2d57b68a-47da-4015-9625-a7ed4edb9c08,DISK], DatanodeInfoWithStorage[127.0.0.1:41530,DS-19d60fbb-50d0-46d6-8726-5e3b984b3a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:46544,DS-e7cda118-9985-43fb-a7b5-aeb4a30c401c,DISK], DatanodeInfoWithStorage[127.0.0.1:42707,DS-fbfea4ff-eef0-4f1f-936a-40861c44e495,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-74589068-172.17.0.7-1597757418285:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43286,DS-e65e11cb-6d6a-49ee-a0de-1acf5c349615,DISK], DatanodeInfoWithStorage[127.0.0.1:36164,DS-3b945447-722c-4f40-a403-95a6b859a208,DISK], DatanodeInfoWithStorage[127.0.0.1:46383,DS-b553eda9-1abc-467f-bf35-8d6626adff6e,DISK], DatanodeInfoWithStorage[127.0.0.1:35024,DS-c631da5c-88c1-4d6a-a4f8-665e11e75560,DISK], DatanodeInfoWithStorage[127.0.0.1:37304,DS-2d57b68a-47da-4015-9625-a7ed4edb9c08,DISK], DatanodeInfoWithStorage[127.0.0.1:41530,DS-19d60fbb-50d0-46d6-8726-5e3b984b3a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:46544,DS-e7cda118-9985-43fb-a7b5-aeb4a30c401c,DISK], DatanodeInfoWithStorage[127.0.0.1:42707,DS-fbfea4ff-eef0-4f1f-936a-40861c44e495,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 99
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-570866530-172.17.0.7-1597757469243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44993,DS-8624e200-b001-4ca8-8fb6-1f7430e85839,DISK], DatanodeInfoWithStorage[127.0.0.1:37938,DS-27b5cda9-da6b-4a0e-9fde-de5c79072a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38074,DS-a90e3cd0-6a65-4f90-90c2-c81a6b1a597c,DISK], DatanodeInfoWithStorage[127.0.0.1:36744,DS-e6a0be3e-1707-4763-bd20-59b78e46c4d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43823,DS-742e8113-e7de-48c1-a0a8-ae013e64459a,DISK], DatanodeInfoWithStorage[127.0.0.1:40557,DS-f95f7b3d-444f-4be3-b275-935c0d89b9d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43015,DS-a05fcc0e-388e-4dd7-a41a-e309ac8c7618,DISK], DatanodeInfoWithStorage[127.0.0.1:45174,DS-8944f617-dc54-4da4-9796-4b17fa170223,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-570866530-172.17.0.7-1597757469243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44993,DS-8624e200-b001-4ca8-8fb6-1f7430e85839,DISK], DatanodeInfoWithStorage[127.0.0.1:37938,DS-27b5cda9-da6b-4a0e-9fde-de5c79072a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38074,DS-a90e3cd0-6a65-4f90-90c2-c81a6b1a597c,DISK], DatanodeInfoWithStorage[127.0.0.1:36744,DS-e6a0be3e-1707-4763-bd20-59b78e46c4d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43823,DS-742e8113-e7de-48c1-a0a8-ae013e64459a,DISK], DatanodeInfoWithStorage[127.0.0.1:40557,DS-f95f7b3d-444f-4be3-b275-935c0d89b9d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43015,DS-a05fcc0e-388e-4dd7-a41a-e309ac8c7618,DISK], DatanodeInfoWithStorage[127.0.0.1:45174,DS-8944f617-dc54-4da4-9796-4b17fa170223,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 99
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1465044558-172.17.0.7-1597757561341:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41762,DS-209fa091-1a7b-4771-85bd-6721b7b8b572,DISK], DatanodeInfoWithStorage[127.0.0.1:35656,DS-9a5ee8f3-4056-406d-ac7a-7fe05ea801ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34871,DS-2eb0a052-69d2-410a-be9a-e6bb2db83cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:34993,DS-fb5522b8-4f35-4210-8674-c4d53b348d15,DISK], DatanodeInfoWithStorage[127.0.0.1:43180,DS-f8a25cff-d414-42c6-b861-1e08af4dd6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46477,DS-e4fc2411-5931-48c5-aabc-08de153699bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41919,DS-9882e179-f274-4857-9f36-48a15e227a22,DISK], DatanodeInfoWithStorage[127.0.0.1:45697,DS-3de3f361-93d1-48f1-abe2-7a493d9454bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1465044558-172.17.0.7-1597757561341:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41762,DS-209fa091-1a7b-4771-85bd-6721b7b8b572,DISK], DatanodeInfoWithStorage[127.0.0.1:35656,DS-9a5ee8f3-4056-406d-ac7a-7fe05ea801ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34871,DS-2eb0a052-69d2-410a-be9a-e6bb2db83cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:34993,DS-fb5522b8-4f35-4210-8674-c4d53b348d15,DISK], DatanodeInfoWithStorage[127.0.0.1:43180,DS-f8a25cff-d414-42c6-b861-1e08af4dd6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46477,DS-e4fc2411-5931-48c5-aabc-08de153699bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41919,DS-9882e179-f274-4857-9f36-48a15e227a22,DISK], DatanodeInfoWithStorage[127.0.0.1:45697,DS-3de3f361-93d1-48f1-abe2-7a493d9454bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 99
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1008896954-172.17.0.7-1597757927502:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41803,DS-46137420-2938-468f-a9e9-6b94f690cbaf,DISK], DatanodeInfoWithStorage[127.0.0.1:40371,DS-6d18fd96-0c5e-40ab-8647-e368865636cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44900,DS-a8e086ee-698e-474d-a2a0-d83b8e4a63c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41309,DS-20d613a9-1979-4935-8993-6f79d30816b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37088,DS-d7dd87c7-5afc-4838-a79f-ce48a0853883,DISK], DatanodeInfoWithStorage[127.0.0.1:38130,DS-55ed3e07-c92b-4aee-9de6-7cc4dee4aa1e,DISK], DatanodeInfoWithStorage[127.0.0.1:37719,DS-5074a8db-3018-4eb2-870a-3f2ced4271c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46446,DS-2468aa55-7e74-468b-99f2-59f2ddc5da4a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1008896954-172.17.0.7-1597757927502:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41803,DS-46137420-2938-468f-a9e9-6b94f690cbaf,DISK], DatanodeInfoWithStorage[127.0.0.1:40371,DS-6d18fd96-0c5e-40ab-8647-e368865636cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44900,DS-a8e086ee-698e-474d-a2a0-d83b8e4a63c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41309,DS-20d613a9-1979-4935-8993-6f79d30816b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37088,DS-d7dd87c7-5afc-4838-a79f-ce48a0853883,DISK], DatanodeInfoWithStorage[127.0.0.1:38130,DS-55ed3e07-c92b-4aee-9de6-7cc4dee4aa1e,DISK], DatanodeInfoWithStorage[127.0.0.1:37719,DS-5074a8db-3018-4eb2-870a-3f2ced4271c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46446,DS-2468aa55-7e74-468b-99f2-59f2ddc5da4a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 99
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1098873585-172.17.0.7-1597757978315:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40745,DS-0e53470f-9dbf-4f6a-8128-8004da957baa,DISK], DatanodeInfoWithStorage[127.0.0.1:44581,DS-9010e111-a71c-4e5e-9070-1cf8981363e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38250,DS-8e0d58b5-1da2-48d1-836c-7548b07b0976,DISK], DatanodeInfoWithStorage[127.0.0.1:40611,DS-3d3158a8-3bd1-42ff-b010-b75de74a7c58,DISK], DatanodeInfoWithStorage[127.0.0.1:41307,DS-833cf2ab-b77d-49c6-bcc9-b5d665e4c38b,DISK], DatanodeInfoWithStorage[127.0.0.1:40683,DS-4d0d9949-86cd-447e-8b3c-24d644ffabd9,DISK], DatanodeInfoWithStorage[127.0.0.1:39329,DS-f055d6fb-3022-4c3f-952f-33e1651f3090,DISK], DatanodeInfoWithStorage[127.0.0.1:37718,DS-0544b990-790b-4f3d-b229-14d85ed34242,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1098873585-172.17.0.7-1597757978315:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40745,DS-0e53470f-9dbf-4f6a-8128-8004da957baa,DISK], DatanodeInfoWithStorage[127.0.0.1:44581,DS-9010e111-a71c-4e5e-9070-1cf8981363e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38250,DS-8e0d58b5-1da2-48d1-836c-7548b07b0976,DISK], DatanodeInfoWithStorage[127.0.0.1:40611,DS-3d3158a8-3bd1-42ff-b010-b75de74a7c58,DISK], DatanodeInfoWithStorage[127.0.0.1:41307,DS-833cf2ab-b77d-49c6-bcc9-b5d665e4c38b,DISK], DatanodeInfoWithStorage[127.0.0.1:40683,DS-4d0d9949-86cd-447e-8b3c-24d644ffabd9,DISK], DatanodeInfoWithStorage[127.0.0.1:39329,DS-f055d6fb-3022-4c3f-952f-33e1651f3090,DISK], DatanodeInfoWithStorage[127.0.0.1:37718,DS-0544b990-790b-4f3d-b229-14d85ed34242,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 99
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1014216693-172.17.0.7-1597758027423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35924,DS-b957763a-422b-473b-8e9a-a869961330d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33234,DS-aef9f053-f5f0-424d-a5bf-b803b730ad4e,DISK], DatanodeInfoWithStorage[127.0.0.1:43728,DS-d0c8c94a-be88-4248-9127-a109995c20ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46256,DS-e503db6f-cebc-4180-9ed9-93abd4f0a12e,DISK], DatanodeInfoWithStorage[127.0.0.1:34002,DS-0e9f6cf1-edc6-4104-b219-87e6f32ed27e,DISK], DatanodeInfoWithStorage[127.0.0.1:40806,DS-4542ff8b-de0f-4fc3-afc8-27b491fdd0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44871,DS-36ad5e5b-a165-451f-b9b9-ca5291c3c3f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35616,DS-6954d230-bb9c-495c-9556-45be61d2d7a5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1014216693-172.17.0.7-1597758027423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35924,DS-b957763a-422b-473b-8e9a-a869961330d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33234,DS-aef9f053-f5f0-424d-a5bf-b803b730ad4e,DISK], DatanodeInfoWithStorage[127.0.0.1:43728,DS-d0c8c94a-be88-4248-9127-a109995c20ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46256,DS-e503db6f-cebc-4180-9ed9-93abd4f0a12e,DISK], DatanodeInfoWithStorage[127.0.0.1:34002,DS-0e9f6cf1-edc6-4104-b219-87e6f32ed27e,DISK], DatanodeInfoWithStorage[127.0.0.1:40806,DS-4542ff8b-de0f-4fc3-afc8-27b491fdd0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44871,DS-36ad5e5b-a165-451f-b9b9-ca5291c3c3f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35616,DS-6954d230-bb9c-495c-9556-45be61d2d7a5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 99
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1858319408-172.17.0.7-1597758119624:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38965,DS-551dd53a-a3b3-4c61-bbe8-df96c271a9c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33263,DS-85de27b4-fa1d-4cff-b278-3aa2445ccde6,DISK], DatanodeInfoWithStorage[127.0.0.1:39984,DS-b4e2d7ed-a587-46cb-a50a-1e4fa7bf854d,DISK], DatanodeInfoWithStorage[127.0.0.1:34789,DS-28535a11-9dc5-4e77-951f-b3dd80109da6,DISK], DatanodeInfoWithStorage[127.0.0.1:42714,DS-7eb25f44-a8bc-4686-85ea-f276a669d760,DISK], DatanodeInfoWithStorage[127.0.0.1:46231,DS-aa075b51-70f5-4a0b-97e0-7c0151011524,DISK], DatanodeInfoWithStorage[127.0.0.1:38409,DS-dee8cf07-4475-4929-8363-1e6e5873f819,DISK], DatanodeInfoWithStorage[127.0.0.1:38859,DS-d97dde19-862b-4380-be50-0421629aad7a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1858319408-172.17.0.7-1597758119624:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38965,DS-551dd53a-a3b3-4c61-bbe8-df96c271a9c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33263,DS-85de27b4-fa1d-4cff-b278-3aa2445ccde6,DISK], DatanodeInfoWithStorage[127.0.0.1:39984,DS-b4e2d7ed-a587-46cb-a50a-1e4fa7bf854d,DISK], DatanodeInfoWithStorage[127.0.0.1:34789,DS-28535a11-9dc5-4e77-951f-b3dd80109da6,DISK], DatanodeInfoWithStorage[127.0.0.1:42714,DS-7eb25f44-a8bc-4686-85ea-f276a669d760,DISK], DatanodeInfoWithStorage[127.0.0.1:46231,DS-aa075b51-70f5-4a0b-97e0-7c0151011524,DISK], DatanodeInfoWithStorage[127.0.0.1:38409,DS-dee8cf07-4475-4929-8363-1e6e5873f819,DISK], DatanodeInfoWithStorage[127.0.0.1:38859,DS-d97dde19-862b-4380-be50-0421629aad7a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 99
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1575019136-172.17.0.7-1597758347492:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42426,DS-784e3148-5453-408f-9f8a-6f20ca461929,DISK], DatanodeInfoWithStorage[127.0.0.1:32770,DS-5df92dfc-463a-49d5-979f-c44a1373cfe0,DISK], DatanodeInfoWithStorage[127.0.0.1:34490,DS-bbc2a85d-64a6-4335-9a0c-87a040cff9fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40024,DS-171da32f-f437-4b2c-9f41-ee15b5f37377,DISK], DatanodeInfoWithStorage[127.0.0.1:37063,DS-a99a13d2-1b45-436b-88e9-56379b22758d,DISK], DatanodeInfoWithStorage[127.0.0.1:34940,DS-de047acd-b946-4953-9993-9de84e24270f,DISK], DatanodeInfoWithStorage[127.0.0.1:39454,DS-5641a9ad-5119-4103-9ce3-5038f3ff4b29,DISK], DatanodeInfoWithStorage[127.0.0.1:33666,DS-b6cb57fe-cb6c-40d6-91a9-2940dbc9f032,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1575019136-172.17.0.7-1597758347492:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42426,DS-784e3148-5453-408f-9f8a-6f20ca461929,DISK], DatanodeInfoWithStorage[127.0.0.1:32770,DS-5df92dfc-463a-49d5-979f-c44a1373cfe0,DISK], DatanodeInfoWithStorage[127.0.0.1:34490,DS-bbc2a85d-64a6-4335-9a0c-87a040cff9fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40024,DS-171da32f-f437-4b2c-9f41-ee15b5f37377,DISK], DatanodeInfoWithStorage[127.0.0.1:37063,DS-a99a13d2-1b45-436b-88e9-56379b22758d,DISK], DatanodeInfoWithStorage[127.0.0.1:34940,DS-de047acd-b946-4953-9993-9de84e24270f,DISK], DatanodeInfoWithStorage[127.0.0.1:39454,DS-5641a9ad-5119-4103-9ce3-5038f3ff4b29,DISK], DatanodeInfoWithStorage[127.0.0.1:33666,DS-b6cb57fe-cb6c-40d6-91a9-2940dbc9f032,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 99
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1660769439-172.17.0.7-1597758441867:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34110,DS-c041b36d-9f3d-4ba2-9df6-cd0494257a88,DISK], DatanodeInfoWithStorage[127.0.0.1:44079,DS-13303112-3e11-4c40-bb9b-950d5fae9070,DISK], DatanodeInfoWithStorage[127.0.0.1:37150,DS-a66e2ffe-80eb-41f9-b31d-55895b456e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:39387,DS-407f5837-9aa3-4496-ade8-b64ac09f2e12,DISK], DatanodeInfoWithStorage[127.0.0.1:32873,DS-1c3b7e93-ba35-4e89-9ba1-5fd200f60f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:38017,DS-320465e9-cf80-45c7-9671-5e4e7f347a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:37297,DS-98cd3800-ff1e-418e-a4b2-fb4135314ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:39318,DS-799f6a31-ac47-4e5d-b4da-8aa1ecc6b59d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1660769439-172.17.0.7-1597758441867:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34110,DS-c041b36d-9f3d-4ba2-9df6-cd0494257a88,DISK], DatanodeInfoWithStorage[127.0.0.1:44079,DS-13303112-3e11-4c40-bb9b-950d5fae9070,DISK], DatanodeInfoWithStorage[127.0.0.1:37150,DS-a66e2ffe-80eb-41f9-b31d-55895b456e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:39387,DS-407f5837-9aa3-4496-ade8-b64ac09f2e12,DISK], DatanodeInfoWithStorage[127.0.0.1:32873,DS-1c3b7e93-ba35-4e89-9ba1-5fd200f60f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:38017,DS-320465e9-cf80-45c7-9671-5e4e7f347a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:37297,DS-98cd3800-ff1e-418e-a4b2-fb4135314ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:39318,DS-799f6a31-ac47-4e5d-b4da-8aa1ecc6b59d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 99
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-274260320-172.17.0.7-1597758644429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41668,DS-2677f360-68a2-480c-9906-ab7b619044d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40362,DS-2e6c7353-dc95-4ec1-82be-43e0acc4698d,DISK], DatanodeInfoWithStorage[127.0.0.1:38295,DS-f08488e5-17a1-4cc8-9b12-f41efcb2fec6,DISK], DatanodeInfoWithStorage[127.0.0.1:39416,DS-0ab387b3-dfc5-407b-ba56-51ca6fb82e54,DISK], DatanodeInfoWithStorage[127.0.0.1:37846,DS-109f788a-99f6-4744-a2fb-1960e32242cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42232,DS-c6bf7af4-d47b-48fb-9e65-4adc3869c436,DISK], DatanodeInfoWithStorage[127.0.0.1:34420,DS-7d948404-1864-4566-bfcf-6de3d7892dba,DISK], DatanodeInfoWithStorage[127.0.0.1:33150,DS-f9742306-6e90-4f7d-99ea-bf7312546cbb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-274260320-172.17.0.7-1597758644429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41668,DS-2677f360-68a2-480c-9906-ab7b619044d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40362,DS-2e6c7353-dc95-4ec1-82be-43e0acc4698d,DISK], DatanodeInfoWithStorage[127.0.0.1:38295,DS-f08488e5-17a1-4cc8-9b12-f41efcb2fec6,DISK], DatanodeInfoWithStorage[127.0.0.1:39416,DS-0ab387b3-dfc5-407b-ba56-51ca6fb82e54,DISK], DatanodeInfoWithStorage[127.0.0.1:37846,DS-109f788a-99f6-4744-a2fb-1960e32242cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42232,DS-c6bf7af4-d47b-48fb-9e65-4adc3869c436,DISK], DatanodeInfoWithStorage[127.0.0.1:34420,DS-7d948404-1864-4566-bfcf-6de3d7892dba,DISK], DatanodeInfoWithStorage[127.0.0.1:33150,DS-f9742306-6e90-4f7d-99ea-bf7312546cbb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 99
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1059744612-172.17.0.7-1597758688895:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40436,DS-81d93bf3-9f2b-4d3c-b42d-d348c52e7f95,DISK], DatanodeInfoWithStorage[127.0.0.1:46545,DS-d6f23dd6-e038-4ab9-a35e-418674f8969f,DISK], DatanodeInfoWithStorage[127.0.0.1:38653,DS-7328b67a-f88c-4744-962c-2dfad1f5537e,DISK], DatanodeInfoWithStorage[127.0.0.1:41531,DS-9bb3c9d5-eb50-46cb-924b-e6401c35415b,DISK], DatanodeInfoWithStorage[127.0.0.1:42580,DS-dbda55c6-19fc-434b-b7df-11c824cf885f,DISK], DatanodeInfoWithStorage[127.0.0.1:37908,DS-9a610091-1019-4020-b489-a8ef9ef5cdb9,DISK], DatanodeInfoWithStorage[127.0.0.1:44303,DS-da5d8d41-c9b6-4f37-aeb4-05a72f4ba2d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40065,DS-44cd1bd2-a519-4758-8a57-9ff6cf3a1db7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1059744612-172.17.0.7-1597758688895:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40436,DS-81d93bf3-9f2b-4d3c-b42d-d348c52e7f95,DISK], DatanodeInfoWithStorage[127.0.0.1:46545,DS-d6f23dd6-e038-4ab9-a35e-418674f8969f,DISK], DatanodeInfoWithStorage[127.0.0.1:38653,DS-7328b67a-f88c-4744-962c-2dfad1f5537e,DISK], DatanodeInfoWithStorage[127.0.0.1:41531,DS-9bb3c9d5-eb50-46cb-924b-e6401c35415b,DISK], DatanodeInfoWithStorage[127.0.0.1:42580,DS-dbda55c6-19fc-434b-b7df-11c824cf885f,DISK], DatanodeInfoWithStorage[127.0.0.1:37908,DS-9a610091-1019-4020-b489-a8ef9ef5cdb9,DISK], DatanodeInfoWithStorage[127.0.0.1:44303,DS-da5d8d41-c9b6-4f37-aeb4-05a72f4ba2d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40065,DS-44cd1bd2-a519-4758-8a57-9ff6cf3a1db7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 99
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1838251122-172.17.0.7-1597758786106:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34992,DS-bd8b0554-55bd-40ba-86a4-c7fcd90fbe75,DISK], DatanodeInfoWithStorage[127.0.0.1:38707,DS-701f70ca-6806-4752-b8ea-e71543b4e35b,DISK], DatanodeInfoWithStorage[127.0.0.1:35946,DS-0edd0d41-3b8b-43d1-91e1-78778a490de3,DISK], DatanodeInfoWithStorage[127.0.0.1:41548,DS-9e7c522d-feb2-48d8-a4a3-d5b86d38ef17,DISK], DatanodeInfoWithStorage[127.0.0.1:46054,DS-98abe072-919c-4cbc-afe7-8093a4ae5092,DISK], DatanodeInfoWithStorage[127.0.0.1:42903,DS-1050632c-3e0f-488b-b899-d01ab931038e,DISK], DatanodeInfoWithStorage[127.0.0.1:42610,DS-d9b02f92-1513-406f-8bdb-30966446f1d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45587,DS-600099cc-557f-40ce-b146-f97881041d78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1838251122-172.17.0.7-1597758786106:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34992,DS-bd8b0554-55bd-40ba-86a4-c7fcd90fbe75,DISK], DatanodeInfoWithStorage[127.0.0.1:38707,DS-701f70ca-6806-4752-b8ea-e71543b4e35b,DISK], DatanodeInfoWithStorage[127.0.0.1:35946,DS-0edd0d41-3b8b-43d1-91e1-78778a490de3,DISK], DatanodeInfoWithStorage[127.0.0.1:41548,DS-9e7c522d-feb2-48d8-a4a3-d5b86d38ef17,DISK], DatanodeInfoWithStorage[127.0.0.1:46054,DS-98abe072-919c-4cbc-afe7-8093a4ae5092,DISK], DatanodeInfoWithStorage[127.0.0.1:42903,DS-1050632c-3e0f-488b-b899-d01ab931038e,DISK], DatanodeInfoWithStorage[127.0.0.1:42610,DS-d9b02f92-1513-406f-8bdb-30966446f1d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45587,DS-600099cc-557f-40ce-b146-f97881041d78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 99
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-3290075-172.17.0.7-1597759352303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39813,DS-b0b8abaf-3428-4924-9b77-8d9c49ef5d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43547,DS-746996e5-1e34-40cb-9f70-0a46ece443cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40576,DS-7334999f-ac8f-48f5-be23-b231b7ff3046,DISK], DatanodeInfoWithStorage[127.0.0.1:35264,DS-a31b9dc6-23ae-46b0-8846-033e232df72b,DISK], DatanodeInfoWithStorage[127.0.0.1:46317,DS-0fa2646c-3a9e-44cb-8a05-61b03e8b6eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:35693,DS-bf9c6347-0896-49c8-9180-00c9a1a81b88,DISK], DatanodeInfoWithStorage[127.0.0.1:38714,DS-4dce25da-7587-47b5-b3fe-729bc506e366,DISK], DatanodeInfoWithStorage[127.0.0.1:36919,DS-2a39063c-29b0-4efe-a6b9-572c4dafa769,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-3290075-172.17.0.7-1597759352303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39813,DS-b0b8abaf-3428-4924-9b77-8d9c49ef5d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43547,DS-746996e5-1e34-40cb-9f70-0a46ece443cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40576,DS-7334999f-ac8f-48f5-be23-b231b7ff3046,DISK], DatanodeInfoWithStorage[127.0.0.1:35264,DS-a31b9dc6-23ae-46b0-8846-033e232df72b,DISK], DatanodeInfoWithStorage[127.0.0.1:46317,DS-0fa2646c-3a9e-44cb-8a05-61b03e8b6eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:35693,DS-bf9c6347-0896-49c8-9180-00c9a1a81b88,DISK], DatanodeInfoWithStorage[127.0.0.1:38714,DS-4dce25da-7587-47b5-b3fe-729bc506e366,DISK], DatanodeInfoWithStorage[127.0.0.1:36919,DS-2a39063c-29b0-4efe-a6b9-572c4dafa769,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 99
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1585250780-172.17.0.7-1597759548309:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46183,DS-5e7ba526-e9bb-49e4-bd39-213015e63004,DISK], DatanodeInfoWithStorage[127.0.0.1:43427,DS-55de625f-4a30-4d6c-b913-88607798e09a,DISK], DatanodeInfoWithStorage[127.0.0.1:45686,DS-c376fb13-f2c2-488b-85df-a33b9f0ab6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35325,DS-30551773-a8c9-4d18-8de8-e29c107a1319,DISK], DatanodeInfoWithStorage[127.0.0.1:37027,DS-adf18e7b-75b4-4c67-8b47-7f05b51b1cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:34722,DS-22fe8611-f86d-4765-b086-4e6721fc88e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35010,DS-d6909046-2998-4fff-89a3-e505c8f751d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34509,DS-a932d4b3-4d50-4ec2-943a-4ba8ddcdb94d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1585250780-172.17.0.7-1597759548309:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46183,DS-5e7ba526-e9bb-49e4-bd39-213015e63004,DISK], DatanodeInfoWithStorage[127.0.0.1:43427,DS-55de625f-4a30-4d6c-b913-88607798e09a,DISK], DatanodeInfoWithStorage[127.0.0.1:45686,DS-c376fb13-f2c2-488b-85df-a33b9f0ab6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35325,DS-30551773-a8c9-4d18-8de8-e29c107a1319,DISK], DatanodeInfoWithStorage[127.0.0.1:37027,DS-adf18e7b-75b4-4c67-8b47-7f05b51b1cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:34722,DS-22fe8611-f86d-4765-b086-4e6721fc88e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35010,DS-d6909046-2998-4fff-89a3-e505c8f751d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34509,DS-a932d4b3-4d50-4ec2-943a-4ba8ddcdb94d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 99
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1526169926-172.17.0.7-1597759592469:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34869,DS-82bd7b68-5115-43d7-aa99-5133d6ac26a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33677,DS-f37ee2e8-26f7-44da-9b8c-5995df0fcdd4,DISK], DatanodeInfoWithStorage[127.0.0.1:37943,DS-f0bb483e-b5b1-43e9-9f26-fcf93e19ebbf,DISK], DatanodeInfoWithStorage[127.0.0.1:41894,DS-951ea316-3263-433c-8139-44a32260e720,DISK], DatanodeInfoWithStorage[127.0.0.1:42836,DS-a9017ff4-889c-4605-b4ef-bc80d3a60556,DISK], DatanodeInfoWithStorage[127.0.0.1:34255,DS-5504008d-7018-4708-a7f7-584d86e29ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:43761,DS-b900a219-c679-4cb8-adb7-2808a97efa09,DISK], DatanodeInfoWithStorage[127.0.0.1:38842,DS-7ec5d2b9-7cd5-4ac1-93a2-1100c0a318be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1526169926-172.17.0.7-1597759592469:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34869,DS-82bd7b68-5115-43d7-aa99-5133d6ac26a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33677,DS-f37ee2e8-26f7-44da-9b8c-5995df0fcdd4,DISK], DatanodeInfoWithStorage[127.0.0.1:37943,DS-f0bb483e-b5b1-43e9-9f26-fcf93e19ebbf,DISK], DatanodeInfoWithStorage[127.0.0.1:41894,DS-951ea316-3263-433c-8139-44a32260e720,DISK], DatanodeInfoWithStorage[127.0.0.1:42836,DS-a9017ff4-889c-4605-b4ef-bc80d3a60556,DISK], DatanodeInfoWithStorage[127.0.0.1:34255,DS-5504008d-7018-4708-a7f7-584d86e29ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:43761,DS-b900a219-c679-4cb8-adb7-2808a97efa09,DISK], DatanodeInfoWithStorage[127.0.0.1:38842,DS-7ec5d2b9-7cd5-4ac1-93a2-1100c0a318be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 99
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1514358809-172.17.0.7-1597759699014:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44540,DS-8ccec827-a879-4d1f-aa66-8953f92c9f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:33193,DS-eb8c7b41-a962-442a-b8bb-ab9e5a096a20,DISK], DatanodeInfoWithStorage[127.0.0.1:35591,DS-e605465b-b516-4016-8348-7cba5f4b4769,DISK], DatanodeInfoWithStorage[127.0.0.1:45542,DS-39ceb124-66ec-43a9-b973-77f203c9141a,DISK], DatanodeInfoWithStorage[127.0.0.1:35119,DS-63f83ce8-a20c-4f2e-a929-64b0e42c45fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40101,DS-d520ce60-966f-4b48-9c76-44cbb9cae7ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40639,DS-ec355d88-42a4-49a0-b196-c219f6bfc7b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34785,DS-f5dd6d6e-f6b9-49d2-87e3-bf5fac60f63c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1514358809-172.17.0.7-1597759699014:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44540,DS-8ccec827-a879-4d1f-aa66-8953f92c9f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:33193,DS-eb8c7b41-a962-442a-b8bb-ab9e5a096a20,DISK], DatanodeInfoWithStorage[127.0.0.1:35591,DS-e605465b-b516-4016-8348-7cba5f4b4769,DISK], DatanodeInfoWithStorage[127.0.0.1:45542,DS-39ceb124-66ec-43a9-b973-77f203c9141a,DISK], DatanodeInfoWithStorage[127.0.0.1:35119,DS-63f83ce8-a20c-4f2e-a929-64b0e42c45fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40101,DS-d520ce60-966f-4b48-9c76-44cbb9cae7ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40639,DS-ec355d88-42a4-49a0-b196-c219f6bfc7b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34785,DS-f5dd6d6e-f6b9-49d2-87e3-bf5fac60f63c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 99
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-784767243-172.17.0.7-1597759836499:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40074,DS-6a118832-663c-4d44-b02a-1413495cd945,DISK], DatanodeInfoWithStorage[127.0.0.1:36159,DS-f75a55fc-cce9-4cf3-a641-03ff63416228,DISK], DatanodeInfoWithStorage[127.0.0.1:35086,DS-8d2b8282-26fb-4e0e-9bc1-dc050fc8c9ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45067,DS-4366df45-6c69-48d0-a319-115f6ed77fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:45957,DS-05058ba5-2c2d-4205-ac68-711343bf78f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35876,DS-56b77ea8-52da-49d2-b661-c881997161df,DISK], DatanodeInfoWithStorage[127.0.0.1:40515,DS-b966b48a-7461-43ee-9d13-fde704585cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:40294,DS-4a75a701-3c48-4603-8d7c-cdb34627a2d9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-784767243-172.17.0.7-1597759836499:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40074,DS-6a118832-663c-4d44-b02a-1413495cd945,DISK], DatanodeInfoWithStorage[127.0.0.1:36159,DS-f75a55fc-cce9-4cf3-a641-03ff63416228,DISK], DatanodeInfoWithStorage[127.0.0.1:35086,DS-8d2b8282-26fb-4e0e-9bc1-dc050fc8c9ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45067,DS-4366df45-6c69-48d0-a319-115f6ed77fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:45957,DS-05058ba5-2c2d-4205-ac68-711343bf78f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35876,DS-56b77ea8-52da-49d2-b661-c881997161df,DISK], DatanodeInfoWithStorage[127.0.0.1:40515,DS-b966b48a-7461-43ee-9d13-fde704585cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:40294,DS-4a75a701-3c48-4603-8d7c-cdb34627a2d9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 99
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-833201521-172.17.0.7-1597760062782:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34839,DS-4940b845-ac7c-444c-8337-3aa7168e4fde,DISK], DatanodeInfoWithStorage[127.0.0.1:44633,DS-670062ed-53c9-45f9-b324-0fa34ea5f155,DISK], DatanodeInfoWithStorage[127.0.0.1:35602,DS-24a7d8ef-25ec-433b-b8e6-bb7b63ad6a04,DISK], DatanodeInfoWithStorage[127.0.0.1:33960,DS-415def31-e12f-410e-baf6-ff9fc8116a16,DISK], DatanodeInfoWithStorage[127.0.0.1:46553,DS-d4778466-bb13-4ec1-9afd-c5026c6a8d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:43015,DS-00695ab9-8258-4782-8f4f-32e4550ac4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44205,DS-da8329b3-8340-43c0-b831-9ca966103259,DISK], DatanodeInfoWithStorage[127.0.0.1:40745,DS-2be38d7a-6891-4d70-bbde-814a50645054,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-833201521-172.17.0.7-1597760062782:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34839,DS-4940b845-ac7c-444c-8337-3aa7168e4fde,DISK], DatanodeInfoWithStorage[127.0.0.1:44633,DS-670062ed-53c9-45f9-b324-0fa34ea5f155,DISK], DatanodeInfoWithStorage[127.0.0.1:35602,DS-24a7d8ef-25ec-433b-b8e6-bb7b63ad6a04,DISK], DatanodeInfoWithStorage[127.0.0.1:33960,DS-415def31-e12f-410e-baf6-ff9fc8116a16,DISK], DatanodeInfoWithStorage[127.0.0.1:46553,DS-d4778466-bb13-4ec1-9afd-c5026c6a8d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:43015,DS-00695ab9-8258-4782-8f4f-32e4550ac4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44205,DS-da8329b3-8340-43c0-b831-9ca966103259,DISK], DatanodeInfoWithStorage[127.0.0.1:40745,DS-2be38d7a-6891-4d70-bbde-814a50645054,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 99
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2093977845-172.17.0.7-1597760478843:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35648,DS-f02f29a7-476a-469a-b55a-86af0afbab3c,DISK], DatanodeInfoWithStorage[127.0.0.1:33022,DS-6a5b149a-d007-431d-84e3-43e5db1ea37f,DISK], DatanodeInfoWithStorage[127.0.0.1:37514,DS-3becacea-76c4-4e8c-a2c9-dc4f2c0a16e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34158,DS-8ecfbcf6-d755-460e-92f7-c65b289c10ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43241,DS-ef6e902e-cab5-4e03-88ab-417df99b3c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37785,DS-00e566f5-a733-43f8-b64d-3b0df19341b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43015,DS-6e9929ae-c71b-4722-90f6-dea50943980e,DISK], DatanodeInfoWithStorage[127.0.0.1:35395,DS-03465ac3-0832-4f6c-af48-1c5ef354f20f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2093977845-172.17.0.7-1597760478843:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35648,DS-f02f29a7-476a-469a-b55a-86af0afbab3c,DISK], DatanodeInfoWithStorage[127.0.0.1:33022,DS-6a5b149a-d007-431d-84e3-43e5db1ea37f,DISK], DatanodeInfoWithStorage[127.0.0.1:37514,DS-3becacea-76c4-4e8c-a2c9-dc4f2c0a16e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34158,DS-8ecfbcf6-d755-460e-92f7-c65b289c10ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43241,DS-ef6e902e-cab5-4e03-88ab-417df99b3c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37785,DS-00e566f5-a733-43f8-b64d-3b0df19341b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43015,DS-6e9929ae-c71b-4722-90f6-dea50943980e,DISK], DatanodeInfoWithStorage[127.0.0.1:35395,DS-03465ac3-0832-4f6c-af48-1c5ef354f20f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 99
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1316332398-172.17.0.7-1597760585087:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44659,DS-5785ccfd-74c1-4d25-8eb8-45f4b16ed7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43194,DS-eda98671-2680-4467-bac8-68dec963438d,DISK], DatanodeInfoWithStorage[127.0.0.1:38230,DS-07cf3de4-4b03-4ba3-80c9-a204741ae3b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41307,DS-f6a68998-bdbd-45ba-a1ea-199cf85afe29,DISK], DatanodeInfoWithStorage[127.0.0.1:36456,DS-45065645-cfb7-4d08-897c-45be959ad5b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46721,DS-c6b4e244-e620-4723-b6c1-06eed78a40e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42607,DS-6e5ce924-37e8-4f7c-af73-d3dd8a972dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:37523,DS-b8816a11-7863-46f8-91b5-f9a861546f38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1316332398-172.17.0.7-1597760585087:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44659,DS-5785ccfd-74c1-4d25-8eb8-45f4b16ed7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43194,DS-eda98671-2680-4467-bac8-68dec963438d,DISK], DatanodeInfoWithStorage[127.0.0.1:38230,DS-07cf3de4-4b03-4ba3-80c9-a204741ae3b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41307,DS-f6a68998-bdbd-45ba-a1ea-199cf85afe29,DISK], DatanodeInfoWithStorage[127.0.0.1:36456,DS-45065645-cfb7-4d08-897c-45be959ad5b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46721,DS-c6b4e244-e620-4723-b6c1-06eed78a40e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42607,DS-6e5ce924-37e8-4f7c-af73-d3dd8a972dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:37523,DS-b8816a11-7863-46f8-91b5-f9a861546f38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 99
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1985199953-172.17.0.7-1597760635689:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38145,DS-6c9451ff-2bf3-4d26-a7ce-4535823f6a17,DISK], DatanodeInfoWithStorage[127.0.0.1:40225,DS-8d0ea178-4a3c-4f0e-847c-103f40fa8fae,DISK], DatanodeInfoWithStorage[127.0.0.1:38249,DS-4b3c6271-7eff-46e8-83ab-e1fb0ddaa0db,DISK], DatanodeInfoWithStorage[127.0.0.1:34532,DS-ac3ca622-c85c-41f1-9f4d-cb2f8c85b113,DISK], DatanodeInfoWithStorage[127.0.0.1:35955,DS-1e6cf64c-b313-478b-84a8-03b9de8f10f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35448,DS-4a2e1b8b-c070-4683-aa63-e3c2603f8c34,DISK], DatanodeInfoWithStorage[127.0.0.1:44831,DS-203dbf13-63fc-425a-a089-2fbd7aa9cc98,DISK], DatanodeInfoWithStorage[127.0.0.1:36863,DS-67dacff0-2702-48c4-8c86-9aa53087eba5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1985199953-172.17.0.7-1597760635689:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38145,DS-6c9451ff-2bf3-4d26-a7ce-4535823f6a17,DISK], DatanodeInfoWithStorage[127.0.0.1:40225,DS-8d0ea178-4a3c-4f0e-847c-103f40fa8fae,DISK], DatanodeInfoWithStorage[127.0.0.1:38249,DS-4b3c6271-7eff-46e8-83ab-e1fb0ddaa0db,DISK], DatanodeInfoWithStorage[127.0.0.1:34532,DS-ac3ca622-c85c-41f1-9f4d-cb2f8c85b113,DISK], DatanodeInfoWithStorage[127.0.0.1:35955,DS-1e6cf64c-b313-478b-84a8-03b9de8f10f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35448,DS-4a2e1b8b-c070-4683-aa63-e3c2603f8c34,DISK], DatanodeInfoWithStorage[127.0.0.1:44831,DS-203dbf13-63fc-425a-a089-2fbd7aa9cc98,DISK], DatanodeInfoWithStorage[127.0.0.1:36863,DS-67dacff0-2702-48c4-8c86-9aa53087eba5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 99
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1489383076-172.17.0.7-1597760681263:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43165,DS-6755c017-c030-4289-aa7e-4ba2e40188a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40639,DS-95916e32-e847-4b84-8636-89e6c4c8c5dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35010,DS-ce915e73-5f4f-42a6-9ec0-50ee0a261a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:41151,DS-f895f63e-f98b-4a58-a017-84ae9e791cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:44429,DS-3379d91a-cb01-47a0-91a4-b58d47b92611,DISK], DatanodeInfoWithStorage[127.0.0.1:35379,DS-1151fe81-1b7e-4a01-8396-dac5d2199067,DISK], DatanodeInfoWithStorage[127.0.0.1:35119,DS-1fe5fa2a-6546-4d52-ab95-c0f230073656,DISK], DatanodeInfoWithStorage[127.0.0.1:34501,DS-e4ded3e3-5d0c-45d8-b3c7-b7a10d1ca491,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1489383076-172.17.0.7-1597760681263:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43165,DS-6755c017-c030-4289-aa7e-4ba2e40188a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40639,DS-95916e32-e847-4b84-8636-89e6c4c8c5dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35010,DS-ce915e73-5f4f-42a6-9ec0-50ee0a261a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:41151,DS-f895f63e-f98b-4a58-a017-84ae9e791cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:44429,DS-3379d91a-cb01-47a0-91a4-b58d47b92611,DISK], DatanodeInfoWithStorage[127.0.0.1:35379,DS-1151fe81-1b7e-4a01-8396-dac5d2199067,DISK], DatanodeInfoWithStorage[127.0.0.1:35119,DS-1fe5fa2a-6546-4d52-ab95-c0f230073656,DISK], DatanodeInfoWithStorage[127.0.0.1:34501,DS-e4ded3e3-5d0c-45d8-b3c7-b7a10d1ca491,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 99
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1462421149-172.17.0.7-1597761010571:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45799,DS-1d6ca41e-fd84-4d9f-8921-ea1b0c45cb04,DISK], DatanodeInfoWithStorage[127.0.0.1:42832,DS-44f93c21-5ed9-4d79-b790-b20b1139461e,DISK], DatanodeInfoWithStorage[127.0.0.1:40633,DS-ec9e79a8-4372-4e51-8c96-228e11d2fa2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42710,DS-2fc2fa2e-3a3f-4f03-bb72-352b832d9189,DISK], DatanodeInfoWithStorage[127.0.0.1:44294,DS-97f5c9c4-b701-4435-bc0e-9c15c9d9d831,DISK], DatanodeInfoWithStorage[127.0.0.1:43614,DS-240b4aaf-2cde-4b79-a0a4-16cc60ff9a94,DISK], DatanodeInfoWithStorage[127.0.0.1:41690,DS-f338c56e-58d2-4d38-a75f-cc55cb3d3f72,DISK], DatanodeInfoWithStorage[127.0.0.1:35839,DS-f81863d2-6815-44c5-824e-f26b0f921c90,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1462421149-172.17.0.7-1597761010571:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45799,DS-1d6ca41e-fd84-4d9f-8921-ea1b0c45cb04,DISK], DatanodeInfoWithStorage[127.0.0.1:42832,DS-44f93c21-5ed9-4d79-b790-b20b1139461e,DISK], DatanodeInfoWithStorage[127.0.0.1:40633,DS-ec9e79a8-4372-4e51-8c96-228e11d2fa2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42710,DS-2fc2fa2e-3a3f-4f03-bb72-352b832d9189,DISK], DatanodeInfoWithStorage[127.0.0.1:44294,DS-97f5c9c4-b701-4435-bc0e-9c15c9d9d831,DISK], DatanodeInfoWithStorage[127.0.0.1:43614,DS-240b4aaf-2cde-4b79-a0a4-16cc60ff9a94,DISK], DatanodeInfoWithStorage[127.0.0.1:41690,DS-f338c56e-58d2-4d38-a75f-cc55cb3d3f72,DISK], DatanodeInfoWithStorage[127.0.0.1:35839,DS-f81863d2-6815-44c5-824e-f26b0f921c90,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 99
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-76330387-172.17.0.7-1597761064209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41741,DS-537602df-cc29-4949-8c31-9220a38d9a31,DISK], DatanodeInfoWithStorage[127.0.0.1:42744,DS-61338fe7-f814-4405-acb6-d85ef3b8896e,DISK], DatanodeInfoWithStorage[127.0.0.1:46453,DS-5a50960f-f5eb-481e-a49c-c301b1ef07e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45262,DS-7c87c1b4-8104-4381-ba2d-dc4c5f8bfab8,DISK], DatanodeInfoWithStorage[127.0.0.1:46848,DS-b8bb0bb8-c14c-475e-889c-d7abb8207443,DISK], DatanodeInfoWithStorage[127.0.0.1:43447,DS-4ccf7de1-e62d-4193-b074-846a8781bd26,DISK], DatanodeInfoWithStorage[127.0.0.1:38730,DS-ee5f660e-3d92-41da-948f-3928d9910ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:43176,DS-7ef4910f-1867-4115-a50a-613587c3d199,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-76330387-172.17.0.7-1597761064209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41741,DS-537602df-cc29-4949-8c31-9220a38d9a31,DISK], DatanodeInfoWithStorage[127.0.0.1:42744,DS-61338fe7-f814-4405-acb6-d85ef3b8896e,DISK], DatanodeInfoWithStorage[127.0.0.1:46453,DS-5a50960f-f5eb-481e-a49c-c301b1ef07e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45262,DS-7c87c1b4-8104-4381-ba2d-dc4c5f8bfab8,DISK], DatanodeInfoWithStorage[127.0.0.1:46848,DS-b8bb0bb8-c14c-475e-889c-d7abb8207443,DISK], DatanodeInfoWithStorage[127.0.0.1:43447,DS-4ccf7de1-e62d-4193-b074-846a8781bd26,DISK], DatanodeInfoWithStorage[127.0.0.1:38730,DS-ee5f660e-3d92-41da-948f-3928d9910ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:43176,DS-7ef4910f-1867-4115-a50a-613587c3d199,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 99
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1206459889-172.17.0.7-1597761727080:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44872,DS-69b64610-25c9-40f4-a8fd-0ceca2e72de3,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-57a0566f-3f98-478e-a9e9-42302909ab26,DISK], DatanodeInfoWithStorage[127.0.0.1:41922,DS-93a58e60-ed3e-42b9-b09d-8a5e01038fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:35532,DS-7175c18f-0c0e-42b5-993d-f1f14a0a8236,DISK], DatanodeInfoWithStorage[127.0.0.1:40830,DS-3269b3c6-a4b9-4719-9916-032ead9134c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43032,DS-b599e0dd-44ee-4ecc-ac23-a97008554df5,DISK], DatanodeInfoWithStorage[127.0.0.1:35766,DS-5841c001-4bdb-4eed-a38d-c854090762b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44283,DS-6d6f8cab-ede3-4c05-9363-dc78ac49e3d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1206459889-172.17.0.7-1597761727080:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44872,DS-69b64610-25c9-40f4-a8fd-0ceca2e72de3,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-57a0566f-3f98-478e-a9e9-42302909ab26,DISK], DatanodeInfoWithStorage[127.0.0.1:41922,DS-93a58e60-ed3e-42b9-b09d-8a5e01038fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:35532,DS-7175c18f-0c0e-42b5-993d-f1f14a0a8236,DISK], DatanodeInfoWithStorage[127.0.0.1:40830,DS-3269b3c6-a4b9-4719-9916-032ead9134c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43032,DS-b599e0dd-44ee-4ecc-ac23-a97008554df5,DISK], DatanodeInfoWithStorage[127.0.0.1:35766,DS-5841c001-4bdb-4eed-a38d-c854090762b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44283,DS-6d6f8cab-ede3-4c05-9363-dc78ac49e3d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 99
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-492457629-172.17.0.7-1597761775588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44883,DS-fb6649ff-926e-4349-abe9-7bd83b145a95,DISK], DatanodeInfoWithStorage[127.0.0.1:38007,DS-d6f1e0a6-1aef-4ff2-8b78-4178f1212f86,DISK], DatanodeInfoWithStorage[127.0.0.1:33742,DS-f1cc3824-2bb5-4f24-9a94-725b0ace84ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42082,DS-ce05a08f-cfa8-48eb-8ced-55e0420b6e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37027,DS-4d224c1f-448c-4fb2-9153-29c1fc45d319,DISK], DatanodeInfoWithStorage[127.0.0.1:46283,DS-1c5a5866-aaae-449a-8f37-04776554b8a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43248,DS-e0fe0041-3ff4-4ae6-bcd3-9587268e8653,DISK], DatanodeInfoWithStorage[127.0.0.1:36815,DS-78ee130b-1cab-42f0-bf41-f6a62b4f0d29,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-492457629-172.17.0.7-1597761775588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44883,DS-fb6649ff-926e-4349-abe9-7bd83b145a95,DISK], DatanodeInfoWithStorage[127.0.0.1:38007,DS-d6f1e0a6-1aef-4ff2-8b78-4178f1212f86,DISK], DatanodeInfoWithStorage[127.0.0.1:33742,DS-f1cc3824-2bb5-4f24-9a94-725b0ace84ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42082,DS-ce05a08f-cfa8-48eb-8ced-55e0420b6e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37027,DS-4d224c1f-448c-4fb2-9153-29c1fc45d319,DISK], DatanodeInfoWithStorage[127.0.0.1:46283,DS-1c5a5866-aaae-449a-8f37-04776554b8a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43248,DS-e0fe0041-3ff4-4ae6-bcd3-9587268e8653,DISK], DatanodeInfoWithStorage[127.0.0.1:36815,DS-78ee130b-1cab-42f0-bf41-f6a62b4f0d29,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 99
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2100008618-172.17.0.7-1597761859362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46427,DS-6b4262f8-b0c6-4406-9270-28eb1e39d7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45149,DS-76c18c9c-a0e3-40ce-84af-7b7af7f6abb6,DISK], DatanodeInfoWithStorage[127.0.0.1:38536,DS-bce47a79-e2dd-4436-a4c2-5e577adf15b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35255,DS-3daee6f9-acb0-447a-b6e4-9cb7d881f530,DISK], DatanodeInfoWithStorage[127.0.0.1:36442,DS-3f889b68-6a34-4c54-9e09-a281cc1730fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34180,DS-b0900fe8-5249-47eb-b63e-971814802628,DISK], DatanodeInfoWithStorage[127.0.0.1:40431,DS-99acb298-0cf0-419b-b1c1-49c4ab280708,DISK], DatanodeInfoWithStorage[127.0.0.1:40396,DS-acd615c5-9af6-44b1-b7be-fad74cd5671c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2100008618-172.17.0.7-1597761859362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46427,DS-6b4262f8-b0c6-4406-9270-28eb1e39d7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45149,DS-76c18c9c-a0e3-40ce-84af-7b7af7f6abb6,DISK], DatanodeInfoWithStorage[127.0.0.1:38536,DS-bce47a79-e2dd-4436-a4c2-5e577adf15b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35255,DS-3daee6f9-acb0-447a-b6e4-9cb7d881f530,DISK], DatanodeInfoWithStorage[127.0.0.1:36442,DS-3f889b68-6a34-4c54-9e09-a281cc1730fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34180,DS-b0900fe8-5249-47eb-b63e-971814802628,DISK], DatanodeInfoWithStorage[127.0.0.1:40431,DS-99acb298-0cf0-419b-b1c1-49c4ab280708,DISK], DatanodeInfoWithStorage[127.0.0.1:40396,DS-acd615c5-9af6-44b1-b7be-fad74cd5671c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 99
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-976417109-172.17.0.7-1597762031991:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44975,DS-d827fde2-1580-44cc-b7c6-08da6111e907,DISK], DatanodeInfoWithStorage[127.0.0.1:37483,DS-72bad9f6-dc92-4a9e-a331-f9d920731735,DISK], DatanodeInfoWithStorage[127.0.0.1:38602,DS-ba816aeb-b7e4-4b24-a252-6cf922d723c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42303,DS-b2c122ae-e640-4e39-b1c9-8b2756b488e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33299,DS-4e1665f0-93a4-43a2-8bec-2f6285f5a132,DISK], DatanodeInfoWithStorage[127.0.0.1:43001,DS-35e84736-9927-4729-b272-8a8f032f8ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:40089,DS-7457df5c-02b2-43ad-8df4-f27bc3f6b1be,DISK], DatanodeInfoWithStorage[127.0.0.1:34960,DS-d8538152-7cb7-4d17-a4fe-712b8ae507d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-976417109-172.17.0.7-1597762031991:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44975,DS-d827fde2-1580-44cc-b7c6-08da6111e907,DISK], DatanodeInfoWithStorage[127.0.0.1:37483,DS-72bad9f6-dc92-4a9e-a331-f9d920731735,DISK], DatanodeInfoWithStorage[127.0.0.1:38602,DS-ba816aeb-b7e4-4b24-a252-6cf922d723c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42303,DS-b2c122ae-e640-4e39-b1c9-8b2756b488e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33299,DS-4e1665f0-93a4-43a2-8bec-2f6285f5a132,DISK], DatanodeInfoWithStorage[127.0.0.1:43001,DS-35e84736-9927-4729-b272-8a8f032f8ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:40089,DS-7457df5c-02b2-43ad-8df4-f27bc3f6b1be,DISK], DatanodeInfoWithStorage[127.0.0.1:34960,DS-d8538152-7cb7-4d17-a4fe-712b8ae507d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 99
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-775671668-172.17.0.7-1597762403111:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41691,DS-bd070ca0-fd38-46e1-a92c-e5426df08e61,DISK], DatanodeInfoWithStorage[127.0.0.1:40204,DS-d7ccdecf-267c-45a5-82b7-7e11c8235ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:44088,DS-089d2176-2447-4df4-b03a-7069d4f5d8d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34423,DS-b9c89e55-71b2-4630-a6b5-747150be71b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33102,DS-169c9d29-e9ee-4fee-a4c9-f822059da615,DISK], DatanodeInfoWithStorage[127.0.0.1:44534,DS-89e80daf-5681-424c-aa9a-ff8ad077edd0,DISK], DatanodeInfoWithStorage[127.0.0.1:43234,DS-13ebd730-21a5-4542-8a16-67ba40ff3dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:42284,DS-01a8a9e4-8d05-4bcd-9517-6b779a1804f7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-775671668-172.17.0.7-1597762403111:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41691,DS-bd070ca0-fd38-46e1-a92c-e5426df08e61,DISK], DatanodeInfoWithStorage[127.0.0.1:40204,DS-d7ccdecf-267c-45a5-82b7-7e11c8235ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:44088,DS-089d2176-2447-4df4-b03a-7069d4f5d8d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34423,DS-b9c89e55-71b2-4630-a6b5-747150be71b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33102,DS-169c9d29-e9ee-4fee-a4c9-f822059da615,DISK], DatanodeInfoWithStorage[127.0.0.1:44534,DS-89e80daf-5681-424c-aa9a-ff8ad077edd0,DISK], DatanodeInfoWithStorage[127.0.0.1:43234,DS-13ebd730-21a5-4542-8a16-67ba40ff3dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:42284,DS-01a8a9e4-8d05-4bcd-9517-6b779a1804f7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 99
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1388539289-172.17.0.7-1597762902223:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42487,DS-a838b3ef-05df-43d5-8a06-a605311545fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41574,DS-943266e2-f7f0-4ee3-a21d-594c457e586b,DISK], DatanodeInfoWithStorage[127.0.0.1:33515,DS-61eb64f2-aa3f-4346-83d2-bfcc23892db4,DISK], DatanodeInfoWithStorage[127.0.0.1:43793,DS-c1573ec6-c4a3-4792-b95d-7cd75eebf68e,DISK], DatanodeInfoWithStorage[127.0.0.1:43892,DS-c42ce87d-9131-4f94-a69c-aeb32280b503,DISK], DatanodeInfoWithStorage[127.0.0.1:35201,DS-b078dad6-9369-490e-872b-8c353d8c8a43,DISK], DatanodeInfoWithStorage[127.0.0.1:35433,DS-de41133b-797c-4230-8e15-bf67b3f2e3ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45162,DS-f0c1e55c-24a9-44b7-892b-0e0bfb1743ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1388539289-172.17.0.7-1597762902223:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42487,DS-a838b3ef-05df-43d5-8a06-a605311545fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41574,DS-943266e2-f7f0-4ee3-a21d-594c457e586b,DISK], DatanodeInfoWithStorage[127.0.0.1:33515,DS-61eb64f2-aa3f-4346-83d2-bfcc23892db4,DISK], DatanodeInfoWithStorage[127.0.0.1:43793,DS-c1573ec6-c4a3-4792-b95d-7cd75eebf68e,DISK], DatanodeInfoWithStorage[127.0.0.1:43892,DS-c42ce87d-9131-4f94-a69c-aeb32280b503,DISK], DatanodeInfoWithStorage[127.0.0.1:35201,DS-b078dad6-9369-490e-872b-8c353d8c8a43,DISK], DatanodeInfoWithStorage[127.0.0.1:35433,DS-de41133b-797c-4230-8e15-bf67b3f2e3ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45162,DS-f0c1e55c-24a9-44b7-892b-0e0bfb1743ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 99
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-290499979-172.17.0.7-1597763085267:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35844,DS-fe25aa68-c886-4c30-a89b-315994860b50,DISK], DatanodeInfoWithStorage[127.0.0.1:41655,DS-a5ed4646-cf60-433b-a3c4-d1e6a314ff77,DISK], DatanodeInfoWithStorage[127.0.0.1:41492,DS-9358c899-d361-4ace-9a1d-8c58bbc32eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:33392,DS-77c52c9a-6afe-47fd-8b9d-4115c5c03415,DISK], DatanodeInfoWithStorage[127.0.0.1:40111,DS-4e718fd5-fee5-40c6-b9ac-59e959abd3e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44750,DS-99d79971-a04a-441e-8900-e21e7057d8e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45745,DS-36e01058-325b-448c-8eb7-b67000895c78,DISK], DatanodeInfoWithStorage[127.0.0.1:44441,DS-50e829f2-fb4a-4086-96be-2f3694c089dc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-290499979-172.17.0.7-1597763085267:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35844,DS-fe25aa68-c886-4c30-a89b-315994860b50,DISK], DatanodeInfoWithStorage[127.0.0.1:41655,DS-a5ed4646-cf60-433b-a3c4-d1e6a314ff77,DISK], DatanodeInfoWithStorage[127.0.0.1:41492,DS-9358c899-d361-4ace-9a1d-8c58bbc32eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:33392,DS-77c52c9a-6afe-47fd-8b9d-4115c5c03415,DISK], DatanodeInfoWithStorage[127.0.0.1:40111,DS-4e718fd5-fee5-40c6-b9ac-59e959abd3e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44750,DS-99d79971-a04a-441e-8900-e21e7057d8e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45745,DS-36e01058-325b-448c-8eb7-b67000895c78,DISK], DatanodeInfoWithStorage[127.0.0.1:44441,DS-50e829f2-fb4a-4086-96be-2f3694c089dc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 99
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1935497718-172.17.0.7-1597763335009:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36022,DS-82d141bd-e502-456c-a998-ea76b63742cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42293,DS-c726f888-9b82-4b70-96d9-c7a708b15d25,DISK], DatanodeInfoWithStorage[127.0.0.1:35209,DS-6213a228-e1e7-4c12-b061-64fcba9e6de0,DISK], DatanodeInfoWithStorage[127.0.0.1:44962,DS-6668d794-7bc5-4078-886d-ba8313869a39,DISK], DatanodeInfoWithStorage[127.0.0.1:39569,DS-8953da13-741a-4a1c-a446-6451020f72bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34367,DS-7550db85-2c23-4d98-8f70-0ee86ae7bac8,DISK], DatanodeInfoWithStorage[127.0.0.1:33633,DS-a047be8a-c0be-44ea-af13-028c20348e99,DISK], DatanodeInfoWithStorage[127.0.0.1:37068,DS-45673829-87c2-471f-9a1b-1421de4957a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1935497718-172.17.0.7-1597763335009:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36022,DS-82d141bd-e502-456c-a998-ea76b63742cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42293,DS-c726f888-9b82-4b70-96d9-c7a708b15d25,DISK], DatanodeInfoWithStorage[127.0.0.1:35209,DS-6213a228-e1e7-4c12-b061-64fcba9e6de0,DISK], DatanodeInfoWithStorage[127.0.0.1:44962,DS-6668d794-7bc5-4078-886d-ba8313869a39,DISK], DatanodeInfoWithStorage[127.0.0.1:39569,DS-8953da13-741a-4a1c-a446-6451020f72bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34367,DS-7550db85-2c23-4d98-8f70-0ee86ae7bac8,DISK], DatanodeInfoWithStorage[127.0.0.1:33633,DS-a047be8a-c0be-44ea-af13-028c20348e99,DISK], DatanodeInfoWithStorage[127.0.0.1:37068,DS-45673829-87c2-471f-9a1b-1421de4957a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 21 out of 50
result: false positive !!!
Total execution time in seconds : 7126
