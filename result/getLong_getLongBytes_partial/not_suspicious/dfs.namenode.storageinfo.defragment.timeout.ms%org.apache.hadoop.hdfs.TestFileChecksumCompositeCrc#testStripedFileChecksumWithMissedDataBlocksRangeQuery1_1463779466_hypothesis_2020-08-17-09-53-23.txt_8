reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 65536
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 65536
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1656536328-172.17.0.9-1597658063307:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34047,DS-c9d8074d-8069-4f1e-988a-ad5f1c2cac08,DISK], DatanodeInfoWithStorage[127.0.0.1:44882,DS-ec6b189e-a4ae-4802-b831-736d18b1686a,DISK], DatanodeInfoWithStorage[127.0.0.1:41171,DS-b99b8b71-918a-4650-aa2a-d20bac6f531e,DISK], DatanodeInfoWithStorage[127.0.0.1:37478,DS-004ef5e5-1cd1-4f07-a26d-a8bbf7f1783b,DISK], DatanodeInfoWithStorage[127.0.0.1:36316,DS-917cecd7-f5f2-408a-a79d-ce28f09c693c,DISK], DatanodeInfoWithStorage[127.0.0.1:37900,DS-787f89bd-c2d9-428e-8ea9-53d2e838dfd9,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-3d020755-62e6-487d-bbfe-8b7e891de253,DISK], DatanodeInfoWithStorage[127.0.0.1:35613,DS-80296df4-35da-4c18-ade1-f76603d2e02d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1656536328-172.17.0.9-1597658063307:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34047,DS-c9d8074d-8069-4f1e-988a-ad5f1c2cac08,DISK], DatanodeInfoWithStorage[127.0.0.1:44882,DS-ec6b189e-a4ae-4802-b831-736d18b1686a,DISK], DatanodeInfoWithStorage[127.0.0.1:41171,DS-b99b8b71-918a-4650-aa2a-d20bac6f531e,DISK], DatanodeInfoWithStorage[127.0.0.1:37478,DS-004ef5e5-1cd1-4f07-a26d-a8bbf7f1783b,DISK], DatanodeInfoWithStorage[127.0.0.1:36316,DS-917cecd7-f5f2-408a-a79d-ce28f09c693c,DISK], DatanodeInfoWithStorage[127.0.0.1:37900,DS-787f89bd-c2d9-428e-8ea9-53d2e838dfd9,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-3d020755-62e6-487d-bbfe-8b7e891de253,DISK], DatanodeInfoWithStorage[127.0.0.1:35613,DS-80296df4-35da-4c18-ade1-f76603d2e02d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 65536
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-955661426-172.17.0.9-1597658134792:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41579,DS-82bf6914-9eb5-420b-b8b2-7fbed01f0a05,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-48693908-c0a4-4d55-85a7-4da45b5b9c16,DISK], DatanodeInfoWithStorage[127.0.0.1:40943,DS-7aa7478c-c47e-4a9b-96fd-f6814b7b8012,DISK], DatanodeInfoWithStorage[127.0.0.1:44596,DS-cfc2c542-f5bb-4beb-8ed5-5a74898f54be,DISK], DatanodeInfoWithStorage[127.0.0.1:45181,DS-e6daf3e9-06dd-4976-b6b8-ca8a19219f67,DISK], DatanodeInfoWithStorage[127.0.0.1:46805,DS-0d849b85-a056-4c69-a284-551b29fdca4d,DISK], DatanodeInfoWithStorage[127.0.0.1:39447,DS-3876ecc5-debc-41a5-8e07-5a97b909b3a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33391,DS-38d360cd-9399-4481-b195-4fe816f73002,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-955661426-172.17.0.9-1597658134792:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41579,DS-82bf6914-9eb5-420b-b8b2-7fbed01f0a05,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-48693908-c0a4-4d55-85a7-4da45b5b9c16,DISK], DatanodeInfoWithStorage[127.0.0.1:40943,DS-7aa7478c-c47e-4a9b-96fd-f6814b7b8012,DISK], DatanodeInfoWithStorage[127.0.0.1:44596,DS-cfc2c542-f5bb-4beb-8ed5-5a74898f54be,DISK], DatanodeInfoWithStorage[127.0.0.1:45181,DS-e6daf3e9-06dd-4976-b6b8-ca8a19219f67,DISK], DatanodeInfoWithStorage[127.0.0.1:46805,DS-0d849b85-a056-4c69-a284-551b29fdca4d,DISK], DatanodeInfoWithStorage[127.0.0.1:39447,DS-3876ecc5-debc-41a5-8e07-5a97b909b3a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33391,DS-38d360cd-9399-4481-b195-4fe816f73002,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 65536
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2071713852-172.17.0.9-1597659206730:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33784,DS-9cc907d4-14bf-4db8-be77-326f7ef4074a,DISK], DatanodeInfoWithStorage[127.0.0.1:33008,DS-ed11615e-83c0-4015-a00f-da025d6b9c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:46466,DS-19c61f92-84f9-4d36-a742-688ee34dc277,DISK], DatanodeInfoWithStorage[127.0.0.1:39741,DS-6791465e-8fbd-4497-86ae-a7c8f743f3f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38466,DS-c5057499-853d-4f0d-b50d-5f2448503848,DISK], DatanodeInfoWithStorage[127.0.0.1:44119,DS-223694cd-0cae-4145-8acb-f4925775beb6,DISK], DatanodeInfoWithStorage[127.0.0.1:44663,DS-81be3258-4c2c-40db-b104-fc9ebcd3869e,DISK], DatanodeInfoWithStorage[127.0.0.1:37454,DS-de954bb2-e796-4e31-ae73-278e25f9fab6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2071713852-172.17.0.9-1597659206730:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33784,DS-9cc907d4-14bf-4db8-be77-326f7ef4074a,DISK], DatanodeInfoWithStorage[127.0.0.1:33008,DS-ed11615e-83c0-4015-a00f-da025d6b9c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:46466,DS-19c61f92-84f9-4d36-a742-688ee34dc277,DISK], DatanodeInfoWithStorage[127.0.0.1:39741,DS-6791465e-8fbd-4497-86ae-a7c8f743f3f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38466,DS-c5057499-853d-4f0d-b50d-5f2448503848,DISK], DatanodeInfoWithStorage[127.0.0.1:44119,DS-223694cd-0cae-4145-8acb-f4925775beb6,DISK], DatanodeInfoWithStorage[127.0.0.1:44663,DS-81be3258-4c2c-40db-b104-fc9ebcd3869e,DISK], DatanodeInfoWithStorage[127.0.0.1:37454,DS-de954bb2-e796-4e31-ae73-278e25f9fab6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 65536
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2099111154-172.17.0.9-1597660471563:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42845,DS-e75b4b3e-0695-47c2-bf86-c947b4af69b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34969,DS-e63a0ead-7684-4316-b811-be42435a5a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:46207,DS-b3d5aecf-05fa-429a-bdcf-061ea587e93e,DISK], DatanodeInfoWithStorage[127.0.0.1:38656,DS-5014d468-e272-40e7-8b6b-2d0c9a1df8e8,DISK], DatanodeInfoWithStorage[127.0.0.1:32862,DS-bdf3b2e8-75b8-4c93-b48f-a0dcf5f2affd,DISK], DatanodeInfoWithStorage[127.0.0.1:44181,DS-45d4b8d4-eadf-4eb1-ac04-777adb664a34,DISK], DatanodeInfoWithStorage[127.0.0.1:38319,DS-00149873-3ce4-4c87-b034-61e75d4998b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34851,DS-e92c80ae-024e-4fb6-9ecd-76281f6ee030,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2099111154-172.17.0.9-1597660471563:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42845,DS-e75b4b3e-0695-47c2-bf86-c947b4af69b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34969,DS-e63a0ead-7684-4316-b811-be42435a5a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:46207,DS-b3d5aecf-05fa-429a-bdcf-061ea587e93e,DISK], DatanodeInfoWithStorage[127.0.0.1:38656,DS-5014d468-e272-40e7-8b6b-2d0c9a1df8e8,DISK], DatanodeInfoWithStorage[127.0.0.1:32862,DS-bdf3b2e8-75b8-4c93-b48f-a0dcf5f2affd,DISK], DatanodeInfoWithStorage[127.0.0.1:44181,DS-45d4b8d4-eadf-4eb1-ac04-777adb664a34,DISK], DatanodeInfoWithStorage[127.0.0.1:38319,DS-00149873-3ce4-4c87-b034-61e75d4998b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34851,DS-e92c80ae-024e-4fb6-9ecd-76281f6ee030,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 65536
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1812757955-172.17.0.9-1597660683462:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42208,DS-718b8620-a3d9-4ea0-9844-cbb8806d1004,DISK], DatanodeInfoWithStorage[127.0.0.1:41440,DS-19629c67-f869-4bfb-b004-f03a473ef85b,DISK], DatanodeInfoWithStorage[127.0.0.1:44953,DS-b8e2851c-5908-46c0-87c1-c676820aedbb,DISK], DatanodeInfoWithStorage[127.0.0.1:34878,DS-0e99bc10-520c-4696-bbc3-a333be52d409,DISK], DatanodeInfoWithStorage[127.0.0.1:41388,DS-0279ab8d-2093-42d3-ad7b-87bca912ff5a,DISK], DatanodeInfoWithStorage[127.0.0.1:42635,DS-778cb94c-2b4c-40e0-8260-5bc63f536a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:34379,DS-c7a987a5-4791-4602-8588-8eddf0b47b73,DISK], DatanodeInfoWithStorage[127.0.0.1:35939,DS-ef6038f3-d630-4730-bcc6-7f9424e0f57c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1812757955-172.17.0.9-1597660683462:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42208,DS-718b8620-a3d9-4ea0-9844-cbb8806d1004,DISK], DatanodeInfoWithStorage[127.0.0.1:41440,DS-19629c67-f869-4bfb-b004-f03a473ef85b,DISK], DatanodeInfoWithStorage[127.0.0.1:44953,DS-b8e2851c-5908-46c0-87c1-c676820aedbb,DISK], DatanodeInfoWithStorage[127.0.0.1:34878,DS-0e99bc10-520c-4696-bbc3-a333be52d409,DISK], DatanodeInfoWithStorage[127.0.0.1:41388,DS-0279ab8d-2093-42d3-ad7b-87bca912ff5a,DISK], DatanodeInfoWithStorage[127.0.0.1:42635,DS-778cb94c-2b4c-40e0-8260-5bc63f536a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:34379,DS-c7a987a5-4791-4602-8588-8eddf0b47b73,DISK], DatanodeInfoWithStorage[127.0.0.1:35939,DS-ef6038f3-d630-4730-bcc6-7f9424e0f57c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 65536
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1377992623-172.17.0.9-1597660899717:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45275,DS-5e09015a-5739-4fd6-82e3-ad34db412a30,DISK], DatanodeInfoWithStorage[127.0.0.1:38507,DS-6f133015-bc38-4625-b0ea-d36cf3f7da4b,DISK], DatanodeInfoWithStorage[127.0.0.1:43233,DS-4e2a557a-16c4-47aa-941c-5409449e06fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43785,DS-2834156d-c718-4500-8f86-04c9703cf88e,DISK], DatanodeInfoWithStorage[127.0.0.1:36677,DS-15f2ae8e-ff97-4345-a691-482d066a3a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:43510,DS-8fea2776-f5a6-45bb-9313-1c52065bb0ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36678,DS-0b474c26-72d3-4bd2-9543-b655114479d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43019,DS-690c3e5f-052e-4f01-80b8-b59b31bd3cd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1377992623-172.17.0.9-1597660899717:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45275,DS-5e09015a-5739-4fd6-82e3-ad34db412a30,DISK], DatanodeInfoWithStorage[127.0.0.1:38507,DS-6f133015-bc38-4625-b0ea-d36cf3f7da4b,DISK], DatanodeInfoWithStorage[127.0.0.1:43233,DS-4e2a557a-16c4-47aa-941c-5409449e06fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43785,DS-2834156d-c718-4500-8f86-04c9703cf88e,DISK], DatanodeInfoWithStorage[127.0.0.1:36677,DS-15f2ae8e-ff97-4345-a691-482d066a3a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:43510,DS-8fea2776-f5a6-45bb-9313-1c52065bb0ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36678,DS-0b474c26-72d3-4bd2-9543-b655114479d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43019,DS-690c3e5f-052e-4f01-80b8-b59b31bd3cd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 65536
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-981062720-172.17.0.9-1597661057687:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44894,DS-708235bc-778c-463f-a808-38c43d0ffb4d,DISK], DatanodeInfoWithStorage[127.0.0.1:46741,DS-1d45ff3a-e528-4dba-b6ba-4aacbb24c552,DISK], DatanodeInfoWithStorage[127.0.0.1:45393,DS-91573701-f864-4fb6-8b27-265fe82333d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44177,DS-b0975262-5341-449d-906f-fde244470ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:44404,DS-716376b1-d950-479d-a74a-4023173b280a,DISK], DatanodeInfoWithStorage[127.0.0.1:45635,DS-6540f5e5-5646-437e-a6fa-adff01354d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45948,DS-f58aa6e3-e4b7-4da8-868d-1a0148ff681c,DISK], DatanodeInfoWithStorage[127.0.0.1:41887,DS-aa75dbc8-d05b-499c-bb78-0008340de292,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-981062720-172.17.0.9-1597661057687:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44894,DS-708235bc-778c-463f-a808-38c43d0ffb4d,DISK], DatanodeInfoWithStorage[127.0.0.1:46741,DS-1d45ff3a-e528-4dba-b6ba-4aacbb24c552,DISK], DatanodeInfoWithStorage[127.0.0.1:45393,DS-91573701-f864-4fb6-8b27-265fe82333d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44177,DS-b0975262-5341-449d-906f-fde244470ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:44404,DS-716376b1-d950-479d-a74a-4023173b280a,DISK], DatanodeInfoWithStorage[127.0.0.1:45635,DS-6540f5e5-5646-437e-a6fa-adff01354d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45948,DS-f58aa6e3-e4b7-4da8-868d-1a0148ff681c,DISK], DatanodeInfoWithStorage[127.0.0.1:41887,DS-aa75dbc8-d05b-499c-bb78-0008340de292,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 65536
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1596014448-172.17.0.9-1597661181339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34829,DS-1308a840-e7b5-457e-b282-52de4737bbc4,DISK], DatanodeInfoWithStorage[127.0.0.1:44049,DS-abc39f4d-a636-43f4-b7dd-b2142a3a4ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:33921,DS-4e279db6-5883-4f62-b400-8963a7dce955,DISK], DatanodeInfoWithStorage[127.0.0.1:40379,DS-5f7500f2-05c8-4c3b-af71-79ba18132673,DISK], DatanodeInfoWithStorage[127.0.0.1:39345,DS-49516546-3db6-422d-bd3c-4dee3e9db262,DISK], DatanodeInfoWithStorage[127.0.0.1:36213,DS-039226c2-6c7d-4d99-8fdf-82188c36641a,DISK], DatanodeInfoWithStorage[127.0.0.1:33203,DS-78f2318b-b04c-411a-8661-833243c3d417,DISK], DatanodeInfoWithStorage[127.0.0.1:45296,DS-e4f0f611-4cbd-4c68-a824-fbb6b7dd87d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1596014448-172.17.0.9-1597661181339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34829,DS-1308a840-e7b5-457e-b282-52de4737bbc4,DISK], DatanodeInfoWithStorage[127.0.0.1:44049,DS-abc39f4d-a636-43f4-b7dd-b2142a3a4ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:33921,DS-4e279db6-5883-4f62-b400-8963a7dce955,DISK], DatanodeInfoWithStorage[127.0.0.1:40379,DS-5f7500f2-05c8-4c3b-af71-79ba18132673,DISK], DatanodeInfoWithStorage[127.0.0.1:39345,DS-49516546-3db6-422d-bd3c-4dee3e9db262,DISK], DatanodeInfoWithStorage[127.0.0.1:36213,DS-039226c2-6c7d-4d99-8fdf-82188c36641a,DISK], DatanodeInfoWithStorage[127.0.0.1:33203,DS-78f2318b-b04c-411a-8661-833243c3d417,DISK], DatanodeInfoWithStorage[127.0.0.1:45296,DS-e4f0f611-4cbd-4c68-a824-fbb6b7dd87d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 65536
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1295932659-172.17.0.9-1597662186274:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39032,DS-5df07574-4638-45c0-9a51-5ae136729d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33214,DS-242a2c3d-9223-4741-926f-d15bd801a2d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42652,DS-0e4c72a2-99c6-493a-8d48-b9a2861ef637,DISK], DatanodeInfoWithStorage[127.0.0.1:35952,DS-7b17e388-d637-40f1-b9e1-44011f1e4ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:39999,DS-78acb956-e326-4022-855a-87392b01befc,DISK], DatanodeInfoWithStorage[127.0.0.1:43733,DS-e6aad94c-a029-413c-ad96-ce182b928f48,DISK], DatanodeInfoWithStorage[127.0.0.1:46496,DS-38ee410d-5344-4848-b0f9-1a6e36632361,DISK], DatanodeInfoWithStorage[127.0.0.1:43992,DS-d77939bf-250a-4d6e-a17a-780e2cb22e32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1295932659-172.17.0.9-1597662186274:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39032,DS-5df07574-4638-45c0-9a51-5ae136729d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33214,DS-242a2c3d-9223-4741-926f-d15bd801a2d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42652,DS-0e4c72a2-99c6-493a-8d48-b9a2861ef637,DISK], DatanodeInfoWithStorage[127.0.0.1:35952,DS-7b17e388-d637-40f1-b9e1-44011f1e4ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:39999,DS-78acb956-e326-4022-855a-87392b01befc,DISK], DatanodeInfoWithStorage[127.0.0.1:43733,DS-e6aad94c-a029-413c-ad96-ce182b928f48,DISK], DatanodeInfoWithStorage[127.0.0.1:46496,DS-38ee410d-5344-4848-b0f9-1a6e36632361,DISK], DatanodeInfoWithStorage[127.0.0.1:43992,DS-d77939bf-250a-4d6e-a17a-780e2cb22e32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 65536
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1037564060-172.17.0.9-1597662788576:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39411,DS-61e7de55-7d9c-4865-baf1-5796807479a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38771,DS-5f29abe8-883a-4a89-852f-4f41a519b6d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45760,DS-0c9a285a-53c0-4a02-b9dc-3b4c5d3d4808,DISK], DatanodeInfoWithStorage[127.0.0.1:35635,DS-5ce5edea-63d0-4395-b63e-a80494e54511,DISK], DatanodeInfoWithStorage[127.0.0.1:33840,DS-8017aa80-9ce9-4f6d-9dd1-df2b91fed7d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35669,DS-8a35b0bb-e460-463d-b844-efce0d05d756,DISK], DatanodeInfoWithStorage[127.0.0.1:33116,DS-f7736565-b652-4f98-be1b-8952adf095e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35222,DS-70a4624f-98d2-41b7-80c6-44231ba612e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1037564060-172.17.0.9-1597662788576:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39411,DS-61e7de55-7d9c-4865-baf1-5796807479a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38771,DS-5f29abe8-883a-4a89-852f-4f41a519b6d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45760,DS-0c9a285a-53c0-4a02-b9dc-3b4c5d3d4808,DISK], DatanodeInfoWithStorage[127.0.0.1:35635,DS-5ce5edea-63d0-4395-b63e-a80494e54511,DISK], DatanodeInfoWithStorage[127.0.0.1:33840,DS-8017aa80-9ce9-4f6d-9dd1-df2b91fed7d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35669,DS-8a35b0bb-e460-463d-b844-efce0d05d756,DISK], DatanodeInfoWithStorage[127.0.0.1:33116,DS-f7736565-b652-4f98-be1b-8952adf095e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35222,DS-70a4624f-98d2-41b7-80c6-44231ba612e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 65536
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-594641491-172.17.0.9-1597662867321:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45105,DS-7b92fd5a-1928-4182-aa02-1a1fe3114db3,DISK], DatanodeInfoWithStorage[127.0.0.1:35907,DS-7bb44e10-2b9a-42d6-acda-c2a1662032f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36966,DS-8d3f5e19-5a4d-4624-aeb5-236184077206,DISK], DatanodeInfoWithStorage[127.0.0.1:44274,DS-eeb93965-8e68-4a34-bfcf-fccbc782d935,DISK], DatanodeInfoWithStorage[127.0.0.1:45024,DS-2ebe20ba-e812-4e30-9b06-bbfbe870de14,DISK], DatanodeInfoWithStorage[127.0.0.1:40735,DS-0fc1dfe4-4374-4181-9653-f7f3775a3426,DISK], DatanodeInfoWithStorage[127.0.0.1:34838,DS-529786ea-3dfc-4744-91af-8efeb2f71daa,DISK], DatanodeInfoWithStorage[127.0.0.1:36479,DS-e4d32ad8-35ba-478a-87ee-6f576da9b492,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-594641491-172.17.0.9-1597662867321:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45105,DS-7b92fd5a-1928-4182-aa02-1a1fe3114db3,DISK], DatanodeInfoWithStorage[127.0.0.1:35907,DS-7bb44e10-2b9a-42d6-acda-c2a1662032f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36966,DS-8d3f5e19-5a4d-4624-aeb5-236184077206,DISK], DatanodeInfoWithStorage[127.0.0.1:44274,DS-eeb93965-8e68-4a34-bfcf-fccbc782d935,DISK], DatanodeInfoWithStorage[127.0.0.1:45024,DS-2ebe20ba-e812-4e30-9b06-bbfbe870de14,DISK], DatanodeInfoWithStorage[127.0.0.1:40735,DS-0fc1dfe4-4374-4181-9653-f7f3775a3426,DISK], DatanodeInfoWithStorage[127.0.0.1:34838,DS-529786ea-3dfc-4744-91af-8efeb2f71daa,DISK], DatanodeInfoWithStorage[127.0.0.1:36479,DS-e4d32ad8-35ba-478a-87ee-6f576da9b492,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 65536
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1613109-172.17.0.9-1597663041014:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33941,DS-0c470d34-634b-439a-ab29-79df36363e08,DISK], DatanodeInfoWithStorage[127.0.0.1:40713,DS-a5138d87-7c2e-487e-b925-127082841516,DISK], DatanodeInfoWithStorage[127.0.0.1:35362,DS-1fc951f7-404f-42e8-8f23-f5e68c689295,DISK], DatanodeInfoWithStorage[127.0.0.1:40941,DS-f4e7c7da-d14c-4e9e-ac26-1eff1552e3eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45253,DS-856933fd-2bf4-47f5-8682-c19c6b352211,DISK], DatanodeInfoWithStorage[127.0.0.1:38494,DS-e5ddd5f9-6d95-4f7b-82ad-347bb006fcae,DISK], DatanodeInfoWithStorage[127.0.0.1:40625,DS-5f2b4daf-1016-4051-ac73-f4f7ba536286,DISK], DatanodeInfoWithStorage[127.0.0.1:42851,DS-0ce84b55-e42c-4c82-b26b-a02a3b01be79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1613109-172.17.0.9-1597663041014:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33941,DS-0c470d34-634b-439a-ab29-79df36363e08,DISK], DatanodeInfoWithStorage[127.0.0.1:40713,DS-a5138d87-7c2e-487e-b925-127082841516,DISK], DatanodeInfoWithStorage[127.0.0.1:35362,DS-1fc951f7-404f-42e8-8f23-f5e68c689295,DISK], DatanodeInfoWithStorage[127.0.0.1:40941,DS-f4e7c7da-d14c-4e9e-ac26-1eff1552e3eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45253,DS-856933fd-2bf4-47f5-8682-c19c6b352211,DISK], DatanodeInfoWithStorage[127.0.0.1:38494,DS-e5ddd5f9-6d95-4f7b-82ad-347bb006fcae,DISK], DatanodeInfoWithStorage[127.0.0.1:40625,DS-5f2b4daf-1016-4051-ac73-f4f7ba536286,DISK], DatanodeInfoWithStorage[127.0.0.1:42851,DS-0ce84b55-e42c-4c82-b26b-a02a3b01be79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 65536
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-348304022-172.17.0.9-1597663502695:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33990,DS-039e0449-8796-4337-bd71-3dbcc982c0e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36535,DS-73d0de5d-9332-4a0f-8c8a-e407cb8a8d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:39095,DS-ce44ae63-3b0d-43d8-88fe-12a0f2b85ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:36827,DS-822d7790-88e4-43f3-924d-1ae6066a8306,DISK], DatanodeInfoWithStorage[127.0.0.1:41020,DS-67bb2607-9ddf-476c-a813-68b7db21ab05,DISK], DatanodeInfoWithStorage[127.0.0.1:39228,DS-10e99b1c-4bd9-4690-bc17-b5db3053c776,DISK], DatanodeInfoWithStorage[127.0.0.1:34324,DS-3a842b97-1410-4648-bd1a-4a824e22e19f,DISK], DatanodeInfoWithStorage[127.0.0.1:33793,DS-dbc8a366-69ec-46e3-adba-73c1c79b0be1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-348304022-172.17.0.9-1597663502695:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33990,DS-039e0449-8796-4337-bd71-3dbcc982c0e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36535,DS-73d0de5d-9332-4a0f-8c8a-e407cb8a8d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:39095,DS-ce44ae63-3b0d-43d8-88fe-12a0f2b85ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:36827,DS-822d7790-88e4-43f3-924d-1ae6066a8306,DISK], DatanodeInfoWithStorage[127.0.0.1:41020,DS-67bb2607-9ddf-476c-a813-68b7db21ab05,DISK], DatanodeInfoWithStorage[127.0.0.1:39228,DS-10e99b1c-4bd9-4690-bc17-b5db3053c776,DISK], DatanodeInfoWithStorage[127.0.0.1:34324,DS-3a842b97-1410-4648-bd1a-4a824e22e19f,DISK], DatanodeInfoWithStorage[127.0.0.1:33793,DS-dbc8a366-69ec-46e3-adba-73c1c79b0be1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 65536
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-404589816-172.17.0.9-1597663737351:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32787,DS-7ffb6fa9-d857-4d80-910e-8cb80a4d7f69,DISK], DatanodeInfoWithStorage[127.0.0.1:38457,DS-caded4e5-39d8-4b62-ac10-4dc9de9a47eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44401,DS-c18924c1-8b32-4fca-8bff-d412293ec8c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42763,DS-8356fb09-beaf-4fa7-afde-c0ecb978b741,DISK], DatanodeInfoWithStorage[127.0.0.1:43277,DS-332fd31c-834b-4786-86be-2d87b81509ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42082,DS-0a8e89ea-10c2-4252-9bce-c99382936a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:33118,DS-87f3e90e-0c6f-4009-b038-f0951a40efa3,DISK], DatanodeInfoWithStorage[127.0.0.1:46819,DS-0698151b-a51c-4080-b151-e073251a9f98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-404589816-172.17.0.9-1597663737351:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32787,DS-7ffb6fa9-d857-4d80-910e-8cb80a4d7f69,DISK], DatanodeInfoWithStorage[127.0.0.1:38457,DS-caded4e5-39d8-4b62-ac10-4dc9de9a47eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44401,DS-c18924c1-8b32-4fca-8bff-d412293ec8c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42763,DS-8356fb09-beaf-4fa7-afde-c0ecb978b741,DISK], DatanodeInfoWithStorage[127.0.0.1:43277,DS-332fd31c-834b-4786-86be-2d87b81509ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42082,DS-0a8e89ea-10c2-4252-9bce-c99382936a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:33118,DS-87f3e90e-0c6f-4009-b038-f0951a40efa3,DISK], DatanodeInfoWithStorage[127.0.0.1:46819,DS-0698151b-a51c-4080-b151-e073251a9f98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 6195
