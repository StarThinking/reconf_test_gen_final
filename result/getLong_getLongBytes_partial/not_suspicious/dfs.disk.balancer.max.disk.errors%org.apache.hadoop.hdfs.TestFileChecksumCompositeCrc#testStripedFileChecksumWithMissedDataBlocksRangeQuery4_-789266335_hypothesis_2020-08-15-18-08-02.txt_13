reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 0
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 0
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1148271875-172.17.0.17-1597515108789:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36835,DS-9919b9b6-2bd7-4e3d-8d29-0bdd695ddbe8,DISK], DatanodeInfoWithStorage[127.0.0.1:42801,DS-6a215848-3d3d-44a6-bf51-d987efed7be9,DISK], DatanodeInfoWithStorage[127.0.0.1:43663,DS-446fcd17-6c8f-4f58-a282-9e014633538d,DISK], DatanodeInfoWithStorage[127.0.0.1:39346,DS-9d94fc31-67ab-4184-9347-b5fa07d38700,DISK], DatanodeInfoWithStorage[127.0.0.1:38357,DS-2df57e89-21ab-43e0-bb2b-25c36b5253d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42278,DS-2e27751e-1c55-4ce5-bf67-01e9ebc41834,DISK], DatanodeInfoWithStorage[127.0.0.1:39495,DS-41b59979-1b87-486b-94e9-93d109a0ef3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44887,DS-160b88b7-4a6c-47e7-bec3-1baf65c4e0cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1148271875-172.17.0.17-1597515108789:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36835,DS-9919b9b6-2bd7-4e3d-8d29-0bdd695ddbe8,DISK], DatanodeInfoWithStorage[127.0.0.1:42801,DS-6a215848-3d3d-44a6-bf51-d987efed7be9,DISK], DatanodeInfoWithStorage[127.0.0.1:43663,DS-446fcd17-6c8f-4f58-a282-9e014633538d,DISK], DatanodeInfoWithStorage[127.0.0.1:39346,DS-9d94fc31-67ab-4184-9347-b5fa07d38700,DISK], DatanodeInfoWithStorage[127.0.0.1:38357,DS-2df57e89-21ab-43e0-bb2b-25c36b5253d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42278,DS-2e27751e-1c55-4ce5-bf67-01e9ebc41834,DISK], DatanodeInfoWithStorage[127.0.0.1:39495,DS-41b59979-1b87-486b-94e9-93d109a0ef3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44887,DS-160b88b7-4a6c-47e7-bec3-1baf65c4e0cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 0
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1175276270-172.17.0.17-1597515185266:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42414,DS-61ab50f7-afb7-4bd8-9528-df78b2ad3ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:43380,DS-17c957f7-a4b6-4348-8da9-df2e25816a52,DISK], DatanodeInfoWithStorage[127.0.0.1:43150,DS-b40a75ca-e0b8-411a-894a-1c508e5a4e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44991,DS-0ddb241a-d3fb-4836-b9c0-b8c32e077ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:36047,DS-b336a74e-f08b-4799-bcec-cde0abc0e578,DISK], DatanodeInfoWithStorage[127.0.0.1:42065,DS-58969481-6ae3-42a5-b33a-aa7a64bd2b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39459,DS-08190ae0-2eb9-4807-babf-6d695b1b0379,DISK], DatanodeInfoWithStorage[127.0.0.1:34441,DS-60c00d28-0788-4535-a28a-156c85764a78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1175276270-172.17.0.17-1597515185266:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42414,DS-61ab50f7-afb7-4bd8-9528-df78b2ad3ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:43380,DS-17c957f7-a4b6-4348-8da9-df2e25816a52,DISK], DatanodeInfoWithStorage[127.0.0.1:43150,DS-b40a75ca-e0b8-411a-894a-1c508e5a4e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44991,DS-0ddb241a-d3fb-4836-b9c0-b8c32e077ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:36047,DS-b336a74e-f08b-4799-bcec-cde0abc0e578,DISK], DatanodeInfoWithStorage[127.0.0.1:42065,DS-58969481-6ae3-42a5-b33a-aa7a64bd2b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39459,DS-08190ae0-2eb9-4807-babf-6d695b1b0379,DISK], DatanodeInfoWithStorage[127.0.0.1:34441,DS-60c00d28-0788-4535-a28a-156c85764a78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 0
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-789638285-172.17.0.17-1597515806666:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34558,DS-503a3c8f-1393-43b6-81e7-5211114014c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42041,DS-8346356d-e169-4185-bde9-7cee3f7d2688,DISK], DatanodeInfoWithStorage[127.0.0.1:41686,DS-96bd1da2-e627-44d3-90a9-423bbb9c657e,DISK], DatanodeInfoWithStorage[127.0.0.1:36173,DS-b9a660f1-3df8-4e77-b7c4-dc4c7be344b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39952,DS-daeb74dd-780c-4611-9654-36658dd8ebde,DISK], DatanodeInfoWithStorage[127.0.0.1:41641,DS-1ed1b0b8-6435-46ed-a9d3-6e7c4241e64d,DISK], DatanodeInfoWithStorage[127.0.0.1:44846,DS-3017afc1-3587-4514-ab79-5846f88275bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38795,DS-e56e03ae-d68c-4bd1-a232-72de5f37f5c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-789638285-172.17.0.17-1597515806666:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34558,DS-503a3c8f-1393-43b6-81e7-5211114014c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42041,DS-8346356d-e169-4185-bde9-7cee3f7d2688,DISK], DatanodeInfoWithStorage[127.0.0.1:41686,DS-96bd1da2-e627-44d3-90a9-423bbb9c657e,DISK], DatanodeInfoWithStorage[127.0.0.1:36173,DS-b9a660f1-3df8-4e77-b7c4-dc4c7be344b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39952,DS-daeb74dd-780c-4611-9654-36658dd8ebde,DISK], DatanodeInfoWithStorage[127.0.0.1:41641,DS-1ed1b0b8-6435-46ed-a9d3-6e7c4241e64d,DISK], DatanodeInfoWithStorage[127.0.0.1:44846,DS-3017afc1-3587-4514-ab79-5846f88275bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38795,DS-e56e03ae-d68c-4bd1-a232-72de5f37f5c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 0
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1356338249-172.17.0.17-1597515849505:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38779,DS-14c9e975-896a-4e58-b22f-dc9c15eb42d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45270,DS-d6d95cbc-a7be-413a-8e4c-62079b713f00,DISK], DatanodeInfoWithStorage[127.0.0.1:45894,DS-4a7cd546-20ad-42ea-9598-2aed7e5ea900,DISK], DatanodeInfoWithStorage[127.0.0.1:43803,DS-24771d71-1afb-4e9b-89b7-8f0da718963c,DISK], DatanodeInfoWithStorage[127.0.0.1:33778,DS-c334e4e9-da22-463e-a973-298bd2e3b266,DISK], DatanodeInfoWithStorage[127.0.0.1:36151,DS-2b452cdb-b480-468b-96bc-152943a10fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:46412,DS-77fc8b42-c52b-48d5-ac1c-360c29c18be1,DISK], DatanodeInfoWithStorage[127.0.0.1:37864,DS-fa189860-93ff-4948-b02e-1e5c54a37b61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1356338249-172.17.0.17-1597515849505:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38779,DS-14c9e975-896a-4e58-b22f-dc9c15eb42d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45270,DS-d6d95cbc-a7be-413a-8e4c-62079b713f00,DISK], DatanodeInfoWithStorage[127.0.0.1:45894,DS-4a7cd546-20ad-42ea-9598-2aed7e5ea900,DISK], DatanodeInfoWithStorage[127.0.0.1:43803,DS-24771d71-1afb-4e9b-89b7-8f0da718963c,DISK], DatanodeInfoWithStorage[127.0.0.1:33778,DS-c334e4e9-da22-463e-a973-298bd2e3b266,DISK], DatanodeInfoWithStorage[127.0.0.1:36151,DS-2b452cdb-b480-468b-96bc-152943a10fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:46412,DS-77fc8b42-c52b-48d5-ac1c-360c29c18be1,DISK], DatanodeInfoWithStorage[127.0.0.1:37864,DS-fa189860-93ff-4948-b02e-1e5c54a37b61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 0
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1033995509-172.17.0.17-1597515977590:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37768,DS-d148d6af-5d73-4919-88e2-bc9b07ce6f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42550,DS-bc693779-8c11-41d6-bc6f-010b236ba1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42721,DS-5f01f78b-8fdd-4111-b756-897047bb1fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:38885,DS-b21fe80a-0963-44bd-9570-ef24a765021c,DISK], DatanodeInfoWithStorage[127.0.0.1:43924,DS-35a400ea-9126-4ae0-b823-7c5e94cbb781,DISK], DatanodeInfoWithStorage[127.0.0.1:44680,DS-98412e0a-5a71-4a2f-823b-bdce152adf16,DISK], DatanodeInfoWithStorage[127.0.0.1:43523,DS-6e782673-c918-430a-89ea-062ddda3bed6,DISK], DatanodeInfoWithStorage[127.0.0.1:39712,DS-94e73274-b4c4-4795-9ef4-6b9b5c709a1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1033995509-172.17.0.17-1597515977590:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37768,DS-d148d6af-5d73-4919-88e2-bc9b07ce6f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42550,DS-bc693779-8c11-41d6-bc6f-010b236ba1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42721,DS-5f01f78b-8fdd-4111-b756-897047bb1fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:38885,DS-b21fe80a-0963-44bd-9570-ef24a765021c,DISK], DatanodeInfoWithStorage[127.0.0.1:43924,DS-35a400ea-9126-4ae0-b823-7c5e94cbb781,DISK], DatanodeInfoWithStorage[127.0.0.1:44680,DS-98412e0a-5a71-4a2f-823b-bdce152adf16,DISK], DatanodeInfoWithStorage[127.0.0.1:43523,DS-6e782673-c918-430a-89ea-062ddda3bed6,DISK], DatanodeInfoWithStorage[127.0.0.1:39712,DS-94e73274-b4c4-4795-9ef4-6b9b5c709a1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 0
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1414340757-172.17.0.17-1597516304910:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46093,DS-ddf877d9-6508-4d44-8bce-faebfdaf7bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:38003,DS-7fe32aa4-11ab-47c8-8ffb-c6d27cea1596,DISK], DatanodeInfoWithStorage[127.0.0.1:36431,DS-e766acec-1811-40fe-a6dd-2dd91fb16f25,DISK], DatanodeInfoWithStorage[127.0.0.1:40821,DS-8931ee30-29a6-434f-96a4-cb300c12a5f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33031,DS-2088a5d1-d6ed-42ad-84dc-3e7e2c980ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:35839,DS-c2ad1719-65e6-405e-9ca0-b4c695956107,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-9b81f9b0-58d8-409f-ae2b-0b90d0e5f437,DISK], DatanodeInfoWithStorage[127.0.0.1:33153,DS-3f719eb9-30d1-490c-8cfa-0de35bf499c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1414340757-172.17.0.17-1597516304910:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46093,DS-ddf877d9-6508-4d44-8bce-faebfdaf7bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:38003,DS-7fe32aa4-11ab-47c8-8ffb-c6d27cea1596,DISK], DatanodeInfoWithStorage[127.0.0.1:36431,DS-e766acec-1811-40fe-a6dd-2dd91fb16f25,DISK], DatanodeInfoWithStorage[127.0.0.1:40821,DS-8931ee30-29a6-434f-96a4-cb300c12a5f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33031,DS-2088a5d1-d6ed-42ad-84dc-3e7e2c980ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:35839,DS-c2ad1719-65e6-405e-9ca0-b4c695956107,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-9b81f9b0-58d8-409f-ae2b-0b90d0e5f437,DISK], DatanodeInfoWithStorage[127.0.0.1:33153,DS-3f719eb9-30d1-490c-8cfa-0de35bf499c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 0
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1985981624-172.17.0.17-1597517695612:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43227,DS-aa5c92da-8692-447e-bc71-b9eb91738376,DISK], DatanodeInfoWithStorage[127.0.0.1:38250,DS-50a91098-c23b-4880-ab01-bcaabbedb1bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44829,DS-0e832af0-bd3f-4899-90e9-a2431ee408a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45231,DS-374bb2a4-587b-46ac-b574-af7352b52a42,DISK], DatanodeInfoWithStorage[127.0.0.1:32880,DS-3236a084-9a49-41fe-b83b-fc7bd7d67c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:34225,DS-14f09f68-996a-4053-b913-bd343fb3ce13,DISK], DatanodeInfoWithStorage[127.0.0.1:34612,DS-123674f7-47af-4882-86fe-40ac28e27c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:46628,DS-3ef52d08-fce3-414b-a72a-6c7baa9a3cd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1985981624-172.17.0.17-1597517695612:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43227,DS-aa5c92da-8692-447e-bc71-b9eb91738376,DISK], DatanodeInfoWithStorage[127.0.0.1:38250,DS-50a91098-c23b-4880-ab01-bcaabbedb1bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44829,DS-0e832af0-bd3f-4899-90e9-a2431ee408a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45231,DS-374bb2a4-587b-46ac-b574-af7352b52a42,DISK], DatanodeInfoWithStorage[127.0.0.1:32880,DS-3236a084-9a49-41fe-b83b-fc7bd7d67c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:34225,DS-14f09f68-996a-4053-b913-bd343fb3ce13,DISK], DatanodeInfoWithStorage[127.0.0.1:34612,DS-123674f7-47af-4882-86fe-40ac28e27c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:46628,DS-3ef52d08-fce3-414b-a72a-6c7baa9a3cd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 0
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1597817913-172.17.0.17-1597517850984:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40349,DS-b9a4c9ff-fb0f-402f-8e6e-6a9f6aefd98a,DISK], DatanodeInfoWithStorage[127.0.0.1:45085,DS-e589ef2a-9018-4ad9-84cd-d7590a6fd400,DISK], DatanodeInfoWithStorage[127.0.0.1:42498,DS-e5373dc5-d45e-48b1-8247-085d3d5350b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38559,DS-b6f6aeaa-0734-4f24-91e7-5a8ff6513bef,DISK], DatanodeInfoWithStorage[127.0.0.1:45481,DS-6ca26dbe-b8f5-450c-b3f4-9fed1421cdf4,DISK], DatanodeInfoWithStorage[127.0.0.1:33467,DS-76473c44-1bd3-45f6-ae66-56a4a081c7b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42304,DS-9d762b44-7e05-40c5-ba5d-6a3816b15c25,DISK], DatanodeInfoWithStorage[127.0.0.1:40067,DS-41b03457-7668-4f43-8a4e-96d8266f2043,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1597817913-172.17.0.17-1597517850984:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40349,DS-b9a4c9ff-fb0f-402f-8e6e-6a9f6aefd98a,DISK], DatanodeInfoWithStorage[127.0.0.1:45085,DS-e589ef2a-9018-4ad9-84cd-d7590a6fd400,DISK], DatanodeInfoWithStorage[127.0.0.1:42498,DS-e5373dc5-d45e-48b1-8247-085d3d5350b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38559,DS-b6f6aeaa-0734-4f24-91e7-5a8ff6513bef,DISK], DatanodeInfoWithStorage[127.0.0.1:45481,DS-6ca26dbe-b8f5-450c-b3f4-9fed1421cdf4,DISK], DatanodeInfoWithStorage[127.0.0.1:33467,DS-76473c44-1bd3-45f6-ae66-56a4a081c7b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42304,DS-9d762b44-7e05-40c5-ba5d-6a3816b15c25,DISK], DatanodeInfoWithStorage[127.0.0.1:40067,DS-41b03457-7668-4f43-8a4e-96d8266f2043,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 0
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-54477022-172.17.0.17-1597518538189:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46518,DS-c3c1a196-6087-4ce2-9ed2-8c8d823484c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37858,DS-b687d4a2-a1c5-4e57-b461-f6d0ccee2e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:35827,DS-eb5cbdbe-8bf4-4f4d-9ad6-41f422dddb8e,DISK], DatanodeInfoWithStorage[127.0.0.1:46041,DS-87c57c4d-9abc-4584-86db-9d881991b705,DISK], DatanodeInfoWithStorage[127.0.0.1:38181,DS-ab79cc02-50b4-4229-83ae-8e03f6392ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:37879,DS-7d8d99c2-f94d-4bb0-8c10-56d122f97e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:41507,DS-31d91dd3-7519-4ea9-b811-0864f68e7726,DISK], DatanodeInfoWithStorage[127.0.0.1:33876,DS-5c55a586-644b-4508-9de7-f806e12e5a11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-54477022-172.17.0.17-1597518538189:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46518,DS-c3c1a196-6087-4ce2-9ed2-8c8d823484c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37858,DS-b687d4a2-a1c5-4e57-b461-f6d0ccee2e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:35827,DS-eb5cbdbe-8bf4-4f4d-9ad6-41f422dddb8e,DISK], DatanodeInfoWithStorage[127.0.0.1:46041,DS-87c57c4d-9abc-4584-86db-9d881991b705,DISK], DatanodeInfoWithStorage[127.0.0.1:38181,DS-ab79cc02-50b4-4229-83ae-8e03f6392ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:37879,DS-7d8d99c2-f94d-4bb0-8c10-56d122f97e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:41507,DS-31d91dd3-7519-4ea9-b811-0864f68e7726,DISK], DatanodeInfoWithStorage[127.0.0.1:33876,DS-5c55a586-644b-4508-9de7-f806e12e5a11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 0
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1699882051-172.17.0.17-1597518802374:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46124,DS-a2c1a0ee-cb90-4c83-8d9f-ae42305ae3a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40676,DS-721955df-dc4b-4021-a1a5-b123d596fc7a,DISK], DatanodeInfoWithStorage[127.0.0.1:41824,DS-711df902-b889-4186-ae2d-a13b7771d212,DISK], DatanodeInfoWithStorage[127.0.0.1:46193,DS-9db2148f-6e20-4df4-9ec4-902bdd5f39a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44922,DS-e340174a-a5e2-4312-8326-eeef963cbf47,DISK], DatanodeInfoWithStorage[127.0.0.1:43127,DS-66c6b99e-27db-478d-82d2-10681ba0acc0,DISK], DatanodeInfoWithStorage[127.0.0.1:42138,DS-1cb24a4c-986a-4b31-b608-7ab4c4c0c934,DISK], DatanodeInfoWithStorage[127.0.0.1:35692,DS-6a9c5b2e-5e87-4bb2-be91-7de3f3ae92bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1699882051-172.17.0.17-1597518802374:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46124,DS-a2c1a0ee-cb90-4c83-8d9f-ae42305ae3a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40676,DS-721955df-dc4b-4021-a1a5-b123d596fc7a,DISK], DatanodeInfoWithStorage[127.0.0.1:41824,DS-711df902-b889-4186-ae2d-a13b7771d212,DISK], DatanodeInfoWithStorage[127.0.0.1:46193,DS-9db2148f-6e20-4df4-9ec4-902bdd5f39a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44922,DS-e340174a-a5e2-4312-8326-eeef963cbf47,DISK], DatanodeInfoWithStorage[127.0.0.1:43127,DS-66c6b99e-27db-478d-82d2-10681ba0acc0,DISK], DatanodeInfoWithStorage[127.0.0.1:42138,DS-1cb24a4c-986a-4b31-b608-7ab4c4c0c934,DISK], DatanodeInfoWithStorage[127.0.0.1:35692,DS-6a9c5b2e-5e87-4bb2-be91-7de3f3ae92bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 0
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2085685074-172.17.0.17-1597519539006:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39175,DS-06e674c5-78ca-4abe-ad8f-33022fe2f033,DISK], DatanodeInfoWithStorage[127.0.0.1:40350,DS-2d78ce3c-e03a-42d5-bd35-6079ebbfeded,DISK], DatanodeInfoWithStorage[127.0.0.1:35669,DS-dd44bbaf-7360-4340-8adf-245efdbdbb02,DISK], DatanodeInfoWithStorage[127.0.0.1:33889,DS-5ed1dd37-ccfa-4563-bf72-4d6c7b1a89a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35463,DS-7718c710-e137-4019-88a9-c90325ce7c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43009,DS-5dbfcbc9-c3ae-42ba-9475-58ed1e1a6100,DISK], DatanodeInfoWithStorage[127.0.0.1:36762,DS-fc119c04-9797-4cff-b06e-bfe335cf752e,DISK], DatanodeInfoWithStorage[127.0.0.1:33773,DS-b06d1e33-846e-4643-95a1-64513b544120,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2085685074-172.17.0.17-1597519539006:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39175,DS-06e674c5-78ca-4abe-ad8f-33022fe2f033,DISK], DatanodeInfoWithStorage[127.0.0.1:40350,DS-2d78ce3c-e03a-42d5-bd35-6079ebbfeded,DISK], DatanodeInfoWithStorage[127.0.0.1:35669,DS-dd44bbaf-7360-4340-8adf-245efdbdbb02,DISK], DatanodeInfoWithStorage[127.0.0.1:33889,DS-5ed1dd37-ccfa-4563-bf72-4d6c7b1a89a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35463,DS-7718c710-e137-4019-88a9-c90325ce7c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43009,DS-5dbfcbc9-c3ae-42ba-9475-58ed1e1a6100,DISK], DatanodeInfoWithStorage[127.0.0.1:36762,DS-fc119c04-9797-4cff-b06e-bfe335cf752e,DISK], DatanodeInfoWithStorage[127.0.0.1:33773,DS-b06d1e33-846e-4643-95a1-64513b544120,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 0
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-741208486-172.17.0.17-1597519616467:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43371,DS-4e3f9676-5c2e-4236-a6c8-a600ee55b98f,DISK], DatanodeInfoWithStorage[127.0.0.1:34114,DS-31d1018f-f6b2-4d4a-9c28-1150586e3a20,DISK], DatanodeInfoWithStorage[127.0.0.1:38493,DS-6a40c81b-a445-4f8e-9600-4e8d24c0b249,DISK], DatanodeInfoWithStorage[127.0.0.1:36320,DS-b83e2bef-893d-4f77-aff1-aaa1a7ad6338,DISK], DatanodeInfoWithStorage[127.0.0.1:40171,DS-cfee2b64-f3dd-437e-9f00-74adafa8fa4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33400,DS-50a64345-8cb3-4072-831b-28c323e1c355,DISK], DatanodeInfoWithStorage[127.0.0.1:43496,DS-129e3cdc-fede-42e5-95f5-7353091a2aea,DISK], DatanodeInfoWithStorage[127.0.0.1:42730,DS-74b6864a-5296-4ce9-bc8d-de8021d618ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-741208486-172.17.0.17-1597519616467:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43371,DS-4e3f9676-5c2e-4236-a6c8-a600ee55b98f,DISK], DatanodeInfoWithStorage[127.0.0.1:34114,DS-31d1018f-f6b2-4d4a-9c28-1150586e3a20,DISK], DatanodeInfoWithStorage[127.0.0.1:38493,DS-6a40c81b-a445-4f8e-9600-4e8d24c0b249,DISK], DatanodeInfoWithStorage[127.0.0.1:36320,DS-b83e2bef-893d-4f77-aff1-aaa1a7ad6338,DISK], DatanodeInfoWithStorage[127.0.0.1:40171,DS-cfee2b64-f3dd-437e-9f00-74adafa8fa4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33400,DS-50a64345-8cb3-4072-831b-28c323e1c355,DISK], DatanodeInfoWithStorage[127.0.0.1:43496,DS-129e3cdc-fede-42e5-95f5-7353091a2aea,DISK], DatanodeInfoWithStorage[127.0.0.1:42730,DS-74b6864a-5296-4ce9-bc8d-de8021d618ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 0
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1691657853-172.17.0.17-1597519859614:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43191,DS-572bb185-eb92-4533-9a05-fd004d3bbe7c,DISK], DatanodeInfoWithStorage[127.0.0.1:45015,DS-8fb80b61-ca98-43d8-90e2-530435f1a9c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37604,DS-9b96b849-ccd9-4893-9a6e-d640caeb49be,DISK], DatanodeInfoWithStorage[127.0.0.1:36863,DS-1be316fa-7807-4205-af3d-78a306cfa290,DISK], DatanodeInfoWithStorage[127.0.0.1:41205,DS-5145e8c1-5349-4328-9bf3-d36742908f44,DISK], DatanodeInfoWithStorage[127.0.0.1:35501,DS-25a7b128-e5cc-438c-a4c4-11a26ddc163e,DISK], DatanodeInfoWithStorage[127.0.0.1:43728,DS-90020fe9-61ca-495b-a5eb-e04b5106ab78,DISK], DatanodeInfoWithStorage[127.0.0.1:37205,DS-d9ee8365-1426-4317-9679-95193f25e3c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1691657853-172.17.0.17-1597519859614:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43191,DS-572bb185-eb92-4533-9a05-fd004d3bbe7c,DISK], DatanodeInfoWithStorage[127.0.0.1:45015,DS-8fb80b61-ca98-43d8-90e2-530435f1a9c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37604,DS-9b96b849-ccd9-4893-9a6e-d640caeb49be,DISK], DatanodeInfoWithStorage[127.0.0.1:36863,DS-1be316fa-7807-4205-af3d-78a306cfa290,DISK], DatanodeInfoWithStorage[127.0.0.1:41205,DS-5145e8c1-5349-4328-9bf3-d36742908f44,DISK], DatanodeInfoWithStorage[127.0.0.1:35501,DS-25a7b128-e5cc-438c-a4c4-11a26ddc163e,DISK], DatanodeInfoWithStorage[127.0.0.1:43728,DS-90020fe9-61ca-495b-a5eb-e04b5106ab78,DISK], DatanodeInfoWithStorage[127.0.0.1:37205,DS-d9ee8365-1426-4317-9679-95193f25e3c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 0
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1800371061-172.17.0.17-1597519902833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33003,DS-ac5269b9-6f3c-4a65-bc13-046669a80278,DISK], DatanodeInfoWithStorage[127.0.0.1:43941,DS-67a03fd3-bf8f-4dae-9bc1-34dff98186ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41927,DS-0d0b79ee-aec3-4c33-9e33-4f22cebe5bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:41977,DS-e9afed3e-5ecb-4a83-aad8-c5abb08f0749,DISK], DatanodeInfoWithStorage[127.0.0.1:34820,DS-8563793d-7a8b-4dd0-a444-82cb8a0b701a,DISK], DatanodeInfoWithStorage[127.0.0.1:46271,DS-68df1e0e-4a05-4c2a-bcc7-527aa91141c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36716,DS-9c64ad47-5973-43fd-b92f-b9f09a1e590f,DISK], DatanodeInfoWithStorage[127.0.0.1:36639,DS-b6e436ac-c1d9-466d-be9c-09eb974f2c28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1800371061-172.17.0.17-1597519902833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33003,DS-ac5269b9-6f3c-4a65-bc13-046669a80278,DISK], DatanodeInfoWithStorage[127.0.0.1:43941,DS-67a03fd3-bf8f-4dae-9bc1-34dff98186ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41927,DS-0d0b79ee-aec3-4c33-9e33-4f22cebe5bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:41977,DS-e9afed3e-5ecb-4a83-aad8-c5abb08f0749,DISK], DatanodeInfoWithStorage[127.0.0.1:34820,DS-8563793d-7a8b-4dd0-a444-82cb8a0b701a,DISK], DatanodeInfoWithStorage[127.0.0.1:46271,DS-68df1e0e-4a05-4c2a-bcc7-527aa91141c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36716,DS-9c64ad47-5973-43fd-b92f-b9f09a1e590f,DISK], DatanodeInfoWithStorage[127.0.0.1:36639,DS-b6e436ac-c1d9-466d-be9c-09eb974f2c28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5773
