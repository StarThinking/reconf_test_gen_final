reconf_parameter: dfs.namenode.checkpoint.period
component: hdfs:NameNode
v1: 3600s
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.period
component: hdfs:NameNode
v1: 3600s
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1660687948-172.17.0.18-1597468491808:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35327,DS-b1fec161-a83f-4c2c-9e1c-6a1bcec37413,DISK], DatanodeInfoWithStorage[127.0.0.1:43675,DS-38089714-dd74-461b-814a-8f15353e53a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33912,DS-1ac33c24-544d-4d6d-b727-90bf955d1bee,DISK], DatanodeInfoWithStorage[127.0.0.1:39776,DS-0c5a5e08-a762-4b0f-9ff9-e99e859674fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36908,DS-0e6f39ad-5049-448a-b536-58f2762125e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46394,DS-011932fd-4f86-4edd-b652-5040830aeb60,DISK], DatanodeInfoWithStorage[127.0.0.1:43608,DS-dc91091d-55b9-467a-a2f7-b51e69f67201,DISK], DatanodeInfoWithStorage[127.0.0.1:40688,DS-d6fa12bb-7d9f-4d64-a510-562c95738179,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1660687948-172.17.0.18-1597468491808:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35327,DS-b1fec161-a83f-4c2c-9e1c-6a1bcec37413,DISK], DatanodeInfoWithStorage[127.0.0.1:43675,DS-38089714-dd74-461b-814a-8f15353e53a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33912,DS-1ac33c24-544d-4d6d-b727-90bf955d1bee,DISK], DatanodeInfoWithStorage[127.0.0.1:39776,DS-0c5a5e08-a762-4b0f-9ff9-e99e859674fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36908,DS-0e6f39ad-5049-448a-b536-58f2762125e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46394,DS-011932fd-4f86-4edd-b652-5040830aeb60,DISK], DatanodeInfoWithStorage[127.0.0.1:43608,DS-dc91091d-55b9-467a-a2f7-b51e69f67201,DISK], DatanodeInfoWithStorage[127.0.0.1:40688,DS-d6fa12bb-7d9f-4d64-a510-562c95738179,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.period
component: hdfs:NameNode
v1: 3600s
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1980981632-172.17.0.18-1597468567615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46072,DS-4682c766-28e0-4c1d-b5e4-e14d2924cb6f,DISK], DatanodeInfoWithStorage[127.0.0.1:35767,DS-1df1a93f-64fc-414c-a432-a9d2648e7160,DISK], DatanodeInfoWithStorage[127.0.0.1:38028,DS-9a1ca69a-79ab-4376-87be-f7a4cc6880c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43943,DS-0dbd0af9-394e-401c-b5a5-938d4f692235,DISK], DatanodeInfoWithStorage[127.0.0.1:36939,DS-3f8d29ff-944d-4e82-a788-83722b217df1,DISK], DatanodeInfoWithStorage[127.0.0.1:40743,DS-8f57ced4-f412-4cfe-8725-ca8f5e1c99aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41621,DS-f2034af2-760b-4880-9534-fefadc6b87b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40569,DS-0c416e3d-b91c-4273-8e4e-6d08eaa09e26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1980981632-172.17.0.18-1597468567615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46072,DS-4682c766-28e0-4c1d-b5e4-e14d2924cb6f,DISK], DatanodeInfoWithStorage[127.0.0.1:35767,DS-1df1a93f-64fc-414c-a432-a9d2648e7160,DISK], DatanodeInfoWithStorage[127.0.0.1:38028,DS-9a1ca69a-79ab-4376-87be-f7a4cc6880c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43943,DS-0dbd0af9-394e-401c-b5a5-938d4f692235,DISK], DatanodeInfoWithStorage[127.0.0.1:36939,DS-3f8d29ff-944d-4e82-a788-83722b217df1,DISK], DatanodeInfoWithStorage[127.0.0.1:40743,DS-8f57ced4-f412-4cfe-8725-ca8f5e1c99aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41621,DS-f2034af2-760b-4880-9534-fefadc6b87b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40569,DS-0c416e3d-b91c-4273-8e4e-6d08eaa09e26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.period
component: hdfs:NameNode
v1: 3600s
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2104378397-172.17.0.18-1597468793005:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35705,DS-955379fc-7d89-477a-b380-cf0d0cb8ed7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40469,DS-2fe52f0b-18fa-47af-99ae-a2c2bca3f833,DISK], DatanodeInfoWithStorage[127.0.0.1:34379,DS-0dd65772-ab39-45e0-a53a-45e88fa62f95,DISK], DatanodeInfoWithStorage[127.0.0.1:41879,DS-98bdcdca-0212-4609-a4a8-a95bec97cd59,DISK], DatanodeInfoWithStorage[127.0.0.1:35452,DS-468b41c0-b265-4415-b161-f0e93802e81d,DISK], DatanodeInfoWithStorage[127.0.0.1:33426,DS-44a68362-6b45-4737-a6cb-0a8878cf0123,DISK], DatanodeInfoWithStorage[127.0.0.1:35081,DS-d8d0ee92-177a-4905-806d-33307d34c8d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44424,DS-3c75b149-faea-4342-b9a5-6940fb60eaef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2104378397-172.17.0.18-1597468793005:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35705,DS-955379fc-7d89-477a-b380-cf0d0cb8ed7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40469,DS-2fe52f0b-18fa-47af-99ae-a2c2bca3f833,DISK], DatanodeInfoWithStorage[127.0.0.1:34379,DS-0dd65772-ab39-45e0-a53a-45e88fa62f95,DISK], DatanodeInfoWithStorage[127.0.0.1:41879,DS-98bdcdca-0212-4609-a4a8-a95bec97cd59,DISK], DatanodeInfoWithStorage[127.0.0.1:35452,DS-468b41c0-b265-4415-b161-f0e93802e81d,DISK], DatanodeInfoWithStorage[127.0.0.1:33426,DS-44a68362-6b45-4737-a6cb-0a8878cf0123,DISK], DatanodeInfoWithStorage[127.0.0.1:35081,DS-d8d0ee92-177a-4905-806d-33307d34c8d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44424,DS-3c75b149-faea-4342-b9a5-6940fb60eaef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.checkpoint.period
component: hdfs:NameNode
v1: 3600s
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1381053886-172.17.0.18-1597468827423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37307,DS-8a09d180-d142-4f04-b1b5-500ac1b1a566,DISK], DatanodeInfoWithStorage[127.0.0.1:39819,DS-4bf9a519-1795-4712-901a-c7b731d0b74e,DISK], DatanodeInfoWithStorage[127.0.0.1:41085,DS-e34534a6-ee41-4ac5-9a4a-f885784bcc89,DISK], DatanodeInfoWithStorage[127.0.0.1:46325,DS-93a1466b-157a-4f5a-a851-df00ea50d8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33357,DS-e6dad783-ae06-458b-a806-064517190a43,DISK], DatanodeInfoWithStorage[127.0.0.1:35262,DS-c016923d-a3ce-45e5-921d-87dc20e762bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35116,DS-214621eb-9c3b-463b-a414-ddd4f061d49c,DISK], DatanodeInfoWithStorage[127.0.0.1:34576,DS-6d78da3e-aec8-41da-920d-0558a539a945,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1381053886-172.17.0.18-1597468827423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37307,DS-8a09d180-d142-4f04-b1b5-500ac1b1a566,DISK], DatanodeInfoWithStorage[127.0.0.1:39819,DS-4bf9a519-1795-4712-901a-c7b731d0b74e,DISK], DatanodeInfoWithStorage[127.0.0.1:41085,DS-e34534a6-ee41-4ac5-9a4a-f885784bcc89,DISK], DatanodeInfoWithStorage[127.0.0.1:46325,DS-93a1466b-157a-4f5a-a851-df00ea50d8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33357,DS-e6dad783-ae06-458b-a806-064517190a43,DISK], DatanodeInfoWithStorage[127.0.0.1:35262,DS-c016923d-a3ce-45e5-921d-87dc20e762bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35116,DS-214621eb-9c3b-463b-a414-ddd4f061d49c,DISK], DatanodeInfoWithStorage[127.0.0.1:34576,DS-6d78da3e-aec8-41da-920d-0558a539a945,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.period
component: hdfs:NameNode
v1: 3600s
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-915938844-172.17.0.18-1597468991285:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41012,DS-597bfddc-c33d-4816-9d73-49f262b88f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:36770,DS-ce75f833-e10b-4a66-98f5-c46d18025910,DISK], DatanodeInfoWithStorage[127.0.0.1:33731,DS-5c0a611a-f48d-4688-8004-e750940309a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37769,DS-7d10f894-0cf0-4973-b323-72c12d5bfc33,DISK], DatanodeInfoWithStorage[127.0.0.1:38682,DS-245f8823-d9cd-434c-8369-fa105c187360,DISK], DatanodeInfoWithStorage[127.0.0.1:46124,DS-4d5e5ecd-ec52-4fb1-9439-3368eb51d132,DISK], DatanodeInfoWithStorage[127.0.0.1:46319,DS-0067a700-e4b0-4dd2-8dc0-db6b841997c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40969,DS-eab3d406-bf95-49c8-acf2-1f64c3dd022e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-915938844-172.17.0.18-1597468991285:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41012,DS-597bfddc-c33d-4816-9d73-49f262b88f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:36770,DS-ce75f833-e10b-4a66-98f5-c46d18025910,DISK], DatanodeInfoWithStorage[127.0.0.1:33731,DS-5c0a611a-f48d-4688-8004-e750940309a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37769,DS-7d10f894-0cf0-4973-b323-72c12d5bfc33,DISK], DatanodeInfoWithStorage[127.0.0.1:38682,DS-245f8823-d9cd-434c-8369-fa105c187360,DISK], DatanodeInfoWithStorage[127.0.0.1:46124,DS-4d5e5ecd-ec52-4fb1-9439-3368eb51d132,DISK], DatanodeInfoWithStorage[127.0.0.1:46319,DS-0067a700-e4b0-4dd2-8dc0-db6b841997c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40969,DS-eab3d406-bf95-49c8-acf2-1f64c3dd022e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.period
component: hdfs:NameNode
v1: 3600s
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-569137087-172.17.0.18-1597469616326:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42150,DS-0cd47560-d1eb-40a5-8477-4844b0058589,DISK], DatanodeInfoWithStorage[127.0.0.1:36876,DS-c8e000b2-594f-488f-a348-1f8a3b0fd81b,DISK], DatanodeInfoWithStorage[127.0.0.1:44420,DS-f603c2fc-4acb-4083-a880-43d128a66878,DISK], DatanodeInfoWithStorage[127.0.0.1:33999,DS-8f7ea613-9182-4b04-bad9-2c770bce2de0,DISK], DatanodeInfoWithStorage[127.0.0.1:36626,DS-369f3537-f397-4d58-a9f0-00fa18a1ced6,DISK], DatanodeInfoWithStorage[127.0.0.1:45832,DS-2efaae35-2655-4221-9efb-fea20c1264cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45960,DS-1aabfb56-c65c-4b06-9545-13ed8f1886c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46463,DS-111c19cb-74a2-4a2a-8ca6-a2d2203c15aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-569137087-172.17.0.18-1597469616326:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42150,DS-0cd47560-d1eb-40a5-8477-4844b0058589,DISK], DatanodeInfoWithStorage[127.0.0.1:36876,DS-c8e000b2-594f-488f-a348-1f8a3b0fd81b,DISK], DatanodeInfoWithStorage[127.0.0.1:44420,DS-f603c2fc-4acb-4083-a880-43d128a66878,DISK], DatanodeInfoWithStorage[127.0.0.1:33999,DS-8f7ea613-9182-4b04-bad9-2c770bce2de0,DISK], DatanodeInfoWithStorage[127.0.0.1:36626,DS-369f3537-f397-4d58-a9f0-00fa18a1ced6,DISK], DatanodeInfoWithStorage[127.0.0.1:45832,DS-2efaae35-2655-4221-9efb-fea20c1264cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45960,DS-1aabfb56-c65c-4b06-9545-13ed8f1886c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46463,DS-111c19cb-74a2-4a2a-8ca6-a2d2203c15aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.period
component: hdfs:NameNode
v1: 3600s
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1164284327-172.17.0.18-1597469916053:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44189,DS-8abdfd0c-9d6e-456c-a426-417b5b404a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37871,DS-9962d950-5ead-457a-9b68-6ccdd7b967e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34472,DS-42eb0cea-9bad-4a09-b8a2-f3964e1e0064,DISK], DatanodeInfoWithStorage[127.0.0.1:43440,DS-7f028320-92ab-4083-8be8-bcc07d4a24df,DISK], DatanodeInfoWithStorage[127.0.0.1:37741,DS-014242f7-5893-4036-80ac-1afbfbd4b3da,DISK], DatanodeInfoWithStorage[127.0.0.1:36445,DS-4bc043e1-98b3-4128-8bce-7bc07f819595,DISK], DatanodeInfoWithStorage[127.0.0.1:33330,DS-fa26fb69-66d2-4b0f-95f4-cbeb600045a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39033,DS-d1bcf349-bf04-4170-9d96-fc93cbc04d50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1164284327-172.17.0.18-1597469916053:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44189,DS-8abdfd0c-9d6e-456c-a426-417b5b404a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37871,DS-9962d950-5ead-457a-9b68-6ccdd7b967e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34472,DS-42eb0cea-9bad-4a09-b8a2-f3964e1e0064,DISK], DatanodeInfoWithStorage[127.0.0.1:43440,DS-7f028320-92ab-4083-8be8-bcc07d4a24df,DISK], DatanodeInfoWithStorage[127.0.0.1:37741,DS-014242f7-5893-4036-80ac-1afbfbd4b3da,DISK], DatanodeInfoWithStorage[127.0.0.1:36445,DS-4bc043e1-98b3-4128-8bce-7bc07f819595,DISK], DatanodeInfoWithStorage[127.0.0.1:33330,DS-fa26fb69-66d2-4b0f-95f4-cbeb600045a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39033,DS-d1bcf349-bf04-4170-9d96-fc93cbc04d50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.period
component: hdfs:NameNode
v1: 3600s
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1479649100-172.17.0.18-1597469995141:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39066,DS-d432ef9a-f0b0-4230-9e27-17671d6d0cab,DISK], DatanodeInfoWithStorage[127.0.0.1:38594,DS-be28c30d-a02a-4793-af8c-d656323c98af,DISK], DatanodeInfoWithStorage[127.0.0.1:45162,DS-cdcbdc66-7026-4dcf-b9a9-53ae834ee786,DISK], DatanodeInfoWithStorage[127.0.0.1:38967,DS-670fbb92-eb1e-451b-ba75-69b746b94d83,DISK], DatanodeInfoWithStorage[127.0.0.1:37510,DS-9e05b29f-2755-447c-8a3e-690148bd36b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42457,DS-4017b594-a74b-48b5-a2d0-072cc3359c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35815,DS-9dd19b74-93ea-4ca6-afdd-ef619fa569fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44572,DS-2a8e28a5-0936-4419-9fbb-369e3a23614f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1479649100-172.17.0.18-1597469995141:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39066,DS-d432ef9a-f0b0-4230-9e27-17671d6d0cab,DISK], DatanodeInfoWithStorage[127.0.0.1:38594,DS-be28c30d-a02a-4793-af8c-d656323c98af,DISK], DatanodeInfoWithStorage[127.0.0.1:45162,DS-cdcbdc66-7026-4dcf-b9a9-53ae834ee786,DISK], DatanodeInfoWithStorage[127.0.0.1:38967,DS-670fbb92-eb1e-451b-ba75-69b746b94d83,DISK], DatanodeInfoWithStorage[127.0.0.1:37510,DS-9e05b29f-2755-447c-8a3e-690148bd36b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42457,DS-4017b594-a74b-48b5-a2d0-072cc3359c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35815,DS-9dd19b74-93ea-4ca6-afdd-ef619fa569fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44572,DS-2a8e28a5-0936-4419-9fbb-369e3a23614f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.period
component: hdfs:NameNode
v1: 3600s
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-619315497-172.17.0.18-1597470449158:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40604,DS-28517d00-e875-4bc9-800c-a5d48dbbac2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46624,DS-95b4274b-f492-45c1-ba38-41aff6c52dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:39805,DS-9ccd5882-7e9d-45b8-a719-c894897872ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44823,DS-8514e2bd-4fd9-40cc-88be-b22431cf4eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:42825,DS-eeb2f2d0-9cb1-4e74-a4f3-85d582a763f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38746,DS-45a92437-ee12-4377-b990-e21326d11e26,DISK], DatanodeInfoWithStorage[127.0.0.1:37712,DS-0d016359-fdcb-4530-9f11-e50d3c5e566d,DISK], DatanodeInfoWithStorage[127.0.0.1:41638,DS-436ca72b-d2dc-4dcc-96ac-d11214c26c15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-619315497-172.17.0.18-1597470449158:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40604,DS-28517d00-e875-4bc9-800c-a5d48dbbac2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46624,DS-95b4274b-f492-45c1-ba38-41aff6c52dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:39805,DS-9ccd5882-7e9d-45b8-a719-c894897872ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44823,DS-8514e2bd-4fd9-40cc-88be-b22431cf4eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:42825,DS-eeb2f2d0-9cb1-4e74-a4f3-85d582a763f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38746,DS-45a92437-ee12-4377-b990-e21326d11e26,DISK], DatanodeInfoWithStorage[127.0.0.1:37712,DS-0d016359-fdcb-4530-9f11-e50d3c5e566d,DISK], DatanodeInfoWithStorage[127.0.0.1:41638,DS-436ca72b-d2dc-4dcc-96ac-d11214c26c15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.period
component: hdfs:NameNode
v1: 3600s
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-73045977-172.17.0.18-1597470606831:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35756,DS-ac299bac-b805-4e3e-8604-70b4744d9e63,DISK], DatanodeInfoWithStorage[127.0.0.1:41203,DS-7503b6ff-3df5-456a-9384-69c923d71b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:38962,DS-3d7ab0ce-d984-4ccf-9e78-26ca423c6948,DISK], DatanodeInfoWithStorage[127.0.0.1:38808,DS-562bfaa2-1beb-4ab3-ae63-7e1f87a2f118,DISK], DatanodeInfoWithStorage[127.0.0.1:39280,DS-22f1c64b-6d97-4bea-a0dc-16f3af11a8d6,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-cdddc2e8-92e1-40ec-b7cb-d91032723d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36704,DS-23b94500-84ea-4e84-8e9d-90ae29218862,DISK], DatanodeInfoWithStorage[127.0.0.1:39120,DS-0cb4a663-5419-4309-9172-4175d14b1e79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-73045977-172.17.0.18-1597470606831:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35756,DS-ac299bac-b805-4e3e-8604-70b4744d9e63,DISK], DatanodeInfoWithStorage[127.0.0.1:41203,DS-7503b6ff-3df5-456a-9384-69c923d71b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:38962,DS-3d7ab0ce-d984-4ccf-9e78-26ca423c6948,DISK], DatanodeInfoWithStorage[127.0.0.1:38808,DS-562bfaa2-1beb-4ab3-ae63-7e1f87a2f118,DISK], DatanodeInfoWithStorage[127.0.0.1:39280,DS-22f1c64b-6d97-4bea-a0dc-16f3af11a8d6,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-cdddc2e8-92e1-40ec-b7cb-d91032723d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36704,DS-23b94500-84ea-4e84-8e9d-90ae29218862,DISK], DatanodeInfoWithStorage[127.0.0.1:39120,DS-0cb4a663-5419-4309-9172-4175d14b1e79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.period
component: hdfs:NameNode
v1: 3600s
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1864149129-172.17.0.18-1597471580315:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46850,DS-4a39dc31-55d7-4830-b0b4-d804fa8525b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43435,DS-2f315d37-5030-48dc-94a1-c3844c66bbf7,DISK], DatanodeInfoWithStorage[127.0.0.1:37786,DS-59df82bd-bbe9-41d4-97f9-0293e86484b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39951,DS-c1083ed3-69bf-4bec-8e5d-ffec66141f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:46319,DS-95b62133-c8f1-4bf6-b5f1-b45add68d22d,DISK], DatanodeInfoWithStorage[127.0.0.1:36487,DS-42f7627e-8336-4a9f-8481-abcdcd064368,DISK], DatanodeInfoWithStorage[127.0.0.1:42680,DS-deddc1af-5c48-42a0-857d-153c89811f10,DISK], DatanodeInfoWithStorage[127.0.0.1:43357,DS-13a4227c-61ff-4b58-b92e-d7a2dd8fb805,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1864149129-172.17.0.18-1597471580315:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46850,DS-4a39dc31-55d7-4830-b0b4-d804fa8525b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43435,DS-2f315d37-5030-48dc-94a1-c3844c66bbf7,DISK], DatanodeInfoWithStorage[127.0.0.1:37786,DS-59df82bd-bbe9-41d4-97f9-0293e86484b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39951,DS-c1083ed3-69bf-4bec-8e5d-ffec66141f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:46319,DS-95b62133-c8f1-4bf6-b5f1-b45add68d22d,DISK], DatanodeInfoWithStorage[127.0.0.1:36487,DS-42f7627e-8336-4a9f-8481-abcdcd064368,DISK], DatanodeInfoWithStorage[127.0.0.1:42680,DS-deddc1af-5c48-42a0-857d-153c89811f10,DISK], DatanodeInfoWithStorage[127.0.0.1:43357,DS-13a4227c-61ff-4b58-b92e-d7a2dd8fb805,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.period
component: hdfs:NameNode
v1: 3600s
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1364385906-172.17.0.18-1597472297621:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43913,DS-a2cdb7d0-494a-4695-896f-4929b33355fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44852,DS-5b8349f2-9718-4553-bd7e-12ec768df4da,DISK], DatanodeInfoWithStorage[127.0.0.1:45645,DS-fc3eea80-f8c4-47d7-a349-054b6e6ef89c,DISK], DatanodeInfoWithStorage[127.0.0.1:37041,DS-c95e08bd-2501-4117-a40b-fd9bd1e0bb42,DISK], DatanodeInfoWithStorage[127.0.0.1:43662,DS-323cdd24-be79-4af6-9b1e-112357fe53a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39709,DS-6641f5fb-a6a7-4ac7-b9f5-29460abad564,DISK], DatanodeInfoWithStorage[127.0.0.1:34789,DS-fa7ed4ca-1a74-4b9d-813b-10f57e415065,DISK], DatanodeInfoWithStorage[127.0.0.1:39813,DS-d139ee50-ecdc-42ae-9353-3dd4f365487d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1364385906-172.17.0.18-1597472297621:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43913,DS-a2cdb7d0-494a-4695-896f-4929b33355fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44852,DS-5b8349f2-9718-4553-bd7e-12ec768df4da,DISK], DatanodeInfoWithStorage[127.0.0.1:45645,DS-fc3eea80-f8c4-47d7-a349-054b6e6ef89c,DISK], DatanodeInfoWithStorage[127.0.0.1:37041,DS-c95e08bd-2501-4117-a40b-fd9bd1e0bb42,DISK], DatanodeInfoWithStorage[127.0.0.1:43662,DS-323cdd24-be79-4af6-9b1e-112357fe53a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39709,DS-6641f5fb-a6a7-4ac7-b9f5-29460abad564,DISK], DatanodeInfoWithStorage[127.0.0.1:34789,DS-fa7ed4ca-1a74-4b9d-813b-10f57e415065,DISK], DatanodeInfoWithStorage[127.0.0.1:39813,DS-d139ee50-ecdc-42ae-9353-3dd4f365487d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.period
component: hdfs:NameNode
v1: 3600s
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-855382333-172.17.0.18-1597472521313:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33338,DS-3f0484b1-091c-44ce-821e-c60d3c341959,DISK], DatanodeInfoWithStorage[127.0.0.1:43512,DS-f0d54848-fa06-4673-96a9-305ba09d67b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46265,DS-afce125d-57f1-44f2-8f4b-8e9605b0fd44,DISK], DatanodeInfoWithStorage[127.0.0.1:40940,DS-4c366425-4f0f-4e1a-bdd3-1c99912b5483,DISK], DatanodeInfoWithStorage[127.0.0.1:35056,DS-e4361106-80e9-4266-b95a-eb49285c10fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34335,DS-6cd6c19c-f14e-4058-82f6-c062e8f5be77,DISK], DatanodeInfoWithStorage[127.0.0.1:37106,DS-7cbab116-fcfb-4ab9-a3aa-256419360d41,DISK], DatanodeInfoWithStorage[127.0.0.1:38698,DS-fb5d7e58-b9c5-44f5-b5d5-77d904c78f96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-855382333-172.17.0.18-1597472521313:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33338,DS-3f0484b1-091c-44ce-821e-c60d3c341959,DISK], DatanodeInfoWithStorage[127.0.0.1:43512,DS-f0d54848-fa06-4673-96a9-305ba09d67b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46265,DS-afce125d-57f1-44f2-8f4b-8e9605b0fd44,DISK], DatanodeInfoWithStorage[127.0.0.1:40940,DS-4c366425-4f0f-4e1a-bdd3-1c99912b5483,DISK], DatanodeInfoWithStorage[127.0.0.1:35056,DS-e4361106-80e9-4266-b95a-eb49285c10fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34335,DS-6cd6c19c-f14e-4058-82f6-c062e8f5be77,DISK], DatanodeInfoWithStorage[127.0.0.1:37106,DS-7cbab116-fcfb-4ab9-a3aa-256419360d41,DISK], DatanodeInfoWithStorage[127.0.0.1:38698,DS-fb5d7e58-b9c5-44f5-b5d5-77d904c78f96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.period
component: hdfs:NameNode
v1: 3600s
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-217660253-172.17.0.18-1597472568575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35864,DS-b7a502ae-362f-461a-ac27-b5f63d39bf95,DISK], DatanodeInfoWithStorage[127.0.0.1:44802,DS-89d8f0f5-83ba-4f35-9894-a0f273b00520,DISK], DatanodeInfoWithStorage[127.0.0.1:33494,DS-94ddfe5e-46df-47d7-8bd7-3cbb1befd728,DISK], DatanodeInfoWithStorage[127.0.0.1:34746,DS-035fe81e-46b3-4108-a18c-cc6f7f0acc07,DISK], DatanodeInfoWithStorage[127.0.0.1:46063,DS-7c0a4234-baff-4583-bb36-cbcad086e325,DISK], DatanodeInfoWithStorage[127.0.0.1:43189,DS-520abaad-1ff8-4b63-b274-301cad7d3391,DISK], DatanodeInfoWithStorage[127.0.0.1:33652,DS-ee97652c-8eca-4008-a0ad-c5f898315d61,DISK], DatanodeInfoWithStorage[127.0.0.1:43021,DS-4e674a5d-c9c5-4afb-81a3-11c232a5dd71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-217660253-172.17.0.18-1597472568575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35864,DS-b7a502ae-362f-461a-ac27-b5f63d39bf95,DISK], DatanodeInfoWithStorage[127.0.0.1:44802,DS-89d8f0f5-83ba-4f35-9894-a0f273b00520,DISK], DatanodeInfoWithStorage[127.0.0.1:33494,DS-94ddfe5e-46df-47d7-8bd7-3cbb1befd728,DISK], DatanodeInfoWithStorage[127.0.0.1:34746,DS-035fe81e-46b3-4108-a18c-cc6f7f0acc07,DISK], DatanodeInfoWithStorage[127.0.0.1:46063,DS-7c0a4234-baff-4583-bb36-cbcad086e325,DISK], DatanodeInfoWithStorage[127.0.0.1:43189,DS-520abaad-1ff8-4b63-b274-301cad7d3391,DISK], DatanodeInfoWithStorage[127.0.0.1:33652,DS-ee97652c-8eca-4008-a0ad-c5f898315d61,DISK], DatanodeInfoWithStorage[127.0.0.1:43021,DS-4e674a5d-c9c5-4afb-81a3-11c232a5dd71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.period
component: hdfs:NameNode
v1: 3600s
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-589112469-172.17.0.18-1597472797964:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37939,DS-151870eb-4272-4c31-8ed1-6a10016aede7,DISK], DatanodeInfoWithStorage[127.0.0.1:36108,DS-e72df947-47b0-42a0-9358-80824e655f67,DISK], DatanodeInfoWithStorage[127.0.0.1:40408,DS-98e401d5-aaa4-4891-908e-fa9c838b29c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45303,DS-a62f9d92-a951-450c-982d-fa824f136c10,DISK], DatanodeInfoWithStorage[127.0.0.1:38740,DS-2d7cbe7a-4e3a-4e36-a492-6b99c092cd4e,DISK], DatanodeInfoWithStorage[127.0.0.1:41203,DS-15d148be-b327-43f1-9f75-7653928379e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33822,DS-277e10fd-7380-442e-99fd-c13916a2bcd3,DISK], DatanodeInfoWithStorage[127.0.0.1:43859,DS-8ae8b1f8-ba5f-4025-849e-eb8afc57b763,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-589112469-172.17.0.18-1597472797964:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37939,DS-151870eb-4272-4c31-8ed1-6a10016aede7,DISK], DatanodeInfoWithStorage[127.0.0.1:36108,DS-e72df947-47b0-42a0-9358-80824e655f67,DISK], DatanodeInfoWithStorage[127.0.0.1:40408,DS-98e401d5-aaa4-4891-908e-fa9c838b29c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45303,DS-a62f9d92-a951-450c-982d-fa824f136c10,DISK], DatanodeInfoWithStorage[127.0.0.1:38740,DS-2d7cbe7a-4e3a-4e36-a492-6b99c092cd4e,DISK], DatanodeInfoWithStorage[127.0.0.1:41203,DS-15d148be-b327-43f1-9f75-7653928379e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33822,DS-277e10fd-7380-442e-99fd-c13916a2bcd3,DISK], DatanodeInfoWithStorage[127.0.0.1:43859,DS-8ae8b1f8-ba5f-4025-849e-eb8afc57b763,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5786
