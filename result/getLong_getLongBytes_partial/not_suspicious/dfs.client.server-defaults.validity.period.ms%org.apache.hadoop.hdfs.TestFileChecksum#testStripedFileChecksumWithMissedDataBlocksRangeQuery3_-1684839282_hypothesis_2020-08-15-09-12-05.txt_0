reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 360
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 360
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-200612179-172.17.0.14-1597482744376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40011,DS-acbfbadb-729a-4acc-a681-406e7c3a0016,DISK], DatanodeInfoWithStorage[127.0.0.1:44877,DS-5e4fee74-405c-43e1-abdc-048d714666a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40006,DS-694ea18d-993b-49d0-8db4-bd913ce4b24f,DISK], DatanodeInfoWithStorage[127.0.0.1:35010,DS-de4938d0-55d2-4977-b0a8-73e6fe90e27f,DISK], DatanodeInfoWithStorage[127.0.0.1:38445,DS-584a136b-0f50-4225-95e8-6891ca1880e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33896,DS-efad4420-d962-4229-8ae3-271cee2acd51,DISK], DatanodeInfoWithStorage[127.0.0.1:39637,DS-ad1d94c2-f886-466c-98d5-8ae0e604531e,DISK], DatanodeInfoWithStorage[127.0.0.1:33907,DS-bb112b8d-6046-4cb3-8325-70d65e0573eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-200612179-172.17.0.14-1597482744376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40011,DS-acbfbadb-729a-4acc-a681-406e7c3a0016,DISK], DatanodeInfoWithStorage[127.0.0.1:44877,DS-5e4fee74-405c-43e1-abdc-048d714666a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40006,DS-694ea18d-993b-49d0-8db4-bd913ce4b24f,DISK], DatanodeInfoWithStorage[127.0.0.1:35010,DS-de4938d0-55d2-4977-b0a8-73e6fe90e27f,DISK], DatanodeInfoWithStorage[127.0.0.1:38445,DS-584a136b-0f50-4225-95e8-6891ca1880e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33896,DS-efad4420-d962-4229-8ae3-271cee2acd51,DISK], DatanodeInfoWithStorage[127.0.0.1:39637,DS-ad1d94c2-f886-466c-98d5-8ae0e604531e,DISK], DatanodeInfoWithStorage[127.0.0.1:33907,DS-bb112b8d-6046-4cb3-8325-70d65e0573eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 360
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1870817802-172.17.0.14-1597482903287:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34205,DS-1fc0d6f3-532d-4253-adb1-055b66c9e3b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38535,DS-e4c21829-5e39-4614-8bf4-bce875d7bb04,DISK], DatanodeInfoWithStorage[127.0.0.1:38793,DS-2837d47b-9fec-4b52-8360-19f2c9480f78,DISK], DatanodeInfoWithStorage[127.0.0.1:46531,DS-1ee347eb-d744-4186-a99a-4fad0b7c58ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40781,DS-91cae154-809a-4fa2-9726-dfc5897a6f11,DISK], DatanodeInfoWithStorage[127.0.0.1:34580,DS-d6267e83-ed70-42b9-853d-1fc8fe77f8d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33733,DS-17127947-057e-4c70-9271-d46e276f337c,DISK], DatanodeInfoWithStorage[127.0.0.1:37260,DS-b1a35abf-129a-47f9-9e3a-7e57a7a56808,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1870817802-172.17.0.14-1597482903287:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34205,DS-1fc0d6f3-532d-4253-adb1-055b66c9e3b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38535,DS-e4c21829-5e39-4614-8bf4-bce875d7bb04,DISK], DatanodeInfoWithStorage[127.0.0.1:38793,DS-2837d47b-9fec-4b52-8360-19f2c9480f78,DISK], DatanodeInfoWithStorage[127.0.0.1:46531,DS-1ee347eb-d744-4186-a99a-4fad0b7c58ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40781,DS-91cae154-809a-4fa2-9726-dfc5897a6f11,DISK], DatanodeInfoWithStorage[127.0.0.1:34580,DS-d6267e83-ed70-42b9-853d-1fc8fe77f8d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33733,DS-17127947-057e-4c70-9271-d46e276f337c,DISK], DatanodeInfoWithStorage[127.0.0.1:37260,DS-b1a35abf-129a-47f9-9e3a-7e57a7a56808,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 360
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1151460527-172.17.0.14-1597483128933:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40994,DS-f8ea39d1-80e9-4104-8f6b-0257ba0e0a14,DISK], DatanodeInfoWithStorage[127.0.0.1:43247,DS-464fd3c8-4715-476b-82ed-c3466b639985,DISK], DatanodeInfoWithStorage[127.0.0.1:46632,DS-57c07ad6-bee9-43bb-a677-72cb5b92d8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42695,DS-15b6f7c0-a4e8-4ed1-b1e3-f2054a4b2389,DISK], DatanodeInfoWithStorage[127.0.0.1:35762,DS-62b4275f-f1a1-42dc-893b-0bead9a9778b,DISK], DatanodeInfoWithStorage[127.0.0.1:44642,DS-682c1c69-a5e8-47ca-bb2b-3bd5a22f27cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43323,DS-838666c3-c985-40fa-afb2-395988a21915,DISK], DatanodeInfoWithStorage[127.0.0.1:40089,DS-95e365f5-a5d4-4dd7-b14d-394cb4b83c86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1151460527-172.17.0.14-1597483128933:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40994,DS-f8ea39d1-80e9-4104-8f6b-0257ba0e0a14,DISK], DatanodeInfoWithStorage[127.0.0.1:43247,DS-464fd3c8-4715-476b-82ed-c3466b639985,DISK], DatanodeInfoWithStorage[127.0.0.1:46632,DS-57c07ad6-bee9-43bb-a677-72cb5b92d8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42695,DS-15b6f7c0-a4e8-4ed1-b1e3-f2054a4b2389,DISK], DatanodeInfoWithStorage[127.0.0.1:35762,DS-62b4275f-f1a1-42dc-893b-0bead9a9778b,DISK], DatanodeInfoWithStorage[127.0.0.1:44642,DS-682c1c69-a5e8-47ca-bb2b-3bd5a22f27cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43323,DS-838666c3-c985-40fa-afb2-395988a21915,DISK], DatanodeInfoWithStorage[127.0.0.1:40089,DS-95e365f5-a5d4-4dd7-b14d-394cb4b83c86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 360
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-64801058-172.17.0.14-1597483638646:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38139,DS-aee7eac9-d813-4e05-a1d5-012dc25371fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45548,DS-c7aaaa0f-b67d-44a1-b31f-982888d1ccc8,DISK], DatanodeInfoWithStorage[127.0.0.1:41191,DS-cc9e12a2-d733-4eb9-848d-72d0394e8f19,DISK], DatanodeInfoWithStorage[127.0.0.1:38068,DS-74265362-3df3-4189-8790-5ea12efa154e,DISK], DatanodeInfoWithStorage[127.0.0.1:34764,DS-c906fb88-9edd-4d20-8594-1bd15b5d4763,DISK], DatanodeInfoWithStorage[127.0.0.1:44327,DS-eff3e213-1a20-488d-877e-1b85c81bcb45,DISK], DatanodeInfoWithStorage[127.0.0.1:37711,DS-914edf77-16f1-43f7-8d87-45e25454f6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46777,DS-2908582b-ed10-46bc-8762-11a4c913019c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-64801058-172.17.0.14-1597483638646:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38139,DS-aee7eac9-d813-4e05-a1d5-012dc25371fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45548,DS-c7aaaa0f-b67d-44a1-b31f-982888d1ccc8,DISK], DatanodeInfoWithStorage[127.0.0.1:41191,DS-cc9e12a2-d733-4eb9-848d-72d0394e8f19,DISK], DatanodeInfoWithStorage[127.0.0.1:38068,DS-74265362-3df3-4189-8790-5ea12efa154e,DISK], DatanodeInfoWithStorage[127.0.0.1:34764,DS-c906fb88-9edd-4d20-8594-1bd15b5d4763,DISK], DatanodeInfoWithStorage[127.0.0.1:44327,DS-eff3e213-1a20-488d-877e-1b85c81bcb45,DISK], DatanodeInfoWithStorage[127.0.0.1:37711,DS-914edf77-16f1-43f7-8d87-45e25454f6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46777,DS-2908582b-ed10-46bc-8762-11a4c913019c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 360
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-31172145-172.17.0.14-1597483903415:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35674,DS-1fd88e7c-4a66-4daf-b811-d3131db69b00,DISK], DatanodeInfoWithStorage[127.0.0.1:44397,DS-e0b1e8fd-ea0c-46c3-96b8-18d87a0788ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40080,DS-c9952c16-6ed7-4c1a-8092-56c3368a7f67,DISK], DatanodeInfoWithStorage[127.0.0.1:41794,DS-24116ebc-487b-4a73-bbca-45ad0b9e8bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:43945,DS-200d441e-987b-41a8-8aaa-faff95a43b94,DISK], DatanodeInfoWithStorage[127.0.0.1:45281,DS-4ed06a93-08ed-4750-92cb-f0e81a5a9d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33554,DS-0c6d632b-5588-4292-b1b9-1f66ed9172f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45710,DS-f5a9796e-6ffa-4b21-9ae9-a0ffd74f0121,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-31172145-172.17.0.14-1597483903415:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35674,DS-1fd88e7c-4a66-4daf-b811-d3131db69b00,DISK], DatanodeInfoWithStorage[127.0.0.1:44397,DS-e0b1e8fd-ea0c-46c3-96b8-18d87a0788ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40080,DS-c9952c16-6ed7-4c1a-8092-56c3368a7f67,DISK], DatanodeInfoWithStorage[127.0.0.1:41794,DS-24116ebc-487b-4a73-bbca-45ad0b9e8bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:43945,DS-200d441e-987b-41a8-8aaa-faff95a43b94,DISK], DatanodeInfoWithStorage[127.0.0.1:45281,DS-4ed06a93-08ed-4750-92cb-f0e81a5a9d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33554,DS-0c6d632b-5588-4292-b1b9-1f66ed9172f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45710,DS-f5a9796e-6ffa-4b21-9ae9-a0ffd74f0121,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 360
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2061909496-172.17.0.14-1597484303242:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37142,DS-ad42b7d1-89b8-4584-b838-62438e39e9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42131,DS-d547cff4-3f0d-46b7-afaa-cd52850c9aac,DISK], DatanodeInfoWithStorage[127.0.0.1:41661,DS-86383b56-e855-48e7-9756-c41470cdea5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40424,DS-abba78f9-cb61-46ad-b4d6-d7263766a3f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45644,DS-3394428f-5dde-4784-8257-8f97e3ea8bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:45443,DS-a8629c6c-8905-4963-af8e-c07f6156f2be,DISK], DatanodeInfoWithStorage[127.0.0.1:32999,DS-4b6d0682-ea3b-4ff1-806b-2b06109932c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38297,DS-a29df5a6-a28c-41f7-b321-76a33128341d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2061909496-172.17.0.14-1597484303242:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37142,DS-ad42b7d1-89b8-4584-b838-62438e39e9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42131,DS-d547cff4-3f0d-46b7-afaa-cd52850c9aac,DISK], DatanodeInfoWithStorage[127.0.0.1:41661,DS-86383b56-e855-48e7-9756-c41470cdea5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40424,DS-abba78f9-cb61-46ad-b4d6-d7263766a3f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45644,DS-3394428f-5dde-4784-8257-8f97e3ea8bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:45443,DS-a8629c6c-8905-4963-af8e-c07f6156f2be,DISK], DatanodeInfoWithStorage[127.0.0.1:32999,DS-4b6d0682-ea3b-4ff1-806b-2b06109932c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38297,DS-a29df5a6-a28c-41f7-b321-76a33128341d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 360
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1251482638-172.17.0.14-1597484415875:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38043,DS-699903ab-2122-44f2-ad29-11753d0a2fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:40215,DS-6a3eba61-4e5f-49c5-b1ed-79d7f11359f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44809,DS-017e454b-5780-42d7-8783-899fca247e47,DISK], DatanodeInfoWithStorage[127.0.0.1:38664,DS-d47cd8bb-4ab3-4801-babe-254d86866ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:42038,DS-a2487f5e-fb08-4098-a493-96d36ff2185c,DISK], DatanodeInfoWithStorage[127.0.0.1:37303,DS-d7d7123b-8a29-47d0-b8ce-d89757db7b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:45892,DS-702a9601-f188-4f26-976e-70e32193c026,DISK], DatanodeInfoWithStorage[127.0.0.1:45184,DS-bd2fba06-4d70-4eac-b3dc-5bdd742bf907,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1251482638-172.17.0.14-1597484415875:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38043,DS-699903ab-2122-44f2-ad29-11753d0a2fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:40215,DS-6a3eba61-4e5f-49c5-b1ed-79d7f11359f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44809,DS-017e454b-5780-42d7-8783-899fca247e47,DISK], DatanodeInfoWithStorage[127.0.0.1:38664,DS-d47cd8bb-4ab3-4801-babe-254d86866ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:42038,DS-a2487f5e-fb08-4098-a493-96d36ff2185c,DISK], DatanodeInfoWithStorage[127.0.0.1:37303,DS-d7d7123b-8a29-47d0-b8ce-d89757db7b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:45892,DS-702a9601-f188-4f26-976e-70e32193c026,DISK], DatanodeInfoWithStorage[127.0.0.1:45184,DS-bd2fba06-4d70-4eac-b3dc-5bdd742bf907,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 360
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-351389444-172.17.0.14-1597484700831:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41821,DS-9d3f3050-dc00-43f1-9805-d2d16c9957cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44443,DS-cd8613b9-a4d3-4416-9470-8cd8318eceed,DISK], DatanodeInfoWithStorage[127.0.0.1:41560,DS-5123ad4f-c793-46a6-9202-b3d0fc564044,DISK], DatanodeInfoWithStorage[127.0.0.1:34247,DS-7fa3f4f6-ff7d-4663-aef7-36899e040f23,DISK], DatanodeInfoWithStorage[127.0.0.1:42011,DS-f44da593-da29-4136-b71b-62bf19364e7c,DISK], DatanodeInfoWithStorage[127.0.0.1:38294,DS-d0ceca0e-6433-4c5c-af59-4aabf855b2a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41274,DS-c79f5d6c-1857-4acb-b6b4-26bf6f3eb6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33145,DS-9f5a4324-df2a-4acb-81f5-da73d8928f50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-351389444-172.17.0.14-1597484700831:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41821,DS-9d3f3050-dc00-43f1-9805-d2d16c9957cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44443,DS-cd8613b9-a4d3-4416-9470-8cd8318eceed,DISK], DatanodeInfoWithStorage[127.0.0.1:41560,DS-5123ad4f-c793-46a6-9202-b3d0fc564044,DISK], DatanodeInfoWithStorage[127.0.0.1:34247,DS-7fa3f4f6-ff7d-4663-aef7-36899e040f23,DISK], DatanodeInfoWithStorage[127.0.0.1:42011,DS-f44da593-da29-4136-b71b-62bf19364e7c,DISK], DatanodeInfoWithStorage[127.0.0.1:38294,DS-d0ceca0e-6433-4c5c-af59-4aabf855b2a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41274,DS-c79f5d6c-1857-4acb-b6b4-26bf6f3eb6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33145,DS-9f5a4324-df2a-4acb-81f5-da73d8928f50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 360
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1528631000-172.17.0.14-1597485242675:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46617,DS-cdf37374-34a0-4535-9e83-fd9e93982487,DISK], DatanodeInfoWithStorage[127.0.0.1:34476,DS-37c8852f-0470-4a97-9ebe-77cb639e4e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:36750,DS-382d8698-4362-4e45-acd5-333e2ad2e8fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33597,DS-958443cd-ebb0-4578-b739-78b52ac73bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:37006,DS-0964aa7a-44ca-4f54-ae60-4dba25295056,DISK], DatanodeInfoWithStorage[127.0.0.1:35684,DS-1d7d8700-9d81-4bc9-90df-389d5cbd58a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40700,DS-ed441b2f-532c-4b32-8d98-d9faa750a681,DISK], DatanodeInfoWithStorage[127.0.0.1:39483,DS-81f8c954-18e5-4318-a002-b43063f75716,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1528631000-172.17.0.14-1597485242675:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46617,DS-cdf37374-34a0-4535-9e83-fd9e93982487,DISK], DatanodeInfoWithStorage[127.0.0.1:34476,DS-37c8852f-0470-4a97-9ebe-77cb639e4e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:36750,DS-382d8698-4362-4e45-acd5-333e2ad2e8fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33597,DS-958443cd-ebb0-4578-b739-78b52ac73bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:37006,DS-0964aa7a-44ca-4f54-ae60-4dba25295056,DISK], DatanodeInfoWithStorage[127.0.0.1:35684,DS-1d7d8700-9d81-4bc9-90df-389d5cbd58a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40700,DS-ed441b2f-532c-4b32-8d98-d9faa750a681,DISK], DatanodeInfoWithStorage[127.0.0.1:39483,DS-81f8c954-18e5-4318-a002-b43063f75716,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 360
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1843763611-172.17.0.14-1597485469080:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39980,DS-76bc2ac4-8037-4472-9fcd-227eb0b7dd90,DISK], DatanodeInfoWithStorage[127.0.0.1:43165,DS-08e13c71-6120-4507-b9ec-fb994b04ae2a,DISK], DatanodeInfoWithStorage[127.0.0.1:43354,DS-8bdbf1cf-d0ac-4183-a20f-c23953c776be,DISK], DatanodeInfoWithStorage[127.0.0.1:38050,DS-05efcfc8-1ef8-45ec-b6ce-ed963e2aa094,DISK], DatanodeInfoWithStorage[127.0.0.1:36718,DS-02e3ba67-3522-4e3e-ab33-2834505c5841,DISK], DatanodeInfoWithStorage[127.0.0.1:45792,DS-d78c2eef-0fe9-4ce2-87f5-49cef0d4eadb,DISK], DatanodeInfoWithStorage[127.0.0.1:44428,DS-4cbbb78c-e8d9-4031-9fe7-90b9caf76188,DISK], DatanodeInfoWithStorage[127.0.0.1:36793,DS-d1938ad6-183d-4f40-bd67-a8081f9a12ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1843763611-172.17.0.14-1597485469080:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39980,DS-76bc2ac4-8037-4472-9fcd-227eb0b7dd90,DISK], DatanodeInfoWithStorage[127.0.0.1:43165,DS-08e13c71-6120-4507-b9ec-fb994b04ae2a,DISK], DatanodeInfoWithStorage[127.0.0.1:43354,DS-8bdbf1cf-d0ac-4183-a20f-c23953c776be,DISK], DatanodeInfoWithStorage[127.0.0.1:38050,DS-05efcfc8-1ef8-45ec-b6ce-ed963e2aa094,DISK], DatanodeInfoWithStorage[127.0.0.1:36718,DS-02e3ba67-3522-4e3e-ab33-2834505c5841,DISK], DatanodeInfoWithStorage[127.0.0.1:45792,DS-d78c2eef-0fe9-4ce2-87f5-49cef0d4eadb,DISK], DatanodeInfoWithStorage[127.0.0.1:44428,DS-4cbbb78c-e8d9-4031-9fe7-90b9caf76188,DISK], DatanodeInfoWithStorage[127.0.0.1:36793,DS-d1938ad6-183d-4f40-bd67-a8081f9a12ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 360
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-210720072-172.17.0.14-1597485724691:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45546,DS-f6976c82-e413-475f-a745-d98c98e64055,DISK], DatanodeInfoWithStorage[127.0.0.1:41934,DS-e171ace6-fc9f-49d8-8850-ff53d5e5c9d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41750,DS-008ac6c2-3442-4fb5-b369-e7bc0bcc41cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40899,DS-6d9eaf85-7163-41df-9620-a6eee7a0931b,DISK], DatanodeInfoWithStorage[127.0.0.1:36949,DS-9b88e920-ac49-475c-a8c7-ff7ec92dd6af,DISK], DatanodeInfoWithStorage[127.0.0.1:37449,DS-af358245-31fb-4f24-a50f-3b9517c7fb14,DISK], DatanodeInfoWithStorage[127.0.0.1:33559,DS-d88071fa-9040-4c66-9678-c307a6fc3fda,DISK], DatanodeInfoWithStorage[127.0.0.1:42172,DS-61392026-8a55-4302-ad94-a99bca06b195,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-210720072-172.17.0.14-1597485724691:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45546,DS-f6976c82-e413-475f-a745-d98c98e64055,DISK], DatanodeInfoWithStorage[127.0.0.1:41934,DS-e171ace6-fc9f-49d8-8850-ff53d5e5c9d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41750,DS-008ac6c2-3442-4fb5-b369-e7bc0bcc41cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40899,DS-6d9eaf85-7163-41df-9620-a6eee7a0931b,DISK], DatanodeInfoWithStorage[127.0.0.1:36949,DS-9b88e920-ac49-475c-a8c7-ff7ec92dd6af,DISK], DatanodeInfoWithStorage[127.0.0.1:37449,DS-af358245-31fb-4f24-a50f-3b9517c7fb14,DISK], DatanodeInfoWithStorage[127.0.0.1:33559,DS-d88071fa-9040-4c66-9678-c307a6fc3fda,DISK], DatanodeInfoWithStorage[127.0.0.1:42172,DS-61392026-8a55-4302-ad94-a99bca06b195,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 360
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-199670253-172.17.0.14-1597485799427:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46015,DS-e1cb8021-d158-49b1-b2de-dd6c9cfc1306,DISK], DatanodeInfoWithStorage[127.0.0.1:44601,DS-f9d600e1-f105-432e-97f6-c18e414e13a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33750,DS-4a0e8b35-5223-4411-896a-ef96883fe5f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38751,DS-56c25da4-abf3-4812-a229-640c690a7809,DISK], DatanodeInfoWithStorage[127.0.0.1:46787,DS-82087de2-8f63-416f-83dc-984e7fabf7da,DISK], DatanodeInfoWithStorage[127.0.0.1:39568,DS-49f18934-3d6c-4aad-8311-11f5518116ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46043,DS-d8fc41f3-24e3-4919-9b12-e871726b456d,DISK], DatanodeInfoWithStorage[127.0.0.1:43703,DS-d7422b82-aa5d-47f5-97e0-8a9233659381,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-199670253-172.17.0.14-1597485799427:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46015,DS-e1cb8021-d158-49b1-b2de-dd6c9cfc1306,DISK], DatanodeInfoWithStorage[127.0.0.1:44601,DS-f9d600e1-f105-432e-97f6-c18e414e13a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33750,DS-4a0e8b35-5223-4411-896a-ef96883fe5f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38751,DS-56c25da4-abf3-4812-a229-640c690a7809,DISK], DatanodeInfoWithStorage[127.0.0.1:46787,DS-82087de2-8f63-416f-83dc-984e7fabf7da,DISK], DatanodeInfoWithStorage[127.0.0.1:39568,DS-49f18934-3d6c-4aad-8311-11f5518116ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46043,DS-d8fc41f3-24e3-4919-9b12-e871726b456d,DISK], DatanodeInfoWithStorage[127.0.0.1:43703,DS-d7422b82-aa5d-47f5-97e0-8a9233659381,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 360
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1263455776-172.17.0.14-1597486610370:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44609,DS-3fb0afda-48fc-4b58-8ec5-c20458f3ecbc,DISK], DatanodeInfoWithStorage[127.0.0.1:37532,DS-adfd8bf9-1b03-44d1-8625-2ea839bc96b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44128,DS-d51c77e7-e942-437c-9287-3eaed815eff0,DISK], DatanodeInfoWithStorage[127.0.0.1:33869,DS-6887a178-a0d1-4fb9-97cb-5d0cc7d6c859,DISK], DatanodeInfoWithStorage[127.0.0.1:46441,DS-d7b89bcd-47c7-43a5-8b57-fbbd8b528e42,DISK], DatanodeInfoWithStorage[127.0.0.1:39281,DS-e18eb681-6fc0-4550-a4fe-04c48387fe63,DISK], DatanodeInfoWithStorage[127.0.0.1:42225,DS-ea842e45-5b68-4f69-b311-95dece21ab3e,DISK], DatanodeInfoWithStorage[127.0.0.1:38504,DS-d6c0dc96-4997-450f-9a69-437734cb8fb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1263455776-172.17.0.14-1597486610370:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44609,DS-3fb0afda-48fc-4b58-8ec5-c20458f3ecbc,DISK], DatanodeInfoWithStorage[127.0.0.1:37532,DS-adfd8bf9-1b03-44d1-8625-2ea839bc96b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44128,DS-d51c77e7-e942-437c-9287-3eaed815eff0,DISK], DatanodeInfoWithStorage[127.0.0.1:33869,DS-6887a178-a0d1-4fb9-97cb-5d0cc7d6c859,DISK], DatanodeInfoWithStorage[127.0.0.1:46441,DS-d7b89bcd-47c7-43a5-8b57-fbbd8b528e42,DISK], DatanodeInfoWithStorage[127.0.0.1:39281,DS-e18eb681-6fc0-4550-a4fe-04c48387fe63,DISK], DatanodeInfoWithStorage[127.0.0.1:42225,DS-ea842e45-5b68-4f69-b311-95dece21ab3e,DISK], DatanodeInfoWithStorage[127.0.0.1:38504,DS-d6c0dc96-4997-450f-9a69-437734cb8fb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 360
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1165971475-172.17.0.14-1597486856350:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44253,DS-bbf40a4a-ac60-4150-9530-437d3b9cd810,DISK], DatanodeInfoWithStorage[127.0.0.1:43573,DS-5c29fb86-54db-40dd-bae0-039406ef3855,DISK], DatanodeInfoWithStorage[127.0.0.1:45691,DS-f922c81f-915f-4721-ab0e-ca6e43808b86,DISK], DatanodeInfoWithStorage[127.0.0.1:36544,DS-42fa7f44-c6bc-4315-a09b-4959c9605858,DISK], DatanodeInfoWithStorage[127.0.0.1:38105,DS-e92a42fc-5a02-4cc7-be83-50b9787219ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35570,DS-17151e85-8279-4448-948f-99a2a79cf1e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45542,DS-807d85b9-eb82-4057-bdf5-fe7937819da8,DISK], DatanodeInfoWithStorage[127.0.0.1:36853,DS-8c6ac783-c146-40d7-a9cb-ec851d2a58b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1165971475-172.17.0.14-1597486856350:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44253,DS-bbf40a4a-ac60-4150-9530-437d3b9cd810,DISK], DatanodeInfoWithStorage[127.0.0.1:43573,DS-5c29fb86-54db-40dd-bae0-039406ef3855,DISK], DatanodeInfoWithStorage[127.0.0.1:45691,DS-f922c81f-915f-4721-ab0e-ca6e43808b86,DISK], DatanodeInfoWithStorage[127.0.0.1:36544,DS-42fa7f44-c6bc-4315-a09b-4959c9605858,DISK], DatanodeInfoWithStorage[127.0.0.1:38105,DS-e92a42fc-5a02-4cc7-be83-50b9787219ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35570,DS-17151e85-8279-4448-948f-99a2a79cf1e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45542,DS-807d85b9-eb82-4057-bdf5-fe7937819da8,DISK], DatanodeInfoWithStorage[127.0.0.1:36853,DS-8c6ac783-c146-40d7-a9cb-ec851d2a58b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 360
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1234069237-172.17.0.14-1597487057239:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37450,DS-ac98dff4-3fae-4a93-a5b3-b039b400cc66,DISK], DatanodeInfoWithStorage[127.0.0.1:41311,DS-22f5925d-a839-4b60-89b9-fc4ff5974fae,DISK], DatanodeInfoWithStorage[127.0.0.1:38012,DS-6132f3fc-44c6-4b14-be6c-b1214e2eac54,DISK], DatanodeInfoWithStorage[127.0.0.1:46520,DS-0a880c9d-955e-461d-abda-aea7ecb22529,DISK], DatanodeInfoWithStorage[127.0.0.1:39527,DS-3c04cc96-00c8-4b2e-89ce-b32081fa2ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:39268,DS-cfbc5ad3-bb59-4fc7-9a1f-15d345b98214,DISK], DatanodeInfoWithStorage[127.0.0.1:44267,DS-1dd6ff40-f487-42f8-9823-957b9d9c4f83,DISK], DatanodeInfoWithStorage[127.0.0.1:43574,DS-73965a1f-e546-4b9b-a50b-91a9d592c640,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1234069237-172.17.0.14-1597487057239:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37450,DS-ac98dff4-3fae-4a93-a5b3-b039b400cc66,DISK], DatanodeInfoWithStorage[127.0.0.1:41311,DS-22f5925d-a839-4b60-89b9-fc4ff5974fae,DISK], DatanodeInfoWithStorage[127.0.0.1:38012,DS-6132f3fc-44c6-4b14-be6c-b1214e2eac54,DISK], DatanodeInfoWithStorage[127.0.0.1:46520,DS-0a880c9d-955e-461d-abda-aea7ecb22529,DISK], DatanodeInfoWithStorage[127.0.0.1:39527,DS-3c04cc96-00c8-4b2e-89ce-b32081fa2ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:39268,DS-cfbc5ad3-bb59-4fc7-9a1f-15d345b98214,DISK], DatanodeInfoWithStorage[127.0.0.1:44267,DS-1dd6ff40-f487-42f8-9823-957b9d9c4f83,DISK], DatanodeInfoWithStorage[127.0.0.1:43574,DS-73965a1f-e546-4b9b-a50b-91a9d592c640,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 360
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-814220725-172.17.0.14-1597487243554:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43197,DS-dc8764dd-45f9-4e30-83d9-bc5639cfa72a,DISK], DatanodeInfoWithStorage[127.0.0.1:35102,DS-ef16d7ef-7ed4-4751-9788-d2665df5fb18,DISK], DatanodeInfoWithStorage[127.0.0.1:41830,DS-f94ce6ac-f542-4036-b0d5-f93f6a701ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:44713,DS-8eeb0897-55f9-47ac-9879-5afcbccaff5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36508,DS-26c5161c-b5c7-4217-aefd-a60c3dd2be08,DISK], DatanodeInfoWithStorage[127.0.0.1:45792,DS-82f65ae3-ea8d-47fb-9ac0-a92b44d17ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:41131,DS-bc1060ff-8ad6-4763-9774-b89ef43e5dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:46574,DS-709b6b58-6d7e-44d5-bad3-c614d1b0b4af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-814220725-172.17.0.14-1597487243554:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43197,DS-dc8764dd-45f9-4e30-83d9-bc5639cfa72a,DISK], DatanodeInfoWithStorage[127.0.0.1:35102,DS-ef16d7ef-7ed4-4751-9788-d2665df5fb18,DISK], DatanodeInfoWithStorage[127.0.0.1:41830,DS-f94ce6ac-f542-4036-b0d5-f93f6a701ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:44713,DS-8eeb0897-55f9-47ac-9879-5afcbccaff5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36508,DS-26c5161c-b5c7-4217-aefd-a60c3dd2be08,DISK], DatanodeInfoWithStorage[127.0.0.1:45792,DS-82f65ae3-ea8d-47fb-9ac0-a92b44d17ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:41131,DS-bc1060ff-8ad6-4763-9774-b89ef43e5dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:46574,DS-709b6b58-6d7e-44d5-bad3-c614d1b0b4af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 360
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1630133540-172.17.0.14-1597487439148:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39780,DS-34d4bc47-fd79-42c1-9928-f07673ec66f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38022,DS-50b6aaec-8720-429a-a7d3-46ab326e708f,DISK], DatanodeInfoWithStorage[127.0.0.1:43624,DS-d1daef2b-8ffb-4e10-a7ca-147c79791d40,DISK], DatanodeInfoWithStorage[127.0.0.1:39911,DS-7caef6b4-6b68-46ab-b77d-58378484e1d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33423,DS-aff7fc7e-a9de-41ef-91b6-6bf2a10da5df,DISK], DatanodeInfoWithStorage[127.0.0.1:38980,DS-8188133b-9c39-4874-ae72-224c5325e4e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46846,DS-248e3ad2-e813-42bc-8775-ad48196f7625,DISK], DatanodeInfoWithStorage[127.0.0.1:35964,DS-3e2a0405-6aaa-46a2-9105-d5ed38cadd8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1630133540-172.17.0.14-1597487439148:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39780,DS-34d4bc47-fd79-42c1-9928-f07673ec66f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38022,DS-50b6aaec-8720-429a-a7d3-46ab326e708f,DISK], DatanodeInfoWithStorage[127.0.0.1:43624,DS-d1daef2b-8ffb-4e10-a7ca-147c79791d40,DISK], DatanodeInfoWithStorage[127.0.0.1:39911,DS-7caef6b4-6b68-46ab-b77d-58378484e1d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33423,DS-aff7fc7e-a9de-41ef-91b6-6bf2a10da5df,DISK], DatanodeInfoWithStorage[127.0.0.1:38980,DS-8188133b-9c39-4874-ae72-224c5325e4e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46846,DS-248e3ad2-e813-42bc-8775-ad48196f7625,DISK], DatanodeInfoWithStorage[127.0.0.1:35964,DS-3e2a0405-6aaa-46a2-9105-d5ed38cadd8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 360
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-346461551-172.17.0.14-1597488209557:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35270,DS-21aa0534-806e-4e5d-9978-30ba524dc597,DISK], DatanodeInfoWithStorage[127.0.0.1:45723,DS-7fdf2dc9-6317-454a-a976-6ea38809a822,DISK], DatanodeInfoWithStorage[127.0.0.1:33384,DS-a80c133a-5d06-40eb-b436-9eafe2b7e26d,DISK], DatanodeInfoWithStorage[127.0.0.1:40383,DS-618fa676-2af4-4e8d-a81c-8c71d8136bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:44919,DS-0b09e5fd-830c-4f7d-92c3-0d5613f8cb76,DISK], DatanodeInfoWithStorage[127.0.0.1:40616,DS-d0652902-4821-4775-afe6-edbd705d9fce,DISK], DatanodeInfoWithStorage[127.0.0.1:37907,DS-fafce1c3-455c-47bf-9d17-ab106f618c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:36647,DS-e3b97732-57b6-4f43-b8b9-a43b1dfa3519,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-346461551-172.17.0.14-1597488209557:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35270,DS-21aa0534-806e-4e5d-9978-30ba524dc597,DISK], DatanodeInfoWithStorage[127.0.0.1:45723,DS-7fdf2dc9-6317-454a-a976-6ea38809a822,DISK], DatanodeInfoWithStorage[127.0.0.1:33384,DS-a80c133a-5d06-40eb-b436-9eafe2b7e26d,DISK], DatanodeInfoWithStorage[127.0.0.1:40383,DS-618fa676-2af4-4e8d-a81c-8c71d8136bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:44919,DS-0b09e5fd-830c-4f7d-92c3-0d5613f8cb76,DISK], DatanodeInfoWithStorage[127.0.0.1:40616,DS-d0652902-4821-4775-afe6-edbd705d9fce,DISK], DatanodeInfoWithStorage[127.0.0.1:37907,DS-fafce1c3-455c-47bf-9d17-ab106f618c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:36647,DS-e3b97732-57b6-4f43-b8b9-a43b1dfa3519,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5650
