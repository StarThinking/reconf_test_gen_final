reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 32768
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 32768
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1379049708-172.17.0.15-1597712143160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42972,DS-2c7ecf00-299e-4c16-84c0-da9e027268ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45335,DS-cab60b31-055b-4a21-bcc1-a43bcc69698b,DISK], DatanodeInfoWithStorage[127.0.0.1:44110,DS-29cb442f-8bb9-4900-b205-2e5118245fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:42495,DS-60193405-cef0-466e-aa11-f0dc94ed46f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41737,DS-85d9fddc-aeb2-4622-a379-17090aa0b0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33258,DS-36dec66e-14e4-4ef4-b6dc-5ef0a89cf1ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34318,DS-9c80c115-bfe1-4529-a162-e67adcbb9f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:40729,DS-0e666db3-c320-4797-9b81-de7c1dd2b976,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1379049708-172.17.0.15-1597712143160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42972,DS-2c7ecf00-299e-4c16-84c0-da9e027268ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45335,DS-cab60b31-055b-4a21-bcc1-a43bcc69698b,DISK], DatanodeInfoWithStorage[127.0.0.1:44110,DS-29cb442f-8bb9-4900-b205-2e5118245fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:42495,DS-60193405-cef0-466e-aa11-f0dc94ed46f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41737,DS-85d9fddc-aeb2-4622-a379-17090aa0b0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33258,DS-36dec66e-14e4-4ef4-b6dc-5ef0a89cf1ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34318,DS-9c80c115-bfe1-4529-a162-e67adcbb9f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:40729,DS-0e666db3-c320-4797-9b81-de7c1dd2b976,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 32768
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-852892307-172.17.0.15-1597713482144:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40015,DS-70976b48-f4f5-45c7-97dc-a83765c4e2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37672,DS-a49296bd-b112-4909-ae42-50fe1af1e95e,DISK], DatanodeInfoWithStorage[127.0.0.1:44647,DS-3e698c49-47fb-4ea2-a10a-40d9097e1d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35141,DS-b8a54b97-83e4-4e50-9a02-2a9cb0ccf8c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33090,DS-49939a02-c3ae-4b81-a6c6-8d75ff35fad9,DISK], DatanodeInfoWithStorage[127.0.0.1:43672,DS-2da30064-a646-4037-b60f-b611686595e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36386,DS-9e66e561-9568-470e-895e-bb22b1e8480e,DISK], DatanodeInfoWithStorage[127.0.0.1:43210,DS-fc5f75e8-bdb8-4e3b-9654-348e0b27bac3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-852892307-172.17.0.15-1597713482144:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40015,DS-70976b48-f4f5-45c7-97dc-a83765c4e2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37672,DS-a49296bd-b112-4909-ae42-50fe1af1e95e,DISK], DatanodeInfoWithStorage[127.0.0.1:44647,DS-3e698c49-47fb-4ea2-a10a-40d9097e1d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35141,DS-b8a54b97-83e4-4e50-9a02-2a9cb0ccf8c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33090,DS-49939a02-c3ae-4b81-a6c6-8d75ff35fad9,DISK], DatanodeInfoWithStorage[127.0.0.1:43672,DS-2da30064-a646-4037-b60f-b611686595e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36386,DS-9e66e561-9568-470e-895e-bb22b1e8480e,DISK], DatanodeInfoWithStorage[127.0.0.1:43210,DS-fc5f75e8-bdb8-4e3b-9654-348e0b27bac3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 32768
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1316165178-172.17.0.15-1597713523424:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40886,DS-95e61889-72b0-407a-8425-485660c6a0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42721,DS-eec5a8d0-0059-464b-8514-e6547111f78b,DISK], DatanodeInfoWithStorage[127.0.0.1:39598,DS-fe5016ea-9f8e-4219-8199-8e3c7e478b80,DISK], DatanodeInfoWithStorage[127.0.0.1:46146,DS-8032de27-5870-4f66-96aa-27ab9b7038f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38492,DS-f9cca9ac-7d1b-4d90-b4ed-c72b47ebaeda,DISK], DatanodeInfoWithStorage[127.0.0.1:41681,DS-8b8787ca-54fa-46f0-88c4-7439396a55a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41205,DS-ee84280d-158e-436f-9fdb-b20cb5603dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:40037,DS-2211b43a-2de5-4472-8e6e-5be7dd4dbcdf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1316165178-172.17.0.15-1597713523424:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40886,DS-95e61889-72b0-407a-8425-485660c6a0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42721,DS-eec5a8d0-0059-464b-8514-e6547111f78b,DISK], DatanodeInfoWithStorage[127.0.0.1:39598,DS-fe5016ea-9f8e-4219-8199-8e3c7e478b80,DISK], DatanodeInfoWithStorage[127.0.0.1:46146,DS-8032de27-5870-4f66-96aa-27ab9b7038f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38492,DS-f9cca9ac-7d1b-4d90-b4ed-c72b47ebaeda,DISK], DatanodeInfoWithStorage[127.0.0.1:41681,DS-8b8787ca-54fa-46f0-88c4-7439396a55a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41205,DS-ee84280d-158e-436f-9fdb-b20cb5603dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:40037,DS-2211b43a-2de5-4472-8e6e-5be7dd4dbcdf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 32768
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2108253832-172.17.0.15-1597714113593:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44292,DS-4fbb1598-6b71-4352-828e-e02c3b48c9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41844,DS-6b4543e9-4d9a-4e84-a1cd-5b692d6ed1fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40170,DS-306edd90-311c-4cad-ae39-b99a20394bed,DISK], DatanodeInfoWithStorage[127.0.0.1:41430,DS-fb8fabf6-81a0-45b7-983d-231970f7abe2,DISK], DatanodeInfoWithStorage[127.0.0.1:42982,DS-8f2c7eb6-7d69-4b80-9eab-9ec89b64122c,DISK], DatanodeInfoWithStorage[127.0.0.1:36880,DS-f7968322-07cf-4aec-8dbd-b084cc389442,DISK], DatanodeInfoWithStorage[127.0.0.1:41221,DS-3a2cba87-5c89-47b7-91b0-519e0550ff3e,DISK], DatanodeInfoWithStorage[127.0.0.1:38808,DS-cefacea3-04d4-4f7c-a319-7af869b21b30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2108253832-172.17.0.15-1597714113593:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44292,DS-4fbb1598-6b71-4352-828e-e02c3b48c9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41844,DS-6b4543e9-4d9a-4e84-a1cd-5b692d6ed1fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40170,DS-306edd90-311c-4cad-ae39-b99a20394bed,DISK], DatanodeInfoWithStorage[127.0.0.1:41430,DS-fb8fabf6-81a0-45b7-983d-231970f7abe2,DISK], DatanodeInfoWithStorage[127.0.0.1:42982,DS-8f2c7eb6-7d69-4b80-9eab-9ec89b64122c,DISK], DatanodeInfoWithStorage[127.0.0.1:36880,DS-f7968322-07cf-4aec-8dbd-b084cc389442,DISK], DatanodeInfoWithStorage[127.0.0.1:41221,DS-3a2cba87-5c89-47b7-91b0-519e0550ff3e,DISK], DatanodeInfoWithStorage[127.0.0.1:38808,DS-cefacea3-04d4-4f7c-a319-7af869b21b30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 32768
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-417411836-172.17.0.15-1597715791871:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35118,DS-9b5729d4-e5df-4f48-b32e-f61c9418d844,DISK], DatanodeInfoWithStorage[127.0.0.1:38573,DS-f18d43b7-0c6d-48fd-a431-706b433e6ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:40028,DS-2893b730-7a35-4cb0-9065-6dadad710667,DISK], DatanodeInfoWithStorage[127.0.0.1:45416,DS-4e1b6c92-52a7-443d-babd-80017ea5fe4a,DISK], DatanodeInfoWithStorage[127.0.0.1:41554,DS-495a864e-1250-41d4-be43-13b76f67d6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38998,DS-92cc094a-5160-4cec-9a77-7546a14db34e,DISK], DatanodeInfoWithStorage[127.0.0.1:37842,DS-216b3657-d8a9-4920-8051-a0e4567d23ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42591,DS-1f03080b-dfe6-4a4a-aad4-a29689c4edaa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-417411836-172.17.0.15-1597715791871:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35118,DS-9b5729d4-e5df-4f48-b32e-f61c9418d844,DISK], DatanodeInfoWithStorage[127.0.0.1:38573,DS-f18d43b7-0c6d-48fd-a431-706b433e6ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:40028,DS-2893b730-7a35-4cb0-9065-6dadad710667,DISK], DatanodeInfoWithStorage[127.0.0.1:45416,DS-4e1b6c92-52a7-443d-babd-80017ea5fe4a,DISK], DatanodeInfoWithStorage[127.0.0.1:41554,DS-495a864e-1250-41d4-be43-13b76f67d6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38998,DS-92cc094a-5160-4cec-9a77-7546a14db34e,DISK], DatanodeInfoWithStorage[127.0.0.1:37842,DS-216b3657-d8a9-4920-8051-a0e4567d23ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42591,DS-1f03080b-dfe6-4a4a-aad4-a29689c4edaa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 32768
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-673916536-172.17.0.15-1597716110433:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43831,DS-25a4415a-49df-47c8-b167-2e647a3631c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43741,DS-409a28bd-0323-49d9-b386-fc806b01ffec,DISK], DatanodeInfoWithStorage[127.0.0.1:34670,DS-c35cc2d8-830a-4ef0-8df4-245c25954f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40955,DS-b8741818-b6d3-4e43-b674-8ecfa5a8f9e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44609,DS-5d1d264b-4b99-4705-9bed-e2a396c44aef,DISK], DatanodeInfoWithStorage[127.0.0.1:42728,DS-b9f3e4a6-39e9-4607-9c66-d5bd963c0212,DISK], DatanodeInfoWithStorage[127.0.0.1:39916,DS-4f75838f-a190-4bfb-815d-e6834c043cba,DISK], DatanodeInfoWithStorage[127.0.0.1:45700,DS-5d1bbe7c-323e-42b9-b0a4-7148288cba0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-673916536-172.17.0.15-1597716110433:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43831,DS-25a4415a-49df-47c8-b167-2e647a3631c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43741,DS-409a28bd-0323-49d9-b386-fc806b01ffec,DISK], DatanodeInfoWithStorage[127.0.0.1:34670,DS-c35cc2d8-830a-4ef0-8df4-245c25954f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40955,DS-b8741818-b6d3-4e43-b674-8ecfa5a8f9e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44609,DS-5d1d264b-4b99-4705-9bed-e2a396c44aef,DISK], DatanodeInfoWithStorage[127.0.0.1:42728,DS-b9f3e4a6-39e9-4607-9c66-d5bd963c0212,DISK], DatanodeInfoWithStorage[127.0.0.1:39916,DS-4f75838f-a190-4bfb-815d-e6834c043cba,DISK], DatanodeInfoWithStorage[127.0.0.1:45700,DS-5d1bbe7c-323e-42b9-b0a4-7148288cba0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 32768
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-714262240-172.17.0.15-1597716747562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46348,DS-f0f87ae4-24c9-4687-b11a-2cb3dee0144e,DISK], DatanodeInfoWithStorage[127.0.0.1:33421,DS-074bfa86-c26b-473a-bdb5-4e420f85d483,DISK], DatanodeInfoWithStorage[127.0.0.1:45397,DS-10532530-543a-4de7-845e-243298dff977,DISK], DatanodeInfoWithStorage[127.0.0.1:40444,DS-4d61ed7f-f7f4-4025-a3a1-4f3da0bde69f,DISK], DatanodeInfoWithStorage[127.0.0.1:45742,DS-19f2f313-93f4-4632-a9ff-0697e060c280,DISK], DatanodeInfoWithStorage[127.0.0.1:45043,DS-5fa2125b-848a-4174-b701-bd9f239ec04a,DISK], DatanodeInfoWithStorage[127.0.0.1:35120,DS-f54cc9a7-cc0c-4eff-92e4-5bed35cc803a,DISK], DatanodeInfoWithStorage[127.0.0.1:45416,DS-b90988f7-9227-4c44-947f-4deeefad120c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-714262240-172.17.0.15-1597716747562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46348,DS-f0f87ae4-24c9-4687-b11a-2cb3dee0144e,DISK], DatanodeInfoWithStorage[127.0.0.1:33421,DS-074bfa86-c26b-473a-bdb5-4e420f85d483,DISK], DatanodeInfoWithStorage[127.0.0.1:45397,DS-10532530-543a-4de7-845e-243298dff977,DISK], DatanodeInfoWithStorage[127.0.0.1:40444,DS-4d61ed7f-f7f4-4025-a3a1-4f3da0bde69f,DISK], DatanodeInfoWithStorage[127.0.0.1:45742,DS-19f2f313-93f4-4632-a9ff-0697e060c280,DISK], DatanodeInfoWithStorage[127.0.0.1:45043,DS-5fa2125b-848a-4174-b701-bd9f239ec04a,DISK], DatanodeInfoWithStorage[127.0.0.1:35120,DS-f54cc9a7-cc0c-4eff-92e4-5bed35cc803a,DISK], DatanodeInfoWithStorage[127.0.0.1:45416,DS-b90988f7-9227-4c44-947f-4deeefad120c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 32768
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-455725309-172.17.0.15-1597717329963:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37150,DS-12fd6778-08ff-46db-9f40-196c36700175,DISK], DatanodeInfoWithStorage[127.0.0.1:40699,DS-bc11452d-fb16-45a7-ab57-d08144762259,DISK], DatanodeInfoWithStorage[127.0.0.1:45732,DS-f2dc74ac-9b6a-42f1-ad3d-a6485dcbd6e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45234,DS-7cfd2c4e-c45e-4be9-9b2b-32494b531b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:41912,DS-dc424cee-6edb-4d37-afde-b52835590951,DISK], DatanodeInfoWithStorage[127.0.0.1:38889,DS-7100c7f1-90a9-4038-854b-a07278b04382,DISK], DatanodeInfoWithStorage[127.0.0.1:35654,DS-45871f47-d070-41dc-9cc7-82f2062c673a,DISK], DatanodeInfoWithStorage[127.0.0.1:40572,DS-db7116e1-89ba-459d-8a78-7e5b50d2680e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-455725309-172.17.0.15-1597717329963:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37150,DS-12fd6778-08ff-46db-9f40-196c36700175,DISK], DatanodeInfoWithStorage[127.0.0.1:40699,DS-bc11452d-fb16-45a7-ab57-d08144762259,DISK], DatanodeInfoWithStorage[127.0.0.1:45732,DS-f2dc74ac-9b6a-42f1-ad3d-a6485dcbd6e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45234,DS-7cfd2c4e-c45e-4be9-9b2b-32494b531b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:41912,DS-dc424cee-6edb-4d37-afde-b52835590951,DISK], DatanodeInfoWithStorage[127.0.0.1:38889,DS-7100c7f1-90a9-4038-854b-a07278b04382,DISK], DatanodeInfoWithStorage[127.0.0.1:35654,DS-45871f47-d070-41dc-9cc7-82f2062c673a,DISK], DatanodeInfoWithStorage[127.0.0.1:40572,DS-db7116e1-89ba-459d-8a78-7e5b50d2680e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 32768
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1251786567-172.17.0.15-1597717668906:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46871,DS-3b680752-de3b-4ef4-8b36-c4902cc91ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:41704,DS-e62a0cca-4ddd-473e-b327-e26ca8f96f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45029,DS-68ed798d-3a98-4975-be5a-75f5aace2e86,DISK], DatanodeInfoWithStorage[127.0.0.1:36040,DS-0a932f22-9599-4ff1-b589-d74c9cfe2ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:44074,DS-7394d61d-5ea1-4097-83c1-9e83c24ed1bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36119,DS-767da173-881d-4ac2-9cc4-dbd77c35de4b,DISK], DatanodeInfoWithStorage[127.0.0.1:39616,DS-72a95abd-f53a-4c44-80e7-501eae91d469,DISK], DatanodeInfoWithStorage[127.0.0.1:46824,DS-f4f91338-7285-4c46-9ddb-5068e87e033d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1251786567-172.17.0.15-1597717668906:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46871,DS-3b680752-de3b-4ef4-8b36-c4902cc91ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:41704,DS-e62a0cca-4ddd-473e-b327-e26ca8f96f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45029,DS-68ed798d-3a98-4975-be5a-75f5aace2e86,DISK], DatanodeInfoWithStorage[127.0.0.1:36040,DS-0a932f22-9599-4ff1-b589-d74c9cfe2ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:44074,DS-7394d61d-5ea1-4097-83c1-9e83c24ed1bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36119,DS-767da173-881d-4ac2-9cc4-dbd77c35de4b,DISK], DatanodeInfoWithStorage[127.0.0.1:39616,DS-72a95abd-f53a-4c44-80e7-501eae91d469,DISK], DatanodeInfoWithStorage[127.0.0.1:46824,DS-f4f91338-7285-4c46-9ddb-5068e87e033d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 32768
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2069087192-172.17.0.15-1597718059361:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33365,DS-9a36bf84-6e84-4b7a-97cf-eb6809aec7aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45013,DS-61d08037-495a-46ef-bd58-abe5bea5c048,DISK], DatanodeInfoWithStorage[127.0.0.1:35318,DS-56a6ee6d-4153-4215-a1da-f275d3cbdde8,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-da3c6624-c1f0-43c0-b216-b0e0c1308b89,DISK], DatanodeInfoWithStorage[127.0.0.1:38071,DS-cce5715a-634b-42d1-83dc-6dde9d6192b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42700,DS-5ba5916e-4e6c-43a5-995a-23cee2daa64b,DISK], DatanodeInfoWithStorage[127.0.0.1:40584,DS-b7bd64cd-7024-457f-89fd-3af16b7d8e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:36554,DS-9aa1cc7a-c745-4a60-8d26-f5286f26f53e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2069087192-172.17.0.15-1597718059361:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33365,DS-9a36bf84-6e84-4b7a-97cf-eb6809aec7aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45013,DS-61d08037-495a-46ef-bd58-abe5bea5c048,DISK], DatanodeInfoWithStorage[127.0.0.1:35318,DS-56a6ee6d-4153-4215-a1da-f275d3cbdde8,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-da3c6624-c1f0-43c0-b216-b0e0c1308b89,DISK], DatanodeInfoWithStorage[127.0.0.1:38071,DS-cce5715a-634b-42d1-83dc-6dde9d6192b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42700,DS-5ba5916e-4e6c-43a5-995a-23cee2daa64b,DISK], DatanodeInfoWithStorage[127.0.0.1:40584,DS-b7bd64cd-7024-457f-89fd-3af16b7d8e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:36554,DS-9aa1cc7a-c745-4a60-8d26-f5286f26f53e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 7285
