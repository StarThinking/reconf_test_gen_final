reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1118917549-172.17.0.7-1597470918696:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38656,DS-f120a461-6d11-4bfb-aa6f-85d4de5fcf43,DISK], DatanodeInfoWithStorage[127.0.0.1:33600,DS-e35a7fb3-f94c-4ce2-9c7b-8c473e91f430,DISK], DatanodeInfoWithStorage[127.0.0.1:42972,DS-00fb1f91-5787-450b-b170-a9f9cc85afca,DISK], DatanodeInfoWithStorage[127.0.0.1:46230,DS-1154260d-6c6f-434c-a644-f22471c76e44,DISK], DatanodeInfoWithStorage[127.0.0.1:45954,DS-40b18437-6be0-425c-b8bc-207339d542e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39244,DS-67798ced-181d-4905-a91e-1852744b4de6,DISK], DatanodeInfoWithStorage[127.0.0.1:39771,DS-205b4b2b-156b-462b-a843-40c46b5276ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40564,DS-8fb6ffd6-47d6-4ee6-abd7-acae3653277e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1118917549-172.17.0.7-1597470918696:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38656,DS-f120a461-6d11-4bfb-aa6f-85d4de5fcf43,DISK], DatanodeInfoWithStorage[127.0.0.1:33600,DS-e35a7fb3-f94c-4ce2-9c7b-8c473e91f430,DISK], DatanodeInfoWithStorage[127.0.0.1:42972,DS-00fb1f91-5787-450b-b170-a9f9cc85afca,DISK], DatanodeInfoWithStorage[127.0.0.1:46230,DS-1154260d-6c6f-434c-a644-f22471c76e44,DISK], DatanodeInfoWithStorage[127.0.0.1:45954,DS-40b18437-6be0-425c-b8bc-207339d542e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39244,DS-67798ced-181d-4905-a91e-1852744b4de6,DISK], DatanodeInfoWithStorage[127.0.0.1:39771,DS-205b4b2b-156b-462b-a843-40c46b5276ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40564,DS-8fb6ffd6-47d6-4ee6-abd7-acae3653277e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1740376339-172.17.0.7-1597471505448:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40314,DS-57b02c1f-ce17-45a9-b9c0-bff6a8f41490,DISK], DatanodeInfoWithStorage[127.0.0.1:44618,DS-bced378d-1857-4f71-a28d-19773275ba93,DISK], DatanodeInfoWithStorage[127.0.0.1:33703,DS-d60f2b19-d076-481f-ae58-d142a10810f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42825,DS-66ac4cf3-d448-4370-be43-6f559ce78c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:35835,DS-d463ac4d-67f3-4648-b788-1cd0653fbb6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39574,DS-6986e1d5-4389-4a41-92dd-d842ab63f61c,DISK], DatanodeInfoWithStorage[127.0.0.1:45479,DS-4b37fed0-a681-49f0-81a0-f6416fe15f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36650,DS-ac6dcb91-07a5-4b2b-af55-ade2b67ff8fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1740376339-172.17.0.7-1597471505448:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40314,DS-57b02c1f-ce17-45a9-b9c0-bff6a8f41490,DISK], DatanodeInfoWithStorage[127.0.0.1:44618,DS-bced378d-1857-4f71-a28d-19773275ba93,DISK], DatanodeInfoWithStorage[127.0.0.1:33703,DS-d60f2b19-d076-481f-ae58-d142a10810f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42825,DS-66ac4cf3-d448-4370-be43-6f559ce78c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:35835,DS-d463ac4d-67f3-4648-b788-1cd0653fbb6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39574,DS-6986e1d5-4389-4a41-92dd-d842ab63f61c,DISK], DatanodeInfoWithStorage[127.0.0.1:45479,DS-4b37fed0-a681-49f0-81a0-f6416fe15f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36650,DS-ac6dcb91-07a5-4b2b-af55-ade2b67ff8fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-189580635-172.17.0.7-1597471852445:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44888,DS-e3425534-f647-428b-b6c4-9e94e0a3c72f,DISK], DatanodeInfoWithStorage[127.0.0.1:39561,DS-d84c777f-e9a4-44d9-a503-2e5a0b6193c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42121,DS-7eb9dbe9-328f-4c41-9da3-216d4abeb568,DISK], DatanodeInfoWithStorage[127.0.0.1:35038,DS-d663af5d-ad24-45a9-9cf6-18b4cffbdacb,DISK], DatanodeInfoWithStorage[127.0.0.1:38778,DS-80df0ae6-5089-45d3-8bcc-0b17d8792158,DISK], DatanodeInfoWithStorage[127.0.0.1:39108,DS-cde0f62e-443f-4c58-a139-d71f5119c3b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41747,DS-3f46cdc8-4162-45c1-92b3-23242d071edd,DISK], DatanodeInfoWithStorage[127.0.0.1:41616,DS-5f6b3927-e2f4-44c5-94e9-ad16f653aed3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-189580635-172.17.0.7-1597471852445:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44888,DS-e3425534-f647-428b-b6c4-9e94e0a3c72f,DISK], DatanodeInfoWithStorage[127.0.0.1:39561,DS-d84c777f-e9a4-44d9-a503-2e5a0b6193c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42121,DS-7eb9dbe9-328f-4c41-9da3-216d4abeb568,DISK], DatanodeInfoWithStorage[127.0.0.1:35038,DS-d663af5d-ad24-45a9-9cf6-18b4cffbdacb,DISK], DatanodeInfoWithStorage[127.0.0.1:38778,DS-80df0ae6-5089-45d3-8bcc-0b17d8792158,DISK], DatanodeInfoWithStorage[127.0.0.1:39108,DS-cde0f62e-443f-4c58-a139-d71f5119c3b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41747,DS-3f46cdc8-4162-45c1-92b3-23242d071edd,DISK], DatanodeInfoWithStorage[127.0.0.1:41616,DS-5f6b3927-e2f4-44c5-94e9-ad16f653aed3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-565852315-172.17.0.7-1597472720205:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37643,DS-3fbb8967-42d5-44f1-a183-a8f738b85c19,DISK], DatanodeInfoWithStorage[127.0.0.1:33135,DS-59972823-3668-4d3c-b717-42a80fb5bfba,DISK], DatanodeInfoWithStorage[127.0.0.1:41937,DS-e3bcb54e-6cc3-4ffa-b17a-679d4d0cb633,DISK], DatanodeInfoWithStorage[127.0.0.1:39665,DS-9e40e4b3-dfcc-4343-b3da-8fd894e782df,DISK], DatanodeInfoWithStorage[127.0.0.1:43126,DS-bc2d9a5c-a1f2-4022-81d9-a89512f7195e,DISK], DatanodeInfoWithStorage[127.0.0.1:42628,DS-22e878d8-69af-4aea-92ee-bfa00a1b41dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44944,DS-85a9463e-7638-4688-a70d-e2a85a1dfa31,DISK], DatanodeInfoWithStorage[127.0.0.1:45450,DS-9d993550-eed6-44f2-9f42-c5fc7aff89df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-565852315-172.17.0.7-1597472720205:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37643,DS-3fbb8967-42d5-44f1-a183-a8f738b85c19,DISK], DatanodeInfoWithStorage[127.0.0.1:33135,DS-59972823-3668-4d3c-b717-42a80fb5bfba,DISK], DatanodeInfoWithStorage[127.0.0.1:41937,DS-e3bcb54e-6cc3-4ffa-b17a-679d4d0cb633,DISK], DatanodeInfoWithStorage[127.0.0.1:39665,DS-9e40e4b3-dfcc-4343-b3da-8fd894e782df,DISK], DatanodeInfoWithStorage[127.0.0.1:43126,DS-bc2d9a5c-a1f2-4022-81d9-a89512f7195e,DISK], DatanodeInfoWithStorage[127.0.0.1:42628,DS-22e878d8-69af-4aea-92ee-bfa00a1b41dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44944,DS-85a9463e-7638-4688-a70d-e2a85a1dfa31,DISK], DatanodeInfoWithStorage[127.0.0.1:45450,DS-9d993550-eed6-44f2-9f42-c5fc7aff89df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-969423429-172.17.0.7-1597473049167:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36316,DS-934481e9-44b1-4620-8b03-e73ffb3df3f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37101,DS-e096b2a8-4608-4a69-942f-92236c9ff0e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-c4c4a553-77e2-46c4-a0da-09461f496b08,DISK], DatanodeInfoWithStorage[127.0.0.1:35387,DS-91bcb371-3832-42ee-aaf1-f8f91251fec6,DISK], DatanodeInfoWithStorage[127.0.0.1:36738,DS-af38482b-84f1-42f9-8e77-3abf2799c711,DISK], DatanodeInfoWithStorage[127.0.0.1:46725,DS-8b175bc5-f327-447e-9e3e-85ec7f4a8816,DISK], DatanodeInfoWithStorage[127.0.0.1:39014,DS-b0f3176b-8fc2-4660-8a78-1fc7a7eb126f,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-437c6296-6773-4d02-b129-533187fca37f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-969423429-172.17.0.7-1597473049167:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36316,DS-934481e9-44b1-4620-8b03-e73ffb3df3f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37101,DS-e096b2a8-4608-4a69-942f-92236c9ff0e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-c4c4a553-77e2-46c4-a0da-09461f496b08,DISK], DatanodeInfoWithStorage[127.0.0.1:35387,DS-91bcb371-3832-42ee-aaf1-f8f91251fec6,DISK], DatanodeInfoWithStorage[127.0.0.1:36738,DS-af38482b-84f1-42f9-8e77-3abf2799c711,DISK], DatanodeInfoWithStorage[127.0.0.1:46725,DS-8b175bc5-f327-447e-9e3e-85ec7f4a8816,DISK], DatanodeInfoWithStorage[127.0.0.1:39014,DS-b0f3176b-8fc2-4660-8a78-1fc7a7eb126f,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-437c6296-6773-4d02-b129-533187fca37f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1361389545-172.17.0.7-1597473291666:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38199,DS-779c94fb-f158-4ac7-b000-c88ed148c5c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45061,DS-76b7a214-8336-48ab-b7dd-f2cf76184501,DISK], DatanodeInfoWithStorage[127.0.0.1:39524,DS-c98ea199-7d4f-4571-9f13-5ea7e9ec004f,DISK], DatanodeInfoWithStorage[127.0.0.1:39421,DS-24d55512-5a07-41d8-85ed-90f862daedca,DISK], DatanodeInfoWithStorage[127.0.0.1:39565,DS-2dc38b51-1bd1-41a1-9cf1-e6e1490d9387,DISK], DatanodeInfoWithStorage[127.0.0.1:36828,DS-4da52014-e784-46f9-8c41-f4ba87f59057,DISK], DatanodeInfoWithStorage[127.0.0.1:34177,DS-4b644296-5342-4b6e-bccc-17269d6f3a96,DISK], DatanodeInfoWithStorage[127.0.0.1:38566,DS-469ca9fb-0c51-4347-99f3-539a739f31ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1361389545-172.17.0.7-1597473291666:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38199,DS-779c94fb-f158-4ac7-b000-c88ed148c5c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45061,DS-76b7a214-8336-48ab-b7dd-f2cf76184501,DISK], DatanodeInfoWithStorage[127.0.0.1:39524,DS-c98ea199-7d4f-4571-9f13-5ea7e9ec004f,DISK], DatanodeInfoWithStorage[127.0.0.1:39421,DS-24d55512-5a07-41d8-85ed-90f862daedca,DISK], DatanodeInfoWithStorage[127.0.0.1:39565,DS-2dc38b51-1bd1-41a1-9cf1-e6e1490d9387,DISK], DatanodeInfoWithStorage[127.0.0.1:36828,DS-4da52014-e784-46f9-8c41-f4ba87f59057,DISK], DatanodeInfoWithStorage[127.0.0.1:34177,DS-4b644296-5342-4b6e-bccc-17269d6f3a96,DISK], DatanodeInfoWithStorage[127.0.0.1:38566,DS-469ca9fb-0c51-4347-99f3-539a739f31ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1419190595-172.17.0.7-1597473371678:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35767,DS-6800721a-c348-4a7b-be0d-4677fb68916a,DISK], DatanodeInfoWithStorage[127.0.0.1:37898,DS-34997623-5760-4670-80ed-727e47110f34,DISK], DatanodeInfoWithStorage[127.0.0.1:44992,DS-f5b92fb4-895b-445a-8411-506763f66d40,DISK], DatanodeInfoWithStorage[127.0.0.1:38955,DS-adb0e948-c965-4416-814b-2e26b1c5a1c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43531,DS-c2b6f310-be0c-4efc-b534-225be22f8a94,DISK], DatanodeInfoWithStorage[127.0.0.1:43348,DS-70e3b3a1-b6bc-4082-8c64-9cddf9103a39,DISK], DatanodeInfoWithStorage[127.0.0.1:45231,DS-79baed7e-3ba6-449a-9e70-0ff485f1424b,DISK], DatanodeInfoWithStorage[127.0.0.1:41502,DS-9f913106-0a13-4e0a-af07-20ef210bd839,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1419190595-172.17.0.7-1597473371678:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35767,DS-6800721a-c348-4a7b-be0d-4677fb68916a,DISK], DatanodeInfoWithStorage[127.0.0.1:37898,DS-34997623-5760-4670-80ed-727e47110f34,DISK], DatanodeInfoWithStorage[127.0.0.1:44992,DS-f5b92fb4-895b-445a-8411-506763f66d40,DISK], DatanodeInfoWithStorage[127.0.0.1:38955,DS-adb0e948-c965-4416-814b-2e26b1c5a1c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43531,DS-c2b6f310-be0c-4efc-b534-225be22f8a94,DISK], DatanodeInfoWithStorage[127.0.0.1:43348,DS-70e3b3a1-b6bc-4082-8c64-9cddf9103a39,DISK], DatanodeInfoWithStorage[127.0.0.1:45231,DS-79baed7e-3ba6-449a-9e70-0ff485f1424b,DISK], DatanodeInfoWithStorage[127.0.0.1:41502,DS-9f913106-0a13-4e0a-af07-20ef210bd839,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1635080327-172.17.0.7-1597473470437:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46380,DS-140c7e50-e511-486c-80f9-c6a60cb13acf,DISK], DatanodeInfoWithStorage[127.0.0.1:43445,DS-3fecf9b6-0a9d-46c9-9e29-cd01f12986a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35380,DS-3f986767-4bb6-473a-b5b6-ee5f4080cb6e,DISK], DatanodeInfoWithStorage[127.0.0.1:46615,DS-bd759033-f016-4774-8b8f-066bc748fc95,DISK], DatanodeInfoWithStorage[127.0.0.1:36383,DS-637162b5-9142-4e1f-95c0-2de782c9ef64,DISK], DatanodeInfoWithStorage[127.0.0.1:43980,DS-a30b0aec-baca-444a-93b1-be1c58f3eb23,DISK], DatanodeInfoWithStorage[127.0.0.1:43530,DS-06c675f3-f677-4e6c-9efe-9602d6b8af3b,DISK], DatanodeInfoWithStorage[127.0.0.1:33328,DS-7f57a84c-c1a6-4c86-87aa-6ec8af07c538,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1635080327-172.17.0.7-1597473470437:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46380,DS-140c7e50-e511-486c-80f9-c6a60cb13acf,DISK], DatanodeInfoWithStorage[127.0.0.1:43445,DS-3fecf9b6-0a9d-46c9-9e29-cd01f12986a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35380,DS-3f986767-4bb6-473a-b5b6-ee5f4080cb6e,DISK], DatanodeInfoWithStorage[127.0.0.1:46615,DS-bd759033-f016-4774-8b8f-066bc748fc95,DISK], DatanodeInfoWithStorage[127.0.0.1:36383,DS-637162b5-9142-4e1f-95c0-2de782c9ef64,DISK], DatanodeInfoWithStorage[127.0.0.1:43980,DS-a30b0aec-baca-444a-93b1-be1c58f3eb23,DISK], DatanodeInfoWithStorage[127.0.0.1:43530,DS-06c675f3-f677-4e6c-9efe-9602d6b8af3b,DISK], DatanodeInfoWithStorage[127.0.0.1:33328,DS-7f57a84c-c1a6-4c86-87aa-6ec8af07c538,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-385273762-172.17.0.7-1597473795785:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36749,DS-c826bacf-4d53-407f-b681-3760bd686b19,DISK], DatanodeInfoWithStorage[127.0.0.1:43746,DS-b50b542c-6da6-41de-9890-85e0ff8e361b,DISK], DatanodeInfoWithStorage[127.0.0.1:34968,DS-a64e43a5-95dd-44c3-8203-a2a9547413c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37657,DS-bb7b20ef-4f51-4f46-84b8-a0c397160a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:42929,DS-2e67a03a-9ed4-47d0-a65b-2d6f2e52ec2a,DISK], DatanodeInfoWithStorage[127.0.0.1:44775,DS-8de541eb-c914-48c9-801c-ae1450bd4aac,DISK], DatanodeInfoWithStorage[127.0.0.1:40512,DS-fe51efbf-cd55-4bf1-9d53-e539bcc1deb6,DISK], DatanodeInfoWithStorage[127.0.0.1:42004,DS-267504f4-7b88-4429-88b6-abec36960950,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-385273762-172.17.0.7-1597473795785:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36749,DS-c826bacf-4d53-407f-b681-3760bd686b19,DISK], DatanodeInfoWithStorage[127.0.0.1:43746,DS-b50b542c-6da6-41de-9890-85e0ff8e361b,DISK], DatanodeInfoWithStorage[127.0.0.1:34968,DS-a64e43a5-95dd-44c3-8203-a2a9547413c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37657,DS-bb7b20ef-4f51-4f46-84b8-a0c397160a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:42929,DS-2e67a03a-9ed4-47d0-a65b-2d6f2e52ec2a,DISK], DatanodeInfoWithStorage[127.0.0.1:44775,DS-8de541eb-c914-48c9-801c-ae1450bd4aac,DISK], DatanodeInfoWithStorage[127.0.0.1:40512,DS-fe51efbf-cd55-4bf1-9d53-e539bcc1deb6,DISK], DatanodeInfoWithStorage[127.0.0.1:42004,DS-267504f4-7b88-4429-88b6-abec36960950,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2070255461-172.17.0.7-1597473867437:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34179,DS-1f1ce5d2-3ea7-45ca-b633-d249b7e867b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41113,DS-9dd3e89f-79b1-412a-bd5a-98f09b63406f,DISK], DatanodeInfoWithStorage[127.0.0.1:35209,DS-8ad2d12f-59bd-4fd9-81c6-e171925a965c,DISK], DatanodeInfoWithStorage[127.0.0.1:39749,DS-ec4fea5d-576e-439a-b801-43b1d6943389,DISK], DatanodeInfoWithStorage[127.0.0.1:42859,DS-4672d36b-55ef-4d66-85f9-0c69ab8dcee4,DISK], DatanodeInfoWithStorage[127.0.0.1:40062,DS-af86bce0-ff3f-48b8-8e98-a588c38e3cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:37683,DS-778cb902-2d72-461e-ae6d-7d04e03f136a,DISK], DatanodeInfoWithStorage[127.0.0.1:43545,DS-d347c64c-87b7-4479-b492-027a83693c23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2070255461-172.17.0.7-1597473867437:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34179,DS-1f1ce5d2-3ea7-45ca-b633-d249b7e867b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41113,DS-9dd3e89f-79b1-412a-bd5a-98f09b63406f,DISK], DatanodeInfoWithStorage[127.0.0.1:35209,DS-8ad2d12f-59bd-4fd9-81c6-e171925a965c,DISK], DatanodeInfoWithStorage[127.0.0.1:39749,DS-ec4fea5d-576e-439a-b801-43b1d6943389,DISK], DatanodeInfoWithStorage[127.0.0.1:42859,DS-4672d36b-55ef-4d66-85f9-0c69ab8dcee4,DISK], DatanodeInfoWithStorage[127.0.0.1:40062,DS-af86bce0-ff3f-48b8-8e98-a588c38e3cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:37683,DS-778cb902-2d72-461e-ae6d-7d04e03f136a,DISK], DatanodeInfoWithStorage[127.0.0.1:43545,DS-d347c64c-87b7-4479-b492-027a83693c23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1759629986-172.17.0.7-1597474111405:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34412,DS-8c2d1f0e-5e19-4536-8d22-256b433d36b6,DISK], DatanodeInfoWithStorage[127.0.0.1:32950,DS-c7b88a1d-3e06-4100-a62d-289a3106104a,DISK], DatanodeInfoWithStorage[127.0.0.1:43019,DS-6115513c-4596-45f4-a53f-85c15f6774e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34155,DS-cefeb112-a06c-4298-b7b8-23f24a46d20b,DISK], DatanodeInfoWithStorage[127.0.0.1:40007,DS-110aa021-7aea-419d-b04a-d0323085d0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45396,DS-509e2eec-a3b7-48ee-b597-8756f85bd7a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36728,DS-5b91b8f3-12ae-4569-a7c5-4da057ca1ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:44546,DS-7648c240-c930-4762-a547-24b24a3091a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1759629986-172.17.0.7-1597474111405:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34412,DS-8c2d1f0e-5e19-4536-8d22-256b433d36b6,DISK], DatanodeInfoWithStorage[127.0.0.1:32950,DS-c7b88a1d-3e06-4100-a62d-289a3106104a,DISK], DatanodeInfoWithStorage[127.0.0.1:43019,DS-6115513c-4596-45f4-a53f-85c15f6774e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34155,DS-cefeb112-a06c-4298-b7b8-23f24a46d20b,DISK], DatanodeInfoWithStorage[127.0.0.1:40007,DS-110aa021-7aea-419d-b04a-d0323085d0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45396,DS-509e2eec-a3b7-48ee-b597-8756f85bd7a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36728,DS-5b91b8f3-12ae-4569-a7c5-4da057ca1ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:44546,DS-7648c240-c930-4762-a547-24b24a3091a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1182023720-172.17.0.7-1597474589170:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38133,DS-cc365e41-3c60-40ac-9eb9-66b30fe607d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40291,DS-5b842a8c-2016-46ea-9a08-c226502f94e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42195,DS-548aced1-eeac-4334-953a-c08f3abb5bba,DISK], DatanodeInfoWithStorage[127.0.0.1:44998,DS-cc450da6-ed60-438b-9683-dc512ca85cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:34302,DS-b39f6fcb-c210-45cb-842a-ab2ff5e1f5ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37779,DS-7d34ffc1-9544-4a45-a1c2-68bdc2ec1c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36353,DS-18d19a84-5bcf-4abb-b10f-adc156a5b3bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40091,DS-f03c0cb2-ab33-4be6-a158-c878bd2d4d46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1182023720-172.17.0.7-1597474589170:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38133,DS-cc365e41-3c60-40ac-9eb9-66b30fe607d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40291,DS-5b842a8c-2016-46ea-9a08-c226502f94e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42195,DS-548aced1-eeac-4334-953a-c08f3abb5bba,DISK], DatanodeInfoWithStorage[127.0.0.1:44998,DS-cc450da6-ed60-438b-9683-dc512ca85cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:34302,DS-b39f6fcb-c210-45cb-842a-ab2ff5e1f5ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37779,DS-7d34ffc1-9544-4a45-a1c2-68bdc2ec1c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36353,DS-18d19a84-5bcf-4abb-b10f-adc156a5b3bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40091,DS-f03c0cb2-ab33-4be6-a158-c878bd2d4d46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1158061037-172.17.0.7-1597474842050:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38673,DS-2d848c51-0e66-4ff2-ac5c-46947142aec1,DISK], DatanodeInfoWithStorage[127.0.0.1:38327,DS-1f6f6d5f-507e-4512-a4b4-c6386d3155d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34786,DS-08dc9b34-cbfb-400a-9c69-1541dba6f219,DISK], DatanodeInfoWithStorage[127.0.0.1:38928,DS-60ff708e-93cd-4603-9352-15d79d2d36ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43619,DS-648fd533-649a-4245-83c4-c1e8f65e9e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:46095,DS-a20a2e7a-6d70-4edf-8ddb-686968c366a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38267,DS-4b2d2fe5-65ee-442f-be2a-8d4233870a61,DISK], DatanodeInfoWithStorage[127.0.0.1:43610,DS-08ff562f-9d92-402c-8360-caa26954c63f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1158061037-172.17.0.7-1597474842050:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38673,DS-2d848c51-0e66-4ff2-ac5c-46947142aec1,DISK], DatanodeInfoWithStorage[127.0.0.1:38327,DS-1f6f6d5f-507e-4512-a4b4-c6386d3155d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34786,DS-08dc9b34-cbfb-400a-9c69-1541dba6f219,DISK], DatanodeInfoWithStorage[127.0.0.1:38928,DS-60ff708e-93cd-4603-9352-15d79d2d36ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43619,DS-648fd533-649a-4245-83c4-c1e8f65e9e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:46095,DS-a20a2e7a-6d70-4edf-8ddb-686968c366a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38267,DS-4b2d2fe5-65ee-442f-be2a-8d4233870a61,DISK], DatanodeInfoWithStorage[127.0.0.1:43610,DS-08ff562f-9d92-402c-8360-caa26954c63f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-100343744-172.17.0.7-1597475342412:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36061,DS-98b04e13-acab-4fb0-83ac-8d1d569a8d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:40317,DS-437e0369-733d-4e63-8737-151311f0f28e,DISK], DatanodeInfoWithStorage[127.0.0.1:43675,DS-bee9085f-57e3-475c-9861-ecc3fca05b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:32984,DS-f2f9ae1e-4d8b-43af-b8db-25f7cb76c78a,DISK], DatanodeInfoWithStorage[127.0.0.1:34775,DS-e092e3ac-d911-45fd-a030-3ad79b78ac43,DISK], DatanodeInfoWithStorage[127.0.0.1:42935,DS-230b22e0-b356-4530-a47a-82fdb0a3fceb,DISK], DatanodeInfoWithStorage[127.0.0.1:40189,DS-fa13a221-325f-4627-8c47-70a9603134ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41328,DS-8c01a8fa-5dd4-4125-8b9b-b4b446134cf8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-100343744-172.17.0.7-1597475342412:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36061,DS-98b04e13-acab-4fb0-83ac-8d1d569a8d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:40317,DS-437e0369-733d-4e63-8737-151311f0f28e,DISK], DatanodeInfoWithStorage[127.0.0.1:43675,DS-bee9085f-57e3-475c-9861-ecc3fca05b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:32984,DS-f2f9ae1e-4d8b-43af-b8db-25f7cb76c78a,DISK], DatanodeInfoWithStorage[127.0.0.1:34775,DS-e092e3ac-d911-45fd-a030-3ad79b78ac43,DISK], DatanodeInfoWithStorage[127.0.0.1:42935,DS-230b22e0-b356-4530-a47a-82fdb0a3fceb,DISK], DatanodeInfoWithStorage[127.0.0.1:40189,DS-fa13a221-325f-4627-8c47-70a9603134ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41328,DS-8c01a8fa-5dd4-4125-8b9b-b4b446134cf8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-373941618-172.17.0.7-1597475992464:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37364,DS-052fa099-f9c3-4167-b1b3-84fbb62d74dc,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-a2392af6-3c05-4a09-8f57-8da065e645cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39209,DS-c2fc1f3f-2376-46d1-bf09-5887ed333719,DISK], DatanodeInfoWithStorage[127.0.0.1:35931,DS-c33ba8b2-2ac8-40f3-bfc7-23b703f25db6,DISK], DatanodeInfoWithStorage[127.0.0.1:44913,DS-dd2e61ae-9ffa-466f-90ae-926a0eb573d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40015,DS-0a5675db-8bd0-4c0e-aa6c-2b1cf5738a79,DISK], DatanodeInfoWithStorage[127.0.0.1:42649,DS-b700a416-f0ee-4e47-85de-a4be6bf6d8cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46372,DS-a15ccb73-a781-47a4-a973-392f0d85825b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-373941618-172.17.0.7-1597475992464:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37364,DS-052fa099-f9c3-4167-b1b3-84fbb62d74dc,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-a2392af6-3c05-4a09-8f57-8da065e645cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39209,DS-c2fc1f3f-2376-46d1-bf09-5887ed333719,DISK], DatanodeInfoWithStorage[127.0.0.1:35931,DS-c33ba8b2-2ac8-40f3-bfc7-23b703f25db6,DISK], DatanodeInfoWithStorage[127.0.0.1:44913,DS-dd2e61ae-9ffa-466f-90ae-926a0eb573d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40015,DS-0a5675db-8bd0-4c0e-aa6c-2b1cf5738a79,DISK], DatanodeInfoWithStorage[127.0.0.1:42649,DS-b700a416-f0ee-4e47-85de-a4be6bf6d8cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46372,DS-a15ccb73-a781-47a4-a973-392f0d85825b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-953609494-172.17.0.7-1597476386579:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39203,DS-43c047d1-7163-4de2-b793-bfaf7958fe5c,DISK], DatanodeInfoWithStorage[127.0.0.1:34054,DS-00a02f1a-04d7-41ea-923b-fd9d4c7cf203,DISK], DatanodeInfoWithStorage[127.0.0.1:37716,DS-756d5670-7770-4cc8-8b38-8dd8ae9c8e41,DISK], DatanodeInfoWithStorage[127.0.0.1:34748,DS-02bbcadf-9285-4580-adf2-d547cc442bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:38975,DS-7bf65422-f294-4d16-abb2-6967ad83ba84,DISK], DatanodeInfoWithStorage[127.0.0.1:37070,DS-662f2c4a-5779-4979-9edd-ff0f22971735,DISK], DatanodeInfoWithStorage[127.0.0.1:44161,DS-0bbf3237-732c-4e92-a4bd-3bf8558eac7e,DISK], DatanodeInfoWithStorage[127.0.0.1:34695,DS-4a333ba3-3039-48f8-9414-e7cd7e31a2e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-953609494-172.17.0.7-1597476386579:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39203,DS-43c047d1-7163-4de2-b793-bfaf7958fe5c,DISK], DatanodeInfoWithStorage[127.0.0.1:34054,DS-00a02f1a-04d7-41ea-923b-fd9d4c7cf203,DISK], DatanodeInfoWithStorage[127.0.0.1:37716,DS-756d5670-7770-4cc8-8b38-8dd8ae9c8e41,DISK], DatanodeInfoWithStorage[127.0.0.1:34748,DS-02bbcadf-9285-4580-adf2-d547cc442bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:38975,DS-7bf65422-f294-4d16-abb2-6967ad83ba84,DISK], DatanodeInfoWithStorage[127.0.0.1:37070,DS-662f2c4a-5779-4979-9edd-ff0f22971735,DISK], DatanodeInfoWithStorage[127.0.0.1:44161,DS-0bbf3237-732c-4e92-a4bd-3bf8558eac7e,DISK], DatanodeInfoWithStorage[127.0.0.1:34695,DS-4a333ba3-3039-48f8-9414-e7cd7e31a2e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-440162245-172.17.0.7-1597476426733:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34388,DS-e747dd68-81ae-491f-9ac7-295dcb825ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:38481,DS-81a9e754-0703-4da6-9ea5-c86c53d37ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:33489,DS-0847a301-7fa6-4703-a243-235b207252ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44965,DS-879055e4-367e-4b23-8daf-48640d68765c,DISK], DatanodeInfoWithStorage[127.0.0.1:42925,DS-1d0ee6fa-ea30-4f63-80e5-1097e91fb98c,DISK], DatanodeInfoWithStorage[127.0.0.1:46321,DS-a7365c13-efb5-4a0b-845f-5aca2bda51e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44087,DS-ab8fdb89-04ef-4883-bd09-54dcc9d9dccd,DISK], DatanodeInfoWithStorage[127.0.0.1:42558,DS-d943a4ae-a9d8-4986-b0a8-2ecb45dbe6ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-440162245-172.17.0.7-1597476426733:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34388,DS-e747dd68-81ae-491f-9ac7-295dcb825ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:38481,DS-81a9e754-0703-4da6-9ea5-c86c53d37ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:33489,DS-0847a301-7fa6-4703-a243-235b207252ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44965,DS-879055e4-367e-4b23-8daf-48640d68765c,DISK], DatanodeInfoWithStorage[127.0.0.1:42925,DS-1d0ee6fa-ea30-4f63-80e5-1097e91fb98c,DISK], DatanodeInfoWithStorage[127.0.0.1:46321,DS-a7365c13-efb5-4a0b-845f-5aca2bda51e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44087,DS-ab8fdb89-04ef-4883-bd09-54dcc9d9dccd,DISK], DatanodeInfoWithStorage[127.0.0.1:42558,DS-d943a4ae-a9d8-4986-b0a8-2ecb45dbe6ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 6296
