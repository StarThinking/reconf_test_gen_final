reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-956723000-172.17.0.15-1597313696786:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37594,DS-8bb60430-1dd0-4b5f-abc1-ebb2af5d6f31,DISK], DatanodeInfoWithStorage[127.0.0.1:41604,DS-a35b46ff-9904-4005-9fd5-99197a2f3351,DISK], DatanodeInfoWithStorage[127.0.0.1:35740,DS-405a99d7-0b80-4077-9aec-d6b41941ed14,DISK], DatanodeInfoWithStorage[127.0.0.1:34581,DS-1e6f300e-6972-4182-a6d8-5f44e26c2d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:45352,DS-e1f6f041-961c-432f-98ad-6ce00111a62b,DISK], DatanodeInfoWithStorage[127.0.0.1:33291,DS-1e9a9b7f-8af9-4b21-a65d-9c1f48aaadab,DISK], DatanodeInfoWithStorage[127.0.0.1:37500,DS-2eca5497-7645-4cb4-a788-e3577b1b5092,DISK], DatanodeInfoWithStorage[127.0.0.1:32858,DS-06ee81ec-4489-48cb-b902-b53a10fdb71c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-956723000-172.17.0.15-1597313696786:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37594,DS-8bb60430-1dd0-4b5f-abc1-ebb2af5d6f31,DISK], DatanodeInfoWithStorage[127.0.0.1:41604,DS-a35b46ff-9904-4005-9fd5-99197a2f3351,DISK], DatanodeInfoWithStorage[127.0.0.1:35740,DS-405a99d7-0b80-4077-9aec-d6b41941ed14,DISK], DatanodeInfoWithStorage[127.0.0.1:34581,DS-1e6f300e-6972-4182-a6d8-5f44e26c2d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:45352,DS-e1f6f041-961c-432f-98ad-6ce00111a62b,DISK], DatanodeInfoWithStorage[127.0.0.1:33291,DS-1e9a9b7f-8af9-4b21-a65d-9c1f48aaadab,DISK], DatanodeInfoWithStorage[127.0.0.1:37500,DS-2eca5497-7645-4cb4-a788-e3577b1b5092,DISK], DatanodeInfoWithStorage[127.0.0.1:32858,DS-06ee81ec-4489-48cb-b902-b53a10fdb71c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1294687784-172.17.0.15-1597314017400:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44511,DS-cc9d7fcb-7405-49ab-a17c-04beaf2d9e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:46252,DS-16890225-3a81-4b12-8004-7e0c8aaf1d88,DISK], DatanodeInfoWithStorage[127.0.0.1:45790,DS-652b4425-3254-4a68-959e-49ff80c912a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39851,DS-2d1bb4fb-4f7f-4c15-a957-24a8625b3341,DISK], DatanodeInfoWithStorage[127.0.0.1:43126,DS-01ecfd21-90c5-4a4b-bb9f-a23d6095271b,DISK], DatanodeInfoWithStorage[127.0.0.1:36507,DS-bf27be32-c8b5-4440-a9f0-6330abf128c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43151,DS-d9a654cd-aeb3-4cf9-ba7d-5de25a25e7e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33037,DS-1517b9bc-a05d-4676-9e2c-09f95322e1e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1294687784-172.17.0.15-1597314017400:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44511,DS-cc9d7fcb-7405-49ab-a17c-04beaf2d9e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:46252,DS-16890225-3a81-4b12-8004-7e0c8aaf1d88,DISK], DatanodeInfoWithStorage[127.0.0.1:45790,DS-652b4425-3254-4a68-959e-49ff80c912a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39851,DS-2d1bb4fb-4f7f-4c15-a957-24a8625b3341,DISK], DatanodeInfoWithStorage[127.0.0.1:43126,DS-01ecfd21-90c5-4a4b-bb9f-a23d6095271b,DISK], DatanodeInfoWithStorage[127.0.0.1:36507,DS-bf27be32-c8b5-4440-a9f0-6330abf128c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43151,DS-d9a654cd-aeb3-4cf9-ba7d-5de25a25e7e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33037,DS-1517b9bc-a05d-4676-9e2c-09f95322e1e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-58268906-172.17.0.15-1597314465736:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42820,DS-06370e82-7e9b-4888-8c58-fd1aa5fe7a62,DISK], DatanodeInfoWithStorage[127.0.0.1:40637,DS-6b398cf3-2f3a-4653-a42c-7694449a1af1,DISK], DatanodeInfoWithStorage[127.0.0.1:40947,DS-001d223d-7570-499c-84d5-87e2c610c9a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35972,DS-c20a4cb8-b30c-41d7-b967-e7fed12d70b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42418,DS-d266b91c-bc65-482f-9c6f-bf7e01843a07,DISK], DatanodeInfoWithStorage[127.0.0.1:43496,DS-866fd5cc-daa1-4414-a765-74d1a1a1ab32,DISK], DatanodeInfoWithStorage[127.0.0.1:41269,DS-c4f2e80b-bc30-4549-9907-e89aaf8d295c,DISK], DatanodeInfoWithStorage[127.0.0.1:41839,DS-10c0c9c5-6109-48ce-9aba-ddac6a17f4aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-58268906-172.17.0.15-1597314465736:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42820,DS-06370e82-7e9b-4888-8c58-fd1aa5fe7a62,DISK], DatanodeInfoWithStorage[127.0.0.1:40637,DS-6b398cf3-2f3a-4653-a42c-7694449a1af1,DISK], DatanodeInfoWithStorage[127.0.0.1:40947,DS-001d223d-7570-499c-84d5-87e2c610c9a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35972,DS-c20a4cb8-b30c-41d7-b967-e7fed12d70b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42418,DS-d266b91c-bc65-482f-9c6f-bf7e01843a07,DISK], DatanodeInfoWithStorage[127.0.0.1:43496,DS-866fd5cc-daa1-4414-a765-74d1a1a1ab32,DISK], DatanodeInfoWithStorage[127.0.0.1:41269,DS-c4f2e80b-bc30-4549-9907-e89aaf8d295c,DISK], DatanodeInfoWithStorage[127.0.0.1:41839,DS-10c0c9c5-6109-48ce-9aba-ddac6a17f4aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1510149287-172.17.0.15-1597314658877:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41123,DS-7a99d4a3-ab71-428e-baa2-20819d292979,DISK], DatanodeInfoWithStorage[127.0.0.1:45413,DS-e8bb5ab5-2599-4e70-9bca-1ef6e2fa4291,DISK], DatanodeInfoWithStorage[127.0.0.1:43417,DS-c34fd34e-ad36-4906-b62c-3db452884d51,DISK], DatanodeInfoWithStorage[127.0.0.1:36860,DS-bbf6712b-1415-4b05-a390-939803728e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35303,DS-509b1124-1046-4de4-8ad2-c02783e8d315,DISK], DatanodeInfoWithStorage[127.0.0.1:45924,DS-9536ca1c-b1eb-454b-a537-d80445392366,DISK], DatanodeInfoWithStorage[127.0.0.1:34871,DS-0051f59c-37a8-4398-8697-c918b1f78930,DISK], DatanodeInfoWithStorage[127.0.0.1:33179,DS-3d0a5d8f-aae4-4b32-a43e-6ae5e9b1b414,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1510149287-172.17.0.15-1597314658877:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41123,DS-7a99d4a3-ab71-428e-baa2-20819d292979,DISK], DatanodeInfoWithStorage[127.0.0.1:45413,DS-e8bb5ab5-2599-4e70-9bca-1ef6e2fa4291,DISK], DatanodeInfoWithStorage[127.0.0.1:43417,DS-c34fd34e-ad36-4906-b62c-3db452884d51,DISK], DatanodeInfoWithStorage[127.0.0.1:36860,DS-bbf6712b-1415-4b05-a390-939803728e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35303,DS-509b1124-1046-4de4-8ad2-c02783e8d315,DISK], DatanodeInfoWithStorage[127.0.0.1:45924,DS-9536ca1c-b1eb-454b-a537-d80445392366,DISK], DatanodeInfoWithStorage[127.0.0.1:34871,DS-0051f59c-37a8-4398-8697-c918b1f78930,DISK], DatanodeInfoWithStorage[127.0.0.1:33179,DS-3d0a5d8f-aae4-4b32-a43e-6ae5e9b1b414,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-306578909-172.17.0.15-1597315133545:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34439,DS-1c4fe799-f5d5-4b41-989e-fad8f71ac60f,DISK], DatanodeInfoWithStorage[127.0.0.1:41811,DS-fe67a400-6ef4-4ef9-bedb-cfe6115535d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45368,DS-14e9acd6-ccec-45d7-8e9a-c0bb4418ada8,DISK], DatanodeInfoWithStorage[127.0.0.1:38840,DS-6bee79ec-acb1-4e03-a959-4697f88c737c,DISK], DatanodeInfoWithStorage[127.0.0.1:45089,DS-5d012170-8bec-4a77-bc83-6ee6c6fcdbc4,DISK], DatanodeInfoWithStorage[127.0.0.1:39792,DS-181aebef-4d9f-4664-adfc-430bb5ec0a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:34653,DS-1e42c4ba-9795-4e3d-b544-11c2fefe6376,DISK], DatanodeInfoWithStorage[127.0.0.1:34867,DS-fe311c1e-44a8-4014-82c5-bfd14dd953ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-306578909-172.17.0.15-1597315133545:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34439,DS-1c4fe799-f5d5-4b41-989e-fad8f71ac60f,DISK], DatanodeInfoWithStorage[127.0.0.1:41811,DS-fe67a400-6ef4-4ef9-bedb-cfe6115535d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45368,DS-14e9acd6-ccec-45d7-8e9a-c0bb4418ada8,DISK], DatanodeInfoWithStorage[127.0.0.1:38840,DS-6bee79ec-acb1-4e03-a959-4697f88c737c,DISK], DatanodeInfoWithStorage[127.0.0.1:45089,DS-5d012170-8bec-4a77-bc83-6ee6c6fcdbc4,DISK], DatanodeInfoWithStorage[127.0.0.1:39792,DS-181aebef-4d9f-4664-adfc-430bb5ec0a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:34653,DS-1e42c4ba-9795-4e3d-b544-11c2fefe6376,DISK], DatanodeInfoWithStorage[127.0.0.1:34867,DS-fe311c1e-44a8-4014-82c5-bfd14dd953ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-446031148-172.17.0.15-1597315453461:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45467,DS-150b6e8b-cb80-4b83-9634-9710010e8e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37327,DS-865450a1-af31-4d4d-a013-de22cc63f246,DISK], DatanodeInfoWithStorage[127.0.0.1:39895,DS-47c5ccc3-9010-4f0d-86e1-f25dc6f47fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:34671,DS-241d7e92-5761-4874-bae1-b61e40daa963,DISK], DatanodeInfoWithStorage[127.0.0.1:33073,DS-d7781152-08ee-4eae-80a1-1d72777d2e16,DISK], DatanodeInfoWithStorage[127.0.0.1:36950,DS-45ab7dbe-98e0-40be-b106-2980f987700b,DISK], DatanodeInfoWithStorage[127.0.0.1:41810,DS-2a4057c0-5217-4b21-9f74-cd8a20d804d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37163,DS-f503e335-8443-4632-8e15-383abf1b104b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-446031148-172.17.0.15-1597315453461:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45467,DS-150b6e8b-cb80-4b83-9634-9710010e8e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37327,DS-865450a1-af31-4d4d-a013-de22cc63f246,DISK], DatanodeInfoWithStorage[127.0.0.1:39895,DS-47c5ccc3-9010-4f0d-86e1-f25dc6f47fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:34671,DS-241d7e92-5761-4874-bae1-b61e40daa963,DISK], DatanodeInfoWithStorage[127.0.0.1:33073,DS-d7781152-08ee-4eae-80a1-1d72777d2e16,DISK], DatanodeInfoWithStorage[127.0.0.1:36950,DS-45ab7dbe-98e0-40be-b106-2980f987700b,DISK], DatanodeInfoWithStorage[127.0.0.1:41810,DS-2a4057c0-5217-4b21-9f74-cd8a20d804d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37163,DS-f503e335-8443-4632-8e15-383abf1b104b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1355142386-172.17.0.15-1597315729091:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36118,DS-79b8084a-5ae4-48bd-8949-b325aa9cac66,DISK], DatanodeInfoWithStorage[127.0.0.1:34525,DS-f3f164f8-6f6f-407f-836d-bba10d88e347,DISK], DatanodeInfoWithStorage[127.0.0.1:34195,DS-06a82ebb-e01d-467b-8972-f7fc33f7c343,DISK], DatanodeInfoWithStorage[127.0.0.1:41014,DS-574a5d70-017b-489e-bd51-668117b0513a,DISK], DatanodeInfoWithStorage[127.0.0.1:46678,DS-f8c830f3-759b-4546-bc73-23b36a415801,DISK], DatanodeInfoWithStorage[127.0.0.1:35993,DS-c817f5c3-f12e-43e4-bc4e-4598dbfe2d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:42260,DS-2931d1d6-8a43-4b7a-ab1b-21e01c181f37,DISK], DatanodeInfoWithStorage[127.0.0.1:44542,DS-49ab0f1d-c77a-4409-9654-5a228d3a45bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1355142386-172.17.0.15-1597315729091:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36118,DS-79b8084a-5ae4-48bd-8949-b325aa9cac66,DISK], DatanodeInfoWithStorage[127.0.0.1:34525,DS-f3f164f8-6f6f-407f-836d-bba10d88e347,DISK], DatanodeInfoWithStorage[127.0.0.1:34195,DS-06a82ebb-e01d-467b-8972-f7fc33f7c343,DISK], DatanodeInfoWithStorage[127.0.0.1:41014,DS-574a5d70-017b-489e-bd51-668117b0513a,DISK], DatanodeInfoWithStorage[127.0.0.1:46678,DS-f8c830f3-759b-4546-bc73-23b36a415801,DISK], DatanodeInfoWithStorage[127.0.0.1:35993,DS-c817f5c3-f12e-43e4-bc4e-4598dbfe2d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:42260,DS-2931d1d6-8a43-4b7a-ab1b-21e01c181f37,DISK], DatanodeInfoWithStorage[127.0.0.1:44542,DS-49ab0f1d-c77a-4409-9654-5a228d3a45bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1983310903-172.17.0.15-1597315853843:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35290,DS-9e6606d1-1dbd-44be-9707-e1df353e0181,DISK], DatanodeInfoWithStorage[127.0.0.1:37027,DS-ef3f08e8-19f9-40cd-b3e2-79bb37e90a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36225,DS-ff364708-daca-45c5-a3c3-48d4603746c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39009,DS-f9a7ee29-b65c-4dec-86b6-8e90aa969f06,DISK], DatanodeInfoWithStorage[127.0.0.1:41432,DS-8cd4a6f2-d3cd-4fbd-b3ce-480614f24fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:41953,DS-5099c112-046e-4f48-afb0-432ce53f6b67,DISK], DatanodeInfoWithStorage[127.0.0.1:38889,DS-ba9b8ef1-2530-45b0-8a1a-417ec62eef50,DISK], DatanodeInfoWithStorage[127.0.0.1:38048,DS-6c6eb451-0b2d-412b-82c4-a1edf14242bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1983310903-172.17.0.15-1597315853843:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35290,DS-9e6606d1-1dbd-44be-9707-e1df353e0181,DISK], DatanodeInfoWithStorage[127.0.0.1:37027,DS-ef3f08e8-19f9-40cd-b3e2-79bb37e90a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36225,DS-ff364708-daca-45c5-a3c3-48d4603746c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39009,DS-f9a7ee29-b65c-4dec-86b6-8e90aa969f06,DISK], DatanodeInfoWithStorage[127.0.0.1:41432,DS-8cd4a6f2-d3cd-4fbd-b3ce-480614f24fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:41953,DS-5099c112-046e-4f48-afb0-432ce53f6b67,DISK], DatanodeInfoWithStorage[127.0.0.1:38889,DS-ba9b8ef1-2530-45b0-8a1a-417ec62eef50,DISK], DatanodeInfoWithStorage[127.0.0.1:38048,DS-6c6eb451-0b2d-412b-82c4-a1edf14242bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-340466045-172.17.0.15-1597316113517:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43492,DS-2d99adb4-4325-49ff-bb62-049a8630ae93,DISK], DatanodeInfoWithStorage[127.0.0.1:35277,DS-5a6e5480-cafb-4de0-95a1-07bdb42278b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35938,DS-e93b65c4-1e4f-4251-8475-cb285426d7f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42573,DS-63b29227-b4a5-4a32-b1af-8150cb1072f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37819,DS-d39c0008-9787-44df-a913-664a10cce18e,DISK], DatanodeInfoWithStorage[127.0.0.1:41495,DS-8d360766-2969-4fa0-b765-3023feb5f69d,DISK], DatanodeInfoWithStorage[127.0.0.1:35259,DS-8e14c36f-1eb3-4804-b41f-8529e0b927b9,DISK], DatanodeInfoWithStorage[127.0.0.1:32827,DS-0ada5d01-fd25-4929-9d38-81fb26307a39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-340466045-172.17.0.15-1597316113517:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43492,DS-2d99adb4-4325-49ff-bb62-049a8630ae93,DISK], DatanodeInfoWithStorage[127.0.0.1:35277,DS-5a6e5480-cafb-4de0-95a1-07bdb42278b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35938,DS-e93b65c4-1e4f-4251-8475-cb285426d7f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42573,DS-63b29227-b4a5-4a32-b1af-8150cb1072f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37819,DS-d39c0008-9787-44df-a913-664a10cce18e,DISK], DatanodeInfoWithStorage[127.0.0.1:41495,DS-8d360766-2969-4fa0-b765-3023feb5f69d,DISK], DatanodeInfoWithStorage[127.0.0.1:35259,DS-8e14c36f-1eb3-4804-b41f-8529e0b927b9,DISK], DatanodeInfoWithStorage[127.0.0.1:32827,DS-0ada5d01-fd25-4929-9d38-81fb26307a39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1750075104-172.17.0.15-1597316307147:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41666,DS-45f562f1-1720-4e7e-b4ae-44320af7fa4f,DISK], DatanodeInfoWithStorage[127.0.0.1:46017,DS-33d31046-7f6c-41fd-b5d4-7a9c1fbcdc3f,DISK], DatanodeInfoWithStorage[127.0.0.1:42592,DS-45e79026-8f00-4c34-b5d9-7a302d739cab,DISK], DatanodeInfoWithStorage[127.0.0.1:35027,DS-f0715393-68cc-4088-8585-96a387ae48cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40956,DS-4e910298-502c-4cc2-bdcf-3c9d65352f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:39460,DS-d772ec21-e09b-4a85-bca7-2349ff19951e,DISK], DatanodeInfoWithStorage[127.0.0.1:42810,DS-4002955c-c9a1-458e-b0eb-5e683db1c31f,DISK], DatanodeInfoWithStorage[127.0.0.1:39976,DS-64d4c613-c811-4123-8ac1-2a0fe070bdf5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1750075104-172.17.0.15-1597316307147:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41666,DS-45f562f1-1720-4e7e-b4ae-44320af7fa4f,DISK], DatanodeInfoWithStorage[127.0.0.1:46017,DS-33d31046-7f6c-41fd-b5d4-7a9c1fbcdc3f,DISK], DatanodeInfoWithStorage[127.0.0.1:42592,DS-45e79026-8f00-4c34-b5d9-7a302d739cab,DISK], DatanodeInfoWithStorage[127.0.0.1:35027,DS-f0715393-68cc-4088-8585-96a387ae48cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40956,DS-4e910298-502c-4cc2-bdcf-3c9d65352f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:39460,DS-d772ec21-e09b-4a85-bca7-2349ff19951e,DISK], DatanodeInfoWithStorage[127.0.0.1:42810,DS-4002955c-c9a1-458e-b0eb-5e683db1c31f,DISK], DatanodeInfoWithStorage[127.0.0.1:39976,DS-64d4c613-c811-4123-8ac1-2a0fe070bdf5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2116698909-172.17.0.15-1597316345214:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46314,DS-08e057b8-7095-4eb1-b436-37cbdec861eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37499,DS-aef85a97-c0aa-4bc7-a631-9650225a507f,DISK], DatanodeInfoWithStorage[127.0.0.1:43222,DS-8298b0e5-78de-4890-b3fa-12c95f5dd1c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39805,DS-448a2b76-6332-433a-921c-f0e3ad561744,DISK], DatanodeInfoWithStorage[127.0.0.1:41161,DS-5f990d68-8f7a-417f-895a-5c179f81623a,DISK], DatanodeInfoWithStorage[127.0.0.1:38961,DS-68b946b6-80e4-4fc1-91ff-180d1b9ef4ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35569,DS-548736f1-4489-4578-b738-52bb781616ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33858,DS-61c6b771-4f04-47b0-8961-4254391efc0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2116698909-172.17.0.15-1597316345214:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46314,DS-08e057b8-7095-4eb1-b436-37cbdec861eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37499,DS-aef85a97-c0aa-4bc7-a631-9650225a507f,DISK], DatanodeInfoWithStorage[127.0.0.1:43222,DS-8298b0e5-78de-4890-b3fa-12c95f5dd1c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39805,DS-448a2b76-6332-433a-921c-f0e3ad561744,DISK], DatanodeInfoWithStorage[127.0.0.1:41161,DS-5f990d68-8f7a-417f-895a-5c179f81623a,DISK], DatanodeInfoWithStorage[127.0.0.1:38961,DS-68b946b6-80e4-4fc1-91ff-180d1b9ef4ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35569,DS-548736f1-4489-4578-b738-52bb781616ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33858,DS-61c6b771-4f04-47b0-8961-4254391efc0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1008083605-172.17.0.15-1597316384933:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42840,DS-f7f1aeeb-5354-43cc-a8ae-7e0f85065c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40312,DS-daa8f539-b092-4a2f-9245-aeaff2d9cfc4,DISK], DatanodeInfoWithStorage[127.0.0.1:42316,DS-ce7ceae8-41c1-4b10-991c-f53aab6ecb8e,DISK], DatanodeInfoWithStorage[127.0.0.1:39288,DS-bd8ad37f-77a0-4c9a-93a2-c2f962d732f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37070,DS-f09cef64-b4e3-4d0d-b815-d58cc1bf4233,DISK], DatanodeInfoWithStorage[127.0.0.1:35531,DS-53f3a80c-a909-41f3-81d5-4794bdd51378,DISK], DatanodeInfoWithStorage[127.0.0.1:37362,DS-47f250c2-2591-4565-be2a-362cff88b485,DISK], DatanodeInfoWithStorage[127.0.0.1:34555,DS-e79cd3cb-996f-4ca1-9000-06ff971df64d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1008083605-172.17.0.15-1597316384933:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42840,DS-f7f1aeeb-5354-43cc-a8ae-7e0f85065c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40312,DS-daa8f539-b092-4a2f-9245-aeaff2d9cfc4,DISK], DatanodeInfoWithStorage[127.0.0.1:42316,DS-ce7ceae8-41c1-4b10-991c-f53aab6ecb8e,DISK], DatanodeInfoWithStorage[127.0.0.1:39288,DS-bd8ad37f-77a0-4c9a-93a2-c2f962d732f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37070,DS-f09cef64-b4e3-4d0d-b815-d58cc1bf4233,DISK], DatanodeInfoWithStorage[127.0.0.1:35531,DS-53f3a80c-a909-41f3-81d5-4794bdd51378,DISK], DatanodeInfoWithStorage[127.0.0.1:37362,DS-47f250c2-2591-4565-be2a-362cff88b485,DISK], DatanodeInfoWithStorage[127.0.0.1:34555,DS-e79cd3cb-996f-4ca1-9000-06ff971df64d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-849575081-172.17.0.15-1597316548338:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43091,DS-1822b44a-c877-46bb-a7c5-1e182a930106,DISK], DatanodeInfoWithStorage[127.0.0.1:41264,DS-8833ac82-c828-49e9-9c05-643f33ec3ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:44137,DS-46b75980-6321-4541-b632-44c097f5800c,DISK], DatanodeInfoWithStorage[127.0.0.1:38259,DS-13ebd7d4-55f8-4625-b862-4fb6a54a54de,DISK], DatanodeInfoWithStorage[127.0.0.1:44394,DS-b5725b91-930e-43fb-a539-8522bf5fe767,DISK], DatanodeInfoWithStorage[127.0.0.1:35641,DS-59d18321-ef18-4f68-afa2-4e72127dc8d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40396,DS-a457b77c-f160-4155-9653-e082c84806bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41754,DS-04089631-73f4-4012-8c7b-37a455638f2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-849575081-172.17.0.15-1597316548338:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43091,DS-1822b44a-c877-46bb-a7c5-1e182a930106,DISK], DatanodeInfoWithStorage[127.0.0.1:41264,DS-8833ac82-c828-49e9-9c05-643f33ec3ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:44137,DS-46b75980-6321-4541-b632-44c097f5800c,DISK], DatanodeInfoWithStorage[127.0.0.1:38259,DS-13ebd7d4-55f8-4625-b862-4fb6a54a54de,DISK], DatanodeInfoWithStorage[127.0.0.1:44394,DS-b5725b91-930e-43fb-a539-8522bf5fe767,DISK], DatanodeInfoWithStorage[127.0.0.1:35641,DS-59d18321-ef18-4f68-afa2-4e72127dc8d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40396,DS-a457b77c-f160-4155-9653-e082c84806bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41754,DS-04089631-73f4-4012-8c7b-37a455638f2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1061509802-172.17.0.15-1597316630148:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39782,DS-10340df8-9f95-45fa-97fe-72fcf28c8e17,DISK], DatanodeInfoWithStorage[127.0.0.1:36631,DS-1622b9fe-8aef-4616-a8e3-e2b3bbfd24bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45634,DS-6d12f15d-b334-4480-bd53-e990fd7fe3e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41482,DS-817a1d16-0041-4feb-b27f-55e4a071a7a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34532,DS-d97e4de6-94f2-4c27-a673-8cc5abcdd353,DISK], DatanodeInfoWithStorage[127.0.0.1:44766,DS-d1df1696-e96f-49eb-a929-fbcd4eeb8138,DISK], DatanodeInfoWithStorage[127.0.0.1:36598,DS-b0c2e4ea-641b-406f-ab20-437999ebfe13,DISK], DatanodeInfoWithStorage[127.0.0.1:44364,DS-bff1d0c1-1b92-420a-a0c3-227e6d551051,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1061509802-172.17.0.15-1597316630148:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39782,DS-10340df8-9f95-45fa-97fe-72fcf28c8e17,DISK], DatanodeInfoWithStorage[127.0.0.1:36631,DS-1622b9fe-8aef-4616-a8e3-e2b3bbfd24bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45634,DS-6d12f15d-b334-4480-bd53-e990fd7fe3e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41482,DS-817a1d16-0041-4feb-b27f-55e4a071a7a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34532,DS-d97e4de6-94f2-4c27-a673-8cc5abcdd353,DISK], DatanodeInfoWithStorage[127.0.0.1:44766,DS-d1df1696-e96f-49eb-a929-fbcd4eeb8138,DISK], DatanodeInfoWithStorage[127.0.0.1:36598,DS-b0c2e4ea-641b-406f-ab20-437999ebfe13,DISK], DatanodeInfoWithStorage[127.0.0.1:44364,DS-bff1d0c1-1b92-420a-a0c3-227e6d551051,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-233007056-172.17.0.15-1597317025126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46756,DS-1b295540-0c24-4a10-950d-6018f083db6e,DISK], DatanodeInfoWithStorage[127.0.0.1:40045,DS-6bc1a133-cecf-4a75-97b5-661d3e193c64,DISK], DatanodeInfoWithStorage[127.0.0.1:46311,DS-1eefb160-136a-4199-a7a3-caf7b853ae1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40101,DS-1a258f37-995d-44f7-8d9e-a420eb6d7faa,DISK], DatanodeInfoWithStorage[127.0.0.1:45345,DS-c29ccff0-a0b0-4313-9174-1e6b4493a760,DISK], DatanodeInfoWithStorage[127.0.0.1:34406,DS-621020e1-1699-412d-adc4-c55b648f51c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46424,DS-002748bc-1c86-47c7-9ec7-2f9c50c2a286,DISK], DatanodeInfoWithStorage[127.0.0.1:40665,DS-8def14a3-3332-4c33-b3aa-11fcdf147da1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-233007056-172.17.0.15-1597317025126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46756,DS-1b295540-0c24-4a10-950d-6018f083db6e,DISK], DatanodeInfoWithStorage[127.0.0.1:40045,DS-6bc1a133-cecf-4a75-97b5-661d3e193c64,DISK], DatanodeInfoWithStorage[127.0.0.1:46311,DS-1eefb160-136a-4199-a7a3-caf7b853ae1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40101,DS-1a258f37-995d-44f7-8d9e-a420eb6d7faa,DISK], DatanodeInfoWithStorage[127.0.0.1:45345,DS-c29ccff0-a0b0-4313-9174-1e6b4493a760,DISK], DatanodeInfoWithStorage[127.0.0.1:34406,DS-621020e1-1699-412d-adc4-c55b648f51c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46424,DS-002748bc-1c86-47c7-9ec7-2f9c50c2a286,DISK], DatanodeInfoWithStorage[127.0.0.1:40665,DS-8def14a3-3332-4c33-b3aa-11fcdf147da1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1696183604-172.17.0.15-1597317649986:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43497,DS-498f0fd7-6012-4d48-9e78-40ec34540b49,DISK], DatanodeInfoWithStorage[127.0.0.1:43831,DS-86fc254e-b29e-4aa8-83e7-140010d4ad7f,DISK], DatanodeInfoWithStorage[127.0.0.1:36601,DS-5a13cfdc-f2c9-4304-93c5-3c6e1677c062,DISK], DatanodeInfoWithStorage[127.0.0.1:45900,DS-0e386a3d-3476-4274-8e8d-059af02adab8,DISK], DatanodeInfoWithStorage[127.0.0.1:33350,DS-35b0adf8-c911-41d1-9d54-77a4528fa59e,DISK], DatanodeInfoWithStorage[127.0.0.1:39510,DS-2ca3145b-5171-4f33-9baf-86b7c61b4829,DISK], DatanodeInfoWithStorage[127.0.0.1:32797,DS-9d214f0b-51bf-4f42-a94d-8837ef20e000,DISK], DatanodeInfoWithStorage[127.0.0.1:45316,DS-019a20b4-d0e1-4790-add0-c9ed302684fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1696183604-172.17.0.15-1597317649986:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43497,DS-498f0fd7-6012-4d48-9e78-40ec34540b49,DISK], DatanodeInfoWithStorage[127.0.0.1:43831,DS-86fc254e-b29e-4aa8-83e7-140010d4ad7f,DISK], DatanodeInfoWithStorage[127.0.0.1:36601,DS-5a13cfdc-f2c9-4304-93c5-3c6e1677c062,DISK], DatanodeInfoWithStorage[127.0.0.1:45900,DS-0e386a3d-3476-4274-8e8d-059af02adab8,DISK], DatanodeInfoWithStorage[127.0.0.1:33350,DS-35b0adf8-c911-41d1-9d54-77a4528fa59e,DISK], DatanodeInfoWithStorage[127.0.0.1:39510,DS-2ca3145b-5171-4f33-9baf-86b7c61b4829,DISK], DatanodeInfoWithStorage[127.0.0.1:32797,DS-9d214f0b-51bf-4f42-a94d-8837ef20e000,DISK], DatanodeInfoWithStorage[127.0.0.1:45316,DS-019a20b4-d0e1-4790-add0-c9ed302684fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-732423865-172.17.0.15-1597317763786:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45884,DS-1a8e538c-7e67-4546-84db-45cd1ab80460,DISK], DatanodeInfoWithStorage[127.0.0.1:46231,DS-1fa8226c-69bd-43b6-8b30-3590e74af545,DISK], DatanodeInfoWithStorage[127.0.0.1:39341,DS-fb95b902-d362-465c-9328-752124647355,DISK], DatanodeInfoWithStorage[127.0.0.1:38551,DS-2c655926-1931-456e-a4c2-f01d551cdea9,DISK], DatanodeInfoWithStorage[127.0.0.1:33160,DS-4e127276-4c20-4ee6-a9a6-51ea918f90e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41550,DS-301a7c2f-ca9d-4b0e-b3f7-7749b75e1ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:39182,DS-89dbf401-ee07-42aa-a11c-33746646837c,DISK], DatanodeInfoWithStorage[127.0.0.1:45370,DS-797549f9-e381-4698-b877-80d7e61ff856,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-732423865-172.17.0.15-1597317763786:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45884,DS-1a8e538c-7e67-4546-84db-45cd1ab80460,DISK], DatanodeInfoWithStorage[127.0.0.1:46231,DS-1fa8226c-69bd-43b6-8b30-3590e74af545,DISK], DatanodeInfoWithStorage[127.0.0.1:39341,DS-fb95b902-d362-465c-9328-752124647355,DISK], DatanodeInfoWithStorage[127.0.0.1:38551,DS-2c655926-1931-456e-a4c2-f01d551cdea9,DISK], DatanodeInfoWithStorage[127.0.0.1:33160,DS-4e127276-4c20-4ee6-a9a6-51ea918f90e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41550,DS-301a7c2f-ca9d-4b0e-b3f7-7749b75e1ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:39182,DS-89dbf401-ee07-42aa-a11c-33746646837c,DISK], DatanodeInfoWithStorage[127.0.0.1:45370,DS-797549f9-e381-4698-b877-80d7e61ff856,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2016588669-172.17.0.15-1597317801866:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40191,DS-feb97606-a7d9-4331-805f-9630657ca0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38452,DS-93bc66be-0bd9-42c5-91e5-a86c4b34db84,DISK], DatanodeInfoWithStorage[127.0.0.1:45176,DS-39b2ab52-3c7b-402e-b6ed-0a8adba145da,DISK], DatanodeInfoWithStorage[127.0.0.1:42649,DS-769689b0-ecc8-4bb7-a3bd-8345085178a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41045,DS-031ae889-1883-4a07-a967-51a00b8f199b,DISK], DatanodeInfoWithStorage[127.0.0.1:37931,DS-3e2f39fd-2ec1-49b1-a422-3ce0b2973490,DISK], DatanodeInfoWithStorage[127.0.0.1:44754,DS-8665db39-ffe8-43a1-8808-9abd2c52b497,DISK], DatanodeInfoWithStorage[127.0.0.1:45827,DS-def46fb0-006d-497b-a2ba-0c6431b4a852,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2016588669-172.17.0.15-1597317801866:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40191,DS-feb97606-a7d9-4331-805f-9630657ca0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38452,DS-93bc66be-0bd9-42c5-91e5-a86c4b34db84,DISK], DatanodeInfoWithStorage[127.0.0.1:45176,DS-39b2ab52-3c7b-402e-b6ed-0a8adba145da,DISK], DatanodeInfoWithStorage[127.0.0.1:42649,DS-769689b0-ecc8-4bb7-a3bd-8345085178a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41045,DS-031ae889-1883-4a07-a967-51a00b8f199b,DISK], DatanodeInfoWithStorage[127.0.0.1:37931,DS-3e2f39fd-2ec1-49b1-a422-3ce0b2973490,DISK], DatanodeInfoWithStorage[127.0.0.1:44754,DS-8665db39-ffe8-43a1-8808-9abd2c52b497,DISK], DatanodeInfoWithStorage[127.0.0.1:45827,DS-def46fb0-006d-497b-a2ba-0c6431b4a852,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1958074475-172.17.0.15-1597318182472:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34543,DS-14f9ec0b-3030-4dff-bb1c-89d94daee45a,DISK], DatanodeInfoWithStorage[127.0.0.1:34485,DS-c83ca2cd-2f25-4be0-9cb0-ee8f340d0384,DISK], DatanodeInfoWithStorage[127.0.0.1:34252,DS-81a1389c-e4f0-43ab-91ac-c1455653c839,DISK], DatanodeInfoWithStorage[127.0.0.1:35951,DS-66ca275e-518b-45d0-b3e4-ab50d6d888c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33090,DS-2c3c964e-8ea0-4d27-bbe1-07a6e44def24,DISK], DatanodeInfoWithStorage[127.0.0.1:44719,DS-d4c2a72f-0d1e-4ad7-895f-db43519e6d70,DISK], DatanodeInfoWithStorage[127.0.0.1:34535,DS-f314f2ca-1d5c-44a6-b87f-204f58318aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:36281,DS-396fe771-d21b-4135-9262-591b5c8dbd83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1958074475-172.17.0.15-1597318182472:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34543,DS-14f9ec0b-3030-4dff-bb1c-89d94daee45a,DISK], DatanodeInfoWithStorage[127.0.0.1:34485,DS-c83ca2cd-2f25-4be0-9cb0-ee8f340d0384,DISK], DatanodeInfoWithStorage[127.0.0.1:34252,DS-81a1389c-e4f0-43ab-91ac-c1455653c839,DISK], DatanodeInfoWithStorage[127.0.0.1:35951,DS-66ca275e-518b-45d0-b3e4-ab50d6d888c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33090,DS-2c3c964e-8ea0-4d27-bbe1-07a6e44def24,DISK], DatanodeInfoWithStorage[127.0.0.1:44719,DS-d4c2a72f-0d1e-4ad7-895f-db43519e6d70,DISK], DatanodeInfoWithStorage[127.0.0.1:34535,DS-f314f2ca-1d5c-44a6-b87f-204f58318aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:36281,DS-396fe771-d21b-4135-9262-591b5c8dbd83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5858
