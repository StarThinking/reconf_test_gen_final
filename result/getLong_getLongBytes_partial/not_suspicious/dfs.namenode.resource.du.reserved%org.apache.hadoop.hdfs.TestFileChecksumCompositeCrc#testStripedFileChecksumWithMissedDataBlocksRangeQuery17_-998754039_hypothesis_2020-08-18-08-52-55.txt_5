reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1076331762-172.17.0.7-1597740868896:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41738,DS-408d761e-9ab4-404a-a31a-1df5620ac2fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39548,DS-4911ced3-d410-4ccc-aa3b-e4052462a899,DISK], DatanodeInfoWithStorage[127.0.0.1:44549,DS-c4e42d7b-9b09-44c0-9080-d0e1f7da1b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35489,DS-d4009975-acfc-4dd3-97c2-71a216f4407c,DISK], DatanodeInfoWithStorage[127.0.0.1:40694,DS-a26dafc3-26ed-4854-861e-920b372d81a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40494,DS-f3ca6d39-cb35-41b9-a17d-b2f24234203c,DISK], DatanodeInfoWithStorage[127.0.0.1:34881,DS-f8bb306b-3192-4480-9402-41b054be69b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42338,DS-bfb90bf7-d761-4e4f-8520-1290eec7ab6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1076331762-172.17.0.7-1597740868896:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41738,DS-408d761e-9ab4-404a-a31a-1df5620ac2fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39548,DS-4911ced3-d410-4ccc-aa3b-e4052462a899,DISK], DatanodeInfoWithStorage[127.0.0.1:44549,DS-c4e42d7b-9b09-44c0-9080-d0e1f7da1b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35489,DS-d4009975-acfc-4dd3-97c2-71a216f4407c,DISK], DatanodeInfoWithStorage[127.0.0.1:40694,DS-a26dafc3-26ed-4854-861e-920b372d81a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40494,DS-f3ca6d39-cb35-41b9-a17d-b2f24234203c,DISK], DatanodeInfoWithStorage[127.0.0.1:34881,DS-f8bb306b-3192-4480-9402-41b054be69b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42338,DS-bfb90bf7-d761-4e4f-8520-1290eec7ab6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1176191335-172.17.0.7-1597741098184:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38352,DS-3f6334b1-1f3a-4a05-9c31-00e6cc984ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:35305,DS-da611a16-b2f7-490c-b450-82861b3c2a65,DISK], DatanodeInfoWithStorage[127.0.0.1:46682,DS-3ee5fab0-bdf9-4b7f-946a-00e04f3e99bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43203,DS-0d3c2570-a332-4cd1-a4d6-bde04c25bd68,DISK], DatanodeInfoWithStorage[127.0.0.1:46111,DS-68485082-59af-4f7a-8104-14ce98278fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:37943,DS-09b5fd5e-9348-4edd-9cf6-217cce9a0c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:44197,DS-fd80d935-c199-44fd-b660-164815bcb116,DISK], DatanodeInfoWithStorage[127.0.0.1:39067,DS-c1be6395-8226-438a-ae59-10d3bf4c563e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1176191335-172.17.0.7-1597741098184:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38352,DS-3f6334b1-1f3a-4a05-9c31-00e6cc984ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:35305,DS-da611a16-b2f7-490c-b450-82861b3c2a65,DISK], DatanodeInfoWithStorage[127.0.0.1:46682,DS-3ee5fab0-bdf9-4b7f-946a-00e04f3e99bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43203,DS-0d3c2570-a332-4cd1-a4d6-bde04c25bd68,DISK], DatanodeInfoWithStorage[127.0.0.1:46111,DS-68485082-59af-4f7a-8104-14ce98278fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:37943,DS-09b5fd5e-9348-4edd-9cf6-217cce9a0c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:44197,DS-fd80d935-c199-44fd-b660-164815bcb116,DISK], DatanodeInfoWithStorage[127.0.0.1:39067,DS-c1be6395-8226-438a-ae59-10d3bf4c563e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-613219690-172.17.0.7-1597741605894:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42787,DS-def2aff3-f66c-4dde-bc87-92f1ff90ed33,DISK], DatanodeInfoWithStorage[127.0.0.1:40902,DS-c5c391cb-8149-4128-98e8-1a4d91376023,DISK], DatanodeInfoWithStorage[127.0.0.1:37839,DS-1b50e59e-3380-4309-b4d7-3856844d5f82,DISK], DatanodeInfoWithStorage[127.0.0.1:36513,DS-4895c6c6-6184-491d-a31a-8bd5f87daf61,DISK], DatanodeInfoWithStorage[127.0.0.1:41656,DS-8638ed65-210d-43e9-a442-01f6658797ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36538,DS-4dc11684-f2ee-4fb1-bb98-2d44a664812f,DISK], DatanodeInfoWithStorage[127.0.0.1:35248,DS-29717e13-42c6-43f9-b27d-d156a553b752,DISK], DatanodeInfoWithStorage[127.0.0.1:33177,DS-1b50efa0-8c0a-4c8a-a004-90d66c551b13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-613219690-172.17.0.7-1597741605894:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42787,DS-def2aff3-f66c-4dde-bc87-92f1ff90ed33,DISK], DatanodeInfoWithStorage[127.0.0.1:40902,DS-c5c391cb-8149-4128-98e8-1a4d91376023,DISK], DatanodeInfoWithStorage[127.0.0.1:37839,DS-1b50e59e-3380-4309-b4d7-3856844d5f82,DISK], DatanodeInfoWithStorage[127.0.0.1:36513,DS-4895c6c6-6184-491d-a31a-8bd5f87daf61,DISK], DatanodeInfoWithStorage[127.0.0.1:41656,DS-8638ed65-210d-43e9-a442-01f6658797ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36538,DS-4dc11684-f2ee-4fb1-bb98-2d44a664812f,DISK], DatanodeInfoWithStorage[127.0.0.1:35248,DS-29717e13-42c6-43f9-b27d-d156a553b752,DISK], DatanodeInfoWithStorage[127.0.0.1:33177,DS-1b50efa0-8c0a-4c8a-a004-90d66c551b13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-691678795-172.17.0.7-1597741640601:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43522,DS-af636d45-dfbe-4bce-926e-02f46411e6f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37034,DS-d4b1cfce-656f-417d-ac1b-555a90f9004e,DISK], DatanodeInfoWithStorage[127.0.0.1:39201,DS-058c26ce-f2e8-4350-9ced-538fbca1ce23,DISK], DatanodeInfoWithStorage[127.0.0.1:39745,DS-0e593530-7540-404d-95fd-c5a871e5f0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40319,DS-6ffe76a8-f873-4afa-87bd-92e5eb749706,DISK], DatanodeInfoWithStorage[127.0.0.1:37978,DS-fd255be9-f9ea-4b0f-96a0-f3d6ffec5881,DISK], DatanodeInfoWithStorage[127.0.0.1:46321,DS-4d675a82-7009-4159-9f9b-e9778d8a7505,DISK], DatanodeInfoWithStorage[127.0.0.1:33221,DS-aa6d1cf6-126a-4d8b-9774-38254e8e0848,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-691678795-172.17.0.7-1597741640601:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43522,DS-af636d45-dfbe-4bce-926e-02f46411e6f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37034,DS-d4b1cfce-656f-417d-ac1b-555a90f9004e,DISK], DatanodeInfoWithStorage[127.0.0.1:39201,DS-058c26ce-f2e8-4350-9ced-538fbca1ce23,DISK], DatanodeInfoWithStorage[127.0.0.1:39745,DS-0e593530-7540-404d-95fd-c5a871e5f0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40319,DS-6ffe76a8-f873-4afa-87bd-92e5eb749706,DISK], DatanodeInfoWithStorage[127.0.0.1:37978,DS-fd255be9-f9ea-4b0f-96a0-f3d6ffec5881,DISK], DatanodeInfoWithStorage[127.0.0.1:46321,DS-4d675a82-7009-4159-9f9b-e9778d8a7505,DISK], DatanodeInfoWithStorage[127.0.0.1:33221,DS-aa6d1cf6-126a-4d8b-9774-38254e8e0848,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-403254143-172.17.0.7-1597742184979:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34168,DS-9f215e0e-e809-4fd0-bba4-20332a7f7617,DISK], DatanodeInfoWithStorage[127.0.0.1:39683,DS-e4a71396-cc51-4510-a14c-bb19a9235530,DISK], DatanodeInfoWithStorage[127.0.0.1:35475,DS-43a13adc-d1b1-4773-bdbe-9cba97f13626,DISK], DatanodeInfoWithStorage[127.0.0.1:42929,DS-13aacfc6-3fae-4fc4-b937-0da06320d5d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38730,DS-a1d8c8a3-2f05-429f-9ebe-692fa2122ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:40609,DS-e84c0dc7-4862-4280-a7a0-288a7468f5af,DISK], DatanodeInfoWithStorage[127.0.0.1:45470,DS-6f203ed9-59a9-44a0-9570-53448eda9a71,DISK], DatanodeInfoWithStorage[127.0.0.1:44823,DS-b199190a-b192-41ed-97f7-f2d47f01efde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-403254143-172.17.0.7-1597742184979:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34168,DS-9f215e0e-e809-4fd0-bba4-20332a7f7617,DISK], DatanodeInfoWithStorage[127.0.0.1:39683,DS-e4a71396-cc51-4510-a14c-bb19a9235530,DISK], DatanodeInfoWithStorage[127.0.0.1:35475,DS-43a13adc-d1b1-4773-bdbe-9cba97f13626,DISK], DatanodeInfoWithStorage[127.0.0.1:42929,DS-13aacfc6-3fae-4fc4-b937-0da06320d5d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38730,DS-a1d8c8a3-2f05-429f-9ebe-692fa2122ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:40609,DS-e84c0dc7-4862-4280-a7a0-288a7468f5af,DISK], DatanodeInfoWithStorage[127.0.0.1:45470,DS-6f203ed9-59a9-44a0-9570-53448eda9a71,DISK], DatanodeInfoWithStorage[127.0.0.1:44823,DS-b199190a-b192-41ed-97f7-f2d47f01efde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1163629317-172.17.0.7-1597742543256:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38416,DS-22010baf-9d18-4914-b6b8-2b0272f725e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41577,DS-df1904e1-5a03-42ac-adb5-57d0cb1428b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37733,DS-808035a1-a527-453d-b4ba-c4be676de6e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-1fecc890-039a-4646-89d2-8007ecab6a01,DISK], DatanodeInfoWithStorage[127.0.0.1:43005,DS-ce9c4e58-5f4e-4cc6-8350-6e953b0fcd15,DISK], DatanodeInfoWithStorage[127.0.0.1:36278,DS-f35aa192-8ed0-4f46-a06c-ac2d090b4555,DISK], DatanodeInfoWithStorage[127.0.0.1:33700,DS-fcfd1f30-b0cf-4d3c-b2e7-91438be6d60c,DISK], DatanodeInfoWithStorage[127.0.0.1:43682,DS-ce7f8695-cb98-4561-9758-12ce198e47ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1163629317-172.17.0.7-1597742543256:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38416,DS-22010baf-9d18-4914-b6b8-2b0272f725e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41577,DS-df1904e1-5a03-42ac-adb5-57d0cb1428b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37733,DS-808035a1-a527-453d-b4ba-c4be676de6e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-1fecc890-039a-4646-89d2-8007ecab6a01,DISK], DatanodeInfoWithStorage[127.0.0.1:43005,DS-ce9c4e58-5f4e-4cc6-8350-6e953b0fcd15,DISK], DatanodeInfoWithStorage[127.0.0.1:36278,DS-f35aa192-8ed0-4f46-a06c-ac2d090b4555,DISK], DatanodeInfoWithStorage[127.0.0.1:33700,DS-fcfd1f30-b0cf-4d3c-b2e7-91438be6d60c,DISK], DatanodeInfoWithStorage[127.0.0.1:43682,DS-ce7f8695-cb98-4561-9758-12ce198e47ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-920215038-172.17.0.7-1597742660979:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45208,DS-686572d3-b59a-4799-87ba-eab807029424,DISK], DatanodeInfoWithStorage[127.0.0.1:41692,DS-e965382b-0b8d-4d13-a13c-b59718b16587,DISK], DatanodeInfoWithStorage[127.0.0.1:42848,DS-91276d75-7744-4655-901f-62bff8b5624f,DISK], DatanodeInfoWithStorage[127.0.0.1:36377,DS-8dee2611-1ce2-454f-95ff-fa10dc087bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:39196,DS-85893263-ac07-4e2f-9a0b-e5c15c0e2f18,DISK], DatanodeInfoWithStorage[127.0.0.1:33678,DS-b0afe162-dbdc-4aa7-8f2c-24a7d87e946e,DISK], DatanodeInfoWithStorage[127.0.0.1:38298,DS-c132b11b-8985-45a6-8d2c-436ee0a07099,DISK], DatanodeInfoWithStorage[127.0.0.1:33061,DS-9b93313e-53e4-4ad3-ae09-fc6c175701db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-920215038-172.17.0.7-1597742660979:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45208,DS-686572d3-b59a-4799-87ba-eab807029424,DISK], DatanodeInfoWithStorage[127.0.0.1:41692,DS-e965382b-0b8d-4d13-a13c-b59718b16587,DISK], DatanodeInfoWithStorage[127.0.0.1:42848,DS-91276d75-7744-4655-901f-62bff8b5624f,DISK], DatanodeInfoWithStorage[127.0.0.1:36377,DS-8dee2611-1ce2-454f-95ff-fa10dc087bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:39196,DS-85893263-ac07-4e2f-9a0b-e5c15c0e2f18,DISK], DatanodeInfoWithStorage[127.0.0.1:33678,DS-b0afe162-dbdc-4aa7-8f2c-24a7d87e946e,DISK], DatanodeInfoWithStorage[127.0.0.1:38298,DS-c132b11b-8985-45a6-8d2c-436ee0a07099,DISK], DatanodeInfoWithStorage[127.0.0.1:33061,DS-9b93313e-53e4-4ad3-ae09-fc6c175701db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1444608530-172.17.0.7-1597742851548:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36723,DS-6a1507b5-559f-4381-98ea-c08aa342afc9,DISK], DatanodeInfoWithStorage[127.0.0.1:44560,DS-3e181b61-0cab-40e9-a028-e1fb59407854,DISK], DatanodeInfoWithStorage[127.0.0.1:46185,DS-b9b5e894-8b21-4615-86fc-15f177391d21,DISK], DatanodeInfoWithStorage[127.0.0.1:41811,DS-e36a4c46-5ff6-4abf-841e-6e8a0cba9230,DISK], DatanodeInfoWithStorage[127.0.0.1:34374,DS-16427c9c-33d6-4707-baa2-f00e0c4ca18e,DISK], DatanodeInfoWithStorage[127.0.0.1:37946,DS-84d67189-e6ec-43b4-ba22-2d60671b0a18,DISK], DatanodeInfoWithStorage[127.0.0.1:37404,DS-e86b5200-fb3a-4e02-ba7a-8a5acdf9050f,DISK], DatanodeInfoWithStorage[127.0.0.1:35788,DS-83ca91d3-f84b-4cd0-915f-2681037cbe29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1444608530-172.17.0.7-1597742851548:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36723,DS-6a1507b5-559f-4381-98ea-c08aa342afc9,DISK], DatanodeInfoWithStorage[127.0.0.1:44560,DS-3e181b61-0cab-40e9-a028-e1fb59407854,DISK], DatanodeInfoWithStorage[127.0.0.1:46185,DS-b9b5e894-8b21-4615-86fc-15f177391d21,DISK], DatanodeInfoWithStorage[127.0.0.1:41811,DS-e36a4c46-5ff6-4abf-841e-6e8a0cba9230,DISK], DatanodeInfoWithStorage[127.0.0.1:34374,DS-16427c9c-33d6-4707-baa2-f00e0c4ca18e,DISK], DatanodeInfoWithStorage[127.0.0.1:37946,DS-84d67189-e6ec-43b4-ba22-2d60671b0a18,DISK], DatanodeInfoWithStorage[127.0.0.1:37404,DS-e86b5200-fb3a-4e02-ba7a-8a5acdf9050f,DISK], DatanodeInfoWithStorage[127.0.0.1:35788,DS-83ca91d3-f84b-4cd0-915f-2681037cbe29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-251745050-172.17.0.7-1597742921770:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39583,DS-c23efad0-982a-4930-88e7-63d6e348fb23,DISK], DatanodeInfoWithStorage[127.0.0.1:35376,DS-888f49e6-293a-4d2e-adb7-eec24b019f97,DISK], DatanodeInfoWithStorage[127.0.0.1:45191,DS-066a8c6c-cd8a-4ffd-acb6-f261925be551,DISK], DatanodeInfoWithStorage[127.0.0.1:45595,DS-d3e8acaa-036b-435a-a41f-2f1b2b47bb15,DISK], DatanodeInfoWithStorage[127.0.0.1:41740,DS-f3051232-78ae-4afc-afa1-3ff591e5094e,DISK], DatanodeInfoWithStorage[127.0.0.1:40674,DS-1f6c4780-69aa-4ca7-a8a5-fe76e625b49b,DISK], DatanodeInfoWithStorage[127.0.0.1:45607,DS-8a9103b1-c4cc-4e37-9359-aff3e099ac76,DISK], DatanodeInfoWithStorage[127.0.0.1:45551,DS-0ed0734f-568f-4ae0-a0e1-7678613833ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-251745050-172.17.0.7-1597742921770:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39583,DS-c23efad0-982a-4930-88e7-63d6e348fb23,DISK], DatanodeInfoWithStorage[127.0.0.1:35376,DS-888f49e6-293a-4d2e-adb7-eec24b019f97,DISK], DatanodeInfoWithStorage[127.0.0.1:45191,DS-066a8c6c-cd8a-4ffd-acb6-f261925be551,DISK], DatanodeInfoWithStorage[127.0.0.1:45595,DS-d3e8acaa-036b-435a-a41f-2f1b2b47bb15,DISK], DatanodeInfoWithStorage[127.0.0.1:41740,DS-f3051232-78ae-4afc-afa1-3ff591e5094e,DISK], DatanodeInfoWithStorage[127.0.0.1:40674,DS-1f6c4780-69aa-4ca7-a8a5-fe76e625b49b,DISK], DatanodeInfoWithStorage[127.0.0.1:45607,DS-8a9103b1-c4cc-4e37-9359-aff3e099ac76,DISK], DatanodeInfoWithStorage[127.0.0.1:45551,DS-0ed0734f-568f-4ae0-a0e1-7678613833ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1227955132-172.17.0.7-1597743455251:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45915,DS-6e15f304-6bbe-45f6-adff-4ad4a3522189,DISK], DatanodeInfoWithStorage[127.0.0.1:40090,DS-a5dfddd3-27a5-4508-8c9d-636851ac529d,DISK], DatanodeInfoWithStorage[127.0.0.1:34217,DS-abf7c9e7-8622-4f06-9562-89e01ca410ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40625,DS-5c1d94bc-38d6-423a-9444-32af9ef56e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:41620,DS-8c2f714b-cf6a-4003-bab0-148fb5197f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:37054,DS-0f04154a-f1ce-4ee5-a837-56f9b8d4e9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44599,DS-e412369f-8d38-482f-97e4-c97ae919ded3,DISK], DatanodeInfoWithStorage[127.0.0.1:35239,DS-be5e9883-ba88-495d-8332-c47c91d0ea73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1227955132-172.17.0.7-1597743455251:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45915,DS-6e15f304-6bbe-45f6-adff-4ad4a3522189,DISK], DatanodeInfoWithStorage[127.0.0.1:40090,DS-a5dfddd3-27a5-4508-8c9d-636851ac529d,DISK], DatanodeInfoWithStorage[127.0.0.1:34217,DS-abf7c9e7-8622-4f06-9562-89e01ca410ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40625,DS-5c1d94bc-38d6-423a-9444-32af9ef56e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:41620,DS-8c2f714b-cf6a-4003-bab0-148fb5197f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:37054,DS-0f04154a-f1ce-4ee5-a837-56f9b8d4e9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44599,DS-e412369f-8d38-482f-97e4-c97ae919ded3,DISK], DatanodeInfoWithStorage[127.0.0.1:35239,DS-be5e9883-ba88-495d-8332-c47c91d0ea73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-189490650-172.17.0.7-1597743561683:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41297,DS-3154ad31-bf1e-42c0-acb1-f19a266dd98b,DISK], DatanodeInfoWithStorage[127.0.0.1:38405,DS-dd945454-9d85-47f9-8812-39fcfd9339c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33454,DS-0d6b4990-9eea-4662-8a37-8c239fdad799,DISK], DatanodeInfoWithStorage[127.0.0.1:37410,DS-e6e26711-5797-41df-b975-67d04f12126a,DISK], DatanodeInfoWithStorage[127.0.0.1:45918,DS-ee317a73-3327-4892-ad14-21416e3121ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44368,DS-dee084c4-0060-483d-b40c-e2bf28c3c2e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41445,DS-9713ce56-f15d-4c6d-9a5e-c7798811b1ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38809,DS-f17fbdb7-1f97-4bca-a30c-d2b545f71e37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-189490650-172.17.0.7-1597743561683:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41297,DS-3154ad31-bf1e-42c0-acb1-f19a266dd98b,DISK], DatanodeInfoWithStorage[127.0.0.1:38405,DS-dd945454-9d85-47f9-8812-39fcfd9339c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33454,DS-0d6b4990-9eea-4662-8a37-8c239fdad799,DISK], DatanodeInfoWithStorage[127.0.0.1:37410,DS-e6e26711-5797-41df-b975-67d04f12126a,DISK], DatanodeInfoWithStorage[127.0.0.1:45918,DS-ee317a73-3327-4892-ad14-21416e3121ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44368,DS-dee084c4-0060-483d-b40c-e2bf28c3c2e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41445,DS-9713ce56-f15d-4c6d-9a5e-c7798811b1ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38809,DS-f17fbdb7-1f97-4bca-a30c-d2b545f71e37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-387210788-172.17.0.7-1597743635605:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37512,DS-327ec033-23b3-47e1-b240-e9c33ee31713,DISK], DatanodeInfoWithStorage[127.0.0.1:40236,DS-7408a85d-4a56-4211-8798-0449c44de74a,DISK], DatanodeInfoWithStorage[127.0.0.1:34306,DS-b3c71e45-957b-4e39-a7b6-ac0894d69a86,DISK], DatanodeInfoWithStorage[127.0.0.1:33915,DS-84e2d5b7-bd86-4799-9307-b43e4314b408,DISK], DatanodeInfoWithStorage[127.0.0.1:41034,DS-9215bd0f-681f-480a-befb-b32e57473580,DISK], DatanodeInfoWithStorage[127.0.0.1:38502,DS-841db42d-df32-4a0c-924f-853fee102685,DISK], DatanodeInfoWithStorage[127.0.0.1:43512,DS-cd3d6c7f-3e4a-4753-bd32-db7ffd616280,DISK], DatanodeInfoWithStorage[127.0.0.1:38220,DS-7e0fa436-1667-42b4-bee1-7b95aa9f485d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-387210788-172.17.0.7-1597743635605:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37512,DS-327ec033-23b3-47e1-b240-e9c33ee31713,DISK], DatanodeInfoWithStorage[127.0.0.1:40236,DS-7408a85d-4a56-4211-8798-0449c44de74a,DISK], DatanodeInfoWithStorage[127.0.0.1:34306,DS-b3c71e45-957b-4e39-a7b6-ac0894d69a86,DISK], DatanodeInfoWithStorage[127.0.0.1:33915,DS-84e2d5b7-bd86-4799-9307-b43e4314b408,DISK], DatanodeInfoWithStorage[127.0.0.1:41034,DS-9215bd0f-681f-480a-befb-b32e57473580,DISK], DatanodeInfoWithStorage[127.0.0.1:38502,DS-841db42d-df32-4a0c-924f-853fee102685,DISK], DatanodeInfoWithStorage[127.0.0.1:43512,DS-cd3d6c7f-3e4a-4753-bd32-db7ffd616280,DISK], DatanodeInfoWithStorage[127.0.0.1:38220,DS-7e0fa436-1667-42b4-bee1-7b95aa9f485d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1273144075-172.17.0.7-1597743674559:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45101,DS-07a04ac2-ea2a-48dc-8a76-20454fff3013,DISK], DatanodeInfoWithStorage[127.0.0.1:36128,DS-5eeae32e-f1c4-4ee7-ae21-fa3795c00747,DISK], DatanodeInfoWithStorage[127.0.0.1:45495,DS-16ad0585-0e63-4c1d-8fd2-e8dca554b39f,DISK], DatanodeInfoWithStorage[127.0.0.1:38055,DS-b97fefc7-7c5e-41a6-8a22-b95bb96fa346,DISK], DatanodeInfoWithStorage[127.0.0.1:36764,DS-81b2d196-f16b-4d0b-b57b-18381afa98b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41064,DS-0e688801-dba2-41f1-aa29-6bf520fa9f09,DISK], DatanodeInfoWithStorage[127.0.0.1:36295,DS-bfe6aab3-241b-4fdd-97d7-5e9836b257bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45976,DS-4b40e86e-9a10-46b3-87d7-f497ba4ddc7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1273144075-172.17.0.7-1597743674559:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45101,DS-07a04ac2-ea2a-48dc-8a76-20454fff3013,DISK], DatanodeInfoWithStorage[127.0.0.1:36128,DS-5eeae32e-f1c4-4ee7-ae21-fa3795c00747,DISK], DatanodeInfoWithStorage[127.0.0.1:45495,DS-16ad0585-0e63-4c1d-8fd2-e8dca554b39f,DISK], DatanodeInfoWithStorage[127.0.0.1:38055,DS-b97fefc7-7c5e-41a6-8a22-b95bb96fa346,DISK], DatanodeInfoWithStorage[127.0.0.1:36764,DS-81b2d196-f16b-4d0b-b57b-18381afa98b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41064,DS-0e688801-dba2-41f1-aa29-6bf520fa9f09,DISK], DatanodeInfoWithStorage[127.0.0.1:36295,DS-bfe6aab3-241b-4fdd-97d7-5e9836b257bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45976,DS-4b40e86e-9a10-46b3-87d7-f497ba4ddc7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-234740998-172.17.0.7-1597743791104:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34333,DS-b230a61b-1b88-4ea9-b1d8-bb1de4260b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:33258,DS-85b2cab3-f481-4917-9b33-191b6074bb54,DISK], DatanodeInfoWithStorage[127.0.0.1:43958,DS-1e0a1585-3b60-48e6-aa0e-c274debe65dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39922,DS-dca66388-37d4-4410-8c98-ccf922ea2b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:43339,DS-139586b1-b9e0-4f22-b334-7a0117754f63,DISK], DatanodeInfoWithStorage[127.0.0.1:32974,DS-77870f24-1e2b-40ee-b25c-3f2c6efb1ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:42159,DS-08027bba-5ff3-40fb-bf93-a3a14d4b1080,DISK], DatanodeInfoWithStorage[127.0.0.1:33296,DS-9838352a-0464-4b91-b3be-1d9486b6b11f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-234740998-172.17.0.7-1597743791104:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34333,DS-b230a61b-1b88-4ea9-b1d8-bb1de4260b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:33258,DS-85b2cab3-f481-4917-9b33-191b6074bb54,DISK], DatanodeInfoWithStorage[127.0.0.1:43958,DS-1e0a1585-3b60-48e6-aa0e-c274debe65dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39922,DS-dca66388-37d4-4410-8c98-ccf922ea2b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:43339,DS-139586b1-b9e0-4f22-b334-7a0117754f63,DISK], DatanodeInfoWithStorage[127.0.0.1:32974,DS-77870f24-1e2b-40ee-b25c-3f2c6efb1ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:42159,DS-08027bba-5ff3-40fb-bf93-a3a14d4b1080,DISK], DatanodeInfoWithStorage[127.0.0.1:33296,DS-9838352a-0464-4b91-b3be-1d9486b6b11f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1195879262-172.17.0.7-1597743830699:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37224,DS-ecdd8343-be7b-4d3d-bf48-fdfb51dc51c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33710,DS-fa3679e0-e623-4d78-b1a5-ff4cc1f1560f,DISK], DatanodeInfoWithStorage[127.0.0.1:36679,DS-aacb1bba-e575-4ad3-984c-0c6dc80adba0,DISK], DatanodeInfoWithStorage[127.0.0.1:44944,DS-81fc2e99-1090-489b-8b87-eff6bdf2469c,DISK], DatanodeInfoWithStorage[127.0.0.1:42448,DS-f004fff4-a6de-456c-af85-2afb330212cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42350,DS-ea81ed18-e5c2-4110-b7d1-70c840899d29,DISK], DatanodeInfoWithStorage[127.0.0.1:44883,DS-81b22232-01b9-4efe-8207-68513378123a,DISK], DatanodeInfoWithStorage[127.0.0.1:45353,DS-0683559c-8d76-4c4c-857d-3af07800eeea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1195879262-172.17.0.7-1597743830699:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37224,DS-ecdd8343-be7b-4d3d-bf48-fdfb51dc51c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33710,DS-fa3679e0-e623-4d78-b1a5-ff4cc1f1560f,DISK], DatanodeInfoWithStorage[127.0.0.1:36679,DS-aacb1bba-e575-4ad3-984c-0c6dc80adba0,DISK], DatanodeInfoWithStorage[127.0.0.1:44944,DS-81fc2e99-1090-489b-8b87-eff6bdf2469c,DISK], DatanodeInfoWithStorage[127.0.0.1:42448,DS-f004fff4-a6de-456c-af85-2afb330212cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42350,DS-ea81ed18-e5c2-4110-b7d1-70c840899d29,DISK], DatanodeInfoWithStorage[127.0.0.1:44883,DS-81b22232-01b9-4efe-8207-68513378123a,DISK], DatanodeInfoWithStorage[127.0.0.1:45353,DS-0683559c-8d76-4c4c-857d-3af07800eeea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1926082611-172.17.0.7-1597744477240:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39128,DS-3843716a-4a05-41dc-8f20-60c13c250230,DISK], DatanodeInfoWithStorage[127.0.0.1:38862,DS-4bb13c18-7fab-44c0-9f38-cd0aef360a25,DISK], DatanodeInfoWithStorage[127.0.0.1:36390,DS-39aa1925-285d-4e2c-bff3-0d38ca59ae12,DISK], DatanodeInfoWithStorage[127.0.0.1:39662,DS-6852f807-3584-49c3-9500-08d72e8c25e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39770,DS-987c9605-497b-4dde-b057-8f36aeadf237,DISK], DatanodeInfoWithStorage[127.0.0.1:45232,DS-7c771534-08ac-4fec-9be7-0c94b6b45146,DISK], DatanodeInfoWithStorage[127.0.0.1:44633,DS-45d29418-b8c4-4458-9de7-172ebdf14d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:45210,DS-4e9c1d30-3e70-4c5a-ba23-fa82e9799c43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1926082611-172.17.0.7-1597744477240:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39128,DS-3843716a-4a05-41dc-8f20-60c13c250230,DISK], DatanodeInfoWithStorage[127.0.0.1:38862,DS-4bb13c18-7fab-44c0-9f38-cd0aef360a25,DISK], DatanodeInfoWithStorage[127.0.0.1:36390,DS-39aa1925-285d-4e2c-bff3-0d38ca59ae12,DISK], DatanodeInfoWithStorage[127.0.0.1:39662,DS-6852f807-3584-49c3-9500-08d72e8c25e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39770,DS-987c9605-497b-4dde-b057-8f36aeadf237,DISK], DatanodeInfoWithStorage[127.0.0.1:45232,DS-7c771534-08ac-4fec-9be7-0c94b6b45146,DISK], DatanodeInfoWithStorage[127.0.0.1:44633,DS-45d29418-b8c4-4458-9de7-172ebdf14d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:45210,DS-4e9c1d30-3e70-4c5a-ba23-fa82e9799c43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-158139848-172.17.0.7-1597745095529:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43858,DS-f5e0c68a-3feb-47bc-b4e7-a27ffbd92a09,DISK], DatanodeInfoWithStorage[127.0.0.1:35849,DS-8f8b3f6e-7e1d-49b1-976b-095b001a7a44,DISK], DatanodeInfoWithStorage[127.0.0.1:42248,DS-b650b489-fbb1-4677-8d0c-9dab1baadd30,DISK], DatanodeInfoWithStorage[127.0.0.1:42198,DS-0410567f-79a7-4e47-8da7-e316b927ae8a,DISK], DatanodeInfoWithStorage[127.0.0.1:37260,DS-ca2191a2-16eb-4ff9-99af-97be900bfeaa,DISK], DatanodeInfoWithStorage[127.0.0.1:40386,DS-ee726dec-f1dd-469a-bbcd-7ac8ea743b02,DISK], DatanodeInfoWithStorage[127.0.0.1:44769,DS-7f29e609-29af-4f95-9c93-3b91814cd987,DISK], DatanodeInfoWithStorage[127.0.0.1:38919,DS-adcba84a-7159-4aac-abc2-61bf0c53dfdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-158139848-172.17.0.7-1597745095529:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43858,DS-f5e0c68a-3feb-47bc-b4e7-a27ffbd92a09,DISK], DatanodeInfoWithStorage[127.0.0.1:35849,DS-8f8b3f6e-7e1d-49b1-976b-095b001a7a44,DISK], DatanodeInfoWithStorage[127.0.0.1:42248,DS-b650b489-fbb1-4677-8d0c-9dab1baadd30,DISK], DatanodeInfoWithStorage[127.0.0.1:42198,DS-0410567f-79a7-4e47-8da7-e316b927ae8a,DISK], DatanodeInfoWithStorage[127.0.0.1:37260,DS-ca2191a2-16eb-4ff9-99af-97be900bfeaa,DISK], DatanodeInfoWithStorage[127.0.0.1:40386,DS-ee726dec-f1dd-469a-bbcd-7ac8ea743b02,DISK], DatanodeInfoWithStorage[127.0.0.1:44769,DS-7f29e609-29af-4f95-9c93-3b91814cd987,DISK], DatanodeInfoWithStorage[127.0.0.1:38919,DS-adcba84a-7159-4aac-abc2-61bf0c53dfdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-612800629-172.17.0.7-1597745291675:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44361,DS-d26e81b3-596e-4069-87ac-a8fb9299d495,DISK], DatanodeInfoWithStorage[127.0.0.1:46427,DS-15db6540-a2b3-45ac-839a-893641422a41,DISK], DatanodeInfoWithStorage[127.0.0.1:35154,DS-e0bcf037-3fb8-4a34-bfad-e7db96f76695,DISK], DatanodeInfoWithStorage[127.0.0.1:43323,DS-301ae9d9-8a72-46cf-aec7-e2fd47254d40,DISK], DatanodeInfoWithStorage[127.0.0.1:32947,DS-1c54e2c7-2cac-4186-9c06-7eb1652eb70d,DISK], DatanodeInfoWithStorage[127.0.0.1:36225,DS-9a44ba6e-4bf0-42a0-a0ef-3c759349f685,DISK], DatanodeInfoWithStorage[127.0.0.1:33075,DS-6e5f8fe7-2a6c-4d1e-a908-1b0d89fff9f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33180,DS-b2070976-42e9-4409-bae3-ddd058a494a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-612800629-172.17.0.7-1597745291675:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44361,DS-d26e81b3-596e-4069-87ac-a8fb9299d495,DISK], DatanodeInfoWithStorage[127.0.0.1:46427,DS-15db6540-a2b3-45ac-839a-893641422a41,DISK], DatanodeInfoWithStorage[127.0.0.1:35154,DS-e0bcf037-3fb8-4a34-bfad-e7db96f76695,DISK], DatanodeInfoWithStorage[127.0.0.1:43323,DS-301ae9d9-8a72-46cf-aec7-e2fd47254d40,DISK], DatanodeInfoWithStorage[127.0.0.1:32947,DS-1c54e2c7-2cac-4186-9c06-7eb1652eb70d,DISK], DatanodeInfoWithStorage[127.0.0.1:36225,DS-9a44ba6e-4bf0-42a0-a0ef-3c759349f685,DISK], DatanodeInfoWithStorage[127.0.0.1:33075,DS-6e5f8fe7-2a6c-4d1e-a908-1b0d89fff9f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33180,DS-b2070976-42e9-4409-bae3-ddd058a494a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-853139980-172.17.0.7-1597745721969:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32782,DS-9c4c28f9-780b-4540-ad42-fc59d1e9ff95,DISK], DatanodeInfoWithStorage[127.0.0.1:39540,DS-a7011867-91a3-4914-8f92-35b0ea5982d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34990,DS-bed6fbde-e42d-4ec8-a954-de1bc3d94260,DISK], DatanodeInfoWithStorage[127.0.0.1:34241,DS-7e4aabce-2c16-4e43-9216-6ce8f8cc4d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:33773,DS-9a6b2460-34df-4c15-b5c4-10bea29d1423,DISK], DatanodeInfoWithStorage[127.0.0.1:41147,DS-ddbf1b69-f1e7-4f52-a7ef-09ef03bbd262,DISK], DatanodeInfoWithStorage[127.0.0.1:41159,DS-f8c43a19-f2a3-4929-b16c-90d927be3fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:38457,DS-1bc1a5bf-19e9-405c-96e8-df421cbb752d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-853139980-172.17.0.7-1597745721969:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32782,DS-9c4c28f9-780b-4540-ad42-fc59d1e9ff95,DISK], DatanodeInfoWithStorage[127.0.0.1:39540,DS-a7011867-91a3-4914-8f92-35b0ea5982d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34990,DS-bed6fbde-e42d-4ec8-a954-de1bc3d94260,DISK], DatanodeInfoWithStorage[127.0.0.1:34241,DS-7e4aabce-2c16-4e43-9216-6ce8f8cc4d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:33773,DS-9a6b2460-34df-4c15-b5c4-10bea29d1423,DISK], DatanodeInfoWithStorage[127.0.0.1:41147,DS-ddbf1b69-f1e7-4f52-a7ef-09ef03bbd262,DISK], DatanodeInfoWithStorage[127.0.0.1:41159,DS-f8c43a19-f2a3-4929-b16c-90d927be3fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:38457,DS-1bc1a5bf-19e9-405c-96e8-df421cbb752d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-998859093-172.17.0.7-1597745764475:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36314,DS-a1ef1f56-6c44-4874-88f4-083e3be8a6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41911,DS-9db7a75a-e845-426c-9cd2-019b5e1da261,DISK], DatanodeInfoWithStorage[127.0.0.1:35443,DS-a35e93e5-d457-406d-8209-b3d8c9d5c4ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34703,DS-78e9d63b-adea-46be-b5d8-75595bac5dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:44035,DS-4d62b1b9-148a-4002-8fe2-c5f5171aea3f,DISK], DatanodeInfoWithStorage[127.0.0.1:37711,DS-3ae08c4d-eb38-4ef8-a52c-a5b499340d75,DISK], DatanodeInfoWithStorage[127.0.0.1:40501,DS-bd82fbb1-9798-4fa1-b7a4-880e79fc4109,DISK], DatanodeInfoWithStorage[127.0.0.1:35245,DS-5b58f046-2bfc-4f73-b34e-ccbef724086e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-998859093-172.17.0.7-1597745764475:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36314,DS-a1ef1f56-6c44-4874-88f4-083e3be8a6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41911,DS-9db7a75a-e845-426c-9cd2-019b5e1da261,DISK], DatanodeInfoWithStorage[127.0.0.1:35443,DS-a35e93e5-d457-406d-8209-b3d8c9d5c4ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34703,DS-78e9d63b-adea-46be-b5d8-75595bac5dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:44035,DS-4d62b1b9-148a-4002-8fe2-c5f5171aea3f,DISK], DatanodeInfoWithStorage[127.0.0.1:37711,DS-3ae08c4d-eb38-4ef8-a52c-a5b499340d75,DISK], DatanodeInfoWithStorage[127.0.0.1:40501,DS-bd82fbb1-9798-4fa1-b7a4-880e79fc4109,DISK], DatanodeInfoWithStorage[127.0.0.1:35245,DS-5b58f046-2bfc-4f73-b34e-ccbef724086e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-614790196-172.17.0.7-1597746128200:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36326,DS-5a229496-5e05-4fe5-860a-75e5b709777a,DISK], DatanodeInfoWithStorage[127.0.0.1:43369,DS-deee68c1-a96d-4f36-9036-b36a8284e94a,DISK], DatanodeInfoWithStorage[127.0.0.1:36562,DS-52fb7cc8-7a2f-42c3-9ef1-6ffdd578c864,DISK], DatanodeInfoWithStorage[127.0.0.1:43559,DS-fa0dd211-093d-45dc-a832-49568014d20f,DISK], DatanodeInfoWithStorage[127.0.0.1:35775,DS-5c1b20d7-0cb5-4d87-942a-e60df051a4e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46203,DS-21545851-a7a3-4cd5-a924-aa3d5ee82bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:40241,DS-bb95962b-7d2a-42ac-8894-533ca26e97bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38880,DS-3ca52b59-911f-4e05-8ce8-f0c4e72c83bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-614790196-172.17.0.7-1597746128200:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36326,DS-5a229496-5e05-4fe5-860a-75e5b709777a,DISK], DatanodeInfoWithStorage[127.0.0.1:43369,DS-deee68c1-a96d-4f36-9036-b36a8284e94a,DISK], DatanodeInfoWithStorage[127.0.0.1:36562,DS-52fb7cc8-7a2f-42c3-9ef1-6ffdd578c864,DISK], DatanodeInfoWithStorage[127.0.0.1:43559,DS-fa0dd211-093d-45dc-a832-49568014d20f,DISK], DatanodeInfoWithStorage[127.0.0.1:35775,DS-5c1b20d7-0cb5-4d87-942a-e60df051a4e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46203,DS-21545851-a7a3-4cd5-a924-aa3d5ee82bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:40241,DS-bb95962b-7d2a-42ac-8894-533ca26e97bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38880,DS-3ca52b59-911f-4e05-8ce8-f0c4e72c83bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5491
