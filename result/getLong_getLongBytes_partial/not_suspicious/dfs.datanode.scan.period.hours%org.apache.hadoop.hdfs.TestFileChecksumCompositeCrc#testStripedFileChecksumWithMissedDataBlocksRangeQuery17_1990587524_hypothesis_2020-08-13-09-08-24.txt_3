reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-633190650-172.17.0.20-1597309950181:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44143,DS-f34effac-f0d4-47d4-b854-ef200c736296,DISK], DatanodeInfoWithStorage[127.0.0.1:44319,DS-272b7d61-a7b1-42f0-8566-7453e1c275d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37441,DS-4b96a895-2ba2-4205-8a69-b7f6224ca08e,DISK], DatanodeInfoWithStorage[127.0.0.1:34165,DS-0a6bfbc4-72ba-467e-aee6-ba4b5b0ddee3,DISK], DatanodeInfoWithStorage[127.0.0.1:45465,DS-8d9a289a-3d4b-418b-97c6-9009a15b2f13,DISK], DatanodeInfoWithStorage[127.0.0.1:38975,DS-c660e888-a83a-43a1-aef6-ba811de7979a,DISK], DatanodeInfoWithStorage[127.0.0.1:46313,DS-8fad85be-f19a-45a5-9053-016eb79cac55,DISK], DatanodeInfoWithStorage[127.0.0.1:34726,DS-9462714d-ea88-4681-b1f5-445034d628f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-633190650-172.17.0.20-1597309950181:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44143,DS-f34effac-f0d4-47d4-b854-ef200c736296,DISK], DatanodeInfoWithStorage[127.0.0.1:44319,DS-272b7d61-a7b1-42f0-8566-7453e1c275d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37441,DS-4b96a895-2ba2-4205-8a69-b7f6224ca08e,DISK], DatanodeInfoWithStorage[127.0.0.1:34165,DS-0a6bfbc4-72ba-467e-aee6-ba4b5b0ddee3,DISK], DatanodeInfoWithStorage[127.0.0.1:45465,DS-8d9a289a-3d4b-418b-97c6-9009a15b2f13,DISK], DatanodeInfoWithStorage[127.0.0.1:38975,DS-c660e888-a83a-43a1-aef6-ba811de7979a,DISK], DatanodeInfoWithStorage[127.0.0.1:46313,DS-8fad85be-f19a-45a5-9053-016eb79cac55,DISK], DatanodeInfoWithStorage[127.0.0.1:34726,DS-9462714d-ea88-4681-b1f5-445034d628f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-790180362-172.17.0.20-1597310566266:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41212,DS-3a1a9f1e-f6d1-47ed-a2dd-af69bb290a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33791,DS-7cf979d1-bfe8-44d1-a877-43d792916886,DISK], DatanodeInfoWithStorage[127.0.0.1:41220,DS-19b23bde-d2c3-403a-9034-11212c6499dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34954,DS-f9c17e31-38c1-4651-8a7c-e82f36ce2d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:42079,DS-2279da01-555b-40ef-934b-9099ea120177,DISK], DatanodeInfoWithStorage[127.0.0.1:34480,DS-74675256-ead8-457a-9307-43705be64044,DISK], DatanodeInfoWithStorage[127.0.0.1:33951,DS-eeafedcd-04cb-4e62-af2f-ca5e2a0853d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37217,DS-c6579eed-6b2d-46b5-b205-5251d54cf8a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-790180362-172.17.0.20-1597310566266:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41212,DS-3a1a9f1e-f6d1-47ed-a2dd-af69bb290a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33791,DS-7cf979d1-bfe8-44d1-a877-43d792916886,DISK], DatanodeInfoWithStorage[127.0.0.1:41220,DS-19b23bde-d2c3-403a-9034-11212c6499dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34954,DS-f9c17e31-38c1-4651-8a7c-e82f36ce2d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:42079,DS-2279da01-555b-40ef-934b-9099ea120177,DISK], DatanodeInfoWithStorage[127.0.0.1:34480,DS-74675256-ead8-457a-9307-43705be64044,DISK], DatanodeInfoWithStorage[127.0.0.1:33951,DS-eeafedcd-04cb-4e62-af2f-ca5e2a0853d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37217,DS-c6579eed-6b2d-46b5-b205-5251d54cf8a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1227162880-172.17.0.20-1597310868407:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41952,DS-a3599c41-c1f9-4d0f-980a-c7223dc7e3bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38277,DS-161ae8d4-2a1f-43da-85b5-7d8b34e0be6c,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-e1254da4-ae9a-407c-9d60-9dc333e5dc7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-61abac89-436e-453d-abab-2c77c71fc48b,DISK], DatanodeInfoWithStorage[127.0.0.1:38163,DS-52784f26-bcc0-4cc8-badf-91fe1e876a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41399,DS-8e835371-0d1c-431b-bd05-a914a70d4a64,DISK], DatanodeInfoWithStorage[127.0.0.1:42714,DS-c2e3e1ef-2b0b-4583-b825-3ff285148e14,DISK], DatanodeInfoWithStorage[127.0.0.1:39186,DS-cc330065-e63c-4acd-ac07-5da79958bc22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1227162880-172.17.0.20-1597310868407:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41952,DS-a3599c41-c1f9-4d0f-980a-c7223dc7e3bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38277,DS-161ae8d4-2a1f-43da-85b5-7d8b34e0be6c,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-e1254da4-ae9a-407c-9d60-9dc333e5dc7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-61abac89-436e-453d-abab-2c77c71fc48b,DISK], DatanodeInfoWithStorage[127.0.0.1:38163,DS-52784f26-bcc0-4cc8-badf-91fe1e876a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41399,DS-8e835371-0d1c-431b-bd05-a914a70d4a64,DISK], DatanodeInfoWithStorage[127.0.0.1:42714,DS-c2e3e1ef-2b0b-4583-b825-3ff285148e14,DISK], DatanodeInfoWithStorage[127.0.0.1:39186,DS-cc330065-e63c-4acd-ac07-5da79958bc22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1718879180-172.17.0.20-1597311287168:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43795,DS-5f5c24a0-616e-4fa0-84c1-f3a181453076,DISK], DatanodeInfoWithStorage[127.0.0.1:40490,DS-ddead17d-e24c-4c8e-a838-8bac997fc0aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44146,DS-b50ccbe0-f906-4892-bfcc-0ca8241134a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41729,DS-897990df-251d-4086-9fab-d60e2b61f4b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42849,DS-4610d732-54cc-48db-83ee-c5ab3cce4b74,DISK], DatanodeInfoWithStorage[127.0.0.1:37312,DS-a79340cd-0846-488a-82e9-b10ca3d04c17,DISK], DatanodeInfoWithStorage[127.0.0.1:43682,DS-919a5139-4d3b-4d77-b11b-a78f4159b1a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41841,DS-950bc519-acd2-4d51-9b83-6eeb7e61ab30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1718879180-172.17.0.20-1597311287168:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43795,DS-5f5c24a0-616e-4fa0-84c1-f3a181453076,DISK], DatanodeInfoWithStorage[127.0.0.1:40490,DS-ddead17d-e24c-4c8e-a838-8bac997fc0aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44146,DS-b50ccbe0-f906-4892-bfcc-0ca8241134a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41729,DS-897990df-251d-4086-9fab-d60e2b61f4b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42849,DS-4610d732-54cc-48db-83ee-c5ab3cce4b74,DISK], DatanodeInfoWithStorage[127.0.0.1:37312,DS-a79340cd-0846-488a-82e9-b10ca3d04c17,DISK], DatanodeInfoWithStorage[127.0.0.1:43682,DS-919a5139-4d3b-4d77-b11b-a78f4159b1a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41841,DS-950bc519-acd2-4d51-9b83-6eeb7e61ab30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-271299184-172.17.0.20-1597311777959:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39031,DS-d52cc731-6981-454d-b7c6-8419a6cc7451,DISK], DatanodeInfoWithStorage[127.0.0.1:43705,DS-aaa650bd-c4e0-423f-a402-e406a8a932fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42626,DS-faa6b774-ffec-46e0-8a67-cdfede7b1f50,DISK], DatanodeInfoWithStorage[127.0.0.1:45791,DS-842faed0-f006-478f-a244-beabd7083312,DISK], DatanodeInfoWithStorage[127.0.0.1:35841,DS-4cba00a1-f1c0-4a2a-8ba4-8bf717fc0adc,DISK], DatanodeInfoWithStorage[127.0.0.1:37421,DS-a9a67d24-0136-4af8-8093-73d378ff1a25,DISK], DatanodeInfoWithStorage[127.0.0.1:42041,DS-a6061ec3-5d47-4a1b-9b84-44782df9202e,DISK], DatanodeInfoWithStorage[127.0.0.1:37224,DS-21951b0b-2c8e-41f6-b257-e0303e3b2479,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-271299184-172.17.0.20-1597311777959:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39031,DS-d52cc731-6981-454d-b7c6-8419a6cc7451,DISK], DatanodeInfoWithStorage[127.0.0.1:43705,DS-aaa650bd-c4e0-423f-a402-e406a8a932fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42626,DS-faa6b774-ffec-46e0-8a67-cdfede7b1f50,DISK], DatanodeInfoWithStorage[127.0.0.1:45791,DS-842faed0-f006-478f-a244-beabd7083312,DISK], DatanodeInfoWithStorage[127.0.0.1:35841,DS-4cba00a1-f1c0-4a2a-8ba4-8bf717fc0adc,DISK], DatanodeInfoWithStorage[127.0.0.1:37421,DS-a9a67d24-0136-4af8-8093-73d378ff1a25,DISK], DatanodeInfoWithStorage[127.0.0.1:42041,DS-a6061ec3-5d47-4a1b-9b84-44782df9202e,DISK], DatanodeInfoWithStorage[127.0.0.1:37224,DS-21951b0b-2c8e-41f6-b257-e0303e3b2479,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-959493509-172.17.0.20-1597312769802:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35978,DS-75f534d0-f532-4636-950b-38e46e9de64c,DISK], DatanodeInfoWithStorage[127.0.0.1:36677,DS-c439e19a-060c-4e77-a66c-cb25ea8a9efe,DISK], DatanodeInfoWithStorage[127.0.0.1:40108,DS-e862e7cf-d5d3-4600-ad53-44c6d7d5de01,DISK], DatanodeInfoWithStorage[127.0.0.1:45844,DS-cdcf78b4-e01d-4810-b8ec-c379ffd8e087,DISK], DatanodeInfoWithStorage[127.0.0.1:46370,DS-f813fb53-5aca-47ce-a471-2617c8665cff,DISK], DatanodeInfoWithStorage[127.0.0.1:44461,DS-5ad1728b-10fe-442a-bc9c-40025dd5f832,DISK], DatanodeInfoWithStorage[127.0.0.1:39548,DS-436ce1f4-eecd-4d20-8e41-e6610e2e2a58,DISK], DatanodeInfoWithStorage[127.0.0.1:36360,DS-ae4faefb-b228-456a-8e4a-917c7fc25b39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-959493509-172.17.0.20-1597312769802:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35978,DS-75f534d0-f532-4636-950b-38e46e9de64c,DISK], DatanodeInfoWithStorage[127.0.0.1:36677,DS-c439e19a-060c-4e77-a66c-cb25ea8a9efe,DISK], DatanodeInfoWithStorage[127.0.0.1:40108,DS-e862e7cf-d5d3-4600-ad53-44c6d7d5de01,DISK], DatanodeInfoWithStorage[127.0.0.1:45844,DS-cdcf78b4-e01d-4810-b8ec-c379ffd8e087,DISK], DatanodeInfoWithStorage[127.0.0.1:46370,DS-f813fb53-5aca-47ce-a471-2617c8665cff,DISK], DatanodeInfoWithStorage[127.0.0.1:44461,DS-5ad1728b-10fe-442a-bc9c-40025dd5f832,DISK], DatanodeInfoWithStorage[127.0.0.1:39548,DS-436ce1f4-eecd-4d20-8e41-e6610e2e2a58,DISK], DatanodeInfoWithStorage[127.0.0.1:36360,DS-ae4faefb-b228-456a-8e4a-917c7fc25b39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1509517659-172.17.0.20-1597312904482:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39746,DS-6321c989-6e40-4beb-b61f-6b7e958df564,DISK], DatanodeInfoWithStorage[127.0.0.1:40116,DS-f102e413-87cc-4839-9c97-9898f3b733b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44658,DS-e52c2ca8-daa6-4345-9c14-7964b4b18d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:42854,DS-09a38207-9735-42a2-be3c-2f05c84edff3,DISK], DatanodeInfoWithStorage[127.0.0.1:40537,DS-a9f05b3c-3eae-4800-8868-a2d3d468aa0c,DISK], DatanodeInfoWithStorage[127.0.0.1:41951,DS-b748d4d3-4b18-4129-a1b6-2bbdb5f25f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40460,DS-27921cb4-4d74-4f24-8aa3-8108de2ab396,DISK], DatanodeInfoWithStorage[127.0.0.1:46198,DS-a47634fb-a352-4cbc-bf52-b131e8cbb39e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1509517659-172.17.0.20-1597312904482:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39746,DS-6321c989-6e40-4beb-b61f-6b7e958df564,DISK], DatanodeInfoWithStorage[127.0.0.1:40116,DS-f102e413-87cc-4839-9c97-9898f3b733b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44658,DS-e52c2ca8-daa6-4345-9c14-7964b4b18d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:42854,DS-09a38207-9735-42a2-be3c-2f05c84edff3,DISK], DatanodeInfoWithStorage[127.0.0.1:40537,DS-a9f05b3c-3eae-4800-8868-a2d3d468aa0c,DISK], DatanodeInfoWithStorage[127.0.0.1:41951,DS-b748d4d3-4b18-4129-a1b6-2bbdb5f25f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40460,DS-27921cb4-4d74-4f24-8aa3-8108de2ab396,DISK], DatanodeInfoWithStorage[127.0.0.1:46198,DS-a47634fb-a352-4cbc-bf52-b131e8cbb39e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-415183039-172.17.0.20-1597313152191:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35356,DS-fba1c1cf-3cad-45c3-b0ae-971cd77459c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35519,DS-99296c5e-f0ac-4a6f-8783-19b2d71a7e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34436,DS-80cf64e4-d5b0-4a9d-a4bc-0ab864339067,DISK], DatanodeInfoWithStorage[127.0.0.1:42192,DS-e686b223-e559-4b0a-9bf6-43d6bad30f52,DISK], DatanodeInfoWithStorage[127.0.0.1:32903,DS-698ad23f-ac19-47df-84f5-71f6379d042b,DISK], DatanodeInfoWithStorage[127.0.0.1:34998,DS-b25a081a-c06b-4cea-90f9-7565b1f40df0,DISK], DatanodeInfoWithStorage[127.0.0.1:45700,DS-65902703-1cb7-4b05-a7d4-b155c6c8f5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37187,DS-cbfe7de9-889b-44d1-a618-262885e019b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-415183039-172.17.0.20-1597313152191:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35356,DS-fba1c1cf-3cad-45c3-b0ae-971cd77459c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35519,DS-99296c5e-f0ac-4a6f-8783-19b2d71a7e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34436,DS-80cf64e4-d5b0-4a9d-a4bc-0ab864339067,DISK], DatanodeInfoWithStorage[127.0.0.1:42192,DS-e686b223-e559-4b0a-9bf6-43d6bad30f52,DISK], DatanodeInfoWithStorage[127.0.0.1:32903,DS-698ad23f-ac19-47df-84f5-71f6379d042b,DISK], DatanodeInfoWithStorage[127.0.0.1:34998,DS-b25a081a-c06b-4cea-90f9-7565b1f40df0,DISK], DatanodeInfoWithStorage[127.0.0.1:45700,DS-65902703-1cb7-4b05-a7d4-b155c6c8f5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37187,DS-cbfe7de9-889b-44d1-a618-262885e019b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1951860997-172.17.0.20-1597314259624:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39233,DS-0a01bf7e-d387-4bb2-908d-9c85e417224a,DISK], DatanodeInfoWithStorage[127.0.0.1:35506,DS-8959331a-ffd7-4973-8c20-bbbd56460dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:38156,DS-45b56409-4126-4e87-ae80-2e19f00b873c,DISK], DatanodeInfoWithStorage[127.0.0.1:35058,DS-d7dc9b04-f517-450c-b60b-074c02c8a471,DISK], DatanodeInfoWithStorage[127.0.0.1:32809,DS-0d5e050d-8023-493e-a6a6-317f347d01d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44313,DS-89f013c2-b106-490d-b0e6-28849dc9fc00,DISK], DatanodeInfoWithStorage[127.0.0.1:36510,DS-9e258a66-45a0-45f5-8d88-b5c560a5d6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44967,DS-d83d4cb4-02ef-4f82-880e-11e3d31135a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1951860997-172.17.0.20-1597314259624:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39233,DS-0a01bf7e-d387-4bb2-908d-9c85e417224a,DISK], DatanodeInfoWithStorage[127.0.0.1:35506,DS-8959331a-ffd7-4973-8c20-bbbd56460dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:38156,DS-45b56409-4126-4e87-ae80-2e19f00b873c,DISK], DatanodeInfoWithStorage[127.0.0.1:35058,DS-d7dc9b04-f517-450c-b60b-074c02c8a471,DISK], DatanodeInfoWithStorage[127.0.0.1:32809,DS-0d5e050d-8023-493e-a6a6-317f347d01d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44313,DS-89f013c2-b106-490d-b0e6-28849dc9fc00,DISK], DatanodeInfoWithStorage[127.0.0.1:36510,DS-9e258a66-45a0-45f5-8d88-b5c560a5d6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44967,DS-d83d4cb4-02ef-4f82-880e-11e3d31135a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 6942
