reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 100
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 100
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1150123856-172.17.0.18-1597643930229:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38360,DS-fa68369e-5e55-438b-85d1-5aa23d936360,DISK], DatanodeInfoWithStorage[127.0.0.1:38809,DS-b1722463-3ec1-4826-aa99-dc7451000efb,DISK], DatanodeInfoWithStorage[127.0.0.1:34685,DS-916c35d1-af2e-449a-80e8-9815d2ef6277,DISK], DatanodeInfoWithStorage[127.0.0.1:36326,DS-67ec603d-023f-4bba-a297-f67dc22d11c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38192,DS-23028a0c-4186-4b54-a777-1891e511b03d,DISK], DatanodeInfoWithStorage[127.0.0.1:45421,DS-772aee72-9177-4055-8533-f3c93b6189f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37027,DS-eed79019-2512-4751-9c49-1006e17d37f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41222,DS-f3ce494b-49b3-4665-8a95-127481c9c80c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1150123856-172.17.0.18-1597643930229:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38360,DS-fa68369e-5e55-438b-85d1-5aa23d936360,DISK], DatanodeInfoWithStorage[127.0.0.1:38809,DS-b1722463-3ec1-4826-aa99-dc7451000efb,DISK], DatanodeInfoWithStorage[127.0.0.1:34685,DS-916c35d1-af2e-449a-80e8-9815d2ef6277,DISK], DatanodeInfoWithStorage[127.0.0.1:36326,DS-67ec603d-023f-4bba-a297-f67dc22d11c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38192,DS-23028a0c-4186-4b54-a777-1891e511b03d,DISK], DatanodeInfoWithStorage[127.0.0.1:45421,DS-772aee72-9177-4055-8533-f3c93b6189f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37027,DS-eed79019-2512-4751-9c49-1006e17d37f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41222,DS-f3ce494b-49b3-4665-8a95-127481c9c80c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 100
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1316496881-172.17.0.18-1597644145725:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34457,DS-9f19e546-9cf9-4600-95c4-7f22b6e5f607,DISK], DatanodeInfoWithStorage[127.0.0.1:38195,DS-26699538-4f61-47e5-b0c9-103b85fc730c,DISK], DatanodeInfoWithStorage[127.0.0.1:38468,DS-b46f3408-61c5-4c01-b043-e5b6a30ab8ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46460,DS-220e7724-29bc-4ea5-9113-114bd646a3df,DISK], DatanodeInfoWithStorage[127.0.0.1:35300,DS-eecfcebf-eff6-497d-af17-e17675678bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:45856,DS-fb84c4c5-8c19-474f-adce-4c12d43b4671,DISK], DatanodeInfoWithStorage[127.0.0.1:42129,DS-9c75c4a3-05a0-46e3-b390-099be6ad8732,DISK], DatanodeInfoWithStorage[127.0.0.1:44777,DS-a31d96e6-701a-4827-8d19-4f771fc806cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1316496881-172.17.0.18-1597644145725:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34457,DS-9f19e546-9cf9-4600-95c4-7f22b6e5f607,DISK], DatanodeInfoWithStorage[127.0.0.1:38195,DS-26699538-4f61-47e5-b0c9-103b85fc730c,DISK], DatanodeInfoWithStorage[127.0.0.1:38468,DS-b46f3408-61c5-4c01-b043-e5b6a30ab8ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46460,DS-220e7724-29bc-4ea5-9113-114bd646a3df,DISK], DatanodeInfoWithStorage[127.0.0.1:35300,DS-eecfcebf-eff6-497d-af17-e17675678bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:45856,DS-fb84c4c5-8c19-474f-adce-4c12d43b4671,DISK], DatanodeInfoWithStorage[127.0.0.1:42129,DS-9c75c4a3-05a0-46e3-b390-099be6ad8732,DISK], DatanodeInfoWithStorage[127.0.0.1:44777,DS-a31d96e6-701a-4827-8d19-4f771fc806cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 100
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-583623854-172.17.0.18-1597644448482:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38075,DS-a2d4779d-a2ed-40e1-8eaf-32e0adeb0398,DISK], DatanodeInfoWithStorage[127.0.0.1:39475,DS-8ef9a36e-d744-49ec-9861-3e60ec677445,DISK], DatanodeInfoWithStorage[127.0.0.1:38999,DS-425d530d-75da-4b48-8e5e-8fbb09017259,DISK], DatanodeInfoWithStorage[127.0.0.1:34060,DS-eeea52a2-e985-45e4-b8bd-fc048fe2937b,DISK], DatanodeInfoWithStorage[127.0.0.1:38259,DS-dde8a07f-39cb-4757-9d02-e598739f43ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34119,DS-2d534d6f-7f3b-4a5b-8b65-2333a0d35f27,DISK], DatanodeInfoWithStorage[127.0.0.1:46221,DS-02e92dcb-57a4-4513-ba25-96bf59526f29,DISK], DatanodeInfoWithStorage[127.0.0.1:38685,DS-a70089b9-0d71-4bea-8193-ff0695ffe8b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-583623854-172.17.0.18-1597644448482:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38075,DS-a2d4779d-a2ed-40e1-8eaf-32e0adeb0398,DISK], DatanodeInfoWithStorage[127.0.0.1:39475,DS-8ef9a36e-d744-49ec-9861-3e60ec677445,DISK], DatanodeInfoWithStorage[127.0.0.1:38999,DS-425d530d-75da-4b48-8e5e-8fbb09017259,DISK], DatanodeInfoWithStorage[127.0.0.1:34060,DS-eeea52a2-e985-45e4-b8bd-fc048fe2937b,DISK], DatanodeInfoWithStorage[127.0.0.1:38259,DS-dde8a07f-39cb-4757-9d02-e598739f43ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34119,DS-2d534d6f-7f3b-4a5b-8b65-2333a0d35f27,DISK], DatanodeInfoWithStorage[127.0.0.1:46221,DS-02e92dcb-57a4-4513-ba25-96bf59526f29,DISK], DatanodeInfoWithStorage[127.0.0.1:38685,DS-a70089b9-0d71-4bea-8193-ff0695ffe8b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 100
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1711980131-172.17.0.18-1597644528987:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35861,DS-25134ecf-7e9c-42fc-aefd-868dbae30cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:44977,DS-2ac58fbe-0538-45ae-bd21-a12096cdcd52,DISK], DatanodeInfoWithStorage[127.0.0.1:41975,DS-c1aa6bb6-9734-46f4-87c3-6b2390756055,DISK], DatanodeInfoWithStorage[127.0.0.1:35765,DS-29bfd904-4994-457e-9f12-07182e91fb0a,DISK], DatanodeInfoWithStorage[127.0.0.1:41408,DS-8d65d9a1-c8c3-476d-9208-3e4c543920ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34366,DS-888ea55a-5f09-4edc-a554-fffaf9d95451,DISK], DatanodeInfoWithStorage[127.0.0.1:44947,DS-f5c9836e-d672-4b3b-8d00-8cffe2674ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:34179,DS-3b9aafa8-8429-4380-b790-3340717e83c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1711980131-172.17.0.18-1597644528987:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35861,DS-25134ecf-7e9c-42fc-aefd-868dbae30cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:44977,DS-2ac58fbe-0538-45ae-bd21-a12096cdcd52,DISK], DatanodeInfoWithStorage[127.0.0.1:41975,DS-c1aa6bb6-9734-46f4-87c3-6b2390756055,DISK], DatanodeInfoWithStorage[127.0.0.1:35765,DS-29bfd904-4994-457e-9f12-07182e91fb0a,DISK], DatanodeInfoWithStorage[127.0.0.1:41408,DS-8d65d9a1-c8c3-476d-9208-3e4c543920ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34366,DS-888ea55a-5f09-4edc-a554-fffaf9d95451,DISK], DatanodeInfoWithStorage[127.0.0.1:44947,DS-f5c9836e-d672-4b3b-8d00-8cffe2674ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:34179,DS-3b9aafa8-8429-4380-b790-3340717e83c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 100
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-156319386-172.17.0.18-1597644991728:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32917,DS-51d61385-ade3-4a72-a6d7-19c61a8b50b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39261,DS-515f8973-d691-4eee-bef4-e8a07f31d7e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39422,DS-9809b221-4c39-4de1-9e4f-459ab006393b,DISK], DatanodeInfoWithStorage[127.0.0.1:44114,DS-bf7d18cd-97e6-4b8c-81de-58de84050ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:45232,DS-1e5f705f-e66c-4e1a-84bb-7cc88a58fe21,DISK], DatanodeInfoWithStorage[127.0.0.1:44400,DS-0b388e3e-0441-406d-9319-164c1807f09b,DISK], DatanodeInfoWithStorage[127.0.0.1:46203,DS-b4573879-e87e-49fb-b3e6-0c1cd652f8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46799,DS-c2c9386a-cb15-4c9e-893e-4abd29c9bddf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-156319386-172.17.0.18-1597644991728:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32917,DS-51d61385-ade3-4a72-a6d7-19c61a8b50b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39261,DS-515f8973-d691-4eee-bef4-e8a07f31d7e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39422,DS-9809b221-4c39-4de1-9e4f-459ab006393b,DISK], DatanodeInfoWithStorage[127.0.0.1:44114,DS-bf7d18cd-97e6-4b8c-81de-58de84050ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:45232,DS-1e5f705f-e66c-4e1a-84bb-7cc88a58fe21,DISK], DatanodeInfoWithStorage[127.0.0.1:44400,DS-0b388e3e-0441-406d-9319-164c1807f09b,DISK], DatanodeInfoWithStorage[127.0.0.1:46203,DS-b4573879-e87e-49fb-b3e6-0c1cd652f8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46799,DS-c2c9386a-cb15-4c9e-893e-4abd29c9bddf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 100
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1871026188-172.17.0.18-1597645212374:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38642,DS-b0839c68-32ff-4f13-9547-46141955e8c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39810,DS-efa44907-4ff8-4448-bc58-9778fb49b2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41950,DS-c7a538c2-0788-439c-9d64-e7ba160639a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36108,DS-bbbd631d-9056-43b1-af5b-e503f33bd96a,DISK], DatanodeInfoWithStorage[127.0.0.1:38280,DS-adf9b763-22ee-48bd-b70c-4fa290a56f79,DISK], DatanodeInfoWithStorage[127.0.0.1:39989,DS-85f2abb8-bafd-427b-88c5-a0e5d1be8c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:43589,DS-b64b9b8c-15f9-435e-97b9-2a03961c0e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:32926,DS-c57e70e3-e2f5-49d5-8d1b-905dddfa9808,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1871026188-172.17.0.18-1597645212374:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38642,DS-b0839c68-32ff-4f13-9547-46141955e8c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39810,DS-efa44907-4ff8-4448-bc58-9778fb49b2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41950,DS-c7a538c2-0788-439c-9d64-e7ba160639a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36108,DS-bbbd631d-9056-43b1-af5b-e503f33bd96a,DISK], DatanodeInfoWithStorage[127.0.0.1:38280,DS-adf9b763-22ee-48bd-b70c-4fa290a56f79,DISK], DatanodeInfoWithStorage[127.0.0.1:39989,DS-85f2abb8-bafd-427b-88c5-a0e5d1be8c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:43589,DS-b64b9b8c-15f9-435e-97b9-2a03961c0e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:32926,DS-c57e70e3-e2f5-49d5-8d1b-905dddfa9808,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 100
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-344168243-172.17.0.18-1597645302680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44252,DS-d4177b4c-943d-48a8-a206-1b56f10ec133,DISK], DatanodeInfoWithStorage[127.0.0.1:36803,DS-bdfa2a59-7de0-48e3-82d3-1f5e56239e00,DISK], DatanodeInfoWithStorage[127.0.0.1:35538,DS-b9d28aa7-24bf-4ee6-b852-9e4b504c0b65,DISK], DatanodeInfoWithStorage[127.0.0.1:44978,DS-10d6332f-afa8-416c-8d86-3607e36fd3c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40305,DS-8dff3aa0-6aae-485c-b386-ab8df1065c63,DISK], DatanodeInfoWithStorage[127.0.0.1:35049,DS-a2f172fd-ddae-4fd4-92ed-cde6c066fd29,DISK], DatanodeInfoWithStorage[127.0.0.1:40512,DS-3eac36a4-61b0-4c4a-b660-fec97a0422ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46072,DS-62cca1bc-33e4-4e88-a300-bd04783e9fd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-344168243-172.17.0.18-1597645302680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44252,DS-d4177b4c-943d-48a8-a206-1b56f10ec133,DISK], DatanodeInfoWithStorage[127.0.0.1:36803,DS-bdfa2a59-7de0-48e3-82d3-1f5e56239e00,DISK], DatanodeInfoWithStorage[127.0.0.1:35538,DS-b9d28aa7-24bf-4ee6-b852-9e4b504c0b65,DISK], DatanodeInfoWithStorage[127.0.0.1:44978,DS-10d6332f-afa8-416c-8d86-3607e36fd3c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40305,DS-8dff3aa0-6aae-485c-b386-ab8df1065c63,DISK], DatanodeInfoWithStorage[127.0.0.1:35049,DS-a2f172fd-ddae-4fd4-92ed-cde6c066fd29,DISK], DatanodeInfoWithStorage[127.0.0.1:40512,DS-3eac36a4-61b0-4c4a-b660-fec97a0422ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46072,DS-62cca1bc-33e4-4e88-a300-bd04783e9fd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 100
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2071442347-172.17.0.18-1597646507961:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32983,DS-e5f7cdbc-4b6b-427e-874f-908bdbf7a542,DISK], DatanodeInfoWithStorage[127.0.0.1:35150,DS-5e0bd7e3-0d5b-4960-972b-01b643abadf4,DISK], DatanodeInfoWithStorage[127.0.0.1:45527,DS-1aa51603-cce8-41cf-ad15-45cc5a4a65f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44375,DS-190022f6-2861-48b1-b723-25bdeb18119a,DISK], DatanodeInfoWithStorage[127.0.0.1:34015,DS-f6e5d0de-8793-483d-ab2d-5468f967e805,DISK], DatanodeInfoWithStorage[127.0.0.1:44333,DS-31ed6640-4030-4778-a78a-658ef5972da8,DISK], DatanodeInfoWithStorage[127.0.0.1:39721,DS-aa163f88-b54a-453d-ab28-deb689e18c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:35089,DS-dd8927cf-b7b0-4879-aad9-dfd1c69377a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2071442347-172.17.0.18-1597646507961:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32983,DS-e5f7cdbc-4b6b-427e-874f-908bdbf7a542,DISK], DatanodeInfoWithStorage[127.0.0.1:35150,DS-5e0bd7e3-0d5b-4960-972b-01b643abadf4,DISK], DatanodeInfoWithStorage[127.0.0.1:45527,DS-1aa51603-cce8-41cf-ad15-45cc5a4a65f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44375,DS-190022f6-2861-48b1-b723-25bdeb18119a,DISK], DatanodeInfoWithStorage[127.0.0.1:34015,DS-f6e5d0de-8793-483d-ab2d-5468f967e805,DISK], DatanodeInfoWithStorage[127.0.0.1:44333,DS-31ed6640-4030-4778-a78a-658ef5972da8,DISK], DatanodeInfoWithStorage[127.0.0.1:39721,DS-aa163f88-b54a-453d-ab28-deb689e18c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:35089,DS-dd8927cf-b7b0-4879-aad9-dfd1c69377a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 100
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-754972568-172.17.0.18-1597647398079:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36803,DS-081ca44d-325c-4d51-b299-25820aeeca92,DISK], DatanodeInfoWithStorage[127.0.0.1:42540,DS-6316fe64-f333-4fe6-a8d8-2868e206d408,DISK], DatanodeInfoWithStorage[127.0.0.1:35132,DS-3f47cd32-ce76-4b8d-8958-fadd3b512795,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-f1771614-d606-4e86-84a8-e75c349b7b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45671,DS-50784ed4-ddd7-4130-989c-ded0764e235c,DISK], DatanodeInfoWithStorage[127.0.0.1:34838,DS-1cf73953-b173-40ea-b6a3-a358e7a39620,DISK], DatanodeInfoWithStorage[127.0.0.1:42454,DS-8458f0d6-4f75-46a3-888d-1d1f52ce6fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:44690,DS-54fb2508-e2e5-4de0-ae25-8810d783f35a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-754972568-172.17.0.18-1597647398079:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36803,DS-081ca44d-325c-4d51-b299-25820aeeca92,DISK], DatanodeInfoWithStorage[127.0.0.1:42540,DS-6316fe64-f333-4fe6-a8d8-2868e206d408,DISK], DatanodeInfoWithStorage[127.0.0.1:35132,DS-3f47cd32-ce76-4b8d-8958-fadd3b512795,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-f1771614-d606-4e86-84a8-e75c349b7b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45671,DS-50784ed4-ddd7-4130-989c-ded0764e235c,DISK], DatanodeInfoWithStorage[127.0.0.1:34838,DS-1cf73953-b173-40ea-b6a3-a358e7a39620,DISK], DatanodeInfoWithStorage[127.0.0.1:42454,DS-8458f0d6-4f75-46a3-888d-1d1f52ce6fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:44690,DS-54fb2508-e2e5-4de0-ae25-8810d783f35a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 100
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-376726653-172.17.0.18-1597647872802:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45854,DS-d036c3a8-f9ed-4d85-a088-814fce36e2e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42843,DS-58d71fee-36df-4536-ad32-2a1077324a96,DISK], DatanodeInfoWithStorage[127.0.0.1:46378,DS-463696ca-5d85-470f-b1c3-2f9f9f0aec94,DISK], DatanodeInfoWithStorage[127.0.0.1:36632,DS-f5dbfb4b-6c31-4908-ab26-a32504e112b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41617,DS-6539c273-d1b2-4559-924d-e95b73d55f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41423,DS-d52f4cb3-9173-4814-aa6c-59a0b57a1e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42334,DS-4973a707-f42f-4070-9f5b-6ca13aeb2f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43890,DS-25aaffe0-8895-46a1-ad92-af47301f4293,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-376726653-172.17.0.18-1597647872802:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45854,DS-d036c3a8-f9ed-4d85-a088-814fce36e2e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42843,DS-58d71fee-36df-4536-ad32-2a1077324a96,DISK], DatanodeInfoWithStorage[127.0.0.1:46378,DS-463696ca-5d85-470f-b1c3-2f9f9f0aec94,DISK], DatanodeInfoWithStorage[127.0.0.1:36632,DS-f5dbfb4b-6c31-4908-ab26-a32504e112b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41617,DS-6539c273-d1b2-4559-924d-e95b73d55f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41423,DS-d52f4cb3-9173-4814-aa6c-59a0b57a1e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42334,DS-4973a707-f42f-4070-9f5b-6ca13aeb2f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43890,DS-25aaffe0-8895-46a1-ad92-af47301f4293,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 100
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-790176907-172.17.0.18-1597648822457:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40368,DS-6cff81d9-700b-4906-8959-eb95078521aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41669,DS-78a404b2-f624-49ba-815b-efce1ab03877,DISK], DatanodeInfoWithStorage[127.0.0.1:44143,DS-b58038d8-b724-4f64-8ff0-59bb8cc37c49,DISK], DatanodeInfoWithStorage[127.0.0.1:37828,DS-4603be14-54bf-43a9-9e70-c97e6b95097a,DISK], DatanodeInfoWithStorage[127.0.0.1:33745,DS-9dc10824-2439-4790-bd75-9948094fb7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44583,DS-2e32befb-c2b6-4e44-8f6d-94118660925f,DISK], DatanodeInfoWithStorage[127.0.0.1:45045,DS-c33c89bd-3518-4af0-b135-5507a4907469,DISK], DatanodeInfoWithStorage[127.0.0.1:34471,DS-13052589-9349-45a8-b6f2-f2e9bbe01691,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-790176907-172.17.0.18-1597648822457:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40368,DS-6cff81d9-700b-4906-8959-eb95078521aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41669,DS-78a404b2-f624-49ba-815b-efce1ab03877,DISK], DatanodeInfoWithStorage[127.0.0.1:44143,DS-b58038d8-b724-4f64-8ff0-59bb8cc37c49,DISK], DatanodeInfoWithStorage[127.0.0.1:37828,DS-4603be14-54bf-43a9-9e70-c97e6b95097a,DISK], DatanodeInfoWithStorage[127.0.0.1:33745,DS-9dc10824-2439-4790-bd75-9948094fb7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44583,DS-2e32befb-c2b6-4e44-8f6d-94118660925f,DISK], DatanodeInfoWithStorage[127.0.0.1:45045,DS-c33c89bd-3518-4af0-b135-5507a4907469,DISK], DatanodeInfoWithStorage[127.0.0.1:34471,DS-13052589-9349-45a8-b6f2-f2e9bbe01691,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 100
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1518900014-172.17.0.18-1597649292803:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41100,DS-067597ae-52ec-4fa5-bba3-9be7d2a6a27c,DISK], DatanodeInfoWithStorage[127.0.0.1:34235,DS-69ba38ed-5e52-46a8-882a-bbe40065da8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42205,DS-228c86cf-2bef-46d5-8975-a3d4937d6d67,DISK], DatanodeInfoWithStorage[127.0.0.1:36127,DS-10126bdb-e6cd-4212-a917-e9a13cdf1cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:38795,DS-311d586e-116a-424f-9fc9-fc2335626bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:44743,DS-64739643-a918-4c2f-8ad3-c66a127fc54a,DISK], DatanodeInfoWithStorage[127.0.0.1:45597,DS-fbbb5a00-d9a7-4001-9e17-b6ef0bed0134,DISK], DatanodeInfoWithStorage[127.0.0.1:46762,DS-06753da6-9165-4ce4-acd4-787f74d4c98d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1518900014-172.17.0.18-1597649292803:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41100,DS-067597ae-52ec-4fa5-bba3-9be7d2a6a27c,DISK], DatanodeInfoWithStorage[127.0.0.1:34235,DS-69ba38ed-5e52-46a8-882a-bbe40065da8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42205,DS-228c86cf-2bef-46d5-8975-a3d4937d6d67,DISK], DatanodeInfoWithStorage[127.0.0.1:36127,DS-10126bdb-e6cd-4212-a917-e9a13cdf1cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:38795,DS-311d586e-116a-424f-9fc9-fc2335626bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:44743,DS-64739643-a918-4c2f-8ad3-c66a127fc54a,DISK], DatanodeInfoWithStorage[127.0.0.1:45597,DS-fbbb5a00-d9a7-4001-9e17-b6ef0bed0134,DISK], DatanodeInfoWithStorage[127.0.0.1:46762,DS-06753da6-9165-4ce4-acd4-787f74d4c98d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 100
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-773893785-172.17.0.18-1597649391205:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33159,DS-6ad63232-0224-4706-9cc7-0b0990703c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:33323,DS-c80849eb-9bf8-4ca4-9545-209f719476a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44852,DS-f20796ab-4185-4fae-9aa4-bce5ad70e0cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39095,DS-f45edd4c-3469-4464-af49-03ab1e823838,DISK], DatanodeInfoWithStorage[127.0.0.1:33260,DS-7e87a45a-f8a2-42fa-9e02-90ab775a4e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36659,DS-3eb6bc43-3e45-4238-b620-13ce3f6a79a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43147,DS-f6f2e4bf-30bc-44fb-84c3-3f8bb2683511,DISK], DatanodeInfoWithStorage[127.0.0.1:44292,DS-552d29e2-f301-49e8-89b8-78db82ff8d07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-773893785-172.17.0.18-1597649391205:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33159,DS-6ad63232-0224-4706-9cc7-0b0990703c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:33323,DS-c80849eb-9bf8-4ca4-9545-209f719476a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44852,DS-f20796ab-4185-4fae-9aa4-bce5ad70e0cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39095,DS-f45edd4c-3469-4464-af49-03ab1e823838,DISK], DatanodeInfoWithStorage[127.0.0.1:33260,DS-7e87a45a-f8a2-42fa-9e02-90ab775a4e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36659,DS-3eb6bc43-3e45-4238-b620-13ce3f6a79a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43147,DS-f6f2e4bf-30bc-44fb-84c3-3f8bb2683511,DISK], DatanodeInfoWithStorage[127.0.0.1:44292,DS-552d29e2-f301-49e8-89b8-78db82ff8d07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 100
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-551926194-172.17.0.18-1597649833342:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43258,DS-b764df91-eb59-4351-aa82-0fbb8f1dfe3e,DISK], DatanodeInfoWithStorage[127.0.0.1:40620,DS-e89529c6-3a29-48ee-8be9-f2e736e83fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:35265,DS-9b137adb-bea5-4b6b-b417-e9f482c8bf22,DISK], DatanodeInfoWithStorage[127.0.0.1:38540,DS-a91db107-4e7e-4e87-a7e4-1e01d9bcf454,DISK], DatanodeInfoWithStorage[127.0.0.1:33255,DS-f237c73b-63b9-45a3-b75a-d5666cda0d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40148,DS-662adab1-02a0-4dac-837a-35723a93e4ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41941,DS-6d11d374-85da-448b-b953-6674db6cc1b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36769,DS-c2ec187f-eafe-442f-b548-755a6adf4441,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-551926194-172.17.0.18-1597649833342:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43258,DS-b764df91-eb59-4351-aa82-0fbb8f1dfe3e,DISK], DatanodeInfoWithStorage[127.0.0.1:40620,DS-e89529c6-3a29-48ee-8be9-f2e736e83fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:35265,DS-9b137adb-bea5-4b6b-b417-e9f482c8bf22,DISK], DatanodeInfoWithStorage[127.0.0.1:38540,DS-a91db107-4e7e-4e87-a7e4-1e01d9bcf454,DISK], DatanodeInfoWithStorage[127.0.0.1:33255,DS-f237c73b-63b9-45a3-b75a-d5666cda0d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40148,DS-662adab1-02a0-4dac-837a-35723a93e4ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41941,DS-6d11d374-85da-448b-b953-6674db6cc1b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36769,DS-c2ec187f-eafe-442f-b548-755a6adf4441,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 100
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-8642274-172.17.0.18-1597649967204:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42522,DS-55081c9e-14db-4e0b-9723-ba5a2e0dcf22,DISK], DatanodeInfoWithStorage[127.0.0.1:35781,DS-f76e46ce-38c6-4311-944d-529cf65787f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44414,DS-ab1fcafa-2e47-4bd3-b4a3-9a9d80e2f528,DISK], DatanodeInfoWithStorage[127.0.0.1:46169,DS-2fcf9245-f489-439d-91d2-27202389b0ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38970,DS-65d727ca-6d89-49fa-b70f-d69129fa7221,DISK], DatanodeInfoWithStorage[127.0.0.1:44109,DS-bfc750ec-9ebb-457d-b1a9-4f9fe9d8d93f,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-4078e174-ca67-4f52-b5d0-c144cc316946,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-baeb0480-6a6c-4fe9-bb68-00e34d6b849e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-8642274-172.17.0.18-1597649967204:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42522,DS-55081c9e-14db-4e0b-9723-ba5a2e0dcf22,DISK], DatanodeInfoWithStorage[127.0.0.1:35781,DS-f76e46ce-38c6-4311-944d-529cf65787f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44414,DS-ab1fcafa-2e47-4bd3-b4a3-9a9d80e2f528,DISK], DatanodeInfoWithStorage[127.0.0.1:46169,DS-2fcf9245-f489-439d-91d2-27202389b0ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38970,DS-65d727ca-6d89-49fa-b70f-d69129fa7221,DISK], DatanodeInfoWithStorage[127.0.0.1:44109,DS-bfc750ec-9ebb-457d-b1a9-4f9fe9d8d93f,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-4078e174-ca67-4f52-b5d0-c144cc316946,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-baeb0480-6a6c-4fe9-bb68-00e34d6b849e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 7020
