reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 30000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 30000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1775870636-172.17.0.13-1597461754386:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34728,DS-91bdadbb-3e98-45be-abf2-82db0146d805,DISK], DatanodeInfoWithStorage[127.0.0.1:39248,DS-6f2271cb-90b6-484b-b1d5-6b5fab3e1da6,DISK], DatanodeInfoWithStorage[127.0.0.1:39557,DS-c92ea65f-7de7-4766-965d-1ac0c3b4b541,DISK], DatanodeInfoWithStorage[127.0.0.1:37181,DS-0f662f5a-c94d-440f-b0af-837cb9aa1a60,DISK], DatanodeInfoWithStorage[127.0.0.1:39806,DS-bc294772-5076-4c50-b02d-3e9a72d6af05,DISK], DatanodeInfoWithStorage[127.0.0.1:39093,DS-101e37a1-0ba4-46e4-8cdf-842715e186ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40238,DS-49c098b0-1e1e-4d93-984f-754389cc6ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:36690,DS-1e7a9284-ef6a-4a87-af83-3f6910669d53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1775870636-172.17.0.13-1597461754386:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34728,DS-91bdadbb-3e98-45be-abf2-82db0146d805,DISK], DatanodeInfoWithStorage[127.0.0.1:39248,DS-6f2271cb-90b6-484b-b1d5-6b5fab3e1da6,DISK], DatanodeInfoWithStorage[127.0.0.1:39557,DS-c92ea65f-7de7-4766-965d-1ac0c3b4b541,DISK], DatanodeInfoWithStorage[127.0.0.1:37181,DS-0f662f5a-c94d-440f-b0af-837cb9aa1a60,DISK], DatanodeInfoWithStorage[127.0.0.1:39806,DS-bc294772-5076-4c50-b02d-3e9a72d6af05,DISK], DatanodeInfoWithStorage[127.0.0.1:39093,DS-101e37a1-0ba4-46e4-8cdf-842715e186ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40238,DS-49c098b0-1e1e-4d93-984f-754389cc6ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:36690,DS-1e7a9284-ef6a-4a87-af83-3f6910669d53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 30000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-836067662-172.17.0.13-1597462357313:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33404,DS-d99a5ee7-2fc7-4ab9-a778-471be33d661e,DISK], DatanodeInfoWithStorage[127.0.0.1:44374,DS-25a18660-d7b0-4c81-a061-7b794bdb3919,DISK], DatanodeInfoWithStorage[127.0.0.1:40791,DS-3b7af1fc-3f0b-41f3-9b78-0b0e5329749a,DISK], DatanodeInfoWithStorage[127.0.0.1:43808,DS-00cf878c-d04a-4286-8ada-064196d111dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41292,DS-9af5cb17-6234-4cd0-bab1-21548eb4341e,DISK], DatanodeInfoWithStorage[127.0.0.1:46277,DS-0dc02427-d9a1-4f58-b079-89a5072a1867,DISK], DatanodeInfoWithStorage[127.0.0.1:33365,DS-942c056c-ce09-4da0-b042-ed9beecb8beb,DISK], DatanodeInfoWithStorage[127.0.0.1:34523,DS-3f52d718-da07-437c-aadf-e3385b5c7221,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-836067662-172.17.0.13-1597462357313:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33404,DS-d99a5ee7-2fc7-4ab9-a778-471be33d661e,DISK], DatanodeInfoWithStorage[127.0.0.1:44374,DS-25a18660-d7b0-4c81-a061-7b794bdb3919,DISK], DatanodeInfoWithStorage[127.0.0.1:40791,DS-3b7af1fc-3f0b-41f3-9b78-0b0e5329749a,DISK], DatanodeInfoWithStorage[127.0.0.1:43808,DS-00cf878c-d04a-4286-8ada-064196d111dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41292,DS-9af5cb17-6234-4cd0-bab1-21548eb4341e,DISK], DatanodeInfoWithStorage[127.0.0.1:46277,DS-0dc02427-d9a1-4f58-b079-89a5072a1867,DISK], DatanodeInfoWithStorage[127.0.0.1:33365,DS-942c056c-ce09-4da0-b042-ed9beecb8beb,DISK], DatanodeInfoWithStorage[127.0.0.1:34523,DS-3f52d718-da07-437c-aadf-e3385b5c7221,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 30000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1768191403-172.17.0.13-1597463089780:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33824,DS-caa3d64e-a2f9-4e85-a884-c232f42b44bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33273,DS-896ee2cc-6957-4615-8668-d682cfd13f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:44671,DS-ac5de6a8-fbe5-4fc3-a4de-a4ef5a818790,DISK], DatanodeInfoWithStorage[127.0.0.1:46826,DS-e8e312fb-c320-46b1-8e5e-8131dd3a8aca,DISK], DatanodeInfoWithStorage[127.0.0.1:41196,DS-eb5c21ac-72cc-4546-8fd7-95f40b9bb4dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-84cf2adf-d956-4c16-b5ab-d111e3aabdfd,DISK], DatanodeInfoWithStorage[127.0.0.1:39805,DS-b5fe8b20-c433-4621-969d-c2b984da2075,DISK], DatanodeInfoWithStorage[127.0.0.1:43008,DS-af11a12f-4c9e-403f-8573-901b322e35a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1768191403-172.17.0.13-1597463089780:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33824,DS-caa3d64e-a2f9-4e85-a884-c232f42b44bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33273,DS-896ee2cc-6957-4615-8668-d682cfd13f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:44671,DS-ac5de6a8-fbe5-4fc3-a4de-a4ef5a818790,DISK], DatanodeInfoWithStorage[127.0.0.1:46826,DS-e8e312fb-c320-46b1-8e5e-8131dd3a8aca,DISK], DatanodeInfoWithStorage[127.0.0.1:41196,DS-eb5c21ac-72cc-4546-8fd7-95f40b9bb4dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-84cf2adf-d956-4c16-b5ab-d111e3aabdfd,DISK], DatanodeInfoWithStorage[127.0.0.1:39805,DS-b5fe8b20-c433-4621-969d-c2b984da2075,DISK], DatanodeInfoWithStorage[127.0.0.1:43008,DS-af11a12f-4c9e-403f-8573-901b322e35a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 30000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-184234628-172.17.0.13-1597463550295:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41420,DS-40e3b288-c740-4680-8deb-c3a2764078bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42266,DS-2f68354c-9d0b-4d32-8093-63e8643d1160,DISK], DatanodeInfoWithStorage[127.0.0.1:41272,DS-cc244729-0c02-4fc4-bee6-7607c751849d,DISK], DatanodeInfoWithStorage[127.0.0.1:34320,DS-f808cf14-acae-43b4-91ae-2ebe71097c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35039,DS-e9c0917a-1496-4051-b551-fd0902eca91f,DISK], DatanodeInfoWithStorage[127.0.0.1:44332,DS-38cdafa9-3b1f-454b-a97e-7926ee89e6c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44841,DS-8a3982ba-93c1-49c6-a3af-8f50434ca829,DISK], DatanodeInfoWithStorage[127.0.0.1:42840,DS-9ee06937-cf4b-4337-85f3-8d881ce43b47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-184234628-172.17.0.13-1597463550295:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41420,DS-40e3b288-c740-4680-8deb-c3a2764078bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42266,DS-2f68354c-9d0b-4d32-8093-63e8643d1160,DISK], DatanodeInfoWithStorage[127.0.0.1:41272,DS-cc244729-0c02-4fc4-bee6-7607c751849d,DISK], DatanodeInfoWithStorage[127.0.0.1:34320,DS-f808cf14-acae-43b4-91ae-2ebe71097c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35039,DS-e9c0917a-1496-4051-b551-fd0902eca91f,DISK], DatanodeInfoWithStorage[127.0.0.1:44332,DS-38cdafa9-3b1f-454b-a97e-7926ee89e6c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44841,DS-8a3982ba-93c1-49c6-a3af-8f50434ca829,DISK], DatanodeInfoWithStorage[127.0.0.1:42840,DS-9ee06937-cf4b-4337-85f3-8d881ce43b47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 30000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-415003925-172.17.0.13-1597463657242:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42659,DS-68599c8f-435b-4014-911a-670cb2ef30be,DISK], DatanodeInfoWithStorage[127.0.0.1:38443,DS-7e9bda6d-87b9-4800-ab5b-8843ea541b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38243,DS-fced2a62-2c6d-436d-a52b-5372c9686757,DISK], DatanodeInfoWithStorage[127.0.0.1:34851,DS-d0876e4b-897c-41c2-bf5e-8e4f9d79baa3,DISK], DatanodeInfoWithStorage[127.0.0.1:38383,DS-7e11e3f8-c27a-4c6a-aa18-9081e4b3abb5,DISK], DatanodeInfoWithStorage[127.0.0.1:45889,DS-a68ee1ee-79d5-413b-90c7-cf1da160cb20,DISK], DatanodeInfoWithStorage[127.0.0.1:43546,DS-468becba-0a4f-46d3-b96b-f87f5787aba3,DISK], DatanodeInfoWithStorage[127.0.0.1:43482,DS-3c96d762-2ca9-4a5f-a2bd-17f6b2dac72d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-415003925-172.17.0.13-1597463657242:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42659,DS-68599c8f-435b-4014-911a-670cb2ef30be,DISK], DatanodeInfoWithStorage[127.0.0.1:38443,DS-7e9bda6d-87b9-4800-ab5b-8843ea541b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38243,DS-fced2a62-2c6d-436d-a52b-5372c9686757,DISK], DatanodeInfoWithStorage[127.0.0.1:34851,DS-d0876e4b-897c-41c2-bf5e-8e4f9d79baa3,DISK], DatanodeInfoWithStorage[127.0.0.1:38383,DS-7e11e3f8-c27a-4c6a-aa18-9081e4b3abb5,DISK], DatanodeInfoWithStorage[127.0.0.1:45889,DS-a68ee1ee-79d5-413b-90c7-cf1da160cb20,DISK], DatanodeInfoWithStorage[127.0.0.1:43546,DS-468becba-0a4f-46d3-b96b-f87f5787aba3,DISK], DatanodeInfoWithStorage[127.0.0.1:43482,DS-3c96d762-2ca9-4a5f-a2bd-17f6b2dac72d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 30000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-126688081-172.17.0.13-1597463693545:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44639,DS-9b26b0c5-6465-4f46-9f7d-8e2c1aacb05d,DISK], DatanodeInfoWithStorage[127.0.0.1:40213,DS-26cd11e4-c94c-4947-9f7e-ccac0a2d7f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:33671,DS-0289f0fa-0cfa-41d7-bc94-76bf37bbffb1,DISK], DatanodeInfoWithStorage[127.0.0.1:45393,DS-99e53d50-2c0c-45ec-8380-ad79a921cac0,DISK], DatanodeInfoWithStorage[127.0.0.1:43845,DS-bba32fe9-68f5-4f6e-a4a0-1462f2705443,DISK], DatanodeInfoWithStorage[127.0.0.1:45427,DS-4874a077-74cf-4fb5-a7bf-8746090f2361,DISK], DatanodeInfoWithStorage[127.0.0.1:35462,DS-d5713e58-f4cf-483f-8dff-4f5c2c9032eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45034,DS-da4f55e5-79c5-4ec3-9a47-c4279917d0a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-126688081-172.17.0.13-1597463693545:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44639,DS-9b26b0c5-6465-4f46-9f7d-8e2c1aacb05d,DISK], DatanodeInfoWithStorage[127.0.0.1:40213,DS-26cd11e4-c94c-4947-9f7e-ccac0a2d7f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:33671,DS-0289f0fa-0cfa-41d7-bc94-76bf37bbffb1,DISK], DatanodeInfoWithStorage[127.0.0.1:45393,DS-99e53d50-2c0c-45ec-8380-ad79a921cac0,DISK], DatanodeInfoWithStorage[127.0.0.1:43845,DS-bba32fe9-68f5-4f6e-a4a0-1462f2705443,DISK], DatanodeInfoWithStorage[127.0.0.1:45427,DS-4874a077-74cf-4fb5-a7bf-8746090f2361,DISK], DatanodeInfoWithStorage[127.0.0.1:35462,DS-d5713e58-f4cf-483f-8dff-4f5c2c9032eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45034,DS-da4f55e5-79c5-4ec3-9a47-c4279917d0a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 30000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1684471968-172.17.0.13-1597463729275:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42203,DS-d14c4323-ab1c-4093-9813-634fdf44de40,DISK], DatanodeInfoWithStorage[127.0.0.1:35994,DS-565187df-fecd-4931-818a-e3884254900a,DISK], DatanodeInfoWithStorage[127.0.0.1:43607,DS-f7a62534-6882-4644-b954-789b8dac9af9,DISK], DatanodeInfoWithStorage[127.0.0.1:35636,DS-45ca8ec6-1d4c-4d89-922d-c2655eb84fff,DISK], DatanodeInfoWithStorage[127.0.0.1:43509,DS-47d5adff-cd56-4a5d-9603-97984d8fce78,DISK], DatanodeInfoWithStorage[127.0.0.1:34302,DS-0336cc1f-c65e-4a61-9ced-0d7b1980462b,DISK], DatanodeInfoWithStorage[127.0.0.1:43152,DS-fb0ced21-160d-4c2f-8889-a8f693985568,DISK], DatanodeInfoWithStorage[127.0.0.1:45474,DS-7280c1b9-fb22-435a-b88e-c9c293bfd426,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1684471968-172.17.0.13-1597463729275:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42203,DS-d14c4323-ab1c-4093-9813-634fdf44de40,DISK], DatanodeInfoWithStorage[127.0.0.1:35994,DS-565187df-fecd-4931-818a-e3884254900a,DISK], DatanodeInfoWithStorage[127.0.0.1:43607,DS-f7a62534-6882-4644-b954-789b8dac9af9,DISK], DatanodeInfoWithStorage[127.0.0.1:35636,DS-45ca8ec6-1d4c-4d89-922d-c2655eb84fff,DISK], DatanodeInfoWithStorage[127.0.0.1:43509,DS-47d5adff-cd56-4a5d-9603-97984d8fce78,DISK], DatanodeInfoWithStorage[127.0.0.1:34302,DS-0336cc1f-c65e-4a61-9ced-0d7b1980462b,DISK], DatanodeInfoWithStorage[127.0.0.1:43152,DS-fb0ced21-160d-4c2f-8889-a8f693985568,DISK], DatanodeInfoWithStorage[127.0.0.1:45474,DS-7280c1b9-fb22-435a-b88e-c9c293bfd426,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 30000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-247367222-172.17.0.13-1597463835021:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38651,DS-e441fb0a-a494-4af9-aecd-b6c2940d464d,DISK], DatanodeInfoWithStorage[127.0.0.1:36437,DS-407ef5a7-d153-4564-b24a-aa7fca84b0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39666,DS-cb52ee14-561a-406d-bcbc-89685132c26d,DISK], DatanodeInfoWithStorage[127.0.0.1:41119,DS-dc8d51d2-7c21-4d66-ad03-3bf67119ec23,DISK], DatanodeInfoWithStorage[127.0.0.1:39335,DS-0a00cefe-4ad7-49cf-adb8-c74e71fbb75a,DISK], DatanodeInfoWithStorage[127.0.0.1:44972,DS-ed5b3787-34e8-49ea-8e9c-2d9a291a8128,DISK], DatanodeInfoWithStorage[127.0.0.1:43339,DS-11b92175-5b1b-4f64-b354-a2036e3cd683,DISK], DatanodeInfoWithStorage[127.0.0.1:43045,DS-7176f8c4-52e6-4624-b3ca-da5239f98006,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-247367222-172.17.0.13-1597463835021:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38651,DS-e441fb0a-a494-4af9-aecd-b6c2940d464d,DISK], DatanodeInfoWithStorage[127.0.0.1:36437,DS-407ef5a7-d153-4564-b24a-aa7fca84b0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39666,DS-cb52ee14-561a-406d-bcbc-89685132c26d,DISK], DatanodeInfoWithStorage[127.0.0.1:41119,DS-dc8d51d2-7c21-4d66-ad03-3bf67119ec23,DISK], DatanodeInfoWithStorage[127.0.0.1:39335,DS-0a00cefe-4ad7-49cf-adb8-c74e71fbb75a,DISK], DatanodeInfoWithStorage[127.0.0.1:44972,DS-ed5b3787-34e8-49ea-8e9c-2d9a291a8128,DISK], DatanodeInfoWithStorage[127.0.0.1:43339,DS-11b92175-5b1b-4f64-b354-a2036e3cd683,DISK], DatanodeInfoWithStorage[127.0.0.1:43045,DS-7176f8c4-52e6-4624-b3ca-da5239f98006,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 30000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1263323728-172.17.0.13-1597464325373:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42224,DS-9c58ff14-16ef-4ec1-b455-2c9cfc4c3c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37056,DS-01654686-0814-42da-b875-ff47925d2686,DISK], DatanodeInfoWithStorage[127.0.0.1:45341,DS-2cf034ae-93e3-418f-bef2-d77c55f91a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:39592,DS-05a138a7-fa55-41b3-a310-081bcf4cb9cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-3704af77-2ec9-4f2f-b503-d0a601894c31,DISK], DatanodeInfoWithStorage[127.0.0.1:45478,DS-ce2ca932-ea49-4e23-a319-631b8104eb11,DISK], DatanodeInfoWithStorage[127.0.0.1:37980,DS-50e4d5ab-f0b7-4b6c-88b7-b3b18825ef49,DISK], DatanodeInfoWithStorage[127.0.0.1:36630,DS-3a79a6d1-e4e7-4fca-9074-661b931c86ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1263323728-172.17.0.13-1597464325373:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42224,DS-9c58ff14-16ef-4ec1-b455-2c9cfc4c3c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37056,DS-01654686-0814-42da-b875-ff47925d2686,DISK], DatanodeInfoWithStorage[127.0.0.1:45341,DS-2cf034ae-93e3-418f-bef2-d77c55f91a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:39592,DS-05a138a7-fa55-41b3-a310-081bcf4cb9cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-3704af77-2ec9-4f2f-b503-d0a601894c31,DISK], DatanodeInfoWithStorage[127.0.0.1:45478,DS-ce2ca932-ea49-4e23-a319-631b8104eb11,DISK], DatanodeInfoWithStorage[127.0.0.1:37980,DS-50e4d5ab-f0b7-4b6c-88b7-b3b18825ef49,DISK], DatanodeInfoWithStorage[127.0.0.1:36630,DS-3a79a6d1-e4e7-4fca-9074-661b931c86ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 30000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-143933348-172.17.0.13-1597464493385:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35066,DS-1cf9620a-8a05-41f9-89da-00682be9f5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34999,DS-ada7bf41-9d2d-4ae1-b83a-9542714a5383,DISK], DatanodeInfoWithStorage[127.0.0.1:35189,DS-f1b01399-3f0a-44c9-8845-00634e18e74a,DISK], DatanodeInfoWithStorage[127.0.0.1:41787,DS-805b0315-b8fd-4d54-9ff4-aca7d02c0d29,DISK], DatanodeInfoWithStorage[127.0.0.1:45949,DS-36008140-29ba-4431-96b3-8d0424c69ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:43648,DS-df3ef4d7-f583-45bb-a5d0-94ebf0601840,DISK], DatanodeInfoWithStorage[127.0.0.1:39286,DS-647af911-4152-47a9-8022-463e91ed038a,DISK], DatanodeInfoWithStorage[127.0.0.1:36012,DS-c2117233-c9cd-4c07-a0e3-51b66f03514b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-143933348-172.17.0.13-1597464493385:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35066,DS-1cf9620a-8a05-41f9-89da-00682be9f5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34999,DS-ada7bf41-9d2d-4ae1-b83a-9542714a5383,DISK], DatanodeInfoWithStorage[127.0.0.1:35189,DS-f1b01399-3f0a-44c9-8845-00634e18e74a,DISK], DatanodeInfoWithStorage[127.0.0.1:41787,DS-805b0315-b8fd-4d54-9ff4-aca7d02c0d29,DISK], DatanodeInfoWithStorage[127.0.0.1:45949,DS-36008140-29ba-4431-96b3-8d0424c69ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:43648,DS-df3ef4d7-f583-45bb-a5d0-94ebf0601840,DISK], DatanodeInfoWithStorage[127.0.0.1:39286,DS-647af911-4152-47a9-8022-463e91ed038a,DISK], DatanodeInfoWithStorage[127.0.0.1:36012,DS-c2117233-c9cd-4c07-a0e3-51b66f03514b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 30000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1169347798-172.17.0.13-1597464641066:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46611,DS-69e79240-48b3-4452-aba4-f558f526eb3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40886,DS-5c0068bb-2fba-4ae1-85d3-359a49d2cbd7,DISK], DatanodeInfoWithStorage[127.0.0.1:40121,DS-15c30167-cdda-4e8b-b571-e30e6898ff6a,DISK], DatanodeInfoWithStorage[127.0.0.1:36644,DS-679fa052-8a79-477a-b8e6-eebd38101c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:46340,DS-37cb07d4-da9f-40ec-a083-2056fe90c390,DISK], DatanodeInfoWithStorage[127.0.0.1:38665,DS-ac9933e9-a85a-4677-b08a-919929533e90,DISK], DatanodeInfoWithStorage[127.0.0.1:38064,DS-cd8928a4-b88b-469b-bbe4-4084fc25f125,DISK], DatanodeInfoWithStorage[127.0.0.1:44791,DS-ff7910b0-8aaa-4bbf-8965-c2a2cee19cac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1169347798-172.17.0.13-1597464641066:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46611,DS-69e79240-48b3-4452-aba4-f558f526eb3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40886,DS-5c0068bb-2fba-4ae1-85d3-359a49d2cbd7,DISK], DatanodeInfoWithStorage[127.0.0.1:40121,DS-15c30167-cdda-4e8b-b571-e30e6898ff6a,DISK], DatanodeInfoWithStorage[127.0.0.1:36644,DS-679fa052-8a79-477a-b8e6-eebd38101c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:46340,DS-37cb07d4-da9f-40ec-a083-2056fe90c390,DISK], DatanodeInfoWithStorage[127.0.0.1:38665,DS-ac9933e9-a85a-4677-b08a-919929533e90,DISK], DatanodeInfoWithStorage[127.0.0.1:38064,DS-cd8928a4-b88b-469b-bbe4-4084fc25f125,DISK], DatanodeInfoWithStorage[127.0.0.1:44791,DS-ff7910b0-8aaa-4bbf-8965-c2a2cee19cac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 30000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-845921949-172.17.0.13-1597464724073:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39434,DS-15d85583-df5c-4a79-b209-857f0df2c31a,DISK], DatanodeInfoWithStorage[127.0.0.1:44893,DS-f1016281-13f8-4c6e-83de-181d7071e927,DISK], DatanodeInfoWithStorage[127.0.0.1:36338,DS-5f2d83d8-c890-41b8-a048-ad36b7c520b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45652,DS-7e2e638c-b89a-496c-a8ca-32aa1b533852,DISK], DatanodeInfoWithStorage[127.0.0.1:46130,DS-dca35a22-62e7-41bf-a05c-531318988ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:37867,DS-a518ab54-e979-4f92-bf42-ffdb72a57c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36797,DS-e533b8f2-70ec-46df-a864-faf40a830b63,DISK], DatanodeInfoWithStorage[127.0.0.1:44330,DS-ba278c78-3b45-483c-8d8c-428ce542356e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-845921949-172.17.0.13-1597464724073:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39434,DS-15d85583-df5c-4a79-b209-857f0df2c31a,DISK], DatanodeInfoWithStorage[127.0.0.1:44893,DS-f1016281-13f8-4c6e-83de-181d7071e927,DISK], DatanodeInfoWithStorage[127.0.0.1:36338,DS-5f2d83d8-c890-41b8-a048-ad36b7c520b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45652,DS-7e2e638c-b89a-496c-a8ca-32aa1b533852,DISK], DatanodeInfoWithStorage[127.0.0.1:46130,DS-dca35a22-62e7-41bf-a05c-531318988ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:37867,DS-a518ab54-e979-4f92-bf42-ffdb72a57c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36797,DS-e533b8f2-70ec-46df-a864-faf40a830b63,DISK], DatanodeInfoWithStorage[127.0.0.1:44330,DS-ba278c78-3b45-483c-8d8c-428ce542356e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 30000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-136264820-172.17.0.13-1597464825125:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38497,DS-56d14e78-991b-4006-9f48-c8aef99eb555,DISK], DatanodeInfoWithStorage[127.0.0.1:33999,DS-b546bf79-cc84-48f8-943a-29c43232b49e,DISK], DatanodeInfoWithStorage[127.0.0.1:46025,DS-7ec7097b-5c31-4875-a9c3-e2e0da2d43ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38810,DS-ade19010-88dd-4e08-a245-534652b7c463,DISK], DatanodeInfoWithStorage[127.0.0.1:44708,DS-2287c3a1-53ec-4df9-819e-3cfaaecec7ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33120,DS-eef4c9e9-eab4-475e-b1e2-88ca1d86aa4e,DISK], DatanodeInfoWithStorage[127.0.0.1:46723,DS-71598208-0836-48d5-a00b-ba60491337b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38684,DS-d103649a-f089-42c7-9ddf-33dd8bdc4544,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-136264820-172.17.0.13-1597464825125:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38497,DS-56d14e78-991b-4006-9f48-c8aef99eb555,DISK], DatanodeInfoWithStorage[127.0.0.1:33999,DS-b546bf79-cc84-48f8-943a-29c43232b49e,DISK], DatanodeInfoWithStorage[127.0.0.1:46025,DS-7ec7097b-5c31-4875-a9c3-e2e0da2d43ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38810,DS-ade19010-88dd-4e08-a245-534652b7c463,DISK], DatanodeInfoWithStorage[127.0.0.1:44708,DS-2287c3a1-53ec-4df9-819e-3cfaaecec7ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33120,DS-eef4c9e9-eab4-475e-b1e2-88ca1d86aa4e,DISK], DatanodeInfoWithStorage[127.0.0.1:46723,DS-71598208-0836-48d5-a00b-ba60491337b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38684,DS-d103649a-f089-42c7-9ddf-33dd8bdc4544,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 30000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2099699454-172.17.0.13-1597465073781:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37282,DS-58c38b7b-6215-49e9-af59-5cdb225f28a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45972,DS-6696bd9f-bf77-49a8-ac07-8bcc8fdcbd35,DISK], DatanodeInfoWithStorage[127.0.0.1:34508,DS-1c4a8500-d56b-4d69-9a36-4408da1cf5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45345,DS-575793f4-c3e6-44c5-aa42-ae01499a6230,DISK], DatanodeInfoWithStorage[127.0.0.1:45396,DS-0a090dda-2745-4e91-b68f-e51585523f12,DISK], DatanodeInfoWithStorage[127.0.0.1:34990,DS-d0056f32-30ce-4df5-93af-9b576d01e9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34647,DS-9fa8233e-30c8-4fa0-91e1-bd4c73c2f7a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46312,DS-ebced6b2-65f7-4ccb-9807-ee0495cbf432,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2099699454-172.17.0.13-1597465073781:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37282,DS-58c38b7b-6215-49e9-af59-5cdb225f28a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45972,DS-6696bd9f-bf77-49a8-ac07-8bcc8fdcbd35,DISK], DatanodeInfoWithStorage[127.0.0.1:34508,DS-1c4a8500-d56b-4d69-9a36-4408da1cf5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45345,DS-575793f4-c3e6-44c5-aa42-ae01499a6230,DISK], DatanodeInfoWithStorage[127.0.0.1:45396,DS-0a090dda-2745-4e91-b68f-e51585523f12,DISK], DatanodeInfoWithStorage[127.0.0.1:34990,DS-d0056f32-30ce-4df5-93af-9b576d01e9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34647,DS-9fa8233e-30c8-4fa0-91e1-bd4c73c2f7a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46312,DS-ebced6b2-65f7-4ccb-9807-ee0495cbf432,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 30000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2003352086-172.17.0.13-1597465149464:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44105,DS-5adadc57-54c8-4323-b50a-ff957c6a2f50,DISK], DatanodeInfoWithStorage[127.0.0.1:43680,DS-5750f283-c5c1-4490-ae58-a7205cab1318,DISK], DatanodeInfoWithStorage[127.0.0.1:46314,DS-4e279449-b8e9-46ae-81c1-9c710be46e63,DISK], DatanodeInfoWithStorage[127.0.0.1:34314,DS-866dda17-f37e-4fc9-961f-9381960a70e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43441,DS-337fbb5a-e0b6-4297-b87e-311438e68077,DISK], DatanodeInfoWithStorage[127.0.0.1:45176,DS-b634a48c-20bb-4bcb-b42b-84afbf87a953,DISK], DatanodeInfoWithStorage[127.0.0.1:38840,DS-25f44736-4202-4d4c-b9fb-e5baf6a380c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33691,DS-8779f689-e751-410e-a1bf-09420ffc1039,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2003352086-172.17.0.13-1597465149464:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44105,DS-5adadc57-54c8-4323-b50a-ff957c6a2f50,DISK], DatanodeInfoWithStorage[127.0.0.1:43680,DS-5750f283-c5c1-4490-ae58-a7205cab1318,DISK], DatanodeInfoWithStorage[127.0.0.1:46314,DS-4e279449-b8e9-46ae-81c1-9c710be46e63,DISK], DatanodeInfoWithStorage[127.0.0.1:34314,DS-866dda17-f37e-4fc9-961f-9381960a70e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43441,DS-337fbb5a-e0b6-4297-b87e-311438e68077,DISK], DatanodeInfoWithStorage[127.0.0.1:45176,DS-b634a48c-20bb-4bcb-b42b-84afbf87a953,DISK], DatanodeInfoWithStorage[127.0.0.1:38840,DS-25f44736-4202-4d4c-b9fb-e5baf6a380c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33691,DS-8779f689-e751-410e-a1bf-09420ffc1039,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 30000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2049535661-172.17.0.13-1597465606888:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41974,DS-9b378dc6-630e-4167-96dd-ed70b4331572,DISK], DatanodeInfoWithStorage[127.0.0.1:42407,DS-571519ce-aa59-4633-a256-f78afb870386,DISK], DatanodeInfoWithStorage[127.0.0.1:44520,DS-342a4c38-ca1f-4446-84c8-0c1a5828c4f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36041,DS-7778630d-a30b-423f-a1e4-d6b14b936ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:33335,DS-b4026646-96e9-496d-ba6f-6d9cfd6f202a,DISK], DatanodeInfoWithStorage[127.0.0.1:46744,DS-578498f6-675e-4107-9d1b-70181dc7c26e,DISK], DatanodeInfoWithStorage[127.0.0.1:38605,DS-37fefd6e-0d14-4cae-9f78-cbd523b26541,DISK], DatanodeInfoWithStorage[127.0.0.1:39547,DS-33ce347f-b3fb-4cd0-8c60-a332ff256f8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2049535661-172.17.0.13-1597465606888:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41974,DS-9b378dc6-630e-4167-96dd-ed70b4331572,DISK], DatanodeInfoWithStorage[127.0.0.1:42407,DS-571519ce-aa59-4633-a256-f78afb870386,DISK], DatanodeInfoWithStorage[127.0.0.1:44520,DS-342a4c38-ca1f-4446-84c8-0c1a5828c4f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36041,DS-7778630d-a30b-423f-a1e4-d6b14b936ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:33335,DS-b4026646-96e9-496d-ba6f-6d9cfd6f202a,DISK], DatanodeInfoWithStorage[127.0.0.1:46744,DS-578498f6-675e-4107-9d1b-70181dc7c26e,DISK], DatanodeInfoWithStorage[127.0.0.1:38605,DS-37fefd6e-0d14-4cae-9f78-cbd523b26541,DISK], DatanodeInfoWithStorage[127.0.0.1:39547,DS-33ce347f-b3fb-4cd0-8c60-a332ff256f8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 30000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1477340951-172.17.0.13-1597465883595:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45489,DS-8f3a2ce8-19df-4e6c-a99a-88ab37096e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:43493,DS-9e2b3512-12c8-4b85-a923-0899858c7cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:45312,DS-32b80bd1-0b8a-4217-ae9d-14326dbcc70d,DISK], DatanodeInfoWithStorage[127.0.0.1:39080,DS-10593ea0-c044-496f-b827-dd6a2ba854f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36470,DS-7c15dfcd-b45f-4e84-90c0-8245796acbe1,DISK], DatanodeInfoWithStorage[127.0.0.1:38202,DS-41749201-8c69-4709-8eca-94ab3f482a88,DISK], DatanodeInfoWithStorage[127.0.0.1:39434,DS-349a8725-6ade-4ffa-af5c-c2b1eb1ebe79,DISK], DatanodeInfoWithStorage[127.0.0.1:40845,DS-9ddd4cab-c7df-4d43-89d4-a07cdc7659a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1477340951-172.17.0.13-1597465883595:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45489,DS-8f3a2ce8-19df-4e6c-a99a-88ab37096e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:43493,DS-9e2b3512-12c8-4b85-a923-0899858c7cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:45312,DS-32b80bd1-0b8a-4217-ae9d-14326dbcc70d,DISK], DatanodeInfoWithStorage[127.0.0.1:39080,DS-10593ea0-c044-496f-b827-dd6a2ba854f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36470,DS-7c15dfcd-b45f-4e84-90c0-8245796acbe1,DISK], DatanodeInfoWithStorage[127.0.0.1:38202,DS-41749201-8c69-4709-8eca-94ab3f482a88,DISK], DatanodeInfoWithStorage[127.0.0.1:39434,DS-349a8725-6ade-4ffa-af5c-c2b1eb1ebe79,DISK], DatanodeInfoWithStorage[127.0.0.1:40845,DS-9ddd4cab-c7df-4d43-89d4-a07cdc7659a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 30000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-503143314-172.17.0.13-1597465991698:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45931,DS-4b76d01e-4f1c-49b4-9217-f9aada371b90,DISK], DatanodeInfoWithStorage[127.0.0.1:36467,DS-73aca795-880e-4891-b0ba-dec1a683b1da,DISK], DatanodeInfoWithStorage[127.0.0.1:46356,DS-d4917f57-20fa-4c06-93b4-39d6e32fb225,DISK], DatanodeInfoWithStorage[127.0.0.1:44475,DS-3bc374ee-241c-4088-8990-699d52f8a945,DISK], DatanodeInfoWithStorage[127.0.0.1:34310,DS-682d4d31-aa03-47b7-8642-b0e6aed17294,DISK], DatanodeInfoWithStorage[127.0.0.1:40045,DS-74681131-072c-45a5-8fb2-8235a8587d44,DISK], DatanodeInfoWithStorage[127.0.0.1:33141,DS-b9f0bd83-a47c-41fc-9fb4-470e0e85f510,DISK], DatanodeInfoWithStorage[127.0.0.1:35181,DS-01d589cc-5347-4a88-bb9b-fc3df56149bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-503143314-172.17.0.13-1597465991698:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45931,DS-4b76d01e-4f1c-49b4-9217-f9aada371b90,DISK], DatanodeInfoWithStorage[127.0.0.1:36467,DS-73aca795-880e-4891-b0ba-dec1a683b1da,DISK], DatanodeInfoWithStorage[127.0.0.1:46356,DS-d4917f57-20fa-4c06-93b4-39d6e32fb225,DISK], DatanodeInfoWithStorage[127.0.0.1:44475,DS-3bc374ee-241c-4088-8990-699d52f8a945,DISK], DatanodeInfoWithStorage[127.0.0.1:34310,DS-682d4d31-aa03-47b7-8642-b0e6aed17294,DISK], DatanodeInfoWithStorage[127.0.0.1:40045,DS-74681131-072c-45a5-8fb2-8235a8587d44,DISK], DatanodeInfoWithStorage[127.0.0.1:33141,DS-b9f0bd83-a47c-41fc-9fb4-470e0e85f510,DISK], DatanodeInfoWithStorage[127.0.0.1:35181,DS-01d589cc-5347-4a88-bb9b-fc3df56149bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 30000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-390404999-172.17.0.13-1597466170544:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43643,DS-0e7e1c53-9a04-4e58-9b07-ad9601e11e47,DISK], DatanodeInfoWithStorage[127.0.0.1:37263,DS-b4f56b03-9af3-4ece-886e-296602bcd3a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36140,DS-16adfeb8-60c5-47b7-9ad6-d76c4d81aa94,DISK], DatanodeInfoWithStorage[127.0.0.1:34366,DS-959092ac-7ff9-4dad-805e-8b29173df246,DISK], DatanodeInfoWithStorage[127.0.0.1:34554,DS-94f7ab8f-010c-4f0a-a9dc-1acd652960ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34158,DS-57e7a75f-cb8f-45de-9a1b-f717b172c15f,DISK], DatanodeInfoWithStorage[127.0.0.1:45525,DS-b50a179e-a2df-4fb3-9bd5-424811167aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:38479,DS-b761c0a0-91f3-4550-a5e7-7819cc1e7723,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-390404999-172.17.0.13-1597466170544:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43643,DS-0e7e1c53-9a04-4e58-9b07-ad9601e11e47,DISK], DatanodeInfoWithStorage[127.0.0.1:37263,DS-b4f56b03-9af3-4ece-886e-296602bcd3a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36140,DS-16adfeb8-60c5-47b7-9ad6-d76c4d81aa94,DISK], DatanodeInfoWithStorage[127.0.0.1:34366,DS-959092ac-7ff9-4dad-805e-8b29173df246,DISK], DatanodeInfoWithStorage[127.0.0.1:34554,DS-94f7ab8f-010c-4f0a-a9dc-1acd652960ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34158,DS-57e7a75f-cb8f-45de-9a1b-f717b172c15f,DISK], DatanodeInfoWithStorage[127.0.0.1:45525,DS-b50a179e-a2df-4fb3-9bd5-424811167aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:38479,DS-b761c0a0-91f3-4550-a5e7-7819cc1e7723,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 30000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-906143297-172.17.0.13-1597466394658:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36026,DS-892d39a9-a6d6-473a-8da6-1ed99b228c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:42964,DS-9fd65814-29da-4137-8b15-87eaea565953,DISK], DatanodeInfoWithStorage[127.0.0.1:39491,DS-9a60adc9-f0eb-4e32-81ff-0eeb61bb51f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35573,DS-00523d3f-d6e5-4018-8edc-c91a9ebc1bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:41749,DS-3d615605-e37b-4979-a4b4-005765d8a255,DISK], DatanodeInfoWithStorage[127.0.0.1:33525,DS-2a374dc1-1133-44c0-bdb3-fb872cae3b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:36300,DS-ef0f0b3f-623f-4bc3-82c8-74819459a03d,DISK], DatanodeInfoWithStorage[127.0.0.1:37987,DS-3b4a24b3-c47a-459e-8ff3-efe09f4192cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-906143297-172.17.0.13-1597466394658:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36026,DS-892d39a9-a6d6-473a-8da6-1ed99b228c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:42964,DS-9fd65814-29da-4137-8b15-87eaea565953,DISK], DatanodeInfoWithStorage[127.0.0.1:39491,DS-9a60adc9-f0eb-4e32-81ff-0eeb61bb51f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35573,DS-00523d3f-d6e5-4018-8edc-c91a9ebc1bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:41749,DS-3d615605-e37b-4979-a4b4-005765d8a255,DISK], DatanodeInfoWithStorage[127.0.0.1:33525,DS-2a374dc1-1133-44c0-bdb3-fb872cae3b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:36300,DS-ef0f0b3f-623f-4bc3-82c8-74819459a03d,DISK], DatanodeInfoWithStorage[127.0.0.1:37987,DS-3b4a24b3-c47a-459e-8ff3-efe09f4192cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5330
