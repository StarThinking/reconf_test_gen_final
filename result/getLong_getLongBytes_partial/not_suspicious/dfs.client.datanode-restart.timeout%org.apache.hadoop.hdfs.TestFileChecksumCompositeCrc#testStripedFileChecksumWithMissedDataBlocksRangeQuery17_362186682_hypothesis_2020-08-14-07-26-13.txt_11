reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 100ms
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 100ms
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1340141130-172.17.0.6-1597390023220:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44094,DS-1197eb72-4749-4d9b-861c-a11b2d59dd7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44885,DS-4864c6ab-bbff-418c-9265-f4e70b2f7b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:46085,DS-53183096-6d72-4d72-9cfd-3150a1cde94f,DISK], DatanodeInfoWithStorage[127.0.0.1:45153,DS-c4a8caae-3f0c-41f3-a699-47621f34fcfb,DISK], DatanodeInfoWithStorage[127.0.0.1:43302,DS-b3b27bcf-9d70-42cc-9898-997289b1c0aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42737,DS-01294ae9-f931-4090-92eb-e6ff9fbecd22,DISK], DatanodeInfoWithStorage[127.0.0.1:38443,DS-0f394b36-2342-4dfa-b39e-4b33ca193198,DISK], DatanodeInfoWithStorage[127.0.0.1:33671,DS-67a81f45-3bca-4af9-b488-3285f0068261,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1340141130-172.17.0.6-1597390023220:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44094,DS-1197eb72-4749-4d9b-861c-a11b2d59dd7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44885,DS-4864c6ab-bbff-418c-9265-f4e70b2f7b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:46085,DS-53183096-6d72-4d72-9cfd-3150a1cde94f,DISK], DatanodeInfoWithStorage[127.0.0.1:45153,DS-c4a8caae-3f0c-41f3-a699-47621f34fcfb,DISK], DatanodeInfoWithStorage[127.0.0.1:43302,DS-b3b27bcf-9d70-42cc-9898-997289b1c0aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42737,DS-01294ae9-f931-4090-92eb-e6ff9fbecd22,DISK], DatanodeInfoWithStorage[127.0.0.1:38443,DS-0f394b36-2342-4dfa-b39e-4b33ca193198,DISK], DatanodeInfoWithStorage[127.0.0.1:33671,DS-67a81f45-3bca-4af9-b488-3285f0068261,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 100ms
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-114598525-172.17.0.6-1597390061356:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34686,DS-733565d3-6630-46e9-a0f7-b61056598b73,DISK], DatanodeInfoWithStorage[127.0.0.1:36340,DS-3b7cf340-027c-49db-b02d-57f4b0b9196c,DISK], DatanodeInfoWithStorage[127.0.0.1:37953,DS-460965dd-a067-464b-96a8-5f7144df38f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45984,DS-9dc4a93e-ea7c-49b0-99f8-d2f149749ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:37221,DS-ed57e60b-30dc-4b48-9b84-116bb85d5fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:36078,DS-b5d7d61c-6d54-4c6f-a357-272db8ce4762,DISK], DatanodeInfoWithStorage[127.0.0.1:33847,DS-02b90c36-c111-4aa1-a699-5a439be594f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34882,DS-8b044f4f-ca55-4801-b67d-26910e32e742,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-114598525-172.17.0.6-1597390061356:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34686,DS-733565d3-6630-46e9-a0f7-b61056598b73,DISK], DatanodeInfoWithStorage[127.0.0.1:36340,DS-3b7cf340-027c-49db-b02d-57f4b0b9196c,DISK], DatanodeInfoWithStorage[127.0.0.1:37953,DS-460965dd-a067-464b-96a8-5f7144df38f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45984,DS-9dc4a93e-ea7c-49b0-99f8-d2f149749ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:37221,DS-ed57e60b-30dc-4b48-9b84-116bb85d5fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:36078,DS-b5d7d61c-6d54-4c6f-a357-272db8ce4762,DISK], DatanodeInfoWithStorage[127.0.0.1:33847,DS-02b90c36-c111-4aa1-a699-5a439be594f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34882,DS-8b044f4f-ca55-4801-b67d-26910e32e742,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 100ms
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-361079097-172.17.0.6-1597390562018:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42523,DS-862738cf-894f-4c24-bc55-64a05c6e0cab,DISK], DatanodeInfoWithStorage[127.0.0.1:33747,DS-a2fbaad4-2e71-4cdd-bdfe-e3649a7cd81e,DISK], DatanodeInfoWithStorage[127.0.0.1:44592,DS-81a13b18-0330-4a6b-8570-0f3e8df8927a,DISK], DatanodeInfoWithStorage[127.0.0.1:35280,DS-a7024aae-7473-463e-b73d-b939a11d658e,DISK], DatanodeInfoWithStorage[127.0.0.1:33464,DS-da410ae2-dfce-4e45-91f1-078cd0ab12be,DISK], DatanodeInfoWithStorage[127.0.0.1:45067,DS-45137ad8-4825-4d8c-ad00-5eb60bd8ff44,DISK], DatanodeInfoWithStorage[127.0.0.1:43943,DS-e42f936e-bd85-412c-983e-7f2490c0517a,DISK], DatanodeInfoWithStorage[127.0.0.1:45284,DS-893bf649-dd5a-4c3e-ac9e-5e2fdd37de86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-361079097-172.17.0.6-1597390562018:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42523,DS-862738cf-894f-4c24-bc55-64a05c6e0cab,DISK], DatanodeInfoWithStorage[127.0.0.1:33747,DS-a2fbaad4-2e71-4cdd-bdfe-e3649a7cd81e,DISK], DatanodeInfoWithStorage[127.0.0.1:44592,DS-81a13b18-0330-4a6b-8570-0f3e8df8927a,DISK], DatanodeInfoWithStorage[127.0.0.1:35280,DS-a7024aae-7473-463e-b73d-b939a11d658e,DISK], DatanodeInfoWithStorage[127.0.0.1:33464,DS-da410ae2-dfce-4e45-91f1-078cd0ab12be,DISK], DatanodeInfoWithStorage[127.0.0.1:45067,DS-45137ad8-4825-4d8c-ad00-5eb60bd8ff44,DISK], DatanodeInfoWithStorage[127.0.0.1:43943,DS-e42f936e-bd85-412c-983e-7f2490c0517a,DISK], DatanodeInfoWithStorage[127.0.0.1:45284,DS-893bf649-dd5a-4c3e-ac9e-5e2fdd37de86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 100ms
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1126975284-172.17.0.6-1597390844187:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40597,DS-2e19df8c-0194-40c0-9a0d-1aba42443636,DISK], DatanodeInfoWithStorage[127.0.0.1:36636,DS-453d639e-0c02-4aca-94d1-15767c7e884f,DISK], DatanodeInfoWithStorage[127.0.0.1:42593,DS-7d101eda-7745-4baf-a4d3-24e8b54d675f,DISK], DatanodeInfoWithStorage[127.0.0.1:34299,DS-c1a5428f-e93b-4883-b9d9-29ce9229f664,DISK], DatanodeInfoWithStorage[127.0.0.1:39647,DS-f63df37f-f8d5-45b4-a44d-3c037e0139b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38418,DS-fea1b4e0-0491-434b-b22f-49fd18665c71,DISK], DatanodeInfoWithStorage[127.0.0.1:33882,DS-86af162f-1154-4d18-9f0a-e1ead107f53c,DISK], DatanodeInfoWithStorage[127.0.0.1:36521,DS-ec716314-7437-4b66-bf66-7d955159b3ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1126975284-172.17.0.6-1597390844187:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40597,DS-2e19df8c-0194-40c0-9a0d-1aba42443636,DISK], DatanodeInfoWithStorage[127.0.0.1:36636,DS-453d639e-0c02-4aca-94d1-15767c7e884f,DISK], DatanodeInfoWithStorage[127.0.0.1:42593,DS-7d101eda-7745-4baf-a4d3-24e8b54d675f,DISK], DatanodeInfoWithStorage[127.0.0.1:34299,DS-c1a5428f-e93b-4883-b9d9-29ce9229f664,DISK], DatanodeInfoWithStorage[127.0.0.1:39647,DS-f63df37f-f8d5-45b4-a44d-3c037e0139b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38418,DS-fea1b4e0-0491-434b-b22f-49fd18665c71,DISK], DatanodeInfoWithStorage[127.0.0.1:33882,DS-86af162f-1154-4d18-9f0a-e1ead107f53c,DISK], DatanodeInfoWithStorage[127.0.0.1:36521,DS-ec716314-7437-4b66-bf66-7d955159b3ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 100ms
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-475934510-172.17.0.6-1597391098326:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41160,DS-df28565b-c9b7-4805-9206-c27a23b55ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:36746,DS-8f5f8522-a6cb-47f8-94e1-49d082e0187d,DISK], DatanodeInfoWithStorage[127.0.0.1:33669,DS-2b39914d-086b-4fbd-8185-6183b1386b37,DISK], DatanodeInfoWithStorage[127.0.0.1:45017,DS-f4297494-0212-4551-9da9-e48e0305fee8,DISK], DatanodeInfoWithStorage[127.0.0.1:42306,DS-60566de2-a369-4a14-8c1b-b39e202dce97,DISK], DatanodeInfoWithStorage[127.0.0.1:40115,DS-da75768d-86ab-4d80-90df-7ab1346dd163,DISK], DatanodeInfoWithStorage[127.0.0.1:38577,DS-7284cd1e-b29d-467b-a77e-82c1761359f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37579,DS-819c93d8-9cb0-4c30-912e-fe52148db692,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-475934510-172.17.0.6-1597391098326:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41160,DS-df28565b-c9b7-4805-9206-c27a23b55ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:36746,DS-8f5f8522-a6cb-47f8-94e1-49d082e0187d,DISK], DatanodeInfoWithStorage[127.0.0.1:33669,DS-2b39914d-086b-4fbd-8185-6183b1386b37,DISK], DatanodeInfoWithStorage[127.0.0.1:45017,DS-f4297494-0212-4551-9da9-e48e0305fee8,DISK], DatanodeInfoWithStorage[127.0.0.1:42306,DS-60566de2-a369-4a14-8c1b-b39e202dce97,DISK], DatanodeInfoWithStorage[127.0.0.1:40115,DS-da75768d-86ab-4d80-90df-7ab1346dd163,DISK], DatanodeInfoWithStorage[127.0.0.1:38577,DS-7284cd1e-b29d-467b-a77e-82c1761359f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37579,DS-819c93d8-9cb0-4c30-912e-fe52148db692,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 100ms
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1185099101-172.17.0.6-1597391231289:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39563,DS-af7a01c7-8e16-4440-ad3e-4b9508a88483,DISK], DatanodeInfoWithStorage[127.0.0.1:39982,DS-57eaad64-f059-421d-a8fe-03fd663f5c43,DISK], DatanodeInfoWithStorage[127.0.0.1:46328,DS-ebbe1425-f33e-4784-934f-3c4cfbe4e026,DISK], DatanodeInfoWithStorage[127.0.0.1:35361,DS-f9938bb3-66c5-4372-8a78-49da80b62659,DISK], DatanodeInfoWithStorage[127.0.0.1:34389,DS-523f0146-d1c0-419d-9965-f6804b379c71,DISK], DatanodeInfoWithStorage[127.0.0.1:38912,DS-2d338f80-d84a-498c-beb6-8714757b55ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37906,DS-4711dcf3-5361-406f-a290-2a220c7bbdda,DISK], DatanodeInfoWithStorage[127.0.0.1:41316,DS-1151c870-5372-446d-bac2-9980387d90f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1185099101-172.17.0.6-1597391231289:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39563,DS-af7a01c7-8e16-4440-ad3e-4b9508a88483,DISK], DatanodeInfoWithStorage[127.0.0.1:39982,DS-57eaad64-f059-421d-a8fe-03fd663f5c43,DISK], DatanodeInfoWithStorage[127.0.0.1:46328,DS-ebbe1425-f33e-4784-934f-3c4cfbe4e026,DISK], DatanodeInfoWithStorage[127.0.0.1:35361,DS-f9938bb3-66c5-4372-8a78-49da80b62659,DISK], DatanodeInfoWithStorage[127.0.0.1:34389,DS-523f0146-d1c0-419d-9965-f6804b379c71,DISK], DatanodeInfoWithStorage[127.0.0.1:38912,DS-2d338f80-d84a-498c-beb6-8714757b55ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37906,DS-4711dcf3-5361-406f-a290-2a220c7bbdda,DISK], DatanodeInfoWithStorage[127.0.0.1:41316,DS-1151c870-5372-446d-bac2-9980387d90f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 100ms
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2120852762-172.17.0.6-1597391302251:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42284,DS-1273c404-fb5d-4869-88e2-d74b7bfefcf1,DISK], DatanodeInfoWithStorage[127.0.0.1:43560,DS-ec3b5ed3-d55a-4e6b-b004-70fe29123772,DISK], DatanodeInfoWithStorage[127.0.0.1:45560,DS-89a96654-ea7c-49ef-86ef-8a0c5d59d15e,DISK], DatanodeInfoWithStorage[127.0.0.1:45576,DS-58de309f-8c91-4bf0-ad09-889c98eae15c,DISK], DatanodeInfoWithStorage[127.0.0.1:35488,DS-f40baeb7-d9c2-46a1-9290-d051e7f5b39c,DISK], DatanodeInfoWithStorage[127.0.0.1:37584,DS-c6249fb9-75b1-4585-a2af-2dbe748c9ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:42357,DS-051983c0-f67d-4893-b747-50ec0b5382b1,DISK], DatanodeInfoWithStorage[127.0.0.1:32932,DS-32bf3773-b46e-49f3-9ad1-191c9098525d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2120852762-172.17.0.6-1597391302251:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42284,DS-1273c404-fb5d-4869-88e2-d74b7bfefcf1,DISK], DatanodeInfoWithStorage[127.0.0.1:43560,DS-ec3b5ed3-d55a-4e6b-b004-70fe29123772,DISK], DatanodeInfoWithStorage[127.0.0.1:45560,DS-89a96654-ea7c-49ef-86ef-8a0c5d59d15e,DISK], DatanodeInfoWithStorage[127.0.0.1:45576,DS-58de309f-8c91-4bf0-ad09-889c98eae15c,DISK], DatanodeInfoWithStorage[127.0.0.1:35488,DS-f40baeb7-d9c2-46a1-9290-d051e7f5b39c,DISK], DatanodeInfoWithStorage[127.0.0.1:37584,DS-c6249fb9-75b1-4585-a2af-2dbe748c9ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:42357,DS-051983c0-f67d-4893-b747-50ec0b5382b1,DISK], DatanodeInfoWithStorage[127.0.0.1:32932,DS-32bf3773-b46e-49f3-9ad1-191c9098525d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 100ms
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1174225758-172.17.0.6-1597391493206:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44663,DS-ce1e171a-7cb2-4666-8123-1ec63f65bf68,DISK], DatanodeInfoWithStorage[127.0.0.1:36655,DS-a372df69-835f-4ec3-9f93-c274bcb944c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40821,DS-44074040-9167-4fdf-bcf2-0b680dfc18f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37349,DS-f36d3893-bfb1-4eae-adab-dce4b1e23c81,DISK], DatanodeInfoWithStorage[127.0.0.1:35067,DS-10a5e782-b2dd-4061-9990-ae49d85b2383,DISK], DatanodeInfoWithStorage[127.0.0.1:46241,DS-cb59ff50-4632-4030-a658-724f6f8a7d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:41156,DS-f2111c9c-f4f9-4a97-9022-8a137e4c8911,DISK], DatanodeInfoWithStorage[127.0.0.1:37476,DS-b271388f-e2b8-4e13-bf64-efb9d006ec02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1174225758-172.17.0.6-1597391493206:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44663,DS-ce1e171a-7cb2-4666-8123-1ec63f65bf68,DISK], DatanodeInfoWithStorage[127.0.0.1:36655,DS-a372df69-835f-4ec3-9f93-c274bcb944c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40821,DS-44074040-9167-4fdf-bcf2-0b680dfc18f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37349,DS-f36d3893-bfb1-4eae-adab-dce4b1e23c81,DISK], DatanodeInfoWithStorage[127.0.0.1:35067,DS-10a5e782-b2dd-4061-9990-ae49d85b2383,DISK], DatanodeInfoWithStorage[127.0.0.1:46241,DS-cb59ff50-4632-4030-a658-724f6f8a7d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:41156,DS-f2111c9c-f4f9-4a97-9022-8a137e4c8911,DISK], DatanodeInfoWithStorage[127.0.0.1:37476,DS-b271388f-e2b8-4e13-bf64-efb9d006ec02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 100ms
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-683446699-172.17.0.6-1597391814372:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33483,DS-63939ec2-0538-4ccc-a4e0-eeda99aeebfc,DISK], DatanodeInfoWithStorage[127.0.0.1:37733,DS-0452eb3b-8138-4c23-b0f2-95ba2a4bfa3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40500,DS-c205804b-381c-4ca4-a0e7-e5d00cd0124e,DISK], DatanodeInfoWithStorage[127.0.0.1:33121,DS-035316d6-b6b7-464f-9075-af8677291c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:37488,DS-4f6a110d-351e-4f3d-b14c-5e2807b48dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:43595,DS-041a1fc3-9dee-4719-897b-0eed06ade045,DISK], DatanodeInfoWithStorage[127.0.0.1:44786,DS-e80ba5d4-436e-41fc-81ec-92af3bf038ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38579,DS-ee34af1b-690f-4400-9293-97db878c19c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-683446699-172.17.0.6-1597391814372:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33483,DS-63939ec2-0538-4ccc-a4e0-eeda99aeebfc,DISK], DatanodeInfoWithStorage[127.0.0.1:37733,DS-0452eb3b-8138-4c23-b0f2-95ba2a4bfa3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40500,DS-c205804b-381c-4ca4-a0e7-e5d00cd0124e,DISK], DatanodeInfoWithStorage[127.0.0.1:33121,DS-035316d6-b6b7-464f-9075-af8677291c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:37488,DS-4f6a110d-351e-4f3d-b14c-5e2807b48dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:43595,DS-041a1fc3-9dee-4719-897b-0eed06ade045,DISK], DatanodeInfoWithStorage[127.0.0.1:44786,DS-e80ba5d4-436e-41fc-81ec-92af3bf038ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38579,DS-ee34af1b-690f-4400-9293-97db878c19c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 100ms
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1901907719-172.17.0.6-1597392028670:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40387,DS-6413d6be-c800-4f83-89b5-6915882655d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43471,DS-f31dd9e2-a18b-4561-9a51-ef5db71c9a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:33637,DS-d868ea4d-267d-4637-807b-06b342a0a638,DISK], DatanodeInfoWithStorage[127.0.0.1:39318,DS-8520d31a-4afc-4349-9d1c-6f633abcb479,DISK], DatanodeInfoWithStorage[127.0.0.1:46043,DS-3fb351e7-55b6-46aa-a436-0cdccc155637,DISK], DatanodeInfoWithStorage[127.0.0.1:42207,DS-e194d5a7-80d1-44ed-a125-a87712044387,DISK], DatanodeInfoWithStorage[127.0.0.1:42876,DS-9b0ceef7-f9c4-4216-916f-0a4d71cc872e,DISK], DatanodeInfoWithStorage[127.0.0.1:37059,DS-3121a4e4-3983-4699-893d-e0f2029af14a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1901907719-172.17.0.6-1597392028670:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40387,DS-6413d6be-c800-4f83-89b5-6915882655d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43471,DS-f31dd9e2-a18b-4561-9a51-ef5db71c9a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:33637,DS-d868ea4d-267d-4637-807b-06b342a0a638,DISK], DatanodeInfoWithStorage[127.0.0.1:39318,DS-8520d31a-4afc-4349-9d1c-6f633abcb479,DISK], DatanodeInfoWithStorage[127.0.0.1:46043,DS-3fb351e7-55b6-46aa-a436-0cdccc155637,DISK], DatanodeInfoWithStorage[127.0.0.1:42207,DS-e194d5a7-80d1-44ed-a125-a87712044387,DISK], DatanodeInfoWithStorage[127.0.0.1:42876,DS-9b0ceef7-f9c4-4216-916f-0a4d71cc872e,DISK], DatanodeInfoWithStorage[127.0.0.1:37059,DS-3121a4e4-3983-4699-893d-e0f2029af14a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 100ms
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-514827668-172.17.0.6-1597392092300:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33669,DS-6df2c2d3-b8f8-4ee6-b297-0d5804f81841,DISK], DatanodeInfoWithStorage[127.0.0.1:44712,DS-4f30fe43-7f29-4436-886b-af682aa56123,DISK], DatanodeInfoWithStorage[127.0.0.1:34725,DS-18761d09-81c3-4a9f-9d49-dc50c7388638,DISK], DatanodeInfoWithStorage[127.0.0.1:41382,DS-4eac3b2c-e16c-4208-a9ff-b99e060ffc78,DISK], DatanodeInfoWithStorage[127.0.0.1:39554,DS-97a95bcb-01bd-4fbb-a1bd-7002d3029c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37580,DS-2c1c0c6b-0a6d-42a6-a988-f65000cef0a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36467,DS-eb21c221-f996-4865-b1ad-05fc3a5cc120,DISK], DatanodeInfoWithStorage[127.0.0.1:44844,DS-4ca22766-c468-4226-9382-2e111b93bc30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-514827668-172.17.0.6-1597392092300:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33669,DS-6df2c2d3-b8f8-4ee6-b297-0d5804f81841,DISK], DatanodeInfoWithStorage[127.0.0.1:44712,DS-4f30fe43-7f29-4436-886b-af682aa56123,DISK], DatanodeInfoWithStorage[127.0.0.1:34725,DS-18761d09-81c3-4a9f-9d49-dc50c7388638,DISK], DatanodeInfoWithStorage[127.0.0.1:41382,DS-4eac3b2c-e16c-4208-a9ff-b99e060ffc78,DISK], DatanodeInfoWithStorage[127.0.0.1:39554,DS-97a95bcb-01bd-4fbb-a1bd-7002d3029c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37580,DS-2c1c0c6b-0a6d-42a6-a988-f65000cef0a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36467,DS-eb21c221-f996-4865-b1ad-05fc3a5cc120,DISK], DatanodeInfoWithStorage[127.0.0.1:44844,DS-4ca22766-c468-4226-9382-2e111b93bc30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 100ms
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1238448347-172.17.0.6-1597392371195:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41921,DS-874ee98b-c1bd-4338-a660-556fe291c0e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37782,DS-aed47dbc-939a-40a8-93d2-02c81c876930,DISK], DatanodeInfoWithStorage[127.0.0.1:39151,DS-9b855488-515d-4d81-9dfb-b7afc500815b,DISK], DatanodeInfoWithStorage[127.0.0.1:45479,DS-12639245-7298-4a70-b676-ffdfe1904ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:39555,DS-aff6f464-05d2-42fd-b850-b1970bea1d80,DISK], DatanodeInfoWithStorage[127.0.0.1:36861,DS-374da572-6570-4ad7-8615-b380f2fb4391,DISK], DatanodeInfoWithStorage[127.0.0.1:40136,DS-f4fae56d-e0e6-4aee-bd8f-5d353676e1ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46311,DS-ff4e4903-e25e-4cdc-843b-6f61cbbae6f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1238448347-172.17.0.6-1597392371195:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41921,DS-874ee98b-c1bd-4338-a660-556fe291c0e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37782,DS-aed47dbc-939a-40a8-93d2-02c81c876930,DISK], DatanodeInfoWithStorage[127.0.0.1:39151,DS-9b855488-515d-4d81-9dfb-b7afc500815b,DISK], DatanodeInfoWithStorage[127.0.0.1:45479,DS-12639245-7298-4a70-b676-ffdfe1904ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:39555,DS-aff6f464-05d2-42fd-b850-b1970bea1d80,DISK], DatanodeInfoWithStorage[127.0.0.1:36861,DS-374da572-6570-4ad7-8615-b380f2fb4391,DISK], DatanodeInfoWithStorage[127.0.0.1:40136,DS-f4fae56d-e0e6-4aee-bd8f-5d353676e1ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46311,DS-ff4e4903-e25e-4cdc-843b-6f61cbbae6f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 100ms
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1360031138-172.17.0.6-1597392440474:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42194,DS-bd6bbb2a-5f10-48dc-94fd-56db08543190,DISK], DatanodeInfoWithStorage[127.0.0.1:43796,DS-fc0e5307-3efb-46bc-a2e3-5037d211001a,DISK], DatanodeInfoWithStorage[127.0.0.1:37183,DS-ea8073f0-a097-4280-b917-11900f19946f,DISK], DatanodeInfoWithStorage[127.0.0.1:33497,DS-63c91307-e664-4076-838f-a5e63e0d6511,DISK], DatanodeInfoWithStorage[127.0.0.1:43057,DS-48f69d74-ee3f-418d-abd5-fc46210f8e21,DISK], DatanodeInfoWithStorage[127.0.0.1:44769,DS-39727fa9-6748-4195-99db-27f36807ab3b,DISK], DatanodeInfoWithStorage[127.0.0.1:39534,DS-a05322fc-efd9-445e-b73d-0de26c1b1424,DISK], DatanodeInfoWithStorage[127.0.0.1:39339,DS-586d17ef-38f3-4d04-825e-6ae30ee056c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1360031138-172.17.0.6-1597392440474:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42194,DS-bd6bbb2a-5f10-48dc-94fd-56db08543190,DISK], DatanodeInfoWithStorage[127.0.0.1:43796,DS-fc0e5307-3efb-46bc-a2e3-5037d211001a,DISK], DatanodeInfoWithStorage[127.0.0.1:37183,DS-ea8073f0-a097-4280-b917-11900f19946f,DISK], DatanodeInfoWithStorage[127.0.0.1:33497,DS-63c91307-e664-4076-838f-a5e63e0d6511,DISK], DatanodeInfoWithStorage[127.0.0.1:43057,DS-48f69d74-ee3f-418d-abd5-fc46210f8e21,DISK], DatanodeInfoWithStorage[127.0.0.1:44769,DS-39727fa9-6748-4195-99db-27f36807ab3b,DISK], DatanodeInfoWithStorage[127.0.0.1:39534,DS-a05322fc-efd9-445e-b73d-0de26c1b1424,DISK], DatanodeInfoWithStorage[127.0.0.1:39339,DS-586d17ef-38f3-4d04-825e-6ae30ee056c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 100ms
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1247810573-172.17.0.6-1597392892732:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41026,DS-a030ac05-9c7e-4bb3-9572-641e4e03589c,DISK], DatanodeInfoWithStorage[127.0.0.1:32787,DS-30327803-6347-440d-bb5e-63a362c1671f,DISK], DatanodeInfoWithStorage[127.0.0.1:38652,DS-0b12add7-d99b-4a0f-b88f-3120965c4561,DISK], DatanodeInfoWithStorage[127.0.0.1:38858,DS-7ea183ab-b7e8-4d0b-ab95-1ba1c4399abe,DISK], DatanodeInfoWithStorage[127.0.0.1:43662,DS-05b33545-9a11-44f2-a96c-ce102c53d809,DISK], DatanodeInfoWithStorage[127.0.0.1:38313,DS-e5644510-ac4b-4a88-ba12-642dc5daaf2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-4bb3dc17-b2da-4b42-afed-bc5b7d475880,DISK], DatanodeInfoWithStorage[127.0.0.1:35519,DS-cdb0eb36-ec02-48df-a5d8-fe7a764b8dae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1247810573-172.17.0.6-1597392892732:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41026,DS-a030ac05-9c7e-4bb3-9572-641e4e03589c,DISK], DatanodeInfoWithStorage[127.0.0.1:32787,DS-30327803-6347-440d-bb5e-63a362c1671f,DISK], DatanodeInfoWithStorage[127.0.0.1:38652,DS-0b12add7-d99b-4a0f-b88f-3120965c4561,DISK], DatanodeInfoWithStorage[127.0.0.1:38858,DS-7ea183ab-b7e8-4d0b-ab95-1ba1c4399abe,DISK], DatanodeInfoWithStorage[127.0.0.1:43662,DS-05b33545-9a11-44f2-a96c-ce102c53d809,DISK], DatanodeInfoWithStorage[127.0.0.1:38313,DS-e5644510-ac4b-4a88-ba12-642dc5daaf2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-4bb3dc17-b2da-4b42-afed-bc5b7d475880,DISK], DatanodeInfoWithStorage[127.0.0.1:35519,DS-cdb0eb36-ec02-48df-a5d8-fe7a764b8dae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 100ms
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-12733106-172.17.0.6-1597393339842:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38916,DS-995ad086-2854-443a-acb5-7a47f07e11ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34548,DS-6c2f4e3e-e3c3-4d85-a19c-02c5fbc80182,DISK], DatanodeInfoWithStorage[127.0.0.1:34991,DS-845e87d9-55e3-4f3b-92c6-482f2b89d072,DISK], DatanodeInfoWithStorage[127.0.0.1:44738,DS-a6677d60-9414-4893-88b8-24815516eacb,DISK], DatanodeInfoWithStorage[127.0.0.1:38558,DS-3ef627f4-d10d-41cf-9bec-52ce9a17ab51,DISK], DatanodeInfoWithStorage[127.0.0.1:39780,DS-884ac95d-e916-4ffc-9704-fc0f730cd169,DISK], DatanodeInfoWithStorage[127.0.0.1:44849,DS-3b69bce8-037f-4495-a37f-1dcc458ee890,DISK], DatanodeInfoWithStorage[127.0.0.1:35070,DS-44dbb7c9-acfe-48e3-a1f5-0fa5cd63c959,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-12733106-172.17.0.6-1597393339842:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38916,DS-995ad086-2854-443a-acb5-7a47f07e11ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34548,DS-6c2f4e3e-e3c3-4d85-a19c-02c5fbc80182,DISK], DatanodeInfoWithStorage[127.0.0.1:34991,DS-845e87d9-55e3-4f3b-92c6-482f2b89d072,DISK], DatanodeInfoWithStorage[127.0.0.1:44738,DS-a6677d60-9414-4893-88b8-24815516eacb,DISK], DatanodeInfoWithStorage[127.0.0.1:38558,DS-3ef627f4-d10d-41cf-9bec-52ce9a17ab51,DISK], DatanodeInfoWithStorage[127.0.0.1:39780,DS-884ac95d-e916-4ffc-9704-fc0f730cd169,DISK], DatanodeInfoWithStorage[127.0.0.1:44849,DS-3b69bce8-037f-4495-a37f-1dcc458ee890,DISK], DatanodeInfoWithStorage[127.0.0.1:35070,DS-44dbb7c9-acfe-48e3-a1f5-0fa5cd63c959,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 100ms
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-661630339-172.17.0.6-1597393902602:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41391,DS-86a23a43-8656-4bef-b3da-ac917d70e19f,DISK], DatanodeInfoWithStorage[127.0.0.1:45132,DS-921a812b-bfa1-4c2c-aa8b-1ead1ae0e764,DISK], DatanodeInfoWithStorage[127.0.0.1:46367,DS-4b5e3481-27e3-4824-8358-c54bc141c7d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39635,DS-302e4e1c-ce6e-4846-a455-41cdd5078853,DISK], DatanodeInfoWithStorage[127.0.0.1:36017,DS-edde85ff-2743-4e6b-a729-81fd470eb89e,DISK], DatanodeInfoWithStorage[127.0.0.1:44088,DS-5225309b-1a45-47e3-ac6a-97f127a34356,DISK], DatanodeInfoWithStorage[127.0.0.1:46602,DS-17859f9f-1c6f-4502-be5c-f46521a931c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33191,DS-337eb8ca-8a73-4976-9052-ab541b898ef3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-661630339-172.17.0.6-1597393902602:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41391,DS-86a23a43-8656-4bef-b3da-ac917d70e19f,DISK], DatanodeInfoWithStorage[127.0.0.1:45132,DS-921a812b-bfa1-4c2c-aa8b-1ead1ae0e764,DISK], DatanodeInfoWithStorage[127.0.0.1:46367,DS-4b5e3481-27e3-4824-8358-c54bc141c7d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39635,DS-302e4e1c-ce6e-4846-a455-41cdd5078853,DISK], DatanodeInfoWithStorage[127.0.0.1:36017,DS-edde85ff-2743-4e6b-a729-81fd470eb89e,DISK], DatanodeInfoWithStorage[127.0.0.1:44088,DS-5225309b-1a45-47e3-ac6a-97f127a34356,DISK], DatanodeInfoWithStorage[127.0.0.1:46602,DS-17859f9f-1c6f-4502-be5c-f46521a931c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33191,DS-337eb8ca-8a73-4976-9052-ab541b898ef3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 100ms
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-582522521-172.17.0.6-1597394003910:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38270,DS-7ae64595-a909-4cb0-9fe7-b50008aff254,DISK], DatanodeInfoWithStorage[127.0.0.1:37816,DS-9f27a177-af2a-4730-ab9b-451326853b85,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-20a82ac3-9634-4cb1-b404-2e4e85948382,DISK], DatanodeInfoWithStorage[127.0.0.1:41491,DS-d1b44022-33b8-408c-8ef7-b2a0ad54eec8,DISK], DatanodeInfoWithStorage[127.0.0.1:35465,DS-d311f00e-18c2-4e64-a8b7-9ddc503e5206,DISK], DatanodeInfoWithStorage[127.0.0.1:44180,DS-b26af9e6-04e4-4729-ba2b-df1d0bcc36ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42708,DS-9f66ed8d-3397-45ec-b12e-bde239272ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:34598,DS-5eaf1d3d-d763-4454-bec6-4332538645f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-582522521-172.17.0.6-1597394003910:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38270,DS-7ae64595-a909-4cb0-9fe7-b50008aff254,DISK], DatanodeInfoWithStorage[127.0.0.1:37816,DS-9f27a177-af2a-4730-ab9b-451326853b85,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-20a82ac3-9634-4cb1-b404-2e4e85948382,DISK], DatanodeInfoWithStorage[127.0.0.1:41491,DS-d1b44022-33b8-408c-8ef7-b2a0ad54eec8,DISK], DatanodeInfoWithStorage[127.0.0.1:35465,DS-d311f00e-18c2-4e64-a8b7-9ddc503e5206,DISK], DatanodeInfoWithStorage[127.0.0.1:44180,DS-b26af9e6-04e4-4729-ba2b-df1d0bcc36ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42708,DS-9f66ed8d-3397-45ec-b12e-bde239272ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:34598,DS-5eaf1d3d-d763-4454-bec6-4332538645f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 100ms
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-43207380-172.17.0.6-1597394040706:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36796,DS-820deb75-b5e9-4d62-b65a-c0023e9e50bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38642,DS-9af5b155-c8fb-44a4-a238-ef539c0b456c,DISK], DatanodeInfoWithStorage[127.0.0.1:43038,DS-952dd83c-89c9-4331-86d1-6907a0bd99d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35840,DS-babea241-6198-4cc1-9666-c1b6b921eb5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43810,DS-16039ff0-9c84-4378-8660-940bdb975397,DISK], DatanodeInfoWithStorage[127.0.0.1:45459,DS-f219b6c4-d808-455f-88b7-ed067b5f051d,DISK], DatanodeInfoWithStorage[127.0.0.1:46874,DS-bb469b2a-543e-4cfb-aa20-d07f0e1c2711,DISK], DatanodeInfoWithStorage[127.0.0.1:46014,DS-8b82c874-a24a-4a58-bf01-f7299070d613,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-43207380-172.17.0.6-1597394040706:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36796,DS-820deb75-b5e9-4d62-b65a-c0023e9e50bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38642,DS-9af5b155-c8fb-44a4-a238-ef539c0b456c,DISK], DatanodeInfoWithStorage[127.0.0.1:43038,DS-952dd83c-89c9-4331-86d1-6907a0bd99d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35840,DS-babea241-6198-4cc1-9666-c1b6b921eb5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43810,DS-16039ff0-9c84-4378-8660-940bdb975397,DISK], DatanodeInfoWithStorage[127.0.0.1:45459,DS-f219b6c4-d808-455f-88b7-ed067b5f051d,DISK], DatanodeInfoWithStorage[127.0.0.1:46874,DS-bb469b2a-543e-4cfb-aa20-d07f0e1c2711,DISK], DatanodeInfoWithStorage[127.0.0.1:46014,DS-8b82c874-a24a-4a58-bf01-f7299070d613,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 100ms
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-104595705-172.17.0.6-1597394225254:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46201,DS-cdd1ead8-0a8d-4025-9b83-e88212d4fcca,DISK], DatanodeInfoWithStorage[127.0.0.1:38754,DS-a74a4279-294e-42ab-b3ed-9b7f827d05ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35573,DS-5922d556-57de-4e48-b1d0-1e3a43b2b1e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42076,DS-9810fed9-dc40-4d5c-86c7-ec2bbbecdbc9,DISK], DatanodeInfoWithStorage[127.0.0.1:36011,DS-b4f7b6d1-e410-41f2-a070-2bdf30762dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:43305,DS-99ad5064-7e38-4d3d-97c0-2ee3fe96cc2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40844,DS-1618668e-3355-4c74-8994-afaf72218761,DISK], DatanodeInfoWithStorage[127.0.0.1:38355,DS-5b2285cf-9766-4270-a7a0-193aac066e49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-104595705-172.17.0.6-1597394225254:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46201,DS-cdd1ead8-0a8d-4025-9b83-e88212d4fcca,DISK], DatanodeInfoWithStorage[127.0.0.1:38754,DS-a74a4279-294e-42ab-b3ed-9b7f827d05ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35573,DS-5922d556-57de-4e48-b1d0-1e3a43b2b1e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42076,DS-9810fed9-dc40-4d5c-86c7-ec2bbbecdbc9,DISK], DatanodeInfoWithStorage[127.0.0.1:36011,DS-b4f7b6d1-e410-41f2-a070-2bdf30762dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:43305,DS-99ad5064-7e38-4d3d-97c0-2ee3fe96cc2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40844,DS-1618668e-3355-4c74-8994-afaf72218761,DISK], DatanodeInfoWithStorage[127.0.0.1:38355,DS-5b2285cf-9766-4270-a7a0-193aac066e49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 100ms
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-875993558-172.17.0.6-1597394504339:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35488,DS-d77d950f-278e-4b0c-93e2-73a5c1ebec9d,DISK], DatanodeInfoWithStorage[127.0.0.1:46030,DS-8ce60dba-b32f-4242-93a0-01b0a47a7cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:44754,DS-d07734c0-66b6-4339-b868-eced2de5fbbb,DISK], DatanodeInfoWithStorage[127.0.0.1:41707,DS-6a40a09b-4db8-43eb-9dcf-0cacb64dd710,DISK], DatanodeInfoWithStorage[127.0.0.1:40691,DS-f79ec194-3653-4932-8727-e72b928525bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46509,DS-edd73257-9842-4ecf-882b-bc24a5a2d577,DISK], DatanodeInfoWithStorage[127.0.0.1:45041,DS-f0dc3024-5716-4f2d-9eff-3c70a35a3441,DISK], DatanodeInfoWithStorage[127.0.0.1:44189,DS-3383db50-d4de-4a5d-9e57-e4055cd15f60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-875993558-172.17.0.6-1597394504339:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35488,DS-d77d950f-278e-4b0c-93e2-73a5c1ebec9d,DISK], DatanodeInfoWithStorage[127.0.0.1:46030,DS-8ce60dba-b32f-4242-93a0-01b0a47a7cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:44754,DS-d07734c0-66b6-4339-b868-eced2de5fbbb,DISK], DatanodeInfoWithStorage[127.0.0.1:41707,DS-6a40a09b-4db8-43eb-9dcf-0cacb64dd710,DISK], DatanodeInfoWithStorage[127.0.0.1:40691,DS-f79ec194-3653-4932-8727-e72b928525bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46509,DS-edd73257-9842-4ecf-882b-bc24a5a2d577,DISK], DatanodeInfoWithStorage[127.0.0.1:45041,DS-f0dc3024-5716-4f2d-9eff-3c70a35a3441,DISK], DatanodeInfoWithStorage[127.0.0.1:44189,DS-3383db50-d4de-4a5d-9e57-e4055cd15f60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 100ms
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2116828749-172.17.0.6-1597394543632:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46810,DS-6fad79a6-0668-4e7a-a63a-ece47df9c8d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33898,DS-9f52ed70-a288-4f6f-bbf1-816d7542495a,DISK], DatanodeInfoWithStorage[127.0.0.1:46468,DS-3aa73add-4950-4344-9ad8-fefd555548a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35896,DS-9d3e9111-832b-4e6f-9215-e8730261285c,DISK], DatanodeInfoWithStorage[127.0.0.1:43982,DS-7e36cc99-1833-4822-99d0-8c92bc985b46,DISK], DatanodeInfoWithStorage[127.0.0.1:46389,DS-0089118d-566b-486c-a204-421f1c6072e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41722,DS-41d6b22e-49dd-4745-b740-32fcccfefc32,DISK], DatanodeInfoWithStorage[127.0.0.1:37785,DS-2b2f9550-4fb5-4847-aeb8-60ab20aea41e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2116828749-172.17.0.6-1597394543632:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46810,DS-6fad79a6-0668-4e7a-a63a-ece47df9c8d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33898,DS-9f52ed70-a288-4f6f-bbf1-816d7542495a,DISK], DatanodeInfoWithStorage[127.0.0.1:46468,DS-3aa73add-4950-4344-9ad8-fefd555548a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35896,DS-9d3e9111-832b-4e6f-9215-e8730261285c,DISK], DatanodeInfoWithStorage[127.0.0.1:43982,DS-7e36cc99-1833-4822-99d0-8c92bc985b46,DISK], DatanodeInfoWithStorage[127.0.0.1:46389,DS-0089118d-566b-486c-a204-421f1c6072e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41722,DS-41d6b22e-49dd-4745-b740-32fcccfefc32,DISK], DatanodeInfoWithStorage[127.0.0.1:37785,DS-2b2f9550-4fb5-4847-aeb8-60ab20aea41e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 100ms
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-534153883-172.17.0.6-1597394683489:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43147,DS-8502c409-fc15-4c4b-8d45-1f0a3ac2e8d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41189,DS-3b811924-3410-4066-b11d-f7738569f21d,DISK], DatanodeInfoWithStorage[127.0.0.1:43644,DS-5c687ce5-7285-4cd5-ae8a-23f210b5f8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36186,DS-1cf6a457-2a7e-45c4-b607-de222b997db1,DISK], DatanodeInfoWithStorage[127.0.0.1:44381,DS-62f4e0af-d189-43ae-b7e9-bd020df6b6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33766,DS-b74a20ca-92f0-4a54-a3b7-c192b4378fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:40231,DS-ce0cb4c2-6094-46a7-8ba5-a1dae8f488a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36041,DS-6f549d0b-cf3a-498a-b1c0-f15225f6c6d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-534153883-172.17.0.6-1597394683489:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43147,DS-8502c409-fc15-4c4b-8d45-1f0a3ac2e8d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41189,DS-3b811924-3410-4066-b11d-f7738569f21d,DISK], DatanodeInfoWithStorage[127.0.0.1:43644,DS-5c687ce5-7285-4cd5-ae8a-23f210b5f8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36186,DS-1cf6a457-2a7e-45c4-b607-de222b997db1,DISK], DatanodeInfoWithStorage[127.0.0.1:44381,DS-62f4e0af-d189-43ae-b7e9-bd020df6b6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33766,DS-b74a20ca-92f0-4a54-a3b7-c192b4378fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:40231,DS-ce0cb4c2-6094-46a7-8ba5-a1dae8f488a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36041,DS-6f549d0b-cf3a-498a-b1c0-f15225f6c6d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 100ms
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1471138863-172.17.0.6-1597394719756:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36618,DS-c3fd9454-2258-4a33-b977-598b05c35d25,DISK], DatanodeInfoWithStorage[127.0.0.1:41080,DS-9f21a844-8177-4cbd-8560-958d7e03e472,DISK], DatanodeInfoWithStorage[127.0.0.1:38024,DS-8caba26f-6dbb-44d0-b40d-509beea3ded3,DISK], DatanodeInfoWithStorage[127.0.0.1:44813,DS-fca411f8-b8ae-441a-b1bc-b6b0746dd963,DISK], DatanodeInfoWithStorage[127.0.0.1:33985,DS-572abffe-3324-43b2-abf5-ab4ed63f38cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38945,DS-9a7ed066-9638-46ee-9c91-7c8c14bf2fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:45058,DS-14e52d8d-a147-46a4-8b76-983ecb4bd39a,DISK], DatanodeInfoWithStorage[127.0.0.1:39115,DS-b7be0a5d-02d1-4519-b2dc-93ad4d1791fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1471138863-172.17.0.6-1597394719756:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36618,DS-c3fd9454-2258-4a33-b977-598b05c35d25,DISK], DatanodeInfoWithStorage[127.0.0.1:41080,DS-9f21a844-8177-4cbd-8560-958d7e03e472,DISK], DatanodeInfoWithStorage[127.0.0.1:38024,DS-8caba26f-6dbb-44d0-b40d-509beea3ded3,DISK], DatanodeInfoWithStorage[127.0.0.1:44813,DS-fca411f8-b8ae-441a-b1bc-b6b0746dd963,DISK], DatanodeInfoWithStorage[127.0.0.1:33985,DS-572abffe-3324-43b2-abf5-ab4ed63f38cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38945,DS-9a7ed066-9638-46ee-9c91-7c8c14bf2fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:45058,DS-14e52d8d-a147-46a4-8b76-983ecb4bd39a,DISK], DatanodeInfoWithStorage[127.0.0.1:39115,DS-b7be0a5d-02d1-4519-b2dc-93ad4d1791fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 100ms
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-444802889-172.17.0.6-1597394795997:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44540,DS-c6b475fa-69bc-4dc6-9f61-9a8621998597,DISK], DatanodeInfoWithStorage[127.0.0.1:37457,DS-d57c0128-42c9-42b1-b56a-e6658bda9786,DISK], DatanodeInfoWithStorage[127.0.0.1:40132,DS-1684ac36-388a-4d0f-86f0-a1a90202de04,DISK], DatanodeInfoWithStorage[127.0.0.1:38733,DS-b81d72da-07d3-49f4-bdb2-017681a955bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34523,DS-0eaf2e39-7166-4060-87f5-ed6dc93dd249,DISK], DatanodeInfoWithStorage[127.0.0.1:45982,DS-f675a30e-7965-4ad6-9efe-2fd9bb4cd920,DISK], DatanodeInfoWithStorage[127.0.0.1:46453,DS-2379369d-8e4e-4069-975b-46f8bbb8085f,DISK], DatanodeInfoWithStorage[127.0.0.1:44818,DS-7525f727-1b5e-4f8c-8b65-96b6a64b7306,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-444802889-172.17.0.6-1597394795997:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44540,DS-c6b475fa-69bc-4dc6-9f61-9a8621998597,DISK], DatanodeInfoWithStorage[127.0.0.1:37457,DS-d57c0128-42c9-42b1-b56a-e6658bda9786,DISK], DatanodeInfoWithStorage[127.0.0.1:40132,DS-1684ac36-388a-4d0f-86f0-a1a90202de04,DISK], DatanodeInfoWithStorage[127.0.0.1:38733,DS-b81d72da-07d3-49f4-bdb2-017681a955bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34523,DS-0eaf2e39-7166-4060-87f5-ed6dc93dd249,DISK], DatanodeInfoWithStorage[127.0.0.1:45982,DS-f675a30e-7965-4ad6-9efe-2fd9bb4cd920,DISK], DatanodeInfoWithStorage[127.0.0.1:46453,DS-2379369d-8e4e-4069-975b-46f8bbb8085f,DISK], DatanodeInfoWithStorage[127.0.0.1:44818,DS-7525f727-1b5e-4f8c-8b65-96b6a64b7306,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 100ms
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1475020187-172.17.0.6-1597395138251:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44028,DS-b5992cae-32db-4211-b47f-e18a73fa2baa,DISK], DatanodeInfoWithStorage[127.0.0.1:39087,DS-de7a41e9-730e-4561-a021-09ac91b99e20,DISK], DatanodeInfoWithStorage[127.0.0.1:34789,DS-315ef568-7c8d-43e8-b1df-69c920d731f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39326,DS-ecef1b50-fb5d-4b7f-8d17-5a030c519518,DISK], DatanodeInfoWithStorage[127.0.0.1:41290,DS-86132b42-702f-4a82-a751-952548ada04f,DISK], DatanodeInfoWithStorage[127.0.0.1:35165,DS-a9f67914-c9ce-4d1d-834f-b029e7c8fd29,DISK], DatanodeInfoWithStorage[127.0.0.1:37310,DS-385f7e2f-4284-4f1d-96b2-143534f5f441,DISK], DatanodeInfoWithStorage[127.0.0.1:34848,DS-22092bda-e152-4e96-9006-780c77f969f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1475020187-172.17.0.6-1597395138251:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44028,DS-b5992cae-32db-4211-b47f-e18a73fa2baa,DISK], DatanodeInfoWithStorage[127.0.0.1:39087,DS-de7a41e9-730e-4561-a021-09ac91b99e20,DISK], DatanodeInfoWithStorage[127.0.0.1:34789,DS-315ef568-7c8d-43e8-b1df-69c920d731f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39326,DS-ecef1b50-fb5d-4b7f-8d17-5a030c519518,DISK], DatanodeInfoWithStorage[127.0.0.1:41290,DS-86132b42-702f-4a82-a751-952548ada04f,DISK], DatanodeInfoWithStorage[127.0.0.1:35165,DS-a9f67914-c9ce-4d1d-834f-b029e7c8fd29,DISK], DatanodeInfoWithStorage[127.0.0.1:37310,DS-385f7e2f-4284-4f1d-96b2-143534f5f441,DISK], DatanodeInfoWithStorage[127.0.0.1:34848,DS-22092bda-e152-4e96-9006-780c77f969f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 16 out of 50
result: false positive !!!
Total execution time in seconds : 5293
