reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-512351624-172.17.0.9-1597526731704:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38509,DS-58e6e566-1a7d-4b53-96aa-ecb9ff36cc37,DISK], DatanodeInfoWithStorage[127.0.0.1:44019,DS-71c51a67-0f3f-4a39-ae24-4c8edbcb84a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33770,DS-71df7ec4-15c9-4eaa-b961-8dbe4721ebaf,DISK], DatanodeInfoWithStorage[127.0.0.1:44158,DS-37be300c-1af1-4f60-9262-00443eaebd73,DISK], DatanodeInfoWithStorage[127.0.0.1:35120,DS-c3bd3d86-85db-4cce-b9c6-35e952036d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:41944,DS-de6ea652-6579-42d0-86bf-a25e0e60cce9,DISK], DatanodeInfoWithStorage[127.0.0.1:38553,DS-4fee20ec-e9b9-44a5-9178-8afc6f2987dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40950,DS-60746285-850b-4b8e-9b3c-43cf8b745486,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-512351624-172.17.0.9-1597526731704:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38509,DS-58e6e566-1a7d-4b53-96aa-ecb9ff36cc37,DISK], DatanodeInfoWithStorage[127.0.0.1:44019,DS-71c51a67-0f3f-4a39-ae24-4c8edbcb84a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33770,DS-71df7ec4-15c9-4eaa-b961-8dbe4721ebaf,DISK], DatanodeInfoWithStorage[127.0.0.1:44158,DS-37be300c-1af1-4f60-9262-00443eaebd73,DISK], DatanodeInfoWithStorage[127.0.0.1:35120,DS-c3bd3d86-85db-4cce-b9c6-35e952036d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:41944,DS-de6ea652-6579-42d0-86bf-a25e0e60cce9,DISK], DatanodeInfoWithStorage[127.0.0.1:38553,DS-4fee20ec-e9b9-44a5-9178-8afc6f2987dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40950,DS-60746285-850b-4b8e-9b3c-43cf8b745486,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1570115546-172.17.0.9-1597526767046:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40426,DS-50ee2c0a-f44b-451e-85fe-50a14f332abe,DISK], DatanodeInfoWithStorage[127.0.0.1:37476,DS-8386afca-d2b9-4e75-949d-1e1f9cf189eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39782,DS-caa514b7-27e2-4d68-b862-51b2d596d809,DISK], DatanodeInfoWithStorage[127.0.0.1:36853,DS-e8062222-8a13-4827-8580-616110fd5856,DISK], DatanodeInfoWithStorage[127.0.0.1:36988,DS-288a4932-d32e-45ee-8aa8-34c008db5427,DISK], DatanodeInfoWithStorage[127.0.0.1:38658,DS-f09dc996-7a8a-4980-a6f7-4b9cbc52a77f,DISK], DatanodeInfoWithStorage[127.0.0.1:42702,DS-c8f48ac5-47c2-4abf-a4d8-f9c89b9dec36,DISK], DatanodeInfoWithStorage[127.0.0.1:32829,DS-ac0e287e-0959-4886-b20b-7775ce692fd4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1570115546-172.17.0.9-1597526767046:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40426,DS-50ee2c0a-f44b-451e-85fe-50a14f332abe,DISK], DatanodeInfoWithStorage[127.0.0.1:37476,DS-8386afca-d2b9-4e75-949d-1e1f9cf189eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39782,DS-caa514b7-27e2-4d68-b862-51b2d596d809,DISK], DatanodeInfoWithStorage[127.0.0.1:36853,DS-e8062222-8a13-4827-8580-616110fd5856,DISK], DatanodeInfoWithStorage[127.0.0.1:36988,DS-288a4932-d32e-45ee-8aa8-34c008db5427,DISK], DatanodeInfoWithStorage[127.0.0.1:38658,DS-f09dc996-7a8a-4980-a6f7-4b9cbc52a77f,DISK], DatanodeInfoWithStorage[127.0.0.1:42702,DS-c8f48ac5-47c2-4abf-a4d8-f9c89b9dec36,DISK], DatanodeInfoWithStorage[127.0.0.1:32829,DS-ac0e287e-0959-4886-b20b-7775ce692fd4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-477712568-172.17.0.9-1597527050141:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35588,DS-d7a71bfa-c0ac-4afb-a985-a78a0499e939,DISK], DatanodeInfoWithStorage[127.0.0.1:33018,DS-7b466fba-a839-41e5-91be-8ff8a2715233,DISK], DatanodeInfoWithStorage[127.0.0.1:44912,DS-f084c7fc-25c1-422d-b0ad-bf7f88ee6508,DISK], DatanodeInfoWithStorage[127.0.0.1:42966,DS-084833c2-c1d2-4a6c-b589-25f274d8375d,DISK], DatanodeInfoWithStorage[127.0.0.1:37510,DS-0982e9b4-e7e2-4390-9c5d-dbbfbeec80b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33001,DS-93bbf848-edc0-4511-bee1-3d64ef813dac,DISK], DatanodeInfoWithStorage[127.0.0.1:42686,DS-21ed21c5-f525-4a93-b4c1-c06730be7af6,DISK], DatanodeInfoWithStorage[127.0.0.1:39747,DS-105283cd-de4f-4896-8307-4843973f7973,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-477712568-172.17.0.9-1597527050141:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35588,DS-d7a71bfa-c0ac-4afb-a985-a78a0499e939,DISK], DatanodeInfoWithStorage[127.0.0.1:33018,DS-7b466fba-a839-41e5-91be-8ff8a2715233,DISK], DatanodeInfoWithStorage[127.0.0.1:44912,DS-f084c7fc-25c1-422d-b0ad-bf7f88ee6508,DISK], DatanodeInfoWithStorage[127.0.0.1:42966,DS-084833c2-c1d2-4a6c-b589-25f274d8375d,DISK], DatanodeInfoWithStorage[127.0.0.1:37510,DS-0982e9b4-e7e2-4390-9c5d-dbbfbeec80b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33001,DS-93bbf848-edc0-4511-bee1-3d64ef813dac,DISK], DatanodeInfoWithStorage[127.0.0.1:42686,DS-21ed21c5-f525-4a93-b4c1-c06730be7af6,DISK], DatanodeInfoWithStorage[127.0.0.1:39747,DS-105283cd-de4f-4896-8307-4843973f7973,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-845586161-172.17.0.9-1597527366555:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38749,DS-4a763c8b-48aa-466e-a36f-e99f4d202eeb,DISK], DatanodeInfoWithStorage[127.0.0.1:41847,DS-ccb30922-afdb-4eb1-b22a-83ab3bfac1e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35276,DS-79c93078-57f2-4d36-8ad9-51cb61a08918,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-ef790785-790d-434d-9573-73ba284452fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41207,DS-9966aa68-ee03-4b3f-b7bf-ad64a41464c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39951,DS-799c03d6-a628-41d3-b9c5-2d224410c05e,DISK], DatanodeInfoWithStorage[127.0.0.1:36373,DS-41365346-6950-4c11-8ff6-800889d88a88,DISK], DatanodeInfoWithStorage[127.0.0.1:39797,DS-5d50014a-689c-4835-872c-6df6266ded3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-845586161-172.17.0.9-1597527366555:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38749,DS-4a763c8b-48aa-466e-a36f-e99f4d202eeb,DISK], DatanodeInfoWithStorage[127.0.0.1:41847,DS-ccb30922-afdb-4eb1-b22a-83ab3bfac1e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35276,DS-79c93078-57f2-4d36-8ad9-51cb61a08918,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-ef790785-790d-434d-9573-73ba284452fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41207,DS-9966aa68-ee03-4b3f-b7bf-ad64a41464c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39951,DS-799c03d6-a628-41d3-b9c5-2d224410c05e,DISK], DatanodeInfoWithStorage[127.0.0.1:36373,DS-41365346-6950-4c11-8ff6-800889d88a88,DISK], DatanodeInfoWithStorage[127.0.0.1:39797,DS-5d50014a-689c-4835-872c-6df6266ded3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1596614689-172.17.0.9-1597527933724:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46307,DS-9a14f81d-15a0-4b13-9ca9-d09f05048630,DISK], DatanodeInfoWithStorage[127.0.0.1:46088,DS-53539433-76a3-46e1-b638-cf65df28e266,DISK], DatanodeInfoWithStorage[127.0.0.1:36913,DS-5a6d95c7-9c81-493d-94d0-1cdba07d981d,DISK], DatanodeInfoWithStorage[127.0.0.1:40965,DS-b48576d5-978d-4654-947a-3f93d5888ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:33587,DS-622745a2-bb0d-4188-8861-d26bb3e55782,DISK], DatanodeInfoWithStorage[127.0.0.1:40581,DS-bf2cd251-24c7-4569-bf6a-f80a07e15b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:35746,DS-6a2e363f-add7-4124-8304-58ece6b63ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:41485,DS-2fcedd96-270f-4003-a20f-a035d681c938,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1596614689-172.17.0.9-1597527933724:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46307,DS-9a14f81d-15a0-4b13-9ca9-d09f05048630,DISK], DatanodeInfoWithStorage[127.0.0.1:46088,DS-53539433-76a3-46e1-b638-cf65df28e266,DISK], DatanodeInfoWithStorage[127.0.0.1:36913,DS-5a6d95c7-9c81-493d-94d0-1cdba07d981d,DISK], DatanodeInfoWithStorage[127.0.0.1:40965,DS-b48576d5-978d-4654-947a-3f93d5888ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:33587,DS-622745a2-bb0d-4188-8861-d26bb3e55782,DISK], DatanodeInfoWithStorage[127.0.0.1:40581,DS-bf2cd251-24c7-4569-bf6a-f80a07e15b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:35746,DS-6a2e363f-add7-4124-8304-58ece6b63ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:41485,DS-2fcedd96-270f-4003-a20f-a035d681c938,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-743207836-172.17.0.9-1597528117599:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42281,DS-8e019ea7-3942-46b7-8b55-e59de46dc1d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37843,DS-6eed8fa0-589d-4987-beeb-6cad64beb80a,DISK], DatanodeInfoWithStorage[127.0.0.1:36008,DS-767771ed-553e-48d9-996e-ada02b1a3c01,DISK], DatanodeInfoWithStorage[127.0.0.1:46647,DS-75bc7a1c-6f2f-46b0-8220-27908cb0e45c,DISK], DatanodeInfoWithStorage[127.0.0.1:33470,DS-567f8dfc-b5ed-49af-b7d1-a302330c50e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40672,DS-a3ac5321-05f5-427f-9360-6d14a14bbb73,DISK], DatanodeInfoWithStorage[127.0.0.1:34469,DS-b1b0c6ff-ca4b-407d-bafb-3fe4d1332fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:33143,DS-ac3be5aa-f315-4049-b4c3-4743958c0c6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-743207836-172.17.0.9-1597528117599:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42281,DS-8e019ea7-3942-46b7-8b55-e59de46dc1d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37843,DS-6eed8fa0-589d-4987-beeb-6cad64beb80a,DISK], DatanodeInfoWithStorage[127.0.0.1:36008,DS-767771ed-553e-48d9-996e-ada02b1a3c01,DISK], DatanodeInfoWithStorage[127.0.0.1:46647,DS-75bc7a1c-6f2f-46b0-8220-27908cb0e45c,DISK], DatanodeInfoWithStorage[127.0.0.1:33470,DS-567f8dfc-b5ed-49af-b7d1-a302330c50e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40672,DS-a3ac5321-05f5-427f-9360-6d14a14bbb73,DISK], DatanodeInfoWithStorage[127.0.0.1:34469,DS-b1b0c6ff-ca4b-407d-bafb-3fe4d1332fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:33143,DS-ac3be5aa-f315-4049-b4c3-4743958c0c6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1516273208-172.17.0.9-1597528255536:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38353,DS-230f8105-48c6-48ce-b4b7-af83f097bb8c,DISK], DatanodeInfoWithStorage[127.0.0.1:40296,DS-09f42715-ba4a-4431-aa0e-01720f05df8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36595,DS-80208e88-0668-4742-9d55-b6ed31b451aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39515,DS-2fe3ad38-c6b3-4059-a7e4-9dfe1e2997c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44704,DS-3380c189-a1d1-4916-b947-7470880c946f,DISK], DatanodeInfoWithStorage[127.0.0.1:38625,DS-75385cbb-49ab-4ccb-9bd9-e571c3bb8d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:36737,DS-782c035d-ea15-4bb1-a51c-9c9e626b4e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:38849,DS-8b77de85-7c44-4feb-9beb-bf63156a6579,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1516273208-172.17.0.9-1597528255536:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38353,DS-230f8105-48c6-48ce-b4b7-af83f097bb8c,DISK], DatanodeInfoWithStorage[127.0.0.1:40296,DS-09f42715-ba4a-4431-aa0e-01720f05df8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36595,DS-80208e88-0668-4742-9d55-b6ed31b451aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39515,DS-2fe3ad38-c6b3-4059-a7e4-9dfe1e2997c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44704,DS-3380c189-a1d1-4916-b947-7470880c946f,DISK], DatanodeInfoWithStorage[127.0.0.1:38625,DS-75385cbb-49ab-4ccb-9bd9-e571c3bb8d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:36737,DS-782c035d-ea15-4bb1-a51c-9c9e626b4e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:38849,DS-8b77de85-7c44-4feb-9beb-bf63156a6579,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-827828859-172.17.0.9-1597528550894:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41492,DS-a32f00ae-f613-4d12-8295-3703076a1309,DISK], DatanodeInfoWithStorage[127.0.0.1:39530,DS-bead053b-0759-4a34-9662-93d5a2ec5b63,DISK], DatanodeInfoWithStorage[127.0.0.1:33708,DS-428234dc-a288-4f7d-a3aa-fb709c41c1f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46541,DS-14c095cf-4f04-44ac-a960-0d8982ee6d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:45407,DS-51bee43d-cbdb-4633-8dc9-0d13890a3022,DISK], DatanodeInfoWithStorage[127.0.0.1:35839,DS-15b0b596-f7b9-445d-8a43-a23817a988e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42042,DS-6ea18e52-1ff7-44d1-b4fb-d62b22426674,DISK], DatanodeInfoWithStorage[127.0.0.1:45658,DS-f28fb31c-b279-46cc-a144-38f72c9378e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-827828859-172.17.0.9-1597528550894:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41492,DS-a32f00ae-f613-4d12-8295-3703076a1309,DISK], DatanodeInfoWithStorage[127.0.0.1:39530,DS-bead053b-0759-4a34-9662-93d5a2ec5b63,DISK], DatanodeInfoWithStorage[127.0.0.1:33708,DS-428234dc-a288-4f7d-a3aa-fb709c41c1f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46541,DS-14c095cf-4f04-44ac-a960-0d8982ee6d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:45407,DS-51bee43d-cbdb-4633-8dc9-0d13890a3022,DISK], DatanodeInfoWithStorage[127.0.0.1:35839,DS-15b0b596-f7b9-445d-8a43-a23817a988e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42042,DS-6ea18e52-1ff7-44d1-b4fb-d62b22426674,DISK], DatanodeInfoWithStorage[127.0.0.1:45658,DS-f28fb31c-b279-46cc-a144-38f72c9378e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-777510755-172.17.0.9-1597529000972:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41121,DS-402da03d-bdae-411f-8c86-274b1cf82245,DISK], DatanodeInfoWithStorage[127.0.0.1:42609,DS-433ba72b-116c-4f50-b8df-ba2d71f68772,DISK], DatanodeInfoWithStorage[127.0.0.1:35545,DS-134d6c3c-dfb3-45fa-bea8-81747003a491,DISK], DatanodeInfoWithStorage[127.0.0.1:33341,DS-e558badb-f733-442b-9c7b-aa72948b7a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:46584,DS-4e46b0b2-7877-4726-a760-142097725370,DISK], DatanodeInfoWithStorage[127.0.0.1:33288,DS-190b54d8-310f-4214-94cd-ba45478c2b88,DISK], DatanodeInfoWithStorage[127.0.0.1:39273,DS-78f66869-097c-4812-bed7-ce5697bc6cba,DISK], DatanodeInfoWithStorage[127.0.0.1:33098,DS-3138cb25-69e9-43d8-b4d2-4e28694f7d3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-777510755-172.17.0.9-1597529000972:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41121,DS-402da03d-bdae-411f-8c86-274b1cf82245,DISK], DatanodeInfoWithStorage[127.0.0.1:42609,DS-433ba72b-116c-4f50-b8df-ba2d71f68772,DISK], DatanodeInfoWithStorage[127.0.0.1:35545,DS-134d6c3c-dfb3-45fa-bea8-81747003a491,DISK], DatanodeInfoWithStorage[127.0.0.1:33341,DS-e558badb-f733-442b-9c7b-aa72948b7a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:46584,DS-4e46b0b2-7877-4726-a760-142097725370,DISK], DatanodeInfoWithStorage[127.0.0.1:33288,DS-190b54d8-310f-4214-94cd-ba45478c2b88,DISK], DatanodeInfoWithStorage[127.0.0.1:39273,DS-78f66869-097c-4812-bed7-ce5697bc6cba,DISK], DatanodeInfoWithStorage[127.0.0.1:33098,DS-3138cb25-69e9-43d8-b4d2-4e28694f7d3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1453102378-172.17.0.9-1597529034104:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42128,DS-f8ad0d66-1d19-47b9-9ca0-1f6b123d3b27,DISK], DatanodeInfoWithStorage[127.0.0.1:33090,DS-d3b48474-01e9-4e05-9286-ccf2d787173a,DISK], DatanodeInfoWithStorage[127.0.0.1:44067,DS-a1dfc3a5-c80e-4a73-a05d-b1f7c66c19e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38342,DS-84c94e9e-3b9f-4146-8cb9-990e1c156be4,DISK], DatanodeInfoWithStorage[127.0.0.1:44516,DS-ced21a40-1f34-40ce-8fd5-69d46613b75e,DISK], DatanodeInfoWithStorage[127.0.0.1:38826,DS-b90965e0-4a4e-4f3e-88cc-37285d858ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:32833,DS-c8ea82c6-cfc7-45dc-a399-98bd3e1b92a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37534,DS-25a1c62e-fc89-4bf8-bead-9c2b21873e5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1453102378-172.17.0.9-1597529034104:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42128,DS-f8ad0d66-1d19-47b9-9ca0-1f6b123d3b27,DISK], DatanodeInfoWithStorage[127.0.0.1:33090,DS-d3b48474-01e9-4e05-9286-ccf2d787173a,DISK], DatanodeInfoWithStorage[127.0.0.1:44067,DS-a1dfc3a5-c80e-4a73-a05d-b1f7c66c19e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38342,DS-84c94e9e-3b9f-4146-8cb9-990e1c156be4,DISK], DatanodeInfoWithStorage[127.0.0.1:44516,DS-ced21a40-1f34-40ce-8fd5-69d46613b75e,DISK], DatanodeInfoWithStorage[127.0.0.1:38826,DS-b90965e0-4a4e-4f3e-88cc-37285d858ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:32833,DS-c8ea82c6-cfc7-45dc-a399-98bd3e1b92a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37534,DS-25a1c62e-fc89-4bf8-bead-9c2b21873e5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1430693107-172.17.0.9-1597529080886:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37086,DS-c600930f-bc0a-483b-8ea4-cdcc158eca78,DISK], DatanodeInfoWithStorage[127.0.0.1:39398,DS-56fb953a-ae3a-4406-9ad0-813c625be9a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35455,DS-8a13e6e2-f613-47ba-b8a2-e71012ebe011,DISK], DatanodeInfoWithStorage[127.0.0.1:43763,DS-4f3aaa68-749e-4454-928a-70d035adf021,DISK], DatanodeInfoWithStorage[127.0.0.1:35662,DS-e9f9ac1c-cc61-4dd3-98ad-77ea10ab4e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:38423,DS-36f7b5b2-371b-4bae-b828-8960a8297483,DISK], DatanodeInfoWithStorage[127.0.0.1:46441,DS-be6e91dc-c8ce-49df-a1cf-ae91157657b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42485,DS-e8c1fbb2-873a-42b9-8ac3-b178f65c0fe3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1430693107-172.17.0.9-1597529080886:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37086,DS-c600930f-bc0a-483b-8ea4-cdcc158eca78,DISK], DatanodeInfoWithStorage[127.0.0.1:39398,DS-56fb953a-ae3a-4406-9ad0-813c625be9a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35455,DS-8a13e6e2-f613-47ba-b8a2-e71012ebe011,DISK], DatanodeInfoWithStorage[127.0.0.1:43763,DS-4f3aaa68-749e-4454-928a-70d035adf021,DISK], DatanodeInfoWithStorage[127.0.0.1:35662,DS-e9f9ac1c-cc61-4dd3-98ad-77ea10ab4e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:38423,DS-36f7b5b2-371b-4bae-b828-8960a8297483,DISK], DatanodeInfoWithStorage[127.0.0.1:46441,DS-be6e91dc-c8ce-49df-a1cf-ae91157657b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42485,DS-e8c1fbb2-873a-42b9-8ac3-b178f65c0fe3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1005430368-172.17.0.9-1597529346140:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36263,DS-3509d863-b38a-4da2-a8a8-6af633c6388f,DISK], DatanodeInfoWithStorage[127.0.0.1:44464,DS-8ef6d0af-8064-4df9-8525-98b1e751e05d,DISK], DatanodeInfoWithStorage[127.0.0.1:46766,DS-7c5d36ca-d7ed-4f9d-80c7-42da5a4f6aac,DISK], DatanodeInfoWithStorage[127.0.0.1:46029,DS-54532b36-31b3-48ce-b749-681d45440f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:40766,DS-f38eb6a5-75ec-4c97-b7cc-3d5e56a53855,DISK], DatanodeInfoWithStorage[127.0.0.1:46076,DS-6ba26032-715b-44d0-a4da-d56e7ff76033,DISK], DatanodeInfoWithStorage[127.0.0.1:42581,DS-19977ecd-025a-490a-a649-0f7353a0f054,DISK], DatanodeInfoWithStorage[127.0.0.1:43883,DS-cc4ffa53-a197-4cc7-862d-6baa9e07bbaa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1005430368-172.17.0.9-1597529346140:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36263,DS-3509d863-b38a-4da2-a8a8-6af633c6388f,DISK], DatanodeInfoWithStorage[127.0.0.1:44464,DS-8ef6d0af-8064-4df9-8525-98b1e751e05d,DISK], DatanodeInfoWithStorage[127.0.0.1:46766,DS-7c5d36ca-d7ed-4f9d-80c7-42da5a4f6aac,DISK], DatanodeInfoWithStorage[127.0.0.1:46029,DS-54532b36-31b3-48ce-b749-681d45440f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:40766,DS-f38eb6a5-75ec-4c97-b7cc-3d5e56a53855,DISK], DatanodeInfoWithStorage[127.0.0.1:46076,DS-6ba26032-715b-44d0-a4da-d56e7ff76033,DISK], DatanodeInfoWithStorage[127.0.0.1:42581,DS-19977ecd-025a-490a-a649-0f7353a0f054,DISK], DatanodeInfoWithStorage[127.0.0.1:43883,DS-cc4ffa53-a197-4cc7-862d-6baa9e07bbaa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-422129640-172.17.0.9-1597529451891:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45491,DS-4ba7494d-faca-49a3-b68b-9aafd5f8b14c,DISK], DatanodeInfoWithStorage[127.0.0.1:44868,DS-3fbe4916-7c91-4524-b205-1b9b409ea9dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41197,DS-45e41b73-f6d5-4a6c-8796-0c4c4bf1079a,DISK], DatanodeInfoWithStorage[127.0.0.1:44210,DS-4ece25f4-127f-4410-a4d8-4a917efd3f00,DISK], DatanodeInfoWithStorage[127.0.0.1:43669,DS-c4d2edb4-3c59-40ef-bf03-2fb645b7c72b,DISK], DatanodeInfoWithStorage[127.0.0.1:36561,DS-7ab64bca-4964-4301-a117-f05a80279ece,DISK], DatanodeInfoWithStorage[127.0.0.1:41555,DS-8aca0237-169c-40c0-8807-7be4435dbe0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36592,DS-faf74ab3-e4d7-4dba-8067-7bf89af330af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-422129640-172.17.0.9-1597529451891:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45491,DS-4ba7494d-faca-49a3-b68b-9aafd5f8b14c,DISK], DatanodeInfoWithStorage[127.0.0.1:44868,DS-3fbe4916-7c91-4524-b205-1b9b409ea9dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41197,DS-45e41b73-f6d5-4a6c-8796-0c4c4bf1079a,DISK], DatanodeInfoWithStorage[127.0.0.1:44210,DS-4ece25f4-127f-4410-a4d8-4a917efd3f00,DISK], DatanodeInfoWithStorage[127.0.0.1:43669,DS-c4d2edb4-3c59-40ef-bf03-2fb645b7c72b,DISK], DatanodeInfoWithStorage[127.0.0.1:36561,DS-7ab64bca-4964-4301-a117-f05a80279ece,DISK], DatanodeInfoWithStorage[127.0.0.1:41555,DS-8aca0237-169c-40c0-8807-7be4435dbe0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36592,DS-faf74ab3-e4d7-4dba-8067-7bf89af330af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1827371464-172.17.0.9-1597529649662:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38742,DS-02021f55-918b-4f48-ade3-4ab8073cbcfb,DISK], DatanodeInfoWithStorage[127.0.0.1:43967,DS-bfe80b20-e893-45dd-8728-77be30c63974,DISK], DatanodeInfoWithStorage[127.0.0.1:45913,DS-10d52d97-86c8-4cf3-8126-d9e85dd54809,DISK], DatanodeInfoWithStorage[127.0.0.1:39662,DS-883c0bce-cd37-41fa-af51-3b87d51a3eac,DISK], DatanodeInfoWithStorage[127.0.0.1:34363,DS-6f562723-4831-4b61-8802-9572fe46dbd2,DISK], DatanodeInfoWithStorage[127.0.0.1:39181,DS-a9732a3e-5d2b-4197-8258-28a18ee686f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43541,DS-dd64470c-3d94-4b4f-8928-6f4d476f81d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35572,DS-1969a9fb-0a88-4e7b-be13-be6adde02a8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1827371464-172.17.0.9-1597529649662:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38742,DS-02021f55-918b-4f48-ade3-4ab8073cbcfb,DISK], DatanodeInfoWithStorage[127.0.0.1:43967,DS-bfe80b20-e893-45dd-8728-77be30c63974,DISK], DatanodeInfoWithStorage[127.0.0.1:45913,DS-10d52d97-86c8-4cf3-8126-d9e85dd54809,DISK], DatanodeInfoWithStorage[127.0.0.1:39662,DS-883c0bce-cd37-41fa-af51-3b87d51a3eac,DISK], DatanodeInfoWithStorage[127.0.0.1:34363,DS-6f562723-4831-4b61-8802-9572fe46dbd2,DISK], DatanodeInfoWithStorage[127.0.0.1:39181,DS-a9732a3e-5d2b-4197-8258-28a18ee686f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43541,DS-dd64470c-3d94-4b4f-8928-6f4d476f81d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35572,DS-1969a9fb-0a88-4e7b-be13-be6adde02a8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1123078478-172.17.0.9-1597529903239:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34410,DS-f0601e5c-ff1f-483e-8de2-f41528439ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:43745,DS-0bee6a76-5192-46f9-b169-866ff290b326,DISK], DatanodeInfoWithStorage[127.0.0.1:34167,DS-470764ea-074a-4eb2-97fa-cb26e5755ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:38894,DS-08f79cbf-359d-4a35-8791-65a8c7a3cd06,DISK], DatanodeInfoWithStorage[127.0.0.1:33914,DS-c9244083-e46c-46a4-8f1c-ea571c2a3c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:33800,DS-e373a0d6-9d7a-4bae-ae0c-0e23dba3fe34,DISK], DatanodeInfoWithStorage[127.0.0.1:44151,DS-f74f855c-bc5a-47b3-a3c9-f1f3f3eebebb,DISK], DatanodeInfoWithStorage[127.0.0.1:42946,DS-046906fd-b05b-4db8-a028-ffbc998a4bfb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1123078478-172.17.0.9-1597529903239:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34410,DS-f0601e5c-ff1f-483e-8de2-f41528439ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:43745,DS-0bee6a76-5192-46f9-b169-866ff290b326,DISK], DatanodeInfoWithStorage[127.0.0.1:34167,DS-470764ea-074a-4eb2-97fa-cb26e5755ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:38894,DS-08f79cbf-359d-4a35-8791-65a8c7a3cd06,DISK], DatanodeInfoWithStorage[127.0.0.1:33914,DS-c9244083-e46c-46a4-8f1c-ea571c2a3c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:33800,DS-e373a0d6-9d7a-4bae-ae0c-0e23dba3fe34,DISK], DatanodeInfoWithStorage[127.0.0.1:44151,DS-f74f855c-bc5a-47b3-a3c9-f1f3f3eebebb,DISK], DatanodeInfoWithStorage[127.0.0.1:42946,DS-046906fd-b05b-4db8-a028-ffbc998a4bfb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1882614783-172.17.0.9-1597530234467:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39603,DS-a07eec58-0f88-48e1-87aa-434eda2f1dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:42139,DS-228798f0-cda9-4314-ae78-3138b11b1fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:35293,DS-942cfcfb-cca1-4452-a36e-66d1701eb782,DISK], DatanodeInfoWithStorage[127.0.0.1:35754,DS-e62a45b5-6e68-4ba8-8114-6e836063e0d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41290,DS-a78e3d00-b9fb-4414-a816-87da7772ed06,DISK], DatanodeInfoWithStorage[127.0.0.1:39748,DS-3cc9eff7-942e-4481-a07e-111226f943eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44024,DS-fb96d2f4-59c7-41b3-a3f8-e75699767e74,DISK], DatanodeInfoWithStorage[127.0.0.1:40576,DS-3c6383c1-4104-461a-9ed5-f257e39939a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1882614783-172.17.0.9-1597530234467:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39603,DS-a07eec58-0f88-48e1-87aa-434eda2f1dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:42139,DS-228798f0-cda9-4314-ae78-3138b11b1fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:35293,DS-942cfcfb-cca1-4452-a36e-66d1701eb782,DISK], DatanodeInfoWithStorage[127.0.0.1:35754,DS-e62a45b5-6e68-4ba8-8114-6e836063e0d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41290,DS-a78e3d00-b9fb-4414-a816-87da7772ed06,DISK], DatanodeInfoWithStorage[127.0.0.1:39748,DS-3cc9eff7-942e-4481-a07e-111226f943eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44024,DS-fb96d2f4-59c7-41b3-a3f8-e75699767e74,DISK], DatanodeInfoWithStorage[127.0.0.1:40576,DS-3c6383c1-4104-461a-9ed5-f257e39939a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1093573554-172.17.0.9-1597531147125:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43473,DS-52304c1e-d154-427c-a26d-874b692e5269,DISK], DatanodeInfoWithStorage[127.0.0.1:43323,DS-19edaca9-7637-4987-8e7f-ba87951bb299,DISK], DatanodeInfoWithStorage[127.0.0.1:46749,DS-70ea1424-3930-4b96-9158-c75cba8a1c50,DISK], DatanodeInfoWithStorage[127.0.0.1:46168,DS-a2720e4d-5332-4602-b843-2ac0fc8b195b,DISK], DatanodeInfoWithStorage[127.0.0.1:44024,DS-84af28dd-023e-4b4f-9bdd-52d10c1d9b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38030,DS-94e601ba-1dec-463a-bc13-eeec7d3f4404,DISK], DatanodeInfoWithStorage[127.0.0.1:39106,DS-8c2e3409-293b-48cf-886d-57d548de6981,DISK], DatanodeInfoWithStorage[127.0.0.1:43440,DS-b45b51bb-64df-4ef6-acf7-82b5ff1dd098,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1093573554-172.17.0.9-1597531147125:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43473,DS-52304c1e-d154-427c-a26d-874b692e5269,DISK], DatanodeInfoWithStorage[127.0.0.1:43323,DS-19edaca9-7637-4987-8e7f-ba87951bb299,DISK], DatanodeInfoWithStorage[127.0.0.1:46749,DS-70ea1424-3930-4b96-9158-c75cba8a1c50,DISK], DatanodeInfoWithStorage[127.0.0.1:46168,DS-a2720e4d-5332-4602-b843-2ac0fc8b195b,DISK], DatanodeInfoWithStorage[127.0.0.1:44024,DS-84af28dd-023e-4b4f-9bdd-52d10c1d9b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38030,DS-94e601ba-1dec-463a-bc13-eeec7d3f4404,DISK], DatanodeInfoWithStorage[127.0.0.1:39106,DS-8c2e3409-293b-48cf-886d-57d548de6981,DISK], DatanodeInfoWithStorage[127.0.0.1:43440,DS-b45b51bb-64df-4ef6-acf7-82b5ff1dd098,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1326161692-172.17.0.9-1597531759754:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35797,DS-d00cb0c3-5124-4317-b31a-387af3f1a2ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36201,DS-a9856b39-61d0-4fbd-8c2c-070f4940a89d,DISK], DatanodeInfoWithStorage[127.0.0.1:42453,DS-e3270579-b17b-4f72-88d4-5b9bceda6a07,DISK], DatanodeInfoWithStorage[127.0.0.1:34559,DS-574cc8f5-8e4a-489a-ab0c-6a8f9f4ee4c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42702,DS-be02b687-9f9d-4f32-bf9d-3434b1a3a81f,DISK], DatanodeInfoWithStorage[127.0.0.1:44148,DS-f5634b4a-6f4d-4ceb-bde9-ee2776d516f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33399,DS-01360355-6d7a-41b7-a2f4-659b7c065ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:36202,DS-3b54de67-4c7d-4bc1-ac78-db20726a9fb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1326161692-172.17.0.9-1597531759754:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35797,DS-d00cb0c3-5124-4317-b31a-387af3f1a2ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36201,DS-a9856b39-61d0-4fbd-8c2c-070f4940a89d,DISK], DatanodeInfoWithStorage[127.0.0.1:42453,DS-e3270579-b17b-4f72-88d4-5b9bceda6a07,DISK], DatanodeInfoWithStorage[127.0.0.1:34559,DS-574cc8f5-8e4a-489a-ab0c-6a8f9f4ee4c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42702,DS-be02b687-9f9d-4f32-bf9d-3434b1a3a81f,DISK], DatanodeInfoWithStorage[127.0.0.1:44148,DS-f5634b4a-6f4d-4ceb-bde9-ee2776d516f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33399,DS-01360355-6d7a-41b7-a2f4-659b7c065ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:36202,DS-3b54de67-4c7d-4bc1-ac78-db20726a9fb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-80788813-172.17.0.9-1597531831461:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34298,DS-a0ee11f5-51f6-4c86-a41b-fd2093d2f152,DISK], DatanodeInfoWithStorage[127.0.0.1:33918,DS-9f2bd503-362f-4e46-abaa-ea6cded1b07d,DISK], DatanodeInfoWithStorage[127.0.0.1:43406,DS-e102a8a9-a7d2-45a0-8bf3-5afadb06036b,DISK], DatanodeInfoWithStorage[127.0.0.1:39897,DS-f5ae8caf-8397-4e88-918a-cdd94be5e50a,DISK], DatanodeInfoWithStorage[127.0.0.1:42222,DS-c3f6b3cc-9e46-4863-8e9a-2046a99fc96b,DISK], DatanodeInfoWithStorage[127.0.0.1:33279,DS-913e4b3b-ac63-4af7-8d40-2d4a4de762ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42430,DS-1aecf779-4244-45d2-add6-59e099a9428b,DISK], DatanodeInfoWithStorage[127.0.0.1:44257,DS-06f19b8d-eb27-42e4-b1d2-d3755c30e220,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-80788813-172.17.0.9-1597531831461:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34298,DS-a0ee11f5-51f6-4c86-a41b-fd2093d2f152,DISK], DatanodeInfoWithStorage[127.0.0.1:33918,DS-9f2bd503-362f-4e46-abaa-ea6cded1b07d,DISK], DatanodeInfoWithStorage[127.0.0.1:43406,DS-e102a8a9-a7d2-45a0-8bf3-5afadb06036b,DISK], DatanodeInfoWithStorage[127.0.0.1:39897,DS-f5ae8caf-8397-4e88-918a-cdd94be5e50a,DISK], DatanodeInfoWithStorage[127.0.0.1:42222,DS-c3f6b3cc-9e46-4863-8e9a-2046a99fc96b,DISK], DatanodeInfoWithStorage[127.0.0.1:33279,DS-913e4b3b-ac63-4af7-8d40-2d4a4de762ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42430,DS-1aecf779-4244-45d2-add6-59e099a9428b,DISK], DatanodeInfoWithStorage[127.0.0.1:44257,DS-06f19b8d-eb27-42e4-b1d2-d3755c30e220,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5459
