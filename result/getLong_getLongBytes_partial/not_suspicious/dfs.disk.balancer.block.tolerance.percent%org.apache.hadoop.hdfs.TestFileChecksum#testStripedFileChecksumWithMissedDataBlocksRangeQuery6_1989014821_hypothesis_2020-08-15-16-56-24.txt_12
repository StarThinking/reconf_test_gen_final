reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 99
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 99
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1577010729-172.17.0.16-1597511410127:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43101,DS-479a4463-4887-458a-bfb8-5a17188243c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46070,DS-51e9086f-5faa-4a73-b2ed-a4a5864ba894,DISK], DatanodeInfoWithStorage[127.0.0.1:40352,DS-3d26f83c-9306-486a-a1d5-f2fca800b4e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42051,DS-0a1a7727-49ac-4acb-a02e-524ee5357564,DISK], DatanodeInfoWithStorage[127.0.0.1:34916,DS-d37dce63-0d5c-4e09-a934-2bb8ae7798c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42179,DS-6b831ce8-9f07-430d-8e48-61bee7ce976c,DISK], DatanodeInfoWithStorage[127.0.0.1:37847,DS-b27ff5e1-cd61-4cde-aace-fc586b9c323d,DISK], DatanodeInfoWithStorage[127.0.0.1:34669,DS-f134ae78-8c43-4f17-8bff-7145102e8bd2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1577010729-172.17.0.16-1597511410127:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43101,DS-479a4463-4887-458a-bfb8-5a17188243c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46070,DS-51e9086f-5faa-4a73-b2ed-a4a5864ba894,DISK], DatanodeInfoWithStorage[127.0.0.1:40352,DS-3d26f83c-9306-486a-a1d5-f2fca800b4e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42051,DS-0a1a7727-49ac-4acb-a02e-524ee5357564,DISK], DatanodeInfoWithStorage[127.0.0.1:34916,DS-d37dce63-0d5c-4e09-a934-2bb8ae7798c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42179,DS-6b831ce8-9f07-430d-8e48-61bee7ce976c,DISK], DatanodeInfoWithStorage[127.0.0.1:37847,DS-b27ff5e1-cd61-4cde-aace-fc586b9c323d,DISK], DatanodeInfoWithStorage[127.0.0.1:34669,DS-f134ae78-8c43-4f17-8bff-7145102e8bd2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 99
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-755273324-172.17.0.16-1597511505152:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41546,DS-8bf23b0d-29f8-4240-a289-431b09426d67,DISK], DatanodeInfoWithStorage[127.0.0.1:34915,DS-cb31cb40-785b-41e7-8a68-a6e8ed52349b,DISK], DatanodeInfoWithStorage[127.0.0.1:44844,DS-b29626a8-d9d8-4d5a-84d0-0ea5b8561478,DISK], DatanodeInfoWithStorage[127.0.0.1:35814,DS-a6adfbb8-9241-4a73-96b4-0ab25a886559,DISK], DatanodeInfoWithStorage[127.0.0.1:38205,DS-6f96857a-6e6f-4e89-97a5-3f361a84637c,DISK], DatanodeInfoWithStorage[127.0.0.1:36690,DS-31a7bbf5-0dc4-4948-ade8-86f29ff57847,DISK], DatanodeInfoWithStorage[127.0.0.1:44061,DS-c1a946ba-306f-4a1e-ad7c-887366e8477b,DISK], DatanodeInfoWithStorage[127.0.0.1:38346,DS-11fd9885-8f9f-48f2-ad1a-3dd53aec65ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-755273324-172.17.0.16-1597511505152:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41546,DS-8bf23b0d-29f8-4240-a289-431b09426d67,DISK], DatanodeInfoWithStorage[127.0.0.1:34915,DS-cb31cb40-785b-41e7-8a68-a6e8ed52349b,DISK], DatanodeInfoWithStorage[127.0.0.1:44844,DS-b29626a8-d9d8-4d5a-84d0-0ea5b8561478,DISK], DatanodeInfoWithStorage[127.0.0.1:35814,DS-a6adfbb8-9241-4a73-96b4-0ab25a886559,DISK], DatanodeInfoWithStorage[127.0.0.1:38205,DS-6f96857a-6e6f-4e89-97a5-3f361a84637c,DISK], DatanodeInfoWithStorage[127.0.0.1:36690,DS-31a7bbf5-0dc4-4948-ade8-86f29ff57847,DISK], DatanodeInfoWithStorage[127.0.0.1:44061,DS-c1a946ba-306f-4a1e-ad7c-887366e8477b,DISK], DatanodeInfoWithStorage[127.0.0.1:38346,DS-11fd9885-8f9f-48f2-ad1a-3dd53aec65ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 99
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-418972552-172.17.0.16-1597511683601:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40368,DS-015ddc77-2bb3-4cee-af70-20fa4dba8ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:38145,DS-5af6de84-23cf-4b8a-81b6-2f8072eb2f28,DISK], DatanodeInfoWithStorage[127.0.0.1:40214,DS-0e8b38d6-da3c-45f5-8509-434caf4351ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43325,DS-cf123f6e-f4ea-47cb-91e1-796c454114f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35758,DS-b88656c4-5883-4c46-843c-18496a260dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:46149,DS-ac3d0439-8520-4544-a9b9-73d8d2109ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:46636,DS-a5ef8c63-85c3-4660-9faa-897ee3704c98,DISK], DatanodeInfoWithStorage[127.0.0.1:38299,DS-18213605-df00-4a7b-b7d3-29adca6fb865,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-418972552-172.17.0.16-1597511683601:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40368,DS-015ddc77-2bb3-4cee-af70-20fa4dba8ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:38145,DS-5af6de84-23cf-4b8a-81b6-2f8072eb2f28,DISK], DatanodeInfoWithStorage[127.0.0.1:40214,DS-0e8b38d6-da3c-45f5-8509-434caf4351ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43325,DS-cf123f6e-f4ea-47cb-91e1-796c454114f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35758,DS-b88656c4-5883-4c46-843c-18496a260dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:46149,DS-ac3d0439-8520-4544-a9b9-73d8d2109ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:46636,DS-a5ef8c63-85c3-4660-9faa-897ee3704c98,DISK], DatanodeInfoWithStorage[127.0.0.1:38299,DS-18213605-df00-4a7b-b7d3-29adca6fb865,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 99
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-395297479-172.17.0.16-1597511822193:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40560,DS-e3a7b4b1-5bd9-4db0-868c-b8f18d3b2873,DISK], DatanodeInfoWithStorage[127.0.0.1:35190,DS-fbce370c-50ed-4008-ae89-a9dab33bd53e,DISK], DatanodeInfoWithStorage[127.0.0.1:36242,DS-bd9bfd23-d637-470f-b946-e130ea480ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:43436,DS-7f0a2598-56f0-470f-9960-739b80a55373,DISK], DatanodeInfoWithStorage[127.0.0.1:40647,DS-843ae38f-48ee-4a0b-a45e-b9add262aea1,DISK], DatanodeInfoWithStorage[127.0.0.1:42819,DS-0af48e53-a099-4f81-884b-476ef1665f01,DISK], DatanodeInfoWithStorage[127.0.0.1:42425,DS-165b2340-7bc2-4180-a093-d2752812457f,DISK], DatanodeInfoWithStorage[127.0.0.1:42918,DS-82d614ee-efa4-4fdf-abc6-3c6d46961e76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-395297479-172.17.0.16-1597511822193:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40560,DS-e3a7b4b1-5bd9-4db0-868c-b8f18d3b2873,DISK], DatanodeInfoWithStorage[127.0.0.1:35190,DS-fbce370c-50ed-4008-ae89-a9dab33bd53e,DISK], DatanodeInfoWithStorage[127.0.0.1:36242,DS-bd9bfd23-d637-470f-b946-e130ea480ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:43436,DS-7f0a2598-56f0-470f-9960-739b80a55373,DISK], DatanodeInfoWithStorage[127.0.0.1:40647,DS-843ae38f-48ee-4a0b-a45e-b9add262aea1,DISK], DatanodeInfoWithStorage[127.0.0.1:42819,DS-0af48e53-a099-4f81-884b-476ef1665f01,DISK], DatanodeInfoWithStorage[127.0.0.1:42425,DS-165b2340-7bc2-4180-a093-d2752812457f,DISK], DatanodeInfoWithStorage[127.0.0.1:42918,DS-82d614ee-efa4-4fdf-abc6-3c6d46961e76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 99
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1820384271-172.17.0.16-1597511881498:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39670,DS-59d681d4-a4cf-4568-b3bb-8accffb6112c,DISK], DatanodeInfoWithStorage[127.0.0.1:41547,DS-d42f7893-342f-436b-a49e-d73a9cf95856,DISK], DatanodeInfoWithStorage[127.0.0.1:38685,DS-717691e5-ad69-4f5c-80aa-f17f1876502d,DISK], DatanodeInfoWithStorage[127.0.0.1:34449,DS-49d4e4d2-559e-4c23-a868-897ec257ec3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41223,DS-f673d892-0d81-4571-8309-82134857ea5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43216,DS-b5732144-a469-4652-9305-929c5da64375,DISK], DatanodeInfoWithStorage[127.0.0.1:44448,DS-c2be10b8-d3ec-47c5-afca-aad80cb62dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:34523,DS-bff02ce3-9e6c-408a-b6d3-db37fc9f2500,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1820384271-172.17.0.16-1597511881498:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39670,DS-59d681d4-a4cf-4568-b3bb-8accffb6112c,DISK], DatanodeInfoWithStorage[127.0.0.1:41547,DS-d42f7893-342f-436b-a49e-d73a9cf95856,DISK], DatanodeInfoWithStorage[127.0.0.1:38685,DS-717691e5-ad69-4f5c-80aa-f17f1876502d,DISK], DatanodeInfoWithStorage[127.0.0.1:34449,DS-49d4e4d2-559e-4c23-a868-897ec257ec3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41223,DS-f673d892-0d81-4571-8309-82134857ea5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43216,DS-b5732144-a469-4652-9305-929c5da64375,DISK], DatanodeInfoWithStorage[127.0.0.1:44448,DS-c2be10b8-d3ec-47c5-afca-aad80cb62dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:34523,DS-bff02ce3-9e6c-408a-b6d3-db37fc9f2500,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 99
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1234147135-172.17.0.16-1597512112842:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34783,DS-51aa905c-71d6-4b4d-b640-49a7ed3223b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42076,DS-9e6bb897-6a59-4487-bb70-2eb26460a7a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35464,DS-cc5a8f24-5dd2-4474-98fa-57bd21b3078d,DISK], DatanodeInfoWithStorage[127.0.0.1:32918,DS-19c42284-7791-4e94-8fe9-ca9f74e8478e,DISK], DatanodeInfoWithStorage[127.0.0.1:45184,DS-7d0b6de4-007e-4035-84ce-87e7ab1859ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42149,DS-be381653-70e9-4c10-ad01-8296eb67d7ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41020,DS-9a134ada-3ae7-4f26-a887-a6ebeefa1ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:36772,DS-a279fa83-ebc1-49c6-abea-bb49fe37c16e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1234147135-172.17.0.16-1597512112842:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34783,DS-51aa905c-71d6-4b4d-b640-49a7ed3223b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42076,DS-9e6bb897-6a59-4487-bb70-2eb26460a7a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35464,DS-cc5a8f24-5dd2-4474-98fa-57bd21b3078d,DISK], DatanodeInfoWithStorage[127.0.0.1:32918,DS-19c42284-7791-4e94-8fe9-ca9f74e8478e,DISK], DatanodeInfoWithStorage[127.0.0.1:45184,DS-7d0b6de4-007e-4035-84ce-87e7ab1859ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42149,DS-be381653-70e9-4c10-ad01-8296eb67d7ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41020,DS-9a134ada-3ae7-4f26-a887-a6ebeefa1ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:36772,DS-a279fa83-ebc1-49c6-abea-bb49fe37c16e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 99
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1789049767-172.17.0.16-1597512357001:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41424,DS-15388fac-0245-4fa3-9367-81d09a66983c,DISK], DatanodeInfoWithStorage[127.0.0.1:34610,DS-137a9b64-0e3e-4940-bf2b-7ea05f530e19,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-c389cc24-6f99-4b85-a822-f15ef367fb6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34589,DS-73e7c25e-e937-4566-b04d-8aad4683e135,DISK], DatanodeInfoWithStorage[127.0.0.1:42519,DS-56aec4dd-1f9b-4dc7-9262-0d42400bae6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45586,DS-23b3a93b-4a6e-4409-913c-318fe46ec387,DISK], DatanodeInfoWithStorage[127.0.0.1:33639,DS-8bf9658f-3f2a-4121-a250-70d19889eda4,DISK], DatanodeInfoWithStorage[127.0.0.1:46454,DS-12462676-b88d-41b2-a2ac-6c9636e3eb78,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1789049767-172.17.0.16-1597512357001:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41424,DS-15388fac-0245-4fa3-9367-81d09a66983c,DISK], DatanodeInfoWithStorage[127.0.0.1:34610,DS-137a9b64-0e3e-4940-bf2b-7ea05f530e19,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-c389cc24-6f99-4b85-a822-f15ef367fb6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34589,DS-73e7c25e-e937-4566-b04d-8aad4683e135,DISK], DatanodeInfoWithStorage[127.0.0.1:42519,DS-56aec4dd-1f9b-4dc7-9262-0d42400bae6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45586,DS-23b3a93b-4a6e-4409-913c-318fe46ec387,DISK], DatanodeInfoWithStorage[127.0.0.1:33639,DS-8bf9658f-3f2a-4121-a250-70d19889eda4,DISK], DatanodeInfoWithStorage[127.0.0.1:46454,DS-12462676-b88d-41b2-a2ac-6c9636e3eb78,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 99
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1357807912-172.17.0.16-1597512637388:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33624,DS-e7e75b3a-616c-4aea-bee5-6eb45cb7a1fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34802,DS-c3cdbb11-461b-44e4-9b8f-7561d1f11617,DISK], DatanodeInfoWithStorage[127.0.0.1:32886,DS-469e78eb-d6f4-49df-992c-af721f2342c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41586,DS-fbbc0c41-90ea-4c65-bc25-a8f5e8f3c7da,DISK], DatanodeInfoWithStorage[127.0.0.1:45991,DS-94d9a613-2eb3-4ddd-9419-a52dc91a2988,DISK], DatanodeInfoWithStorage[127.0.0.1:43590,DS-167ffff0-a5de-454d-a04b-e51d6552e0c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36398,DS-44612876-0d0e-4bfc-90f9-e3f237e1c7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41109,DS-d4b7fcc5-cbeb-4acd-8451-9e13cb82d3e8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1357807912-172.17.0.16-1597512637388:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33624,DS-e7e75b3a-616c-4aea-bee5-6eb45cb7a1fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34802,DS-c3cdbb11-461b-44e4-9b8f-7561d1f11617,DISK], DatanodeInfoWithStorage[127.0.0.1:32886,DS-469e78eb-d6f4-49df-992c-af721f2342c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41586,DS-fbbc0c41-90ea-4c65-bc25-a8f5e8f3c7da,DISK], DatanodeInfoWithStorage[127.0.0.1:45991,DS-94d9a613-2eb3-4ddd-9419-a52dc91a2988,DISK], DatanodeInfoWithStorage[127.0.0.1:43590,DS-167ffff0-a5de-454d-a04b-e51d6552e0c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36398,DS-44612876-0d0e-4bfc-90f9-e3f237e1c7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41109,DS-d4b7fcc5-cbeb-4acd-8451-9e13cb82d3e8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 99
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-631226072-172.17.0.16-1597512921762:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34761,DS-95264b6e-3a82-428a-80c7-3845e770bda0,DISK], DatanodeInfoWithStorage[127.0.0.1:34012,DS-3318b8f0-fe8c-421f-8c8a-18f47345ea27,DISK], DatanodeInfoWithStorage[127.0.0.1:33794,DS-75b9ebee-db8c-4525-a36c-1654b00dfb48,DISK], DatanodeInfoWithStorage[127.0.0.1:42980,DS-19bd3ed9-d3b5-43ab-bb56-0b7ad96c131b,DISK], DatanodeInfoWithStorage[127.0.0.1:33197,DS-29645f19-778b-41a7-b7ae-8f518f737ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:40469,DS-868bb3ec-e8d1-49bd-85e4-2df5dade971e,DISK], DatanodeInfoWithStorage[127.0.0.1:34707,DS-a736b997-9030-4097-9062-43929bb41fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:37075,DS-515ca506-0a23-430f-a60e-cb3a6b2ce225,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-631226072-172.17.0.16-1597512921762:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34761,DS-95264b6e-3a82-428a-80c7-3845e770bda0,DISK], DatanodeInfoWithStorage[127.0.0.1:34012,DS-3318b8f0-fe8c-421f-8c8a-18f47345ea27,DISK], DatanodeInfoWithStorage[127.0.0.1:33794,DS-75b9ebee-db8c-4525-a36c-1654b00dfb48,DISK], DatanodeInfoWithStorage[127.0.0.1:42980,DS-19bd3ed9-d3b5-43ab-bb56-0b7ad96c131b,DISK], DatanodeInfoWithStorage[127.0.0.1:33197,DS-29645f19-778b-41a7-b7ae-8f518f737ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:40469,DS-868bb3ec-e8d1-49bd-85e4-2df5dade971e,DISK], DatanodeInfoWithStorage[127.0.0.1:34707,DS-a736b997-9030-4097-9062-43929bb41fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:37075,DS-515ca506-0a23-430f-a60e-cb3a6b2ce225,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 99
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1888701936-172.17.0.16-1597512969488:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36495,DS-a744b465-134e-4071-ac62-715311d4b5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38156,DS-20e51c43-0704-4fd2-89e3-b4ff6a97c5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42867,DS-d4480535-99d9-4e00-8233-fb1f91694d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:36943,DS-f4882535-82f4-4771-b98c-882004b4857a,DISK], DatanodeInfoWithStorage[127.0.0.1:46049,DS-99d91a72-c3ea-42b2-a70c-518173455cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:34617,DS-e0bba75a-00e3-4b5b-84f0-c33a2e2adbfc,DISK], DatanodeInfoWithStorage[127.0.0.1:44610,DS-edc31cba-4ae8-40c6-8aa9-ceb64ec460a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41081,DS-719f31d4-0785-48a5-a696-267317eff49b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1888701936-172.17.0.16-1597512969488:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36495,DS-a744b465-134e-4071-ac62-715311d4b5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38156,DS-20e51c43-0704-4fd2-89e3-b4ff6a97c5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42867,DS-d4480535-99d9-4e00-8233-fb1f91694d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:36943,DS-f4882535-82f4-4771-b98c-882004b4857a,DISK], DatanodeInfoWithStorage[127.0.0.1:46049,DS-99d91a72-c3ea-42b2-a70c-518173455cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:34617,DS-e0bba75a-00e3-4b5b-84f0-c33a2e2adbfc,DISK], DatanodeInfoWithStorage[127.0.0.1:44610,DS-edc31cba-4ae8-40c6-8aa9-ceb64ec460a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41081,DS-719f31d4-0785-48a5-a696-267317eff49b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 99
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-189528726-172.17.0.16-1597513449362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45012,DS-f9092f66-6e55-4338-88e1-b4ae13b2dc22,DISK], DatanodeInfoWithStorage[127.0.0.1:39117,DS-ec91085b-e566-4631-bc72-f22af6e4af9c,DISK], DatanodeInfoWithStorage[127.0.0.1:33161,DS-69759453-58d1-4982-ab14-5897b8c67ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:44843,DS-3979bd1b-43ac-4fa1-b6d7-1aa492753872,DISK], DatanodeInfoWithStorage[127.0.0.1:41962,DS-edaaf47b-6e7f-4ec2-951f-9bf5f7c49d32,DISK], DatanodeInfoWithStorage[127.0.0.1:45188,DS-50befea7-4aa0-44b2-b99b-d6f8e3e9393e,DISK], DatanodeInfoWithStorage[127.0.0.1:33843,DS-9c97b59d-3a8c-49c3-befe-b1f7e8dbf56e,DISK], DatanodeInfoWithStorage[127.0.0.1:34850,DS-0cc49b4d-ada3-4c1e-90ce-9eff66bd29d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-189528726-172.17.0.16-1597513449362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45012,DS-f9092f66-6e55-4338-88e1-b4ae13b2dc22,DISK], DatanodeInfoWithStorage[127.0.0.1:39117,DS-ec91085b-e566-4631-bc72-f22af6e4af9c,DISK], DatanodeInfoWithStorage[127.0.0.1:33161,DS-69759453-58d1-4982-ab14-5897b8c67ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:44843,DS-3979bd1b-43ac-4fa1-b6d7-1aa492753872,DISK], DatanodeInfoWithStorage[127.0.0.1:41962,DS-edaaf47b-6e7f-4ec2-951f-9bf5f7c49d32,DISK], DatanodeInfoWithStorage[127.0.0.1:45188,DS-50befea7-4aa0-44b2-b99b-d6f8e3e9393e,DISK], DatanodeInfoWithStorage[127.0.0.1:33843,DS-9c97b59d-3a8c-49c3-befe-b1f7e8dbf56e,DISK], DatanodeInfoWithStorage[127.0.0.1:34850,DS-0cc49b4d-ada3-4c1e-90ce-9eff66bd29d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 99
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1611386904-172.17.0.16-1597513504081:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39858,DS-a04b62cf-b962-4a4f-8090-e98e11ea0536,DISK], DatanodeInfoWithStorage[127.0.0.1:32798,DS-09a3ecac-d3e6-4e69-a6ca-afda39b73929,DISK], DatanodeInfoWithStorage[127.0.0.1:37619,DS-62e56ab1-097e-4456-983a-0429c3ce9f47,DISK], DatanodeInfoWithStorage[127.0.0.1:44419,DS-eb50884d-fc81-4f17-9a28-71ab3c1a734a,DISK], DatanodeInfoWithStorage[127.0.0.1:43197,DS-1f8c627d-a707-4628-ab20-1910d2096c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:37136,DS-f04e62f6-de84-4f62-a32c-cafae4e547c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36161,DS-fda6a765-0e64-45e5-b504-54c690629c84,DISK], DatanodeInfoWithStorage[127.0.0.1:33839,DS-d3d27729-beb0-4be2-8605-6537d46cbde1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1611386904-172.17.0.16-1597513504081:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39858,DS-a04b62cf-b962-4a4f-8090-e98e11ea0536,DISK], DatanodeInfoWithStorage[127.0.0.1:32798,DS-09a3ecac-d3e6-4e69-a6ca-afda39b73929,DISK], DatanodeInfoWithStorage[127.0.0.1:37619,DS-62e56ab1-097e-4456-983a-0429c3ce9f47,DISK], DatanodeInfoWithStorage[127.0.0.1:44419,DS-eb50884d-fc81-4f17-9a28-71ab3c1a734a,DISK], DatanodeInfoWithStorage[127.0.0.1:43197,DS-1f8c627d-a707-4628-ab20-1910d2096c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:37136,DS-f04e62f6-de84-4f62-a32c-cafae4e547c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36161,DS-fda6a765-0e64-45e5-b504-54c690629c84,DISK], DatanodeInfoWithStorage[127.0.0.1:33839,DS-d3d27729-beb0-4be2-8605-6537d46cbde1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 99
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1999651653-172.17.0.16-1597513557671:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40567,DS-5ca126ca-8544-4427-87ff-f78ff2dbd14d,DISK], DatanodeInfoWithStorage[127.0.0.1:45807,DS-f006c262-3c01-4f7b-b9a8-a1f5acd6dbbc,DISK], DatanodeInfoWithStorage[127.0.0.1:42729,DS-e0d537a2-8fd1-467f-ab4f-ffb981130b14,DISK], DatanodeInfoWithStorage[127.0.0.1:45378,DS-dae92172-2a4f-4e01-b7eb-fc1bf9612f04,DISK], DatanodeInfoWithStorage[127.0.0.1:40614,DS-3c12bce2-f2fd-4d4e-91dd-bd2b95f0a2f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33894,DS-2ff28eb7-1b58-404b-988d-0eaa47b5972e,DISK], DatanodeInfoWithStorage[127.0.0.1:39333,DS-7fae3346-b073-4617-a779-08e12c214a95,DISK], DatanodeInfoWithStorage[127.0.0.1:43578,DS-bd068f3e-e15a-4a8b-81bd-845792a87566,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1999651653-172.17.0.16-1597513557671:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40567,DS-5ca126ca-8544-4427-87ff-f78ff2dbd14d,DISK], DatanodeInfoWithStorage[127.0.0.1:45807,DS-f006c262-3c01-4f7b-b9a8-a1f5acd6dbbc,DISK], DatanodeInfoWithStorage[127.0.0.1:42729,DS-e0d537a2-8fd1-467f-ab4f-ffb981130b14,DISK], DatanodeInfoWithStorage[127.0.0.1:45378,DS-dae92172-2a4f-4e01-b7eb-fc1bf9612f04,DISK], DatanodeInfoWithStorage[127.0.0.1:40614,DS-3c12bce2-f2fd-4d4e-91dd-bd2b95f0a2f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33894,DS-2ff28eb7-1b58-404b-988d-0eaa47b5972e,DISK], DatanodeInfoWithStorage[127.0.0.1:39333,DS-7fae3346-b073-4617-a779-08e12c214a95,DISK], DatanodeInfoWithStorage[127.0.0.1:43578,DS-bd068f3e-e15a-4a8b-81bd-845792a87566,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 99
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1342403291-172.17.0.16-1597514224898:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43747,DS-d7dd1ddf-4520-4fe4-8363-9bd8161367b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38716,DS-73f84855-f697-47dd-980d-280c41c093ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35054,DS-de4b4217-cc3e-4a5e-8001-4826225b6f13,DISK], DatanodeInfoWithStorage[127.0.0.1:44457,DS-1fdb1ca9-31d6-497d-a66f-1e986f974624,DISK], DatanodeInfoWithStorage[127.0.0.1:36294,DS-ff051269-3564-4d25-b336-5a4d1a78de71,DISK], DatanodeInfoWithStorage[127.0.0.1:40888,DS-fda9561b-4800-4ed5-8a3e-cd98cf3fee1c,DISK], DatanodeInfoWithStorage[127.0.0.1:33879,DS-588675f3-28f3-4475-9ce0-f9d3cbdbe124,DISK], DatanodeInfoWithStorage[127.0.0.1:37013,DS-ae705235-b957-4a90-838e-b4e4e4efb738,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1342403291-172.17.0.16-1597514224898:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43747,DS-d7dd1ddf-4520-4fe4-8363-9bd8161367b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38716,DS-73f84855-f697-47dd-980d-280c41c093ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35054,DS-de4b4217-cc3e-4a5e-8001-4826225b6f13,DISK], DatanodeInfoWithStorage[127.0.0.1:44457,DS-1fdb1ca9-31d6-497d-a66f-1e986f974624,DISK], DatanodeInfoWithStorage[127.0.0.1:36294,DS-ff051269-3564-4d25-b336-5a4d1a78de71,DISK], DatanodeInfoWithStorage[127.0.0.1:40888,DS-fda9561b-4800-4ed5-8a3e-cd98cf3fee1c,DISK], DatanodeInfoWithStorage[127.0.0.1:33879,DS-588675f3-28f3-4475-9ce0-f9d3cbdbe124,DISK], DatanodeInfoWithStorage[127.0.0.1:37013,DS-ae705235-b957-4a90-838e-b4e4e4efb738,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 99
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1805926436-172.17.0.16-1597514269321:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46502,DS-e3997f5d-7984-4333-ad1c-f4c2d7a54dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:44626,DS-0b55aa43-785e-48e3-8e1c-1d6586ae3d40,DISK], DatanodeInfoWithStorage[127.0.0.1:38502,DS-6a46e467-5255-41e7-be55-e2cfa5042a86,DISK], DatanodeInfoWithStorage[127.0.0.1:37225,DS-2f4524da-d5a4-46a3-ba73-7a10760679d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44602,DS-386e2fc6-3d38-44ed-aed1-f01998898fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:46739,DS-3f571133-94ce-4bd5-8c9c-0a38cdd417bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41020,DS-b0a6ff5f-2411-4768-b2df-abf61ae51f79,DISK], DatanodeInfoWithStorage[127.0.0.1:37521,DS-913d34af-fb1d-4560-a02f-5d143b083577,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1805926436-172.17.0.16-1597514269321:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46502,DS-e3997f5d-7984-4333-ad1c-f4c2d7a54dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:44626,DS-0b55aa43-785e-48e3-8e1c-1d6586ae3d40,DISK], DatanodeInfoWithStorage[127.0.0.1:38502,DS-6a46e467-5255-41e7-be55-e2cfa5042a86,DISK], DatanodeInfoWithStorage[127.0.0.1:37225,DS-2f4524da-d5a4-46a3-ba73-7a10760679d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44602,DS-386e2fc6-3d38-44ed-aed1-f01998898fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:46739,DS-3f571133-94ce-4bd5-8c9c-0a38cdd417bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41020,DS-b0a6ff5f-2411-4768-b2df-abf61ae51f79,DISK], DatanodeInfoWithStorage[127.0.0.1:37521,DS-913d34af-fb1d-4560-a02f-5d143b083577,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 99
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2034644746-172.17.0.16-1597514322742:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36832,DS-c94fab4c-ef42-4d1d-a9fe-7020f23a473a,DISK], DatanodeInfoWithStorage[127.0.0.1:44226,DS-8cf07cb5-fa91-42d1-b3d8-fea0cee4ae8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45977,DS-3eb899e6-01f0-4cd4-9a53-adb3b30e6fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:36295,DS-2b3bf0f0-e4ea-4e88-bf65-fd75db5eb4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35473,DS-ec426256-dce5-47e9-8755-47a20fdc982f,DISK], DatanodeInfoWithStorage[127.0.0.1:37982,DS-5171f2ce-ab17-4a12-98f1-0bf25d723deb,DISK], DatanodeInfoWithStorage[127.0.0.1:42445,DS-89476da8-bfca-4599-b510-fbc1312b7174,DISK], DatanodeInfoWithStorage[127.0.0.1:45438,DS-18f8043b-233e-407a-a10f-39ed17520c1b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2034644746-172.17.0.16-1597514322742:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36832,DS-c94fab4c-ef42-4d1d-a9fe-7020f23a473a,DISK], DatanodeInfoWithStorage[127.0.0.1:44226,DS-8cf07cb5-fa91-42d1-b3d8-fea0cee4ae8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45977,DS-3eb899e6-01f0-4cd4-9a53-adb3b30e6fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:36295,DS-2b3bf0f0-e4ea-4e88-bf65-fd75db5eb4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35473,DS-ec426256-dce5-47e9-8755-47a20fdc982f,DISK], DatanodeInfoWithStorage[127.0.0.1:37982,DS-5171f2ce-ab17-4a12-98f1-0bf25d723deb,DISK], DatanodeInfoWithStorage[127.0.0.1:42445,DS-89476da8-bfca-4599-b510-fbc1312b7174,DISK], DatanodeInfoWithStorage[127.0.0.1:45438,DS-18f8043b-233e-407a-a10f-39ed17520c1b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 99
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-145494574-172.17.0.16-1597514653901:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32852,DS-5a3ea398-a315-4c19-8cb4-a9decf6ae453,DISK], DatanodeInfoWithStorage[127.0.0.1:34547,DS-721da116-0039-428f-b3a6-b66271863af3,DISK], DatanodeInfoWithStorage[127.0.0.1:38308,DS-ab2e2c1a-5b90-4018-8903-7cb7dff44ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-1864d7f7-1f6f-4eda-85b7-f48cfa38ae8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43782,DS-984b7871-125c-4f48-9aaa-5419434ecb19,DISK], DatanodeInfoWithStorage[127.0.0.1:40606,DS-0a19a4d9-479c-4a36-a96a-6a4822341197,DISK], DatanodeInfoWithStorage[127.0.0.1:34804,DS-24c5799e-4d58-4f19-bb46-e423773b8339,DISK], DatanodeInfoWithStorage[127.0.0.1:46621,DS-2752086c-682d-44fa-a612-719f41a321e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-145494574-172.17.0.16-1597514653901:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32852,DS-5a3ea398-a315-4c19-8cb4-a9decf6ae453,DISK], DatanodeInfoWithStorage[127.0.0.1:34547,DS-721da116-0039-428f-b3a6-b66271863af3,DISK], DatanodeInfoWithStorage[127.0.0.1:38308,DS-ab2e2c1a-5b90-4018-8903-7cb7dff44ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-1864d7f7-1f6f-4eda-85b7-f48cfa38ae8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43782,DS-984b7871-125c-4f48-9aaa-5419434ecb19,DISK], DatanodeInfoWithStorage[127.0.0.1:40606,DS-0a19a4d9-479c-4a36-a96a-6a4822341197,DISK], DatanodeInfoWithStorage[127.0.0.1:34804,DS-24c5799e-4d58-4f19-bb46-e423773b8339,DISK], DatanodeInfoWithStorage[127.0.0.1:46621,DS-2752086c-682d-44fa-a612-719f41a321e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 99
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1975371945-172.17.0.16-1597514789042:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43291,DS-6348a509-f796-414a-8590-f1e0cea1e8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43127,DS-b52a9b51-995c-46af-a84a-30b740d4d447,DISK], DatanodeInfoWithStorage[127.0.0.1:44463,DS-00f99be0-3aa6-437a-b363-19e031bdd1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35204,DS-8128c51b-3742-4be9-ba98-8d93b4c07c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:41385,DS-ea7266b3-6b67-4299-806b-5303f179c1a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46346,DS-bf3bf8b2-7723-47a0-8b02-9c932a0d4b45,DISK], DatanodeInfoWithStorage[127.0.0.1:40203,DS-34bd1e43-ff7a-4110-9c7c-2001f681b905,DISK], DatanodeInfoWithStorage[127.0.0.1:33608,DS-8cbd75af-58be-4230-8255-b47d564089c2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1975371945-172.17.0.16-1597514789042:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43291,DS-6348a509-f796-414a-8590-f1e0cea1e8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43127,DS-b52a9b51-995c-46af-a84a-30b740d4d447,DISK], DatanodeInfoWithStorage[127.0.0.1:44463,DS-00f99be0-3aa6-437a-b363-19e031bdd1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35204,DS-8128c51b-3742-4be9-ba98-8d93b4c07c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:41385,DS-ea7266b3-6b67-4299-806b-5303f179c1a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46346,DS-bf3bf8b2-7723-47a0-8b02-9c932a0d4b45,DISK], DatanodeInfoWithStorage[127.0.0.1:40203,DS-34bd1e43-ff7a-4110-9c7c-2001f681b905,DISK], DatanodeInfoWithStorage[127.0.0.1:33608,DS-8cbd75af-58be-4230-8255-b47d564089c2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 99
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2081345019-172.17.0.16-1597515087164:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43003,DS-34ca1358-bfca-4c63-8f4c-9785e6861ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:42022,DS-faef4764-a1ab-4f4a-b7a3-79bdd07ec6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38824,DS-897728a0-e883-4cdf-88e2-282422002055,DISK], DatanodeInfoWithStorage[127.0.0.1:39426,DS-06c20718-7f6e-4af1-baa3-cc810c2176ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39560,DS-69c86170-dff9-4dd0-be35-6d0cd315ec14,DISK], DatanodeInfoWithStorage[127.0.0.1:46221,DS-f114ae84-5c12-4e46-81c9-648d6c95ac98,DISK], DatanodeInfoWithStorage[127.0.0.1:36141,DS-4171f683-c6a1-431a-b0e2-f94462ed95c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-3aecb236-ef06-4692-ac17-56eec113d0c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2081345019-172.17.0.16-1597515087164:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43003,DS-34ca1358-bfca-4c63-8f4c-9785e6861ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:42022,DS-faef4764-a1ab-4f4a-b7a3-79bdd07ec6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38824,DS-897728a0-e883-4cdf-88e2-282422002055,DISK], DatanodeInfoWithStorage[127.0.0.1:39426,DS-06c20718-7f6e-4af1-baa3-cc810c2176ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39560,DS-69c86170-dff9-4dd0-be35-6d0cd315ec14,DISK], DatanodeInfoWithStorage[127.0.0.1:46221,DS-f114ae84-5c12-4e46-81c9-648d6c95ac98,DISK], DatanodeInfoWithStorage[127.0.0.1:36141,DS-4171f683-c6a1-431a-b0e2-f94462ed95c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-3aecb236-ef06-4692-ac17-56eec113d0c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 99
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1495278332-172.17.0.16-1597515133630:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34398,DS-f8304fe5-8108-4276-9f99-06c695470f75,DISK], DatanodeInfoWithStorage[127.0.0.1:42272,DS-aedb4b87-35ab-4a03-8c25-a3c18a28b584,DISK], DatanodeInfoWithStorage[127.0.0.1:33203,DS-36b5e72b-47e5-4a6c-b30d-638a087c7372,DISK], DatanodeInfoWithStorage[127.0.0.1:35288,DS-07ec07ac-804c-4634-bf84-86dc96469a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38728,DS-2d881c8e-c6f1-4b10-9ef8-b0a499852956,DISK], DatanodeInfoWithStorage[127.0.0.1:44656,DS-bb7c419c-b279-4d0a-b02e-7b44954e259e,DISK], DatanodeInfoWithStorage[127.0.0.1:42610,DS-3217d0c3-b229-45c8-980e-8c596ffd5e07,DISK], DatanodeInfoWithStorage[127.0.0.1:41223,DS-992425ea-d37a-4755-ad30-3d291a9ee5cc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1495278332-172.17.0.16-1597515133630:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34398,DS-f8304fe5-8108-4276-9f99-06c695470f75,DISK], DatanodeInfoWithStorage[127.0.0.1:42272,DS-aedb4b87-35ab-4a03-8c25-a3c18a28b584,DISK], DatanodeInfoWithStorage[127.0.0.1:33203,DS-36b5e72b-47e5-4a6c-b30d-638a087c7372,DISK], DatanodeInfoWithStorage[127.0.0.1:35288,DS-07ec07ac-804c-4634-bf84-86dc96469a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38728,DS-2d881c8e-c6f1-4b10-9ef8-b0a499852956,DISK], DatanodeInfoWithStorage[127.0.0.1:44656,DS-bb7c419c-b279-4d0a-b02e-7b44954e259e,DISK], DatanodeInfoWithStorage[127.0.0.1:42610,DS-3217d0c3-b229-45c8-980e-8c596ffd5e07,DISK], DatanodeInfoWithStorage[127.0.0.1:41223,DS-992425ea-d37a-4755-ad30-3d291a9ee5cc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 99
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2062175738-172.17.0.16-1597515317673:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42272,DS-93bd6654-e16f-4478-b994-071bf9039cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:43177,DS-ccd215fa-6803-4467-99ca-4b27d124b480,DISK], DatanodeInfoWithStorage[127.0.0.1:39062,DS-46076183-ff99-4c61-9354-ee4f982e0efe,DISK], DatanodeInfoWithStorage[127.0.0.1:37493,DS-159ad4e0-6008-4344-820e-7be67080f918,DISK], DatanodeInfoWithStorage[127.0.0.1:38534,DS-78c0ebb2-d0ff-4712-bd85-8af8982b1cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:35433,DS-160b023b-990f-484f-b2af-bb40c6969144,DISK], DatanodeInfoWithStorage[127.0.0.1:41909,DS-10e03d6a-a5eb-4b95-b2ab-282df213bfc2,DISK], DatanodeInfoWithStorage[127.0.0.1:41668,DS-111d2f4e-176c-4ae5-b153-4426066319dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2062175738-172.17.0.16-1597515317673:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42272,DS-93bd6654-e16f-4478-b994-071bf9039cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:43177,DS-ccd215fa-6803-4467-99ca-4b27d124b480,DISK], DatanodeInfoWithStorage[127.0.0.1:39062,DS-46076183-ff99-4c61-9354-ee4f982e0efe,DISK], DatanodeInfoWithStorage[127.0.0.1:37493,DS-159ad4e0-6008-4344-820e-7be67080f918,DISK], DatanodeInfoWithStorage[127.0.0.1:38534,DS-78c0ebb2-d0ff-4712-bd85-8af8982b1cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:35433,DS-160b023b-990f-484f-b2af-bb40c6969144,DISK], DatanodeInfoWithStorage[127.0.0.1:41909,DS-10e03d6a-a5eb-4b95-b2ab-282df213bfc2,DISK], DatanodeInfoWithStorage[127.0.0.1:41668,DS-111d2f4e-176c-4ae5-b153-4426066319dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 99
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-611560656-172.17.0.16-1597515406392:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43530,DS-668b794b-133f-40a9-89a5-4e1b3d5e2bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:44566,DS-8d3d9230-db26-451c-8e27-9672bcec691e,DISK], DatanodeInfoWithStorage[127.0.0.1:32833,DS-c86a9b36-e7ff-4ab6-990c-adbc82565dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:42315,DS-cdb006bc-edcf-4852-a28a-fa68ad425e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:44866,DS-d1b57cfa-29a2-4c63-b6c3-af8c68935428,DISK], DatanodeInfoWithStorage[127.0.0.1:43637,DS-002586de-1606-4354-a380-9a0398b51232,DISK], DatanodeInfoWithStorage[127.0.0.1:37803,DS-bd67660f-3fd2-4766-a009-33b2f1a8f0be,DISK], DatanodeInfoWithStorage[127.0.0.1:36165,DS-d9842cb0-1a3d-4968-b32c-55e32cdaad0e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-611560656-172.17.0.16-1597515406392:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43530,DS-668b794b-133f-40a9-89a5-4e1b3d5e2bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:44566,DS-8d3d9230-db26-451c-8e27-9672bcec691e,DISK], DatanodeInfoWithStorage[127.0.0.1:32833,DS-c86a9b36-e7ff-4ab6-990c-adbc82565dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:42315,DS-cdb006bc-edcf-4852-a28a-fa68ad425e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:44866,DS-d1b57cfa-29a2-4c63-b6c3-af8c68935428,DISK], DatanodeInfoWithStorage[127.0.0.1:43637,DS-002586de-1606-4354-a380-9a0398b51232,DISK], DatanodeInfoWithStorage[127.0.0.1:37803,DS-bd67660f-3fd2-4766-a009-33b2f1a8f0be,DISK], DatanodeInfoWithStorage[127.0.0.1:36165,DS-d9842cb0-1a3d-4968-b32c-55e32cdaad0e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 99
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-96037217-172.17.0.16-1597515642271:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34355,DS-0dd8ba5a-040c-488f-b454-d32da6ce2aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:37711,DS-74b3cea2-8815-4851-9c76-e728da3e9598,DISK], DatanodeInfoWithStorage[127.0.0.1:43667,DS-32279b25-7730-4cca-9f78-85f783dd835f,DISK], DatanodeInfoWithStorage[127.0.0.1:40328,DS-3af6bb7a-b68b-4e14-922e-57dfbbbe3b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:45926,DS-d6f76e8f-d3c8-4c78-832e-08dd2279144a,DISK], DatanodeInfoWithStorage[127.0.0.1:42857,DS-515248a0-ba7f-4612-9ca6-b4a7823555a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39210,DS-df70b0fe-ee65-4f00-b835-aa4e38d48bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:44538,DS-67c3750f-d7b5-469e-9e85-8b9d2609bd87,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-96037217-172.17.0.16-1597515642271:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34355,DS-0dd8ba5a-040c-488f-b454-d32da6ce2aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:37711,DS-74b3cea2-8815-4851-9c76-e728da3e9598,DISK], DatanodeInfoWithStorage[127.0.0.1:43667,DS-32279b25-7730-4cca-9f78-85f783dd835f,DISK], DatanodeInfoWithStorage[127.0.0.1:40328,DS-3af6bb7a-b68b-4e14-922e-57dfbbbe3b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:45926,DS-d6f76e8f-d3c8-4c78-832e-08dd2279144a,DISK], DatanodeInfoWithStorage[127.0.0.1:42857,DS-515248a0-ba7f-4612-9ca6-b4a7823555a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39210,DS-df70b0fe-ee65-4f00-b835-aa4e38d48bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:44538,DS-67c3750f-d7b5-469e-9e85-8b9d2609bd87,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 99
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-906136809-172.17.0.16-1597515784274:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41916,DS-e36cfc78-0ee6-4eff-94de-625e195a7b48,DISK], DatanodeInfoWithStorage[127.0.0.1:39012,DS-1d275340-e299-4ce0-b49b-0eb893663f40,DISK], DatanodeInfoWithStorage[127.0.0.1:35402,DS-0ee1b564-ef03-45d5-bbf2-a29535e0b830,DISK], DatanodeInfoWithStorage[127.0.0.1:38513,DS-2cde6741-f816-499b-84de-d7cfec5b4e56,DISK], DatanodeInfoWithStorage[127.0.0.1:35997,DS-3ca266e7-0d46-4a04-9d30-49f6cad5837d,DISK], DatanodeInfoWithStorage[127.0.0.1:34712,DS-8de82b13-c5ed-48ba-b7be-e4b92c70db6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39526,DS-dd74270f-7ad7-4cd0-b785-4d708daa611a,DISK], DatanodeInfoWithStorage[127.0.0.1:40416,DS-e6266c87-cee7-40ae-b16e-960e4b15c9ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-906136809-172.17.0.16-1597515784274:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41916,DS-e36cfc78-0ee6-4eff-94de-625e195a7b48,DISK], DatanodeInfoWithStorage[127.0.0.1:39012,DS-1d275340-e299-4ce0-b49b-0eb893663f40,DISK], DatanodeInfoWithStorage[127.0.0.1:35402,DS-0ee1b564-ef03-45d5-bbf2-a29535e0b830,DISK], DatanodeInfoWithStorage[127.0.0.1:38513,DS-2cde6741-f816-499b-84de-d7cfec5b4e56,DISK], DatanodeInfoWithStorage[127.0.0.1:35997,DS-3ca266e7-0d46-4a04-9d30-49f6cad5837d,DISK], DatanodeInfoWithStorage[127.0.0.1:34712,DS-8de82b13-c5ed-48ba-b7be-e4b92c70db6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39526,DS-dd74270f-7ad7-4cd0-b785-4d708daa611a,DISK], DatanodeInfoWithStorage[127.0.0.1:40416,DS-e6266c87-cee7-40ae-b16e-960e4b15c9ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 99
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1754118022-172.17.0.16-1597515881642:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41439,DS-f65e98c1-5bbb-40f4-849d-5f5fc58d8d37,DISK], DatanodeInfoWithStorage[127.0.0.1:35345,DS-a04d51dc-7858-4188-8814-72523d1d91ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40736,DS-54ced336-9188-4105-873d-c75bf7bd78e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43941,DS-e3b7f87b-bede-4d19-bfa1-c2437f60198c,DISK], DatanodeInfoWithStorage[127.0.0.1:36794,DS-2e63b444-0a40-4f49-934c-47ef1c0f6387,DISK], DatanodeInfoWithStorage[127.0.0.1:43784,DS-6d4776f9-e601-432a-b07d-c7f71e2f8da9,DISK], DatanodeInfoWithStorage[127.0.0.1:39412,DS-1cb57e27-26a4-4602-b18c-09201b3ed4fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42588,DS-9b577199-d324-41b6-a6f9-24bd9c08611b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1754118022-172.17.0.16-1597515881642:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41439,DS-f65e98c1-5bbb-40f4-849d-5f5fc58d8d37,DISK], DatanodeInfoWithStorage[127.0.0.1:35345,DS-a04d51dc-7858-4188-8814-72523d1d91ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40736,DS-54ced336-9188-4105-873d-c75bf7bd78e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43941,DS-e3b7f87b-bede-4d19-bfa1-c2437f60198c,DISK], DatanodeInfoWithStorage[127.0.0.1:36794,DS-2e63b444-0a40-4f49-934c-47ef1c0f6387,DISK], DatanodeInfoWithStorage[127.0.0.1:43784,DS-6d4776f9-e601-432a-b07d-c7f71e2f8da9,DISK], DatanodeInfoWithStorage[127.0.0.1:39412,DS-1cb57e27-26a4-4602-b18c-09201b3ed4fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42588,DS-9b577199-d324-41b6-a6f9-24bd9c08611b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 99
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2146495900-172.17.0.16-1597516067054:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40319,DS-ff626a3a-7d14-43df-8a1a-95f438deb5f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33347,DS-c803ae5f-107e-4750-aab8-fcfd473ac3c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39799,DS-aafad3cc-a2bc-40a5-a797-4a2dec764ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:38592,DS-6f741641-3805-451f-825d-66395fb00f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:46156,DS-c20dcd8e-3bc3-4a42-887e-5d4a0ffb7600,DISK], DatanodeInfoWithStorage[127.0.0.1:36558,DS-098f54f9-2f45-448a-b115-a89a7e0b1b34,DISK], DatanodeInfoWithStorage[127.0.0.1:44677,DS-13870adc-6884-4582-afef-d0cd18bf4a21,DISK], DatanodeInfoWithStorage[127.0.0.1:41793,DS-aa11694b-621a-444b-8185-e449571ad9e6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2146495900-172.17.0.16-1597516067054:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40319,DS-ff626a3a-7d14-43df-8a1a-95f438deb5f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33347,DS-c803ae5f-107e-4750-aab8-fcfd473ac3c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39799,DS-aafad3cc-a2bc-40a5-a797-4a2dec764ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:38592,DS-6f741641-3805-451f-825d-66395fb00f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:46156,DS-c20dcd8e-3bc3-4a42-887e-5d4a0ffb7600,DISK], DatanodeInfoWithStorage[127.0.0.1:36558,DS-098f54f9-2f45-448a-b115-a89a7e0b1b34,DISK], DatanodeInfoWithStorage[127.0.0.1:44677,DS-13870adc-6884-4582-afef-d0cd18bf4a21,DISK], DatanodeInfoWithStorage[127.0.0.1:41793,DS-aa11694b-621a-444b-8185-e449571ad9e6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 99
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1977824918-172.17.0.16-1597516109278:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37831,DS-5156882b-363e-4e4c-91be-6e6b4f8bee09,DISK], DatanodeInfoWithStorage[127.0.0.1:43058,DS-7831ac92-f001-472e-9779-fb0b08e926ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37333,DS-cbed3c18-6124-46f5-aa42-3c3f648e7b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45162,DS-45beff1f-f3d4-4213-a92d-dfcea634eddd,DISK], DatanodeInfoWithStorage[127.0.0.1:43365,DS-7531b7f9-f8d1-4dc5-b7e9-1fedd5f41d75,DISK], DatanodeInfoWithStorage[127.0.0.1:34762,DS-188aca91-76a9-4b6b-94cd-3164c6a39bac,DISK], DatanodeInfoWithStorage[127.0.0.1:40821,DS-65fee33f-26ba-4c4a-9e54-be13d462ac4c,DISK], DatanodeInfoWithStorage[127.0.0.1:35811,DS-5cde9ed7-cd15-4bba-be7f-3abd642b6df0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1977824918-172.17.0.16-1597516109278:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37831,DS-5156882b-363e-4e4c-91be-6e6b4f8bee09,DISK], DatanodeInfoWithStorage[127.0.0.1:43058,DS-7831ac92-f001-472e-9779-fb0b08e926ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37333,DS-cbed3c18-6124-46f5-aa42-3c3f648e7b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45162,DS-45beff1f-f3d4-4213-a92d-dfcea634eddd,DISK], DatanodeInfoWithStorage[127.0.0.1:43365,DS-7531b7f9-f8d1-4dc5-b7e9-1fedd5f41d75,DISK], DatanodeInfoWithStorage[127.0.0.1:34762,DS-188aca91-76a9-4b6b-94cd-3164c6a39bac,DISK], DatanodeInfoWithStorage[127.0.0.1:40821,DS-65fee33f-26ba-4c4a-9e54-be13d462ac4c,DISK], DatanodeInfoWithStorage[127.0.0.1:35811,DS-5cde9ed7-cd15-4bba-be7f-3abd642b6df0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 99
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1397940070-172.17.0.16-1597516390948:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40046,DS-45fc827f-22d1-4d36-930b-437efb3ce330,DISK], DatanodeInfoWithStorage[127.0.0.1:38160,DS-7ca55fa7-ad9f-4097-b498-2ae997f40d71,DISK], DatanodeInfoWithStorage[127.0.0.1:37744,DS-05213ab8-f87f-4618-82ba-0b456175491b,DISK], DatanodeInfoWithStorage[127.0.0.1:45508,DS-27124111-a198-4954-be31-025abfcacf63,DISK], DatanodeInfoWithStorage[127.0.0.1:38405,DS-98f1c9df-2cde-478e-9e55-9ce167ace277,DISK], DatanodeInfoWithStorage[127.0.0.1:41253,DS-d7a2161c-5430-4f24-8901-42d56dd78be8,DISK], DatanodeInfoWithStorage[127.0.0.1:46220,DS-365cca6c-c0a5-4dcb-9ef9-788b1aac9a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40476,DS-f231d726-f3ad-489c-843b-bed6b23b2f84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1397940070-172.17.0.16-1597516390948:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40046,DS-45fc827f-22d1-4d36-930b-437efb3ce330,DISK], DatanodeInfoWithStorage[127.0.0.1:38160,DS-7ca55fa7-ad9f-4097-b498-2ae997f40d71,DISK], DatanodeInfoWithStorage[127.0.0.1:37744,DS-05213ab8-f87f-4618-82ba-0b456175491b,DISK], DatanodeInfoWithStorage[127.0.0.1:45508,DS-27124111-a198-4954-be31-025abfcacf63,DISK], DatanodeInfoWithStorage[127.0.0.1:38405,DS-98f1c9df-2cde-478e-9e55-9ce167ace277,DISK], DatanodeInfoWithStorage[127.0.0.1:41253,DS-d7a2161c-5430-4f24-8901-42d56dd78be8,DISK], DatanodeInfoWithStorage[127.0.0.1:46220,DS-365cca6c-c0a5-4dcb-9ef9-788b1aac9a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40476,DS-f231d726-f3ad-489c-843b-bed6b23b2f84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 99
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1230889443-172.17.0.16-1597517003869:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37295,DS-f09a471a-bf62-4d5e-bfd0-45c9701bed52,DISK], DatanodeInfoWithStorage[127.0.0.1:45131,DS-0f9c0c32-909f-42fb-8c0f-28bdaa4ef5f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43676,DS-238eb8af-f373-498a-8dd4-a84e6e8b0660,DISK], DatanodeInfoWithStorage[127.0.0.1:40019,DS-ef146aa5-e80b-4db9-9729-ba834f01c677,DISK], DatanodeInfoWithStorage[127.0.0.1:39426,DS-e1da0c77-4436-4353-981b-c27846b0058e,DISK], DatanodeInfoWithStorage[127.0.0.1:34331,DS-777f30e1-6491-487e-bd57-438e0364f474,DISK], DatanodeInfoWithStorage[127.0.0.1:43788,DS-dd6dc730-1e19-4cde-85b2-dd18e120beaf,DISK], DatanodeInfoWithStorage[127.0.0.1:45141,DS-1d441a6d-7a40-4972-b379-2b3926932465,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1230889443-172.17.0.16-1597517003869:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37295,DS-f09a471a-bf62-4d5e-bfd0-45c9701bed52,DISK], DatanodeInfoWithStorage[127.0.0.1:45131,DS-0f9c0c32-909f-42fb-8c0f-28bdaa4ef5f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43676,DS-238eb8af-f373-498a-8dd4-a84e6e8b0660,DISK], DatanodeInfoWithStorage[127.0.0.1:40019,DS-ef146aa5-e80b-4db9-9729-ba834f01c677,DISK], DatanodeInfoWithStorage[127.0.0.1:39426,DS-e1da0c77-4436-4353-981b-c27846b0058e,DISK], DatanodeInfoWithStorage[127.0.0.1:34331,DS-777f30e1-6491-487e-bd57-438e0364f474,DISK], DatanodeInfoWithStorage[127.0.0.1:43788,DS-dd6dc730-1e19-4cde-85b2-dd18e120beaf,DISK], DatanodeInfoWithStorage[127.0.0.1:45141,DS-1d441a6d-7a40-4972-b379-2b3926932465,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 99
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1652028421-172.17.0.16-1597517153658:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38173,DS-7195bf6e-ca58-4e53-9209-f6c75106e952,DISK], DatanodeInfoWithStorage[127.0.0.1:42302,DS-cae44365-eadd-49c3-b440-7e681dba41f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38825,DS-e9370686-c552-4032-999f-0435f8938609,DISK], DatanodeInfoWithStorage[127.0.0.1:33099,DS-919d6113-2fe9-45df-b781-5f7a03126ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:44763,DS-722a8f5f-bf3c-4228-8af5-e9c14ca0965b,DISK], DatanodeInfoWithStorage[127.0.0.1:33072,DS-3271041d-d553-4a5f-b5e4-5ca93018ff59,DISK], DatanodeInfoWithStorage[127.0.0.1:37545,DS-fec024bb-d2ee-4ac2-bd15-0a1edab7ae01,DISK], DatanodeInfoWithStorage[127.0.0.1:42059,DS-f89e8828-9e00-4f82-9191-6cee53ee7242,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1652028421-172.17.0.16-1597517153658:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38173,DS-7195bf6e-ca58-4e53-9209-f6c75106e952,DISK], DatanodeInfoWithStorage[127.0.0.1:42302,DS-cae44365-eadd-49c3-b440-7e681dba41f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38825,DS-e9370686-c552-4032-999f-0435f8938609,DISK], DatanodeInfoWithStorage[127.0.0.1:33099,DS-919d6113-2fe9-45df-b781-5f7a03126ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:44763,DS-722a8f5f-bf3c-4228-8af5-e9c14ca0965b,DISK], DatanodeInfoWithStorage[127.0.0.1:33072,DS-3271041d-d553-4a5f-b5e4-5ca93018ff59,DISK], DatanodeInfoWithStorage[127.0.0.1:37545,DS-fec024bb-d2ee-4ac2-bd15-0a1edab7ae01,DISK], DatanodeInfoWithStorage[127.0.0.1:42059,DS-f89e8828-9e00-4f82-9191-6cee53ee7242,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 99
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1783851915-172.17.0.16-1597517373889:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35167,DS-b4ccd01f-2f82-4f58-8d92-bfadef736273,DISK], DatanodeInfoWithStorage[127.0.0.1:41369,DS-92216b2a-4212-4b98-9f59-727c6f6c29a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39770,DS-c6709118-3c36-44d1-890f-98cb0447ec0d,DISK], DatanodeInfoWithStorage[127.0.0.1:32791,DS-2715aad8-a0c9-4c3e-a0d1-e27ee9be2c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:41112,DS-261802fb-b7c9-4796-bc3a-a4020b5070be,DISK], DatanodeInfoWithStorage[127.0.0.1:43672,DS-b66460f4-e802-41b3-a710-fd2236b68f95,DISK], DatanodeInfoWithStorage[127.0.0.1:46645,DS-4f185bee-d093-42c7-b500-2711f75b7353,DISK], DatanodeInfoWithStorage[127.0.0.1:37997,DS-8535efb5-7127-4ba9-86d9-5998d765025a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1783851915-172.17.0.16-1597517373889:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35167,DS-b4ccd01f-2f82-4f58-8d92-bfadef736273,DISK], DatanodeInfoWithStorage[127.0.0.1:41369,DS-92216b2a-4212-4b98-9f59-727c6f6c29a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39770,DS-c6709118-3c36-44d1-890f-98cb0447ec0d,DISK], DatanodeInfoWithStorage[127.0.0.1:32791,DS-2715aad8-a0c9-4c3e-a0d1-e27ee9be2c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:41112,DS-261802fb-b7c9-4796-bc3a-a4020b5070be,DISK], DatanodeInfoWithStorage[127.0.0.1:43672,DS-b66460f4-e802-41b3-a710-fd2236b68f95,DISK], DatanodeInfoWithStorage[127.0.0.1:46645,DS-4f185bee-d093-42c7-b500-2711f75b7353,DISK], DatanodeInfoWithStorage[127.0.0.1:37997,DS-8535efb5-7127-4ba9-86d9-5998d765025a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 20 out of 50
result: false positive !!!
Total execution time in seconds : 7051
