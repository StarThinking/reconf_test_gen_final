reconf_parameter: dfs.block.access.key.update.interval
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.key.update.interval
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-933905780-172.17.0.21-1597397271371:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40932,DS-3491fa08-f60a-4b4b-9526-74cfc260ff54,DISK], DatanodeInfoWithStorage[127.0.0.1:36748,DS-d19331f2-1312-4455-a786-ecbaab07e322,DISK], DatanodeInfoWithStorage[127.0.0.1:45311,DS-75c89ba1-3bdb-46b2-bf04-a746921419fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39093,DS-30ad27db-b15f-4649-bc3a-ae6bd823298d,DISK], DatanodeInfoWithStorage[127.0.0.1:32908,DS-8502f8c1-1114-4f22-86a9-7f48223a481f,DISK], DatanodeInfoWithStorage[127.0.0.1:38742,DS-0ef4e134-1872-4e33-9b48-48159cb7aa3e,DISK], DatanodeInfoWithStorage[127.0.0.1:34231,DS-5c43d12f-64c2-4f72-bb63-d60970ffad8f,DISK], DatanodeInfoWithStorage[127.0.0.1:34010,DS-edb4d317-87f8-415a-af41-5638c4af4813,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-933905780-172.17.0.21-1597397271371:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40932,DS-3491fa08-f60a-4b4b-9526-74cfc260ff54,DISK], DatanodeInfoWithStorage[127.0.0.1:36748,DS-d19331f2-1312-4455-a786-ecbaab07e322,DISK], DatanodeInfoWithStorage[127.0.0.1:45311,DS-75c89ba1-3bdb-46b2-bf04-a746921419fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39093,DS-30ad27db-b15f-4649-bc3a-ae6bd823298d,DISK], DatanodeInfoWithStorage[127.0.0.1:32908,DS-8502f8c1-1114-4f22-86a9-7f48223a481f,DISK], DatanodeInfoWithStorage[127.0.0.1:38742,DS-0ef4e134-1872-4e33-9b48-48159cb7aa3e,DISK], DatanodeInfoWithStorage[127.0.0.1:34231,DS-5c43d12f-64c2-4f72-bb63-d60970ffad8f,DISK], DatanodeInfoWithStorage[127.0.0.1:34010,DS-edb4d317-87f8-415a-af41-5638c4af4813,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.key.update.interval
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2004657053-172.17.0.21-1597398737481:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33554,DS-1e5044c6-68b0-4f6d-b66a-e5e86235892a,DISK], DatanodeInfoWithStorage[127.0.0.1:36399,DS-e75a1212-3c93-4619-b155-86f5ed518082,DISK], DatanodeInfoWithStorage[127.0.0.1:35294,DS-07d20aac-5cb7-4c4a-bf07-564723be2b03,DISK], DatanodeInfoWithStorage[127.0.0.1:41002,DS-a8d37e7c-6bc3-44c5-a83b-aeeea0c83d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:44812,DS-8345aa6e-8570-4cf7-9a57-0cdcd2ac156f,DISK], DatanodeInfoWithStorage[127.0.0.1:34580,DS-1dda4667-bab6-4dbd-ad99-dd8090f6a7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41976,DS-845c9a5c-498f-4f5f-88ca-5bd7c6eb8065,DISK], DatanodeInfoWithStorage[127.0.0.1:33326,DS-5ea456bd-ee47-4b8e-9b0b-cea6cd2e4347,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2004657053-172.17.0.21-1597398737481:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33554,DS-1e5044c6-68b0-4f6d-b66a-e5e86235892a,DISK], DatanodeInfoWithStorage[127.0.0.1:36399,DS-e75a1212-3c93-4619-b155-86f5ed518082,DISK], DatanodeInfoWithStorage[127.0.0.1:35294,DS-07d20aac-5cb7-4c4a-bf07-564723be2b03,DISK], DatanodeInfoWithStorage[127.0.0.1:41002,DS-a8d37e7c-6bc3-44c5-a83b-aeeea0c83d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:44812,DS-8345aa6e-8570-4cf7-9a57-0cdcd2ac156f,DISK], DatanodeInfoWithStorage[127.0.0.1:34580,DS-1dda4667-bab6-4dbd-ad99-dd8090f6a7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41976,DS-845c9a5c-498f-4f5f-88ca-5bd7c6eb8065,DISK], DatanodeInfoWithStorage[127.0.0.1:33326,DS-5ea456bd-ee47-4b8e-9b0b-cea6cd2e4347,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.key.update.interval
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1085834155-172.17.0.21-1597398822889:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38159,DS-0c61bb68-3af1-4659-837a-5f6d77c76f21,DISK], DatanodeInfoWithStorage[127.0.0.1:36035,DS-9637c0bd-ba7e-4dac-a934-1e2c80005a38,DISK], DatanodeInfoWithStorage[127.0.0.1:39139,DS-dfef5063-cd94-4580-b942-132923ceaa0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39774,DS-c69d9dc5-aad2-4137-aeba-1a8d30a9d9be,DISK], DatanodeInfoWithStorage[127.0.0.1:39663,DS-fb46a82b-607c-4a16-8b4e-888fb8b470cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36703,DS-0843ca5f-2e97-455d-a156-a8b2fe98126a,DISK], DatanodeInfoWithStorage[127.0.0.1:41450,DS-88b8ffe4-21ed-4fcb-a760-15853e1d0274,DISK], DatanodeInfoWithStorage[127.0.0.1:46689,DS-7a1e6bda-39c6-49ac-b327-9e1d6934de5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1085834155-172.17.0.21-1597398822889:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38159,DS-0c61bb68-3af1-4659-837a-5f6d77c76f21,DISK], DatanodeInfoWithStorage[127.0.0.1:36035,DS-9637c0bd-ba7e-4dac-a934-1e2c80005a38,DISK], DatanodeInfoWithStorage[127.0.0.1:39139,DS-dfef5063-cd94-4580-b942-132923ceaa0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39774,DS-c69d9dc5-aad2-4137-aeba-1a8d30a9d9be,DISK], DatanodeInfoWithStorage[127.0.0.1:39663,DS-fb46a82b-607c-4a16-8b4e-888fb8b470cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36703,DS-0843ca5f-2e97-455d-a156-a8b2fe98126a,DISK], DatanodeInfoWithStorage[127.0.0.1:41450,DS-88b8ffe4-21ed-4fcb-a760-15853e1d0274,DISK], DatanodeInfoWithStorage[127.0.0.1:46689,DS-7a1e6bda-39c6-49ac-b327-9e1d6934de5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.key.update.interval
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2058262240-172.17.0.21-1597398964313:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37852,DS-924965b6-c739-4f79-b620-8c67e9c0301c,DISK], DatanodeInfoWithStorage[127.0.0.1:35853,DS-40cc6b62-760b-457e-8607-38d299503a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:45696,DS-9c872ff5-a6a0-4c68-b0c5-81bcfd8b46d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39301,DS-591ab71b-4b67-43da-b6fa-3d38db9d5a36,DISK], DatanodeInfoWithStorage[127.0.0.1:33369,DS-631b5065-1109-4e4e-866b-e3ddf42f5fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:44989,DS-f525794a-c58e-49fb-a680-d050fa2bb076,DISK], DatanodeInfoWithStorage[127.0.0.1:44882,DS-449ca133-3726-4d3d-a0ec-4f6b10639733,DISK], DatanodeInfoWithStorage[127.0.0.1:42444,DS-eafa47cf-3dfd-4d5d-bf93-1e976d06a730,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2058262240-172.17.0.21-1597398964313:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37852,DS-924965b6-c739-4f79-b620-8c67e9c0301c,DISK], DatanodeInfoWithStorage[127.0.0.1:35853,DS-40cc6b62-760b-457e-8607-38d299503a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:45696,DS-9c872ff5-a6a0-4c68-b0c5-81bcfd8b46d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39301,DS-591ab71b-4b67-43da-b6fa-3d38db9d5a36,DISK], DatanodeInfoWithStorage[127.0.0.1:33369,DS-631b5065-1109-4e4e-866b-e3ddf42f5fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:44989,DS-f525794a-c58e-49fb-a680-d050fa2bb076,DISK], DatanodeInfoWithStorage[127.0.0.1:44882,DS-449ca133-3726-4d3d-a0ec-4f6b10639733,DISK], DatanodeInfoWithStorage[127.0.0.1:42444,DS-eafa47cf-3dfd-4d5d-bf93-1e976d06a730,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.key.update.interval
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-630957008-172.17.0.21-1597400297689:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44261,DS-bd5a0473-3644-49df-9a3f-243e18c97b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42850,DS-6a25a756-7678-4216-9cf6-a22b8d0b6da3,DISK], DatanodeInfoWithStorage[127.0.0.1:44138,DS-fa97b90f-4480-497c-a138-23889b7d7427,DISK], DatanodeInfoWithStorage[127.0.0.1:33969,DS-b46ae3b8-a999-44b9-82f7-3e5bd1127225,DISK], DatanodeInfoWithStorage[127.0.0.1:45080,DS-296fcccb-c30e-4336-9201-991c4be00d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:45887,DS-675dd9b2-6636-4f0b-b67f-ef3470f6291f,DISK], DatanodeInfoWithStorage[127.0.0.1:36809,DS-13a7b6ea-9343-401d-b14f-0f3207cf67bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42589,DS-b3f81339-6d3d-4a39-a079-04ab99f5801d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-630957008-172.17.0.21-1597400297689:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44261,DS-bd5a0473-3644-49df-9a3f-243e18c97b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42850,DS-6a25a756-7678-4216-9cf6-a22b8d0b6da3,DISK], DatanodeInfoWithStorage[127.0.0.1:44138,DS-fa97b90f-4480-497c-a138-23889b7d7427,DISK], DatanodeInfoWithStorage[127.0.0.1:33969,DS-b46ae3b8-a999-44b9-82f7-3e5bd1127225,DISK], DatanodeInfoWithStorage[127.0.0.1:45080,DS-296fcccb-c30e-4336-9201-991c4be00d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:45887,DS-675dd9b2-6636-4f0b-b67f-ef3470f6291f,DISK], DatanodeInfoWithStorage[127.0.0.1:36809,DS-13a7b6ea-9343-401d-b14f-0f3207cf67bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42589,DS-b3f81339-6d3d-4a39-a079-04ab99f5801d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.key.update.interval
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-577338133-172.17.0.21-1597400385604:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37085,DS-199765b1-7fed-4686-adfd-a4b1554e6cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:37765,DS-0f11b961-4d80-4b75-9b20-545ab79f98d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34691,DS-61461b3b-a93e-4ecf-ac91-6202560e62b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33103,DS-29e490f4-9a1f-4c76-aac5-fd9c9f324bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:38469,DS-15107377-5921-4615-90a8-9b4ed6268fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:39676,DS-32e25da8-0269-41a9-8d31-a4acfe1fa304,DISK], DatanodeInfoWithStorage[127.0.0.1:42757,DS-50369c36-99b2-403c-a552-d46f32b751eb,DISK], DatanodeInfoWithStorage[127.0.0.1:32992,DS-40725502-4841-46dd-b1d7-7b0ccdf900c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-577338133-172.17.0.21-1597400385604:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37085,DS-199765b1-7fed-4686-adfd-a4b1554e6cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:37765,DS-0f11b961-4d80-4b75-9b20-545ab79f98d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34691,DS-61461b3b-a93e-4ecf-ac91-6202560e62b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33103,DS-29e490f4-9a1f-4c76-aac5-fd9c9f324bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:38469,DS-15107377-5921-4615-90a8-9b4ed6268fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:39676,DS-32e25da8-0269-41a9-8d31-a4acfe1fa304,DISK], DatanodeInfoWithStorage[127.0.0.1:42757,DS-50369c36-99b2-403c-a552-d46f32b751eb,DISK], DatanodeInfoWithStorage[127.0.0.1:32992,DS-40725502-4841-46dd-b1d7-7b0ccdf900c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.key.update.interval
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1541700396-172.17.0.21-1597400609352:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46874,DS-5cdb6d24-1a9c-411f-9cb7-9ddfdd0b038a,DISK], DatanodeInfoWithStorage[127.0.0.1:40153,DS-ebae4e7b-e43a-4d7d-b09c-e387a730d9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43560,DS-eac77a98-eb5b-4b11-a2ce-e2947d63d289,DISK], DatanodeInfoWithStorage[127.0.0.1:44626,DS-0442e4b6-b878-4ad2-a997-503129ddbeff,DISK], DatanodeInfoWithStorage[127.0.0.1:32941,DS-f1fc4c08-bf6c-4809-a844-84bf006f19a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41109,DS-f63c34b0-42c1-40ab-aa5c-09fdf9d49b39,DISK], DatanodeInfoWithStorage[127.0.0.1:38992,DS-c9e27e60-f027-4f7d-b2f6-ac94289fea11,DISK], DatanodeInfoWithStorage[127.0.0.1:39612,DS-25ab10e3-d165-4c8e-8659-55e068892486,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1541700396-172.17.0.21-1597400609352:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46874,DS-5cdb6d24-1a9c-411f-9cb7-9ddfdd0b038a,DISK], DatanodeInfoWithStorage[127.0.0.1:40153,DS-ebae4e7b-e43a-4d7d-b09c-e387a730d9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43560,DS-eac77a98-eb5b-4b11-a2ce-e2947d63d289,DISK], DatanodeInfoWithStorage[127.0.0.1:44626,DS-0442e4b6-b878-4ad2-a997-503129ddbeff,DISK], DatanodeInfoWithStorage[127.0.0.1:32941,DS-f1fc4c08-bf6c-4809-a844-84bf006f19a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41109,DS-f63c34b0-42c1-40ab-aa5c-09fdf9d49b39,DISK], DatanodeInfoWithStorage[127.0.0.1:38992,DS-c9e27e60-f027-4f7d-b2f6-ac94289fea11,DISK], DatanodeInfoWithStorage[127.0.0.1:39612,DS-25ab10e3-d165-4c8e-8659-55e068892486,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.key.update.interval
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1160637258-172.17.0.21-1597400819113:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34135,DS-2ac74f0c-c5d4-430f-b4f6-61374bac1473,DISK], DatanodeInfoWithStorage[127.0.0.1:43017,DS-7a52643a-6b2b-4bd1-a359-f106fc60e600,DISK], DatanodeInfoWithStorage[127.0.0.1:33056,DS-88d66f78-0d7d-421a-af72-54d1a9921f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:44878,DS-9ef72bdd-95bd-42c9-a3de-2d45602fbe94,DISK], DatanodeInfoWithStorage[127.0.0.1:45018,DS-9fd5e8ca-31a6-4d94-801a-f5f35d180d92,DISK], DatanodeInfoWithStorage[127.0.0.1:40637,DS-515f31ac-4690-4a10-bc05-7537be4c2a35,DISK], DatanodeInfoWithStorage[127.0.0.1:46049,DS-4a997ac8-e339-4b2a-b59d-e34464e005b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41893,DS-876a6c73-2a53-41f1-bd72-d1b2b469697f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1160637258-172.17.0.21-1597400819113:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34135,DS-2ac74f0c-c5d4-430f-b4f6-61374bac1473,DISK], DatanodeInfoWithStorage[127.0.0.1:43017,DS-7a52643a-6b2b-4bd1-a359-f106fc60e600,DISK], DatanodeInfoWithStorage[127.0.0.1:33056,DS-88d66f78-0d7d-421a-af72-54d1a9921f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:44878,DS-9ef72bdd-95bd-42c9-a3de-2d45602fbe94,DISK], DatanodeInfoWithStorage[127.0.0.1:45018,DS-9fd5e8ca-31a6-4d94-801a-f5f35d180d92,DISK], DatanodeInfoWithStorage[127.0.0.1:40637,DS-515f31ac-4690-4a10-bc05-7537be4c2a35,DISK], DatanodeInfoWithStorage[127.0.0.1:46049,DS-4a997ac8-e339-4b2a-b59d-e34464e005b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41893,DS-876a6c73-2a53-41f1-bd72-d1b2b469697f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.key.update.interval
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1887877606-172.17.0.21-1597400861550:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35943,DS-c0e77260-5ccd-4765-87f8-19ac792ba6fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43216,DS-cdbc6a93-4416-4cbe-8d06-e8b1ee7a0e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:39205,DS-3bdffeb1-0970-4304-96f6-131a1b810777,DISK], DatanodeInfoWithStorage[127.0.0.1:41489,DS-570f573f-aa76-476d-879c-7830509f8215,DISK], DatanodeInfoWithStorage[127.0.0.1:44996,DS-7d7fa6ca-59ed-4953-963d-75cdfdb9d015,DISK], DatanodeInfoWithStorage[127.0.0.1:33115,DS-a9c43c90-dc24-4114-92b7-0ea9968d3396,DISK], DatanodeInfoWithStorage[127.0.0.1:39017,DS-4e7bba63-a810-4ec9-9b1a-256e8a1bb70e,DISK], DatanodeInfoWithStorage[127.0.0.1:43061,DS-8e483568-7fc5-47dc-a4b3-5d96f05942af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1887877606-172.17.0.21-1597400861550:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35943,DS-c0e77260-5ccd-4765-87f8-19ac792ba6fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43216,DS-cdbc6a93-4416-4cbe-8d06-e8b1ee7a0e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:39205,DS-3bdffeb1-0970-4304-96f6-131a1b810777,DISK], DatanodeInfoWithStorage[127.0.0.1:41489,DS-570f573f-aa76-476d-879c-7830509f8215,DISK], DatanodeInfoWithStorage[127.0.0.1:44996,DS-7d7fa6ca-59ed-4953-963d-75cdfdb9d015,DISK], DatanodeInfoWithStorage[127.0.0.1:33115,DS-a9c43c90-dc24-4114-92b7-0ea9968d3396,DISK], DatanodeInfoWithStorage[127.0.0.1:39017,DS-4e7bba63-a810-4ec9-9b1a-256e8a1bb70e,DISK], DatanodeInfoWithStorage[127.0.0.1:43061,DS-8e483568-7fc5-47dc-a4b3-5d96f05942af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.key.update.interval
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1841421302-172.17.0.21-1597401189853:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40050,DS-27e2069b-eabe-493b-812e-ea28375268b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35435,DS-dfa50c68-d5ad-4b5d-ac48-9d0858e23b13,DISK], DatanodeInfoWithStorage[127.0.0.1:44912,DS-48fa9806-7269-4eae-a9e1-8b1d5a93efda,DISK], DatanodeInfoWithStorage[127.0.0.1:39820,DS-6db52155-87ad-458c-bb08-97f3a87d30fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33115,DS-6d65d375-bb5b-4120-87df-461d84639ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:46273,DS-6a4eb591-47ac-4275-8ec4-3c5052471731,DISK], DatanodeInfoWithStorage[127.0.0.1:39886,DS-00e5e050-675e-48e9-be28-9060c90b1406,DISK], DatanodeInfoWithStorage[127.0.0.1:42716,DS-4b4d573f-2e7e-4528-a1ed-fc3ab548ccee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1841421302-172.17.0.21-1597401189853:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40050,DS-27e2069b-eabe-493b-812e-ea28375268b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35435,DS-dfa50c68-d5ad-4b5d-ac48-9d0858e23b13,DISK], DatanodeInfoWithStorage[127.0.0.1:44912,DS-48fa9806-7269-4eae-a9e1-8b1d5a93efda,DISK], DatanodeInfoWithStorage[127.0.0.1:39820,DS-6db52155-87ad-458c-bb08-97f3a87d30fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33115,DS-6d65d375-bb5b-4120-87df-461d84639ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:46273,DS-6a4eb591-47ac-4275-8ec4-3c5052471731,DISK], DatanodeInfoWithStorage[127.0.0.1:39886,DS-00e5e050-675e-48e9-be28-9060c90b1406,DISK], DatanodeInfoWithStorage[127.0.0.1:42716,DS-4b4d573f-2e7e-4528-a1ed-fc3ab548ccee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.key.update.interval
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-742612813-172.17.0.21-1597401712915:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37083,DS-dba24ecf-e792-406f-8f72-01540f089bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:33658,DS-7e2bd626-0963-4a2d-b795-48358d850564,DISK], DatanodeInfoWithStorage[127.0.0.1:41884,DS-390a97fa-d86c-4609-8feb-b3c59ff83160,DISK], DatanodeInfoWithStorage[127.0.0.1:42774,DS-118509a5-8ad1-49e9-9ac3-4776263c33b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39691,DS-89f7354a-5b00-48b4-8eb6-282e9e6502e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39800,DS-a141c49d-1a8f-43de-b75a-2839f603ce73,DISK], DatanodeInfoWithStorage[127.0.0.1:44796,DS-2a982b3e-c2a7-4ad5-bbda-41fd4b4919d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45108,DS-2df9fcc4-4163-4f56-9d0a-e6c3f781d57c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-742612813-172.17.0.21-1597401712915:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37083,DS-dba24ecf-e792-406f-8f72-01540f089bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:33658,DS-7e2bd626-0963-4a2d-b795-48358d850564,DISK], DatanodeInfoWithStorage[127.0.0.1:41884,DS-390a97fa-d86c-4609-8feb-b3c59ff83160,DISK], DatanodeInfoWithStorage[127.0.0.1:42774,DS-118509a5-8ad1-49e9-9ac3-4776263c33b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39691,DS-89f7354a-5b00-48b4-8eb6-282e9e6502e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39800,DS-a141c49d-1a8f-43de-b75a-2839f603ce73,DISK], DatanodeInfoWithStorage[127.0.0.1:44796,DS-2a982b3e-c2a7-4ad5-bbda-41fd4b4919d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45108,DS-2df9fcc4-4163-4f56-9d0a-e6c3f781d57c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.key.update.interval
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-654622537-172.17.0.21-1597401983744:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46254,DS-9f0003fe-87cc-45dd-838f-50b6a4696e13,DISK], DatanodeInfoWithStorage[127.0.0.1:38313,DS-036e93b4-f734-46c9-af12-41e3e7f45a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:41020,DS-b78f2776-ca36-489d-929c-35b3c81e674c,DISK], DatanodeInfoWithStorage[127.0.0.1:43537,DS-6c0cb9b6-9942-482c-97a0-daac630cca30,DISK], DatanodeInfoWithStorage[127.0.0.1:34140,DS-4d860c4a-db21-4a95-88b8-67de4aa350e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33005,DS-c72a9f7f-d3be-4a32-8173-6dc4eec54e90,DISK], DatanodeInfoWithStorage[127.0.0.1:33624,DS-c13914b9-5fc9-41b9-8e4e-b3bde707f4c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36935,DS-260536b1-bb87-41cc-9e0f-4bc7d96332e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-654622537-172.17.0.21-1597401983744:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46254,DS-9f0003fe-87cc-45dd-838f-50b6a4696e13,DISK], DatanodeInfoWithStorage[127.0.0.1:38313,DS-036e93b4-f734-46c9-af12-41e3e7f45a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:41020,DS-b78f2776-ca36-489d-929c-35b3c81e674c,DISK], DatanodeInfoWithStorage[127.0.0.1:43537,DS-6c0cb9b6-9942-482c-97a0-daac630cca30,DISK], DatanodeInfoWithStorage[127.0.0.1:34140,DS-4d860c4a-db21-4a95-88b8-67de4aa350e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33005,DS-c72a9f7f-d3be-4a32-8173-6dc4eec54e90,DISK], DatanodeInfoWithStorage[127.0.0.1:33624,DS-c13914b9-5fc9-41b9-8e4e-b3bde707f4c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36935,DS-260536b1-bb87-41cc-9e0f-4bc7d96332e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.key.update.interval
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1476894026-172.17.0.21-1597402971609:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40910,DS-e17380dc-03fc-4ba6-a38b-cf9e3abbfec0,DISK], DatanodeInfoWithStorage[127.0.0.1:35304,DS-18b954a0-6d7e-460c-abb8-831497c81100,DISK], DatanodeInfoWithStorage[127.0.0.1:34451,DS-e39b51ff-b5a1-4efe-8a02-ce8f23bcf8c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42020,DS-43d30356-4009-4a4b-86f5-9419fa90c01f,DISK], DatanodeInfoWithStorage[127.0.0.1:39316,DS-418c087b-6640-4d05-8521-5436e0860cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:35118,DS-f3725638-0022-4465-8125-356733ee0382,DISK], DatanodeInfoWithStorage[127.0.0.1:44913,DS-2d1a488e-227c-4eba-9009-0b0388a96672,DISK], DatanodeInfoWithStorage[127.0.0.1:42524,DS-63eacf86-560f-4ea5-9f32-0293359cd417,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1476894026-172.17.0.21-1597402971609:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40910,DS-e17380dc-03fc-4ba6-a38b-cf9e3abbfec0,DISK], DatanodeInfoWithStorage[127.0.0.1:35304,DS-18b954a0-6d7e-460c-abb8-831497c81100,DISK], DatanodeInfoWithStorage[127.0.0.1:34451,DS-e39b51ff-b5a1-4efe-8a02-ce8f23bcf8c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42020,DS-43d30356-4009-4a4b-86f5-9419fa90c01f,DISK], DatanodeInfoWithStorage[127.0.0.1:39316,DS-418c087b-6640-4d05-8521-5436e0860cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:35118,DS-f3725638-0022-4465-8125-356733ee0382,DISK], DatanodeInfoWithStorage[127.0.0.1:44913,DS-2d1a488e-227c-4eba-9009-0b0388a96672,DISK], DatanodeInfoWithStorage[127.0.0.1:42524,DS-63eacf86-560f-4ea5-9f32-0293359cd417,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 6855
