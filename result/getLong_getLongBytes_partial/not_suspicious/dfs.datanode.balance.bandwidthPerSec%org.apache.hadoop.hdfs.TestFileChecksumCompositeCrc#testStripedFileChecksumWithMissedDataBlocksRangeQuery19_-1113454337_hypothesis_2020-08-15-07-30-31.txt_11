reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1196481253-172.17.0.15-1597476911769:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40749,DS-0b54ecca-c0ad-45ed-8fde-e66f29e743d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44266,DS-7fd3d5cc-41e7-4083-8674-ce0d27a025d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44271,DS-1b895c91-4c9c-4580-896b-5a7e4052c0f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35664,DS-a125945b-ae49-452f-9faa-3cd5cfd982c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38626,DS-ee778f6b-21de-4d32-ac19-2e91ec69caed,DISK], DatanodeInfoWithStorage[127.0.0.1:44840,DS-dccf8a7e-fa2f-459a-9fcd-c200b5b3629a,DISK], DatanodeInfoWithStorage[127.0.0.1:41140,DS-781921a3-2312-4382-8ff5-e519b3ecaac9,DISK], DatanodeInfoWithStorage[127.0.0.1:42809,DS-4f2efa6c-e1b7-49a6-9aa5-1da5e61898ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1196481253-172.17.0.15-1597476911769:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40749,DS-0b54ecca-c0ad-45ed-8fde-e66f29e743d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44266,DS-7fd3d5cc-41e7-4083-8674-ce0d27a025d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44271,DS-1b895c91-4c9c-4580-896b-5a7e4052c0f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35664,DS-a125945b-ae49-452f-9faa-3cd5cfd982c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38626,DS-ee778f6b-21de-4d32-ac19-2e91ec69caed,DISK], DatanodeInfoWithStorage[127.0.0.1:44840,DS-dccf8a7e-fa2f-459a-9fcd-c200b5b3629a,DISK], DatanodeInfoWithStorage[127.0.0.1:41140,DS-781921a3-2312-4382-8ff5-e519b3ecaac9,DISK], DatanodeInfoWithStorage[127.0.0.1:42809,DS-4f2efa6c-e1b7-49a6-9aa5-1da5e61898ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1663800750-172.17.0.15-1597477366907:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39740,DS-02a1b4d9-64c2-4f5c-a2cb-3eb7dfa3ba3e,DISK], DatanodeInfoWithStorage[127.0.0.1:37130,DS-db79d9a4-4b37-45b2-bce8-089fab13af92,DISK], DatanodeInfoWithStorage[127.0.0.1:41744,DS-1cf8ff65-1162-4296-b074-e89950a6c13c,DISK], DatanodeInfoWithStorage[127.0.0.1:42175,DS-449773e1-f592-4cc3-8088-8e8f0c240a25,DISK], DatanodeInfoWithStorage[127.0.0.1:38733,DS-18287904-8a52-4706-8f58-2d6336a60e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45607,DS-5f596a86-4665-4f4a-b6eb-fa68ea4fc854,DISK], DatanodeInfoWithStorage[127.0.0.1:44657,DS-e0ee3fff-cfcf-449d-bdb3-d523a12c2dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:43479,DS-5bd9507f-e72e-4b24-aed2-a8b91592f06f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1663800750-172.17.0.15-1597477366907:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39740,DS-02a1b4d9-64c2-4f5c-a2cb-3eb7dfa3ba3e,DISK], DatanodeInfoWithStorage[127.0.0.1:37130,DS-db79d9a4-4b37-45b2-bce8-089fab13af92,DISK], DatanodeInfoWithStorage[127.0.0.1:41744,DS-1cf8ff65-1162-4296-b074-e89950a6c13c,DISK], DatanodeInfoWithStorage[127.0.0.1:42175,DS-449773e1-f592-4cc3-8088-8e8f0c240a25,DISK], DatanodeInfoWithStorage[127.0.0.1:38733,DS-18287904-8a52-4706-8f58-2d6336a60e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45607,DS-5f596a86-4665-4f4a-b6eb-fa68ea4fc854,DISK], DatanodeInfoWithStorage[127.0.0.1:44657,DS-e0ee3fff-cfcf-449d-bdb3-d523a12c2dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:43479,DS-5bd9507f-e72e-4b24-aed2-a8b91592f06f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-203185185-172.17.0.15-1597477763242:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45061,DS-fabf614f-b9bc-47bd-a247-f9e51e66cad7,DISK], DatanodeInfoWithStorage[127.0.0.1:39645,DS-4a39be6c-95dc-42fd-aa17-2add5171f1ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38222,DS-6c064ae7-2216-4605-bcca-b0a2f619c380,DISK], DatanodeInfoWithStorage[127.0.0.1:34416,DS-79b94202-1b85-4fe1-8a71-5acc77a7dc52,DISK], DatanodeInfoWithStorage[127.0.0.1:35024,DS-45133ec5-032d-4b93-b265-3a54acf974b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46246,DS-550c95ca-0be6-4cfd-9a4e-e36691784eed,DISK], DatanodeInfoWithStorage[127.0.0.1:38563,DS-88ccfac1-a125-4b8f-8402-04e1fcf0eac1,DISK], DatanodeInfoWithStorage[127.0.0.1:41216,DS-5ac3a6a7-e50c-4a8a-8fe2-6bd7a99d7da8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-203185185-172.17.0.15-1597477763242:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45061,DS-fabf614f-b9bc-47bd-a247-f9e51e66cad7,DISK], DatanodeInfoWithStorage[127.0.0.1:39645,DS-4a39be6c-95dc-42fd-aa17-2add5171f1ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38222,DS-6c064ae7-2216-4605-bcca-b0a2f619c380,DISK], DatanodeInfoWithStorage[127.0.0.1:34416,DS-79b94202-1b85-4fe1-8a71-5acc77a7dc52,DISK], DatanodeInfoWithStorage[127.0.0.1:35024,DS-45133ec5-032d-4b93-b265-3a54acf974b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46246,DS-550c95ca-0be6-4cfd-9a4e-e36691784eed,DISK], DatanodeInfoWithStorage[127.0.0.1:38563,DS-88ccfac1-a125-4b8f-8402-04e1fcf0eac1,DISK], DatanodeInfoWithStorage[127.0.0.1:41216,DS-5ac3a6a7-e50c-4a8a-8fe2-6bd7a99d7da8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-762203666-172.17.0.15-1597477914702:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33078,DS-0ef9249c-6e9a-48f5-89e4-d035b5bbcbac,DISK], DatanodeInfoWithStorage[127.0.0.1:39747,DS-2e13284b-9297-4461-bb20-0ef69de13868,DISK], DatanodeInfoWithStorage[127.0.0.1:36370,DS-9573b562-715d-4317-b3fb-b53296d93775,DISK], DatanodeInfoWithStorage[127.0.0.1:46308,DS-681432f9-4e2b-4ea1-89a2-5a0e9cf0f289,DISK], DatanodeInfoWithStorage[127.0.0.1:38633,DS-654c729b-7fce-4da2-b309-162564a682b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41899,DS-587f82b3-14ea-4a8f-9033-f9ba8d9aba24,DISK], DatanodeInfoWithStorage[127.0.0.1:41325,DS-50c8e4e8-78ad-47c3-917e-0039a0ca34ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42302,DS-bb9c70f1-5611-415d-9994-86e0544e7c25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-762203666-172.17.0.15-1597477914702:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33078,DS-0ef9249c-6e9a-48f5-89e4-d035b5bbcbac,DISK], DatanodeInfoWithStorage[127.0.0.1:39747,DS-2e13284b-9297-4461-bb20-0ef69de13868,DISK], DatanodeInfoWithStorage[127.0.0.1:36370,DS-9573b562-715d-4317-b3fb-b53296d93775,DISK], DatanodeInfoWithStorage[127.0.0.1:46308,DS-681432f9-4e2b-4ea1-89a2-5a0e9cf0f289,DISK], DatanodeInfoWithStorage[127.0.0.1:38633,DS-654c729b-7fce-4da2-b309-162564a682b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41899,DS-587f82b3-14ea-4a8f-9033-f9ba8d9aba24,DISK], DatanodeInfoWithStorage[127.0.0.1:41325,DS-50c8e4e8-78ad-47c3-917e-0039a0ca34ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42302,DS-bb9c70f1-5611-415d-9994-86e0544e7c25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-973953387-172.17.0.15-1597477955604:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45784,DS-bcbcfb45-0573-4711-9d9f-38546c885516,DISK], DatanodeInfoWithStorage[127.0.0.1:40143,DS-aaa3f251-1f6d-4c54-b32d-c36f2784fc0f,DISK], DatanodeInfoWithStorage[127.0.0.1:42199,DS-1068fec3-363a-44f2-b979-f7486c8982d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46248,DS-6f29319a-f877-44c9-84df-5ead20f54f97,DISK], DatanodeInfoWithStorage[127.0.0.1:38627,DS-b66d5608-e316-4e29-b9ae-c8866071f19c,DISK], DatanodeInfoWithStorage[127.0.0.1:42913,DS-d70b64e6-25ec-4236-99c2-546310a3e6b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34976,DS-30a7a539-5e12-4228-91b3-d7c5e1d1b180,DISK], DatanodeInfoWithStorage[127.0.0.1:34348,DS-0d4b511a-dec3-48f8-8c1b-d5a5719e3fd5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-973953387-172.17.0.15-1597477955604:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45784,DS-bcbcfb45-0573-4711-9d9f-38546c885516,DISK], DatanodeInfoWithStorage[127.0.0.1:40143,DS-aaa3f251-1f6d-4c54-b32d-c36f2784fc0f,DISK], DatanodeInfoWithStorage[127.0.0.1:42199,DS-1068fec3-363a-44f2-b979-f7486c8982d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46248,DS-6f29319a-f877-44c9-84df-5ead20f54f97,DISK], DatanodeInfoWithStorage[127.0.0.1:38627,DS-b66d5608-e316-4e29-b9ae-c8866071f19c,DISK], DatanodeInfoWithStorage[127.0.0.1:42913,DS-d70b64e6-25ec-4236-99c2-546310a3e6b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34976,DS-30a7a539-5e12-4228-91b3-d7c5e1d1b180,DISK], DatanodeInfoWithStorage[127.0.0.1:34348,DS-0d4b511a-dec3-48f8-8c1b-d5a5719e3fd5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1309453683-172.17.0.15-1597478833436:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38053,DS-d1dc07dc-2a87-4373-baf0-ab207baf1a84,DISK], DatanodeInfoWithStorage[127.0.0.1:36751,DS-02dfe737-6f46-42f6-b7b5-a7ad69d4fdc4,DISK], DatanodeInfoWithStorage[127.0.0.1:37664,DS-70f3c366-6c52-4a28-82b6-b34447f8048d,DISK], DatanodeInfoWithStorage[127.0.0.1:45723,DS-19f5946e-e73e-47d3-9de2-603e7fa4cf0c,DISK], DatanodeInfoWithStorage[127.0.0.1:37825,DS-ba7b85a4-a5c5-4bf2-8c21-b83a53464e06,DISK], DatanodeInfoWithStorage[127.0.0.1:32793,DS-ec11ffd6-fd61-4ba0-893e-2ad420d289d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46829,DS-fdfdc179-3753-4e87-b3ba-7e84b27ca6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37459,DS-1efee4bd-1177-48ff-b899-c3e99a7f2e62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1309453683-172.17.0.15-1597478833436:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38053,DS-d1dc07dc-2a87-4373-baf0-ab207baf1a84,DISK], DatanodeInfoWithStorage[127.0.0.1:36751,DS-02dfe737-6f46-42f6-b7b5-a7ad69d4fdc4,DISK], DatanodeInfoWithStorage[127.0.0.1:37664,DS-70f3c366-6c52-4a28-82b6-b34447f8048d,DISK], DatanodeInfoWithStorage[127.0.0.1:45723,DS-19f5946e-e73e-47d3-9de2-603e7fa4cf0c,DISK], DatanodeInfoWithStorage[127.0.0.1:37825,DS-ba7b85a4-a5c5-4bf2-8c21-b83a53464e06,DISK], DatanodeInfoWithStorage[127.0.0.1:32793,DS-ec11ffd6-fd61-4ba0-893e-2ad420d289d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46829,DS-fdfdc179-3753-4e87-b3ba-7e84b27ca6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37459,DS-1efee4bd-1177-48ff-b899-c3e99a7f2e62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-110423335-172.17.0.15-1597479859998:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38020,DS-d9c475ea-ad49-4d18-986e-c79905b81e36,DISK], DatanodeInfoWithStorage[127.0.0.1:41890,DS-06485fcf-889e-4e8e-8bf9-5269dbf817ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46869,DS-1947d5e5-3946-47de-b357-f929ff76126e,DISK], DatanodeInfoWithStorage[127.0.0.1:34769,DS-4b0f7e2d-28a3-472c-a93d-49e09f7180e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36018,DS-1e824375-5d55-4bee-a919-eeb5e951694f,DISK], DatanodeInfoWithStorage[127.0.0.1:37197,DS-04df7ae2-628f-43b9-b38b-deab26a81d21,DISK], DatanodeInfoWithStorage[127.0.0.1:42553,DS-5edf562c-9a6f-4ecb-93ef-d80124ee9a92,DISK], DatanodeInfoWithStorage[127.0.0.1:41602,DS-4e4a203f-2375-4d66-aaf9-8ced401c5f41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-110423335-172.17.0.15-1597479859998:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38020,DS-d9c475ea-ad49-4d18-986e-c79905b81e36,DISK], DatanodeInfoWithStorage[127.0.0.1:41890,DS-06485fcf-889e-4e8e-8bf9-5269dbf817ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46869,DS-1947d5e5-3946-47de-b357-f929ff76126e,DISK], DatanodeInfoWithStorage[127.0.0.1:34769,DS-4b0f7e2d-28a3-472c-a93d-49e09f7180e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36018,DS-1e824375-5d55-4bee-a919-eeb5e951694f,DISK], DatanodeInfoWithStorage[127.0.0.1:37197,DS-04df7ae2-628f-43b9-b38b-deab26a81d21,DISK], DatanodeInfoWithStorage[127.0.0.1:42553,DS-5edf562c-9a6f-4ecb-93ef-d80124ee9a92,DISK], DatanodeInfoWithStorage[127.0.0.1:41602,DS-4e4a203f-2375-4d66-aaf9-8ced401c5f41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1467514370-172.17.0.15-1597479895281:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42635,DS-e0a9bc92-08d2-4b0b-bf86-0c59841c8cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:42670,DS-731d89df-c258-4a6e-8543-31fe72a6b442,DISK], DatanodeInfoWithStorage[127.0.0.1:43445,DS-e9ee8ee2-5994-4894-9cfc-8c6d15e21a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36653,DS-f13f5a52-7df9-44a5-8672-2a22863ad353,DISK], DatanodeInfoWithStorage[127.0.0.1:39703,DS-346a467e-8764-416e-aebc-ee81a01a1193,DISK], DatanodeInfoWithStorage[127.0.0.1:38410,DS-6839dee1-b5aa-4cf8-8caf-2e6402498ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:37334,DS-8e01607d-88ba-4771-8500-9e16fb4a338b,DISK], DatanodeInfoWithStorage[127.0.0.1:38198,DS-fe0cde29-9fa0-4894-be79-bbf9145c4e07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1467514370-172.17.0.15-1597479895281:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42635,DS-e0a9bc92-08d2-4b0b-bf86-0c59841c8cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:42670,DS-731d89df-c258-4a6e-8543-31fe72a6b442,DISK], DatanodeInfoWithStorage[127.0.0.1:43445,DS-e9ee8ee2-5994-4894-9cfc-8c6d15e21a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36653,DS-f13f5a52-7df9-44a5-8672-2a22863ad353,DISK], DatanodeInfoWithStorage[127.0.0.1:39703,DS-346a467e-8764-416e-aebc-ee81a01a1193,DISK], DatanodeInfoWithStorage[127.0.0.1:38410,DS-6839dee1-b5aa-4cf8-8caf-2e6402498ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:37334,DS-8e01607d-88ba-4771-8500-9e16fb4a338b,DISK], DatanodeInfoWithStorage[127.0.0.1:38198,DS-fe0cde29-9fa0-4894-be79-bbf9145c4e07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1346677388-172.17.0.15-1597480071093:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36386,DS-3ada8e31-bed6-45cd-999b-582aaed194c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39594,DS-d012ac9a-97a0-4fe5-8f44-d379311edca4,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-c6a94aa1-484b-429e-baaa-a36103b906d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36846,DS-f02c66e5-247c-436e-8ab9-4850a2218cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:33034,DS-4e57ec63-8752-468b-9226-6c1330b53a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:41565,DS-90510fd5-f448-4874-9303-76a56b1aaf10,DISK], DatanodeInfoWithStorage[127.0.0.1:41634,DS-c90b1678-2043-46aa-9df7-85431be55d80,DISK], DatanodeInfoWithStorage[127.0.0.1:34913,DS-fc5eda62-55a6-416c-ba7e-8e059ee3d13b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1346677388-172.17.0.15-1597480071093:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36386,DS-3ada8e31-bed6-45cd-999b-582aaed194c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39594,DS-d012ac9a-97a0-4fe5-8f44-d379311edca4,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-c6a94aa1-484b-429e-baaa-a36103b906d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36846,DS-f02c66e5-247c-436e-8ab9-4850a2218cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:33034,DS-4e57ec63-8752-468b-9226-6c1330b53a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:41565,DS-90510fd5-f448-4874-9303-76a56b1aaf10,DISK], DatanodeInfoWithStorage[127.0.0.1:41634,DS-c90b1678-2043-46aa-9df7-85431be55d80,DISK], DatanodeInfoWithStorage[127.0.0.1:34913,DS-fc5eda62-55a6-416c-ba7e-8e059ee3d13b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2046079460-172.17.0.15-1597480393768:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40219,DS-84394870-c01c-4a4b-9eb0-5b7118ff4f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44553,DS-13683dc1-3fd7-4438-b25f-3cfc87ec3a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44588,DS-10616dc7-7950-422a-a4f2-2d233964cbdb,DISK], DatanodeInfoWithStorage[127.0.0.1:45079,DS-4e892b99-e6a4-4972-9201-fcf71e4637a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38866,DS-535aa690-74d4-45d0-9732-d833d9393f25,DISK], DatanodeInfoWithStorage[127.0.0.1:39268,DS-d78e76e5-9e69-4c2a-a909-ce0bfad5116c,DISK], DatanodeInfoWithStorage[127.0.0.1:33496,DS-630f18f3-2006-4f0d-926b-cf3d8162b8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40619,DS-52c6bb66-70b0-4c06-a9a6-f663588bccdc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2046079460-172.17.0.15-1597480393768:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40219,DS-84394870-c01c-4a4b-9eb0-5b7118ff4f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44553,DS-13683dc1-3fd7-4438-b25f-3cfc87ec3a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44588,DS-10616dc7-7950-422a-a4f2-2d233964cbdb,DISK], DatanodeInfoWithStorage[127.0.0.1:45079,DS-4e892b99-e6a4-4972-9201-fcf71e4637a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38866,DS-535aa690-74d4-45d0-9732-d833d9393f25,DISK], DatanodeInfoWithStorage[127.0.0.1:39268,DS-d78e76e5-9e69-4c2a-a909-ce0bfad5116c,DISK], DatanodeInfoWithStorage[127.0.0.1:33496,DS-630f18f3-2006-4f0d-926b-cf3d8162b8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40619,DS-52c6bb66-70b0-4c06-a9a6-f663588bccdc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-641502101-172.17.0.15-1597480965387:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41512,DS-e190cf2c-97b7-401b-9138-2ed5c7b6271b,DISK], DatanodeInfoWithStorage[127.0.0.1:40970,DS-451ab018-cdd8-4d9e-9ca8-7f94df62279a,DISK], DatanodeInfoWithStorage[127.0.0.1:36953,DS-d22b7712-0a80-4b48-b776-1f4078bbc049,DISK], DatanodeInfoWithStorage[127.0.0.1:41891,DS-94586cfb-8b53-4aca-88c4-1d9321cf5859,DISK], DatanodeInfoWithStorage[127.0.0.1:42266,DS-fd5bd032-da84-4f69-9ced-41dd1bc12324,DISK], DatanodeInfoWithStorage[127.0.0.1:36994,DS-4c369904-9335-4cb1-b012-b794feed1615,DISK], DatanodeInfoWithStorage[127.0.0.1:43106,DS-edcc3de9-6b94-4771-92a4-1a9407be47f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45474,DS-719be5de-c732-4b36-870f-6fa66fb6901d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-641502101-172.17.0.15-1597480965387:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41512,DS-e190cf2c-97b7-401b-9138-2ed5c7b6271b,DISK], DatanodeInfoWithStorage[127.0.0.1:40970,DS-451ab018-cdd8-4d9e-9ca8-7f94df62279a,DISK], DatanodeInfoWithStorage[127.0.0.1:36953,DS-d22b7712-0a80-4b48-b776-1f4078bbc049,DISK], DatanodeInfoWithStorage[127.0.0.1:41891,DS-94586cfb-8b53-4aca-88c4-1d9321cf5859,DISK], DatanodeInfoWithStorage[127.0.0.1:42266,DS-fd5bd032-da84-4f69-9ced-41dd1bc12324,DISK], DatanodeInfoWithStorage[127.0.0.1:36994,DS-4c369904-9335-4cb1-b012-b794feed1615,DISK], DatanodeInfoWithStorage[127.0.0.1:43106,DS-edcc3de9-6b94-4771-92a4-1a9407be47f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45474,DS-719be5de-c732-4b36-870f-6fa66fb6901d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-720514156-172.17.0.15-1597481152689:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34470,DS-ea835a9b-8a40-4ea2-8592-d7715c474ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:34820,DS-2d3a1365-d77d-45f8-9d14-ce09b2375789,DISK], DatanodeInfoWithStorage[127.0.0.1:42259,DS-d36f1cdc-7e9c-43c0-86fc-eedad1142d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:36111,DS-8aaa861b-76fa-4d11-b072-54969c33b06c,DISK], DatanodeInfoWithStorage[127.0.0.1:36874,DS-918006af-d231-41da-acd8-4174efe9370c,DISK], DatanodeInfoWithStorage[127.0.0.1:36124,DS-5c2671ea-b68d-40f2-be7d-da4f7c51ebd5,DISK], DatanodeInfoWithStorage[127.0.0.1:45971,DS-6c374bad-8ddf-45c0-b47c-bcfbcc053503,DISK], DatanodeInfoWithStorage[127.0.0.1:45801,DS-129a6622-61a7-48b0-b91b-eb2ee536b5f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-720514156-172.17.0.15-1597481152689:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34470,DS-ea835a9b-8a40-4ea2-8592-d7715c474ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:34820,DS-2d3a1365-d77d-45f8-9d14-ce09b2375789,DISK], DatanodeInfoWithStorage[127.0.0.1:42259,DS-d36f1cdc-7e9c-43c0-86fc-eedad1142d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:36111,DS-8aaa861b-76fa-4d11-b072-54969c33b06c,DISK], DatanodeInfoWithStorage[127.0.0.1:36874,DS-918006af-d231-41da-acd8-4174efe9370c,DISK], DatanodeInfoWithStorage[127.0.0.1:36124,DS-5c2671ea-b68d-40f2-be7d-da4f7c51ebd5,DISK], DatanodeInfoWithStorage[127.0.0.1:45971,DS-6c374bad-8ddf-45c0-b47c-bcfbcc053503,DISK], DatanodeInfoWithStorage[127.0.0.1:45801,DS-129a6622-61a7-48b0-b91b-eb2ee536b5f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-457698154-172.17.0.15-1597481924550:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35647,DS-d5bfa360-bc6f-4c3b-adc5-96dcfb71f63d,DISK], DatanodeInfoWithStorage[127.0.0.1:34324,DS-47ad19d8-a752-4e83-b09f-5967164782cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39370,DS-2c132479-051c-4c17-a80c-2c2a82566e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:33708,DS-dc3afd73-1a45-4bb9-8c7e-9aeb47813151,DISK], DatanodeInfoWithStorage[127.0.0.1:37539,DS-d7a9c845-169b-4c0c-95b4-8e5b4c1c6949,DISK], DatanodeInfoWithStorage[127.0.0.1:45739,DS-8aff75a3-2904-45a4-817f-70625840c70b,DISK], DatanodeInfoWithStorage[127.0.0.1:34894,DS-3ddfa470-1be5-40dd-a9f0-98ed24ce3547,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-9f5e365c-ff31-41d3-a293-b12437ec46df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-457698154-172.17.0.15-1597481924550:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35647,DS-d5bfa360-bc6f-4c3b-adc5-96dcfb71f63d,DISK], DatanodeInfoWithStorage[127.0.0.1:34324,DS-47ad19d8-a752-4e83-b09f-5967164782cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39370,DS-2c132479-051c-4c17-a80c-2c2a82566e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:33708,DS-dc3afd73-1a45-4bb9-8c7e-9aeb47813151,DISK], DatanodeInfoWithStorage[127.0.0.1:37539,DS-d7a9c845-169b-4c0c-95b4-8e5b4c1c6949,DISK], DatanodeInfoWithStorage[127.0.0.1:45739,DS-8aff75a3-2904-45a4-817f-70625840c70b,DISK], DatanodeInfoWithStorage[127.0.0.1:34894,DS-3ddfa470-1be5-40dd-a9f0-98ed24ce3547,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-9f5e365c-ff31-41d3-a293-b12437ec46df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1501012347-172.17.0.15-1597481962029:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43716,DS-8785f20e-2e97-4229-82bb-621a79eb4896,DISK], DatanodeInfoWithStorage[127.0.0.1:34064,DS-1328d9d6-c681-4363-ad3c-57a7fdcc064b,DISK], DatanodeInfoWithStorage[127.0.0.1:43161,DS-1ac15493-9a8c-4052-8fde-8d805f7451e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46048,DS-eb5727a1-b2c2-4fab-8628-3ae8e8df52c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42398,DS-947f30ed-3a9c-41a1-888a-e06ed0a08c85,DISK], DatanodeInfoWithStorage[127.0.0.1:33032,DS-fbff8c8b-f35b-4fce-a5eb-c73fbe957aca,DISK], DatanodeInfoWithStorage[127.0.0.1:33845,DS-86286250-0e14-458b-b95e-b7219f3ced4a,DISK], DatanodeInfoWithStorage[127.0.0.1:39442,DS-bbfd90b7-9945-46ee-9973-2b4023a36173,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1501012347-172.17.0.15-1597481962029:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43716,DS-8785f20e-2e97-4229-82bb-621a79eb4896,DISK], DatanodeInfoWithStorage[127.0.0.1:34064,DS-1328d9d6-c681-4363-ad3c-57a7fdcc064b,DISK], DatanodeInfoWithStorage[127.0.0.1:43161,DS-1ac15493-9a8c-4052-8fde-8d805f7451e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46048,DS-eb5727a1-b2c2-4fab-8628-3ae8e8df52c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42398,DS-947f30ed-3a9c-41a1-888a-e06ed0a08c85,DISK], DatanodeInfoWithStorage[127.0.0.1:33032,DS-fbff8c8b-f35b-4fce-a5eb-c73fbe957aca,DISK], DatanodeInfoWithStorage[127.0.0.1:33845,DS-86286250-0e14-458b-b95e-b7219f3ced4a,DISK], DatanodeInfoWithStorage[127.0.0.1:39442,DS-bbfd90b7-9945-46ee-9973-2b4023a36173,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5436
