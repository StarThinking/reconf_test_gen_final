reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1877097936-172.17.0.6-1597347288770:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34748,DS-774bbe7f-ed5d-45d0-b440-cc4a74d63685,DISK], DatanodeInfoWithStorage[127.0.0.1:37642,DS-460b748c-e922-4a12-874b-7121f59bacad,DISK], DatanodeInfoWithStorage[127.0.0.1:45367,DS-936e60ba-2587-4938-823d-03b01b14d8c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33421,DS-e6fb1453-2eb1-4fcf-9331-0dbf52f5fbc6,DISK], DatanodeInfoWithStorage[127.0.0.1:39134,DS-5a4c6001-13f2-4975-b760-9442fc1d1dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:46305,DS-093deb9d-c3aa-42e4-81f5-519ea826d438,DISK], DatanodeInfoWithStorage[127.0.0.1:43816,DS-a5035c98-1561-4c7b-868b-91b77464bb94,DISK], DatanodeInfoWithStorage[127.0.0.1:40613,DS-c90d8033-5888-4756-bf3a-2e5aeb009700,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1877097936-172.17.0.6-1597347288770:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34748,DS-774bbe7f-ed5d-45d0-b440-cc4a74d63685,DISK], DatanodeInfoWithStorage[127.0.0.1:37642,DS-460b748c-e922-4a12-874b-7121f59bacad,DISK], DatanodeInfoWithStorage[127.0.0.1:45367,DS-936e60ba-2587-4938-823d-03b01b14d8c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33421,DS-e6fb1453-2eb1-4fcf-9331-0dbf52f5fbc6,DISK], DatanodeInfoWithStorage[127.0.0.1:39134,DS-5a4c6001-13f2-4975-b760-9442fc1d1dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:46305,DS-093deb9d-c3aa-42e4-81f5-519ea826d438,DISK], DatanodeInfoWithStorage[127.0.0.1:43816,DS-a5035c98-1561-4c7b-868b-91b77464bb94,DISK], DatanodeInfoWithStorage[127.0.0.1:40613,DS-c90d8033-5888-4756-bf3a-2e5aeb009700,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1093590668-172.17.0.6-1597347951590:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35188,DS-ad4f5ff2-0bd8-4938-8187-01f01beb1d33,DISK], DatanodeInfoWithStorage[127.0.0.1:44379,DS-70db2b0a-fca1-44ac-8177-092cbeee1e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:39938,DS-9e4f1df1-3612-4a68-b73b-11d414a883db,DISK], DatanodeInfoWithStorage[127.0.0.1:39745,DS-9b010d94-10f8-40d1-82df-70819019f8b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38453,DS-0e657e5b-5a75-45b2-87d6-d7898f5e02f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-3be5afae-cce8-4db1-b1ad-bc8aec929032,DISK], DatanodeInfoWithStorage[127.0.0.1:37818,DS-d4d5f462-c3ce-419d-8fd4-b44e06e07ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:33113,DS-a9d710e3-f6ed-4f48-86c9-8304fba3b26e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1093590668-172.17.0.6-1597347951590:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35188,DS-ad4f5ff2-0bd8-4938-8187-01f01beb1d33,DISK], DatanodeInfoWithStorage[127.0.0.1:44379,DS-70db2b0a-fca1-44ac-8177-092cbeee1e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:39938,DS-9e4f1df1-3612-4a68-b73b-11d414a883db,DISK], DatanodeInfoWithStorage[127.0.0.1:39745,DS-9b010d94-10f8-40d1-82df-70819019f8b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38453,DS-0e657e5b-5a75-45b2-87d6-d7898f5e02f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-3be5afae-cce8-4db1-b1ad-bc8aec929032,DISK], DatanodeInfoWithStorage[127.0.0.1:37818,DS-d4d5f462-c3ce-419d-8fd4-b44e06e07ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:33113,DS-a9d710e3-f6ed-4f48-86c9-8304fba3b26e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-676445358-172.17.0.6-1597348488405:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37452,DS-9e81bed6-6d19-4d0e-ac86-1e797cc2d961,DISK], DatanodeInfoWithStorage[127.0.0.1:38417,DS-87f48175-4d5b-406f-8579-0377ba4f9193,DISK], DatanodeInfoWithStorage[127.0.0.1:42098,DS-65c17759-cd2c-4ef7-8b9e-b60397de00a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44519,DS-d509e5c8-4321-4036-92ca-f8e8e4a78565,DISK], DatanodeInfoWithStorage[127.0.0.1:35296,DS-23af7490-42fc-440d-85b2-83bc60b47e94,DISK], DatanodeInfoWithStorage[127.0.0.1:40724,DS-3bab5559-0184-415b-858e-f66634bdad9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37543,DS-edb9e4ba-a16b-4548-b66c-01719f96c17a,DISK], DatanodeInfoWithStorage[127.0.0.1:45307,DS-efd9bfca-a433-4e91-acb3-6091d5bf78f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-676445358-172.17.0.6-1597348488405:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37452,DS-9e81bed6-6d19-4d0e-ac86-1e797cc2d961,DISK], DatanodeInfoWithStorage[127.0.0.1:38417,DS-87f48175-4d5b-406f-8579-0377ba4f9193,DISK], DatanodeInfoWithStorage[127.0.0.1:42098,DS-65c17759-cd2c-4ef7-8b9e-b60397de00a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44519,DS-d509e5c8-4321-4036-92ca-f8e8e4a78565,DISK], DatanodeInfoWithStorage[127.0.0.1:35296,DS-23af7490-42fc-440d-85b2-83bc60b47e94,DISK], DatanodeInfoWithStorage[127.0.0.1:40724,DS-3bab5559-0184-415b-858e-f66634bdad9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37543,DS-edb9e4ba-a16b-4548-b66c-01719f96c17a,DISK], DatanodeInfoWithStorage[127.0.0.1:45307,DS-efd9bfca-a433-4e91-acb3-6091d5bf78f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1072294521-172.17.0.6-1597348718257:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32904,DS-31d22822-9a02-4464-80a2-97dc0e281c25,DISK], DatanodeInfoWithStorage[127.0.0.1:37671,DS-ef05495a-609d-49a7-9e50-414c00effddf,DISK], DatanodeInfoWithStorage[127.0.0.1:40825,DS-7525aad5-1e53-413e-bf9e-a446f0522595,DISK], DatanodeInfoWithStorage[127.0.0.1:34811,DS-5cdb4fbf-10f2-4a72-8292-e004458638a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33922,DS-8825fb3f-110d-4026-b104-044dffbedd10,DISK], DatanodeInfoWithStorage[127.0.0.1:46409,DS-86aca93a-2b02-4c44-8883-c3e70a5f5f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45505,DS-f18bf4fe-616b-4efe-ba5d-b1cb1303a296,DISK], DatanodeInfoWithStorage[127.0.0.1:40027,DS-aa17c8f2-fe70-4917-bcf1-43a963b90838,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1072294521-172.17.0.6-1597348718257:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32904,DS-31d22822-9a02-4464-80a2-97dc0e281c25,DISK], DatanodeInfoWithStorage[127.0.0.1:37671,DS-ef05495a-609d-49a7-9e50-414c00effddf,DISK], DatanodeInfoWithStorage[127.0.0.1:40825,DS-7525aad5-1e53-413e-bf9e-a446f0522595,DISK], DatanodeInfoWithStorage[127.0.0.1:34811,DS-5cdb4fbf-10f2-4a72-8292-e004458638a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33922,DS-8825fb3f-110d-4026-b104-044dffbedd10,DISK], DatanodeInfoWithStorage[127.0.0.1:46409,DS-86aca93a-2b02-4c44-8883-c3e70a5f5f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45505,DS-f18bf4fe-616b-4efe-ba5d-b1cb1303a296,DISK], DatanodeInfoWithStorage[127.0.0.1:40027,DS-aa17c8f2-fe70-4917-bcf1-43a963b90838,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-257464001-172.17.0.6-1597348814650:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38160,DS-2c53d111-3f2e-4480-840f-6f137d0cfbf6,DISK], DatanodeInfoWithStorage[127.0.0.1:43921,DS-e993912f-75c0-4fe0-9464-6b5828844c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:40979,DS-ce755cb4-17ea-4ab4-b8c1-bf3ce202d603,DISK], DatanodeInfoWithStorage[127.0.0.1:41665,DS-13512d6e-b154-4328-9235-c6a132e08155,DISK], DatanodeInfoWithStorage[127.0.0.1:41066,DS-6b705c0f-6854-434d-aab1-444503456f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:44251,DS-a8c18c1d-eec6-4052-8ea1-4d130844b3cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43105,DS-3e40f967-7ac8-4930-b462-fe251f84a427,DISK], DatanodeInfoWithStorage[127.0.0.1:37326,DS-1dcadd6f-a589-47cf-9c71-f61ab96c42b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-257464001-172.17.0.6-1597348814650:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38160,DS-2c53d111-3f2e-4480-840f-6f137d0cfbf6,DISK], DatanodeInfoWithStorage[127.0.0.1:43921,DS-e993912f-75c0-4fe0-9464-6b5828844c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:40979,DS-ce755cb4-17ea-4ab4-b8c1-bf3ce202d603,DISK], DatanodeInfoWithStorage[127.0.0.1:41665,DS-13512d6e-b154-4328-9235-c6a132e08155,DISK], DatanodeInfoWithStorage[127.0.0.1:41066,DS-6b705c0f-6854-434d-aab1-444503456f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:44251,DS-a8c18c1d-eec6-4052-8ea1-4d130844b3cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43105,DS-3e40f967-7ac8-4930-b462-fe251f84a427,DISK], DatanodeInfoWithStorage[127.0.0.1:37326,DS-1dcadd6f-a589-47cf-9c71-f61ab96c42b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1919995647-172.17.0.6-1597349060233:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39423,DS-02f1b6a1-0909-4346-b613-c14294fb7fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:40798,DS-1a028f6d-a4f5-4bdc-8924-f79c2ffd77b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43898,DS-fb5a537b-a18c-4ef0-bc8e-9467676a0e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41973,DS-29c847a5-99f7-44a1-bc2a-581493afc1d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44656,DS-f18933b5-2c64-4ff7-a770-1db30f5c852f,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-4a6150b2-ae2d-4b11-98e0-ad82106b9563,DISK], DatanodeInfoWithStorage[127.0.0.1:37993,DS-e87aa798-8fc1-421c-a1f3-5867c9b81c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45641,DS-645caf00-f5a7-41ea-ae7d-92b1fc049068,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1919995647-172.17.0.6-1597349060233:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39423,DS-02f1b6a1-0909-4346-b613-c14294fb7fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:40798,DS-1a028f6d-a4f5-4bdc-8924-f79c2ffd77b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43898,DS-fb5a537b-a18c-4ef0-bc8e-9467676a0e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41973,DS-29c847a5-99f7-44a1-bc2a-581493afc1d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44656,DS-f18933b5-2c64-4ff7-a770-1db30f5c852f,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-4a6150b2-ae2d-4b11-98e0-ad82106b9563,DISK], DatanodeInfoWithStorage[127.0.0.1:37993,DS-e87aa798-8fc1-421c-a1f3-5867c9b81c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45641,DS-645caf00-f5a7-41ea-ae7d-92b1fc049068,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1101535965-172.17.0.6-1597349342644:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44080,DS-d9dc9829-7567-4064-bbda-9e6f35d5d424,DISK], DatanodeInfoWithStorage[127.0.0.1:46031,DS-6d1b4bda-342c-46e1-a934-2571afb33d27,DISK], DatanodeInfoWithStorage[127.0.0.1:40726,DS-742138d3-0142-4029-b14a-b41f87d89339,DISK], DatanodeInfoWithStorage[127.0.0.1:33041,DS-7560b68f-573a-4e41-b2ef-5555aaaaec74,DISK], DatanodeInfoWithStorage[127.0.0.1:36554,DS-a2622c8d-7b4f-4157-8830-5946552e2bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:35956,DS-e83110c5-02cf-45fc-9ee5-afc9ed173827,DISK], DatanodeInfoWithStorage[127.0.0.1:37379,DS-ee01c055-5220-46c9-8c65-a10a66147f12,DISK], DatanodeInfoWithStorage[127.0.0.1:39811,DS-eff81c7d-0900-410d-ba7f-f447e017e57a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1101535965-172.17.0.6-1597349342644:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44080,DS-d9dc9829-7567-4064-bbda-9e6f35d5d424,DISK], DatanodeInfoWithStorage[127.0.0.1:46031,DS-6d1b4bda-342c-46e1-a934-2571afb33d27,DISK], DatanodeInfoWithStorage[127.0.0.1:40726,DS-742138d3-0142-4029-b14a-b41f87d89339,DISK], DatanodeInfoWithStorage[127.0.0.1:33041,DS-7560b68f-573a-4e41-b2ef-5555aaaaec74,DISK], DatanodeInfoWithStorage[127.0.0.1:36554,DS-a2622c8d-7b4f-4157-8830-5946552e2bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:35956,DS-e83110c5-02cf-45fc-9ee5-afc9ed173827,DISK], DatanodeInfoWithStorage[127.0.0.1:37379,DS-ee01c055-5220-46c9-8c65-a10a66147f12,DISK], DatanodeInfoWithStorage[127.0.0.1:39811,DS-eff81c7d-0900-410d-ba7f-f447e017e57a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1305546695-172.17.0.6-1597349645368:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33319,DS-415e6ff1-a7ce-465a-8b64-7743a948b1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38220,DS-faee02f5-6dbc-4648-9363-710e5bb67ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:43037,DS-a5e911ae-17a5-40e2-9a9b-92ab44cbcb14,DISK], DatanodeInfoWithStorage[127.0.0.1:39636,DS-5cdbf130-872a-4aa5-bd61-264f23fb2e30,DISK], DatanodeInfoWithStorage[127.0.0.1:41387,DS-d8f25d86-d061-491d-865d-9ffd61b9a1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42299,DS-24b64d69-bf50-45ad-bdf4-0738682604fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41837,DS-a487843c-17cf-4027-a406-7e6cfd314755,DISK], DatanodeInfoWithStorage[127.0.0.1:44127,DS-958fe2a4-4a92-4c9b-889c-177ab19647ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1305546695-172.17.0.6-1597349645368:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33319,DS-415e6ff1-a7ce-465a-8b64-7743a948b1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38220,DS-faee02f5-6dbc-4648-9363-710e5bb67ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:43037,DS-a5e911ae-17a5-40e2-9a9b-92ab44cbcb14,DISK], DatanodeInfoWithStorage[127.0.0.1:39636,DS-5cdbf130-872a-4aa5-bd61-264f23fb2e30,DISK], DatanodeInfoWithStorage[127.0.0.1:41387,DS-d8f25d86-d061-491d-865d-9ffd61b9a1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42299,DS-24b64d69-bf50-45ad-bdf4-0738682604fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41837,DS-a487843c-17cf-4027-a406-7e6cfd314755,DISK], DatanodeInfoWithStorage[127.0.0.1:44127,DS-958fe2a4-4a92-4c9b-889c-177ab19647ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-173808509-172.17.0.6-1597349735150:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34092,DS-46afe1d1-5d83-4305-b702-f6fefd7b4af4,DISK], DatanodeInfoWithStorage[127.0.0.1:39039,DS-6479f42a-dbc9-4d66-bbf7-2ff3eea4958f,DISK], DatanodeInfoWithStorage[127.0.0.1:42236,DS-f41ba50e-7c30-4450-937f-a8d12efd1b18,DISK], DatanodeInfoWithStorage[127.0.0.1:37964,DS-1e836d28-f590-4e77-bae5-631d06050762,DISK], DatanodeInfoWithStorage[127.0.0.1:35134,DS-0ed92a19-06ef-4411-951a-a191f726db8c,DISK], DatanodeInfoWithStorage[127.0.0.1:33630,DS-0b42ec04-a1da-461c-8d34-723a9d85c17e,DISK], DatanodeInfoWithStorage[127.0.0.1:35832,DS-06790266-4a50-4f00-bdd8-b8da457b3850,DISK], DatanodeInfoWithStorage[127.0.0.1:46231,DS-af1ac761-a5eb-4ccc-8a3a-f040665e308a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-173808509-172.17.0.6-1597349735150:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34092,DS-46afe1d1-5d83-4305-b702-f6fefd7b4af4,DISK], DatanodeInfoWithStorage[127.0.0.1:39039,DS-6479f42a-dbc9-4d66-bbf7-2ff3eea4958f,DISK], DatanodeInfoWithStorage[127.0.0.1:42236,DS-f41ba50e-7c30-4450-937f-a8d12efd1b18,DISK], DatanodeInfoWithStorage[127.0.0.1:37964,DS-1e836d28-f590-4e77-bae5-631d06050762,DISK], DatanodeInfoWithStorage[127.0.0.1:35134,DS-0ed92a19-06ef-4411-951a-a191f726db8c,DISK], DatanodeInfoWithStorage[127.0.0.1:33630,DS-0b42ec04-a1da-461c-8d34-723a9d85c17e,DISK], DatanodeInfoWithStorage[127.0.0.1:35832,DS-06790266-4a50-4f00-bdd8-b8da457b3850,DISK], DatanodeInfoWithStorage[127.0.0.1:46231,DS-af1ac761-a5eb-4ccc-8a3a-f040665e308a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2015463872-172.17.0.6-1597349928207:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34988,DS-b1566df0-ff46-4c04-8f86-67d4a55504d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38352,DS-7a1b188d-f579-43b1-90a7-ba7dc827da6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45173,DS-b15a5ae2-e1e2-4f79-a851-bec27a68750a,DISK], DatanodeInfoWithStorage[127.0.0.1:36983,DS-b93645bb-a488-4a3e-b98b-f176b04d1e23,DISK], DatanodeInfoWithStorage[127.0.0.1:45362,DS-db2195da-7010-433d-b2b6-2e59ba3a6593,DISK], DatanodeInfoWithStorage[127.0.0.1:37047,DS-535e42ad-44d7-445b-ab4f-840cb4473591,DISK], DatanodeInfoWithStorage[127.0.0.1:33539,DS-3d53e954-d79d-4b8b-bc70-326f04833ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:46722,DS-94e3afa8-c7ae-4a24-b39b-148e16af8670,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2015463872-172.17.0.6-1597349928207:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34988,DS-b1566df0-ff46-4c04-8f86-67d4a55504d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38352,DS-7a1b188d-f579-43b1-90a7-ba7dc827da6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45173,DS-b15a5ae2-e1e2-4f79-a851-bec27a68750a,DISK], DatanodeInfoWithStorage[127.0.0.1:36983,DS-b93645bb-a488-4a3e-b98b-f176b04d1e23,DISK], DatanodeInfoWithStorage[127.0.0.1:45362,DS-db2195da-7010-433d-b2b6-2e59ba3a6593,DISK], DatanodeInfoWithStorage[127.0.0.1:37047,DS-535e42ad-44d7-445b-ab4f-840cb4473591,DISK], DatanodeInfoWithStorage[127.0.0.1:33539,DS-3d53e954-d79d-4b8b-bc70-326f04833ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:46722,DS-94e3afa8-c7ae-4a24-b39b-148e16af8670,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1883365163-172.17.0.6-1597350486511:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39952,DS-adb0277b-e02f-4ab8-8915-1d2a3190665e,DISK], DatanodeInfoWithStorage[127.0.0.1:33652,DS-2af3056c-99ce-45bf-b0c6-eb7134998a31,DISK], DatanodeInfoWithStorage[127.0.0.1:41942,DS-17c57155-c6af-4e87-8d48-038a54b4c9de,DISK], DatanodeInfoWithStorage[127.0.0.1:34543,DS-14f6a0b2-5676-493e-96bf-1a4a884dec53,DISK], DatanodeInfoWithStorage[127.0.0.1:43856,DS-f56658be-4b4b-4a7b-bb2d-fe0076f0f1f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34160,DS-322bfb07-8c78-4bf5-b023-7f139e736625,DISK], DatanodeInfoWithStorage[127.0.0.1:37078,DS-607423cc-e9b7-4193-a9ae-abd952a1f326,DISK], DatanodeInfoWithStorage[127.0.0.1:39582,DS-eff155ce-86ee-46d2-aa77-ccf306cf3f59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1883365163-172.17.0.6-1597350486511:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39952,DS-adb0277b-e02f-4ab8-8915-1d2a3190665e,DISK], DatanodeInfoWithStorage[127.0.0.1:33652,DS-2af3056c-99ce-45bf-b0c6-eb7134998a31,DISK], DatanodeInfoWithStorage[127.0.0.1:41942,DS-17c57155-c6af-4e87-8d48-038a54b4c9de,DISK], DatanodeInfoWithStorage[127.0.0.1:34543,DS-14f6a0b2-5676-493e-96bf-1a4a884dec53,DISK], DatanodeInfoWithStorage[127.0.0.1:43856,DS-f56658be-4b4b-4a7b-bb2d-fe0076f0f1f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34160,DS-322bfb07-8c78-4bf5-b023-7f139e736625,DISK], DatanodeInfoWithStorage[127.0.0.1:37078,DS-607423cc-e9b7-4193-a9ae-abd952a1f326,DISK], DatanodeInfoWithStorage[127.0.0.1:39582,DS-eff155ce-86ee-46d2-aa77-ccf306cf3f59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-598526329-172.17.0.6-1597351516152:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37458,DS-3978db85-553d-47c2-b51d-9e3da72a76f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37760,DS-b658fda7-1efb-43c3-97a8-fa932e78eab0,DISK], DatanodeInfoWithStorage[127.0.0.1:39759,DS-9ebc2e21-1ed0-451c-b566-e585f53aff91,DISK], DatanodeInfoWithStorage[127.0.0.1:39158,DS-7b328b54-ff8e-4e45-819b-197d2581655a,DISK], DatanodeInfoWithStorage[127.0.0.1:35801,DS-28973c71-767a-4ff0-919c-39c14fc8ae55,DISK], DatanodeInfoWithStorage[127.0.0.1:34991,DS-ee159fb1-4587-4ccf-afc0-2af389bb76cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41656,DS-7c3d3af5-c575-49f9-a4d8-2b243f9c2643,DISK], DatanodeInfoWithStorage[127.0.0.1:42911,DS-e88484a3-9451-4f1b-901b-83208c75ff14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-598526329-172.17.0.6-1597351516152:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37458,DS-3978db85-553d-47c2-b51d-9e3da72a76f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37760,DS-b658fda7-1efb-43c3-97a8-fa932e78eab0,DISK], DatanodeInfoWithStorage[127.0.0.1:39759,DS-9ebc2e21-1ed0-451c-b566-e585f53aff91,DISK], DatanodeInfoWithStorage[127.0.0.1:39158,DS-7b328b54-ff8e-4e45-819b-197d2581655a,DISK], DatanodeInfoWithStorage[127.0.0.1:35801,DS-28973c71-767a-4ff0-919c-39c14fc8ae55,DISK], DatanodeInfoWithStorage[127.0.0.1:34991,DS-ee159fb1-4587-4ccf-afc0-2af389bb76cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41656,DS-7c3d3af5-c575-49f9-a4d8-2b243f9c2643,DISK], DatanodeInfoWithStorage[127.0.0.1:42911,DS-e88484a3-9451-4f1b-901b-83208c75ff14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-669855066-172.17.0.6-1597351741583:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35303,DS-f69e4648-dfbe-4e06-a6eb-bd9ed3e129e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38711,DS-fc8ffc30-26d4-4992-b59b-38ab81195d63,DISK], DatanodeInfoWithStorage[127.0.0.1:41593,DS-a1610291-8f92-439a-bf3e-919bd0c94420,DISK], DatanodeInfoWithStorage[127.0.0.1:36683,DS-aa0bc316-2c5b-4859-8077-3b239316ca97,DISK], DatanodeInfoWithStorage[127.0.0.1:42802,DS-b4006971-af11-467d-8e3d-8ebcdd7e5437,DISK], DatanodeInfoWithStorage[127.0.0.1:38391,DS-7158adb0-8ac6-47fb-8176-55856cde560d,DISK], DatanodeInfoWithStorage[127.0.0.1:36545,DS-76410881-7cac-4d3e-9ff6-c6df4d8cba97,DISK], DatanodeInfoWithStorage[127.0.0.1:44407,DS-b6acae7f-0025-49cc-9128-f5c904700175,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-669855066-172.17.0.6-1597351741583:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35303,DS-f69e4648-dfbe-4e06-a6eb-bd9ed3e129e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38711,DS-fc8ffc30-26d4-4992-b59b-38ab81195d63,DISK], DatanodeInfoWithStorage[127.0.0.1:41593,DS-a1610291-8f92-439a-bf3e-919bd0c94420,DISK], DatanodeInfoWithStorage[127.0.0.1:36683,DS-aa0bc316-2c5b-4859-8077-3b239316ca97,DISK], DatanodeInfoWithStorage[127.0.0.1:42802,DS-b4006971-af11-467d-8e3d-8ebcdd7e5437,DISK], DatanodeInfoWithStorage[127.0.0.1:38391,DS-7158adb0-8ac6-47fb-8176-55856cde560d,DISK], DatanodeInfoWithStorage[127.0.0.1:36545,DS-76410881-7cac-4d3e-9ff6-c6df4d8cba97,DISK], DatanodeInfoWithStorage[127.0.0.1:44407,DS-b6acae7f-0025-49cc-9128-f5c904700175,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1587775705-172.17.0.6-1597352975387:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45852,DS-bcda93d3-621e-417a-b827-d6b655196d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:44042,DS-87f071c4-7a6e-4d3e-b59d-7dbbdf5d0767,DISK], DatanodeInfoWithStorage[127.0.0.1:44369,DS-c4f7750c-b0f5-434a-b799-9d7c1fd9dc45,DISK], DatanodeInfoWithStorage[127.0.0.1:41940,DS-8c7fbcaa-0f4b-4bcf-bce7-f12cfb3911ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34320,DS-b7bf9287-5034-482d-a913-6c01f2fb49de,DISK], DatanodeInfoWithStorage[127.0.0.1:42176,DS-83c69ec4-6e95-4a73-9b98-b1546e47a92c,DISK], DatanodeInfoWithStorage[127.0.0.1:33727,DS-bafaf690-e956-4c77-816b-72feabc3f7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39740,DS-57313155-a09b-4537-9046-b5e23908e998,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1587775705-172.17.0.6-1597352975387:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45852,DS-bcda93d3-621e-417a-b827-d6b655196d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:44042,DS-87f071c4-7a6e-4d3e-b59d-7dbbdf5d0767,DISK], DatanodeInfoWithStorage[127.0.0.1:44369,DS-c4f7750c-b0f5-434a-b799-9d7c1fd9dc45,DISK], DatanodeInfoWithStorage[127.0.0.1:41940,DS-8c7fbcaa-0f4b-4bcf-bce7-f12cfb3911ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34320,DS-b7bf9287-5034-482d-a913-6c01f2fb49de,DISK], DatanodeInfoWithStorage[127.0.0.1:42176,DS-83c69ec4-6e95-4a73-9b98-b1546e47a92c,DISK], DatanodeInfoWithStorage[127.0.0.1:33727,DS-bafaf690-e956-4c77-816b-72feabc3f7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39740,DS-57313155-a09b-4537-9046-b5e23908e998,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-817349624-172.17.0.6-1597353061112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43742,DS-a6a042b1-71d3-4740-b387-1c74dbfaec79,DISK], DatanodeInfoWithStorage[127.0.0.1:33195,DS-928d5d7d-c219-4820-88d1-fab8e055ce35,DISK], DatanodeInfoWithStorage[127.0.0.1:33126,DS-d71562f5-1ca8-4090-8209-c803b242d7e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44942,DS-a9f89269-9b3c-40e6-9bd0-4870e179eb8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38743,DS-2a5b24f7-13de-40a1-a745-e4855f7a3bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:35175,DS-e89492db-e76f-480e-bf48-9bcb0c3fc657,DISK], DatanodeInfoWithStorage[127.0.0.1:36464,DS-123addb5-27a5-4964-a1cf-0faa045bc8a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35528,DS-39ea0ce7-841b-45c7-8dbc-09b166852b83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-817349624-172.17.0.6-1597353061112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43742,DS-a6a042b1-71d3-4740-b387-1c74dbfaec79,DISK], DatanodeInfoWithStorage[127.0.0.1:33195,DS-928d5d7d-c219-4820-88d1-fab8e055ce35,DISK], DatanodeInfoWithStorage[127.0.0.1:33126,DS-d71562f5-1ca8-4090-8209-c803b242d7e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44942,DS-a9f89269-9b3c-40e6-9bd0-4870e179eb8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38743,DS-2a5b24f7-13de-40a1-a745-e4855f7a3bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:35175,DS-e89492db-e76f-480e-bf48-9bcb0c3fc657,DISK], DatanodeInfoWithStorage[127.0.0.1:36464,DS-123addb5-27a5-4964-a1cf-0faa045bc8a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35528,DS-39ea0ce7-841b-45c7-8dbc-09b166852b83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1436467860-172.17.0.6-1597353606004:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37022,DS-43c36bbb-da01-4d08-96b2-14ee63018c38,DISK], DatanodeInfoWithStorage[127.0.0.1:40048,DS-0d574650-ece5-4cb2-b8d6-39e1cee67103,DISK], DatanodeInfoWithStorage[127.0.0.1:33493,DS-1e70598d-c6a4-430b-b6ab-a3f1549ed75e,DISK], DatanodeInfoWithStorage[127.0.0.1:44871,DS-2e0f440f-99ae-48e4-8535-a2a2c6da24f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33902,DS-6071dc4e-1c6d-4073-9020-b4645522ccd9,DISK], DatanodeInfoWithStorage[127.0.0.1:45501,DS-95fba4e3-d883-4948-b7e0-3daf1c2c3ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:40525,DS-9f4a9915-55b2-45de-a57e-26940bc0f4e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35595,DS-bde58ee9-2d7c-439b-a75f-ed9de2baec65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1436467860-172.17.0.6-1597353606004:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37022,DS-43c36bbb-da01-4d08-96b2-14ee63018c38,DISK], DatanodeInfoWithStorage[127.0.0.1:40048,DS-0d574650-ece5-4cb2-b8d6-39e1cee67103,DISK], DatanodeInfoWithStorage[127.0.0.1:33493,DS-1e70598d-c6a4-430b-b6ab-a3f1549ed75e,DISK], DatanodeInfoWithStorage[127.0.0.1:44871,DS-2e0f440f-99ae-48e4-8535-a2a2c6da24f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33902,DS-6071dc4e-1c6d-4073-9020-b4645522ccd9,DISK], DatanodeInfoWithStorage[127.0.0.1:45501,DS-95fba4e3-d883-4948-b7e0-3daf1c2c3ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:40525,DS-9f4a9915-55b2-45de-a57e-26940bc0f4e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35595,DS-bde58ee9-2d7c-439b-a75f-ed9de2baec65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1038705857-172.17.0.6-1597353883897:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39950,DS-4e04f691-6059-42ec-adf2-4c2a5f372b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:34633,DS-3ae37c9e-8f8e-4aca-bf05-de0c0437ce08,DISK], DatanodeInfoWithStorage[127.0.0.1:42758,DS-e1a076a1-b1f7-45ad-b767-878910022743,DISK], DatanodeInfoWithStorage[127.0.0.1:38344,DS-77e755e2-2d48-46bb-b000-7c2e8c3fab38,DISK], DatanodeInfoWithStorage[127.0.0.1:35229,DS-7c814325-710d-4142-a941-7ec8444fc1f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34142,DS-f223eede-7ce7-4189-b51b-166c9a59b7fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39128,DS-2183c094-1f1a-4fc7-9710-6980c3734b64,DISK], DatanodeInfoWithStorage[127.0.0.1:44789,DS-dce03196-0a97-4a1a-be3a-a2d2d20591e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1038705857-172.17.0.6-1597353883897:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39950,DS-4e04f691-6059-42ec-adf2-4c2a5f372b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:34633,DS-3ae37c9e-8f8e-4aca-bf05-de0c0437ce08,DISK], DatanodeInfoWithStorage[127.0.0.1:42758,DS-e1a076a1-b1f7-45ad-b767-878910022743,DISK], DatanodeInfoWithStorage[127.0.0.1:38344,DS-77e755e2-2d48-46bb-b000-7c2e8c3fab38,DISK], DatanodeInfoWithStorage[127.0.0.1:35229,DS-7c814325-710d-4142-a941-7ec8444fc1f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34142,DS-f223eede-7ce7-4189-b51b-166c9a59b7fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39128,DS-2183c094-1f1a-4fc7-9710-6980c3734b64,DISK], DatanodeInfoWithStorage[127.0.0.1:44789,DS-dce03196-0a97-4a1a-be3a-a2d2d20591e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 6918
