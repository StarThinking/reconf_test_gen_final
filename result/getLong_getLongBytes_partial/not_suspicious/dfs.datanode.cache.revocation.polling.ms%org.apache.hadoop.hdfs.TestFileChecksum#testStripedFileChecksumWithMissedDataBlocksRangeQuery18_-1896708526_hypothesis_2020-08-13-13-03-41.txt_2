reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2048893595-172.17.0.16-1597324478675:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34243,DS-fa62f236-5f24-4b7a-b882-c256ed91ccec,DISK], DatanodeInfoWithStorage[127.0.0.1:34518,DS-465af03e-1fc4-4101-85fe-1db00571a1f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41134,DS-7c6d1adb-1d84-4af2-9707-8d25ab3ba554,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-02de9939-4c6d-4e24-953c-4e89d4ff7076,DISK], DatanodeInfoWithStorage[127.0.0.1:43566,DS-cca5045b-04af-4bb9-85de-eb8a5363b9b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41603,DS-1a2ae5d8-3103-42a6-b230-52775ced3691,DISK], DatanodeInfoWithStorage[127.0.0.1:40253,DS-74d7307c-e720-4b2b-9fbe-492c13d18a82,DISK], DatanodeInfoWithStorage[127.0.0.1:40212,DS-357a41c8-5e24-4907-897e-d05c168ff001,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2048893595-172.17.0.16-1597324478675:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34243,DS-fa62f236-5f24-4b7a-b882-c256ed91ccec,DISK], DatanodeInfoWithStorage[127.0.0.1:34518,DS-465af03e-1fc4-4101-85fe-1db00571a1f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41134,DS-7c6d1adb-1d84-4af2-9707-8d25ab3ba554,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-02de9939-4c6d-4e24-953c-4e89d4ff7076,DISK], DatanodeInfoWithStorage[127.0.0.1:43566,DS-cca5045b-04af-4bb9-85de-eb8a5363b9b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41603,DS-1a2ae5d8-3103-42a6-b230-52775ced3691,DISK], DatanodeInfoWithStorage[127.0.0.1:40253,DS-74d7307c-e720-4b2b-9fbe-492c13d18a82,DISK], DatanodeInfoWithStorage[127.0.0.1:40212,DS-357a41c8-5e24-4907-897e-d05c168ff001,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-854895508-172.17.0.16-1597324820685:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36679,DS-509ce4f2-6869-4fe4-8bcf-c5faa63adba3,DISK], DatanodeInfoWithStorage[127.0.0.1:41278,DS-9f2aab64-187d-4cca-8b39-24fc448028b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39563,DS-9b990ab5-8394-469a-9654-99d7c299fc29,DISK], DatanodeInfoWithStorage[127.0.0.1:43987,DS-178025a3-a9db-4fb1-972d-e65eecc56bad,DISK], DatanodeInfoWithStorage[127.0.0.1:41853,DS-b91937fd-5f71-4854-a7a4-77ec972e2910,DISK], DatanodeInfoWithStorage[127.0.0.1:46110,DS-890299e3-1f78-4f31-bc66-40c53069e920,DISK], DatanodeInfoWithStorage[127.0.0.1:35908,DS-b58b480f-3144-4341-9b1e-943b372a38e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37871,DS-0b4ea7ff-671a-4d43-ada4-8f39c7d28825,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-854895508-172.17.0.16-1597324820685:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36679,DS-509ce4f2-6869-4fe4-8bcf-c5faa63adba3,DISK], DatanodeInfoWithStorage[127.0.0.1:41278,DS-9f2aab64-187d-4cca-8b39-24fc448028b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39563,DS-9b990ab5-8394-469a-9654-99d7c299fc29,DISK], DatanodeInfoWithStorage[127.0.0.1:43987,DS-178025a3-a9db-4fb1-972d-e65eecc56bad,DISK], DatanodeInfoWithStorage[127.0.0.1:41853,DS-b91937fd-5f71-4854-a7a4-77ec972e2910,DISK], DatanodeInfoWithStorage[127.0.0.1:46110,DS-890299e3-1f78-4f31-bc66-40c53069e920,DISK], DatanodeInfoWithStorage[127.0.0.1:35908,DS-b58b480f-3144-4341-9b1e-943b372a38e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37871,DS-0b4ea7ff-671a-4d43-ada4-8f39c7d28825,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-246092126-172.17.0.16-1597325070243:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39413,DS-40204d4f-f661-4dab-910a-551f27fcadff,DISK], DatanodeInfoWithStorage[127.0.0.1:39923,DS-e84a2572-82fd-4615-84b9-cc8b45cc9ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:40374,DS-cda95c77-e355-4c0d-9bdf-d855e8f6e180,DISK], DatanodeInfoWithStorage[127.0.0.1:39115,DS-ea0aa75e-ca1c-4b0b-91b1-e193539827bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37567,DS-f7c6d0ed-0990-4a75-9eb3-133e40b22788,DISK], DatanodeInfoWithStorage[127.0.0.1:44441,DS-9d685e6d-a09d-4043-b8d5-da8b097db7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40227,DS-acf4ad0d-922f-4cf2-9e67-e94003e5c119,DISK], DatanodeInfoWithStorage[127.0.0.1:42112,DS-2e880974-c7c9-4a32-8069-e9a00319af21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-246092126-172.17.0.16-1597325070243:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39413,DS-40204d4f-f661-4dab-910a-551f27fcadff,DISK], DatanodeInfoWithStorage[127.0.0.1:39923,DS-e84a2572-82fd-4615-84b9-cc8b45cc9ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:40374,DS-cda95c77-e355-4c0d-9bdf-d855e8f6e180,DISK], DatanodeInfoWithStorage[127.0.0.1:39115,DS-ea0aa75e-ca1c-4b0b-91b1-e193539827bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37567,DS-f7c6d0ed-0990-4a75-9eb3-133e40b22788,DISK], DatanodeInfoWithStorage[127.0.0.1:44441,DS-9d685e6d-a09d-4043-b8d5-da8b097db7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40227,DS-acf4ad0d-922f-4cf2-9e67-e94003e5c119,DISK], DatanodeInfoWithStorage[127.0.0.1:42112,DS-2e880974-c7c9-4a32-8069-e9a00319af21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-498693239-172.17.0.16-1597325920181:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34144,DS-852e4e82-377e-4705-b0d1-39d7aecc6a28,DISK], DatanodeInfoWithStorage[127.0.0.1:33305,DS-9d0349bd-d7d1-483b-a0b7-0725f71d476d,DISK], DatanodeInfoWithStorage[127.0.0.1:43693,DS-fb3c80c4-6672-4739-9f48-6359850563a7,DISK], DatanodeInfoWithStorage[127.0.0.1:32989,DS-068074dd-1943-47b9-ae0f-70dfbd0e3abc,DISK], DatanodeInfoWithStorage[127.0.0.1:34954,DS-8d3398f7-3e6c-4e94-8913-83b3e51c97f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-5f902706-6988-428c-82ae-d17015916a86,DISK], DatanodeInfoWithStorage[127.0.0.1:44400,DS-dd846fda-0897-409e-8666-53fe81e7cb75,DISK], DatanodeInfoWithStorage[127.0.0.1:46696,DS-955cc186-2231-483a-88fe-e99307164771,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-498693239-172.17.0.16-1597325920181:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34144,DS-852e4e82-377e-4705-b0d1-39d7aecc6a28,DISK], DatanodeInfoWithStorage[127.0.0.1:33305,DS-9d0349bd-d7d1-483b-a0b7-0725f71d476d,DISK], DatanodeInfoWithStorage[127.0.0.1:43693,DS-fb3c80c4-6672-4739-9f48-6359850563a7,DISK], DatanodeInfoWithStorage[127.0.0.1:32989,DS-068074dd-1943-47b9-ae0f-70dfbd0e3abc,DISK], DatanodeInfoWithStorage[127.0.0.1:34954,DS-8d3398f7-3e6c-4e94-8913-83b3e51c97f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-5f902706-6988-428c-82ae-d17015916a86,DISK], DatanodeInfoWithStorage[127.0.0.1:44400,DS-dd846fda-0897-409e-8666-53fe81e7cb75,DISK], DatanodeInfoWithStorage[127.0.0.1:46696,DS-955cc186-2231-483a-88fe-e99307164771,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-299130819-172.17.0.16-1597326055893:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34599,DS-0e215754-0695-427b-8b00-8b15266342f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42518,DS-eac5da96-0185-4d2a-8874-91a99938a07f,DISK], DatanodeInfoWithStorage[127.0.0.1:43827,DS-ab5683eb-1110-4f63-bb08-a01ec92c2bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:35314,DS-43774c93-4126-48c8-8828-f53093dd76d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46155,DS-3b334473-b17e-482b-89cf-e562cd10fac2,DISK], DatanodeInfoWithStorage[127.0.0.1:33354,DS-541a89f1-6b44-4806-8f16-6a0b501acebe,DISK], DatanodeInfoWithStorage[127.0.0.1:41044,DS-a33ec9f8-f6b2-43ba-be60-6a71fa1419e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34576,DS-9cc3ac16-a624-4839-9348-9ab80ba269ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-299130819-172.17.0.16-1597326055893:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34599,DS-0e215754-0695-427b-8b00-8b15266342f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42518,DS-eac5da96-0185-4d2a-8874-91a99938a07f,DISK], DatanodeInfoWithStorage[127.0.0.1:43827,DS-ab5683eb-1110-4f63-bb08-a01ec92c2bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:35314,DS-43774c93-4126-48c8-8828-f53093dd76d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46155,DS-3b334473-b17e-482b-89cf-e562cd10fac2,DISK], DatanodeInfoWithStorage[127.0.0.1:33354,DS-541a89f1-6b44-4806-8f16-6a0b501acebe,DISK], DatanodeInfoWithStorage[127.0.0.1:41044,DS-a33ec9f8-f6b2-43ba-be60-6a71fa1419e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34576,DS-9cc3ac16-a624-4839-9348-9ab80ba269ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2058435327-172.17.0.16-1597326311289:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33844,DS-68612b2b-2876-40dd-b9a6-ce3a5c26cb92,DISK], DatanodeInfoWithStorage[127.0.0.1:38745,DS-d7a12417-4e59-4945-9474-35f8913d7915,DISK], DatanodeInfoWithStorage[127.0.0.1:42495,DS-4086c0e3-ced3-486f-8c8c-3c7d2b4b0cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:40819,DS-a61abea0-2bd5-4a0c-bbeb-aead39214687,DISK], DatanodeInfoWithStorage[127.0.0.1:39938,DS-b56fc2a0-519b-4952-ba2c-6e363585906b,DISK], DatanodeInfoWithStorage[127.0.0.1:36469,DS-df1d7a52-8811-406c-8261-832c2da027ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39644,DS-937b0a73-6fce-4702-a5d9-542e911bff80,DISK], DatanodeInfoWithStorage[127.0.0.1:43420,DS-ca1ff2f9-3d6b-47a1-8138-821fa4b9458f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2058435327-172.17.0.16-1597326311289:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33844,DS-68612b2b-2876-40dd-b9a6-ce3a5c26cb92,DISK], DatanodeInfoWithStorage[127.0.0.1:38745,DS-d7a12417-4e59-4945-9474-35f8913d7915,DISK], DatanodeInfoWithStorage[127.0.0.1:42495,DS-4086c0e3-ced3-486f-8c8c-3c7d2b4b0cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:40819,DS-a61abea0-2bd5-4a0c-bbeb-aead39214687,DISK], DatanodeInfoWithStorage[127.0.0.1:39938,DS-b56fc2a0-519b-4952-ba2c-6e363585906b,DISK], DatanodeInfoWithStorage[127.0.0.1:36469,DS-df1d7a52-8811-406c-8261-832c2da027ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39644,DS-937b0a73-6fce-4702-a5d9-542e911bff80,DISK], DatanodeInfoWithStorage[127.0.0.1:43420,DS-ca1ff2f9-3d6b-47a1-8138-821fa4b9458f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1620279197-172.17.0.16-1597326452572:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42409,DS-0d83ea65-8e3f-4ce4-a734-8d82e66702d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46026,DS-a82129d3-8dfe-4615-a890-93408b59562c,DISK], DatanodeInfoWithStorage[127.0.0.1:39806,DS-5b289d8b-e4aa-4eb6-acf4-7c30c095f7c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40632,DS-c4ae7af7-28e1-4595-a2e0-eb03540ad949,DISK], DatanodeInfoWithStorage[127.0.0.1:38967,DS-a8fdfcf1-6092-400e-9bed-fcbc213e647b,DISK], DatanodeInfoWithStorage[127.0.0.1:41042,DS-4317d62c-84bc-455d-9d48-75352ef5bb8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43402,DS-87c87c65-3cdf-4803-a29d-5e22f84bc060,DISK], DatanodeInfoWithStorage[127.0.0.1:33824,DS-3e5f4c67-f852-422d-bc12-559b6a21b1fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1620279197-172.17.0.16-1597326452572:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42409,DS-0d83ea65-8e3f-4ce4-a734-8d82e66702d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46026,DS-a82129d3-8dfe-4615-a890-93408b59562c,DISK], DatanodeInfoWithStorage[127.0.0.1:39806,DS-5b289d8b-e4aa-4eb6-acf4-7c30c095f7c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40632,DS-c4ae7af7-28e1-4595-a2e0-eb03540ad949,DISK], DatanodeInfoWithStorage[127.0.0.1:38967,DS-a8fdfcf1-6092-400e-9bed-fcbc213e647b,DISK], DatanodeInfoWithStorage[127.0.0.1:41042,DS-4317d62c-84bc-455d-9d48-75352ef5bb8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43402,DS-87c87c65-3cdf-4803-a29d-5e22f84bc060,DISK], DatanodeInfoWithStorage[127.0.0.1:33824,DS-3e5f4c67-f852-422d-bc12-559b6a21b1fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1761178721-172.17.0.16-1597326817169:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43500,DS-270ee4fa-9b12-4379-986c-8c7941447b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:38933,DS-06802bac-aa02-45d9-a6f6-dec38f2cca1a,DISK], DatanodeInfoWithStorage[127.0.0.1:35081,DS-20fefd47-7606-4529-8603-3bd648ac7867,DISK], DatanodeInfoWithStorage[127.0.0.1:35252,DS-1a052633-1e85-4d36-a179-f4213af4d17d,DISK], DatanodeInfoWithStorage[127.0.0.1:44784,DS-da1d58de-13a1-493e-b677-dc67a5eed6b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45343,DS-7d197410-0a08-4632-aec2-b616acf4ae8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37381,DS-8af136ea-259b-4ba0-951a-d0ff1681a095,DISK], DatanodeInfoWithStorage[127.0.0.1:41745,DS-4a8d3e55-945b-46dd-b5e6-f15336da58df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1761178721-172.17.0.16-1597326817169:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43500,DS-270ee4fa-9b12-4379-986c-8c7941447b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:38933,DS-06802bac-aa02-45d9-a6f6-dec38f2cca1a,DISK], DatanodeInfoWithStorage[127.0.0.1:35081,DS-20fefd47-7606-4529-8603-3bd648ac7867,DISK], DatanodeInfoWithStorage[127.0.0.1:35252,DS-1a052633-1e85-4d36-a179-f4213af4d17d,DISK], DatanodeInfoWithStorage[127.0.0.1:44784,DS-da1d58de-13a1-493e-b677-dc67a5eed6b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45343,DS-7d197410-0a08-4632-aec2-b616acf4ae8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37381,DS-8af136ea-259b-4ba0-951a-d0ff1681a095,DISK], DatanodeInfoWithStorage[127.0.0.1:41745,DS-4a8d3e55-945b-46dd-b5e6-f15336da58df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-641691755-172.17.0.16-1597326926174:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33568,DS-9090c0d9-a13f-4e0e-993a-4a718dbfb2cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43103,DS-25229f29-69bc-40a9-a107-806d27c90ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:33057,DS-1beb33d6-95c8-4f80-bdf0-e9e2a0b4a805,DISK], DatanodeInfoWithStorage[127.0.0.1:35851,DS-662d7f27-20fb-4ee2-8fa0-2e353894198e,DISK], DatanodeInfoWithStorage[127.0.0.1:46782,DS-cb4ab13a-31af-43c8-9f27-49a3ebd3980e,DISK], DatanodeInfoWithStorage[127.0.0.1:35168,DS-c1f730e1-845d-4bf4-a4b6-d4865f951209,DISK], DatanodeInfoWithStorage[127.0.0.1:40651,DS-eba901fa-e623-41ea-a481-7bec3766af12,DISK], DatanodeInfoWithStorage[127.0.0.1:37047,DS-9439a478-7c74-4bb7-bf9a-984e8619dca9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-641691755-172.17.0.16-1597326926174:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33568,DS-9090c0d9-a13f-4e0e-993a-4a718dbfb2cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43103,DS-25229f29-69bc-40a9-a107-806d27c90ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:33057,DS-1beb33d6-95c8-4f80-bdf0-e9e2a0b4a805,DISK], DatanodeInfoWithStorage[127.0.0.1:35851,DS-662d7f27-20fb-4ee2-8fa0-2e353894198e,DISK], DatanodeInfoWithStorage[127.0.0.1:46782,DS-cb4ab13a-31af-43c8-9f27-49a3ebd3980e,DISK], DatanodeInfoWithStorage[127.0.0.1:35168,DS-c1f730e1-845d-4bf4-a4b6-d4865f951209,DISK], DatanodeInfoWithStorage[127.0.0.1:40651,DS-eba901fa-e623-41ea-a481-7bec3766af12,DISK], DatanodeInfoWithStorage[127.0.0.1:37047,DS-9439a478-7c74-4bb7-bf9a-984e8619dca9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2088436065-172.17.0.16-1597327424714:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37786,DS-a137899f-d81e-4d26-ba96-1d2e71a9102f,DISK], DatanodeInfoWithStorage[127.0.0.1:39113,DS-143dd5e1-acb6-4fd1-b46c-5b9cd1704085,DISK], DatanodeInfoWithStorage[127.0.0.1:40794,DS-425d9d39-0dd9-497e-bfa0-6feb8d589032,DISK], DatanodeInfoWithStorage[127.0.0.1:41803,DS-42a43978-a95c-4abf-a4d2-026a9fd1d5bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44190,DS-f340ad0e-421f-4236-97e0-4569678388d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45303,DS-c5fa9a6c-429a-497a-9eff-a39f5e9314d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46738,DS-b1df61b0-9542-4cfc-9bd9-2406d07dab05,DISK], DatanodeInfoWithStorage[127.0.0.1:42642,DS-f7f6deb7-231c-4764-bdf9-074c8c08c2d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2088436065-172.17.0.16-1597327424714:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37786,DS-a137899f-d81e-4d26-ba96-1d2e71a9102f,DISK], DatanodeInfoWithStorage[127.0.0.1:39113,DS-143dd5e1-acb6-4fd1-b46c-5b9cd1704085,DISK], DatanodeInfoWithStorage[127.0.0.1:40794,DS-425d9d39-0dd9-497e-bfa0-6feb8d589032,DISK], DatanodeInfoWithStorage[127.0.0.1:41803,DS-42a43978-a95c-4abf-a4d2-026a9fd1d5bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44190,DS-f340ad0e-421f-4236-97e0-4569678388d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45303,DS-c5fa9a6c-429a-497a-9eff-a39f5e9314d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46738,DS-b1df61b0-9542-4cfc-9bd9-2406d07dab05,DISK], DatanodeInfoWithStorage[127.0.0.1:42642,DS-f7f6deb7-231c-4764-bdf9-074c8c08c2d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-848946969-172.17.0.16-1597327842203:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44624,DS-461a89d0-1fab-48b4-b210-3be91bc56060,DISK], DatanodeInfoWithStorage[127.0.0.1:35712,DS-b6e2bc10-3035-43ad-a884-fa0162dc6ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:40437,DS-53179ae5-e3fa-40c4-b954-981ff1a6cf24,DISK], DatanodeInfoWithStorage[127.0.0.1:44723,DS-4f991ac5-e256-4911-a81e-1fc99e700e84,DISK], DatanodeInfoWithStorage[127.0.0.1:44480,DS-acef100e-367c-4dfa-81e8-7fe59997395a,DISK], DatanodeInfoWithStorage[127.0.0.1:46760,DS-7a0d146e-1bc4-48a0-80c0-0236a3841970,DISK], DatanodeInfoWithStorage[127.0.0.1:40795,DS-41b91e24-ac15-4ddb-8063-16561eb3fc16,DISK], DatanodeInfoWithStorage[127.0.0.1:39345,DS-1215b45f-cc36-4617-8b5c-da819533908e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-848946969-172.17.0.16-1597327842203:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44624,DS-461a89d0-1fab-48b4-b210-3be91bc56060,DISK], DatanodeInfoWithStorage[127.0.0.1:35712,DS-b6e2bc10-3035-43ad-a884-fa0162dc6ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:40437,DS-53179ae5-e3fa-40c4-b954-981ff1a6cf24,DISK], DatanodeInfoWithStorage[127.0.0.1:44723,DS-4f991ac5-e256-4911-a81e-1fc99e700e84,DISK], DatanodeInfoWithStorage[127.0.0.1:44480,DS-acef100e-367c-4dfa-81e8-7fe59997395a,DISK], DatanodeInfoWithStorage[127.0.0.1:46760,DS-7a0d146e-1bc4-48a0-80c0-0236a3841970,DISK], DatanodeInfoWithStorage[127.0.0.1:40795,DS-41b91e24-ac15-4ddb-8063-16561eb3fc16,DISK], DatanodeInfoWithStorage[127.0.0.1:39345,DS-1215b45f-cc36-4617-8b5c-da819533908e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-201434052-172.17.0.16-1597327872960:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38055,DS-67a05312-60ce-49ff-9d12-41fd38421a66,DISK], DatanodeInfoWithStorage[127.0.0.1:41268,DS-67d2473f-4fa9-4632-9431-323dfce1b979,DISK], DatanodeInfoWithStorage[127.0.0.1:38593,DS-7f079d90-f49b-4c5b-b09b-82df2866a997,DISK], DatanodeInfoWithStorage[127.0.0.1:38692,DS-c083f1e7-9e06-488e-be88-6de6be5291ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40032,DS-a7258f7d-a713-41e0-80b3-e38ea6cc36dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33995,DS-57c23b76-651e-44d3-9cf2-85ef4b83ec43,DISK], DatanodeInfoWithStorage[127.0.0.1:39934,DS-84bef870-fe09-425b-ac2f-3abf9b7d835c,DISK], DatanodeInfoWithStorage[127.0.0.1:35817,DS-b550969b-babd-4f9d-910a-fa307031b3a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-201434052-172.17.0.16-1597327872960:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38055,DS-67a05312-60ce-49ff-9d12-41fd38421a66,DISK], DatanodeInfoWithStorage[127.0.0.1:41268,DS-67d2473f-4fa9-4632-9431-323dfce1b979,DISK], DatanodeInfoWithStorage[127.0.0.1:38593,DS-7f079d90-f49b-4c5b-b09b-82df2866a997,DISK], DatanodeInfoWithStorage[127.0.0.1:38692,DS-c083f1e7-9e06-488e-be88-6de6be5291ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40032,DS-a7258f7d-a713-41e0-80b3-e38ea6cc36dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33995,DS-57c23b76-651e-44d3-9cf2-85ef4b83ec43,DISK], DatanodeInfoWithStorage[127.0.0.1:39934,DS-84bef870-fe09-425b-ac2f-3abf9b7d835c,DISK], DatanodeInfoWithStorage[127.0.0.1:35817,DS-b550969b-babd-4f9d-910a-fa307031b3a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-822569789-172.17.0.16-1597327938364:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43312,DS-216c74e7-eb54-4def-9c70-89f61ef6478f,DISK], DatanodeInfoWithStorage[127.0.0.1:32966,DS-b5a82bf8-7096-4940-8daf-4fd478bdffe7,DISK], DatanodeInfoWithStorage[127.0.0.1:43398,DS-3034606a-1f59-4f06-a28f-bd44f4d5bbbb,DISK], DatanodeInfoWithStorage[127.0.0.1:37576,DS-b137e319-791c-45e2-908b-690835e9b9c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37905,DS-6c18b36c-f31c-4c24-a800-50de41f282ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43475,DS-c1fb4135-fe9a-4288-b881-02609d3049da,DISK], DatanodeInfoWithStorage[127.0.0.1:37433,DS-a4254ae0-9b15-4bb0-9fae-bca17c4a0c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40565,DS-78a809da-2657-439b-8342-bbf98a45be80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-822569789-172.17.0.16-1597327938364:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43312,DS-216c74e7-eb54-4def-9c70-89f61ef6478f,DISK], DatanodeInfoWithStorage[127.0.0.1:32966,DS-b5a82bf8-7096-4940-8daf-4fd478bdffe7,DISK], DatanodeInfoWithStorage[127.0.0.1:43398,DS-3034606a-1f59-4f06-a28f-bd44f4d5bbbb,DISK], DatanodeInfoWithStorage[127.0.0.1:37576,DS-b137e319-791c-45e2-908b-690835e9b9c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37905,DS-6c18b36c-f31c-4c24-a800-50de41f282ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43475,DS-c1fb4135-fe9a-4288-b881-02609d3049da,DISK], DatanodeInfoWithStorage[127.0.0.1:37433,DS-a4254ae0-9b15-4bb0-9fae-bca17c4a0c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40565,DS-78a809da-2657-439b-8342-bbf98a45be80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-799339254-172.17.0.16-1597328225452:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42229,DS-b7d3fee9-db0c-4a92-8acd-21714df4eea8,DISK], DatanodeInfoWithStorage[127.0.0.1:37261,DS-2e948701-e7c6-4b61-a333-6efdb01c4dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:43734,DS-8b5b2111-0914-4e95-bd31-f07608a46ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:45708,DS-88f20a29-b551-4abe-9a8f-dc09fd7bfa3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45535,DS-8a562173-112d-4f2e-b0f8-7e30502443d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37109,DS-c50e445e-4793-4e2c-9af2-3238470373ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42010,DS-42052822-44be-4a7c-9423-698a13163d51,DISK], DatanodeInfoWithStorage[127.0.0.1:33750,DS-46a47a6c-d021-402f-a6ba-6f963e0ade72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-799339254-172.17.0.16-1597328225452:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42229,DS-b7d3fee9-db0c-4a92-8acd-21714df4eea8,DISK], DatanodeInfoWithStorage[127.0.0.1:37261,DS-2e948701-e7c6-4b61-a333-6efdb01c4dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:43734,DS-8b5b2111-0914-4e95-bd31-f07608a46ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:45708,DS-88f20a29-b551-4abe-9a8f-dc09fd7bfa3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45535,DS-8a562173-112d-4f2e-b0f8-7e30502443d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37109,DS-c50e445e-4793-4e2c-9af2-3238470373ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42010,DS-42052822-44be-4a7c-9423-698a13163d51,DISK], DatanodeInfoWithStorage[127.0.0.1:33750,DS-46a47a6c-d021-402f-a6ba-6f963e0ade72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1831164999-172.17.0.16-1597328442752:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42543,DS-df2c9e7f-0ceb-4aad-b9fa-457083a6b596,DISK], DatanodeInfoWithStorage[127.0.0.1:41024,DS-0315acd3-f519-4cae-8e3e-341725b188a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35921,DS-6a092df6-9ccf-46a9-b080-3f90cf4a13b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45414,DS-72fa7fc6-82c1-4f80-ad57-54fad5f98d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:46051,DS-985d1abd-e1c6-419b-8a36-a31629682e57,DISK], DatanodeInfoWithStorage[127.0.0.1:38916,DS-ba0e72b4-0f45-44c8-a616-6ae42104d182,DISK], DatanodeInfoWithStorage[127.0.0.1:38275,DS-4c50e7c2-e8ef-4abd-bc19-dec7f0155e19,DISK], DatanodeInfoWithStorage[127.0.0.1:39037,DS-ee7f72b2-f324-4e10-a493-a642c4a55b54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1831164999-172.17.0.16-1597328442752:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42543,DS-df2c9e7f-0ceb-4aad-b9fa-457083a6b596,DISK], DatanodeInfoWithStorage[127.0.0.1:41024,DS-0315acd3-f519-4cae-8e3e-341725b188a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35921,DS-6a092df6-9ccf-46a9-b080-3f90cf4a13b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45414,DS-72fa7fc6-82c1-4f80-ad57-54fad5f98d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:46051,DS-985d1abd-e1c6-419b-8a36-a31629682e57,DISK], DatanodeInfoWithStorage[127.0.0.1:38916,DS-ba0e72b4-0f45-44c8-a616-6ae42104d182,DISK], DatanodeInfoWithStorage[127.0.0.1:38275,DS-4c50e7c2-e8ef-4abd-bc19-dec7f0155e19,DISK], DatanodeInfoWithStorage[127.0.0.1:39037,DS-ee7f72b2-f324-4e10-a493-a642c4a55b54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5190
