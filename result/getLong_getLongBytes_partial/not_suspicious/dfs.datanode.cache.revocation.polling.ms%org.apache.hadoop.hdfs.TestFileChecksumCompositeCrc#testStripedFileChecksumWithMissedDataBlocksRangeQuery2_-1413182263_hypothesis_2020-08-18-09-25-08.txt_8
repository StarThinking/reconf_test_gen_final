reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-220229220-172.17.0.9-1597743060999:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37585,DS-45484f0b-4158-422b-8537-880c257c9546,DISK], DatanodeInfoWithStorage[127.0.0.1:36753,DS-5018afab-2d46-4eae-b80a-90dfd1dd9b61,DISK], DatanodeInfoWithStorage[127.0.0.1:38813,DS-7ca317fa-9551-4b58-9bbc-950abcda9804,DISK], DatanodeInfoWithStorage[127.0.0.1:33569,DS-71835626-321a-4919-8dbe-a44b25087d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:39437,DS-9e1aed27-67d8-4c42-b61d-e9bc9cab5192,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-8a538910-c5ec-466b-9700-43e104e1b867,DISK], DatanodeInfoWithStorage[127.0.0.1:37663,DS-09d77e1f-5a3f-40e7-9878-c0a8322f9857,DISK], DatanodeInfoWithStorage[127.0.0.1:45019,DS-6c2b94da-3db4-4a1e-b5a0-026389553527,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-220229220-172.17.0.9-1597743060999:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37585,DS-45484f0b-4158-422b-8537-880c257c9546,DISK], DatanodeInfoWithStorage[127.0.0.1:36753,DS-5018afab-2d46-4eae-b80a-90dfd1dd9b61,DISK], DatanodeInfoWithStorage[127.0.0.1:38813,DS-7ca317fa-9551-4b58-9bbc-950abcda9804,DISK], DatanodeInfoWithStorage[127.0.0.1:33569,DS-71835626-321a-4919-8dbe-a44b25087d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:39437,DS-9e1aed27-67d8-4c42-b61d-e9bc9cab5192,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-8a538910-c5ec-466b-9700-43e104e1b867,DISK], DatanodeInfoWithStorage[127.0.0.1:37663,DS-09d77e1f-5a3f-40e7-9878-c0a8322f9857,DISK], DatanodeInfoWithStorage[127.0.0.1:45019,DS-6c2b94da-3db4-4a1e-b5a0-026389553527,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-492218341-172.17.0.9-1597743354170:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41503,DS-c3e7d699-a49e-4d0e-8f29-17f81fd2075d,DISK], DatanodeInfoWithStorage[127.0.0.1:37821,DS-a837a856-35fc-472b-b96f-3449c3a0dcc2,DISK], DatanodeInfoWithStorage[127.0.0.1:34243,DS-82ba9941-3e85-4bfc-8522-700d7b771bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:39501,DS-54d5bdfa-73bf-4c35-87f6-5aeeb0213bed,DISK], DatanodeInfoWithStorage[127.0.0.1:44735,DS-478fca8b-d0cc-4e4a-9697-4035e28c1534,DISK], DatanodeInfoWithStorage[127.0.0.1:40389,DS-77f7f58b-b9b9-4887-9822-8fa7f46946f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44142,DS-a220c80f-1b7a-4713-bf4b-45db9f878ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:46676,DS-ac8e91c8-637f-446e-9ab7-1a8b41d146fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-492218341-172.17.0.9-1597743354170:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41503,DS-c3e7d699-a49e-4d0e-8f29-17f81fd2075d,DISK], DatanodeInfoWithStorage[127.0.0.1:37821,DS-a837a856-35fc-472b-b96f-3449c3a0dcc2,DISK], DatanodeInfoWithStorage[127.0.0.1:34243,DS-82ba9941-3e85-4bfc-8522-700d7b771bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:39501,DS-54d5bdfa-73bf-4c35-87f6-5aeeb0213bed,DISK], DatanodeInfoWithStorage[127.0.0.1:44735,DS-478fca8b-d0cc-4e4a-9697-4035e28c1534,DISK], DatanodeInfoWithStorage[127.0.0.1:40389,DS-77f7f58b-b9b9-4887-9822-8fa7f46946f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44142,DS-a220c80f-1b7a-4713-bf4b-45db9f878ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:46676,DS-ac8e91c8-637f-446e-9ab7-1a8b41d146fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1167415643-172.17.0.9-1597743896736:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45975,DS-d5ccb66b-2c87-40c9-b6fb-37fa5e3cd526,DISK], DatanodeInfoWithStorage[127.0.0.1:43313,DS-97de1682-3ec4-4e49-b8eb-5972e677f615,DISK], DatanodeInfoWithStorage[127.0.0.1:37121,DS-2ab0dee4-7380-452a-a451-83c84d7b1627,DISK], DatanodeInfoWithStorage[127.0.0.1:44676,DS-4bf4eca3-7b6c-4f05-857f-92e9949365d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34321,DS-8600c141-69c9-4364-83a4-36b5ef9330cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36517,DS-f0d565cc-376a-43ca-85fc-8bdf7f050732,DISK], DatanodeInfoWithStorage[127.0.0.1:44710,DS-72c4058f-b255-4426-a6cf-1c19b3003d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:41175,DS-1489edef-1276-4b3a-bdca-ebe80a8e1f87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1167415643-172.17.0.9-1597743896736:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45975,DS-d5ccb66b-2c87-40c9-b6fb-37fa5e3cd526,DISK], DatanodeInfoWithStorage[127.0.0.1:43313,DS-97de1682-3ec4-4e49-b8eb-5972e677f615,DISK], DatanodeInfoWithStorage[127.0.0.1:37121,DS-2ab0dee4-7380-452a-a451-83c84d7b1627,DISK], DatanodeInfoWithStorage[127.0.0.1:44676,DS-4bf4eca3-7b6c-4f05-857f-92e9949365d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34321,DS-8600c141-69c9-4364-83a4-36b5ef9330cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36517,DS-f0d565cc-376a-43ca-85fc-8bdf7f050732,DISK], DatanodeInfoWithStorage[127.0.0.1:44710,DS-72c4058f-b255-4426-a6cf-1c19b3003d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:41175,DS-1489edef-1276-4b3a-bdca-ebe80a8e1f87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-741771684-172.17.0.9-1597744370290:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39532,DS-cff72d7e-dfee-493b-8b02-a962006d4d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33317,DS-44dc7075-82ae-41e6-9595-b9acf4f1fd0c,DISK], DatanodeInfoWithStorage[127.0.0.1:45766,DS-2d90e86f-4532-43fc-965e-c6736bacb486,DISK], DatanodeInfoWithStorage[127.0.0.1:36818,DS-3fffe1c0-64a2-4940-8f5e-759291f9c4a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33467,DS-0ca13693-5567-4d69-bb8d-640bebc33165,DISK], DatanodeInfoWithStorage[127.0.0.1:42980,DS-5e07815f-a900-4470-a13b-c47626e06aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:36981,DS-2d226c61-73eb-4c3d-aac3-d3df94866d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:38938,DS-47d63329-2895-4340-a963-5122adfa62a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-741771684-172.17.0.9-1597744370290:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39532,DS-cff72d7e-dfee-493b-8b02-a962006d4d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33317,DS-44dc7075-82ae-41e6-9595-b9acf4f1fd0c,DISK], DatanodeInfoWithStorage[127.0.0.1:45766,DS-2d90e86f-4532-43fc-965e-c6736bacb486,DISK], DatanodeInfoWithStorage[127.0.0.1:36818,DS-3fffe1c0-64a2-4940-8f5e-759291f9c4a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33467,DS-0ca13693-5567-4d69-bb8d-640bebc33165,DISK], DatanodeInfoWithStorage[127.0.0.1:42980,DS-5e07815f-a900-4470-a13b-c47626e06aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:36981,DS-2d226c61-73eb-4c3d-aac3-d3df94866d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:38938,DS-47d63329-2895-4340-a963-5122adfa62a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1060973669-172.17.0.9-1597744746793:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35491,DS-17b1db87-57f2-454d-a32b-09b4459995f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33297,DS-9e62bb13-322d-4429-86b4-be77a41cf263,DISK], DatanodeInfoWithStorage[127.0.0.1:42714,DS-8c8da6da-17ae-437f-8fca-dabf0a6975df,DISK], DatanodeInfoWithStorage[127.0.0.1:38260,DS-fb833880-ac05-44a0-9bd6-5ca4831b0389,DISK], DatanodeInfoWithStorage[127.0.0.1:36681,DS-10c1edae-2a1c-4c77-b7f8-d8ab9fd3d02d,DISK], DatanodeInfoWithStorage[127.0.0.1:38769,DS-e975ee77-220b-463a-afe0-afd5f30e88a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38540,DS-4db37826-6fb6-47e6-970a-dbbceed6d972,DISK], DatanodeInfoWithStorage[127.0.0.1:34209,DS-64d1d0e9-0244-4506-b5da-0fd3deb76aae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1060973669-172.17.0.9-1597744746793:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35491,DS-17b1db87-57f2-454d-a32b-09b4459995f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33297,DS-9e62bb13-322d-4429-86b4-be77a41cf263,DISK], DatanodeInfoWithStorage[127.0.0.1:42714,DS-8c8da6da-17ae-437f-8fca-dabf0a6975df,DISK], DatanodeInfoWithStorage[127.0.0.1:38260,DS-fb833880-ac05-44a0-9bd6-5ca4831b0389,DISK], DatanodeInfoWithStorage[127.0.0.1:36681,DS-10c1edae-2a1c-4c77-b7f8-d8ab9fd3d02d,DISK], DatanodeInfoWithStorage[127.0.0.1:38769,DS-e975ee77-220b-463a-afe0-afd5f30e88a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38540,DS-4db37826-6fb6-47e6-970a-dbbceed6d972,DISK], DatanodeInfoWithStorage[127.0.0.1:34209,DS-64d1d0e9-0244-4506-b5da-0fd3deb76aae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2010522289-172.17.0.9-1597745012115:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42244,DS-58862c33-d41e-4ec3-a467-a496def105ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46248,DS-64aedc36-79d1-4374-b0cd-768fd20e922d,DISK], DatanodeInfoWithStorage[127.0.0.1:40087,DS-75136bc1-6523-464c-8ed0-38bbf68d247d,DISK], DatanodeInfoWithStorage[127.0.0.1:34700,DS-db59d746-aea6-4d21-9211-778172299215,DISK], DatanodeInfoWithStorage[127.0.0.1:38881,DS-0b1382ae-befb-43a6-a435-117d3545cd62,DISK], DatanodeInfoWithStorage[127.0.0.1:43769,DS-7934efa1-15e1-4896-ac2c-f59e164d868a,DISK], DatanodeInfoWithStorage[127.0.0.1:34539,DS-d1f06d79-20b8-4501-a5f3-55778b1bbd82,DISK], DatanodeInfoWithStorage[127.0.0.1:36794,DS-1029f2fe-5272-4b2d-861e-65632d801249,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2010522289-172.17.0.9-1597745012115:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42244,DS-58862c33-d41e-4ec3-a467-a496def105ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46248,DS-64aedc36-79d1-4374-b0cd-768fd20e922d,DISK], DatanodeInfoWithStorage[127.0.0.1:40087,DS-75136bc1-6523-464c-8ed0-38bbf68d247d,DISK], DatanodeInfoWithStorage[127.0.0.1:34700,DS-db59d746-aea6-4d21-9211-778172299215,DISK], DatanodeInfoWithStorage[127.0.0.1:38881,DS-0b1382ae-befb-43a6-a435-117d3545cd62,DISK], DatanodeInfoWithStorage[127.0.0.1:43769,DS-7934efa1-15e1-4896-ac2c-f59e164d868a,DISK], DatanodeInfoWithStorage[127.0.0.1:34539,DS-d1f06d79-20b8-4501-a5f3-55778b1bbd82,DISK], DatanodeInfoWithStorage[127.0.0.1:36794,DS-1029f2fe-5272-4b2d-861e-65632d801249,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-21482680-172.17.0.9-1597745159451:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35000,DS-ef974a75-4752-4510-b369-af0c78973eda,DISK], DatanodeInfoWithStorage[127.0.0.1:35622,DS-0b8a13b9-ca73-4b58-bcd8-fdf0b33c5697,DISK], DatanodeInfoWithStorage[127.0.0.1:38090,DS-f27265fa-73c7-4e00-9626-d93084a210ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46542,DS-63a5f4d7-070a-4844-ade2-4fe23af5023f,DISK], DatanodeInfoWithStorage[127.0.0.1:46703,DS-440e1fa7-8c18-4e4a-816b-de1e58e3021e,DISK], DatanodeInfoWithStorage[127.0.0.1:46620,DS-f4a0e04f-b78f-4f8a-8f2c-3113dbde6aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:34607,DS-16b4b020-c545-45c0-a553-7e0432cdab3f,DISK], DatanodeInfoWithStorage[127.0.0.1:42718,DS-b6285ad0-e500-4402-9cf7-06d3c3ea8434,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-21482680-172.17.0.9-1597745159451:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35000,DS-ef974a75-4752-4510-b369-af0c78973eda,DISK], DatanodeInfoWithStorage[127.0.0.1:35622,DS-0b8a13b9-ca73-4b58-bcd8-fdf0b33c5697,DISK], DatanodeInfoWithStorage[127.0.0.1:38090,DS-f27265fa-73c7-4e00-9626-d93084a210ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46542,DS-63a5f4d7-070a-4844-ade2-4fe23af5023f,DISK], DatanodeInfoWithStorage[127.0.0.1:46703,DS-440e1fa7-8c18-4e4a-816b-de1e58e3021e,DISK], DatanodeInfoWithStorage[127.0.0.1:46620,DS-f4a0e04f-b78f-4f8a-8f2c-3113dbde6aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:34607,DS-16b4b020-c545-45c0-a553-7e0432cdab3f,DISK], DatanodeInfoWithStorage[127.0.0.1:42718,DS-b6285ad0-e500-4402-9cf7-06d3c3ea8434,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-356694832-172.17.0.9-1597745395609:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46128,DS-c15a1683-43ef-425b-b8ef-5a3e8e41d06c,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-eebd6432-d9d1-4544-aec5-9853db73165c,DISK], DatanodeInfoWithStorage[127.0.0.1:36141,DS-4eb1528e-8ff7-40f9-9b38-f7f228463290,DISK], DatanodeInfoWithStorage[127.0.0.1:40313,DS-67430dd9-0a99-470d-9687-ae2de681a924,DISK], DatanodeInfoWithStorage[127.0.0.1:33865,DS-ec64308d-603e-4822-b467-fe005e19bcee,DISK], DatanodeInfoWithStorage[127.0.0.1:44315,DS-0d510f14-47df-48ae-a9e0-90adc609d291,DISK], DatanodeInfoWithStorage[127.0.0.1:33874,DS-b4cc6856-0221-4628-828c-2d46ddf106cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37650,DS-c3fa0770-b9d2-463d-9c01-8be075da3b43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-356694832-172.17.0.9-1597745395609:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46128,DS-c15a1683-43ef-425b-b8ef-5a3e8e41d06c,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-eebd6432-d9d1-4544-aec5-9853db73165c,DISK], DatanodeInfoWithStorage[127.0.0.1:36141,DS-4eb1528e-8ff7-40f9-9b38-f7f228463290,DISK], DatanodeInfoWithStorage[127.0.0.1:40313,DS-67430dd9-0a99-470d-9687-ae2de681a924,DISK], DatanodeInfoWithStorage[127.0.0.1:33865,DS-ec64308d-603e-4822-b467-fe005e19bcee,DISK], DatanodeInfoWithStorage[127.0.0.1:44315,DS-0d510f14-47df-48ae-a9e0-90adc609d291,DISK], DatanodeInfoWithStorage[127.0.0.1:33874,DS-b4cc6856-0221-4628-828c-2d46ddf106cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37650,DS-c3fa0770-b9d2-463d-9c01-8be075da3b43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1097529164-172.17.0.9-1597745879265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43309,DS-48e43486-bb23-478e-9837-1b65e634eba7,DISK], DatanodeInfoWithStorage[127.0.0.1:41275,DS-257ea371-0b8a-40dc-8c02-58efd8a349da,DISK], DatanodeInfoWithStorage[127.0.0.1:44001,DS-f15d3c7f-1087-4f8e-9b73-4ae834dcff5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43605,DS-87275d5a-da46-40da-aa2c-f16b0d5bf539,DISK], DatanodeInfoWithStorage[127.0.0.1:37021,DS-43b891a6-e227-4484-8132-fe764a7ec9b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41497,DS-76d33ab1-9154-40c5-90aa-949c1b8301fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44524,DS-4d50c70a-2503-4ae6-8226-76d1e20c43a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39891,DS-cd02d174-50a7-4086-8645-dee0a78c55c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1097529164-172.17.0.9-1597745879265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43309,DS-48e43486-bb23-478e-9837-1b65e634eba7,DISK], DatanodeInfoWithStorage[127.0.0.1:41275,DS-257ea371-0b8a-40dc-8c02-58efd8a349da,DISK], DatanodeInfoWithStorage[127.0.0.1:44001,DS-f15d3c7f-1087-4f8e-9b73-4ae834dcff5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43605,DS-87275d5a-da46-40da-aa2c-f16b0d5bf539,DISK], DatanodeInfoWithStorage[127.0.0.1:37021,DS-43b891a6-e227-4484-8132-fe764a7ec9b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41497,DS-76d33ab1-9154-40c5-90aa-949c1b8301fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44524,DS-4d50c70a-2503-4ae6-8226-76d1e20c43a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39891,DS-cd02d174-50a7-4086-8645-dee0a78c55c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-877902032-172.17.0.9-1597746272720:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45241,DS-c6fc451f-c72f-4397-bf33-d53ef7549781,DISK], DatanodeInfoWithStorage[127.0.0.1:38708,DS-e325a9bb-8f07-4cde-bcad-7da07cfd4aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:39035,DS-a03a68e1-390d-492b-9158-45d357ede4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:32993,DS-f0938708-69fd-4f0e-9719-3b48ed023885,DISK], DatanodeInfoWithStorage[127.0.0.1:41740,DS-28c76f07-c075-4bc3-ac23-54e5e9cc71b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45153,DS-298e9ec0-8d8e-416f-812d-e1f341899f52,DISK], DatanodeInfoWithStorage[127.0.0.1:41013,DS-01337105-cffb-41c5-befd-c69a6c37a4b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45137,DS-718a53a3-95bb-40f8-ba3b-6ce65665ca0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-877902032-172.17.0.9-1597746272720:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45241,DS-c6fc451f-c72f-4397-bf33-d53ef7549781,DISK], DatanodeInfoWithStorage[127.0.0.1:38708,DS-e325a9bb-8f07-4cde-bcad-7da07cfd4aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:39035,DS-a03a68e1-390d-492b-9158-45d357ede4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:32993,DS-f0938708-69fd-4f0e-9719-3b48ed023885,DISK], DatanodeInfoWithStorage[127.0.0.1:41740,DS-28c76f07-c075-4bc3-ac23-54e5e9cc71b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45153,DS-298e9ec0-8d8e-416f-812d-e1f341899f52,DISK], DatanodeInfoWithStorage[127.0.0.1:41013,DS-01337105-cffb-41c5-befd-c69a6c37a4b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45137,DS-718a53a3-95bb-40f8-ba3b-6ce65665ca0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-274143468-172.17.0.9-1597746755115:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44637,DS-49671ace-9c98-4891-97c6-72ab4bdba32a,DISK], DatanodeInfoWithStorage[127.0.0.1:38798,DS-cd835a62-0953-4cbe-b287-08ffe1a07288,DISK], DatanodeInfoWithStorage[127.0.0.1:36410,DS-5613eea9-b88d-4440-96e7-377974ace30b,DISK], DatanodeInfoWithStorage[127.0.0.1:35790,DS-da7e5eac-cb6b-4f95-8434-c2f2410c95f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33207,DS-9e897f5d-3c22-4070-ad47-a9b65594637d,DISK], DatanodeInfoWithStorage[127.0.0.1:38535,DS-902cbeec-1360-41d0-acfc-38e70d74afb8,DISK], DatanodeInfoWithStorage[127.0.0.1:44336,DS-8e187c57-dbe5-49be-9de1-226476039fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:35063,DS-2497360b-e557-4694-b6a4-626d07819bfa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-274143468-172.17.0.9-1597746755115:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44637,DS-49671ace-9c98-4891-97c6-72ab4bdba32a,DISK], DatanodeInfoWithStorage[127.0.0.1:38798,DS-cd835a62-0953-4cbe-b287-08ffe1a07288,DISK], DatanodeInfoWithStorage[127.0.0.1:36410,DS-5613eea9-b88d-4440-96e7-377974ace30b,DISK], DatanodeInfoWithStorage[127.0.0.1:35790,DS-da7e5eac-cb6b-4f95-8434-c2f2410c95f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33207,DS-9e897f5d-3c22-4070-ad47-a9b65594637d,DISK], DatanodeInfoWithStorage[127.0.0.1:38535,DS-902cbeec-1360-41d0-acfc-38e70d74afb8,DISK], DatanodeInfoWithStorage[127.0.0.1:44336,DS-8e187c57-dbe5-49be-9de1-226476039fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:35063,DS-2497360b-e557-4694-b6a4-626d07819bfa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1637795268-172.17.0.9-1597746914082:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44184,DS-24f4dad8-42d0-4c03-97b0-d8ab6bd95fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:34060,DS-782142b5-e2df-4457-88d9-8440205e6c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34344,DS-ce5dadc5-3eff-4974-a3d3-6fef5f108aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:39277,DS-ebd51751-4721-4744-8bbd-6e303ea9052c,DISK], DatanodeInfoWithStorage[127.0.0.1:41956,DS-ded130be-c19a-430d-bac9-9bf5cc1e6868,DISK], DatanodeInfoWithStorage[127.0.0.1:39390,DS-71903cfb-3de9-46b9-b9b9-6c8cd429073a,DISK], DatanodeInfoWithStorage[127.0.0.1:41125,DS-f125c927-4e93-4b81-93a9-076acb6ad2fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-17edc725-3322-4764-80c1-a5356a25e1cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1637795268-172.17.0.9-1597746914082:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44184,DS-24f4dad8-42d0-4c03-97b0-d8ab6bd95fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:34060,DS-782142b5-e2df-4457-88d9-8440205e6c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34344,DS-ce5dadc5-3eff-4974-a3d3-6fef5f108aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:39277,DS-ebd51751-4721-4744-8bbd-6e303ea9052c,DISK], DatanodeInfoWithStorage[127.0.0.1:41956,DS-ded130be-c19a-430d-bac9-9bf5cc1e6868,DISK], DatanodeInfoWithStorage[127.0.0.1:39390,DS-71903cfb-3de9-46b9-b9b9-6c8cd429073a,DISK], DatanodeInfoWithStorage[127.0.0.1:41125,DS-f125c927-4e93-4b81-93a9-076acb6ad2fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-17edc725-3322-4764-80c1-a5356a25e1cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1887812225-172.17.0.9-1597746956276:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36364,DS-d9a9a4cf-cbf5-4096-a53d-e5cafa1b0651,DISK], DatanodeInfoWithStorage[127.0.0.1:35759,DS-ad61faa3-6766-4201-a943-7f434eb07256,DISK], DatanodeInfoWithStorage[127.0.0.1:36555,DS-13e370b7-98cb-40f0-b0df-11b45f092613,DISK], DatanodeInfoWithStorage[127.0.0.1:37452,DS-11edeb2d-de15-4787-a3f9-be645e468856,DISK], DatanodeInfoWithStorage[127.0.0.1:40068,DS-3f97c3d9-a9cb-4f8d-ac4c-e9778311f84a,DISK], DatanodeInfoWithStorage[127.0.0.1:39187,DS-c2cca10d-a2a0-4424-b6e3-f1fae636c8b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33074,DS-bd07ddf0-a698-4aff-94f6-1e077ebdfc69,DISK], DatanodeInfoWithStorage[127.0.0.1:37672,DS-1f3e9cff-966e-484e-97da-f1919c98c38b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1887812225-172.17.0.9-1597746956276:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36364,DS-d9a9a4cf-cbf5-4096-a53d-e5cafa1b0651,DISK], DatanodeInfoWithStorage[127.0.0.1:35759,DS-ad61faa3-6766-4201-a943-7f434eb07256,DISK], DatanodeInfoWithStorage[127.0.0.1:36555,DS-13e370b7-98cb-40f0-b0df-11b45f092613,DISK], DatanodeInfoWithStorage[127.0.0.1:37452,DS-11edeb2d-de15-4787-a3f9-be645e468856,DISK], DatanodeInfoWithStorage[127.0.0.1:40068,DS-3f97c3d9-a9cb-4f8d-ac4c-e9778311f84a,DISK], DatanodeInfoWithStorage[127.0.0.1:39187,DS-c2cca10d-a2a0-4424-b6e3-f1fae636c8b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33074,DS-bd07ddf0-a698-4aff-94f6-1e077ebdfc69,DISK], DatanodeInfoWithStorage[127.0.0.1:37672,DS-1f3e9cff-966e-484e-97da-f1919c98c38b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2089408545-172.17.0.9-1597748246464:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33874,DS-36085ee1-3521-4ea2-bfb5-99f4df7e1a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:40202,DS-50142ed0-302b-4cd3-8c5c-3e5aa68319a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44895,DS-c554e5ba-fe1e-4e66-9114-83973df9baf3,DISK], DatanodeInfoWithStorage[127.0.0.1:41732,DS-726260a8-90de-41e6-b73f-6c4636050fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:36729,DS-bc0024a5-8377-475b-8944-51b0f35b81e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45138,DS-fa6cafd1-704d-4b2d-9f1a-b2afe8438ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:41751,DS-4eab99b5-03b2-4e3d-adbd-6d884a8d7182,DISK], DatanodeInfoWithStorage[127.0.0.1:42769,DS-8e6ba77f-7495-4433-b414-98f305a97e7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2089408545-172.17.0.9-1597748246464:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33874,DS-36085ee1-3521-4ea2-bfb5-99f4df7e1a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:40202,DS-50142ed0-302b-4cd3-8c5c-3e5aa68319a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44895,DS-c554e5ba-fe1e-4e66-9114-83973df9baf3,DISK], DatanodeInfoWithStorage[127.0.0.1:41732,DS-726260a8-90de-41e6-b73f-6c4636050fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:36729,DS-bc0024a5-8377-475b-8944-51b0f35b81e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45138,DS-fa6cafd1-704d-4b2d-9f1a-b2afe8438ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:41751,DS-4eab99b5-03b2-4e3d-adbd-6d884a8d7182,DISK], DatanodeInfoWithStorage[127.0.0.1:42769,DS-8e6ba77f-7495-4433-b414-98f305a97e7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1931942463-172.17.0.9-1597748335130:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41316,DS-49f0a105-2e23-4430-bba6-abc6f95c7efd,DISK], DatanodeInfoWithStorage[127.0.0.1:42240,DS-3fa44ddc-7957-4be4-b41f-63bbff938a55,DISK], DatanodeInfoWithStorage[127.0.0.1:35274,DS-07449e47-48c7-4b07-9a51-92ac4450f844,DISK], DatanodeInfoWithStorage[127.0.0.1:33415,DS-c23e717f-d776-4182-983a-755c7d16d8a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35290,DS-cdf1c361-5bdf-4640-8a9c-9bf33ae3982f,DISK], DatanodeInfoWithStorage[127.0.0.1:45855,DS-b47fef78-8a4f-4b81-b4cb-814fcafa636a,DISK], DatanodeInfoWithStorage[127.0.0.1:41930,DS-223cab6a-95b2-41fd-b5d1-1657abda8e15,DISK], DatanodeInfoWithStorage[127.0.0.1:37993,DS-1e591b90-2c14-4979-b4a8-8433cc975e20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1931942463-172.17.0.9-1597748335130:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41316,DS-49f0a105-2e23-4430-bba6-abc6f95c7efd,DISK], DatanodeInfoWithStorage[127.0.0.1:42240,DS-3fa44ddc-7957-4be4-b41f-63bbff938a55,DISK], DatanodeInfoWithStorage[127.0.0.1:35274,DS-07449e47-48c7-4b07-9a51-92ac4450f844,DISK], DatanodeInfoWithStorage[127.0.0.1:33415,DS-c23e717f-d776-4182-983a-755c7d16d8a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35290,DS-cdf1c361-5bdf-4640-8a9c-9bf33ae3982f,DISK], DatanodeInfoWithStorage[127.0.0.1:45855,DS-b47fef78-8a4f-4b81-b4cb-814fcafa636a,DISK], DatanodeInfoWithStorage[127.0.0.1:41930,DS-223cab6a-95b2-41fd-b5d1-1657abda8e15,DISK], DatanodeInfoWithStorage[127.0.0.1:37993,DS-1e591b90-2c14-4979-b4a8-8433cc975e20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5721
