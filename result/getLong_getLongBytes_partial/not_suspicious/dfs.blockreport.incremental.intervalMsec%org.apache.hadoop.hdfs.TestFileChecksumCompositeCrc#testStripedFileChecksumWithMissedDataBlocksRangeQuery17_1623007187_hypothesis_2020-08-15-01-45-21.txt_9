reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1327780306-172.17.0.3-1597455934366:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35067,DS-8037bfea-1fbe-40fe-bb55-0922331ae166,DISK], DatanodeInfoWithStorage[127.0.0.1:44597,DS-a0f958a8-ea4d-452a-977e-e51bbad56db3,DISK], DatanodeInfoWithStorage[127.0.0.1:45649,DS-6633b3e1-2c18-4aa1-b497-69f2d8893cef,DISK], DatanodeInfoWithStorage[127.0.0.1:35611,DS-c5c8c9d4-3c9a-4883-80d6-45078b11e16a,DISK], DatanodeInfoWithStorage[127.0.0.1:38890,DS-112f2b87-8549-4ec5-a331-e1eeb4ec8108,DISK], DatanodeInfoWithStorage[127.0.0.1:45265,DS-eb8bf964-ccc8-4f80-b833-5f404bd33316,DISK], DatanodeInfoWithStorage[127.0.0.1:40284,DS-f7ba429e-e044-4ee1-b698-81ec48b960fc,DISK], DatanodeInfoWithStorage[127.0.0.1:32900,DS-a961baca-3d79-4dcd-b61c-7244b3f3a1e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1327780306-172.17.0.3-1597455934366:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35067,DS-8037bfea-1fbe-40fe-bb55-0922331ae166,DISK], DatanodeInfoWithStorage[127.0.0.1:44597,DS-a0f958a8-ea4d-452a-977e-e51bbad56db3,DISK], DatanodeInfoWithStorage[127.0.0.1:45649,DS-6633b3e1-2c18-4aa1-b497-69f2d8893cef,DISK], DatanodeInfoWithStorage[127.0.0.1:35611,DS-c5c8c9d4-3c9a-4883-80d6-45078b11e16a,DISK], DatanodeInfoWithStorage[127.0.0.1:38890,DS-112f2b87-8549-4ec5-a331-e1eeb4ec8108,DISK], DatanodeInfoWithStorage[127.0.0.1:45265,DS-eb8bf964-ccc8-4f80-b833-5f404bd33316,DISK], DatanodeInfoWithStorage[127.0.0.1:40284,DS-f7ba429e-e044-4ee1-b698-81ec48b960fc,DISK], DatanodeInfoWithStorage[127.0.0.1:32900,DS-a961baca-3d79-4dcd-b61c-7244b3f3a1e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1507228215-172.17.0.3-1597456319776:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37779,DS-558b813c-a6f9-44cf-b3c1-ce750f51f319,DISK], DatanodeInfoWithStorage[127.0.0.1:42064,DS-1a5574ba-2ef2-4732-8bee-8ca9a64df879,DISK], DatanodeInfoWithStorage[127.0.0.1:32832,DS-eda23a04-89ea-4e91-ad11-2bf7f1b3e1df,DISK], DatanodeInfoWithStorage[127.0.0.1:38189,DS-5ddc18ef-a643-45b5-856d-aab654ac4035,DISK], DatanodeInfoWithStorage[127.0.0.1:45160,DS-c849af69-3aaa-4b30-aa9d-43569851f657,DISK], DatanodeInfoWithStorage[127.0.0.1:35403,DS-fbb0f1fd-5196-4496-a578-62b6c43a8f34,DISK], DatanodeInfoWithStorage[127.0.0.1:45800,DS-54b58855-1ced-4a8e-924c-04bffd5275f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33285,DS-3efaeaa2-a262-46e9-b86e-a54910ae0a43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1507228215-172.17.0.3-1597456319776:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37779,DS-558b813c-a6f9-44cf-b3c1-ce750f51f319,DISK], DatanodeInfoWithStorage[127.0.0.1:42064,DS-1a5574ba-2ef2-4732-8bee-8ca9a64df879,DISK], DatanodeInfoWithStorage[127.0.0.1:32832,DS-eda23a04-89ea-4e91-ad11-2bf7f1b3e1df,DISK], DatanodeInfoWithStorage[127.0.0.1:38189,DS-5ddc18ef-a643-45b5-856d-aab654ac4035,DISK], DatanodeInfoWithStorage[127.0.0.1:45160,DS-c849af69-3aaa-4b30-aa9d-43569851f657,DISK], DatanodeInfoWithStorage[127.0.0.1:35403,DS-fbb0f1fd-5196-4496-a578-62b6c43a8f34,DISK], DatanodeInfoWithStorage[127.0.0.1:45800,DS-54b58855-1ced-4a8e-924c-04bffd5275f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33285,DS-3efaeaa2-a262-46e9-b86e-a54910ae0a43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1959889709-172.17.0.3-1597457612402:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42659,DS-0750273d-ed4f-45fb-8d5b-7640c9d8a113,DISK], DatanodeInfoWithStorage[127.0.0.1:35377,DS-9c55cc76-d9bb-478a-a7c1-cb3060af49ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40919,DS-04587c61-72f8-42b7-b35e-b27e7d195e68,DISK], DatanodeInfoWithStorage[127.0.0.1:45930,DS-3345fbb0-ff9b-4889-bead-8312dae33d45,DISK], DatanodeInfoWithStorage[127.0.0.1:44368,DS-7c22d9a8-a4fe-48c9-8b78-54aaf9ab75e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40433,DS-a9dc6f97-8fea-4e67-a996-2d2b0353c3ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41608,DS-e5c35d67-ce4e-4df1-ab7c-b07857c467f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41336,DS-e5205900-001d-4b1c-99ec-3af9bb2ceda6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1959889709-172.17.0.3-1597457612402:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42659,DS-0750273d-ed4f-45fb-8d5b-7640c9d8a113,DISK], DatanodeInfoWithStorage[127.0.0.1:35377,DS-9c55cc76-d9bb-478a-a7c1-cb3060af49ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40919,DS-04587c61-72f8-42b7-b35e-b27e7d195e68,DISK], DatanodeInfoWithStorage[127.0.0.1:45930,DS-3345fbb0-ff9b-4889-bead-8312dae33d45,DISK], DatanodeInfoWithStorage[127.0.0.1:44368,DS-7c22d9a8-a4fe-48c9-8b78-54aaf9ab75e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40433,DS-a9dc6f97-8fea-4e67-a996-2d2b0353c3ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41608,DS-e5c35d67-ce4e-4df1-ab7c-b07857c467f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41336,DS-e5205900-001d-4b1c-99ec-3af9bb2ceda6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-344318775-172.17.0.3-1597457817951:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34116,DS-036733f8-03c3-4928-ac7b-0689a64b7c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42027,DS-352bc01a-5d5e-4500-ae45-453c5152887d,DISK], DatanodeInfoWithStorage[127.0.0.1:38897,DS-49cd0a63-4439-409e-8e4f-97ee59d3c6ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38739,DS-9d8410cb-0c44-4d8c-aaab-f64575d7c6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44165,DS-f1d6e42b-3d3e-4c0f-af44-f602e91d7f93,DISK], DatanodeInfoWithStorage[127.0.0.1:39521,DS-3bd3fc95-5adb-48c9-96e3-8957767b5273,DISK], DatanodeInfoWithStorage[127.0.0.1:44449,DS-ebc6282e-8c85-4e49-97e4-a8f0adb997b0,DISK], DatanodeInfoWithStorage[127.0.0.1:32781,DS-240fc3c6-1e2a-4cc3-a8d2-c83b0bae727c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-344318775-172.17.0.3-1597457817951:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34116,DS-036733f8-03c3-4928-ac7b-0689a64b7c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42027,DS-352bc01a-5d5e-4500-ae45-453c5152887d,DISK], DatanodeInfoWithStorage[127.0.0.1:38897,DS-49cd0a63-4439-409e-8e4f-97ee59d3c6ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38739,DS-9d8410cb-0c44-4d8c-aaab-f64575d7c6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44165,DS-f1d6e42b-3d3e-4c0f-af44-f602e91d7f93,DISK], DatanodeInfoWithStorage[127.0.0.1:39521,DS-3bd3fc95-5adb-48c9-96e3-8957767b5273,DISK], DatanodeInfoWithStorage[127.0.0.1:44449,DS-ebc6282e-8c85-4e49-97e4-a8f0adb997b0,DISK], DatanodeInfoWithStorage[127.0.0.1:32781,DS-240fc3c6-1e2a-4cc3-a8d2-c83b0bae727c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-705875997-172.17.0.3-1597458374699:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33694,DS-2483a7e7-86f4-49de-a60d-a217cb3ddcd0,DISK], DatanodeInfoWithStorage[127.0.0.1:35582,DS-14934300-d95e-4687-ab58-3e08c290b106,DISK], DatanodeInfoWithStorage[127.0.0.1:40991,DS-418edacd-2392-4b1c-be33-0da4f968e5fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37296,DS-8f32b8e5-5b8e-4c70-87c0-7d915850da31,DISK], DatanodeInfoWithStorage[127.0.0.1:35404,DS-526f9a24-84e9-4bb4-9b9d-9e0378cc452f,DISK], DatanodeInfoWithStorage[127.0.0.1:37844,DS-a133df07-47dc-43de-b262-c68d0aa20883,DISK], DatanodeInfoWithStorage[127.0.0.1:43214,DS-73627ea5-ba82-4778-8fbc-7d0fc7e48940,DISK], DatanodeInfoWithStorage[127.0.0.1:43963,DS-a00d90cb-89c0-4f75-aae6-eca26a61278e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-705875997-172.17.0.3-1597458374699:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33694,DS-2483a7e7-86f4-49de-a60d-a217cb3ddcd0,DISK], DatanodeInfoWithStorage[127.0.0.1:35582,DS-14934300-d95e-4687-ab58-3e08c290b106,DISK], DatanodeInfoWithStorage[127.0.0.1:40991,DS-418edacd-2392-4b1c-be33-0da4f968e5fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37296,DS-8f32b8e5-5b8e-4c70-87c0-7d915850da31,DISK], DatanodeInfoWithStorage[127.0.0.1:35404,DS-526f9a24-84e9-4bb4-9b9d-9e0378cc452f,DISK], DatanodeInfoWithStorage[127.0.0.1:37844,DS-a133df07-47dc-43de-b262-c68d0aa20883,DISK], DatanodeInfoWithStorage[127.0.0.1:43214,DS-73627ea5-ba82-4778-8fbc-7d0fc7e48940,DISK], DatanodeInfoWithStorage[127.0.0.1:43963,DS-a00d90cb-89c0-4f75-aae6-eca26a61278e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-193874873-172.17.0.3-1597458415881:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36059,DS-fdd84601-8938-4a77-b8b2-71ab344c093a,DISK], DatanodeInfoWithStorage[127.0.0.1:40132,DS-08df5222-8085-44f8-b921-e92d2f7366f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45837,DS-3ec197eb-02f3-43f1-853e-a88e9b644a95,DISK], DatanodeInfoWithStorage[127.0.0.1:42971,DS-371a0bde-738d-4234-826a-d0468102ff1a,DISK], DatanodeInfoWithStorage[127.0.0.1:46450,DS-07cd1cb4-aa2d-49b4-86b8-63edef54b1bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39009,DS-6346bdc2-7ba3-4825-bac5-cdce647f8ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:37592,DS-f0143237-21a9-402f-914b-04cd4785ec42,DISK], DatanodeInfoWithStorage[127.0.0.1:41615,DS-b49cdf79-66f6-4906-91ce-d6d7d83248d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-193874873-172.17.0.3-1597458415881:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36059,DS-fdd84601-8938-4a77-b8b2-71ab344c093a,DISK], DatanodeInfoWithStorage[127.0.0.1:40132,DS-08df5222-8085-44f8-b921-e92d2f7366f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45837,DS-3ec197eb-02f3-43f1-853e-a88e9b644a95,DISK], DatanodeInfoWithStorage[127.0.0.1:42971,DS-371a0bde-738d-4234-826a-d0468102ff1a,DISK], DatanodeInfoWithStorage[127.0.0.1:46450,DS-07cd1cb4-aa2d-49b4-86b8-63edef54b1bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39009,DS-6346bdc2-7ba3-4825-bac5-cdce647f8ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:37592,DS-f0143237-21a9-402f-914b-04cd4785ec42,DISK], DatanodeInfoWithStorage[127.0.0.1:41615,DS-b49cdf79-66f6-4906-91ce-d6d7d83248d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-551634696-172.17.0.3-1597458633950:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37633,DS-dbf9418c-a248-4ac8-a67e-1e4e9423e065,DISK], DatanodeInfoWithStorage[127.0.0.1:38556,DS-ebbac23c-cc38-48b3-b7da-ee401f45a239,DISK], DatanodeInfoWithStorage[127.0.0.1:38887,DS-8ba5485c-4207-4452-9aa7-d9338a59c49e,DISK], DatanodeInfoWithStorage[127.0.0.1:40379,DS-c8e89647-8010-4cfb-80d0-0d959408c388,DISK], DatanodeInfoWithStorage[127.0.0.1:38519,DS-f058161e-8574-4166-a330-2c5dab2393fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34033,DS-1d5c02fe-54e0-4f27-b128-16e8b52dd2ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45475,DS-504cc5cb-73c4-41c7-a870-92fdba5ff361,DISK], DatanodeInfoWithStorage[127.0.0.1:33992,DS-3793d362-0899-4f73-bf2a-4cf3eec0c199,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-551634696-172.17.0.3-1597458633950:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37633,DS-dbf9418c-a248-4ac8-a67e-1e4e9423e065,DISK], DatanodeInfoWithStorage[127.0.0.1:38556,DS-ebbac23c-cc38-48b3-b7da-ee401f45a239,DISK], DatanodeInfoWithStorage[127.0.0.1:38887,DS-8ba5485c-4207-4452-9aa7-d9338a59c49e,DISK], DatanodeInfoWithStorage[127.0.0.1:40379,DS-c8e89647-8010-4cfb-80d0-0d959408c388,DISK], DatanodeInfoWithStorage[127.0.0.1:38519,DS-f058161e-8574-4166-a330-2c5dab2393fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34033,DS-1d5c02fe-54e0-4f27-b128-16e8b52dd2ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45475,DS-504cc5cb-73c4-41c7-a870-92fdba5ff361,DISK], DatanodeInfoWithStorage[127.0.0.1:33992,DS-3793d362-0899-4f73-bf2a-4cf3eec0c199,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-591251393-172.17.0.3-1597459816562:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33561,DS-37bb1240-948c-4d78-b43f-61270e057f62,DISK], DatanodeInfoWithStorage[127.0.0.1:34344,DS-a1580548-9c6b-4156-904e-2cb19570b51c,DISK], DatanodeInfoWithStorage[127.0.0.1:42387,DS-3d0eb166-44b0-45f9-bdfc-1f00b6a75543,DISK], DatanodeInfoWithStorage[127.0.0.1:36279,DS-c342851a-1d36-4da0-beab-56789ab0464b,DISK], DatanodeInfoWithStorage[127.0.0.1:41560,DS-79b8f5bf-f8f2-45f3-9a78-504923f83112,DISK], DatanodeInfoWithStorage[127.0.0.1:43322,DS-455b3f19-1262-4c65-8a17-3d0f3fc53c56,DISK], DatanodeInfoWithStorage[127.0.0.1:44094,DS-d8d36880-80b4-4f55-a53b-ca671be4d505,DISK], DatanodeInfoWithStorage[127.0.0.1:42962,DS-071d8deb-cb00-4772-80b0-1b7f50738105,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-591251393-172.17.0.3-1597459816562:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33561,DS-37bb1240-948c-4d78-b43f-61270e057f62,DISK], DatanodeInfoWithStorage[127.0.0.1:34344,DS-a1580548-9c6b-4156-904e-2cb19570b51c,DISK], DatanodeInfoWithStorage[127.0.0.1:42387,DS-3d0eb166-44b0-45f9-bdfc-1f00b6a75543,DISK], DatanodeInfoWithStorage[127.0.0.1:36279,DS-c342851a-1d36-4da0-beab-56789ab0464b,DISK], DatanodeInfoWithStorage[127.0.0.1:41560,DS-79b8f5bf-f8f2-45f3-9a78-504923f83112,DISK], DatanodeInfoWithStorage[127.0.0.1:43322,DS-455b3f19-1262-4c65-8a17-3d0f3fc53c56,DISK], DatanodeInfoWithStorage[127.0.0.1:44094,DS-d8d36880-80b4-4f55-a53b-ca671be4d505,DISK], DatanodeInfoWithStorage[127.0.0.1:42962,DS-071d8deb-cb00-4772-80b0-1b7f50738105,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1846617853-172.17.0.3-1597460005952:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46646,DS-d9e6fcb6-f1e7-47a5-b61d-f20e4123f7c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44940,DS-f87c6908-4dd1-428b-a8dc-90286aaeb9f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34974,DS-fd272f06-a52b-461e-b4eb-d712ecac3ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:38046,DS-056e198e-d789-47e3-a1f5-216901b216b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42444,DS-209c1c0b-09aa-43b9-ad55-29574b0f0765,DISK], DatanodeInfoWithStorage[127.0.0.1:36095,DS-b8e1f9c7-bc72-4a27-9e99-2a295fdeeecd,DISK], DatanodeInfoWithStorage[127.0.0.1:35537,DS-40a9fb21-08db-421d-aa46-90aa0aff4236,DISK], DatanodeInfoWithStorage[127.0.0.1:41283,DS-5c5aca5c-5ea9-4103-ae12-6ff89fe06adb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1846617853-172.17.0.3-1597460005952:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46646,DS-d9e6fcb6-f1e7-47a5-b61d-f20e4123f7c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44940,DS-f87c6908-4dd1-428b-a8dc-90286aaeb9f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34974,DS-fd272f06-a52b-461e-b4eb-d712ecac3ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:38046,DS-056e198e-d789-47e3-a1f5-216901b216b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42444,DS-209c1c0b-09aa-43b9-ad55-29574b0f0765,DISK], DatanodeInfoWithStorage[127.0.0.1:36095,DS-b8e1f9c7-bc72-4a27-9e99-2a295fdeeecd,DISK], DatanodeInfoWithStorage[127.0.0.1:35537,DS-40a9fb21-08db-421d-aa46-90aa0aff4236,DISK], DatanodeInfoWithStorage[127.0.0.1:41283,DS-5c5aca5c-5ea9-4103-ae12-6ff89fe06adb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-928529602-172.17.0.3-1597460544277:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46333,DS-d961af10-06f2-4861-a871-de2acd5a7716,DISK], DatanodeInfoWithStorage[127.0.0.1:37630,DS-ff1d4ffd-184a-4fd8-b3a2-1cbe83d5b1d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41112,DS-e765002b-7ef9-4a23-855f-ce8e75eea8a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43858,DS-99b13776-f6f3-4516-9f03-0d18014c6be7,DISK], DatanodeInfoWithStorage[127.0.0.1:38282,DS-ddbe5d66-fd13-4e0d-bbc7-4970a6dff1e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40946,DS-c3d0d841-e3e1-4d6a-82f6-7276ffb892fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36503,DS-7a2656e2-6549-4ac0-8591-92cc8f0e3d73,DISK], DatanodeInfoWithStorage[127.0.0.1:44474,DS-0b7f5aca-8b6e-4004-b684-51d20f3f3425,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-928529602-172.17.0.3-1597460544277:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46333,DS-d961af10-06f2-4861-a871-de2acd5a7716,DISK], DatanodeInfoWithStorage[127.0.0.1:37630,DS-ff1d4ffd-184a-4fd8-b3a2-1cbe83d5b1d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41112,DS-e765002b-7ef9-4a23-855f-ce8e75eea8a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43858,DS-99b13776-f6f3-4516-9f03-0d18014c6be7,DISK], DatanodeInfoWithStorage[127.0.0.1:38282,DS-ddbe5d66-fd13-4e0d-bbc7-4970a6dff1e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40946,DS-c3d0d841-e3e1-4d6a-82f6-7276ffb892fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36503,DS-7a2656e2-6549-4ac0-8591-92cc8f0e3d73,DISK], DatanodeInfoWithStorage[127.0.0.1:44474,DS-0b7f5aca-8b6e-4004-b684-51d20f3f3425,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-131726609-172.17.0.3-1597460947139:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46797,DS-06de9d84-455c-4102-8056-779584fd7fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:41993,DS-fc15c5da-9643-482c-8845-9391394eb8e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44395,DS-dad19fd3-b9cf-4bfa-96a5-3616afd6ea72,DISK], DatanodeInfoWithStorage[127.0.0.1:39477,DS-929f60b6-17ac-49e2-8bed-9d3c125ca7f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43129,DS-01892b16-19dd-4176-b1eb-579a7e4074f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46380,DS-64cb123d-f0f1-40ae-84b7-99b9d8747dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:36955,DS-87edcfd1-1d39-4bd7-b4a1-47c078d79d46,DISK], DatanodeInfoWithStorage[127.0.0.1:37411,DS-19a41486-e71d-4ac7-9937-08274eb4a4be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-131726609-172.17.0.3-1597460947139:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46797,DS-06de9d84-455c-4102-8056-779584fd7fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:41993,DS-fc15c5da-9643-482c-8845-9391394eb8e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44395,DS-dad19fd3-b9cf-4bfa-96a5-3616afd6ea72,DISK], DatanodeInfoWithStorage[127.0.0.1:39477,DS-929f60b6-17ac-49e2-8bed-9d3c125ca7f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43129,DS-01892b16-19dd-4176-b1eb-579a7e4074f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46380,DS-64cb123d-f0f1-40ae-84b7-99b9d8747dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:36955,DS-87edcfd1-1d39-4bd7-b4a1-47c078d79d46,DISK], DatanodeInfoWithStorage[127.0.0.1:37411,DS-19a41486-e71d-4ac7-9937-08274eb4a4be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5450
