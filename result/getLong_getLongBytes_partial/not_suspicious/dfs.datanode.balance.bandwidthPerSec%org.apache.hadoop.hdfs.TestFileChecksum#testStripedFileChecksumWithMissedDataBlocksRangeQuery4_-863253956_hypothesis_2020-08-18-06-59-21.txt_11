reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 100m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 100m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1421385494-172.17.0.21-1597734336788:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37193,DS-27ef2a16-009e-403b-aa4f-bfdd829fbf3f,DISK], DatanodeInfoWithStorage[127.0.0.1:37317,DS-5aad4a00-c5ef-479c-989e-c5b8dab38475,DISK], DatanodeInfoWithStorage[127.0.0.1:45750,DS-a0d02afd-9673-4dac-afee-06055db83849,DISK], DatanodeInfoWithStorage[127.0.0.1:44971,DS-8a68a654-02fb-4993-bd1d-977e6ceab37d,DISK], DatanodeInfoWithStorage[127.0.0.1:44426,DS-708301fe-f2ad-446e-86d5-aa54d2f18452,DISK], DatanodeInfoWithStorage[127.0.0.1:44694,DS-76a8297a-7723-4a44-b723-343023af1bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:44649,DS-8477fa6b-8878-4a2a-a959-9914ff1c8dde,DISK], DatanodeInfoWithStorage[127.0.0.1:33615,DS-2b7790dd-ab96-45fe-89ec-a9234e998916,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1421385494-172.17.0.21-1597734336788:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37193,DS-27ef2a16-009e-403b-aa4f-bfdd829fbf3f,DISK], DatanodeInfoWithStorage[127.0.0.1:37317,DS-5aad4a00-c5ef-479c-989e-c5b8dab38475,DISK], DatanodeInfoWithStorage[127.0.0.1:45750,DS-a0d02afd-9673-4dac-afee-06055db83849,DISK], DatanodeInfoWithStorage[127.0.0.1:44971,DS-8a68a654-02fb-4993-bd1d-977e6ceab37d,DISK], DatanodeInfoWithStorage[127.0.0.1:44426,DS-708301fe-f2ad-446e-86d5-aa54d2f18452,DISK], DatanodeInfoWithStorage[127.0.0.1:44694,DS-76a8297a-7723-4a44-b723-343023af1bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:44649,DS-8477fa6b-8878-4a2a-a959-9914ff1c8dde,DISK], DatanodeInfoWithStorage[127.0.0.1:33615,DS-2b7790dd-ab96-45fe-89ec-a9234e998916,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 100m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-455572548-172.17.0.21-1597734635448:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45293,DS-6c183de4-54a0-472a-9f18-ceb5a08f5b06,DISK], DatanodeInfoWithStorage[127.0.0.1:39495,DS-bdbdb349-b1df-4c5f-92ec-30a0a65f1ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:40662,DS-6cd9a50c-230b-481c-bf04-4f0e33962536,DISK], DatanodeInfoWithStorage[127.0.0.1:43400,DS-027e4dc4-4134-4895-8593-8280cd2fba77,DISK], DatanodeInfoWithStorage[127.0.0.1:38225,DS-bf59593c-0f2a-43f4-bbd5-6549b3940539,DISK], DatanodeInfoWithStorage[127.0.0.1:44040,DS-b98a84b5-3bbc-4ccc-b007-e1e2fea40fde,DISK], DatanodeInfoWithStorage[127.0.0.1:33705,DS-902e88f9-dfc4-4f24-af69-f626b683d868,DISK], DatanodeInfoWithStorage[127.0.0.1:46451,DS-139bd239-9260-4d87-b87d-7c88f8e6c5a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-455572548-172.17.0.21-1597734635448:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45293,DS-6c183de4-54a0-472a-9f18-ceb5a08f5b06,DISK], DatanodeInfoWithStorage[127.0.0.1:39495,DS-bdbdb349-b1df-4c5f-92ec-30a0a65f1ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:40662,DS-6cd9a50c-230b-481c-bf04-4f0e33962536,DISK], DatanodeInfoWithStorage[127.0.0.1:43400,DS-027e4dc4-4134-4895-8593-8280cd2fba77,DISK], DatanodeInfoWithStorage[127.0.0.1:38225,DS-bf59593c-0f2a-43f4-bbd5-6549b3940539,DISK], DatanodeInfoWithStorage[127.0.0.1:44040,DS-b98a84b5-3bbc-4ccc-b007-e1e2fea40fde,DISK], DatanodeInfoWithStorage[127.0.0.1:33705,DS-902e88f9-dfc4-4f24-af69-f626b683d868,DISK], DatanodeInfoWithStorage[127.0.0.1:46451,DS-139bd239-9260-4d87-b87d-7c88f8e6c5a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 100m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1401861334-172.17.0.21-1597734875353:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34001,DS-0b010d46-3605-4076-9dc5-7066486b4ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:37933,DS-6f69fb71-15a7-481a-a7f4-4741920b9ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:39207,DS-02be96cc-ef6f-4003-9d03-be48731b61ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39325,DS-a4d79401-5bca-44ba-89c4-d7058514c327,DISK], DatanodeInfoWithStorage[127.0.0.1:45932,DS-cefd2714-7d13-4ada-b35d-766668ea75d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46086,DS-e54d1ee7-7941-46d4-9778-49ac029e9338,DISK], DatanodeInfoWithStorage[127.0.0.1:43635,DS-cbff3da4-097b-415c-ac63-edd64654c31d,DISK], DatanodeInfoWithStorage[127.0.0.1:35088,DS-af4bc98c-271d-49f4-8b59-3f153342ee60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1401861334-172.17.0.21-1597734875353:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34001,DS-0b010d46-3605-4076-9dc5-7066486b4ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:37933,DS-6f69fb71-15a7-481a-a7f4-4741920b9ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:39207,DS-02be96cc-ef6f-4003-9d03-be48731b61ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39325,DS-a4d79401-5bca-44ba-89c4-d7058514c327,DISK], DatanodeInfoWithStorage[127.0.0.1:45932,DS-cefd2714-7d13-4ada-b35d-766668ea75d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46086,DS-e54d1ee7-7941-46d4-9778-49ac029e9338,DISK], DatanodeInfoWithStorage[127.0.0.1:43635,DS-cbff3da4-097b-415c-ac63-edd64654c31d,DISK], DatanodeInfoWithStorage[127.0.0.1:35088,DS-af4bc98c-271d-49f4-8b59-3f153342ee60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 100m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1211193184-172.17.0.21-1597735214614:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39873,DS-637d5bc5-edeb-44d8-8a55-9d481aadaa0a,DISK], DatanodeInfoWithStorage[127.0.0.1:44734,DS-ed758b7c-fdad-42d0-b1eb-e8e1482f2564,DISK], DatanodeInfoWithStorage[127.0.0.1:42141,DS-ed1438bb-3546-4e8a-b1e3-22ce91bdaac5,DISK], DatanodeInfoWithStorage[127.0.0.1:35883,DS-8166938e-0fb6-4b17-be75-b54223fc2ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:44025,DS-09ef7a14-d52b-4798-aa20-3ecfae595d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:35780,DS-242b6372-8549-4714-a1da-8a223134649a,DISK], DatanodeInfoWithStorage[127.0.0.1:37861,DS-8d9be1c6-7497-4f36-9751-a479c91883b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35606,DS-ae60f7ec-ab3f-44d6-bfd8-b690f44a587e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1211193184-172.17.0.21-1597735214614:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39873,DS-637d5bc5-edeb-44d8-8a55-9d481aadaa0a,DISK], DatanodeInfoWithStorage[127.0.0.1:44734,DS-ed758b7c-fdad-42d0-b1eb-e8e1482f2564,DISK], DatanodeInfoWithStorage[127.0.0.1:42141,DS-ed1438bb-3546-4e8a-b1e3-22ce91bdaac5,DISK], DatanodeInfoWithStorage[127.0.0.1:35883,DS-8166938e-0fb6-4b17-be75-b54223fc2ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:44025,DS-09ef7a14-d52b-4798-aa20-3ecfae595d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:35780,DS-242b6372-8549-4714-a1da-8a223134649a,DISK], DatanodeInfoWithStorage[127.0.0.1:37861,DS-8d9be1c6-7497-4f36-9751-a479c91883b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35606,DS-ae60f7ec-ab3f-44d6-bfd8-b690f44a587e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 100m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-93419719-172.17.0.21-1597736257321:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33125,DS-b4e03282-cec4-4b94-a04c-c5102f2d9a53,DISK], DatanodeInfoWithStorage[127.0.0.1:45644,DS-ae2a5b22-763b-4792-a114-ad6b224d30d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38767,DS-3ea3ecca-a015-4e6e-84d4-a047b569e966,DISK], DatanodeInfoWithStorage[127.0.0.1:42704,DS-d0c2b050-e5b7-453a-be58-7b521bb0ee68,DISK], DatanodeInfoWithStorage[127.0.0.1:40535,DS-07e06825-261c-47cd-bb99-05e648854c51,DISK], DatanodeInfoWithStorage[127.0.0.1:44707,DS-a089c3a1-d75b-48d6-a525-2900ccd7ecb1,DISK], DatanodeInfoWithStorage[127.0.0.1:36036,DS-295a9fdb-36db-44bd-ba54-128298646f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:44575,DS-213a74c3-2f1e-4ca3-819e-145423a3a9f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-93419719-172.17.0.21-1597736257321:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33125,DS-b4e03282-cec4-4b94-a04c-c5102f2d9a53,DISK], DatanodeInfoWithStorage[127.0.0.1:45644,DS-ae2a5b22-763b-4792-a114-ad6b224d30d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38767,DS-3ea3ecca-a015-4e6e-84d4-a047b569e966,DISK], DatanodeInfoWithStorage[127.0.0.1:42704,DS-d0c2b050-e5b7-453a-be58-7b521bb0ee68,DISK], DatanodeInfoWithStorage[127.0.0.1:40535,DS-07e06825-261c-47cd-bb99-05e648854c51,DISK], DatanodeInfoWithStorage[127.0.0.1:44707,DS-a089c3a1-d75b-48d6-a525-2900ccd7ecb1,DISK], DatanodeInfoWithStorage[127.0.0.1:36036,DS-295a9fdb-36db-44bd-ba54-128298646f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:44575,DS-213a74c3-2f1e-4ca3-819e-145423a3a9f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 100m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2085348239-172.17.0.21-1597736926949:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32779,DS-dbf23fc8-0c5d-4cf6-8377-59f903e5bb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:37186,DS-83a556ff-4eac-4fa8-9164-755f78f450fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33879,DS-c3989445-8c78-456c-b0b9-68de417250b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33561,DS-51063ec4-f798-4d40-8eea-5bec4620cc01,DISK], DatanodeInfoWithStorage[127.0.0.1:37600,DS-d7d77f3a-90ba-4e39-9e99-ce7df351d87b,DISK], DatanodeInfoWithStorage[127.0.0.1:36439,DS-ce3729db-1e1b-4b3e-909a-76b048753f73,DISK], DatanodeInfoWithStorage[127.0.0.1:42746,DS-760c7655-cb65-4126-8bd4-aad9dab7fe7d,DISK], DatanodeInfoWithStorage[127.0.0.1:36660,DS-0dc9c24b-83d8-4c94-a8a7-0395de6beeda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2085348239-172.17.0.21-1597736926949:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32779,DS-dbf23fc8-0c5d-4cf6-8377-59f903e5bb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:37186,DS-83a556ff-4eac-4fa8-9164-755f78f450fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33879,DS-c3989445-8c78-456c-b0b9-68de417250b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33561,DS-51063ec4-f798-4d40-8eea-5bec4620cc01,DISK], DatanodeInfoWithStorage[127.0.0.1:37600,DS-d7d77f3a-90ba-4e39-9e99-ce7df351d87b,DISK], DatanodeInfoWithStorage[127.0.0.1:36439,DS-ce3729db-1e1b-4b3e-909a-76b048753f73,DISK], DatanodeInfoWithStorage[127.0.0.1:42746,DS-760c7655-cb65-4126-8bd4-aad9dab7fe7d,DISK], DatanodeInfoWithStorage[127.0.0.1:36660,DS-0dc9c24b-83d8-4c94-a8a7-0395de6beeda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 100m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-172976669-172.17.0.21-1597737276850:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34001,DS-75d2b8c5-9e2b-42b2-840a-07cdc655d328,DISK], DatanodeInfoWithStorage[127.0.0.1:42929,DS-bc893033-2b42-4007-9a9d-6eacb218fe45,DISK], DatanodeInfoWithStorage[127.0.0.1:46486,DS-520aed0f-ae76-405b-bb92-af403274743b,DISK], DatanodeInfoWithStorage[127.0.0.1:37460,DS-72bcf7ec-b6d4-4f09-81ac-bcc17279af1b,DISK], DatanodeInfoWithStorage[127.0.0.1:37716,DS-2f712b6d-7b4b-4f13-8108-4389e72a9db9,DISK], DatanodeInfoWithStorage[127.0.0.1:34011,DS-7403481b-0409-40f3-b5c4-929160cdcdcd,DISK], DatanodeInfoWithStorage[127.0.0.1:37439,DS-ac97ed91-979c-4caf-be7b-a68ffebe3c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:35539,DS-d711b333-331a-4eb1-a8d0-977e7e43d0e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-172976669-172.17.0.21-1597737276850:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34001,DS-75d2b8c5-9e2b-42b2-840a-07cdc655d328,DISK], DatanodeInfoWithStorage[127.0.0.1:42929,DS-bc893033-2b42-4007-9a9d-6eacb218fe45,DISK], DatanodeInfoWithStorage[127.0.0.1:46486,DS-520aed0f-ae76-405b-bb92-af403274743b,DISK], DatanodeInfoWithStorage[127.0.0.1:37460,DS-72bcf7ec-b6d4-4f09-81ac-bcc17279af1b,DISK], DatanodeInfoWithStorage[127.0.0.1:37716,DS-2f712b6d-7b4b-4f13-8108-4389e72a9db9,DISK], DatanodeInfoWithStorage[127.0.0.1:34011,DS-7403481b-0409-40f3-b5c4-929160cdcdcd,DISK], DatanodeInfoWithStorage[127.0.0.1:37439,DS-ac97ed91-979c-4caf-be7b-a68ffebe3c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:35539,DS-d711b333-331a-4eb1-a8d0-977e7e43d0e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 100m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-954886570-172.17.0.21-1597737363149:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43270,DS-6416a1f7-09f2-4bf9-aaca-742f191112cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38894,DS-92561338-c7d6-4c29-87aa-4b95a7ecf7b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44732,DS-c5d32064-383a-4214-a112-e9fb5934658d,DISK], DatanodeInfoWithStorage[127.0.0.1:34645,DS-a6e0c322-f16b-44bc-a5f2-461fb8878388,DISK], DatanodeInfoWithStorage[127.0.0.1:34311,DS-6c9aa449-e1dd-4726-9786-4445cd23c676,DISK], DatanodeInfoWithStorage[127.0.0.1:46493,DS-90f0c51c-9a6a-426c-aa39-4c03ef635685,DISK], DatanodeInfoWithStorage[127.0.0.1:44292,DS-02c3f6d3-20d2-40d0-9636-6bbdf597333c,DISK], DatanodeInfoWithStorage[127.0.0.1:35765,DS-358ca9de-d3cd-4318-9771-a30591cb2257,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-954886570-172.17.0.21-1597737363149:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43270,DS-6416a1f7-09f2-4bf9-aaca-742f191112cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38894,DS-92561338-c7d6-4c29-87aa-4b95a7ecf7b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44732,DS-c5d32064-383a-4214-a112-e9fb5934658d,DISK], DatanodeInfoWithStorage[127.0.0.1:34645,DS-a6e0c322-f16b-44bc-a5f2-461fb8878388,DISK], DatanodeInfoWithStorage[127.0.0.1:34311,DS-6c9aa449-e1dd-4726-9786-4445cd23c676,DISK], DatanodeInfoWithStorage[127.0.0.1:46493,DS-90f0c51c-9a6a-426c-aa39-4c03ef635685,DISK], DatanodeInfoWithStorage[127.0.0.1:44292,DS-02c3f6d3-20d2-40d0-9636-6bbdf597333c,DISK], DatanodeInfoWithStorage[127.0.0.1:35765,DS-358ca9de-d3cd-4318-9771-a30591cb2257,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 100m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-351957532-172.17.0.21-1597737476156:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41919,DS-19024ed4-244c-4b0b-b169-9dca34dad1f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39727,DS-4e097f60-d3c3-4414-a92c-449c22dbaa52,DISK], DatanodeInfoWithStorage[127.0.0.1:36541,DS-d8333447-a74d-46b5-80e7-80cc3585aaf5,DISK], DatanodeInfoWithStorage[127.0.0.1:38718,DS-c149115e-2496-4de4-a64e-1f33c610e13d,DISK], DatanodeInfoWithStorage[127.0.0.1:44424,DS-4a45cfbd-cb70-45a0-90e2-6610c16b0785,DISK], DatanodeInfoWithStorage[127.0.0.1:43384,DS-907c4316-a852-4ef0-9ce0-b3d417e2c453,DISK], DatanodeInfoWithStorage[127.0.0.1:46487,DS-76c6832b-1aef-4510-a9ff-41ca0f03b520,DISK], DatanodeInfoWithStorage[127.0.0.1:41971,DS-730b87d6-5f61-46c0-8dbf-6d5007d7df73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-351957532-172.17.0.21-1597737476156:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41919,DS-19024ed4-244c-4b0b-b169-9dca34dad1f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39727,DS-4e097f60-d3c3-4414-a92c-449c22dbaa52,DISK], DatanodeInfoWithStorage[127.0.0.1:36541,DS-d8333447-a74d-46b5-80e7-80cc3585aaf5,DISK], DatanodeInfoWithStorage[127.0.0.1:38718,DS-c149115e-2496-4de4-a64e-1f33c610e13d,DISK], DatanodeInfoWithStorage[127.0.0.1:44424,DS-4a45cfbd-cb70-45a0-90e2-6610c16b0785,DISK], DatanodeInfoWithStorage[127.0.0.1:43384,DS-907c4316-a852-4ef0-9ce0-b3d417e2c453,DISK], DatanodeInfoWithStorage[127.0.0.1:46487,DS-76c6832b-1aef-4510-a9ff-41ca0f03b520,DISK], DatanodeInfoWithStorage[127.0.0.1:41971,DS-730b87d6-5f61-46c0-8dbf-6d5007d7df73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 100m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-954566728-172.17.0.21-1597737998042:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38945,DS-8b453357-714a-4cf6-a33d-d23f1bbd1970,DISK], DatanodeInfoWithStorage[127.0.0.1:33242,DS-a1c7c592-6364-49d1-a22a-36ab3e8ecbf3,DISK], DatanodeInfoWithStorage[127.0.0.1:44554,DS-87b5de47-8713-4a39-a8a4-2c46dbe03df1,DISK], DatanodeInfoWithStorage[127.0.0.1:38364,DS-3c5b96e0-308a-4dee-96b2-42eb1b07995d,DISK], DatanodeInfoWithStorage[127.0.0.1:46200,DS-0c92da25-2d58-4264-9abb-178559304e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:41459,DS-05beb2fd-89ea-4ed4-b0a5-5de50ca93354,DISK], DatanodeInfoWithStorage[127.0.0.1:38655,DS-04ce330d-061b-4962-911f-36247eae6843,DISK], DatanodeInfoWithStorage[127.0.0.1:40003,DS-c6c1d81d-ef0b-4ce7-a8a3-fef665664825,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-954566728-172.17.0.21-1597737998042:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38945,DS-8b453357-714a-4cf6-a33d-d23f1bbd1970,DISK], DatanodeInfoWithStorage[127.0.0.1:33242,DS-a1c7c592-6364-49d1-a22a-36ab3e8ecbf3,DISK], DatanodeInfoWithStorage[127.0.0.1:44554,DS-87b5de47-8713-4a39-a8a4-2c46dbe03df1,DISK], DatanodeInfoWithStorage[127.0.0.1:38364,DS-3c5b96e0-308a-4dee-96b2-42eb1b07995d,DISK], DatanodeInfoWithStorage[127.0.0.1:46200,DS-0c92da25-2d58-4264-9abb-178559304e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:41459,DS-05beb2fd-89ea-4ed4-b0a5-5de50ca93354,DISK], DatanodeInfoWithStorage[127.0.0.1:38655,DS-04ce330d-061b-4962-911f-36247eae6843,DISK], DatanodeInfoWithStorage[127.0.0.1:40003,DS-c6c1d81d-ef0b-4ce7-a8a3-fef665664825,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 100m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2045226334-172.17.0.21-1597738085413:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34468,DS-aec1ac3e-3e78-45d0-9750-358536ba8989,DISK], DatanodeInfoWithStorage[127.0.0.1:46336,DS-d6245c3b-45c8-4d0e-ae40-d64c6fdeb66f,DISK], DatanodeInfoWithStorage[127.0.0.1:37589,DS-ca3a7d58-0f0b-42c8-8187-5d04365a8d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42303,DS-340deeb1-96a1-4fd0-bd0f-7a619d0459ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36345,DS-e99ae794-70c3-4c65-b0aa-382eea3870ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45403,DS-feeb3c38-bd23-41a0-aa42-9d7d0b04a8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46035,DS-af0ea5e4-13b1-4980-b435-f79268309e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44857,DS-7b766f34-0210-4118-ba3e-009df55c1a2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2045226334-172.17.0.21-1597738085413:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34468,DS-aec1ac3e-3e78-45d0-9750-358536ba8989,DISK], DatanodeInfoWithStorage[127.0.0.1:46336,DS-d6245c3b-45c8-4d0e-ae40-d64c6fdeb66f,DISK], DatanodeInfoWithStorage[127.0.0.1:37589,DS-ca3a7d58-0f0b-42c8-8187-5d04365a8d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42303,DS-340deeb1-96a1-4fd0-bd0f-7a619d0459ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36345,DS-e99ae794-70c3-4c65-b0aa-382eea3870ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45403,DS-feeb3c38-bd23-41a0-aa42-9d7d0b04a8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46035,DS-af0ea5e4-13b1-4980-b435-f79268309e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44857,DS-7b766f34-0210-4118-ba3e-009df55c1a2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 100m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1745998808-172.17.0.21-1597739018413:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39742,DS-06ce0c23-7e78-4690-8b81-4fd010e3c659,DISK], DatanodeInfoWithStorage[127.0.0.1:44021,DS-ec4bc2c8-eb09-4d7d-b256-ac285bf83076,DISK], DatanodeInfoWithStorage[127.0.0.1:44112,DS-46d2fa2a-66b6-4fd7-836f-0a4bb0af7c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45117,DS-ebd690ed-9e86-4795-ad00-bc8934d01976,DISK], DatanodeInfoWithStorage[127.0.0.1:44077,DS-431fb9ae-516e-4e8b-8309-25ad2d00a84c,DISK], DatanodeInfoWithStorage[127.0.0.1:44759,DS-2e6154ab-cda9-4d55-8638-4336f88a665c,DISK], DatanodeInfoWithStorage[127.0.0.1:34869,DS-aee24e20-87fe-4e9c-9714-dddaf8785d44,DISK], DatanodeInfoWithStorage[127.0.0.1:46153,DS-656cfdbd-8d6b-45c3-94b7-7d0842c5c644,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1745998808-172.17.0.21-1597739018413:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39742,DS-06ce0c23-7e78-4690-8b81-4fd010e3c659,DISK], DatanodeInfoWithStorage[127.0.0.1:44021,DS-ec4bc2c8-eb09-4d7d-b256-ac285bf83076,DISK], DatanodeInfoWithStorage[127.0.0.1:44112,DS-46d2fa2a-66b6-4fd7-836f-0a4bb0af7c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45117,DS-ebd690ed-9e86-4795-ad00-bc8934d01976,DISK], DatanodeInfoWithStorage[127.0.0.1:44077,DS-431fb9ae-516e-4e8b-8309-25ad2d00a84c,DISK], DatanodeInfoWithStorage[127.0.0.1:44759,DS-2e6154ab-cda9-4d55-8638-4336f88a665c,DISK], DatanodeInfoWithStorage[127.0.0.1:34869,DS-aee24e20-87fe-4e9c-9714-dddaf8785d44,DISK], DatanodeInfoWithStorage[127.0.0.1:46153,DS-656cfdbd-8d6b-45c3-94b7-7d0842c5c644,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 100m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-4652403-172.17.0.21-1597739112991:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33357,DS-607f1a87-add9-4cdc-b575-a26aca24d54f,DISK], DatanodeInfoWithStorage[127.0.0.1:41903,DS-ca5faed6-f650-4877-a2bf-5b45b77b49bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40249,DS-3ca15980-8835-46ef-a08f-5f2da9b7a484,DISK], DatanodeInfoWithStorage[127.0.0.1:36252,DS-806e4279-f22d-4784-a6f1-8b32d65d8cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:36659,DS-a79d585a-1149-4c22-bb0c-1bed6d6e9d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39679,DS-c6b3ab57-aa3e-4c02-ad03-4de729f2d974,DISK], DatanodeInfoWithStorage[127.0.0.1:37510,DS-e1a616a2-2d64-4c65-ba0e-441e008af646,DISK], DatanodeInfoWithStorage[127.0.0.1:42924,DS-1be9c8b6-8c5f-42c6-a8d7-ef402b9d6031,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-4652403-172.17.0.21-1597739112991:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33357,DS-607f1a87-add9-4cdc-b575-a26aca24d54f,DISK], DatanodeInfoWithStorage[127.0.0.1:41903,DS-ca5faed6-f650-4877-a2bf-5b45b77b49bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40249,DS-3ca15980-8835-46ef-a08f-5f2da9b7a484,DISK], DatanodeInfoWithStorage[127.0.0.1:36252,DS-806e4279-f22d-4784-a6f1-8b32d65d8cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:36659,DS-a79d585a-1149-4c22-bb0c-1bed6d6e9d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39679,DS-c6b3ab57-aa3e-4c02-ad03-4de729f2d974,DISK], DatanodeInfoWithStorage[127.0.0.1:37510,DS-e1a616a2-2d64-4c65-ba0e-441e008af646,DISK], DatanodeInfoWithStorage[127.0.0.1:42924,DS-1be9c8b6-8c5f-42c6-a8d7-ef402b9d6031,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 100m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1143789158-172.17.0.21-1597739184077:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38631,DS-ff2f504f-5a1e-4c34-9f8c-6faa5ffebeb2,DISK], DatanodeInfoWithStorage[127.0.0.1:34966,DS-2eac232d-7afc-4cab-90f9-05ccc673020f,DISK], DatanodeInfoWithStorage[127.0.0.1:41905,DS-21f75c9a-9ac5-484a-bcca-17be23cb1c98,DISK], DatanodeInfoWithStorage[127.0.0.1:45898,DS-e62e40e0-8305-4bf2-8f9c-4c60c2af778c,DISK], DatanodeInfoWithStorage[127.0.0.1:44995,DS-a371e665-7618-4827-a420-172d52172374,DISK], DatanodeInfoWithStorage[127.0.0.1:34086,DS-cf820f6c-1a64-4f34-bec7-545ccfbb7538,DISK], DatanodeInfoWithStorage[127.0.0.1:46597,DS-558cd924-ceb7-440c-86e8-f3c3bbbce208,DISK], DatanodeInfoWithStorage[127.0.0.1:36383,DS-2809d6e3-5b04-40ee-95d6-0412d663c751,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1143789158-172.17.0.21-1597739184077:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38631,DS-ff2f504f-5a1e-4c34-9f8c-6faa5ffebeb2,DISK], DatanodeInfoWithStorage[127.0.0.1:34966,DS-2eac232d-7afc-4cab-90f9-05ccc673020f,DISK], DatanodeInfoWithStorage[127.0.0.1:41905,DS-21f75c9a-9ac5-484a-bcca-17be23cb1c98,DISK], DatanodeInfoWithStorage[127.0.0.1:45898,DS-e62e40e0-8305-4bf2-8f9c-4c60c2af778c,DISK], DatanodeInfoWithStorage[127.0.0.1:44995,DS-a371e665-7618-4827-a420-172d52172374,DISK], DatanodeInfoWithStorage[127.0.0.1:34086,DS-cf820f6c-1a64-4f34-bec7-545ccfbb7538,DISK], DatanodeInfoWithStorage[127.0.0.1:46597,DS-558cd924-ceb7-440c-86e8-f3c3bbbce208,DISK], DatanodeInfoWithStorage[127.0.0.1:36383,DS-2809d6e3-5b04-40ee-95d6-0412d663c751,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 100m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1746789025-172.17.0.21-1597739409100:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37775,DS-bd797de0-e867-41b6-82f4-a9d39d755579,DISK], DatanodeInfoWithStorage[127.0.0.1:42654,DS-2115de22-0a55-4a2b-8c6d-0b38097dd82e,DISK], DatanodeInfoWithStorage[127.0.0.1:46608,DS-2165ecde-c69f-419c-920b-d650c9a64cc7,DISK], DatanodeInfoWithStorage[127.0.0.1:38150,DS-699b2ed6-b710-4c88-b597-eb60b7b4b817,DISK], DatanodeInfoWithStorage[127.0.0.1:43950,DS-a2442b03-3013-4df8-90bb-f16826181b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:44438,DS-8c392c8e-a913-459b-aadd-1c377d7236cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43502,DS-3cffb08f-9c29-4d6c-87d0-d7232b54fd75,DISK], DatanodeInfoWithStorage[127.0.0.1:41197,DS-b99fee00-4799-4019-b8c1-c468fee00bfa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1746789025-172.17.0.21-1597739409100:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37775,DS-bd797de0-e867-41b6-82f4-a9d39d755579,DISK], DatanodeInfoWithStorage[127.0.0.1:42654,DS-2115de22-0a55-4a2b-8c6d-0b38097dd82e,DISK], DatanodeInfoWithStorage[127.0.0.1:46608,DS-2165ecde-c69f-419c-920b-d650c9a64cc7,DISK], DatanodeInfoWithStorage[127.0.0.1:38150,DS-699b2ed6-b710-4c88-b597-eb60b7b4b817,DISK], DatanodeInfoWithStorage[127.0.0.1:43950,DS-a2442b03-3013-4df8-90bb-f16826181b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:44438,DS-8c392c8e-a913-459b-aadd-1c377d7236cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43502,DS-3cffb08f-9c29-4d6c-87d0-d7232b54fd75,DISK], DatanodeInfoWithStorage[127.0.0.1:41197,DS-b99fee00-4799-4019-b8c1-c468fee00bfa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 100m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-837301142-172.17.0.21-1597739587061:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33011,DS-174f54a8-104a-44bd-a10f-dd99f5d7c345,DISK], DatanodeInfoWithStorage[127.0.0.1:44704,DS-01cd2066-c882-42f7-b920-212f8dd25890,DISK], DatanodeInfoWithStorage[127.0.0.1:35224,DS-70d871d1-7c15-4859-9911-b6acfbba2e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:39987,DS-1810f02c-44a6-47c9-8879-871d08d52c10,DISK], DatanodeInfoWithStorage[127.0.0.1:33930,DS-5068f38d-ef01-424d-891c-1947056cfac6,DISK], DatanodeInfoWithStorage[127.0.0.1:38705,DS-0f7b065d-2575-4705-965e-2f4538f9a8a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45244,DS-df113857-ec99-4345-b479-759d62207feb,DISK], DatanodeInfoWithStorage[127.0.0.1:40465,DS-cf4fcc7a-16f2-47c9-a4b7-90f86368d4e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-837301142-172.17.0.21-1597739587061:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33011,DS-174f54a8-104a-44bd-a10f-dd99f5d7c345,DISK], DatanodeInfoWithStorage[127.0.0.1:44704,DS-01cd2066-c882-42f7-b920-212f8dd25890,DISK], DatanodeInfoWithStorage[127.0.0.1:35224,DS-70d871d1-7c15-4859-9911-b6acfbba2e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:39987,DS-1810f02c-44a6-47c9-8879-871d08d52c10,DISK], DatanodeInfoWithStorage[127.0.0.1:33930,DS-5068f38d-ef01-424d-891c-1947056cfac6,DISK], DatanodeInfoWithStorage[127.0.0.1:38705,DS-0f7b065d-2575-4705-965e-2f4538f9a8a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45244,DS-df113857-ec99-4345-b479-759d62207feb,DISK], DatanodeInfoWithStorage[127.0.0.1:40465,DS-cf4fcc7a-16f2-47c9-a4b7-90f86368d4e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5685
