reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-22662210-172.17.0.17-1597664647656:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34156,DS-a3c4c0f6-e387-4d89-a2d8-46a216022ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:39830,DS-bc2fd7b4-b2cb-4f3c-afbb-41cc32ff6737,DISK], DatanodeInfoWithStorage[127.0.0.1:42451,DS-2a4b662e-133f-407b-95f3-f63326d4c942,DISK], DatanodeInfoWithStorage[127.0.0.1:45853,DS-ff807abe-5cd6-4cf2-ba78-ab3d4d92ac65,DISK], DatanodeInfoWithStorage[127.0.0.1:40797,DS-8c7220d8-083e-44d2-aabb-ae21f6008637,DISK], DatanodeInfoWithStorage[127.0.0.1:39535,DS-06dc3a10-f563-400b-a730-f601da6897c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41492,DS-6317dee1-4248-4026-b291-517c2a2315c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35072,DS-501d867f-3d49-49a7-b660-31c6d7d114b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-22662210-172.17.0.17-1597664647656:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34156,DS-a3c4c0f6-e387-4d89-a2d8-46a216022ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:39830,DS-bc2fd7b4-b2cb-4f3c-afbb-41cc32ff6737,DISK], DatanodeInfoWithStorage[127.0.0.1:42451,DS-2a4b662e-133f-407b-95f3-f63326d4c942,DISK], DatanodeInfoWithStorage[127.0.0.1:45853,DS-ff807abe-5cd6-4cf2-ba78-ab3d4d92ac65,DISK], DatanodeInfoWithStorage[127.0.0.1:40797,DS-8c7220d8-083e-44d2-aabb-ae21f6008637,DISK], DatanodeInfoWithStorage[127.0.0.1:39535,DS-06dc3a10-f563-400b-a730-f601da6897c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41492,DS-6317dee1-4248-4026-b291-517c2a2315c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35072,DS-501d867f-3d49-49a7-b660-31c6d7d114b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1430402581-172.17.0.17-1597664942408:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46133,DS-b5d713a7-784c-4911-8019-ffedea24cf48,DISK], DatanodeInfoWithStorage[127.0.0.1:35455,DS-bb4b1f22-11f3-4551-a5ee-fe5a230fbe7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44307,DS-ccc0c7f0-8851-46d6-9204-8d02118a52e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33369,DS-163c3775-b66c-4b0a-9335-ed39a9f977e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33429,DS-6151e0e7-4fed-4b3b-a2ea-5a58608db77e,DISK], DatanodeInfoWithStorage[127.0.0.1:38447,DS-af20ce07-1e3f-4071-bdea-7c4be0404eec,DISK], DatanodeInfoWithStorage[127.0.0.1:40546,DS-658cbdfc-2db9-4865-b3f0-356ee4a8d2a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38665,DS-97e827bd-0979-4515-aa09-70eb25a5d32f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1430402581-172.17.0.17-1597664942408:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46133,DS-b5d713a7-784c-4911-8019-ffedea24cf48,DISK], DatanodeInfoWithStorage[127.0.0.1:35455,DS-bb4b1f22-11f3-4551-a5ee-fe5a230fbe7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44307,DS-ccc0c7f0-8851-46d6-9204-8d02118a52e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33369,DS-163c3775-b66c-4b0a-9335-ed39a9f977e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33429,DS-6151e0e7-4fed-4b3b-a2ea-5a58608db77e,DISK], DatanodeInfoWithStorage[127.0.0.1:38447,DS-af20ce07-1e3f-4071-bdea-7c4be0404eec,DISK], DatanodeInfoWithStorage[127.0.0.1:40546,DS-658cbdfc-2db9-4865-b3f0-356ee4a8d2a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38665,DS-97e827bd-0979-4515-aa09-70eb25a5d32f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-326163813-172.17.0.17-1597665084058:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36820,DS-d8716712-e3e2-4bb7-9416-9cd69b6c4aee,DISK], DatanodeInfoWithStorage[127.0.0.1:40138,DS-baa5bff9-7d3b-483b-99a6-ea96f516760e,DISK], DatanodeInfoWithStorage[127.0.0.1:36907,DS-90631184-8197-4ce1-a0b8-fd235f93be8b,DISK], DatanodeInfoWithStorage[127.0.0.1:40434,DS-678c5e55-683f-4c75-b284-6fc256c064e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33288,DS-625b0d0d-6ee3-40c8-8f35-44f1cdc73cba,DISK], DatanodeInfoWithStorage[127.0.0.1:39361,DS-537c7738-d50d-4c02-8e0e-002fda18983c,DISK], DatanodeInfoWithStorage[127.0.0.1:43010,DS-ae971220-c8b8-4885-8062-0c758867f13d,DISK], DatanodeInfoWithStorage[127.0.0.1:37371,DS-19be0df3-b35a-455e-b63c-b333d3116415,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-326163813-172.17.0.17-1597665084058:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36820,DS-d8716712-e3e2-4bb7-9416-9cd69b6c4aee,DISK], DatanodeInfoWithStorage[127.0.0.1:40138,DS-baa5bff9-7d3b-483b-99a6-ea96f516760e,DISK], DatanodeInfoWithStorage[127.0.0.1:36907,DS-90631184-8197-4ce1-a0b8-fd235f93be8b,DISK], DatanodeInfoWithStorage[127.0.0.1:40434,DS-678c5e55-683f-4c75-b284-6fc256c064e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33288,DS-625b0d0d-6ee3-40c8-8f35-44f1cdc73cba,DISK], DatanodeInfoWithStorage[127.0.0.1:39361,DS-537c7738-d50d-4c02-8e0e-002fda18983c,DISK], DatanodeInfoWithStorage[127.0.0.1:43010,DS-ae971220-c8b8-4885-8062-0c758867f13d,DISK], DatanodeInfoWithStorage[127.0.0.1:37371,DS-19be0df3-b35a-455e-b63c-b333d3116415,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-464227371-172.17.0.17-1597665600395:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42638,DS-31643839-a2a6-47d0-ba0f-ea4f375fbbaa,DISK], DatanodeInfoWithStorage[127.0.0.1:42242,DS-12c2ae52-285f-46de-b234-4a77ef28eaae,DISK], DatanodeInfoWithStorage[127.0.0.1:45465,DS-b725d6e6-77df-4ca5-9ca4-fd85a2488c88,DISK], DatanodeInfoWithStorage[127.0.0.1:41129,DS-00e3d52a-4397-4c76-930a-9488c9016eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:35208,DS-117f3417-9303-47db-a87e-426ea11914bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34622,DS-fb1c478c-c3d1-4713-8dd4-76d959e2c2df,DISK], DatanodeInfoWithStorage[127.0.0.1:40631,DS-6de0cb4e-c3fc-41ac-9c13-55473a3e6ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:46178,DS-a257c033-3aa0-4f34-9bd3-33e78566eb85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-464227371-172.17.0.17-1597665600395:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42638,DS-31643839-a2a6-47d0-ba0f-ea4f375fbbaa,DISK], DatanodeInfoWithStorage[127.0.0.1:42242,DS-12c2ae52-285f-46de-b234-4a77ef28eaae,DISK], DatanodeInfoWithStorage[127.0.0.1:45465,DS-b725d6e6-77df-4ca5-9ca4-fd85a2488c88,DISK], DatanodeInfoWithStorage[127.0.0.1:41129,DS-00e3d52a-4397-4c76-930a-9488c9016eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:35208,DS-117f3417-9303-47db-a87e-426ea11914bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34622,DS-fb1c478c-c3d1-4713-8dd4-76d959e2c2df,DISK], DatanodeInfoWithStorage[127.0.0.1:40631,DS-6de0cb4e-c3fc-41ac-9c13-55473a3e6ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:46178,DS-a257c033-3aa0-4f34-9bd3-33e78566eb85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1888033503-172.17.0.17-1597666152141:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43772,DS-260bb111-11f4-4204-93d0-465be527cca8,DISK], DatanodeInfoWithStorage[127.0.0.1:38352,DS-160e7f3c-612c-4abe-8a35-47a7eaf58536,DISK], DatanodeInfoWithStorage[127.0.0.1:38711,DS-623d4738-9c3b-4125-aa94-0afae728276c,DISK], DatanodeInfoWithStorage[127.0.0.1:34517,DS-5f20c096-7c3b-4e92-b62a-e1a468223110,DISK], DatanodeInfoWithStorage[127.0.0.1:40333,DS-a913bd0d-5148-4319-8ad1-0018349b734a,DISK], DatanodeInfoWithStorage[127.0.0.1:33153,DS-bc63c8f3-66e5-4482-8088-cc89c8ae2d56,DISK], DatanodeInfoWithStorage[127.0.0.1:43062,DS-41f4954e-968e-48a9-b4d1-dc09db3cd921,DISK], DatanodeInfoWithStorage[127.0.0.1:39903,DS-a6d4f366-8895-4581-8fe5-f8c354dcffa7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1888033503-172.17.0.17-1597666152141:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43772,DS-260bb111-11f4-4204-93d0-465be527cca8,DISK], DatanodeInfoWithStorage[127.0.0.1:38352,DS-160e7f3c-612c-4abe-8a35-47a7eaf58536,DISK], DatanodeInfoWithStorage[127.0.0.1:38711,DS-623d4738-9c3b-4125-aa94-0afae728276c,DISK], DatanodeInfoWithStorage[127.0.0.1:34517,DS-5f20c096-7c3b-4e92-b62a-e1a468223110,DISK], DatanodeInfoWithStorage[127.0.0.1:40333,DS-a913bd0d-5148-4319-8ad1-0018349b734a,DISK], DatanodeInfoWithStorage[127.0.0.1:33153,DS-bc63c8f3-66e5-4482-8088-cc89c8ae2d56,DISK], DatanodeInfoWithStorage[127.0.0.1:43062,DS-41f4954e-968e-48a9-b4d1-dc09db3cd921,DISK], DatanodeInfoWithStorage[127.0.0.1:39903,DS-a6d4f366-8895-4581-8fe5-f8c354dcffa7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1047123671-172.17.0.17-1597666526263:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34293,DS-b410ba58-6643-43c3-8005-35fafa3695d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33752,DS-4a58a90d-39ad-4a76-a8d6-59b4c182fd6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36297,DS-c35dceae-e727-41b8-9b87-1326cc13d1ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37071,DS-9317e0a8-5e6a-4243-b7bf-996a14ca06b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34735,DS-d85804ff-e428-48ad-93db-9d6134988bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:32955,DS-aba939e9-30ba-4cbd-805d-f35cd6f3cf00,DISK], DatanodeInfoWithStorage[127.0.0.1:38843,DS-4cf02b6c-d9a9-4339-b9e7-90e0ece9aa97,DISK], DatanodeInfoWithStorage[127.0.0.1:37891,DS-f6d49355-ff82-4561-b751-e4237cb72315,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1047123671-172.17.0.17-1597666526263:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34293,DS-b410ba58-6643-43c3-8005-35fafa3695d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33752,DS-4a58a90d-39ad-4a76-a8d6-59b4c182fd6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36297,DS-c35dceae-e727-41b8-9b87-1326cc13d1ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37071,DS-9317e0a8-5e6a-4243-b7bf-996a14ca06b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34735,DS-d85804ff-e428-48ad-93db-9d6134988bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:32955,DS-aba939e9-30ba-4cbd-805d-f35cd6f3cf00,DISK], DatanodeInfoWithStorage[127.0.0.1:38843,DS-4cf02b6c-d9a9-4339-b9e7-90e0ece9aa97,DISK], DatanodeInfoWithStorage[127.0.0.1:37891,DS-f6d49355-ff82-4561-b751-e4237cb72315,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-202684257-172.17.0.17-1597666645296:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37280,DS-efa32736-6ab4-4b16-a2ea-59b314aeea63,DISK], DatanodeInfoWithStorage[127.0.0.1:46207,DS-4b26b67a-2766-4335-8580-9ca0c5f526e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41158,DS-12328c63-7717-4587-8e8b-2e6419f1151c,DISK], DatanodeInfoWithStorage[127.0.0.1:45175,DS-774884d2-6a96-4ce1-a6d8-976c1ada8b55,DISK], DatanodeInfoWithStorage[127.0.0.1:46499,DS-4ac24930-d918-4ae5-a10d-62c8d51f2959,DISK], DatanodeInfoWithStorage[127.0.0.1:35324,DS-508613b6-648e-4efa-bcc7-fb74ca5a2da2,DISK], DatanodeInfoWithStorage[127.0.0.1:34861,DS-745470dc-a696-4074-bfb8-f28cab1ade5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36414,DS-de3542fa-c6cf-4e3b-a2bd-c355d7ec03d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-202684257-172.17.0.17-1597666645296:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37280,DS-efa32736-6ab4-4b16-a2ea-59b314aeea63,DISK], DatanodeInfoWithStorage[127.0.0.1:46207,DS-4b26b67a-2766-4335-8580-9ca0c5f526e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41158,DS-12328c63-7717-4587-8e8b-2e6419f1151c,DISK], DatanodeInfoWithStorage[127.0.0.1:45175,DS-774884d2-6a96-4ce1-a6d8-976c1ada8b55,DISK], DatanodeInfoWithStorage[127.0.0.1:46499,DS-4ac24930-d918-4ae5-a10d-62c8d51f2959,DISK], DatanodeInfoWithStorage[127.0.0.1:35324,DS-508613b6-648e-4efa-bcc7-fb74ca5a2da2,DISK], DatanodeInfoWithStorage[127.0.0.1:34861,DS-745470dc-a696-4074-bfb8-f28cab1ade5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36414,DS-de3542fa-c6cf-4e3b-a2bd-c355d7ec03d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-937733389-172.17.0.17-1597667291410:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36162,DS-cbe314b3-9dcc-4c76-8fa7-1eddb4a4e57f,DISK], DatanodeInfoWithStorage[127.0.0.1:41662,DS-37ba0bc5-d17e-4a93-aa6d-e273784953e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44983,DS-784a9e62-5cf8-459e-a3d9-c64f28d03c48,DISK], DatanodeInfoWithStorage[127.0.0.1:43064,DS-9bc42868-ae9f-4997-9ada-9261659fcd60,DISK], DatanodeInfoWithStorage[127.0.0.1:46713,DS-a97644a8-9eaa-4b8a-b149-b208cd344d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:43599,DS-f09db552-9ba7-44cf-b781-1aa5a37871d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38788,DS-841300df-8ebd-40b1-8c24-a0685ce3be3b,DISK], DatanodeInfoWithStorage[127.0.0.1:33477,DS-3e0cf84c-9d8f-4c04-9d25-bacd1fb456fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-937733389-172.17.0.17-1597667291410:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36162,DS-cbe314b3-9dcc-4c76-8fa7-1eddb4a4e57f,DISK], DatanodeInfoWithStorage[127.0.0.1:41662,DS-37ba0bc5-d17e-4a93-aa6d-e273784953e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44983,DS-784a9e62-5cf8-459e-a3d9-c64f28d03c48,DISK], DatanodeInfoWithStorage[127.0.0.1:43064,DS-9bc42868-ae9f-4997-9ada-9261659fcd60,DISK], DatanodeInfoWithStorage[127.0.0.1:46713,DS-a97644a8-9eaa-4b8a-b149-b208cd344d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:43599,DS-f09db552-9ba7-44cf-b781-1aa5a37871d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38788,DS-841300df-8ebd-40b1-8c24-a0685ce3be3b,DISK], DatanodeInfoWithStorage[127.0.0.1:33477,DS-3e0cf84c-9d8f-4c04-9d25-bacd1fb456fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1329954028-172.17.0.17-1597667452076:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37416,DS-14c7ae58-2230-4411-8ca8-288b47884a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:42296,DS-b5875dfa-6aae-4208-8618-4be0c057a9ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37592,DS-59fbd1e2-6ea8-4d58-9ceb-21437c4d5b17,DISK], DatanodeInfoWithStorage[127.0.0.1:40593,DS-96cb6e9d-3383-4531-a9fa-962451672264,DISK], DatanodeInfoWithStorage[127.0.0.1:43196,DS-8b722a63-8a63-4cc9-bafb-7e6740adc3d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38210,DS-c74f489d-7584-455b-b669-5c6c4c3e9690,DISK], DatanodeInfoWithStorage[127.0.0.1:37905,DS-330fb7db-9a7b-4abd-a7b5-6edf3c79cf66,DISK], DatanodeInfoWithStorage[127.0.0.1:46721,DS-be4989e1-e4ca-43ba-8acb-d633a003b608,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1329954028-172.17.0.17-1597667452076:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37416,DS-14c7ae58-2230-4411-8ca8-288b47884a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:42296,DS-b5875dfa-6aae-4208-8618-4be0c057a9ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37592,DS-59fbd1e2-6ea8-4d58-9ceb-21437c4d5b17,DISK], DatanodeInfoWithStorage[127.0.0.1:40593,DS-96cb6e9d-3383-4531-a9fa-962451672264,DISK], DatanodeInfoWithStorage[127.0.0.1:43196,DS-8b722a63-8a63-4cc9-bafb-7e6740adc3d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38210,DS-c74f489d-7584-455b-b669-5c6c4c3e9690,DISK], DatanodeInfoWithStorage[127.0.0.1:37905,DS-330fb7db-9a7b-4abd-a7b5-6edf3c79cf66,DISK], DatanodeInfoWithStorage[127.0.0.1:46721,DS-be4989e1-e4ca-43ba-8acb-d633a003b608,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1548647189-172.17.0.17-1597667570398:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32929,DS-2720342d-1794-42f4-907c-86402e75854e,DISK], DatanodeInfoWithStorage[127.0.0.1:35052,DS-069a9bb3-e93a-49d4-87b9-e67bc18ca8c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38763,DS-bf1699d9-13c1-49bc-b9c5-3ae644069020,DISK], DatanodeInfoWithStorage[127.0.0.1:40070,DS-9d5d3bef-e336-4a21-9bd8-d7d5aa47693d,DISK], DatanodeInfoWithStorage[127.0.0.1:37496,DS-f6f6143c-423b-4070-ab19-fe1f29a9e7fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45470,DS-e7eb780a-ec9a-4c46-93b9-1b3e26172c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35482,DS-71c79e43-1d88-4fd3-a057-c4b8ef97a979,DISK], DatanodeInfoWithStorage[127.0.0.1:40867,DS-b9378758-1868-4fd7-b217-68259e2aeef4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1548647189-172.17.0.17-1597667570398:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32929,DS-2720342d-1794-42f4-907c-86402e75854e,DISK], DatanodeInfoWithStorage[127.0.0.1:35052,DS-069a9bb3-e93a-49d4-87b9-e67bc18ca8c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38763,DS-bf1699d9-13c1-49bc-b9c5-3ae644069020,DISK], DatanodeInfoWithStorage[127.0.0.1:40070,DS-9d5d3bef-e336-4a21-9bd8-d7d5aa47693d,DISK], DatanodeInfoWithStorage[127.0.0.1:37496,DS-f6f6143c-423b-4070-ab19-fe1f29a9e7fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45470,DS-e7eb780a-ec9a-4c46-93b9-1b3e26172c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35482,DS-71c79e43-1d88-4fd3-a057-c4b8ef97a979,DISK], DatanodeInfoWithStorage[127.0.0.1:40867,DS-b9378758-1868-4fd7-b217-68259e2aeef4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-834595012-172.17.0.17-1597667636007:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37699,DS-843cb87f-2ddc-4fb9-a48e-bbe92db31269,DISK], DatanodeInfoWithStorage[127.0.0.1:45076,DS-b9004aac-2472-4572-a7af-8a952f8b788e,DISK], DatanodeInfoWithStorage[127.0.0.1:34933,DS-554ef96a-7ed6-4dd4-acd1-04de2b8278ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33715,DS-632c9d71-4ff7-47bc-ae1d-59a95fb60777,DISK], DatanodeInfoWithStorage[127.0.0.1:38272,DS-6afafdcb-f113-4a9f-ad88-955e61519c62,DISK], DatanodeInfoWithStorage[127.0.0.1:46036,DS-4d0272e5-d9ae-4f5a-9c0c-00c6f6b01086,DISK], DatanodeInfoWithStorage[127.0.0.1:36007,DS-20ae8e0e-0ed0-4d62-a2f0-b25b24b9e67e,DISK], DatanodeInfoWithStorage[127.0.0.1:46681,DS-fd4e3fba-cb7d-4a9d-9aa0-8a910ed0b9f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-834595012-172.17.0.17-1597667636007:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37699,DS-843cb87f-2ddc-4fb9-a48e-bbe92db31269,DISK], DatanodeInfoWithStorage[127.0.0.1:45076,DS-b9004aac-2472-4572-a7af-8a952f8b788e,DISK], DatanodeInfoWithStorage[127.0.0.1:34933,DS-554ef96a-7ed6-4dd4-acd1-04de2b8278ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33715,DS-632c9d71-4ff7-47bc-ae1d-59a95fb60777,DISK], DatanodeInfoWithStorage[127.0.0.1:38272,DS-6afafdcb-f113-4a9f-ad88-955e61519c62,DISK], DatanodeInfoWithStorage[127.0.0.1:46036,DS-4d0272e5-d9ae-4f5a-9c0c-00c6f6b01086,DISK], DatanodeInfoWithStorage[127.0.0.1:36007,DS-20ae8e0e-0ed0-4d62-a2f0-b25b24b9e67e,DISK], DatanodeInfoWithStorage[127.0.0.1:46681,DS-fd4e3fba-cb7d-4a9d-9aa0-8a910ed0b9f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-641638410-172.17.0.17-1597668021011:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42813,DS-56475ff2-d488-417e-bc39-fb683a47e673,DISK], DatanodeInfoWithStorage[127.0.0.1:38416,DS-11ace813-81e5-43a2-92fe-97cb5b44d03d,DISK], DatanodeInfoWithStorage[127.0.0.1:45842,DS-3a89d86d-738e-42b9-8642-f9233f2cc568,DISK], DatanodeInfoWithStorage[127.0.0.1:46026,DS-4e7e4ca4-c20c-4744-94e5-999e2cd0895f,DISK], DatanodeInfoWithStorage[127.0.0.1:38588,DS-1a808caa-3289-4316-adc5-8048c3802ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:39355,DS-54dbec77-9da5-4662-ac12-e6fcffb2fa1c,DISK], DatanodeInfoWithStorage[127.0.0.1:45770,DS-20451ccf-1575-4417-a55a-16863adb2a87,DISK], DatanodeInfoWithStorage[127.0.0.1:46343,DS-a06a757a-1034-4aa6-92a5-a62b32b9a040,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-641638410-172.17.0.17-1597668021011:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42813,DS-56475ff2-d488-417e-bc39-fb683a47e673,DISK], DatanodeInfoWithStorage[127.0.0.1:38416,DS-11ace813-81e5-43a2-92fe-97cb5b44d03d,DISK], DatanodeInfoWithStorage[127.0.0.1:45842,DS-3a89d86d-738e-42b9-8642-f9233f2cc568,DISK], DatanodeInfoWithStorage[127.0.0.1:46026,DS-4e7e4ca4-c20c-4744-94e5-999e2cd0895f,DISK], DatanodeInfoWithStorage[127.0.0.1:38588,DS-1a808caa-3289-4316-adc5-8048c3802ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:39355,DS-54dbec77-9da5-4662-ac12-e6fcffb2fa1c,DISK], DatanodeInfoWithStorage[127.0.0.1:45770,DS-20451ccf-1575-4417-a55a-16863adb2a87,DISK], DatanodeInfoWithStorage[127.0.0.1:46343,DS-a06a757a-1034-4aa6-92a5-a62b32b9a040,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1397102410-172.17.0.17-1597668354506:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37038,DS-f1e591fd-aa01-426a-aca0-eb3b4043b82e,DISK], DatanodeInfoWithStorage[127.0.0.1:46343,DS-bad976ec-1f75-42bd-8eff-05f8c1107070,DISK], DatanodeInfoWithStorage[127.0.0.1:41139,DS-12b5f4fa-0515-422b-aaf8-ed0f2f329454,DISK], DatanodeInfoWithStorage[127.0.0.1:38939,DS-06d472c0-b03f-454b-a456-3326da057d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39075,DS-7a164815-714c-4bd2-ad22-674d35bb2bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:37786,DS-0239134e-fe11-4c63-b31e-5be296701a19,DISK], DatanodeInfoWithStorage[127.0.0.1:40537,DS-40fe5edd-361c-48d8-885b-071aade5f1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39208,DS-f4429648-898f-4ad4-9c24-6e7b8ad3e811,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1397102410-172.17.0.17-1597668354506:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37038,DS-f1e591fd-aa01-426a-aca0-eb3b4043b82e,DISK], DatanodeInfoWithStorage[127.0.0.1:46343,DS-bad976ec-1f75-42bd-8eff-05f8c1107070,DISK], DatanodeInfoWithStorage[127.0.0.1:41139,DS-12b5f4fa-0515-422b-aaf8-ed0f2f329454,DISK], DatanodeInfoWithStorage[127.0.0.1:38939,DS-06d472c0-b03f-454b-a456-3326da057d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39075,DS-7a164815-714c-4bd2-ad22-674d35bb2bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:37786,DS-0239134e-fe11-4c63-b31e-5be296701a19,DISK], DatanodeInfoWithStorage[127.0.0.1:40537,DS-40fe5edd-361c-48d8-885b-071aade5f1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39208,DS-f4429648-898f-4ad4-9c24-6e7b8ad3e811,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1474004938-172.17.0.17-1597668495506:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35902,DS-92703736-a60a-443e-b334-4ab5712961bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46778,DS-502c9cdc-95e2-461b-8be8-87925622d47b,DISK], DatanodeInfoWithStorage[127.0.0.1:45383,DS-e9d55f9c-3c6e-4b06-b1dd-078479a45b16,DISK], DatanodeInfoWithStorage[127.0.0.1:45461,DS-e9a2423b-7afe-434c-bf67-721d02ae485c,DISK], DatanodeInfoWithStorage[127.0.0.1:40072,DS-ac64a0fe-4cbe-41d2-8872-585786d56af4,DISK], DatanodeInfoWithStorage[127.0.0.1:37946,DS-39df2757-df28-42b2-a8c0-c3e04df02da3,DISK], DatanodeInfoWithStorage[127.0.0.1:40387,DS-c39202a9-cb54-4a5e-bf31-835674d62530,DISK], DatanodeInfoWithStorage[127.0.0.1:34691,DS-0ab6c290-ef4c-4b63-9f13-6e0cb010a728,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1474004938-172.17.0.17-1597668495506:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35902,DS-92703736-a60a-443e-b334-4ab5712961bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46778,DS-502c9cdc-95e2-461b-8be8-87925622d47b,DISK], DatanodeInfoWithStorage[127.0.0.1:45383,DS-e9d55f9c-3c6e-4b06-b1dd-078479a45b16,DISK], DatanodeInfoWithStorage[127.0.0.1:45461,DS-e9a2423b-7afe-434c-bf67-721d02ae485c,DISK], DatanodeInfoWithStorage[127.0.0.1:40072,DS-ac64a0fe-4cbe-41d2-8872-585786d56af4,DISK], DatanodeInfoWithStorage[127.0.0.1:37946,DS-39df2757-df28-42b2-a8c0-c3e04df02da3,DISK], DatanodeInfoWithStorage[127.0.0.1:40387,DS-c39202a9-cb54-4a5e-bf31-835674d62530,DISK], DatanodeInfoWithStorage[127.0.0.1:34691,DS-0ab6c290-ef4c-4b63-9f13-6e0cb010a728,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-842037071-172.17.0.17-1597668679735:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37901,DS-f701aa78-617b-4b88-988f-d58d646b25bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35469,DS-b2df8415-83e0-41a5-ac37-0e2fc6e9177a,DISK], DatanodeInfoWithStorage[127.0.0.1:45033,DS-1ee14332-1188-46db-98d3-294af932718a,DISK], DatanodeInfoWithStorage[127.0.0.1:35329,DS-5c5c5afc-0227-484a-94be-5bb14d49af11,DISK], DatanodeInfoWithStorage[127.0.0.1:41642,DS-90141767-5002-4114-b5d8-4a75155d7803,DISK], DatanodeInfoWithStorage[127.0.0.1:38896,DS-c14167af-01ab-42e5-bbe3-a5c609223b68,DISK], DatanodeInfoWithStorage[127.0.0.1:42797,DS-525dc26e-e78d-4223-84e0-38576905045f,DISK], DatanodeInfoWithStorage[127.0.0.1:35537,DS-c946d8e4-2f39-4450-b01c-1f57e95394b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-842037071-172.17.0.17-1597668679735:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37901,DS-f701aa78-617b-4b88-988f-d58d646b25bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35469,DS-b2df8415-83e0-41a5-ac37-0e2fc6e9177a,DISK], DatanodeInfoWithStorage[127.0.0.1:45033,DS-1ee14332-1188-46db-98d3-294af932718a,DISK], DatanodeInfoWithStorage[127.0.0.1:35329,DS-5c5c5afc-0227-484a-94be-5bb14d49af11,DISK], DatanodeInfoWithStorage[127.0.0.1:41642,DS-90141767-5002-4114-b5d8-4a75155d7803,DISK], DatanodeInfoWithStorage[127.0.0.1:38896,DS-c14167af-01ab-42e5-bbe3-a5c609223b68,DISK], DatanodeInfoWithStorage[127.0.0.1:42797,DS-525dc26e-e78d-4223-84e0-38576905045f,DISK], DatanodeInfoWithStorage[127.0.0.1:35537,DS-c946d8e4-2f39-4450-b01c-1f57e95394b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1924135134-172.17.0.17-1597669061011:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38249,DS-393455cc-ef38-4e46-834f-b42f1eb576ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45585,DS-908efa2b-5ebf-421c-a119-ff6da4a9bad0,DISK], DatanodeInfoWithStorage[127.0.0.1:46736,DS-5eaffa5a-8c63-4287-be5e-26ee4059d02b,DISK], DatanodeInfoWithStorage[127.0.0.1:36205,DS-8f287881-6ca1-496e-aa54-bb0ae6840963,DISK], DatanodeInfoWithStorage[127.0.0.1:42206,DS-063e666b-83bb-4ea8-b8f5-b263fc7e6581,DISK], DatanodeInfoWithStorage[127.0.0.1:32987,DS-a2f505b0-16af-4f45-a22f-3184d09cbd36,DISK], DatanodeInfoWithStorage[127.0.0.1:45950,DS-dd08ee31-2fa0-4436-97ed-bf79aca6a084,DISK], DatanodeInfoWithStorage[127.0.0.1:41879,DS-97b98868-e01e-4db2-9871-80e0c72c6f2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1924135134-172.17.0.17-1597669061011:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38249,DS-393455cc-ef38-4e46-834f-b42f1eb576ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45585,DS-908efa2b-5ebf-421c-a119-ff6da4a9bad0,DISK], DatanodeInfoWithStorage[127.0.0.1:46736,DS-5eaffa5a-8c63-4287-be5e-26ee4059d02b,DISK], DatanodeInfoWithStorage[127.0.0.1:36205,DS-8f287881-6ca1-496e-aa54-bb0ae6840963,DISK], DatanodeInfoWithStorage[127.0.0.1:42206,DS-063e666b-83bb-4ea8-b8f5-b263fc7e6581,DISK], DatanodeInfoWithStorage[127.0.0.1:32987,DS-a2f505b0-16af-4f45-a22f-3184d09cbd36,DISK], DatanodeInfoWithStorage[127.0.0.1:45950,DS-dd08ee31-2fa0-4436-97ed-bf79aca6a084,DISK], DatanodeInfoWithStorage[127.0.0.1:41879,DS-97b98868-e01e-4db2-9871-80e0c72c6f2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1030973440-172.17.0.17-1597669098731:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45776,DS-c1fdb275-4192-4a96-b73d-1c394e93dc8b,DISK], DatanodeInfoWithStorage[127.0.0.1:44133,DS-3dd7283b-1110-422d-8088-b2ebe64f38df,DISK], DatanodeInfoWithStorage[127.0.0.1:42933,DS-d162776d-0306-43f2-9c71-fc7d06163753,DISK], DatanodeInfoWithStorage[127.0.0.1:45431,DS-e5ff8c30-a94c-4635-a88b-55ac03c789dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42011,DS-2e5d1587-551f-4957-ba1c-2dfca9734bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:37719,DS-bbdab25b-a1c9-47af-9b0f-f703da5f0865,DISK], DatanodeInfoWithStorage[127.0.0.1:43216,DS-dca23f39-80df-44be-870f-73dd7f3b58ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-aa012788-d9be-441e-9d48-25cd0041a06c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1030973440-172.17.0.17-1597669098731:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45776,DS-c1fdb275-4192-4a96-b73d-1c394e93dc8b,DISK], DatanodeInfoWithStorage[127.0.0.1:44133,DS-3dd7283b-1110-422d-8088-b2ebe64f38df,DISK], DatanodeInfoWithStorage[127.0.0.1:42933,DS-d162776d-0306-43f2-9c71-fc7d06163753,DISK], DatanodeInfoWithStorage[127.0.0.1:45431,DS-e5ff8c30-a94c-4635-a88b-55ac03c789dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42011,DS-2e5d1587-551f-4957-ba1c-2dfca9734bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:37719,DS-bbdab25b-a1c9-47af-9b0f-f703da5f0865,DISK], DatanodeInfoWithStorage[127.0.0.1:43216,DS-dca23f39-80df-44be-870f-73dd7f3b58ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-aa012788-d9be-441e-9d48-25cd0041a06c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2051123728-172.17.0.17-1597669800712:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33512,DS-0185084d-cd55-46cc-86f8-2be3c29cc83c,DISK], DatanodeInfoWithStorage[127.0.0.1:46447,DS-243dc95b-b777-455b-a8b9-285f53ef5f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:39053,DS-60f1559d-fb01-49ed-96ec-26291e3bb816,DISK], DatanodeInfoWithStorage[127.0.0.1:33040,DS-a36ffb5b-afa9-4443-9293-3f5f524e13c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40269,DS-8d7a3c94-8c19-4da1-96f7-99b674ed17db,DISK], DatanodeInfoWithStorage[127.0.0.1:45341,DS-0558adc0-e323-4bef-951a-6615ce0f2d98,DISK], DatanodeInfoWithStorage[127.0.0.1:33419,DS-9cd42672-0fe7-4a7b-867f-aeae56929a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:38255,DS-21b21164-1143-414a-aaa3-3bd830dd995d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2051123728-172.17.0.17-1597669800712:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33512,DS-0185084d-cd55-46cc-86f8-2be3c29cc83c,DISK], DatanodeInfoWithStorage[127.0.0.1:46447,DS-243dc95b-b777-455b-a8b9-285f53ef5f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:39053,DS-60f1559d-fb01-49ed-96ec-26291e3bb816,DISK], DatanodeInfoWithStorage[127.0.0.1:33040,DS-a36ffb5b-afa9-4443-9293-3f5f524e13c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40269,DS-8d7a3c94-8c19-4da1-96f7-99b674ed17db,DISK], DatanodeInfoWithStorage[127.0.0.1:45341,DS-0558adc0-e323-4bef-951a-6615ce0f2d98,DISK], DatanodeInfoWithStorage[127.0.0.1:33419,DS-9cd42672-0fe7-4a7b-867f-aeae56929a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:38255,DS-21b21164-1143-414a-aaa3-3bd830dd995d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1437212323-172.17.0.17-1597669839714:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38027,DS-0ba38cbe-61df-4344-a34b-70604b275d80,DISK], DatanodeInfoWithStorage[127.0.0.1:42192,DS-544f3bd8-fc07-423e-8efc-be5566487367,DISK], DatanodeInfoWithStorage[127.0.0.1:40430,DS-ca70f91e-75e4-487b-9d06-acf10ce87b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:43874,DS-e40a0869-8603-4853-83ed-4ccaeb299b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35131,DS-9b9a70cb-6f32-4daa-a466-7dab63787179,DISK], DatanodeInfoWithStorage[127.0.0.1:42871,DS-45dea460-5739-4f9c-a92f-43c9889b4c62,DISK], DatanodeInfoWithStorage[127.0.0.1:46855,DS-b7ec3365-11b1-4d96-8eb0-c4192b1a71bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42699,DS-fab24200-c76e-4289-924e-e92628060ae2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1437212323-172.17.0.17-1597669839714:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38027,DS-0ba38cbe-61df-4344-a34b-70604b275d80,DISK], DatanodeInfoWithStorage[127.0.0.1:42192,DS-544f3bd8-fc07-423e-8efc-be5566487367,DISK], DatanodeInfoWithStorage[127.0.0.1:40430,DS-ca70f91e-75e4-487b-9d06-acf10ce87b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:43874,DS-e40a0869-8603-4853-83ed-4ccaeb299b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35131,DS-9b9a70cb-6f32-4daa-a466-7dab63787179,DISK], DatanodeInfoWithStorage[127.0.0.1:42871,DS-45dea460-5739-4f9c-a92f-43c9889b4c62,DISK], DatanodeInfoWithStorage[127.0.0.1:46855,DS-b7ec3365-11b1-4d96-8eb0-c4192b1a71bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42699,DS-fab24200-c76e-4289-924e-e92628060ae2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5651
