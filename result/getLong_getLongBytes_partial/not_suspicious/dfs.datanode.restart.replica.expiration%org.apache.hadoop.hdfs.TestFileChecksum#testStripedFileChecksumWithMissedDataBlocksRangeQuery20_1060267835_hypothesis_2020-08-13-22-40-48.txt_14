reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-861620840-172.17.0.9-1597358488534:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44838,DS-5f050338-cd82-479b-801e-216ec3fee8be,DISK], DatanodeInfoWithStorage[127.0.0.1:44825,DS-ee0e6343-c356-4b1d-bdfc-25fb99df0811,DISK], DatanodeInfoWithStorage[127.0.0.1:46454,DS-5c2c245a-cdcb-4332-9041-fc9e149276cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40348,DS-12e80ce3-1723-484a-bbd3-3d69326cacbe,DISK], DatanodeInfoWithStorage[127.0.0.1:34814,DS-dba69176-b79a-4c94-b782-2f83e9908e88,DISK], DatanodeInfoWithStorage[127.0.0.1:37306,DS-fb8bfcd6-87df-456a-9ba8-2a99c9340561,DISK], DatanodeInfoWithStorage[127.0.0.1:37620,DS-53ff8e4c-c0e6-425f-b1da-26c7a4bd90b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35671,DS-99f0cbb0-ab40-4e37-b17d-77268b439394,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-861620840-172.17.0.9-1597358488534:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44838,DS-5f050338-cd82-479b-801e-216ec3fee8be,DISK], DatanodeInfoWithStorage[127.0.0.1:44825,DS-ee0e6343-c356-4b1d-bdfc-25fb99df0811,DISK], DatanodeInfoWithStorage[127.0.0.1:46454,DS-5c2c245a-cdcb-4332-9041-fc9e149276cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40348,DS-12e80ce3-1723-484a-bbd3-3d69326cacbe,DISK], DatanodeInfoWithStorage[127.0.0.1:34814,DS-dba69176-b79a-4c94-b782-2f83e9908e88,DISK], DatanodeInfoWithStorage[127.0.0.1:37306,DS-fb8bfcd6-87df-456a-9ba8-2a99c9340561,DISK], DatanodeInfoWithStorage[127.0.0.1:37620,DS-53ff8e4c-c0e6-425f-b1da-26c7a4bd90b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35671,DS-99f0cbb0-ab40-4e37-b17d-77268b439394,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-935379219-172.17.0.9-1597359255025:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44537,DS-f31fc35c-1a60-4baa-8f96-2525ff59e724,DISK], DatanodeInfoWithStorage[127.0.0.1:44880,DS-6c914d85-8614-4074-95bd-e4ebafe1d5c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37069,DS-4c94a138-04ad-4dbd-b0b8-11f42229d38e,DISK], DatanodeInfoWithStorage[127.0.0.1:42423,DS-0b81beb1-069e-49c0-ba1f-b5cb1ff0b05b,DISK], DatanodeInfoWithStorage[127.0.0.1:33706,DS-32cbcd3e-2f95-43eb-b69d-f547c2e91b02,DISK], DatanodeInfoWithStorage[127.0.0.1:33882,DS-2a6e56ba-f961-47d8-bcec-b40c2099c973,DISK], DatanodeInfoWithStorage[127.0.0.1:43353,DS-4c6655f3-5314-4c4e-8775-6d9e3cb4cc2f,DISK], DatanodeInfoWithStorage[127.0.0.1:36111,DS-15e1a2f2-c01d-4c0f-b74e-a0319f822710,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-935379219-172.17.0.9-1597359255025:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44537,DS-f31fc35c-1a60-4baa-8f96-2525ff59e724,DISK], DatanodeInfoWithStorage[127.0.0.1:44880,DS-6c914d85-8614-4074-95bd-e4ebafe1d5c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37069,DS-4c94a138-04ad-4dbd-b0b8-11f42229d38e,DISK], DatanodeInfoWithStorage[127.0.0.1:42423,DS-0b81beb1-069e-49c0-ba1f-b5cb1ff0b05b,DISK], DatanodeInfoWithStorage[127.0.0.1:33706,DS-32cbcd3e-2f95-43eb-b69d-f547c2e91b02,DISK], DatanodeInfoWithStorage[127.0.0.1:33882,DS-2a6e56ba-f961-47d8-bcec-b40c2099c973,DISK], DatanodeInfoWithStorage[127.0.0.1:43353,DS-4c6655f3-5314-4c4e-8775-6d9e3cb4cc2f,DISK], DatanodeInfoWithStorage[127.0.0.1:36111,DS-15e1a2f2-c01d-4c0f-b74e-a0319f822710,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-491849917-172.17.0.9-1597359534240:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41055,DS-73d8c3bc-b70d-4822-b018-1575bc9a412e,DISK], DatanodeInfoWithStorage[127.0.0.1:46541,DS-0a7739cb-e767-461c-bf78-f421e8e41b55,DISK], DatanodeInfoWithStorage[127.0.0.1:33395,DS-b4be3624-6d36-4f6f-b281-e58aaf8321fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35106,DS-97d2d0f6-7861-44b6-8781-cb48b8bf09b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34893,DS-fa578bea-134b-4b33-8470-08ef626bda35,DISK], DatanodeInfoWithStorage[127.0.0.1:34045,DS-9fb95127-877d-4b4a-bc85-013e7a535eed,DISK], DatanodeInfoWithStorage[127.0.0.1:41934,DS-13d19a20-7f48-46e5-a874-4f07562ff8cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46062,DS-9ee3b577-ddee-4cd3-9c02-dbe80aade728,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-491849917-172.17.0.9-1597359534240:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41055,DS-73d8c3bc-b70d-4822-b018-1575bc9a412e,DISK], DatanodeInfoWithStorage[127.0.0.1:46541,DS-0a7739cb-e767-461c-bf78-f421e8e41b55,DISK], DatanodeInfoWithStorage[127.0.0.1:33395,DS-b4be3624-6d36-4f6f-b281-e58aaf8321fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35106,DS-97d2d0f6-7861-44b6-8781-cb48b8bf09b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34893,DS-fa578bea-134b-4b33-8470-08ef626bda35,DISK], DatanodeInfoWithStorage[127.0.0.1:34045,DS-9fb95127-877d-4b4a-bc85-013e7a535eed,DISK], DatanodeInfoWithStorage[127.0.0.1:41934,DS-13d19a20-7f48-46e5-a874-4f07562ff8cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46062,DS-9ee3b577-ddee-4cd3-9c02-dbe80aade728,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2071261898-172.17.0.9-1597359736773:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38858,DS-80369031-5cee-4636-aee3-3b29026c8bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:41421,DS-06dc9419-b819-4254-b8f5-3d7cd747d6dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35622,DS-5123e0b7-b6ce-48f0-8bcd-f5580a7994fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37659,DS-8e0131bb-c3b9-4fd1-9308-8d916328ca5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40213,DS-5029fadc-260c-4570-bfb1-222e15642957,DISK], DatanodeInfoWithStorage[127.0.0.1:34275,DS-3f2eb856-e471-42bb-ba90-1eacad5445fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44393,DS-cf9ad9dd-4214-44b8-86a0-d74e09edd32c,DISK], DatanodeInfoWithStorage[127.0.0.1:44859,DS-948da51c-092f-4542-ac9c-545d0e1f8678,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2071261898-172.17.0.9-1597359736773:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38858,DS-80369031-5cee-4636-aee3-3b29026c8bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:41421,DS-06dc9419-b819-4254-b8f5-3d7cd747d6dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35622,DS-5123e0b7-b6ce-48f0-8bcd-f5580a7994fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37659,DS-8e0131bb-c3b9-4fd1-9308-8d916328ca5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40213,DS-5029fadc-260c-4570-bfb1-222e15642957,DISK], DatanodeInfoWithStorage[127.0.0.1:34275,DS-3f2eb856-e471-42bb-ba90-1eacad5445fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44393,DS-cf9ad9dd-4214-44b8-86a0-d74e09edd32c,DISK], DatanodeInfoWithStorage[127.0.0.1:44859,DS-948da51c-092f-4542-ac9c-545d0e1f8678,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-90068384-172.17.0.9-1597359768254:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41077,DS-fa79ced8-7c87-4b95-8ade-0ab0bdce744a,DISK], DatanodeInfoWithStorage[127.0.0.1:46219,DS-fe7710ea-5b63-4c64-be62-a59dde04d421,DISK], DatanodeInfoWithStorage[127.0.0.1:34108,DS-dca8a1c3-8028-446e-8398-e96467db6d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43825,DS-30c113ed-3ee3-4acd-8368-7332530cb4ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33140,DS-7c8460fe-31e8-409b-b5ed-f15eac4f8194,DISK], DatanodeInfoWithStorage[127.0.0.1:41089,DS-b5373282-cd14-47aa-b470-d10925900e50,DISK], DatanodeInfoWithStorage[127.0.0.1:36414,DS-d93968c4-5aed-41d9-a363-8f70de129a97,DISK], DatanodeInfoWithStorage[127.0.0.1:33000,DS-dccf37c4-a3cc-499f-b2aa-ead143d0d498,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-90068384-172.17.0.9-1597359768254:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41077,DS-fa79ced8-7c87-4b95-8ade-0ab0bdce744a,DISK], DatanodeInfoWithStorage[127.0.0.1:46219,DS-fe7710ea-5b63-4c64-be62-a59dde04d421,DISK], DatanodeInfoWithStorage[127.0.0.1:34108,DS-dca8a1c3-8028-446e-8398-e96467db6d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43825,DS-30c113ed-3ee3-4acd-8368-7332530cb4ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33140,DS-7c8460fe-31e8-409b-b5ed-f15eac4f8194,DISK], DatanodeInfoWithStorage[127.0.0.1:41089,DS-b5373282-cd14-47aa-b470-d10925900e50,DISK], DatanodeInfoWithStorage[127.0.0.1:36414,DS-d93968c4-5aed-41d9-a363-8f70de129a97,DISK], DatanodeInfoWithStorage[127.0.0.1:33000,DS-dccf37c4-a3cc-499f-b2aa-ead143d0d498,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2095750305-172.17.0.9-1597360173508:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43046,DS-225c735f-404e-434a-acf3-ef35f03bde2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46089,DS-373994a7-45cb-4831-ae05-4a03a90ea3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34731,DS-0c03a703-313d-422d-9f6d-78a4dfc37d37,DISK], DatanodeInfoWithStorage[127.0.0.1:33856,DS-1262a607-575f-442c-a969-2edb7953266d,DISK], DatanodeInfoWithStorage[127.0.0.1:40546,DS-66c899bf-ce22-41b2-ae8a-c97bc34327b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45597,DS-3daed964-f561-49d9-baee-71777e4fe511,DISK], DatanodeInfoWithStorage[127.0.0.1:45836,DS-8721e920-fc45-4db1-a29a-f584f3d5510b,DISK], DatanodeInfoWithStorage[127.0.0.1:39959,DS-672d43ac-ba9e-4a4b-95af-6e549e9a1c52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2095750305-172.17.0.9-1597360173508:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43046,DS-225c735f-404e-434a-acf3-ef35f03bde2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46089,DS-373994a7-45cb-4831-ae05-4a03a90ea3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34731,DS-0c03a703-313d-422d-9f6d-78a4dfc37d37,DISK], DatanodeInfoWithStorage[127.0.0.1:33856,DS-1262a607-575f-442c-a969-2edb7953266d,DISK], DatanodeInfoWithStorage[127.0.0.1:40546,DS-66c899bf-ce22-41b2-ae8a-c97bc34327b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45597,DS-3daed964-f561-49d9-baee-71777e4fe511,DISK], DatanodeInfoWithStorage[127.0.0.1:45836,DS-8721e920-fc45-4db1-a29a-f584f3d5510b,DISK], DatanodeInfoWithStorage[127.0.0.1:39959,DS-672d43ac-ba9e-4a4b-95af-6e549e9a1c52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-919214773-172.17.0.9-1597361102988:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38586,DS-b312b806-cea5-48fc-adfd-d9b7e35d1331,DISK], DatanodeInfoWithStorage[127.0.0.1:41212,DS-13600b5d-7179-40fb-a626-910b2b321c3c,DISK], DatanodeInfoWithStorage[127.0.0.1:41152,DS-6e74c173-e51b-48d8-814f-bcb8decc0758,DISK], DatanodeInfoWithStorage[127.0.0.1:42770,DS-5c258a01-6e26-4837-b073-4402f19f2768,DISK], DatanodeInfoWithStorage[127.0.0.1:42957,DS-f5a1c434-4e7e-48f0-82db-827b226143cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37344,DS-f5067355-418c-4547-9793-5eeea3188133,DISK], DatanodeInfoWithStorage[127.0.0.1:45371,DS-44c469fd-faf2-4c19-94d8-f52acee9f421,DISK], DatanodeInfoWithStorage[127.0.0.1:34107,DS-64c0893d-fe4f-45eb-ba3c-a945f0820208,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-919214773-172.17.0.9-1597361102988:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38586,DS-b312b806-cea5-48fc-adfd-d9b7e35d1331,DISK], DatanodeInfoWithStorage[127.0.0.1:41212,DS-13600b5d-7179-40fb-a626-910b2b321c3c,DISK], DatanodeInfoWithStorage[127.0.0.1:41152,DS-6e74c173-e51b-48d8-814f-bcb8decc0758,DISK], DatanodeInfoWithStorage[127.0.0.1:42770,DS-5c258a01-6e26-4837-b073-4402f19f2768,DISK], DatanodeInfoWithStorage[127.0.0.1:42957,DS-f5a1c434-4e7e-48f0-82db-827b226143cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37344,DS-f5067355-418c-4547-9793-5eeea3188133,DISK], DatanodeInfoWithStorage[127.0.0.1:45371,DS-44c469fd-faf2-4c19-94d8-f52acee9f421,DISK], DatanodeInfoWithStorage[127.0.0.1:34107,DS-64c0893d-fe4f-45eb-ba3c-a945f0820208,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-111062642-172.17.0.9-1597361782573:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45894,DS-6a54730d-f766-4af5-a7a9-66b2bb899505,DISK], DatanodeInfoWithStorage[127.0.0.1:43028,DS-1fa7bb57-d0df-4df3-a912-df874eeaa468,DISK], DatanodeInfoWithStorage[127.0.0.1:43842,DS-06165fd7-be31-4732-88db-13f03177d3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45553,DS-17eed6c0-3210-45ff-991f-9e2dc25380a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36633,DS-f80b6b81-5402-42d0-babe-5f37fd39f9d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45151,DS-ec7a972e-cbd2-4c1b-a129-c69bf43453e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43841,DS-051e3838-6336-49aa-ac78-6618564f456b,DISK], DatanodeInfoWithStorage[127.0.0.1:40646,DS-56554196-72dc-4adc-ae32-00f0c27ea275,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-111062642-172.17.0.9-1597361782573:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45894,DS-6a54730d-f766-4af5-a7a9-66b2bb899505,DISK], DatanodeInfoWithStorage[127.0.0.1:43028,DS-1fa7bb57-d0df-4df3-a912-df874eeaa468,DISK], DatanodeInfoWithStorage[127.0.0.1:43842,DS-06165fd7-be31-4732-88db-13f03177d3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45553,DS-17eed6c0-3210-45ff-991f-9e2dc25380a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36633,DS-f80b6b81-5402-42d0-babe-5f37fd39f9d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45151,DS-ec7a972e-cbd2-4c1b-a129-c69bf43453e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43841,DS-051e3838-6336-49aa-ac78-6618564f456b,DISK], DatanodeInfoWithStorage[127.0.0.1:40646,DS-56554196-72dc-4adc-ae32-00f0c27ea275,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-887043734-172.17.0.9-1597362479171:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44172,DS-944a4eb7-ece2-4390-8d94-5c08aa8e507b,DISK], DatanodeInfoWithStorage[127.0.0.1:45411,DS-7bd2640f-693e-4992-bda0-f0fe0d7bfa6c,DISK], DatanodeInfoWithStorage[127.0.0.1:35763,DS-e30d1bc1-c651-4882-8332-7b69c5a585bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39754,DS-a8092b03-fa75-4c66-852d-34806f5aa7b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36991,DS-b5f32ec3-84ea-490e-8d94-4824b037a1c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45701,DS-0d5eaf80-a55a-400d-a86e-fda50e5b88a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38244,DS-3b05514d-8534-48e9-af26-1522b95a6b31,DISK], DatanodeInfoWithStorage[127.0.0.1:37414,DS-9ca951a8-7bfb-4ed7-8006-72dd60c2b6af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-887043734-172.17.0.9-1597362479171:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44172,DS-944a4eb7-ece2-4390-8d94-5c08aa8e507b,DISK], DatanodeInfoWithStorage[127.0.0.1:45411,DS-7bd2640f-693e-4992-bda0-f0fe0d7bfa6c,DISK], DatanodeInfoWithStorage[127.0.0.1:35763,DS-e30d1bc1-c651-4882-8332-7b69c5a585bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39754,DS-a8092b03-fa75-4c66-852d-34806f5aa7b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36991,DS-b5f32ec3-84ea-490e-8d94-4824b037a1c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45701,DS-0d5eaf80-a55a-400d-a86e-fda50e5b88a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38244,DS-3b05514d-8534-48e9-af26-1522b95a6b31,DISK], DatanodeInfoWithStorage[127.0.0.1:37414,DS-9ca951a8-7bfb-4ed7-8006-72dd60c2b6af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1319302208-172.17.0.9-1597362869942:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45115,DS-e9a02233-e906-47ea-9fb2-a4ea0631f696,DISK], DatanodeInfoWithStorage[127.0.0.1:45324,DS-49ff133c-8f7b-4d4d-89a7-b5865e7831cb,DISK], DatanodeInfoWithStorage[127.0.0.1:32905,DS-161af06c-2979-43dc-af55-97c7d9902931,DISK], DatanodeInfoWithStorage[127.0.0.1:40440,DS-87d616d5-0afb-402c-b089-bea5e434435a,DISK], DatanodeInfoWithStorage[127.0.0.1:36456,DS-195f1c9c-6781-45ec-bf27-0577c01d2881,DISK], DatanodeInfoWithStorage[127.0.0.1:45353,DS-26e017ec-3d6b-4ac6-a6a7-dd3f7bb6d199,DISK], DatanodeInfoWithStorage[127.0.0.1:36449,DS-a284a668-d0e5-453e-aaa4-037f84690396,DISK], DatanodeInfoWithStorage[127.0.0.1:38844,DS-fc5a6143-7679-42cf-b1a3-314ad6126dff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1319302208-172.17.0.9-1597362869942:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45115,DS-e9a02233-e906-47ea-9fb2-a4ea0631f696,DISK], DatanodeInfoWithStorage[127.0.0.1:45324,DS-49ff133c-8f7b-4d4d-89a7-b5865e7831cb,DISK], DatanodeInfoWithStorage[127.0.0.1:32905,DS-161af06c-2979-43dc-af55-97c7d9902931,DISK], DatanodeInfoWithStorage[127.0.0.1:40440,DS-87d616d5-0afb-402c-b089-bea5e434435a,DISK], DatanodeInfoWithStorage[127.0.0.1:36456,DS-195f1c9c-6781-45ec-bf27-0577c01d2881,DISK], DatanodeInfoWithStorage[127.0.0.1:45353,DS-26e017ec-3d6b-4ac6-a6a7-dd3f7bb6d199,DISK], DatanodeInfoWithStorage[127.0.0.1:36449,DS-a284a668-d0e5-453e-aaa4-037f84690396,DISK], DatanodeInfoWithStorage[127.0.0.1:38844,DS-fc5a6143-7679-42cf-b1a3-314ad6126dff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-958105955-172.17.0.9-1597363809597:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33292,DS-6954efee-e283-4711-8f0f-45f809b4c976,DISK], DatanodeInfoWithStorage[127.0.0.1:41013,DS-3375ea8d-2c9f-4e38-8956-ececa6a540ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45418,DS-bab6b85f-a315-42e6-9d5a-0e9dfcdbf6a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40228,DS-c4623ee2-a391-420b-a4a7-65e44ed1c3c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43612,DS-d617463e-6504-407f-a86e-d5dd44996a29,DISK], DatanodeInfoWithStorage[127.0.0.1:38796,DS-fcf0d605-b205-470f-880e-450d3fdb83aa,DISK], DatanodeInfoWithStorage[127.0.0.1:32768,DS-2a555424-2064-4afb-836b-4c585924e8e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34846,DS-af79ddb6-1578-4153-bc20-0709dba7dcc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-958105955-172.17.0.9-1597363809597:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33292,DS-6954efee-e283-4711-8f0f-45f809b4c976,DISK], DatanodeInfoWithStorage[127.0.0.1:41013,DS-3375ea8d-2c9f-4e38-8956-ececa6a540ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45418,DS-bab6b85f-a315-42e6-9d5a-0e9dfcdbf6a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40228,DS-c4623ee2-a391-420b-a4a7-65e44ed1c3c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43612,DS-d617463e-6504-407f-a86e-d5dd44996a29,DISK], DatanodeInfoWithStorage[127.0.0.1:38796,DS-fcf0d605-b205-470f-880e-450d3fdb83aa,DISK], DatanodeInfoWithStorage[127.0.0.1:32768,DS-2a555424-2064-4afb-836b-4c585924e8e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34846,DS-af79ddb6-1578-4153-bc20-0709dba7dcc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 1 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5515
