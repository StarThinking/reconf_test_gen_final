reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1065147308-172.17.0.3-1597531576958:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37306,DS-b1c8eb32-5824-4e5a-b664-802015be9464,DISK], DatanodeInfoWithStorage[127.0.0.1:42891,DS-d1b8e1db-532e-4b0b-89ce-8c2ff5ab8821,DISK], DatanodeInfoWithStorage[127.0.0.1:46628,DS-7fe314cb-95bb-4230-a32e-29d95f9ab6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44846,DS-0772b175-87d8-45a7-8199-9dc2cd40630a,DISK], DatanodeInfoWithStorage[127.0.0.1:45274,DS-0dbe9846-192c-4545-9327-1475f34ee5ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41612,DS-c6e6dd5e-7a15-484d-b535-314c9bd3ed35,DISK], DatanodeInfoWithStorage[127.0.0.1:41366,DS-defb93c1-9b5a-4018-abef-6a721e141d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42802,DS-decbe24d-de55-4356-a640-a540dfe1c3de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1065147308-172.17.0.3-1597531576958:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37306,DS-b1c8eb32-5824-4e5a-b664-802015be9464,DISK], DatanodeInfoWithStorage[127.0.0.1:42891,DS-d1b8e1db-532e-4b0b-89ce-8c2ff5ab8821,DISK], DatanodeInfoWithStorage[127.0.0.1:46628,DS-7fe314cb-95bb-4230-a32e-29d95f9ab6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44846,DS-0772b175-87d8-45a7-8199-9dc2cd40630a,DISK], DatanodeInfoWithStorage[127.0.0.1:45274,DS-0dbe9846-192c-4545-9327-1475f34ee5ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41612,DS-c6e6dd5e-7a15-484d-b535-314c9bd3ed35,DISK], DatanodeInfoWithStorage[127.0.0.1:41366,DS-defb93c1-9b5a-4018-abef-6a721e141d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42802,DS-decbe24d-de55-4356-a640-a540dfe1c3de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1057033172-172.17.0.3-1597532004812:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37222,DS-5e54c179-e7ed-4f7d-bf56-ec3f647e0760,DISK], DatanodeInfoWithStorage[127.0.0.1:37492,DS-59a5be60-3713-4183-b31f-4c5ecb533059,DISK], DatanodeInfoWithStorage[127.0.0.1:33585,DS-daaf4f1e-c5d8-478d-9566-359e6a25aee9,DISK], DatanodeInfoWithStorage[127.0.0.1:38019,DS-24419634-47e5-409a-bb41-194d10a89447,DISK], DatanodeInfoWithStorage[127.0.0.1:37685,DS-7303cada-02ad-43c4-aef2-247cb1f1783a,DISK], DatanodeInfoWithStorage[127.0.0.1:43079,DS-31a6f6e8-0e0f-4958-9c94-6c8a9d38c9a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38508,DS-e0ee4940-3923-465f-a7f3-a189a79e019f,DISK], DatanodeInfoWithStorage[127.0.0.1:38576,DS-9d81b0c1-8a2b-42eb-85b2-794b17b50abb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1057033172-172.17.0.3-1597532004812:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37222,DS-5e54c179-e7ed-4f7d-bf56-ec3f647e0760,DISK], DatanodeInfoWithStorage[127.0.0.1:37492,DS-59a5be60-3713-4183-b31f-4c5ecb533059,DISK], DatanodeInfoWithStorage[127.0.0.1:33585,DS-daaf4f1e-c5d8-478d-9566-359e6a25aee9,DISK], DatanodeInfoWithStorage[127.0.0.1:38019,DS-24419634-47e5-409a-bb41-194d10a89447,DISK], DatanodeInfoWithStorage[127.0.0.1:37685,DS-7303cada-02ad-43c4-aef2-247cb1f1783a,DISK], DatanodeInfoWithStorage[127.0.0.1:43079,DS-31a6f6e8-0e0f-4958-9c94-6c8a9d38c9a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38508,DS-e0ee4940-3923-465f-a7f3-a189a79e019f,DISK], DatanodeInfoWithStorage[127.0.0.1:38576,DS-9d81b0c1-8a2b-42eb-85b2-794b17b50abb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1129404157-172.17.0.3-1597532118323:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38707,DS-be92a552-5d4a-4f44-aa25-82c44dfdc1b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34876,DS-ab762b45-31a6-44f9-9538-7b1247540235,DISK], DatanodeInfoWithStorage[127.0.0.1:39637,DS-097cbe50-7e93-4b20-948b-4ec6dd3660a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45253,DS-a4c2a7f2-7ed5-4ff0-996d-500f902f49b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37339,DS-66cbb21a-2c54-42c4-a6e8-711b221b7e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35573,DS-41b4657c-60e7-4293-9b13-f9a49be21036,DISK], DatanodeInfoWithStorage[127.0.0.1:33295,DS-33d3b041-2443-4b78-a54f-802f9f8562d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41108,DS-048694f9-81bb-4376-a1e4-8d2ff335bb54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1129404157-172.17.0.3-1597532118323:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38707,DS-be92a552-5d4a-4f44-aa25-82c44dfdc1b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34876,DS-ab762b45-31a6-44f9-9538-7b1247540235,DISK], DatanodeInfoWithStorage[127.0.0.1:39637,DS-097cbe50-7e93-4b20-948b-4ec6dd3660a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45253,DS-a4c2a7f2-7ed5-4ff0-996d-500f902f49b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37339,DS-66cbb21a-2c54-42c4-a6e8-711b221b7e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35573,DS-41b4657c-60e7-4293-9b13-f9a49be21036,DISK], DatanodeInfoWithStorage[127.0.0.1:33295,DS-33d3b041-2443-4b78-a54f-802f9f8562d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41108,DS-048694f9-81bb-4376-a1e4-8d2ff335bb54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1114680899-172.17.0.3-1597532631654:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38938,DS-0fe23a7b-2816-4fbf-82a2-513a1125e81d,DISK], DatanodeInfoWithStorage[127.0.0.1:40615,DS-41a197ec-f2ab-4b5b-8504-85d34f5c50c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42308,DS-94b1e05b-95f6-4fb4-ad59-d44229c7f485,DISK], DatanodeInfoWithStorage[127.0.0.1:35715,DS-adfac5be-bc9a-410e-a73a-79cf12cf3257,DISK], DatanodeInfoWithStorage[127.0.0.1:35847,DS-bdd212a5-3798-4d2c-828a-715ce51e7e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39870,DS-d347f69b-8b9d-4451-bca0-c258b196d8d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40762,DS-0248973d-5607-4e09-81a2-b93937eb9e39,DISK], DatanodeInfoWithStorage[127.0.0.1:35809,DS-9960f117-d99e-4b8a-821f-39b7816603db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1114680899-172.17.0.3-1597532631654:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38938,DS-0fe23a7b-2816-4fbf-82a2-513a1125e81d,DISK], DatanodeInfoWithStorage[127.0.0.1:40615,DS-41a197ec-f2ab-4b5b-8504-85d34f5c50c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42308,DS-94b1e05b-95f6-4fb4-ad59-d44229c7f485,DISK], DatanodeInfoWithStorage[127.0.0.1:35715,DS-adfac5be-bc9a-410e-a73a-79cf12cf3257,DISK], DatanodeInfoWithStorage[127.0.0.1:35847,DS-bdd212a5-3798-4d2c-828a-715ce51e7e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39870,DS-d347f69b-8b9d-4451-bca0-c258b196d8d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40762,DS-0248973d-5607-4e09-81a2-b93937eb9e39,DISK], DatanodeInfoWithStorage[127.0.0.1:35809,DS-9960f117-d99e-4b8a-821f-39b7816603db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1863671809-172.17.0.3-1597532835357:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43741,DS-5088aa89-2402-4ce3-a703-e64359bad4ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45812,DS-8e469854-7911-4c10-931b-cfe5e339ced4,DISK], DatanodeInfoWithStorage[127.0.0.1:39828,DS-43d3fea2-a2da-4137-8741-634270540d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:34676,DS-6cfb22d5-2eeb-42ca-abb9-3e3f4229e1c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36101,DS-d05c4269-d169-4bb6-8ddb-c57fd73dcc65,DISK], DatanodeInfoWithStorage[127.0.0.1:35946,DS-ee741b5c-f500-42da-abd8-290f54ed8bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:40325,DS-92d829a0-f664-405b-a1db-c1f89a46452d,DISK], DatanodeInfoWithStorage[127.0.0.1:36747,DS-643aed90-e58d-457f-97b7-2a4e01f7a69b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1863671809-172.17.0.3-1597532835357:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43741,DS-5088aa89-2402-4ce3-a703-e64359bad4ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45812,DS-8e469854-7911-4c10-931b-cfe5e339ced4,DISK], DatanodeInfoWithStorage[127.0.0.1:39828,DS-43d3fea2-a2da-4137-8741-634270540d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:34676,DS-6cfb22d5-2eeb-42ca-abb9-3e3f4229e1c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36101,DS-d05c4269-d169-4bb6-8ddb-c57fd73dcc65,DISK], DatanodeInfoWithStorage[127.0.0.1:35946,DS-ee741b5c-f500-42da-abd8-290f54ed8bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:40325,DS-92d829a0-f664-405b-a1db-c1f89a46452d,DISK], DatanodeInfoWithStorage[127.0.0.1:36747,DS-643aed90-e58d-457f-97b7-2a4e01f7a69b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1137993667-172.17.0.3-1597533623967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45777,DS-330f9acb-5a6d-4cbc-ba25-6f473ecf0f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45523,DS-3ed87c07-0fb8-4efa-8d97-417e6130dfb3,DISK], DatanodeInfoWithStorage[127.0.0.1:33429,DS-f22a75e0-38f1-47db-9e91-84f8a750be51,DISK], DatanodeInfoWithStorage[127.0.0.1:37084,DS-e6569f2d-5492-4fc2-b804-2486a074def6,DISK], DatanodeInfoWithStorage[127.0.0.1:38973,DS-385a92bf-c831-47d2-9ffb-36d6ec37989d,DISK], DatanodeInfoWithStorage[127.0.0.1:42321,DS-461a6945-e3e5-4504-a76f-d356168768c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45920,DS-d09af8db-05e7-4889-9c46-b0dbea0c2cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:40953,DS-0fb9fd68-70c5-4413-a576-e772101730c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1137993667-172.17.0.3-1597533623967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45777,DS-330f9acb-5a6d-4cbc-ba25-6f473ecf0f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45523,DS-3ed87c07-0fb8-4efa-8d97-417e6130dfb3,DISK], DatanodeInfoWithStorage[127.0.0.1:33429,DS-f22a75e0-38f1-47db-9e91-84f8a750be51,DISK], DatanodeInfoWithStorage[127.0.0.1:37084,DS-e6569f2d-5492-4fc2-b804-2486a074def6,DISK], DatanodeInfoWithStorage[127.0.0.1:38973,DS-385a92bf-c831-47d2-9ffb-36d6ec37989d,DISK], DatanodeInfoWithStorage[127.0.0.1:42321,DS-461a6945-e3e5-4504-a76f-d356168768c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45920,DS-d09af8db-05e7-4889-9c46-b0dbea0c2cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:40953,DS-0fb9fd68-70c5-4413-a576-e772101730c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1071721255-172.17.0.3-1597533735891:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34512,DS-7ca9c2f0-d6b9-4120-842c-c5aa4577f3aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33792,DS-6d437211-1250-44bb-b668-6b766da0ecba,DISK], DatanodeInfoWithStorage[127.0.0.1:32837,DS-e8ebc61e-ec1b-4b0b-a552-1a3ef75fca83,DISK], DatanodeInfoWithStorage[127.0.0.1:45043,DS-f7a295cc-6a67-4b1f-b1fa-d8f431c8e151,DISK], DatanodeInfoWithStorage[127.0.0.1:45474,DS-04be5edc-0d3d-4737-8268-136012d5b5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39724,DS-2919c387-2cd6-48d9-8a18-083264067908,DISK], DatanodeInfoWithStorage[127.0.0.1:46067,DS-0a738dc0-edbb-471b-b3cc-8c371cd7966d,DISK], DatanodeInfoWithStorage[127.0.0.1:40016,DS-9234c763-4c45-4c5a-aab9-136b41093f92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1071721255-172.17.0.3-1597533735891:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34512,DS-7ca9c2f0-d6b9-4120-842c-c5aa4577f3aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33792,DS-6d437211-1250-44bb-b668-6b766da0ecba,DISK], DatanodeInfoWithStorage[127.0.0.1:32837,DS-e8ebc61e-ec1b-4b0b-a552-1a3ef75fca83,DISK], DatanodeInfoWithStorage[127.0.0.1:45043,DS-f7a295cc-6a67-4b1f-b1fa-d8f431c8e151,DISK], DatanodeInfoWithStorage[127.0.0.1:45474,DS-04be5edc-0d3d-4737-8268-136012d5b5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39724,DS-2919c387-2cd6-48d9-8a18-083264067908,DISK], DatanodeInfoWithStorage[127.0.0.1:46067,DS-0a738dc0-edbb-471b-b3cc-8c371cd7966d,DISK], DatanodeInfoWithStorage[127.0.0.1:40016,DS-9234c763-4c45-4c5a-aab9-136b41093f92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1340452949-172.17.0.3-1597534063282:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40898,DS-f676675a-3e50-4909-9f6a-3b3f6d7ba580,DISK], DatanodeInfoWithStorage[127.0.0.1:44801,DS-67bce72d-a2cd-447f-9afd-5329d4f1423d,DISK], DatanodeInfoWithStorage[127.0.0.1:34306,DS-bf59a88d-1e4b-457a-9c1e-ec1e6ad26813,DISK], DatanodeInfoWithStorage[127.0.0.1:46397,DS-0643a275-b87c-4b33-a535-bcb353e0c032,DISK], DatanodeInfoWithStorage[127.0.0.1:44412,DS-8d686abd-ffa3-4390-87bf-4328b6fefa91,DISK], DatanodeInfoWithStorage[127.0.0.1:38635,DS-8e45cdff-31b1-48a3-88d4-5ca93d7320ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45834,DS-17c591aa-7133-4730-9612-6e13971b6dce,DISK], DatanodeInfoWithStorage[127.0.0.1:40539,DS-df184e42-182a-485f-9f0e-d11d12ec7120,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1340452949-172.17.0.3-1597534063282:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40898,DS-f676675a-3e50-4909-9f6a-3b3f6d7ba580,DISK], DatanodeInfoWithStorage[127.0.0.1:44801,DS-67bce72d-a2cd-447f-9afd-5329d4f1423d,DISK], DatanodeInfoWithStorage[127.0.0.1:34306,DS-bf59a88d-1e4b-457a-9c1e-ec1e6ad26813,DISK], DatanodeInfoWithStorage[127.0.0.1:46397,DS-0643a275-b87c-4b33-a535-bcb353e0c032,DISK], DatanodeInfoWithStorage[127.0.0.1:44412,DS-8d686abd-ffa3-4390-87bf-4328b6fefa91,DISK], DatanodeInfoWithStorage[127.0.0.1:38635,DS-8e45cdff-31b1-48a3-88d4-5ca93d7320ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45834,DS-17c591aa-7133-4730-9612-6e13971b6dce,DISK], DatanodeInfoWithStorage[127.0.0.1:40539,DS-df184e42-182a-485f-9f0e-d11d12ec7120,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-897524783-172.17.0.3-1597534141708:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33715,DS-4b45b347-69e4-4ddc-a9bb-726779edc2fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42057,DS-dd46478f-eea2-401b-bbf4-7768887e7003,DISK], DatanodeInfoWithStorage[127.0.0.1:33648,DS-6c44c75f-9dfc-408f-9dc3-a5f9e542a58a,DISK], DatanodeInfoWithStorage[127.0.0.1:35750,DS-986695b1-7e3d-4321-8564-b6596d0cd40e,DISK], DatanodeInfoWithStorage[127.0.0.1:33564,DS-af06ca17-3bee-442c-8aa9-e5cc298934f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35417,DS-770b8373-3e00-4c27-b4a0-9eba97287e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36449,DS-9470e670-5476-4c10-a98c-37be2bff1420,DISK], DatanodeInfoWithStorage[127.0.0.1:37549,DS-36b59278-f75b-47bc-add9-71cbefbe352e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-897524783-172.17.0.3-1597534141708:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33715,DS-4b45b347-69e4-4ddc-a9bb-726779edc2fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42057,DS-dd46478f-eea2-401b-bbf4-7768887e7003,DISK], DatanodeInfoWithStorage[127.0.0.1:33648,DS-6c44c75f-9dfc-408f-9dc3-a5f9e542a58a,DISK], DatanodeInfoWithStorage[127.0.0.1:35750,DS-986695b1-7e3d-4321-8564-b6596d0cd40e,DISK], DatanodeInfoWithStorage[127.0.0.1:33564,DS-af06ca17-3bee-442c-8aa9-e5cc298934f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35417,DS-770b8373-3e00-4c27-b4a0-9eba97287e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36449,DS-9470e670-5476-4c10-a98c-37be2bff1420,DISK], DatanodeInfoWithStorage[127.0.0.1:37549,DS-36b59278-f75b-47bc-add9-71cbefbe352e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-277066481-172.17.0.3-1597534439130:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43953,DS-d9aab048-7256-4c05-a3e7-5866b05c43a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44199,DS-757fd7ce-e98f-4239-9256-5a6253700f17,DISK], DatanodeInfoWithStorage[127.0.0.1:36531,DS-76635fac-c44f-4484-91e4-89c8d20ebd74,DISK], DatanodeInfoWithStorage[127.0.0.1:45399,DS-bb638df8-5750-447d-a0b4-58980a3a5de9,DISK], DatanodeInfoWithStorage[127.0.0.1:38581,DS-c88bfaed-27ae-439c-96b0-07179787a870,DISK], DatanodeInfoWithStorage[127.0.0.1:39805,DS-870afe6e-2670-488d-a6c3-a2cc6b765985,DISK], DatanodeInfoWithStorage[127.0.0.1:33651,DS-29598183-f80b-4238-a45e-4983874611ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33536,DS-e07851a9-fbeb-402e-9663-9445d60cf791,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-277066481-172.17.0.3-1597534439130:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43953,DS-d9aab048-7256-4c05-a3e7-5866b05c43a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44199,DS-757fd7ce-e98f-4239-9256-5a6253700f17,DISK], DatanodeInfoWithStorage[127.0.0.1:36531,DS-76635fac-c44f-4484-91e4-89c8d20ebd74,DISK], DatanodeInfoWithStorage[127.0.0.1:45399,DS-bb638df8-5750-447d-a0b4-58980a3a5de9,DISK], DatanodeInfoWithStorage[127.0.0.1:38581,DS-c88bfaed-27ae-439c-96b0-07179787a870,DISK], DatanodeInfoWithStorage[127.0.0.1:39805,DS-870afe6e-2670-488d-a6c3-a2cc6b765985,DISK], DatanodeInfoWithStorage[127.0.0.1:33651,DS-29598183-f80b-4238-a45e-4983874611ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33536,DS-e07851a9-fbeb-402e-9663-9445d60cf791,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-489861223-172.17.0.3-1597534899910:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36073,DS-c21f85e6-117f-48fc-b4d3-2d0bbb271a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:39645,DS-7d24ea65-46c3-4fd5-8f01-030fd2cbc5ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45318,DS-8a6b1c83-ba28-494f-9c32-bc39d178a669,DISK], DatanodeInfoWithStorage[127.0.0.1:41954,DS-2708c795-6b4c-40eb-8bed-10edc0510e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:43034,DS-7082ee3e-c5d0-4a16-9c55-98abdf4e49ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38785,DS-4d6999e0-4c79-47bb-9743-c9544a997bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:34830,DS-546ad7ae-ccbe-43db-91d6-37f69129da93,DISK], DatanodeInfoWithStorage[127.0.0.1:41622,DS-5aa9b5bf-dc75-4695-9809-f5fa6df1263e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-489861223-172.17.0.3-1597534899910:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36073,DS-c21f85e6-117f-48fc-b4d3-2d0bbb271a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:39645,DS-7d24ea65-46c3-4fd5-8f01-030fd2cbc5ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45318,DS-8a6b1c83-ba28-494f-9c32-bc39d178a669,DISK], DatanodeInfoWithStorage[127.0.0.1:41954,DS-2708c795-6b4c-40eb-8bed-10edc0510e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:43034,DS-7082ee3e-c5d0-4a16-9c55-98abdf4e49ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38785,DS-4d6999e0-4c79-47bb-9743-c9544a997bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:34830,DS-546ad7ae-ccbe-43db-91d6-37f69129da93,DISK], DatanodeInfoWithStorage[127.0.0.1:41622,DS-5aa9b5bf-dc75-4695-9809-f5fa6df1263e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1069349201-172.17.0.3-1597535178722:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33339,DS-e9f54fba-b234-4937-881b-8af968273daa,DISK], DatanodeInfoWithStorage[127.0.0.1:34618,DS-2af0427a-5e54-4eaa-ab0a-41a92a195f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43689,DS-3a9ddcc5-1112-4379-bff7-c057d462f121,DISK], DatanodeInfoWithStorage[127.0.0.1:45569,DS-0be3b314-452e-43ce-b2f2-51dd604d4e50,DISK], DatanodeInfoWithStorage[127.0.0.1:39903,DS-6bf15624-4f3f-48bf-867d-4d84ea2f908c,DISK], DatanodeInfoWithStorage[127.0.0.1:37144,DS-1c6f4a5c-b353-4025-999c-084470cc4475,DISK], DatanodeInfoWithStorage[127.0.0.1:40198,DS-d7f2856b-5475-4aab-a3f3-595b125778a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38718,DS-c04d22a8-985d-45c3-b719-821406a19ba4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1069349201-172.17.0.3-1597535178722:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33339,DS-e9f54fba-b234-4937-881b-8af968273daa,DISK], DatanodeInfoWithStorage[127.0.0.1:34618,DS-2af0427a-5e54-4eaa-ab0a-41a92a195f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43689,DS-3a9ddcc5-1112-4379-bff7-c057d462f121,DISK], DatanodeInfoWithStorage[127.0.0.1:45569,DS-0be3b314-452e-43ce-b2f2-51dd604d4e50,DISK], DatanodeInfoWithStorage[127.0.0.1:39903,DS-6bf15624-4f3f-48bf-867d-4d84ea2f908c,DISK], DatanodeInfoWithStorage[127.0.0.1:37144,DS-1c6f4a5c-b353-4025-999c-084470cc4475,DISK], DatanodeInfoWithStorage[127.0.0.1:40198,DS-d7f2856b-5475-4aab-a3f3-595b125778a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38718,DS-c04d22a8-985d-45c3-b719-821406a19ba4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-969227416-172.17.0.3-1597535419523:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44472,DS-657fda06-7540-4f24-85ce-4421994e58b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-679a4a2d-c0dd-4b50-a821-cffd2dddefb8,DISK], DatanodeInfoWithStorage[127.0.0.1:39565,DS-4f723280-29bb-4dba-ab1d-fa9d76cb8411,DISK], DatanodeInfoWithStorage[127.0.0.1:35342,DS-fbacb9b0-752a-4239-a2d6-4e11bb88e186,DISK], DatanodeInfoWithStorage[127.0.0.1:33472,DS-80d99eba-745c-4fdd-956b-965666a811b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45946,DS-8de81093-8dc2-4412-8bc1-7998f0ca4edd,DISK], DatanodeInfoWithStorage[127.0.0.1:36197,DS-9986443a-ad9b-4ef0-b2b7-fcb2e837bb95,DISK], DatanodeInfoWithStorage[127.0.0.1:37282,DS-0e98180a-4eb3-47a0-a233-d2cbb6e7b86b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-969227416-172.17.0.3-1597535419523:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44472,DS-657fda06-7540-4f24-85ce-4421994e58b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-679a4a2d-c0dd-4b50-a821-cffd2dddefb8,DISK], DatanodeInfoWithStorage[127.0.0.1:39565,DS-4f723280-29bb-4dba-ab1d-fa9d76cb8411,DISK], DatanodeInfoWithStorage[127.0.0.1:35342,DS-fbacb9b0-752a-4239-a2d6-4e11bb88e186,DISK], DatanodeInfoWithStorage[127.0.0.1:33472,DS-80d99eba-745c-4fdd-956b-965666a811b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45946,DS-8de81093-8dc2-4412-8bc1-7998f0ca4edd,DISK], DatanodeInfoWithStorage[127.0.0.1:36197,DS-9986443a-ad9b-4ef0-b2b7-fcb2e837bb95,DISK], DatanodeInfoWithStorage[127.0.0.1:37282,DS-0e98180a-4eb3-47a0-a233-d2cbb6e7b86b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1878626708-172.17.0.3-1597535969121:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36904,DS-68555550-aa12-4bb9-86d0-8d8590890d55,DISK], DatanodeInfoWithStorage[127.0.0.1:43598,DS-91644959-df3e-4184-9656-6d138424c2f6,DISK], DatanodeInfoWithStorage[127.0.0.1:32837,DS-b6c1db9a-714e-4f38-9f8f-d69deb5f8513,DISK], DatanodeInfoWithStorage[127.0.0.1:33448,DS-4086a73b-da5b-4f61-bf83-f4ca5d28833b,DISK], DatanodeInfoWithStorage[127.0.0.1:37987,DS-69ede8d4-373a-43cc-8145-eb0b0c50cd53,DISK], DatanodeInfoWithStorage[127.0.0.1:40358,DS-56cee7d5-d1d8-4359-ba24-fcabd949aa32,DISK], DatanodeInfoWithStorage[127.0.0.1:46187,DS-526012ca-df95-44aa-b216-b28f8585fc5a,DISK], DatanodeInfoWithStorage[127.0.0.1:36160,DS-10ace35f-272c-4387-a596-eed60936babf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1878626708-172.17.0.3-1597535969121:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36904,DS-68555550-aa12-4bb9-86d0-8d8590890d55,DISK], DatanodeInfoWithStorage[127.0.0.1:43598,DS-91644959-df3e-4184-9656-6d138424c2f6,DISK], DatanodeInfoWithStorage[127.0.0.1:32837,DS-b6c1db9a-714e-4f38-9f8f-d69deb5f8513,DISK], DatanodeInfoWithStorage[127.0.0.1:33448,DS-4086a73b-da5b-4f61-bf83-f4ca5d28833b,DISK], DatanodeInfoWithStorage[127.0.0.1:37987,DS-69ede8d4-373a-43cc-8145-eb0b0c50cd53,DISK], DatanodeInfoWithStorage[127.0.0.1:40358,DS-56cee7d5-d1d8-4359-ba24-fcabd949aa32,DISK], DatanodeInfoWithStorage[127.0.0.1:46187,DS-526012ca-df95-44aa-b216-b28f8585fc5a,DISK], DatanodeInfoWithStorage[127.0.0.1:36160,DS-10ace35f-272c-4387-a596-eed60936babf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-282555495-172.17.0.3-1597536162053:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42275,DS-829800d3-d8a1-46ba-a444-d4a6285bab3f,DISK], DatanodeInfoWithStorage[127.0.0.1:34977,DS-1926777c-8c2d-46ec-a716-e81801fae65f,DISK], DatanodeInfoWithStorage[127.0.0.1:34269,DS-d2a07bad-c1f6-4aab-b3f3-1b55a6ebd699,DISK], DatanodeInfoWithStorage[127.0.0.1:37279,DS-57b14b8a-2a6a-4aa2-b911-fae5f51f4a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:46337,DS-38aea86e-93c4-4343-a282-0730b9fde27b,DISK], DatanodeInfoWithStorage[127.0.0.1:41876,DS-3a321b31-acd0-4370-8806-967502c7ef06,DISK], DatanodeInfoWithStorage[127.0.0.1:46071,DS-05a284d4-04bc-4943-bc98-cb6643433760,DISK], DatanodeInfoWithStorage[127.0.0.1:33259,DS-97efad95-b58d-47a2-9e6c-49d15ca8a62f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-282555495-172.17.0.3-1597536162053:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42275,DS-829800d3-d8a1-46ba-a444-d4a6285bab3f,DISK], DatanodeInfoWithStorage[127.0.0.1:34977,DS-1926777c-8c2d-46ec-a716-e81801fae65f,DISK], DatanodeInfoWithStorage[127.0.0.1:34269,DS-d2a07bad-c1f6-4aab-b3f3-1b55a6ebd699,DISK], DatanodeInfoWithStorage[127.0.0.1:37279,DS-57b14b8a-2a6a-4aa2-b911-fae5f51f4a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:46337,DS-38aea86e-93c4-4343-a282-0730b9fde27b,DISK], DatanodeInfoWithStorage[127.0.0.1:41876,DS-3a321b31-acd0-4370-8806-967502c7ef06,DISK], DatanodeInfoWithStorage[127.0.0.1:46071,DS-05a284d4-04bc-4943-bc98-cb6643433760,DISK], DatanodeInfoWithStorage[127.0.0.1:33259,DS-97efad95-b58d-47a2-9e6c-49d15ca8a62f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-101951769-172.17.0.3-1597536362645:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44408,DS-443f66be-6787-4b8b-a667-3d56e98bbd41,DISK], DatanodeInfoWithStorage[127.0.0.1:42213,DS-f8b87e41-916d-4605-91ac-dd85fc6d5abb,DISK], DatanodeInfoWithStorage[127.0.0.1:39445,DS-bc8fa886-2722-4b0f-9029-a7b955771c80,DISK], DatanodeInfoWithStorage[127.0.0.1:35280,DS-59464067-269f-4bc3-acab-6b95430a0e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43671,DS-1d7aceea-57bb-423a-81c1-212ccf32cd49,DISK], DatanodeInfoWithStorage[127.0.0.1:40353,DS-02db4fa4-1b8b-4031-bcb6-3f294a5981b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43421,DS-4650cac7-bca7-4ed8-b78c-2f7ee81def8c,DISK], DatanodeInfoWithStorage[127.0.0.1:37935,DS-ae5442cb-c134-40fc-a0a2-19f748c17da8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-101951769-172.17.0.3-1597536362645:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44408,DS-443f66be-6787-4b8b-a667-3d56e98bbd41,DISK], DatanodeInfoWithStorage[127.0.0.1:42213,DS-f8b87e41-916d-4605-91ac-dd85fc6d5abb,DISK], DatanodeInfoWithStorage[127.0.0.1:39445,DS-bc8fa886-2722-4b0f-9029-a7b955771c80,DISK], DatanodeInfoWithStorage[127.0.0.1:35280,DS-59464067-269f-4bc3-acab-6b95430a0e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43671,DS-1d7aceea-57bb-423a-81c1-212ccf32cd49,DISK], DatanodeInfoWithStorage[127.0.0.1:40353,DS-02db4fa4-1b8b-4031-bcb6-3f294a5981b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43421,DS-4650cac7-bca7-4ed8-b78c-2f7ee81def8c,DISK], DatanodeInfoWithStorage[127.0.0.1:37935,DS-ae5442cb-c134-40fc-a0a2-19f748c17da8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-271572757-172.17.0.3-1597536735258:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44768,DS-a065a2fa-2506-432e-a8f1-e7354d3f6b54,DISK], DatanodeInfoWithStorage[127.0.0.1:34557,DS-48b70f23-946e-404f-ae5d-390165ea13c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39142,DS-6a874501-e29c-498a-bc1d-4a8391586741,DISK], DatanodeInfoWithStorage[127.0.0.1:40702,DS-59bca1b0-0cc4-4220-975c-2aea85766326,DISK], DatanodeInfoWithStorage[127.0.0.1:39589,DS-4423c6b6-603a-4aea-b96c-40f1af20edb5,DISK], DatanodeInfoWithStorage[127.0.0.1:46288,DS-a7b86f5c-af5a-467c-9a9b-67a0ac91cb08,DISK], DatanodeInfoWithStorage[127.0.0.1:41859,DS-2bb4b036-2c44-411e-a698-098c4dc91be9,DISK], DatanodeInfoWithStorage[127.0.0.1:36368,DS-6ce0301c-70c5-4071-af88-5366cf8fa8d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-271572757-172.17.0.3-1597536735258:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44768,DS-a065a2fa-2506-432e-a8f1-e7354d3f6b54,DISK], DatanodeInfoWithStorage[127.0.0.1:34557,DS-48b70f23-946e-404f-ae5d-390165ea13c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39142,DS-6a874501-e29c-498a-bc1d-4a8391586741,DISK], DatanodeInfoWithStorage[127.0.0.1:40702,DS-59bca1b0-0cc4-4220-975c-2aea85766326,DISK], DatanodeInfoWithStorage[127.0.0.1:39589,DS-4423c6b6-603a-4aea-b96c-40f1af20edb5,DISK], DatanodeInfoWithStorage[127.0.0.1:46288,DS-a7b86f5c-af5a-467c-9a9b-67a0ac91cb08,DISK], DatanodeInfoWithStorage[127.0.0.1:41859,DS-2bb4b036-2c44-411e-a698-098c4dc91be9,DISK], DatanodeInfoWithStorage[127.0.0.1:36368,DS-6ce0301c-70c5-4071-af88-5366cf8fa8d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1865584407-172.17.0.3-1597536932293:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36716,DS-8ef25982-8fbc-4534-adb8-25cfd290b083,DISK], DatanodeInfoWithStorage[127.0.0.1:43771,DS-ca9df52c-e244-4a85-b6cb-863bcbcd2a90,DISK], DatanodeInfoWithStorage[127.0.0.1:37756,DS-8108aec1-b00c-4d55-835b-37851d36ee03,DISK], DatanodeInfoWithStorage[127.0.0.1:39167,DS-cf1e6566-fca1-463f-8093-1d1bac2910f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37761,DS-d798d412-13b1-41ee-b558-0310fd9dfb52,DISK], DatanodeInfoWithStorage[127.0.0.1:40042,DS-1a02a9da-b4fd-462c-af38-b1c6104b3903,DISK], DatanodeInfoWithStorage[127.0.0.1:37450,DS-3859b8fb-ad63-4004-b97d-c27e957914bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33640,DS-b26f4a5c-b401-4bd2-ad4a-74267cb11d95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1865584407-172.17.0.3-1597536932293:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36716,DS-8ef25982-8fbc-4534-adb8-25cfd290b083,DISK], DatanodeInfoWithStorage[127.0.0.1:43771,DS-ca9df52c-e244-4a85-b6cb-863bcbcd2a90,DISK], DatanodeInfoWithStorage[127.0.0.1:37756,DS-8108aec1-b00c-4d55-835b-37851d36ee03,DISK], DatanodeInfoWithStorage[127.0.0.1:39167,DS-cf1e6566-fca1-463f-8093-1d1bac2910f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37761,DS-d798d412-13b1-41ee-b558-0310fd9dfb52,DISK], DatanodeInfoWithStorage[127.0.0.1:40042,DS-1a02a9da-b4fd-462c-af38-b1c6104b3903,DISK], DatanodeInfoWithStorage[127.0.0.1:37450,DS-3859b8fb-ad63-4004-b97d-c27e957914bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33640,DS-b26f4a5c-b401-4bd2-ad4a-74267cb11d95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5575
