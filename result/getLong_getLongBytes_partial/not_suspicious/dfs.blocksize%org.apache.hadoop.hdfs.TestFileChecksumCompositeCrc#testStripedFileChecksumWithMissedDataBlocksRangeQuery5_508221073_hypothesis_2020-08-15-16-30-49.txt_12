reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-780712639-172.17.0.6-1597510032655:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34437,DS-2d4d6d38-fea0-4ae7-94eb-d0a131b1b304,DISK], DatanodeInfoWithStorage[127.0.0.1:34475,DS-a37be13a-5cce-49bb-a359-d47e396a3844,DISK], DatanodeInfoWithStorage[127.0.0.1:38250,DS-161e4908-012d-4d9f-ba5a-59dd04c69fda,DISK], DatanodeInfoWithStorage[127.0.0.1:43558,DS-bb3cca91-6242-4ef6-97a3-6915cd9825ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38921,DS-62a421a1-da8f-4181-bda5-a989a347249b,DISK], DatanodeInfoWithStorage[127.0.0.1:39513,DS-654f0da3-4944-4df1-948e-cdc68d11a0d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44860,DS-d76c0058-43b3-4da4-82ae-dc819277437e,DISK], DatanodeInfoWithStorage[127.0.0.1:32771,DS-d1eea18e-cd59-46ce-93d7-b8188a8a6b28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-780712639-172.17.0.6-1597510032655:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34437,DS-2d4d6d38-fea0-4ae7-94eb-d0a131b1b304,DISK], DatanodeInfoWithStorage[127.0.0.1:34475,DS-a37be13a-5cce-49bb-a359-d47e396a3844,DISK], DatanodeInfoWithStorage[127.0.0.1:38250,DS-161e4908-012d-4d9f-ba5a-59dd04c69fda,DISK], DatanodeInfoWithStorage[127.0.0.1:43558,DS-bb3cca91-6242-4ef6-97a3-6915cd9825ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38921,DS-62a421a1-da8f-4181-bda5-a989a347249b,DISK], DatanodeInfoWithStorage[127.0.0.1:39513,DS-654f0da3-4944-4df1-948e-cdc68d11a0d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44860,DS-d76c0058-43b3-4da4-82ae-dc819277437e,DISK], DatanodeInfoWithStorage[127.0.0.1:32771,DS-d1eea18e-cd59-46ce-93d7-b8188a8a6b28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-267087177-172.17.0.6-1597510059952:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37208,DS-381c3841-466d-46f5-8c49-7058a78e080a,DISK], DatanodeInfoWithStorage[127.0.0.1:39634,DS-46e15630-ab9e-46ff-a3ad-eceb87f6f978,DISK], DatanodeInfoWithStorage[127.0.0.1:37348,DS-0fa326fe-4e88-4567-b710-952f03b59bda,DISK], DatanodeInfoWithStorage[127.0.0.1:36874,DS-e0023ef5-4b0a-48a5-b763-7639717e8f02,DISK], DatanodeInfoWithStorage[127.0.0.1:41994,DS-186881e1-1bc0-4136-bfe0-eae72af5d078,DISK], DatanodeInfoWithStorage[127.0.0.1:41154,DS-ae71fb30-da31-4c97-bf8f-3fcde32fd6bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37350,DS-a324f59a-7cc2-43cf-aea1-8e927ed6d55f,DISK], DatanodeInfoWithStorage[127.0.0.1:39249,DS-24f9b57e-7ed4-4631-930f-2689688d3f28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-267087177-172.17.0.6-1597510059952:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37208,DS-381c3841-466d-46f5-8c49-7058a78e080a,DISK], DatanodeInfoWithStorage[127.0.0.1:39634,DS-46e15630-ab9e-46ff-a3ad-eceb87f6f978,DISK], DatanodeInfoWithStorage[127.0.0.1:37348,DS-0fa326fe-4e88-4567-b710-952f03b59bda,DISK], DatanodeInfoWithStorage[127.0.0.1:36874,DS-e0023ef5-4b0a-48a5-b763-7639717e8f02,DISK], DatanodeInfoWithStorage[127.0.0.1:41994,DS-186881e1-1bc0-4136-bfe0-eae72af5d078,DISK], DatanodeInfoWithStorage[127.0.0.1:41154,DS-ae71fb30-da31-4c97-bf8f-3fcde32fd6bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37350,DS-a324f59a-7cc2-43cf-aea1-8e927ed6d55f,DISK], DatanodeInfoWithStorage[127.0.0.1:39249,DS-24f9b57e-7ed4-4631-930f-2689688d3f28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-142754574-172.17.0.6-1597510098740:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39194,DS-3f30740a-2872-4b8b-8558-2c866c934d80,DISK], DatanodeInfoWithStorage[127.0.0.1:32939,DS-bbe2dbe4-2177-43ce-a09a-986f29316876,DISK], DatanodeInfoWithStorage[127.0.0.1:40520,DS-efac312f-3d1b-4baa-8d6b-2b62cdfd1f22,DISK], DatanodeInfoWithStorage[127.0.0.1:39457,DS-4bed58ad-a4ac-4202-9e47-5d7edbb3d26e,DISK], DatanodeInfoWithStorage[127.0.0.1:39131,DS-d5b29cea-1679-47f8-8acf-0d08585b3edc,DISK], DatanodeInfoWithStorage[127.0.0.1:37990,DS-6c04d7dd-5550-4c34-9079-e314431a02cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35742,DS-3da4fcc3-c44f-48a0-bd99-373e61ee3fef,DISK], DatanodeInfoWithStorage[127.0.0.1:42811,DS-d6a1c906-1e4b-4427-b9ee-3c535e7bc699,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-142754574-172.17.0.6-1597510098740:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39194,DS-3f30740a-2872-4b8b-8558-2c866c934d80,DISK], DatanodeInfoWithStorage[127.0.0.1:32939,DS-bbe2dbe4-2177-43ce-a09a-986f29316876,DISK], DatanodeInfoWithStorage[127.0.0.1:40520,DS-efac312f-3d1b-4baa-8d6b-2b62cdfd1f22,DISK], DatanodeInfoWithStorage[127.0.0.1:39457,DS-4bed58ad-a4ac-4202-9e47-5d7edbb3d26e,DISK], DatanodeInfoWithStorage[127.0.0.1:39131,DS-d5b29cea-1679-47f8-8acf-0d08585b3edc,DISK], DatanodeInfoWithStorage[127.0.0.1:37990,DS-6c04d7dd-5550-4c34-9079-e314431a02cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35742,DS-3da4fcc3-c44f-48a0-bd99-373e61ee3fef,DISK], DatanodeInfoWithStorage[127.0.0.1:42811,DS-d6a1c906-1e4b-4427-b9ee-3c535e7bc699,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1964291168-172.17.0.6-1597510560856:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44247,DS-d2068a0f-c17c-4d76-aea3-de9753463a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:37409,DS-0c3f269a-4095-4891-abe3-26cebcdcede4,DISK], DatanodeInfoWithStorage[127.0.0.1:37788,DS-747d501f-31f8-49fe-ae6f-ea0edec2cccf,DISK], DatanodeInfoWithStorage[127.0.0.1:46860,DS-d2139aa4-4157-49d3-950e-62bfdbca5500,DISK], DatanodeInfoWithStorage[127.0.0.1:41968,DS-b4ac0203-5cea-46f6-9833-b315fb0a2e61,DISK], DatanodeInfoWithStorage[127.0.0.1:38384,DS-4dbf76cc-3db4-4e44-a1fa-27e5fa46ea7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45512,DS-9e40b0b5-d634-447d-b29a-3e8f5370f037,DISK], DatanodeInfoWithStorage[127.0.0.1:46760,DS-1c8a7c84-e141-44d5-9b12-5e69b50e70eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1964291168-172.17.0.6-1597510560856:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44247,DS-d2068a0f-c17c-4d76-aea3-de9753463a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:37409,DS-0c3f269a-4095-4891-abe3-26cebcdcede4,DISK], DatanodeInfoWithStorage[127.0.0.1:37788,DS-747d501f-31f8-49fe-ae6f-ea0edec2cccf,DISK], DatanodeInfoWithStorage[127.0.0.1:46860,DS-d2139aa4-4157-49d3-950e-62bfdbca5500,DISK], DatanodeInfoWithStorage[127.0.0.1:41968,DS-b4ac0203-5cea-46f6-9833-b315fb0a2e61,DISK], DatanodeInfoWithStorage[127.0.0.1:38384,DS-4dbf76cc-3db4-4e44-a1fa-27e5fa46ea7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45512,DS-9e40b0b5-d634-447d-b29a-3e8f5370f037,DISK], DatanodeInfoWithStorage[127.0.0.1:46760,DS-1c8a7c84-e141-44d5-9b12-5e69b50e70eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1955143463-172.17.0.6-1597511552748:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33189,DS-cb22c522-a430-4a93-a8d4-29f824c79990,DISK], DatanodeInfoWithStorage[127.0.0.1:38777,DS-1c0e9363-a765-44cb-8613-b8c70e8b593b,DISK], DatanodeInfoWithStorage[127.0.0.1:44813,DS-f621b87a-ff9d-410f-b37a-ecf8b43fc27e,DISK], DatanodeInfoWithStorage[127.0.0.1:45432,DS-ceecd42a-7aee-44f5-a56f-9081efa60b57,DISK], DatanodeInfoWithStorage[127.0.0.1:35300,DS-5cb1e242-9191-47bf-8bd1-6a2a508c6068,DISK], DatanodeInfoWithStorage[127.0.0.1:44592,DS-1202afca-348f-42dc-a81a-5e8b9949b692,DISK], DatanodeInfoWithStorage[127.0.0.1:45677,DS-91d93c57-4288-47c9-8c5e-06d3b8946a17,DISK], DatanodeInfoWithStorage[127.0.0.1:46083,DS-8a6d239c-b768-41c8-a898-6b312fb21fd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1955143463-172.17.0.6-1597511552748:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33189,DS-cb22c522-a430-4a93-a8d4-29f824c79990,DISK], DatanodeInfoWithStorage[127.0.0.1:38777,DS-1c0e9363-a765-44cb-8613-b8c70e8b593b,DISK], DatanodeInfoWithStorage[127.0.0.1:44813,DS-f621b87a-ff9d-410f-b37a-ecf8b43fc27e,DISK], DatanodeInfoWithStorage[127.0.0.1:45432,DS-ceecd42a-7aee-44f5-a56f-9081efa60b57,DISK], DatanodeInfoWithStorage[127.0.0.1:35300,DS-5cb1e242-9191-47bf-8bd1-6a2a508c6068,DISK], DatanodeInfoWithStorage[127.0.0.1:44592,DS-1202afca-348f-42dc-a81a-5e8b9949b692,DISK], DatanodeInfoWithStorage[127.0.0.1:45677,DS-91d93c57-4288-47c9-8c5e-06d3b8946a17,DISK], DatanodeInfoWithStorage[127.0.0.1:46083,DS-8a6d239c-b768-41c8-a898-6b312fb21fd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1334816003-172.17.0.6-1597511980517:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44373,DS-69839eae-01dd-49b4-9ac8-0fdd8e1574f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38466,DS-9ff0dece-c8b0-406f-b6e3-d0be272c852a,DISK], DatanodeInfoWithStorage[127.0.0.1:44562,DS-ffb9d2ae-fb1c-4425-9158-9ff9fead1772,DISK], DatanodeInfoWithStorage[127.0.0.1:44091,DS-c8282393-9714-4df3-9a75-12cf6afa27e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39434,DS-34e9de97-96fc-442c-b6c2-237cdb26934e,DISK], DatanodeInfoWithStorage[127.0.0.1:42995,DS-d4f8eaac-82b2-4945-bd7c-cb5b7af4debd,DISK], DatanodeInfoWithStorage[127.0.0.1:39878,DS-8d94fdce-2ae4-4355-b46c-2ead01dde9b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33354,DS-bdd93c1c-5437-4e40-a0d6-b75e41c7c071,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1334816003-172.17.0.6-1597511980517:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44373,DS-69839eae-01dd-49b4-9ac8-0fdd8e1574f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38466,DS-9ff0dece-c8b0-406f-b6e3-d0be272c852a,DISK], DatanodeInfoWithStorage[127.0.0.1:44562,DS-ffb9d2ae-fb1c-4425-9158-9ff9fead1772,DISK], DatanodeInfoWithStorage[127.0.0.1:44091,DS-c8282393-9714-4df3-9a75-12cf6afa27e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39434,DS-34e9de97-96fc-442c-b6c2-237cdb26934e,DISK], DatanodeInfoWithStorage[127.0.0.1:42995,DS-d4f8eaac-82b2-4945-bd7c-cb5b7af4debd,DISK], DatanodeInfoWithStorage[127.0.0.1:39878,DS-8d94fdce-2ae4-4355-b46c-2ead01dde9b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33354,DS-bdd93c1c-5437-4e40-a0d6-b75e41c7c071,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-204779161-172.17.0.6-1597512207744:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45633,DS-c101008c-e33b-4303-ae64-b11dd827d131,DISK], DatanodeInfoWithStorage[127.0.0.1:37263,DS-70e0133d-f6c6-4cac-bb94-dd4ec0fa19f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33461,DS-7ae403fc-8798-4673-87db-e5c631dda239,DISK], DatanodeInfoWithStorage[127.0.0.1:35344,DS-716ec5d1-d03f-40e2-ad77-d02023a881d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44061,DS-04c65a94-e041-4f35-b17b-d71173ba7a77,DISK], DatanodeInfoWithStorage[127.0.0.1:33798,DS-2f9fd930-97a3-4d6a-a008-cc97d797b875,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-ae656b84-fc97-4992-81a5-6f48e29e247c,DISK], DatanodeInfoWithStorage[127.0.0.1:36733,DS-982187e9-f9ca-4e74-802e-333d0f23c882,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-204779161-172.17.0.6-1597512207744:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45633,DS-c101008c-e33b-4303-ae64-b11dd827d131,DISK], DatanodeInfoWithStorage[127.0.0.1:37263,DS-70e0133d-f6c6-4cac-bb94-dd4ec0fa19f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33461,DS-7ae403fc-8798-4673-87db-e5c631dda239,DISK], DatanodeInfoWithStorage[127.0.0.1:35344,DS-716ec5d1-d03f-40e2-ad77-d02023a881d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44061,DS-04c65a94-e041-4f35-b17b-d71173ba7a77,DISK], DatanodeInfoWithStorage[127.0.0.1:33798,DS-2f9fd930-97a3-4d6a-a008-cc97d797b875,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-ae656b84-fc97-4992-81a5-6f48e29e247c,DISK], DatanodeInfoWithStorage[127.0.0.1:36733,DS-982187e9-f9ca-4e74-802e-333d0f23c882,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-888613260-172.17.0.6-1597513180581:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40748,DS-8d5db0b1-0d07-4f45-9f8e-e05689acf3d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46007,DS-56330f95-2d79-4001-ab4e-085587fae8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37138,DS-0c8778f7-b2a6-400a-bf53-c41b989ba207,DISK], DatanodeInfoWithStorage[127.0.0.1:39472,DS-96cd6534-7ba5-42f7-b49a-c4a8ea0032a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42327,DS-38e9ac5c-7830-4ca1-a0df-997653099101,DISK], DatanodeInfoWithStorage[127.0.0.1:39900,DS-789faade-28ab-4699-88cc-89d527df168b,DISK], DatanodeInfoWithStorage[127.0.0.1:33719,DS-af6d27a3-9cff-4c07-a69a-ba1ed510431c,DISK], DatanodeInfoWithStorage[127.0.0.1:45213,DS-51200860-4fae-4a8f-93b9-7e5c9f498e8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-888613260-172.17.0.6-1597513180581:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40748,DS-8d5db0b1-0d07-4f45-9f8e-e05689acf3d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46007,DS-56330f95-2d79-4001-ab4e-085587fae8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37138,DS-0c8778f7-b2a6-400a-bf53-c41b989ba207,DISK], DatanodeInfoWithStorage[127.0.0.1:39472,DS-96cd6534-7ba5-42f7-b49a-c4a8ea0032a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42327,DS-38e9ac5c-7830-4ca1-a0df-997653099101,DISK], DatanodeInfoWithStorage[127.0.0.1:39900,DS-789faade-28ab-4699-88cc-89d527df168b,DISK], DatanodeInfoWithStorage[127.0.0.1:33719,DS-af6d27a3-9cff-4c07-a69a-ba1ed510431c,DISK], DatanodeInfoWithStorage[127.0.0.1:45213,DS-51200860-4fae-4a8f-93b9-7e5c9f498e8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1674491247-172.17.0.6-1597513220436:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36827,DS-71fb110b-738f-4a30-a1fa-06b973654494,DISK], DatanodeInfoWithStorage[127.0.0.1:41696,DS-77319b95-8f55-425f-baf2-72e422ca5f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43042,DS-e4138e2b-1e3f-4748-b4d0-16683a0de678,DISK], DatanodeInfoWithStorage[127.0.0.1:41376,DS-af2fca8c-a3fb-47c3-9933-ee9834c9e728,DISK], DatanodeInfoWithStorage[127.0.0.1:41854,DS-60de5151-dc3d-4f0e-a3ed-fc24b29df16b,DISK], DatanodeInfoWithStorage[127.0.0.1:43690,DS-e93ae28e-acff-41d8-81d8-da3cf98c0791,DISK], DatanodeInfoWithStorage[127.0.0.1:40263,DS-d9c746eb-66cd-45fc-843d-961a2bea02a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34559,DS-bd564f2d-ca47-4868-b937-96d17d4ac977,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1674491247-172.17.0.6-1597513220436:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36827,DS-71fb110b-738f-4a30-a1fa-06b973654494,DISK], DatanodeInfoWithStorage[127.0.0.1:41696,DS-77319b95-8f55-425f-baf2-72e422ca5f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43042,DS-e4138e2b-1e3f-4748-b4d0-16683a0de678,DISK], DatanodeInfoWithStorage[127.0.0.1:41376,DS-af2fca8c-a3fb-47c3-9933-ee9834c9e728,DISK], DatanodeInfoWithStorage[127.0.0.1:41854,DS-60de5151-dc3d-4f0e-a3ed-fc24b29df16b,DISK], DatanodeInfoWithStorage[127.0.0.1:43690,DS-e93ae28e-acff-41d8-81d8-da3cf98c0791,DISK], DatanodeInfoWithStorage[127.0.0.1:40263,DS-d9c746eb-66cd-45fc-843d-961a2bea02a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34559,DS-bd564f2d-ca47-4868-b937-96d17d4ac977,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-753372781-172.17.0.6-1597513740145:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35278,DS-21e1bc42-c461-465f-b4d7-23b87592fa0a,DISK], DatanodeInfoWithStorage[127.0.0.1:40741,DS-55319f37-f6af-43b2-8400-7a4900ce3c68,DISK], DatanodeInfoWithStorage[127.0.0.1:38153,DS-707f6299-dd64-458a-a9b6-108f7e88340c,DISK], DatanodeInfoWithStorage[127.0.0.1:44396,DS-60ed608d-45fc-4b23-93be-817859e62920,DISK], DatanodeInfoWithStorage[127.0.0.1:44348,DS-8e1b8069-e261-46b6-b4a0-e5bbc17740b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44537,DS-b0f9864b-17a5-4556-9a7f-547c4bb7ca79,DISK], DatanodeInfoWithStorage[127.0.0.1:35140,DS-9d7bc61d-3920-422b-8baa-f681c0d2609b,DISK], DatanodeInfoWithStorage[127.0.0.1:33957,DS-88ed77ad-eca7-4fdc-aba4-fe67643b0282,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-753372781-172.17.0.6-1597513740145:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35278,DS-21e1bc42-c461-465f-b4d7-23b87592fa0a,DISK], DatanodeInfoWithStorage[127.0.0.1:40741,DS-55319f37-f6af-43b2-8400-7a4900ce3c68,DISK], DatanodeInfoWithStorage[127.0.0.1:38153,DS-707f6299-dd64-458a-a9b6-108f7e88340c,DISK], DatanodeInfoWithStorage[127.0.0.1:44396,DS-60ed608d-45fc-4b23-93be-817859e62920,DISK], DatanodeInfoWithStorage[127.0.0.1:44348,DS-8e1b8069-e261-46b6-b4a0-e5bbc17740b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44537,DS-b0f9864b-17a5-4556-9a7f-547c4bb7ca79,DISK], DatanodeInfoWithStorage[127.0.0.1:35140,DS-9d7bc61d-3920-422b-8baa-f681c0d2609b,DISK], DatanodeInfoWithStorage[127.0.0.1:33957,DS-88ed77ad-eca7-4fdc-aba4-fe67643b0282,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 4 out of 50
result: might be true error
Total execution time in seconds : 5445
