reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 36
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 36
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-245134339-172.17.0.19-1597664736412:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40103,DS-c7a35868-ab5c-4b85-8024-f9974dc48b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38491,DS-0a3544e0-6202-4e34-9575-2ce3d1775758,DISK], DatanodeInfoWithStorage[127.0.0.1:42267,DS-f4e1bea8-560a-4b3a-aa40-dfc597462b92,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-ccb11072-2463-4d34-b56a-de8e519988be,DISK], DatanodeInfoWithStorage[127.0.0.1:38406,DS-20da808a-f100-401b-b598-ac993777aca5,DISK], DatanodeInfoWithStorage[127.0.0.1:38999,DS-9c7ac093-b3cd-4502-9ff5-e04a3c1b57dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40936,DS-4f0a3ea5-fdf4-4c67-9106-e6fb64e1f399,DISK], DatanodeInfoWithStorage[127.0.0.1:43094,DS-79fef7dc-0c1f-4c3c-9dd3-de3474462e41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-245134339-172.17.0.19-1597664736412:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40103,DS-c7a35868-ab5c-4b85-8024-f9974dc48b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38491,DS-0a3544e0-6202-4e34-9575-2ce3d1775758,DISK], DatanodeInfoWithStorage[127.0.0.1:42267,DS-f4e1bea8-560a-4b3a-aa40-dfc597462b92,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-ccb11072-2463-4d34-b56a-de8e519988be,DISK], DatanodeInfoWithStorage[127.0.0.1:38406,DS-20da808a-f100-401b-b598-ac993777aca5,DISK], DatanodeInfoWithStorage[127.0.0.1:38999,DS-9c7ac093-b3cd-4502-9ff5-e04a3c1b57dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40936,DS-4f0a3ea5-fdf4-4c67-9106-e6fb64e1f399,DISK], DatanodeInfoWithStorage[127.0.0.1:43094,DS-79fef7dc-0c1f-4c3c-9dd3-de3474462e41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 36
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2130863197-172.17.0.19-1597664960099:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33373,DS-4a021530-613e-4ba2-848a-bd0505cd15c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43570,DS-f2e67f06-21bd-4a2e-bdf8-d2dc51e7ace8,DISK], DatanodeInfoWithStorage[127.0.0.1:45298,DS-ac5a04ae-951b-4684-b6ca-8f567ffc9e48,DISK], DatanodeInfoWithStorage[127.0.0.1:41925,DS-3030052d-2fd5-4e7e-929e-13c1179a9b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:43215,DS-bb814193-ed48-45c4-ae71-bdbda78f53e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33715,DS-8f35fe5c-d1ca-45e0-a37b-a95284cad77f,DISK], DatanodeInfoWithStorage[127.0.0.1:45507,DS-17d2cfa6-222c-4fd9-8b90-f41c1bb2f7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35751,DS-db873014-1ec2-466a-a7aa-5a0a0cce5bcb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2130863197-172.17.0.19-1597664960099:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33373,DS-4a021530-613e-4ba2-848a-bd0505cd15c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43570,DS-f2e67f06-21bd-4a2e-bdf8-d2dc51e7ace8,DISK], DatanodeInfoWithStorage[127.0.0.1:45298,DS-ac5a04ae-951b-4684-b6ca-8f567ffc9e48,DISK], DatanodeInfoWithStorage[127.0.0.1:41925,DS-3030052d-2fd5-4e7e-929e-13c1179a9b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:43215,DS-bb814193-ed48-45c4-ae71-bdbda78f53e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33715,DS-8f35fe5c-d1ca-45e0-a37b-a95284cad77f,DISK], DatanodeInfoWithStorage[127.0.0.1:45507,DS-17d2cfa6-222c-4fd9-8b90-f41c1bb2f7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35751,DS-db873014-1ec2-466a-a7aa-5a0a0cce5bcb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 36
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-235549013-172.17.0.19-1597665298160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33412,DS-740d0fb0-bc13-4462-aba1-c158d75b7e62,DISK], DatanodeInfoWithStorage[127.0.0.1:43318,DS-98dcd241-740b-4d44-aa24-b472d5d1877c,DISK], DatanodeInfoWithStorage[127.0.0.1:45367,DS-1abcf118-1a98-450b-ac1d-82978814ff38,DISK], DatanodeInfoWithStorage[127.0.0.1:35994,DS-5e083a6a-5cba-490c-bbbc-55a3b6cb85df,DISK], DatanodeInfoWithStorage[127.0.0.1:44846,DS-435c0ac5-f508-4a95-80f6-1dc3bcb9b59d,DISK], DatanodeInfoWithStorage[127.0.0.1:37024,DS-003d681a-7e05-4fef-b020-688d240de640,DISK], DatanodeInfoWithStorage[127.0.0.1:35564,DS-2ed64142-fcc9-4121-8f9f-8d0bf9107689,DISK], DatanodeInfoWithStorage[127.0.0.1:38167,DS-c175247e-de86-49ea-8d6c-8632d15b54aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-235549013-172.17.0.19-1597665298160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33412,DS-740d0fb0-bc13-4462-aba1-c158d75b7e62,DISK], DatanodeInfoWithStorage[127.0.0.1:43318,DS-98dcd241-740b-4d44-aa24-b472d5d1877c,DISK], DatanodeInfoWithStorage[127.0.0.1:45367,DS-1abcf118-1a98-450b-ac1d-82978814ff38,DISK], DatanodeInfoWithStorage[127.0.0.1:35994,DS-5e083a6a-5cba-490c-bbbc-55a3b6cb85df,DISK], DatanodeInfoWithStorage[127.0.0.1:44846,DS-435c0ac5-f508-4a95-80f6-1dc3bcb9b59d,DISK], DatanodeInfoWithStorage[127.0.0.1:37024,DS-003d681a-7e05-4fef-b020-688d240de640,DISK], DatanodeInfoWithStorage[127.0.0.1:35564,DS-2ed64142-fcc9-4121-8f9f-8d0bf9107689,DISK], DatanodeInfoWithStorage[127.0.0.1:38167,DS-c175247e-de86-49ea-8d6c-8632d15b54aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 36
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1711143565-172.17.0.19-1597665581192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40673,DS-688be872-2c0f-4cf5-8266-949e6588f87f,DISK], DatanodeInfoWithStorage[127.0.0.1:37663,DS-8565032d-6798-4b43-ba43-b6b33a46a618,DISK], DatanodeInfoWithStorage[127.0.0.1:41067,DS-0eac6be6-9467-4f57-9f31-af930b5565f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41084,DS-89eb160a-9ee0-4da1-85db-9a8f059b4915,DISK], DatanodeInfoWithStorage[127.0.0.1:35474,DS-23d75123-ac11-492e-a544-de0bc8f21e76,DISK], DatanodeInfoWithStorage[127.0.0.1:36508,DS-2a99d05a-7b9a-4a18-9b3f-5d28a265a20b,DISK], DatanodeInfoWithStorage[127.0.0.1:41830,DS-d59cd935-2269-4852-80b2-488f27aea45e,DISK], DatanodeInfoWithStorage[127.0.0.1:39779,DS-90c50ad1-8c78-4beb-b8cf-2eacc57f3f29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1711143565-172.17.0.19-1597665581192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40673,DS-688be872-2c0f-4cf5-8266-949e6588f87f,DISK], DatanodeInfoWithStorage[127.0.0.1:37663,DS-8565032d-6798-4b43-ba43-b6b33a46a618,DISK], DatanodeInfoWithStorage[127.0.0.1:41067,DS-0eac6be6-9467-4f57-9f31-af930b5565f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41084,DS-89eb160a-9ee0-4da1-85db-9a8f059b4915,DISK], DatanodeInfoWithStorage[127.0.0.1:35474,DS-23d75123-ac11-492e-a544-de0bc8f21e76,DISK], DatanodeInfoWithStorage[127.0.0.1:36508,DS-2a99d05a-7b9a-4a18-9b3f-5d28a265a20b,DISK], DatanodeInfoWithStorage[127.0.0.1:41830,DS-d59cd935-2269-4852-80b2-488f27aea45e,DISK], DatanodeInfoWithStorage[127.0.0.1:39779,DS-90c50ad1-8c78-4beb-b8cf-2eacc57f3f29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 36
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-821589641-172.17.0.19-1597665977519:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34370,DS-af1e87ba-2f90-4600-b28a-43670c17f6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40979,DS-a0a7c7fd-8488-4807-b156-13c09ecc1cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:43467,DS-5b1c33cd-3ffd-4890-bed1-7791c6767046,DISK], DatanodeInfoWithStorage[127.0.0.1:35712,DS-72cc1d52-9eb8-42f7-a72c-4f1999d2a025,DISK], DatanodeInfoWithStorage[127.0.0.1:37762,DS-395179d3-dbaf-4f9b-8a15-e3cc8a87348d,DISK], DatanodeInfoWithStorage[127.0.0.1:36597,DS-868fc600-6fe9-4929-9bd0-08e9617f3581,DISK], DatanodeInfoWithStorage[127.0.0.1:37724,DS-4c81a40f-f9cc-4cdb-a766-76a24139f979,DISK], DatanodeInfoWithStorage[127.0.0.1:33310,DS-444471f0-3dbd-40c7-a5aa-f9e579106d53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-821589641-172.17.0.19-1597665977519:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34370,DS-af1e87ba-2f90-4600-b28a-43670c17f6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40979,DS-a0a7c7fd-8488-4807-b156-13c09ecc1cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:43467,DS-5b1c33cd-3ffd-4890-bed1-7791c6767046,DISK], DatanodeInfoWithStorage[127.0.0.1:35712,DS-72cc1d52-9eb8-42f7-a72c-4f1999d2a025,DISK], DatanodeInfoWithStorage[127.0.0.1:37762,DS-395179d3-dbaf-4f9b-8a15-e3cc8a87348d,DISK], DatanodeInfoWithStorage[127.0.0.1:36597,DS-868fc600-6fe9-4929-9bd0-08e9617f3581,DISK], DatanodeInfoWithStorage[127.0.0.1:37724,DS-4c81a40f-f9cc-4cdb-a766-76a24139f979,DISK], DatanodeInfoWithStorage[127.0.0.1:33310,DS-444471f0-3dbd-40c7-a5aa-f9e579106d53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 36
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-198810758-172.17.0.19-1597666125465:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42990,DS-64e3017b-d8e8-49ee-bace-f094bbb09099,DISK], DatanodeInfoWithStorage[127.0.0.1:40747,DS-1a69da6b-1f73-4f8d-87db-356d8974131a,DISK], DatanodeInfoWithStorage[127.0.0.1:41287,DS-160e926e-e830-4909-a7f0-cb15c281f901,DISK], DatanodeInfoWithStorage[127.0.0.1:35086,DS-96c36444-9b5a-4932-bb36-30b43f1aa016,DISK], DatanodeInfoWithStorage[127.0.0.1:37546,DS-11806326-fddf-40ad-9fe2-8d9f01d58225,DISK], DatanodeInfoWithStorage[127.0.0.1:46641,DS-11fe4082-644b-4a05-82cd-f53e5c79dec5,DISK], DatanodeInfoWithStorage[127.0.0.1:45506,DS-11bbabd8-109f-4c15-a892-d66681ae31f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46620,DS-505d3fd6-9d71-401b-8ed4-4bc2ea2e6b6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-198810758-172.17.0.19-1597666125465:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42990,DS-64e3017b-d8e8-49ee-bace-f094bbb09099,DISK], DatanodeInfoWithStorage[127.0.0.1:40747,DS-1a69da6b-1f73-4f8d-87db-356d8974131a,DISK], DatanodeInfoWithStorage[127.0.0.1:41287,DS-160e926e-e830-4909-a7f0-cb15c281f901,DISK], DatanodeInfoWithStorage[127.0.0.1:35086,DS-96c36444-9b5a-4932-bb36-30b43f1aa016,DISK], DatanodeInfoWithStorage[127.0.0.1:37546,DS-11806326-fddf-40ad-9fe2-8d9f01d58225,DISK], DatanodeInfoWithStorage[127.0.0.1:46641,DS-11fe4082-644b-4a05-82cd-f53e5c79dec5,DISK], DatanodeInfoWithStorage[127.0.0.1:45506,DS-11bbabd8-109f-4c15-a892-d66681ae31f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46620,DS-505d3fd6-9d71-401b-8ed4-4bc2ea2e6b6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 36
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-436058415-172.17.0.19-1597666365506:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33746,DS-686a94de-ab37-44c1-844e-9a46a932cf5b,DISK], DatanodeInfoWithStorage[127.0.0.1:35019,DS-22d37c08-78b4-45d5-bbd5-9dd470c70df3,DISK], DatanodeInfoWithStorage[127.0.0.1:35524,DS-42e4879b-4b26-4490-b0d9-bbe3b985fa95,DISK], DatanodeInfoWithStorage[127.0.0.1:40916,DS-4d40da75-a3d5-40ef-8dee-4d9dcace4c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:45801,DS-b9ed886c-b9d1-43e4-a662-1ec9f33e728f,DISK], DatanodeInfoWithStorage[127.0.0.1:34178,DS-1fba6076-4f0f-4b29-a546-d9a7333644b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46465,DS-33d3fed4-5442-449d-ac3b-551c76186559,DISK], DatanodeInfoWithStorage[127.0.0.1:36691,DS-0da648be-3bf9-4ec5-ae3a-8fa04c7035ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-436058415-172.17.0.19-1597666365506:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33746,DS-686a94de-ab37-44c1-844e-9a46a932cf5b,DISK], DatanodeInfoWithStorage[127.0.0.1:35019,DS-22d37c08-78b4-45d5-bbd5-9dd470c70df3,DISK], DatanodeInfoWithStorage[127.0.0.1:35524,DS-42e4879b-4b26-4490-b0d9-bbe3b985fa95,DISK], DatanodeInfoWithStorage[127.0.0.1:40916,DS-4d40da75-a3d5-40ef-8dee-4d9dcace4c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:45801,DS-b9ed886c-b9d1-43e4-a662-1ec9f33e728f,DISK], DatanodeInfoWithStorage[127.0.0.1:34178,DS-1fba6076-4f0f-4b29-a546-d9a7333644b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46465,DS-33d3fed4-5442-449d-ac3b-551c76186559,DISK], DatanodeInfoWithStorage[127.0.0.1:36691,DS-0da648be-3bf9-4ec5-ae3a-8fa04c7035ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 36
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-802093849-172.17.0.19-1597666797946:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45293,DS-1bbd93f2-d376-4488-a82f-e85f822ec995,DISK], DatanodeInfoWithStorage[127.0.0.1:44585,DS-e3764a1b-35ac-4786-bcb1-e5e225e392f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34512,DS-b9f68a2e-b81a-4a54-939c-922e17cc875a,DISK], DatanodeInfoWithStorage[127.0.0.1:34380,DS-0d5b2f33-2302-4711-9932-31a96fcf8a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:39778,DS-a3067b3e-c203-40d7-a7d0-e24143621486,DISK], DatanodeInfoWithStorage[127.0.0.1:39708,DS-6677ef25-5f0f-48ce-b688-0343f5b06061,DISK], DatanodeInfoWithStorage[127.0.0.1:37017,DS-893a0b0a-9700-46e4-9287-bc24a5b7fabe,DISK], DatanodeInfoWithStorage[127.0.0.1:42156,DS-16a0a054-b4bf-4d53-9b93-16d0cea2a446,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-802093849-172.17.0.19-1597666797946:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45293,DS-1bbd93f2-d376-4488-a82f-e85f822ec995,DISK], DatanodeInfoWithStorage[127.0.0.1:44585,DS-e3764a1b-35ac-4786-bcb1-e5e225e392f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34512,DS-b9f68a2e-b81a-4a54-939c-922e17cc875a,DISK], DatanodeInfoWithStorage[127.0.0.1:34380,DS-0d5b2f33-2302-4711-9932-31a96fcf8a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:39778,DS-a3067b3e-c203-40d7-a7d0-e24143621486,DISK], DatanodeInfoWithStorage[127.0.0.1:39708,DS-6677ef25-5f0f-48ce-b688-0343f5b06061,DISK], DatanodeInfoWithStorage[127.0.0.1:37017,DS-893a0b0a-9700-46e4-9287-bc24a5b7fabe,DISK], DatanodeInfoWithStorage[127.0.0.1:42156,DS-16a0a054-b4bf-4d53-9b93-16d0cea2a446,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 36
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1789910698-172.17.0.19-1597666946257:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42702,DS-9e78b552-5b72-4e65-beef-e7ae33b6bb25,DISK], DatanodeInfoWithStorage[127.0.0.1:35478,DS-f9b978e5-94b8-443e-b9c7-8b800ce5e74a,DISK], DatanodeInfoWithStorage[127.0.0.1:44042,DS-0538242a-afd9-4b72-9c49-d6e1bb3855de,DISK], DatanodeInfoWithStorage[127.0.0.1:40659,DS-55ec7f1b-e54b-4da0-8aea-cd634b13c631,DISK], DatanodeInfoWithStorage[127.0.0.1:33370,DS-18f9ebf6-775a-48f0-9f73-8e3c8175ded4,DISK], DatanodeInfoWithStorage[127.0.0.1:39153,DS-18e2a4a2-7d57-4661-9839-85840433e66b,DISK], DatanodeInfoWithStorage[127.0.0.1:37872,DS-0172b39c-1195-4b3e-aaf8-70af6d498b42,DISK], DatanodeInfoWithStorage[127.0.0.1:36728,DS-6c5e2f1c-17aa-4941-aef0-9aac3ab5c071,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1789910698-172.17.0.19-1597666946257:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42702,DS-9e78b552-5b72-4e65-beef-e7ae33b6bb25,DISK], DatanodeInfoWithStorage[127.0.0.1:35478,DS-f9b978e5-94b8-443e-b9c7-8b800ce5e74a,DISK], DatanodeInfoWithStorage[127.0.0.1:44042,DS-0538242a-afd9-4b72-9c49-d6e1bb3855de,DISK], DatanodeInfoWithStorage[127.0.0.1:40659,DS-55ec7f1b-e54b-4da0-8aea-cd634b13c631,DISK], DatanodeInfoWithStorage[127.0.0.1:33370,DS-18f9ebf6-775a-48f0-9f73-8e3c8175ded4,DISK], DatanodeInfoWithStorage[127.0.0.1:39153,DS-18e2a4a2-7d57-4661-9839-85840433e66b,DISK], DatanodeInfoWithStorage[127.0.0.1:37872,DS-0172b39c-1195-4b3e-aaf8-70af6d498b42,DISK], DatanodeInfoWithStorage[127.0.0.1:36728,DS-6c5e2f1c-17aa-4941-aef0-9aac3ab5c071,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 36
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-792694264-172.17.0.19-1597667450959:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43904,DS-d79bfb04-9ae8-47f1-bd50-85e973c6e4ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34278,DS-e5fa3677-6df3-43fd-a224-fa2c769fdc46,DISK], DatanodeInfoWithStorage[127.0.0.1:37537,DS-58f9dbec-5ae1-46ea-8803-d29d9188dd04,DISK], DatanodeInfoWithStorage[127.0.0.1:35024,DS-3c58285d-e986-41fc-aa9e-6d4a76d52969,DISK], DatanodeInfoWithStorage[127.0.0.1:45503,DS-c1ed17b7-89a0-446c-a113-902e07f0173b,DISK], DatanodeInfoWithStorage[127.0.0.1:40758,DS-cdb2f617-60eb-4cb7-b38e-484b832d56b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33319,DS-e496892a-06ed-40c3-86b6-541e487eb9c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46381,DS-ad94ab6f-5698-4bf4-a31a-f8baf295528c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-792694264-172.17.0.19-1597667450959:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43904,DS-d79bfb04-9ae8-47f1-bd50-85e973c6e4ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34278,DS-e5fa3677-6df3-43fd-a224-fa2c769fdc46,DISK], DatanodeInfoWithStorage[127.0.0.1:37537,DS-58f9dbec-5ae1-46ea-8803-d29d9188dd04,DISK], DatanodeInfoWithStorage[127.0.0.1:35024,DS-3c58285d-e986-41fc-aa9e-6d4a76d52969,DISK], DatanodeInfoWithStorage[127.0.0.1:45503,DS-c1ed17b7-89a0-446c-a113-902e07f0173b,DISK], DatanodeInfoWithStorage[127.0.0.1:40758,DS-cdb2f617-60eb-4cb7-b38e-484b832d56b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33319,DS-e496892a-06ed-40c3-86b6-541e487eb9c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46381,DS-ad94ab6f-5698-4bf4-a31a-f8baf295528c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 36
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2059914925-172.17.0.19-1597667738741:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43667,DS-09ab4fe8-5c16-4331-9e65-601db9006c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:33478,DS-e8c9ea1f-c9c7-4c2a-98f4-bd75d622317a,DISK], DatanodeInfoWithStorage[127.0.0.1:33519,DS-5d180e12-8c58-4a2a-b36f-eb5d5e9c41cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46213,DS-85a3be1a-179e-4746-9728-36bcb0e592af,DISK], DatanodeInfoWithStorage[127.0.0.1:38300,DS-7d1193ed-4ea8-403b-a17b-d9d889ba122c,DISK], DatanodeInfoWithStorage[127.0.0.1:40194,DS-287dac2a-2511-43f0-b851-0073d9af1cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:39060,DS-7f5d7e2a-1b2e-4321-9005-07b763d10097,DISK], DatanodeInfoWithStorage[127.0.0.1:38534,DS-5191d48c-1c0b-4ca4-a06d-d6c4b70f39ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2059914925-172.17.0.19-1597667738741:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43667,DS-09ab4fe8-5c16-4331-9e65-601db9006c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:33478,DS-e8c9ea1f-c9c7-4c2a-98f4-bd75d622317a,DISK], DatanodeInfoWithStorage[127.0.0.1:33519,DS-5d180e12-8c58-4a2a-b36f-eb5d5e9c41cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46213,DS-85a3be1a-179e-4746-9728-36bcb0e592af,DISK], DatanodeInfoWithStorage[127.0.0.1:38300,DS-7d1193ed-4ea8-403b-a17b-d9d889ba122c,DISK], DatanodeInfoWithStorage[127.0.0.1:40194,DS-287dac2a-2511-43f0-b851-0073d9af1cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:39060,DS-7f5d7e2a-1b2e-4321-9005-07b763d10097,DISK], DatanodeInfoWithStorage[127.0.0.1:38534,DS-5191d48c-1c0b-4ca4-a06d-d6c4b70f39ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 36
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1965677266-172.17.0.19-1597667837595:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37537,DS-d1deecfc-aba7-4d36-bb4c-91668e886175,DISK], DatanodeInfoWithStorage[127.0.0.1:33586,DS-7e3de22b-1440-4280-9739-58dc25689237,DISK], DatanodeInfoWithStorage[127.0.0.1:38144,DS-016c834f-80d2-4672-ad10-74b5bc2dd5de,DISK], DatanodeInfoWithStorage[127.0.0.1:45498,DS-2488e2f8-48fd-4217-9923-9cb2f30f0a76,DISK], DatanodeInfoWithStorage[127.0.0.1:35652,DS-d6c3fce6-1ad0-41a1-a71b-67c057e92dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:33426,DS-271a7c1b-4c4d-4eb1-b834-25a0f9e69abe,DISK], DatanodeInfoWithStorage[127.0.0.1:38759,DS-871d156c-3300-450f-9045-a5b56d36cd17,DISK], DatanodeInfoWithStorage[127.0.0.1:43186,DS-579e91f3-ccf9-4e9c-add4-90b8c67f4690,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1965677266-172.17.0.19-1597667837595:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37537,DS-d1deecfc-aba7-4d36-bb4c-91668e886175,DISK], DatanodeInfoWithStorage[127.0.0.1:33586,DS-7e3de22b-1440-4280-9739-58dc25689237,DISK], DatanodeInfoWithStorage[127.0.0.1:38144,DS-016c834f-80d2-4672-ad10-74b5bc2dd5de,DISK], DatanodeInfoWithStorage[127.0.0.1:45498,DS-2488e2f8-48fd-4217-9923-9cb2f30f0a76,DISK], DatanodeInfoWithStorage[127.0.0.1:35652,DS-d6c3fce6-1ad0-41a1-a71b-67c057e92dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:33426,DS-271a7c1b-4c4d-4eb1-b834-25a0f9e69abe,DISK], DatanodeInfoWithStorage[127.0.0.1:38759,DS-871d156c-3300-450f-9045-a5b56d36cd17,DISK], DatanodeInfoWithStorage[127.0.0.1:43186,DS-579e91f3-ccf9-4e9c-add4-90b8c67f4690,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 36
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2077082921-172.17.0.19-1597668131595:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37980,DS-58b66cda-3a41-49c8-9a2a-e48645c2f6e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44961,DS-d3f99910-9ec9-44a0-88c3-8e82cc2eeb6a,DISK], DatanodeInfoWithStorage[127.0.0.1:37315,DS-82ebc637-d94b-40e3-a69e-80685e28a5bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45646,DS-0ec974e3-25e2-4ebc-885f-4ce43e8d722c,DISK], DatanodeInfoWithStorage[127.0.0.1:45819,DS-414080c0-b489-4dc0-8e95-a56c3111b6cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36267,DS-2bd61f8a-a9f5-416e-af72-05aab406a588,DISK], DatanodeInfoWithStorage[127.0.0.1:33751,DS-4431c96e-1867-4a9d-9d6a-fb7ac58ab670,DISK], DatanodeInfoWithStorage[127.0.0.1:39505,DS-c3338210-5e47-4a4c-8c9c-e0dff11ff8a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2077082921-172.17.0.19-1597668131595:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37980,DS-58b66cda-3a41-49c8-9a2a-e48645c2f6e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44961,DS-d3f99910-9ec9-44a0-88c3-8e82cc2eeb6a,DISK], DatanodeInfoWithStorage[127.0.0.1:37315,DS-82ebc637-d94b-40e3-a69e-80685e28a5bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45646,DS-0ec974e3-25e2-4ebc-885f-4ce43e8d722c,DISK], DatanodeInfoWithStorage[127.0.0.1:45819,DS-414080c0-b489-4dc0-8e95-a56c3111b6cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36267,DS-2bd61f8a-a9f5-416e-af72-05aab406a588,DISK], DatanodeInfoWithStorage[127.0.0.1:33751,DS-4431c96e-1867-4a9d-9d6a-fb7ac58ab670,DISK], DatanodeInfoWithStorage[127.0.0.1:39505,DS-c3338210-5e47-4a4c-8c9c-e0dff11ff8a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 36
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-601225909-172.17.0.19-1597668405053:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44688,DS-7fe32679-8a11-4959-a56d-0d23ee4b03a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44936,DS-82c4e1ca-2c1e-421a-a786-6aa2662e5769,DISK], DatanodeInfoWithStorage[127.0.0.1:46207,DS-5db55ffa-7d7f-44df-876f-e5d2235381a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34132,DS-7bf18c10-271c-4be8-b1c5-def941309646,DISK], DatanodeInfoWithStorage[127.0.0.1:34309,DS-d4f45043-3453-47d1-a533-a6ff478b6cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:37057,DS-7e37812a-b39c-4d1a-8811-5449d4b63817,DISK], DatanodeInfoWithStorage[127.0.0.1:34709,DS-62746dfc-1b43-4063-a226-79799569e29a,DISK], DatanodeInfoWithStorage[127.0.0.1:36432,DS-5db13adc-3194-464a-bce4-791e9731bbb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-601225909-172.17.0.19-1597668405053:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44688,DS-7fe32679-8a11-4959-a56d-0d23ee4b03a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44936,DS-82c4e1ca-2c1e-421a-a786-6aa2662e5769,DISK], DatanodeInfoWithStorage[127.0.0.1:46207,DS-5db55ffa-7d7f-44df-876f-e5d2235381a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34132,DS-7bf18c10-271c-4be8-b1c5-def941309646,DISK], DatanodeInfoWithStorage[127.0.0.1:34309,DS-d4f45043-3453-47d1-a533-a6ff478b6cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:37057,DS-7e37812a-b39c-4d1a-8811-5449d4b63817,DISK], DatanodeInfoWithStorage[127.0.0.1:34709,DS-62746dfc-1b43-4063-a226-79799569e29a,DISK], DatanodeInfoWithStorage[127.0.0.1:36432,DS-5db13adc-3194-464a-bce4-791e9731bbb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 36
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-82975758-172.17.0.19-1597668452648:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38149,DS-d07470ba-7af3-486a-89f7-c84a9bba9afd,DISK], DatanodeInfoWithStorage[127.0.0.1:45967,DS-2eda2d3a-beeb-4bf2-af25-0b6ccc7e8940,DISK], DatanodeInfoWithStorage[127.0.0.1:43676,DS-0ea80ab7-78dc-4284-884d-d294c278fa55,DISK], DatanodeInfoWithStorage[127.0.0.1:36246,DS-b6766c25-d8a1-4603-86d9-56b452a5288d,DISK], DatanodeInfoWithStorage[127.0.0.1:35874,DS-a48444a9-6b88-4aa2-a569-dbc5148dda7a,DISK], DatanodeInfoWithStorage[127.0.0.1:45883,DS-12f57e71-e152-4235-8d6a-9d48a741b0f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43162,DS-b4e9cbfc-f1fc-40ca-9862-8ee004dc34ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36618,DS-f65730c7-327b-4fc2-bc00-97d0ae476ddb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-82975758-172.17.0.19-1597668452648:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38149,DS-d07470ba-7af3-486a-89f7-c84a9bba9afd,DISK], DatanodeInfoWithStorage[127.0.0.1:45967,DS-2eda2d3a-beeb-4bf2-af25-0b6ccc7e8940,DISK], DatanodeInfoWithStorage[127.0.0.1:43676,DS-0ea80ab7-78dc-4284-884d-d294c278fa55,DISK], DatanodeInfoWithStorage[127.0.0.1:36246,DS-b6766c25-d8a1-4603-86d9-56b452a5288d,DISK], DatanodeInfoWithStorage[127.0.0.1:35874,DS-a48444a9-6b88-4aa2-a569-dbc5148dda7a,DISK], DatanodeInfoWithStorage[127.0.0.1:45883,DS-12f57e71-e152-4235-8d6a-9d48a741b0f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43162,DS-b4e9cbfc-f1fc-40ca-9862-8ee004dc34ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36618,DS-f65730c7-327b-4fc2-bc00-97d0ae476ddb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 36
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1352601109-172.17.0.19-1597668915461:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45360,DS-d6d2f730-e9b8-4aef-97d0-41fd161a8bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:43187,DS-77a78b5e-4ddd-46f2-b050-169540a5c5bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45541,DS-78e2d425-d1d6-4085-bab1-e19e0ab0c939,DISK], DatanodeInfoWithStorage[127.0.0.1:35912,DS-3bd751f2-2b35-465c-8d3b-13c97003e650,DISK], DatanodeInfoWithStorage[127.0.0.1:40469,DS-ee9e3c17-660b-41b7-9049-491a35c88cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:46277,DS-f836eea0-fdfa-478b-8ba0-d204ad477c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:41531,DS-6bb4ab58-811f-4ad5-b1b8-2b5f1b302739,DISK], DatanodeInfoWithStorage[127.0.0.1:37433,DS-12dd5b68-524a-4a65-8324-319bd5e36cf6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1352601109-172.17.0.19-1597668915461:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45360,DS-d6d2f730-e9b8-4aef-97d0-41fd161a8bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:43187,DS-77a78b5e-4ddd-46f2-b050-169540a5c5bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45541,DS-78e2d425-d1d6-4085-bab1-e19e0ab0c939,DISK], DatanodeInfoWithStorage[127.0.0.1:35912,DS-3bd751f2-2b35-465c-8d3b-13c97003e650,DISK], DatanodeInfoWithStorage[127.0.0.1:40469,DS-ee9e3c17-660b-41b7-9049-491a35c88cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:46277,DS-f836eea0-fdfa-478b-8ba0-d204ad477c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:41531,DS-6bb4ab58-811f-4ad5-b1b8-2b5f1b302739,DISK], DatanodeInfoWithStorage[127.0.0.1:37433,DS-12dd5b68-524a-4a65-8324-319bd5e36cf6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 36
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1510245328-172.17.0.19-1597669303268:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41725,DS-ae7aa86a-97fb-4411-a273-4ab57ed1f21a,DISK], DatanodeInfoWithStorage[127.0.0.1:39986,DS-9bb042df-1410-4ba3-92d7-c3996f98ab36,DISK], DatanodeInfoWithStorage[127.0.0.1:43588,DS-d3070d0d-3400-41af-9e87-3fd872ae1687,DISK], DatanodeInfoWithStorage[127.0.0.1:39426,DS-401decae-eb70-4bf6-b276-82d99c2ef9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33694,DS-88be7510-0644-4750-a1d8-2ee80123c676,DISK], DatanodeInfoWithStorage[127.0.0.1:41732,DS-dc55ce03-3f18-4590-81d6-38b68b5c85e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38620,DS-a872cec8-27a4-42df-a75e-0a8517f0c801,DISK], DatanodeInfoWithStorage[127.0.0.1:39292,DS-993b4a0f-a816-4a29-b753-b3809942c443,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1510245328-172.17.0.19-1597669303268:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41725,DS-ae7aa86a-97fb-4411-a273-4ab57ed1f21a,DISK], DatanodeInfoWithStorage[127.0.0.1:39986,DS-9bb042df-1410-4ba3-92d7-c3996f98ab36,DISK], DatanodeInfoWithStorage[127.0.0.1:43588,DS-d3070d0d-3400-41af-9e87-3fd872ae1687,DISK], DatanodeInfoWithStorage[127.0.0.1:39426,DS-401decae-eb70-4bf6-b276-82d99c2ef9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33694,DS-88be7510-0644-4750-a1d8-2ee80123c676,DISK], DatanodeInfoWithStorage[127.0.0.1:41732,DS-dc55ce03-3f18-4590-81d6-38b68b5c85e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38620,DS-a872cec8-27a4-42df-a75e-0a8517f0c801,DISK], DatanodeInfoWithStorage[127.0.0.1:39292,DS-993b4a0f-a816-4a29-b753-b3809942c443,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 36
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1916116082-172.17.0.19-1597669602005:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45284,DS-11cd59e9-7af5-4a2c-88fd-da81b4bcda73,DISK], DatanodeInfoWithStorage[127.0.0.1:38301,DS-b480cf57-c887-4d54-a14d-f44572d4c0ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35407,DS-1e2ec2f2-5d64-4408-a80e-eb634da5682c,DISK], DatanodeInfoWithStorage[127.0.0.1:45536,DS-42eb896c-5372-4248-9dd6-6823abf0953e,DISK], DatanodeInfoWithStorage[127.0.0.1:34660,DS-f913d120-1a89-4a73-b985-4615551eb83c,DISK], DatanodeInfoWithStorage[127.0.0.1:45964,DS-5896f2f9-5cc6-43f3-a8fd-d79465ad8837,DISK], DatanodeInfoWithStorage[127.0.0.1:40558,DS-4dcbe080-6889-4222-b481-481879f21920,DISK], DatanodeInfoWithStorage[127.0.0.1:44016,DS-dd6fb32f-5641-4099-bb98-c16b9e71151f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1916116082-172.17.0.19-1597669602005:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45284,DS-11cd59e9-7af5-4a2c-88fd-da81b4bcda73,DISK], DatanodeInfoWithStorage[127.0.0.1:38301,DS-b480cf57-c887-4d54-a14d-f44572d4c0ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35407,DS-1e2ec2f2-5d64-4408-a80e-eb634da5682c,DISK], DatanodeInfoWithStorage[127.0.0.1:45536,DS-42eb896c-5372-4248-9dd6-6823abf0953e,DISK], DatanodeInfoWithStorage[127.0.0.1:34660,DS-f913d120-1a89-4a73-b985-4615551eb83c,DISK], DatanodeInfoWithStorage[127.0.0.1:45964,DS-5896f2f9-5cc6-43f3-a8fd-d79465ad8837,DISK], DatanodeInfoWithStorage[127.0.0.1:40558,DS-4dcbe080-6889-4222-b481-481879f21920,DISK], DatanodeInfoWithStorage[127.0.0.1:44016,DS-dd6fb32f-5641-4099-bb98-c16b9e71151f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 36
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1838380521-172.17.0.19-1597669792232:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34740,DS-d2d0cfcd-db76-4329-bbf4-86ec1b05d055,DISK], DatanodeInfoWithStorage[127.0.0.1:38358,DS-7572e12c-0760-4ffa-9d28-0c11d71d3bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:33864,DS-e1f097a2-53c2-4c01-9926-e35cbfb701b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35875,DS-de0466a3-56e0-4a7a-8e96-2d87104af8cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42907,DS-8a492243-03a0-4a07-b8be-87722a8a20bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35928,DS-e9f451ad-4d10-4622-b1a0-3ee5bfb4e2cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45020,DS-da91970e-086d-4d65-8863-e9f940349588,DISK], DatanodeInfoWithStorage[127.0.0.1:43068,DS-8f7620e7-7c5e-40fe-926a-3431641066dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1838380521-172.17.0.19-1597669792232:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34740,DS-d2d0cfcd-db76-4329-bbf4-86ec1b05d055,DISK], DatanodeInfoWithStorage[127.0.0.1:38358,DS-7572e12c-0760-4ffa-9d28-0c11d71d3bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:33864,DS-e1f097a2-53c2-4c01-9926-e35cbfb701b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35875,DS-de0466a3-56e0-4a7a-8e96-2d87104af8cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42907,DS-8a492243-03a0-4a07-b8be-87722a8a20bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35928,DS-e9f451ad-4d10-4622-b1a0-3ee5bfb4e2cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45020,DS-da91970e-086d-4d65-8863-e9f940349588,DISK], DatanodeInfoWithStorage[127.0.0.1:43068,DS-8f7620e7-7c5e-40fe-926a-3431641066dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 36
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1035635844-172.17.0.19-1597669982038:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40061,DS-6085c09e-4f7e-4f24-a87c-5e7a91ba9a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40595,DS-e3f26c9c-3533-4ca5-8457-49651b761821,DISK], DatanodeInfoWithStorage[127.0.0.1:36496,DS-b51897e8-f534-4f4e-af73-8a7009bfe0f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45820,DS-f623c3de-c1ee-43a5-b812-6e923d253075,DISK], DatanodeInfoWithStorage[127.0.0.1:35502,DS-d64b89c8-44a1-4bfa-ab1a-ff1a42489c25,DISK], DatanodeInfoWithStorage[127.0.0.1:44447,DS-94e63a4f-fe1b-4812-927e-54fe981ab412,DISK], DatanodeInfoWithStorage[127.0.0.1:39578,DS-1d9a21a2-a192-413a-9b79-01ac46a890df,DISK], DatanodeInfoWithStorage[127.0.0.1:34131,DS-1688d8d3-03e2-4ba5-abbd-531895bd9517,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1035635844-172.17.0.19-1597669982038:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40061,DS-6085c09e-4f7e-4f24-a87c-5e7a91ba9a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40595,DS-e3f26c9c-3533-4ca5-8457-49651b761821,DISK], DatanodeInfoWithStorage[127.0.0.1:36496,DS-b51897e8-f534-4f4e-af73-8a7009bfe0f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45820,DS-f623c3de-c1ee-43a5-b812-6e923d253075,DISK], DatanodeInfoWithStorage[127.0.0.1:35502,DS-d64b89c8-44a1-4bfa-ab1a-ff1a42489c25,DISK], DatanodeInfoWithStorage[127.0.0.1:44447,DS-94e63a4f-fe1b-4812-927e-54fe981ab412,DISK], DatanodeInfoWithStorage[127.0.0.1:39578,DS-1d9a21a2-a192-413a-9b79-01ac46a890df,DISK], DatanodeInfoWithStorage[127.0.0.1:34131,DS-1688d8d3-03e2-4ba5-abbd-531895bd9517,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 36
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-544576543-172.17.0.19-1597670133102:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35494,DS-21e2d636-735e-4a64-8fbb-8b6e77d75c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:38656,DS-72e24777-cc4b-4a74-8af3-82966bb8bc5d,DISK], DatanodeInfoWithStorage[127.0.0.1:35200,DS-eec36d0b-54d6-4042-a815-d5f7660d3ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:45072,DS-7af229d0-3619-47ff-ae0e-d8e8ef37238a,DISK], DatanodeInfoWithStorage[127.0.0.1:34255,DS-e4aa4572-7682-4ceb-aafa-e35aff21360b,DISK], DatanodeInfoWithStorage[127.0.0.1:36709,DS-b53d6aea-4dce-4611-8699-81351811e639,DISK], DatanodeInfoWithStorage[127.0.0.1:33203,DS-9e39e1db-1c00-4b3f-8021-2c430e43e05a,DISK], DatanodeInfoWithStorage[127.0.0.1:38986,DS-2ea19c49-0618-4703-b4b3-0b644e9baa22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-544576543-172.17.0.19-1597670133102:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35494,DS-21e2d636-735e-4a64-8fbb-8b6e77d75c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:38656,DS-72e24777-cc4b-4a74-8af3-82966bb8bc5d,DISK], DatanodeInfoWithStorage[127.0.0.1:35200,DS-eec36d0b-54d6-4042-a815-d5f7660d3ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:45072,DS-7af229d0-3619-47ff-ae0e-d8e8ef37238a,DISK], DatanodeInfoWithStorage[127.0.0.1:34255,DS-e4aa4572-7682-4ceb-aafa-e35aff21360b,DISK], DatanodeInfoWithStorage[127.0.0.1:36709,DS-b53d6aea-4dce-4611-8699-81351811e639,DISK], DatanodeInfoWithStorage[127.0.0.1:33203,DS-9e39e1db-1c00-4b3f-8021-2c430e43e05a,DISK], DatanodeInfoWithStorage[127.0.0.1:38986,DS-2ea19c49-0618-4703-b4b3-0b644e9baa22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 36
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1352994951-172.17.0.19-1597671598917:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44451,DS-ed734d2b-15db-454c-a158-8829d664543a,DISK], DatanodeInfoWithStorage[127.0.0.1:40551,DS-b18b5d77-be0a-42fd-aedd-3483ae1638a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44894,DS-2a79d853-c69c-42ee-996a-3c878c84ea2e,DISK], DatanodeInfoWithStorage[127.0.0.1:44357,DS-768fb671-ee9e-4548-a152-464d684f2107,DISK], DatanodeInfoWithStorage[127.0.0.1:41163,DS-eb4432f7-39a9-416d-a7aa-61d8585fd7be,DISK], DatanodeInfoWithStorage[127.0.0.1:38006,DS-95a5d8bf-99ed-4910-b3f9-5dae27b5e392,DISK], DatanodeInfoWithStorage[127.0.0.1:42382,DS-d30454c5-0816-4074-854f-be146c147394,DISK], DatanodeInfoWithStorage[127.0.0.1:45447,DS-a9ae94fe-1de6-463b-846e-fe0f90dfd1e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1352994951-172.17.0.19-1597671598917:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44451,DS-ed734d2b-15db-454c-a158-8829d664543a,DISK], DatanodeInfoWithStorage[127.0.0.1:40551,DS-b18b5d77-be0a-42fd-aedd-3483ae1638a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44894,DS-2a79d853-c69c-42ee-996a-3c878c84ea2e,DISK], DatanodeInfoWithStorage[127.0.0.1:44357,DS-768fb671-ee9e-4548-a152-464d684f2107,DISK], DatanodeInfoWithStorage[127.0.0.1:41163,DS-eb4432f7-39a9-416d-a7aa-61d8585fd7be,DISK], DatanodeInfoWithStorage[127.0.0.1:38006,DS-95a5d8bf-99ed-4910-b3f9-5dae27b5e392,DISK], DatanodeInfoWithStorage[127.0.0.1:42382,DS-d30454c5-0816-4074-854f-be146c147394,DISK], DatanodeInfoWithStorage[127.0.0.1:45447,DS-a9ae94fe-1de6-463b-846e-fe0f90dfd1e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 16 out of 50
result: false positive !!!
Total execution time in seconds : 7116
