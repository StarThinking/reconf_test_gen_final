reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2050589865-172.17.0.2-1597638468658:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41972,DS-13db1da1-a817-4008-9b89-931ab60e623a,DISK], DatanodeInfoWithStorage[127.0.0.1:34041,DS-0c860993-f3c6-42dd-9ed0-7af82f423251,DISK], DatanodeInfoWithStorage[127.0.0.1:41469,DS-83746462-f4d1-4546-b374-a6db67d2f485,DISK], DatanodeInfoWithStorage[127.0.0.1:36174,DS-e8bbf001-12a9-41e5-aede-86fa5e4c5c65,DISK], DatanodeInfoWithStorage[127.0.0.1:37385,DS-de0fe9fa-8902-4431-a7a0-3fedcf3d7c50,DISK], DatanodeInfoWithStorage[127.0.0.1:46137,DS-d5b6120f-25eb-4921-9e62-8994dbd5033c,DISK], DatanodeInfoWithStorage[127.0.0.1:33568,DS-64ab95e2-d6d9-49e9-9458-0a3b5a2e951a,DISK], DatanodeInfoWithStorage[127.0.0.1:46216,DS-53a402d9-931d-4c25-b443-824618c45c07,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2050589865-172.17.0.2-1597638468658:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41972,DS-13db1da1-a817-4008-9b89-931ab60e623a,DISK], DatanodeInfoWithStorage[127.0.0.1:34041,DS-0c860993-f3c6-42dd-9ed0-7af82f423251,DISK], DatanodeInfoWithStorage[127.0.0.1:41469,DS-83746462-f4d1-4546-b374-a6db67d2f485,DISK], DatanodeInfoWithStorage[127.0.0.1:36174,DS-e8bbf001-12a9-41e5-aede-86fa5e4c5c65,DISK], DatanodeInfoWithStorage[127.0.0.1:37385,DS-de0fe9fa-8902-4431-a7a0-3fedcf3d7c50,DISK], DatanodeInfoWithStorage[127.0.0.1:46137,DS-d5b6120f-25eb-4921-9e62-8994dbd5033c,DISK], DatanodeInfoWithStorage[127.0.0.1:33568,DS-64ab95e2-d6d9-49e9-9458-0a3b5a2e951a,DISK], DatanodeInfoWithStorage[127.0.0.1:46216,DS-53a402d9-931d-4c25-b443-824618c45c07,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1899039573-172.17.0.2-1597638682601:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36461,DS-33345bd2-b5d9-492b-bb4b-7d08ae8ebd45,DISK], DatanodeInfoWithStorage[127.0.0.1:33674,DS-1f016982-fb17-43a5-91a7-fcd8f6ea92ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42220,DS-3b74357c-07ab-4874-a008-43c262309146,DISK], DatanodeInfoWithStorage[127.0.0.1:41785,DS-5a8140c3-e425-4741-b277-99218c7e709e,DISK], DatanodeInfoWithStorage[127.0.0.1:38519,DS-0e87fa5a-ae8d-4b1a-9668-6a480a853d92,DISK], DatanodeInfoWithStorage[127.0.0.1:43217,DS-776c1732-205b-4fff-b45f-222e08468f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:46340,DS-2ab250dc-9dbc-481f-a456-510484600c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43005,DS-e238abde-de16-43a7-847f-5029ea60266f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1899039573-172.17.0.2-1597638682601:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36461,DS-33345bd2-b5d9-492b-bb4b-7d08ae8ebd45,DISK], DatanodeInfoWithStorage[127.0.0.1:33674,DS-1f016982-fb17-43a5-91a7-fcd8f6ea92ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42220,DS-3b74357c-07ab-4874-a008-43c262309146,DISK], DatanodeInfoWithStorage[127.0.0.1:41785,DS-5a8140c3-e425-4741-b277-99218c7e709e,DISK], DatanodeInfoWithStorage[127.0.0.1:38519,DS-0e87fa5a-ae8d-4b1a-9668-6a480a853d92,DISK], DatanodeInfoWithStorage[127.0.0.1:43217,DS-776c1732-205b-4fff-b45f-222e08468f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:46340,DS-2ab250dc-9dbc-481f-a456-510484600c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43005,DS-e238abde-de16-43a7-847f-5029ea60266f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1736674377-172.17.0.2-1597639109630:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41242,DS-59dbfca4-f61f-4235-8c9c-3f5961774426,DISK], DatanodeInfoWithStorage[127.0.0.1:40134,DS-c3018457-d851-4529-ab79-b45b900d1059,DISK], DatanodeInfoWithStorage[127.0.0.1:36688,DS-89d10fae-5743-46a9-847b-daa3576ed79a,DISK], DatanodeInfoWithStorage[127.0.0.1:39925,DS-65a931d5-ef12-4067-b03a-06247bb3e567,DISK], DatanodeInfoWithStorage[127.0.0.1:38237,DS-480f2503-952c-4f3a-9ac3-bd7c33d343c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38632,DS-2e003a79-0d3c-4219-aedc-6d0dd2b348ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41884,DS-6f77abf0-05d3-43b5-afa1-4b440c3fd5d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35184,DS-57fb6a2f-75b5-488d-9d35-37ceb84bcd05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1736674377-172.17.0.2-1597639109630:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41242,DS-59dbfca4-f61f-4235-8c9c-3f5961774426,DISK], DatanodeInfoWithStorage[127.0.0.1:40134,DS-c3018457-d851-4529-ab79-b45b900d1059,DISK], DatanodeInfoWithStorage[127.0.0.1:36688,DS-89d10fae-5743-46a9-847b-daa3576ed79a,DISK], DatanodeInfoWithStorage[127.0.0.1:39925,DS-65a931d5-ef12-4067-b03a-06247bb3e567,DISK], DatanodeInfoWithStorage[127.0.0.1:38237,DS-480f2503-952c-4f3a-9ac3-bd7c33d343c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38632,DS-2e003a79-0d3c-4219-aedc-6d0dd2b348ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41884,DS-6f77abf0-05d3-43b5-afa1-4b440c3fd5d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35184,DS-57fb6a2f-75b5-488d-9d35-37ceb84bcd05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-836265594-172.17.0.2-1597639196883:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44697,DS-a32dab85-288b-4403-a26c-6e58ba318f98,DISK], DatanodeInfoWithStorage[127.0.0.1:35489,DS-7fea7b91-3c4c-4559-b75e-00e076d87967,DISK], DatanodeInfoWithStorage[127.0.0.1:36466,DS-ddf65407-261c-4d71-be18-c834c0745d59,DISK], DatanodeInfoWithStorage[127.0.0.1:46735,DS-fa22f5c8-d970-4498-9d0e-9836faa865d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34979,DS-fa554f71-7048-44de-928f-fe221c4b539e,DISK], DatanodeInfoWithStorage[127.0.0.1:41827,DS-02e56bb1-e577-4ffa-b6d9-acbf7d8325e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37134,DS-a102121b-996e-4fd1-90bd-a8d0e14747e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44832,DS-133d3991-d2cd-4397-8b04-cf4d3bdafa80,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-836265594-172.17.0.2-1597639196883:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44697,DS-a32dab85-288b-4403-a26c-6e58ba318f98,DISK], DatanodeInfoWithStorage[127.0.0.1:35489,DS-7fea7b91-3c4c-4559-b75e-00e076d87967,DISK], DatanodeInfoWithStorage[127.0.0.1:36466,DS-ddf65407-261c-4d71-be18-c834c0745d59,DISK], DatanodeInfoWithStorage[127.0.0.1:46735,DS-fa22f5c8-d970-4498-9d0e-9836faa865d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34979,DS-fa554f71-7048-44de-928f-fe221c4b539e,DISK], DatanodeInfoWithStorage[127.0.0.1:41827,DS-02e56bb1-e577-4ffa-b6d9-acbf7d8325e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37134,DS-a102121b-996e-4fd1-90bd-a8d0e14747e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44832,DS-133d3991-d2cd-4397-8b04-cf4d3bdafa80,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-865876781-172.17.0.2-1597639389510:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39023,DS-b2c2e7af-e59a-4411-98c2-131a7a4b66c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36187,DS-319a52c4-f70c-4829-9ae3-2a42cfcf2d82,DISK], DatanodeInfoWithStorage[127.0.0.1:34777,DS-6d4bb7bf-e02e-4d56-a643-59720e215721,DISK], DatanodeInfoWithStorage[127.0.0.1:36999,DS-5d12dd7b-9fa2-4501-88ad-c8f8ef3b8b96,DISK], DatanodeInfoWithStorage[127.0.0.1:45559,DS-0c8f4ee9-e2e2-47b2-b10b-f246cd9300e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42025,DS-24c21f71-6f05-4527-ad74-bfe30d6725ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42545,DS-b130d2ba-068b-483e-a537-8b5376238a97,DISK], DatanodeInfoWithStorage[127.0.0.1:37125,DS-e8244e26-5540-4144-8872-e34279b65119,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-865876781-172.17.0.2-1597639389510:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39023,DS-b2c2e7af-e59a-4411-98c2-131a7a4b66c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36187,DS-319a52c4-f70c-4829-9ae3-2a42cfcf2d82,DISK], DatanodeInfoWithStorage[127.0.0.1:34777,DS-6d4bb7bf-e02e-4d56-a643-59720e215721,DISK], DatanodeInfoWithStorage[127.0.0.1:36999,DS-5d12dd7b-9fa2-4501-88ad-c8f8ef3b8b96,DISK], DatanodeInfoWithStorage[127.0.0.1:45559,DS-0c8f4ee9-e2e2-47b2-b10b-f246cd9300e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42025,DS-24c21f71-6f05-4527-ad74-bfe30d6725ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42545,DS-b130d2ba-068b-483e-a537-8b5376238a97,DISK], DatanodeInfoWithStorage[127.0.0.1:37125,DS-e8244e26-5540-4144-8872-e34279b65119,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1669686420-172.17.0.2-1597639563541:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36392,DS-454b097e-8c65-4e35-bdbf-ecdcdf8bc088,DISK], DatanodeInfoWithStorage[127.0.0.1:39755,DS-c4c1ca17-058c-4fd0-b9a4-eaf5d78f660d,DISK], DatanodeInfoWithStorage[127.0.0.1:41156,DS-129d8216-d058-4567-b4b1-a1eca063341d,DISK], DatanodeInfoWithStorage[127.0.0.1:36354,DS-09b62513-834f-4cc6-a80f-1d4a38134d47,DISK], DatanodeInfoWithStorage[127.0.0.1:35395,DS-b5987820-c77e-49c6-81f0-2663426e57d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36888,DS-925c8f0f-b400-41e4-9465-e807c65971e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37621,DS-7a008013-9bd8-4d1e-a6b7-831b0f775e77,DISK], DatanodeInfoWithStorage[127.0.0.1:37223,DS-5b036964-b2ff-4af0-89ad-3a2b8e0e2c1f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1669686420-172.17.0.2-1597639563541:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36392,DS-454b097e-8c65-4e35-bdbf-ecdcdf8bc088,DISK], DatanodeInfoWithStorage[127.0.0.1:39755,DS-c4c1ca17-058c-4fd0-b9a4-eaf5d78f660d,DISK], DatanodeInfoWithStorage[127.0.0.1:41156,DS-129d8216-d058-4567-b4b1-a1eca063341d,DISK], DatanodeInfoWithStorage[127.0.0.1:36354,DS-09b62513-834f-4cc6-a80f-1d4a38134d47,DISK], DatanodeInfoWithStorage[127.0.0.1:35395,DS-b5987820-c77e-49c6-81f0-2663426e57d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36888,DS-925c8f0f-b400-41e4-9465-e807c65971e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37621,DS-7a008013-9bd8-4d1e-a6b7-831b0f775e77,DISK], DatanodeInfoWithStorage[127.0.0.1:37223,DS-5b036964-b2ff-4af0-89ad-3a2b8e0e2c1f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1660778857-172.17.0.2-1597639847795:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32906,DS-0f7b15ee-427b-4af4-9ade-96b12d3b9d14,DISK], DatanodeInfoWithStorage[127.0.0.1:43920,DS-931a3142-6797-42e2-8aa7-dfb2520131da,DISK], DatanodeInfoWithStorage[127.0.0.1:32879,DS-77edbb35-0e0e-4356-a5ad-6658518637ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39249,DS-e82c8e13-4556-4fa2-b3da-1c0e40c087d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40676,DS-0250113a-527d-4e3f-821f-74d905511b62,DISK], DatanodeInfoWithStorage[127.0.0.1:40759,DS-be207b8c-3f21-4b84-8424-558d5f837e34,DISK], DatanodeInfoWithStorage[127.0.0.1:33202,DS-593304c7-f54e-44f7-b830-e0aa209bf84c,DISK], DatanodeInfoWithStorage[127.0.0.1:35327,DS-ee73315d-e8a3-443f-a0fe-c46bf49e1b90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1660778857-172.17.0.2-1597639847795:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32906,DS-0f7b15ee-427b-4af4-9ade-96b12d3b9d14,DISK], DatanodeInfoWithStorage[127.0.0.1:43920,DS-931a3142-6797-42e2-8aa7-dfb2520131da,DISK], DatanodeInfoWithStorage[127.0.0.1:32879,DS-77edbb35-0e0e-4356-a5ad-6658518637ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39249,DS-e82c8e13-4556-4fa2-b3da-1c0e40c087d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40676,DS-0250113a-527d-4e3f-821f-74d905511b62,DISK], DatanodeInfoWithStorage[127.0.0.1:40759,DS-be207b8c-3f21-4b84-8424-558d5f837e34,DISK], DatanodeInfoWithStorage[127.0.0.1:33202,DS-593304c7-f54e-44f7-b830-e0aa209bf84c,DISK], DatanodeInfoWithStorage[127.0.0.1:35327,DS-ee73315d-e8a3-443f-a0fe-c46bf49e1b90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1457846076-172.17.0.2-1597639889170:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42855,DS-6bd28901-926f-4f0a-a37c-4339a0741a77,DISK], DatanodeInfoWithStorage[127.0.0.1:35016,DS-34997968-e65d-4b87-acec-771f8121d98a,DISK], DatanodeInfoWithStorage[127.0.0.1:42022,DS-3ec470aa-fd70-42b5-849d-5232dc5b149c,DISK], DatanodeInfoWithStorage[127.0.0.1:36542,DS-661b3b8e-6ac0-4f33-b7fe-7c9fb9d0622a,DISK], DatanodeInfoWithStorage[127.0.0.1:44496,DS-31f226ed-25e2-4486-9100-62b73b69d5cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41510,DS-3923c75c-b5f8-495a-9135-4666720ef7f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37038,DS-82a0d34d-49db-475b-96a3-530269aea5cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44682,DS-bd9a095d-4ad6-4eee-8030-e6dc36e25e13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1457846076-172.17.0.2-1597639889170:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42855,DS-6bd28901-926f-4f0a-a37c-4339a0741a77,DISK], DatanodeInfoWithStorage[127.0.0.1:35016,DS-34997968-e65d-4b87-acec-771f8121d98a,DISK], DatanodeInfoWithStorage[127.0.0.1:42022,DS-3ec470aa-fd70-42b5-849d-5232dc5b149c,DISK], DatanodeInfoWithStorage[127.0.0.1:36542,DS-661b3b8e-6ac0-4f33-b7fe-7c9fb9d0622a,DISK], DatanodeInfoWithStorage[127.0.0.1:44496,DS-31f226ed-25e2-4486-9100-62b73b69d5cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41510,DS-3923c75c-b5f8-495a-9135-4666720ef7f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37038,DS-82a0d34d-49db-475b-96a3-530269aea5cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44682,DS-bd9a095d-4ad6-4eee-8030-e6dc36e25e13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1337768210-172.17.0.2-1597639933207:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37554,DS-d8637882-4f7b-4752-86df-994260219b96,DISK], DatanodeInfoWithStorage[127.0.0.1:37715,DS-07b3c262-1162-4819-8b5b-f8edde5be7fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38025,DS-6c97b390-eb07-478b-8fa4-94438ec34a81,DISK], DatanodeInfoWithStorage[127.0.0.1:42578,DS-c3de49a4-5e0a-4dce-bb40-f489a5a459a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44150,DS-294f763d-bcf4-4ba9-833e-825d31f96c40,DISK], DatanodeInfoWithStorage[127.0.0.1:43966,DS-7e029bbf-e6f5-43f2-b7dc-9463213fcb81,DISK], DatanodeInfoWithStorage[127.0.0.1:38033,DS-f18a65d6-1555-46b0-a313-f23925f18712,DISK], DatanodeInfoWithStorage[127.0.0.1:37240,DS-4ac1602c-bcf9-45ba-a46d-93c7e7034128,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1337768210-172.17.0.2-1597639933207:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37554,DS-d8637882-4f7b-4752-86df-994260219b96,DISK], DatanodeInfoWithStorage[127.0.0.1:37715,DS-07b3c262-1162-4819-8b5b-f8edde5be7fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38025,DS-6c97b390-eb07-478b-8fa4-94438ec34a81,DISK], DatanodeInfoWithStorage[127.0.0.1:42578,DS-c3de49a4-5e0a-4dce-bb40-f489a5a459a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44150,DS-294f763d-bcf4-4ba9-833e-825d31f96c40,DISK], DatanodeInfoWithStorage[127.0.0.1:43966,DS-7e029bbf-e6f5-43f2-b7dc-9463213fcb81,DISK], DatanodeInfoWithStorage[127.0.0.1:38033,DS-f18a65d6-1555-46b0-a313-f23925f18712,DISK], DatanodeInfoWithStorage[127.0.0.1:37240,DS-4ac1602c-bcf9-45ba-a46d-93c7e7034128,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-35862711-172.17.0.2-1597640114211:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40810,DS-d55a39b2-be6e-4f9c-8044-85d6952ce617,DISK], DatanodeInfoWithStorage[127.0.0.1:34031,DS-3262b87b-0f57-4416-a12e-cc33f0a3f062,DISK], DatanodeInfoWithStorage[127.0.0.1:36771,DS-010a6db4-3b72-46ed-87dd-d1b1891e81c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33369,DS-4b65119c-3424-49d8-8bd0-3a65e6463795,DISK], DatanodeInfoWithStorage[127.0.0.1:40357,DS-07f1e80f-3faa-4286-b3ec-ccf9d22d6574,DISK], DatanodeInfoWithStorage[127.0.0.1:36320,DS-f59d2d1f-e155-4b06-841b-a929023c7a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:43635,DS-a8d68242-d399-42e0-b4b8-3e9fe46a337b,DISK], DatanodeInfoWithStorage[127.0.0.1:34935,DS-dccbdac5-0967-498b-bd18-b608894dcc1f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-35862711-172.17.0.2-1597640114211:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40810,DS-d55a39b2-be6e-4f9c-8044-85d6952ce617,DISK], DatanodeInfoWithStorage[127.0.0.1:34031,DS-3262b87b-0f57-4416-a12e-cc33f0a3f062,DISK], DatanodeInfoWithStorage[127.0.0.1:36771,DS-010a6db4-3b72-46ed-87dd-d1b1891e81c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33369,DS-4b65119c-3424-49d8-8bd0-3a65e6463795,DISK], DatanodeInfoWithStorage[127.0.0.1:40357,DS-07f1e80f-3faa-4286-b3ec-ccf9d22d6574,DISK], DatanodeInfoWithStorage[127.0.0.1:36320,DS-f59d2d1f-e155-4b06-841b-a929023c7a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:43635,DS-a8d68242-d399-42e0-b4b8-3e9fe46a337b,DISK], DatanodeInfoWithStorage[127.0.0.1:34935,DS-dccbdac5-0967-498b-bd18-b608894dcc1f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1585973241-172.17.0.2-1597640465264:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36763,DS-3006ebf2-75e2-459a-a8c0-41fe866ddf15,DISK], DatanodeInfoWithStorage[127.0.0.1:43579,DS-51bed6ce-6e99-457b-b5e1-94d53e24626a,DISK], DatanodeInfoWithStorage[127.0.0.1:33214,DS-4e56a819-9d2c-4cca-b0c8-ee8edc73ac9d,DISK], DatanodeInfoWithStorage[127.0.0.1:33798,DS-7ce006b5-f6db-467a-b590-89a5659dd2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46598,DS-94de3cda-c634-4792-8213-be16d10414e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40360,DS-ebe773e1-bbc1-46f2-803d-00176784c30b,DISK], DatanodeInfoWithStorage[127.0.0.1:43716,DS-c46a9f68-00e0-4451-992c-2a7c542a0d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:39157,DS-20068b3c-1b22-49dd-8ad4-68e84562c591,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1585973241-172.17.0.2-1597640465264:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36763,DS-3006ebf2-75e2-459a-a8c0-41fe866ddf15,DISK], DatanodeInfoWithStorage[127.0.0.1:43579,DS-51bed6ce-6e99-457b-b5e1-94d53e24626a,DISK], DatanodeInfoWithStorage[127.0.0.1:33214,DS-4e56a819-9d2c-4cca-b0c8-ee8edc73ac9d,DISK], DatanodeInfoWithStorage[127.0.0.1:33798,DS-7ce006b5-f6db-467a-b590-89a5659dd2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46598,DS-94de3cda-c634-4792-8213-be16d10414e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40360,DS-ebe773e1-bbc1-46f2-803d-00176784c30b,DISK], DatanodeInfoWithStorage[127.0.0.1:43716,DS-c46a9f68-00e0-4451-992c-2a7c542a0d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:39157,DS-20068b3c-1b22-49dd-8ad4-68e84562c591,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-702131438-172.17.0.2-1597640503046:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41309,DS-05e09e1c-3cd8-4e5d-98dc-d80e968d5a01,DISK], DatanodeInfoWithStorage[127.0.0.1:38774,DS-41187a5e-b1ce-4fc1-8ac2-20c8adcefaa4,DISK], DatanodeInfoWithStorage[127.0.0.1:43571,DS-ea54b3d2-6342-4913-b4f1-3214b26215f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38487,DS-6d1bc044-14b5-44e8-a970-05b195991f30,DISK], DatanodeInfoWithStorage[127.0.0.1:44442,DS-bab02b65-6826-48bf-87fb-feb58a9759a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34819,DS-6b54b2a5-09a4-48e6-8122-d63182606179,DISK], DatanodeInfoWithStorage[127.0.0.1:40870,DS-2d94d478-1a23-48f3-ba08-98bae26c7041,DISK], DatanodeInfoWithStorage[127.0.0.1:39124,DS-cb0957e4-a9ed-443d-9536-1238056e1214,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-702131438-172.17.0.2-1597640503046:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41309,DS-05e09e1c-3cd8-4e5d-98dc-d80e968d5a01,DISK], DatanodeInfoWithStorage[127.0.0.1:38774,DS-41187a5e-b1ce-4fc1-8ac2-20c8adcefaa4,DISK], DatanodeInfoWithStorage[127.0.0.1:43571,DS-ea54b3d2-6342-4913-b4f1-3214b26215f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38487,DS-6d1bc044-14b5-44e8-a970-05b195991f30,DISK], DatanodeInfoWithStorage[127.0.0.1:44442,DS-bab02b65-6826-48bf-87fb-feb58a9759a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34819,DS-6b54b2a5-09a4-48e6-8122-d63182606179,DISK], DatanodeInfoWithStorage[127.0.0.1:40870,DS-2d94d478-1a23-48f3-ba08-98bae26c7041,DISK], DatanodeInfoWithStorage[127.0.0.1:39124,DS-cb0957e4-a9ed-443d-9536-1238056e1214,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-901393859-172.17.0.2-1597640647887:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46034,DS-2d7575a6-66c1-4127-8f54-b744d4ff2185,DISK], DatanodeInfoWithStorage[127.0.0.1:42609,DS-6642ab2c-b5d6-4736-a3ee-c7e589e560cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40234,DS-73499d5c-90a7-4cd9-80fd-ce0438067235,DISK], DatanodeInfoWithStorage[127.0.0.1:46146,DS-59c6fcfb-caa0-43c5-bee1-7d8597c45826,DISK], DatanodeInfoWithStorage[127.0.0.1:46811,DS-ac7ff6ed-855c-4922-a3d7-496b7ac14d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:39508,DS-df7e5d30-f226-4a8e-9d1b-42312647fb92,DISK], DatanodeInfoWithStorage[127.0.0.1:39828,DS-89ed7d2d-c0e2-4270-b414-5c047dca66c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34493,DS-cb5adbe0-d628-42a3-8eb3-6e02a4f10108,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-901393859-172.17.0.2-1597640647887:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46034,DS-2d7575a6-66c1-4127-8f54-b744d4ff2185,DISK], DatanodeInfoWithStorage[127.0.0.1:42609,DS-6642ab2c-b5d6-4736-a3ee-c7e589e560cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40234,DS-73499d5c-90a7-4cd9-80fd-ce0438067235,DISK], DatanodeInfoWithStorage[127.0.0.1:46146,DS-59c6fcfb-caa0-43c5-bee1-7d8597c45826,DISK], DatanodeInfoWithStorage[127.0.0.1:46811,DS-ac7ff6ed-855c-4922-a3d7-496b7ac14d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:39508,DS-df7e5d30-f226-4a8e-9d1b-42312647fb92,DISK], DatanodeInfoWithStorage[127.0.0.1:39828,DS-89ed7d2d-c0e2-4270-b414-5c047dca66c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34493,DS-cb5adbe0-d628-42a3-8eb3-6e02a4f10108,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-414847595-172.17.0.2-1597641265202:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36772,DS-c22525db-9272-4868-87a8-918f548c635b,DISK], DatanodeInfoWithStorage[127.0.0.1:33796,DS-5f97b91f-2fae-43e9-8524-016cb74036e2,DISK], DatanodeInfoWithStorage[127.0.0.1:32799,DS-77cfdc5e-a083-47a8-b67c-4aaa48546706,DISK], DatanodeInfoWithStorage[127.0.0.1:40718,DS-8eb48805-62f0-40a0-849e-c0e9866db8c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36062,DS-11186bb7-a3a3-4b72-9538-cf9642ba2cca,DISK], DatanodeInfoWithStorage[127.0.0.1:41781,DS-4080cb6b-2301-45fa-af14-27f303f23534,DISK], DatanodeInfoWithStorage[127.0.0.1:42093,DS-8fba0459-85f7-47e1-a05a-0c2e24698b31,DISK], DatanodeInfoWithStorage[127.0.0.1:43496,DS-7787e678-a87f-4946-aba0-4e2096c2799c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-414847595-172.17.0.2-1597641265202:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36772,DS-c22525db-9272-4868-87a8-918f548c635b,DISK], DatanodeInfoWithStorage[127.0.0.1:33796,DS-5f97b91f-2fae-43e9-8524-016cb74036e2,DISK], DatanodeInfoWithStorage[127.0.0.1:32799,DS-77cfdc5e-a083-47a8-b67c-4aaa48546706,DISK], DatanodeInfoWithStorage[127.0.0.1:40718,DS-8eb48805-62f0-40a0-849e-c0e9866db8c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36062,DS-11186bb7-a3a3-4b72-9538-cf9642ba2cca,DISK], DatanodeInfoWithStorage[127.0.0.1:41781,DS-4080cb6b-2301-45fa-af14-27f303f23534,DISK], DatanodeInfoWithStorage[127.0.0.1:42093,DS-8fba0459-85f7-47e1-a05a-0c2e24698b31,DISK], DatanodeInfoWithStorage[127.0.0.1:43496,DS-7787e678-a87f-4946-aba0-4e2096c2799c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1414817313-172.17.0.2-1597641303705:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38267,DS-4a4c0f53-ee2f-4854-bbe6-a6d5c7af1342,DISK], DatanodeInfoWithStorage[127.0.0.1:43888,DS-9e50ff42-1328-4021-bd1f-9acdf798dcd1,DISK], DatanodeInfoWithStorage[127.0.0.1:33558,DS-94a622e9-4b04-4451-a512-981e5abb7caa,DISK], DatanodeInfoWithStorage[127.0.0.1:42937,DS-8322f295-9611-4d91-b15c-349da33b1fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:34595,DS-c11c59a4-782e-4b48-a9da-307e5765bbfa,DISK], DatanodeInfoWithStorage[127.0.0.1:33199,DS-3feb91f6-943f-4f7e-ac95-6dcf2904edd8,DISK], DatanodeInfoWithStorage[127.0.0.1:42238,DS-889e3bc0-5684-41a0-8ec9-76596ba904d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44488,DS-d33f8cbf-c2b0-4603-bfb5-8be9b2af866b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1414817313-172.17.0.2-1597641303705:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38267,DS-4a4c0f53-ee2f-4854-bbe6-a6d5c7af1342,DISK], DatanodeInfoWithStorage[127.0.0.1:43888,DS-9e50ff42-1328-4021-bd1f-9acdf798dcd1,DISK], DatanodeInfoWithStorage[127.0.0.1:33558,DS-94a622e9-4b04-4451-a512-981e5abb7caa,DISK], DatanodeInfoWithStorage[127.0.0.1:42937,DS-8322f295-9611-4d91-b15c-349da33b1fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:34595,DS-c11c59a4-782e-4b48-a9da-307e5765bbfa,DISK], DatanodeInfoWithStorage[127.0.0.1:33199,DS-3feb91f6-943f-4f7e-ac95-6dcf2904edd8,DISK], DatanodeInfoWithStorage[127.0.0.1:42238,DS-889e3bc0-5684-41a0-8ec9-76596ba904d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44488,DS-d33f8cbf-c2b0-4603-bfb5-8be9b2af866b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-527274170-172.17.0.2-1597641398020:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43265,DS-27c94d0d-61dc-4794-a431-2937d46c33d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33818,DS-2d30d12c-3198-4790-a568-e179fb179413,DISK], DatanodeInfoWithStorage[127.0.0.1:40118,DS-f5cb8e8f-8bca-4f70-bbce-fc973117698a,DISK], DatanodeInfoWithStorage[127.0.0.1:37588,DS-1a1a4d3f-ad0b-4494-8bf1-3b701728e420,DISK], DatanodeInfoWithStorage[127.0.0.1:41917,DS-eed175d0-8fa7-4562-8015-e85f19d11a80,DISK], DatanodeInfoWithStorage[127.0.0.1:36719,DS-b22cfb35-4212-427d-a329-5cf5e04e2b30,DISK], DatanodeInfoWithStorage[127.0.0.1:35626,DS-2d1d72ca-e415-439a-8dd4-05600d6b122a,DISK], DatanodeInfoWithStorage[127.0.0.1:39917,DS-11cfbd89-c894-4eb2-879f-6d8901b32615,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-527274170-172.17.0.2-1597641398020:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43265,DS-27c94d0d-61dc-4794-a431-2937d46c33d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33818,DS-2d30d12c-3198-4790-a568-e179fb179413,DISK], DatanodeInfoWithStorage[127.0.0.1:40118,DS-f5cb8e8f-8bca-4f70-bbce-fc973117698a,DISK], DatanodeInfoWithStorage[127.0.0.1:37588,DS-1a1a4d3f-ad0b-4494-8bf1-3b701728e420,DISK], DatanodeInfoWithStorage[127.0.0.1:41917,DS-eed175d0-8fa7-4562-8015-e85f19d11a80,DISK], DatanodeInfoWithStorage[127.0.0.1:36719,DS-b22cfb35-4212-427d-a329-5cf5e04e2b30,DISK], DatanodeInfoWithStorage[127.0.0.1:35626,DS-2d1d72ca-e415-439a-8dd4-05600d6b122a,DISK], DatanodeInfoWithStorage[127.0.0.1:39917,DS-11cfbd89-c894-4eb2-879f-6d8901b32615,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1735292504-172.17.0.2-1597641881558:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42656,DS-cc0a3e04-d5f1-43d3-8c40-faf109fcfdeb,DISK], DatanodeInfoWithStorage[127.0.0.1:33411,DS-6830a4b6-c1ac-477c-b551-c78690c02006,DISK], DatanodeInfoWithStorage[127.0.0.1:40534,DS-205fb787-122b-451f-b301-5719c240de1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40259,DS-da660dc2-f402-467e-893b-73d84674ad21,DISK], DatanodeInfoWithStorage[127.0.0.1:45305,DS-c05ec91a-e561-403e-8abc-daad7b62ff8a,DISK], DatanodeInfoWithStorage[127.0.0.1:45890,DS-08fd8bdb-297c-4d8c-b90e-cec264a9a918,DISK], DatanodeInfoWithStorage[127.0.0.1:40059,DS-449aaeae-a8a5-48c3-aba5-5a896db3c2c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37432,DS-ba510417-3d82-408c-9c31-01128849d3eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1735292504-172.17.0.2-1597641881558:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42656,DS-cc0a3e04-d5f1-43d3-8c40-faf109fcfdeb,DISK], DatanodeInfoWithStorage[127.0.0.1:33411,DS-6830a4b6-c1ac-477c-b551-c78690c02006,DISK], DatanodeInfoWithStorage[127.0.0.1:40534,DS-205fb787-122b-451f-b301-5719c240de1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40259,DS-da660dc2-f402-467e-893b-73d84674ad21,DISK], DatanodeInfoWithStorage[127.0.0.1:45305,DS-c05ec91a-e561-403e-8abc-daad7b62ff8a,DISK], DatanodeInfoWithStorage[127.0.0.1:45890,DS-08fd8bdb-297c-4d8c-b90e-cec264a9a918,DISK], DatanodeInfoWithStorage[127.0.0.1:40059,DS-449aaeae-a8a5-48c3-aba5-5a896db3c2c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37432,DS-ba510417-3d82-408c-9c31-01128849d3eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1766781330-172.17.0.2-1597642064730:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37779,DS-12d650e4-9435-4ac1-bd72-73aa9e8e502e,DISK], DatanodeInfoWithStorage[127.0.0.1:41756,DS-3b358cef-e884-43e5-9de7-42e5f0d4ec86,DISK], DatanodeInfoWithStorage[127.0.0.1:45692,DS-179e1ed5-8e21-4487-b6b9-85b799d9c0c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34324,DS-0e902e12-a3e6-454f-9af2-e71ff2c3dffd,DISK], DatanodeInfoWithStorage[127.0.0.1:45247,DS-94307a78-df04-4578-a175-f625c1496241,DISK], DatanodeInfoWithStorage[127.0.0.1:39808,DS-650b1580-32a8-4e61-8ea5-1cd1db7e50bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36072,DS-ea36e00c-7d99-428e-8620-26a0f3c26818,DISK], DatanodeInfoWithStorage[127.0.0.1:41807,DS-20c9a4ac-a4e0-468b-9ae9-e47196b23472,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1766781330-172.17.0.2-1597642064730:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37779,DS-12d650e4-9435-4ac1-bd72-73aa9e8e502e,DISK], DatanodeInfoWithStorage[127.0.0.1:41756,DS-3b358cef-e884-43e5-9de7-42e5f0d4ec86,DISK], DatanodeInfoWithStorage[127.0.0.1:45692,DS-179e1ed5-8e21-4487-b6b9-85b799d9c0c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34324,DS-0e902e12-a3e6-454f-9af2-e71ff2c3dffd,DISK], DatanodeInfoWithStorage[127.0.0.1:45247,DS-94307a78-df04-4578-a175-f625c1496241,DISK], DatanodeInfoWithStorage[127.0.0.1:39808,DS-650b1580-32a8-4e61-8ea5-1cd1db7e50bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36072,DS-ea36e00c-7d99-428e-8620-26a0f3c26818,DISK], DatanodeInfoWithStorage[127.0.0.1:41807,DS-20c9a4ac-a4e0-468b-9ae9-e47196b23472,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1005192727-172.17.0.2-1597642162257:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41181,DS-0805bf64-dc1a-4c66-b03a-900477fd0ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:35552,DS-821ce8f5-20db-4dc8-ac21-d155c117901e,DISK], DatanodeInfoWithStorage[127.0.0.1:40286,DS-bc8d52c6-3879-4bf8-894d-f4f10695b5db,DISK], DatanodeInfoWithStorage[127.0.0.1:42472,DS-ac6eb129-ed01-400c-9c1b-0ccf3e86ad90,DISK], DatanodeInfoWithStorage[127.0.0.1:44106,DS-9ee45899-bfd1-4242-8ddb-f27cb15a89ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45856,DS-197b812a-710a-4a1c-8633-9d1f43956142,DISK], DatanodeInfoWithStorage[127.0.0.1:33588,DS-f9aad780-1c05-47ba-a546-530aa21a18a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40896,DS-82317816-a883-44a3-9aba-b77a70333628,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1005192727-172.17.0.2-1597642162257:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41181,DS-0805bf64-dc1a-4c66-b03a-900477fd0ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:35552,DS-821ce8f5-20db-4dc8-ac21-d155c117901e,DISK], DatanodeInfoWithStorage[127.0.0.1:40286,DS-bc8d52c6-3879-4bf8-894d-f4f10695b5db,DISK], DatanodeInfoWithStorage[127.0.0.1:42472,DS-ac6eb129-ed01-400c-9c1b-0ccf3e86ad90,DISK], DatanodeInfoWithStorage[127.0.0.1:44106,DS-9ee45899-bfd1-4242-8ddb-f27cb15a89ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45856,DS-197b812a-710a-4a1c-8633-9d1f43956142,DISK], DatanodeInfoWithStorage[127.0.0.1:33588,DS-f9aad780-1c05-47ba-a546-530aa21a18a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40896,DS-82317816-a883-44a3-9aba-b77a70333628,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1720227407-172.17.0.2-1597642409951:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42399,DS-69bfa1f1-0acc-4015-a8cd-f6e464f946c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40277,DS-4fd982fa-f36e-4ec0-ab27-a273793a56d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33702,DS-be62034f-3664-49b0-b24e-1bfd0962f7ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41670,DS-4f70be77-f690-4ff4-9638-31e71b40ac46,DISK], DatanodeInfoWithStorage[127.0.0.1:35637,DS-a1b090ae-cb32-4588-bdce-70227ddfb9d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35382,DS-a49b35de-34e6-4372-b359-351f939c53c1,DISK], DatanodeInfoWithStorage[127.0.0.1:32932,DS-3f0eaa27-dca4-4613-971b-5c74253ed6de,DISK], DatanodeInfoWithStorage[127.0.0.1:33230,DS-6a2c5277-b25a-4358-9cdd-a08a15e3750d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1720227407-172.17.0.2-1597642409951:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42399,DS-69bfa1f1-0acc-4015-a8cd-f6e464f946c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40277,DS-4fd982fa-f36e-4ec0-ab27-a273793a56d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33702,DS-be62034f-3664-49b0-b24e-1bfd0962f7ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41670,DS-4f70be77-f690-4ff4-9638-31e71b40ac46,DISK], DatanodeInfoWithStorage[127.0.0.1:35637,DS-a1b090ae-cb32-4588-bdce-70227ddfb9d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35382,DS-a49b35de-34e6-4372-b359-351f939c53c1,DISK], DatanodeInfoWithStorage[127.0.0.1:32932,DS-3f0eaa27-dca4-4613-971b-5c74253ed6de,DISK], DatanodeInfoWithStorage[127.0.0.1:33230,DS-6a2c5277-b25a-4358-9cdd-a08a15e3750d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-778974603-172.17.0.2-1597642509212:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43405,DS-4222d6e0-3c41-4c3e-a0e5-1eedc675d3d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40190,DS-c8849374-f86a-486a-be33-6313c3d8f46d,DISK], DatanodeInfoWithStorage[127.0.0.1:35005,DS-9a5d6b03-e75e-4375-ba8d-6dff983c2cad,DISK], DatanodeInfoWithStorage[127.0.0.1:37616,DS-8ee0d161-8746-4b83-87c8-227b5b824a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:35970,DS-1ad38085-48e0-4eaf-b14f-ebf02ace0405,DISK], DatanodeInfoWithStorage[127.0.0.1:42092,DS-69c4f93b-1b9e-47fc-9bed-02c712083db8,DISK], DatanodeInfoWithStorage[127.0.0.1:44219,DS-5b04415d-63b2-48c3-b52b-af7b00c35ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:36681,DS-865d39cb-25d7-4d00-9da7-9690724534a4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-778974603-172.17.0.2-1597642509212:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43405,DS-4222d6e0-3c41-4c3e-a0e5-1eedc675d3d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40190,DS-c8849374-f86a-486a-be33-6313c3d8f46d,DISK], DatanodeInfoWithStorage[127.0.0.1:35005,DS-9a5d6b03-e75e-4375-ba8d-6dff983c2cad,DISK], DatanodeInfoWithStorage[127.0.0.1:37616,DS-8ee0d161-8746-4b83-87c8-227b5b824a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:35970,DS-1ad38085-48e0-4eaf-b14f-ebf02ace0405,DISK], DatanodeInfoWithStorage[127.0.0.1:42092,DS-69c4f93b-1b9e-47fc-9bed-02c712083db8,DISK], DatanodeInfoWithStorage[127.0.0.1:44219,DS-5b04415d-63b2-48c3-b52b-af7b00c35ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:36681,DS-865d39cb-25d7-4d00-9da7-9690724534a4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-136905766-172.17.0.2-1597642787189:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45406,DS-4a2d65ed-139d-455d-9456-a9d589f364cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44687,DS-abe83883-4f44-4611-9d10-a729cec605a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44570,DS-c55e1ffe-96e2-4521-a944-6423bdfc02b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45326,DS-8cc1dd46-71f1-449e-8ca6-5eaf69c47c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:32974,DS-e97534a2-1e97-4fd8-8269-7416d5a420f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38275,DS-0f8adbae-0272-4140-b6af-04861b249845,DISK], DatanodeInfoWithStorage[127.0.0.1:33521,DS-9399b094-82b0-4a93-8476-58e3175aa8ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38178,DS-c557f5cd-5c7b-4a09-b22f-7a60ac3d0636,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-136905766-172.17.0.2-1597642787189:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45406,DS-4a2d65ed-139d-455d-9456-a9d589f364cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44687,DS-abe83883-4f44-4611-9d10-a729cec605a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44570,DS-c55e1ffe-96e2-4521-a944-6423bdfc02b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45326,DS-8cc1dd46-71f1-449e-8ca6-5eaf69c47c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:32974,DS-e97534a2-1e97-4fd8-8269-7416d5a420f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38275,DS-0f8adbae-0272-4140-b6af-04861b249845,DISK], DatanodeInfoWithStorage[127.0.0.1:33521,DS-9399b094-82b0-4a93-8476-58e3175aa8ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38178,DS-c557f5cd-5c7b-4a09-b22f-7a60ac3d0636,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1083265225-172.17.0.2-1597642921482:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37005,DS-4eb35100-7344-40ca-9e30-247da284816b,DISK], DatanodeInfoWithStorage[127.0.0.1:38058,DS-1f75c51c-5e8d-4d42-a9a6-1f0a721ebaea,DISK], DatanodeInfoWithStorage[127.0.0.1:45417,DS-1130e625-503f-4f92-a023-3e752fbdf1ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33478,DS-fe7c78f3-0e2d-4514-bb68-287dfb53f12b,DISK], DatanodeInfoWithStorage[127.0.0.1:36695,DS-82ad4ec4-c80d-4b50-b5a0-980984f75ede,DISK], DatanodeInfoWithStorage[127.0.0.1:34130,DS-d91cd194-aef4-40be-ae2d-8ffa084c9dff,DISK], DatanodeInfoWithStorage[127.0.0.1:41506,DS-b4231bee-0d96-4f1c-a13b-f6a12412a1f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42573,DS-8b20877d-0ea3-4a91-86a1-a89903185166,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1083265225-172.17.0.2-1597642921482:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37005,DS-4eb35100-7344-40ca-9e30-247da284816b,DISK], DatanodeInfoWithStorage[127.0.0.1:38058,DS-1f75c51c-5e8d-4d42-a9a6-1f0a721ebaea,DISK], DatanodeInfoWithStorage[127.0.0.1:45417,DS-1130e625-503f-4f92-a023-3e752fbdf1ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33478,DS-fe7c78f3-0e2d-4514-bb68-287dfb53f12b,DISK], DatanodeInfoWithStorage[127.0.0.1:36695,DS-82ad4ec4-c80d-4b50-b5a0-980984f75ede,DISK], DatanodeInfoWithStorage[127.0.0.1:34130,DS-d91cd194-aef4-40be-ae2d-8ffa084c9dff,DISK], DatanodeInfoWithStorage[127.0.0.1:41506,DS-b4231bee-0d96-4f1c-a13b-f6a12412a1f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42573,DS-8b20877d-0ea3-4a91-86a1-a89903185166,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1737937854-172.17.0.2-1597643048835:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45764,DS-1eaef3dc-57ad-4cf7-a994-9ae2a4a82367,DISK], DatanodeInfoWithStorage[127.0.0.1:33596,DS-86c38d3f-b78d-49da-b315-8a36ffbbae76,DISK], DatanodeInfoWithStorage[127.0.0.1:43974,DS-cc1d8379-e0a0-4447-b7c5-0395fc860def,DISK], DatanodeInfoWithStorage[127.0.0.1:44871,DS-e0cb437f-0232-4cc1-990d-8d121332f5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42109,DS-bd4e4162-d03c-4ac9-bf53-844fa9ac466c,DISK], DatanodeInfoWithStorage[127.0.0.1:38406,DS-c29622d7-b7b5-4059-a378-33466ccbc122,DISK], DatanodeInfoWithStorage[127.0.0.1:43534,DS-255f53e8-980c-4184-b617-22d9c637a48e,DISK], DatanodeInfoWithStorage[127.0.0.1:46155,DS-cf681186-5106-4ec9-89b6-60c7dc38623c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1737937854-172.17.0.2-1597643048835:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45764,DS-1eaef3dc-57ad-4cf7-a994-9ae2a4a82367,DISK], DatanodeInfoWithStorage[127.0.0.1:33596,DS-86c38d3f-b78d-49da-b315-8a36ffbbae76,DISK], DatanodeInfoWithStorage[127.0.0.1:43974,DS-cc1d8379-e0a0-4447-b7c5-0395fc860def,DISK], DatanodeInfoWithStorage[127.0.0.1:44871,DS-e0cb437f-0232-4cc1-990d-8d121332f5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42109,DS-bd4e4162-d03c-4ac9-bf53-844fa9ac466c,DISK], DatanodeInfoWithStorage[127.0.0.1:38406,DS-c29622d7-b7b5-4059-a378-33466ccbc122,DISK], DatanodeInfoWithStorage[127.0.0.1:43534,DS-255f53e8-980c-4184-b617-22d9c637a48e,DISK], DatanodeInfoWithStorage[127.0.0.1:46155,DS-cf681186-5106-4ec9-89b6-60c7dc38623c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-972827940-172.17.0.2-1597643441850:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34233,DS-0c52fecd-b1fe-4707-b15a-dce2b38ad3f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39916,DS-820eb121-e7f2-47a9-8dd0-965df1f7d675,DISK], DatanodeInfoWithStorage[127.0.0.1:42395,DS-5eebb7af-d982-42ba-91ac-86ca36fa37f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34441,DS-e0cd94b6-f1e8-4551-a759-7524053a16f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43002,DS-87e79746-d0e6-4d73-9c75-66bad36f449b,DISK], DatanodeInfoWithStorage[127.0.0.1:45304,DS-c7d139c1-1563-4017-8927-e04823afe992,DISK], DatanodeInfoWithStorage[127.0.0.1:44118,DS-4393278b-b6ac-4628-b91c-cfb81d311c92,DISK], DatanodeInfoWithStorage[127.0.0.1:41377,DS-d99163aa-fcf3-49e5-aba1-114f21ba78c2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-972827940-172.17.0.2-1597643441850:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34233,DS-0c52fecd-b1fe-4707-b15a-dce2b38ad3f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39916,DS-820eb121-e7f2-47a9-8dd0-965df1f7d675,DISK], DatanodeInfoWithStorage[127.0.0.1:42395,DS-5eebb7af-d982-42ba-91ac-86ca36fa37f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34441,DS-e0cd94b6-f1e8-4551-a759-7524053a16f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43002,DS-87e79746-d0e6-4d73-9c75-66bad36f449b,DISK], DatanodeInfoWithStorage[127.0.0.1:45304,DS-c7d139c1-1563-4017-8927-e04823afe992,DISK], DatanodeInfoWithStorage[127.0.0.1:44118,DS-4393278b-b6ac-4628-b91c-cfb81d311c92,DISK], DatanodeInfoWithStorage[127.0.0.1:41377,DS-d99163aa-fcf3-49e5-aba1-114f21ba78c2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-818682863-172.17.0.2-1597643584803:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35141,DS-c3d82f0f-d87b-4a76-ab8f-def20503a75b,DISK], DatanodeInfoWithStorage[127.0.0.1:34005,DS-00761b8b-1742-4ba0-a736-f5be4bf7c457,DISK], DatanodeInfoWithStorage[127.0.0.1:32991,DS-ca1197ac-5dc1-400c-b8c3-78fa39df1f01,DISK], DatanodeInfoWithStorage[127.0.0.1:44223,DS-1b199f8b-56eb-4397-93a3-3c1123aba072,DISK], DatanodeInfoWithStorage[127.0.0.1:35156,DS-80fe8150-cb38-4a64-80aa-d87b76c3ba2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37549,DS-6ed87f2b-5d96-429f-bd5b-652b8f109124,DISK], DatanodeInfoWithStorage[127.0.0.1:33842,DS-e001ac39-f950-487c-8fd8-8191b6ce7a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34651,DS-dbf1dc66-df11-41cb-be10-018b5a15d653,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-818682863-172.17.0.2-1597643584803:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35141,DS-c3d82f0f-d87b-4a76-ab8f-def20503a75b,DISK], DatanodeInfoWithStorage[127.0.0.1:34005,DS-00761b8b-1742-4ba0-a736-f5be4bf7c457,DISK], DatanodeInfoWithStorage[127.0.0.1:32991,DS-ca1197ac-5dc1-400c-b8c3-78fa39df1f01,DISK], DatanodeInfoWithStorage[127.0.0.1:44223,DS-1b199f8b-56eb-4397-93a3-3c1123aba072,DISK], DatanodeInfoWithStorage[127.0.0.1:35156,DS-80fe8150-cb38-4a64-80aa-d87b76c3ba2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37549,DS-6ed87f2b-5d96-429f-bd5b-652b8f109124,DISK], DatanodeInfoWithStorage[127.0.0.1:33842,DS-e001ac39-f950-487c-8fd8-8191b6ce7a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34651,DS-dbf1dc66-df11-41cb-be10-018b5a15d653,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1853440480-172.17.0.2-1597644241241:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37201,DS-3768f5f0-2ae3-489a-af81-7f5fd559d837,DISK], DatanodeInfoWithStorage[127.0.0.1:41209,DS-0f8dc928-59bc-42da-a32f-84ff098e0868,DISK], DatanodeInfoWithStorage[127.0.0.1:39978,DS-b8db651d-02dc-4971-97af-024fb51ba986,DISK], DatanodeInfoWithStorage[127.0.0.1:44917,DS-0d0d86ab-712b-44f8-9d1a-a23a88868634,DISK], DatanodeInfoWithStorage[127.0.0.1:40535,DS-5f07c6c6-b6ba-4a0d-ad50-19dff72a3783,DISK], DatanodeInfoWithStorage[127.0.0.1:42073,DS-50ae432b-69f3-48bc-8b83-ef443a1a6eea,DISK], DatanodeInfoWithStorage[127.0.0.1:42399,DS-eb37c592-9e67-4d42-a617-eb6efca1ddb1,DISK], DatanodeInfoWithStorage[127.0.0.1:45852,DS-fdc80b63-852b-4096-8758-bf1320223306,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1853440480-172.17.0.2-1597644241241:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37201,DS-3768f5f0-2ae3-489a-af81-7f5fd559d837,DISK], DatanodeInfoWithStorage[127.0.0.1:41209,DS-0f8dc928-59bc-42da-a32f-84ff098e0868,DISK], DatanodeInfoWithStorage[127.0.0.1:39978,DS-b8db651d-02dc-4971-97af-024fb51ba986,DISK], DatanodeInfoWithStorage[127.0.0.1:44917,DS-0d0d86ab-712b-44f8-9d1a-a23a88868634,DISK], DatanodeInfoWithStorage[127.0.0.1:40535,DS-5f07c6c6-b6ba-4a0d-ad50-19dff72a3783,DISK], DatanodeInfoWithStorage[127.0.0.1:42073,DS-50ae432b-69f3-48bc-8b83-ef443a1a6eea,DISK], DatanodeInfoWithStorage[127.0.0.1:42399,DS-eb37c592-9e67-4d42-a617-eb6efca1ddb1,DISK], DatanodeInfoWithStorage[127.0.0.1:45852,DS-fdc80b63-852b-4096-8758-bf1320223306,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1970395878-172.17.0.2-1597644711114:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40462,DS-d27d0a00-3740-47e6-a4a9-e81bc2e0cc53,DISK], DatanodeInfoWithStorage[127.0.0.1:39675,DS-f04bbf3f-5c60-439d-be47-e82ab42ace04,DISK], DatanodeInfoWithStorage[127.0.0.1:34131,DS-de390511-6231-4507-8246-98b8d9ee820c,DISK], DatanodeInfoWithStorage[127.0.0.1:33877,DS-0d1af83a-7780-4657-b402-bb1c264217ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40810,DS-72895482-8e26-4602-881b-9d9b1e6a82e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43480,DS-00cf1049-8b88-4766-a675-6e94f5871c22,DISK], DatanodeInfoWithStorage[127.0.0.1:36510,DS-0f86ebd9-6bd4-4ed6-955a-fc9fbe06500e,DISK], DatanodeInfoWithStorage[127.0.0.1:34969,DS-64ee1d74-3efa-4e45-8c9d-7292a9d8ff24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1970395878-172.17.0.2-1597644711114:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40462,DS-d27d0a00-3740-47e6-a4a9-e81bc2e0cc53,DISK], DatanodeInfoWithStorage[127.0.0.1:39675,DS-f04bbf3f-5c60-439d-be47-e82ab42ace04,DISK], DatanodeInfoWithStorage[127.0.0.1:34131,DS-de390511-6231-4507-8246-98b8d9ee820c,DISK], DatanodeInfoWithStorage[127.0.0.1:33877,DS-0d1af83a-7780-4657-b402-bb1c264217ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40810,DS-72895482-8e26-4602-881b-9d9b1e6a82e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43480,DS-00cf1049-8b88-4766-a675-6e94f5871c22,DISK], DatanodeInfoWithStorage[127.0.0.1:36510,DS-0f86ebd9-6bd4-4ed6-955a-fc9fbe06500e,DISK], DatanodeInfoWithStorage[127.0.0.1:34969,DS-64ee1d74-3efa-4e45-8c9d-7292a9d8ff24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-49446248-172.17.0.2-1597644846112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38879,DS-de03ebef-830f-48d7-b3a7-bbf0c9b624a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44178,DS-ba612a4d-43fd-456a-aa45-96c239da4266,DISK], DatanodeInfoWithStorage[127.0.0.1:33589,DS-5f87a86f-c9b7-4604-a42d-5f7a3e4fa8e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35822,DS-3f5f5429-70db-468a-8792-39e224167f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:44504,DS-beaefa8c-7230-456d-a367-18f30e5a1575,DISK], DatanodeInfoWithStorage[127.0.0.1:34080,DS-3f1f063a-49ec-4a0d-87dc-fed022ebb4c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38502,DS-6186de79-0624-40c6-85cf-43fcd2529b34,DISK], DatanodeInfoWithStorage[127.0.0.1:34642,DS-f391ee54-4585-42c1-b36a-46a9cbc23123,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-49446248-172.17.0.2-1597644846112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38879,DS-de03ebef-830f-48d7-b3a7-bbf0c9b624a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44178,DS-ba612a4d-43fd-456a-aa45-96c239da4266,DISK], DatanodeInfoWithStorage[127.0.0.1:33589,DS-5f87a86f-c9b7-4604-a42d-5f7a3e4fa8e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35822,DS-3f5f5429-70db-468a-8792-39e224167f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:44504,DS-beaefa8c-7230-456d-a367-18f30e5a1575,DISK], DatanodeInfoWithStorage[127.0.0.1:34080,DS-3f1f063a-49ec-4a0d-87dc-fed022ebb4c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38502,DS-6186de79-0624-40c6-85cf-43fcd2529b34,DISK], DatanodeInfoWithStorage[127.0.0.1:34642,DS-f391ee54-4585-42c1-b36a-46a9cbc23123,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 19 out of 50
result: false positive !!!
Total execution time in seconds : 6846
