reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 1073741824
v2: 62914560
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 1073741824
v2: 62914560
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1142860928-172.17.0.9-1597663952459:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36812,DS-0d6a5095-8708-4e68-bf82-4ee3bde9119b,DISK], DatanodeInfoWithStorage[127.0.0.1:44814,DS-e178ca08-d029-4a59-b549-3926e9f60725,DISK], DatanodeInfoWithStorage[127.0.0.1:42395,DS-4d02c17f-995a-43fd-9cd2-272d40bb1d91,DISK], DatanodeInfoWithStorage[127.0.0.1:40341,DS-a1027569-b811-4e75-bafb-9615b6f6346e,DISK], DatanodeInfoWithStorage[127.0.0.1:42876,DS-bb131f91-fac3-4e32-a6e2-5c07acdb4e55,DISK], DatanodeInfoWithStorage[127.0.0.1:43171,DS-695b2ba5-69d3-4207-a344-7d0b5353defd,DISK], DatanodeInfoWithStorage[127.0.0.1:41231,DS-2cd240df-05c1-40b6-ad84-e26cffa06b04,DISK], DatanodeInfoWithStorage[127.0.0.1:35050,DS-75e26dcf-171e-404f-8127-ec02b17aa5b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1142860928-172.17.0.9-1597663952459:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36812,DS-0d6a5095-8708-4e68-bf82-4ee3bde9119b,DISK], DatanodeInfoWithStorage[127.0.0.1:44814,DS-e178ca08-d029-4a59-b549-3926e9f60725,DISK], DatanodeInfoWithStorage[127.0.0.1:42395,DS-4d02c17f-995a-43fd-9cd2-272d40bb1d91,DISK], DatanodeInfoWithStorage[127.0.0.1:40341,DS-a1027569-b811-4e75-bafb-9615b6f6346e,DISK], DatanodeInfoWithStorage[127.0.0.1:42876,DS-bb131f91-fac3-4e32-a6e2-5c07acdb4e55,DISK], DatanodeInfoWithStorage[127.0.0.1:43171,DS-695b2ba5-69d3-4207-a344-7d0b5353defd,DISK], DatanodeInfoWithStorage[127.0.0.1:41231,DS-2cd240df-05c1-40b6-ad84-e26cffa06b04,DISK], DatanodeInfoWithStorage[127.0.0.1:35050,DS-75e26dcf-171e-404f-8127-ec02b17aa5b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 1073741824
v2: 62914560
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-879676358-172.17.0.9-1597664065991:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39608,DS-54b0f669-8257-41eb-99ec-c78d153bf814,DISK], DatanodeInfoWithStorage[127.0.0.1:37293,DS-91bc7e67-913e-448b-94c5-f7e79244827a,DISK], DatanodeInfoWithStorage[127.0.0.1:45079,DS-4712dc32-c3d3-4352-8c8c-96c828e39d69,DISK], DatanodeInfoWithStorage[127.0.0.1:44805,DS-b3de4144-4c29-41ba-ab81-2aaccda3d24f,DISK], DatanodeInfoWithStorage[127.0.0.1:43093,DS-b1c99608-0c4e-49a5-8862-20208b859f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45993,DS-e1d87258-d0c8-4d8d-a011-5148b602226b,DISK], DatanodeInfoWithStorage[127.0.0.1:45670,DS-0b280290-8279-4bc3-b1f9-ceb31dbc1e99,DISK], DatanodeInfoWithStorage[127.0.0.1:44492,DS-4cad4317-aea2-4703-9e3d-7959b1df673c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-879676358-172.17.0.9-1597664065991:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39608,DS-54b0f669-8257-41eb-99ec-c78d153bf814,DISK], DatanodeInfoWithStorage[127.0.0.1:37293,DS-91bc7e67-913e-448b-94c5-f7e79244827a,DISK], DatanodeInfoWithStorage[127.0.0.1:45079,DS-4712dc32-c3d3-4352-8c8c-96c828e39d69,DISK], DatanodeInfoWithStorage[127.0.0.1:44805,DS-b3de4144-4c29-41ba-ab81-2aaccda3d24f,DISK], DatanodeInfoWithStorage[127.0.0.1:43093,DS-b1c99608-0c4e-49a5-8862-20208b859f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45993,DS-e1d87258-d0c8-4d8d-a011-5148b602226b,DISK], DatanodeInfoWithStorage[127.0.0.1:45670,DS-0b280290-8279-4bc3-b1f9-ceb31dbc1e99,DISK], DatanodeInfoWithStorage[127.0.0.1:44492,DS-4cad4317-aea2-4703-9e3d-7959b1df673c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 1073741824
v2: 62914560
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-67984257-172.17.0.9-1597664403545:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43351,DS-6552d152-7b7c-4df8-8dc3-9bfb8eb76a86,DISK], DatanodeInfoWithStorage[127.0.0.1:44737,DS-8726c715-f6c7-4944-94af-82d56644ba56,DISK], DatanodeInfoWithStorage[127.0.0.1:41832,DS-cc5896ae-bade-40db-a6d5-d2274249960f,DISK], DatanodeInfoWithStorage[127.0.0.1:44430,DS-4023635b-40fe-40c5-b945-c89ba84f87d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40282,DS-13d1b4d8-47d5-4eda-9571-37acdb4b62c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34611,DS-93b68d9e-6760-482a-afef-de84cb823d79,DISK], DatanodeInfoWithStorage[127.0.0.1:37141,DS-27a687b7-f872-4ec2-ba9d-1e0212c53929,DISK], DatanodeInfoWithStorage[127.0.0.1:32815,DS-b06d7014-6b09-44a8-8526-7078c02f3ca0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-67984257-172.17.0.9-1597664403545:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43351,DS-6552d152-7b7c-4df8-8dc3-9bfb8eb76a86,DISK], DatanodeInfoWithStorage[127.0.0.1:44737,DS-8726c715-f6c7-4944-94af-82d56644ba56,DISK], DatanodeInfoWithStorage[127.0.0.1:41832,DS-cc5896ae-bade-40db-a6d5-d2274249960f,DISK], DatanodeInfoWithStorage[127.0.0.1:44430,DS-4023635b-40fe-40c5-b945-c89ba84f87d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40282,DS-13d1b4d8-47d5-4eda-9571-37acdb4b62c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34611,DS-93b68d9e-6760-482a-afef-de84cb823d79,DISK], DatanodeInfoWithStorage[127.0.0.1:37141,DS-27a687b7-f872-4ec2-ba9d-1e0212c53929,DISK], DatanodeInfoWithStorage[127.0.0.1:32815,DS-b06d7014-6b09-44a8-8526-7078c02f3ca0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 1073741824
v2: 62914560
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1937085918-172.17.0.9-1597665244115:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34364,DS-5cda269b-1d0b-4538-bace-7772f3b1eade,DISK], DatanodeInfoWithStorage[127.0.0.1:46219,DS-09ca7c34-ad09-4fa9-9cbb-03f4a8e43d91,DISK], DatanodeInfoWithStorage[127.0.0.1:44976,DS-132eca22-aad7-4205-9eed-435e584d79cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40642,DS-6b5f7cc7-b8cd-4521-931e-782f2f51d2a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43123,DS-1ef7a71b-6312-444e-b2b6-c6035478532e,DISK], DatanodeInfoWithStorage[127.0.0.1:46762,DS-b48a6d4e-e1d1-49d6-ba5a-c2176f92a0d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42604,DS-79cc112b-a8f8-42c0-8cef-dc5658cc598a,DISK], DatanodeInfoWithStorage[127.0.0.1:38781,DS-5fa6cbaf-0742-41a4-b999-847a9f4106ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1937085918-172.17.0.9-1597665244115:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34364,DS-5cda269b-1d0b-4538-bace-7772f3b1eade,DISK], DatanodeInfoWithStorage[127.0.0.1:46219,DS-09ca7c34-ad09-4fa9-9cbb-03f4a8e43d91,DISK], DatanodeInfoWithStorage[127.0.0.1:44976,DS-132eca22-aad7-4205-9eed-435e584d79cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40642,DS-6b5f7cc7-b8cd-4521-931e-782f2f51d2a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43123,DS-1ef7a71b-6312-444e-b2b6-c6035478532e,DISK], DatanodeInfoWithStorage[127.0.0.1:46762,DS-b48a6d4e-e1d1-49d6-ba5a-c2176f92a0d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42604,DS-79cc112b-a8f8-42c0-8cef-dc5658cc598a,DISK], DatanodeInfoWithStorage[127.0.0.1:38781,DS-5fa6cbaf-0742-41a4-b999-847a9f4106ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 1073741824
v2: 62914560
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-244403731-172.17.0.9-1597665911084:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36457,DS-4e474e6a-609d-4be0-9540-0b9f09178538,DISK], DatanodeInfoWithStorage[127.0.0.1:38836,DS-cb3afe64-7b01-4321-9c14-f7506fd1879b,DISK], DatanodeInfoWithStorage[127.0.0.1:43268,DS-343ebfaa-03e8-4985-8c16-f8a1c98170cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44358,DS-74c97f73-74df-4f72-b425-30d471e3f998,DISK], DatanodeInfoWithStorage[127.0.0.1:46051,DS-94116527-74ec-4329-b600-bc132c0a0259,DISK], DatanodeInfoWithStorage[127.0.0.1:44415,DS-13f0034a-50ba-4f85-ba9c-fea0f72dc92c,DISK], DatanodeInfoWithStorage[127.0.0.1:33709,DS-411d47b3-5548-48b4-9585-73870017c4c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39856,DS-d94bb1a6-4a28-48da-aae3-474bffe6e5a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-244403731-172.17.0.9-1597665911084:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36457,DS-4e474e6a-609d-4be0-9540-0b9f09178538,DISK], DatanodeInfoWithStorage[127.0.0.1:38836,DS-cb3afe64-7b01-4321-9c14-f7506fd1879b,DISK], DatanodeInfoWithStorage[127.0.0.1:43268,DS-343ebfaa-03e8-4985-8c16-f8a1c98170cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44358,DS-74c97f73-74df-4f72-b425-30d471e3f998,DISK], DatanodeInfoWithStorage[127.0.0.1:46051,DS-94116527-74ec-4329-b600-bc132c0a0259,DISK], DatanodeInfoWithStorage[127.0.0.1:44415,DS-13f0034a-50ba-4f85-ba9c-fea0f72dc92c,DISK], DatanodeInfoWithStorage[127.0.0.1:33709,DS-411d47b3-5548-48b4-9585-73870017c4c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39856,DS-d94bb1a6-4a28-48da-aae3-474bffe6e5a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 1073741824
v2: 62914560
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-344793855-172.17.0.9-1597666288902:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39203,DS-b05136a4-8acc-4f89-89fa-9cb469df7024,DISK], DatanodeInfoWithStorage[127.0.0.1:43206,DS-a8ca60c0-9463-4343-99dd-6add86614d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:37836,DS-fd402d0f-9ae5-4571-9c88-55953ce5490a,DISK], DatanodeInfoWithStorage[127.0.0.1:36543,DS-14741b8f-32da-4e2a-8b5b-3b06b9cb1ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:42175,DS-f29d3859-8071-45db-8725-89ba7fa29a72,DISK], DatanodeInfoWithStorage[127.0.0.1:42246,DS-3ca92bf8-82dd-40f4-b13e-8820e6e61a49,DISK], DatanodeInfoWithStorage[127.0.0.1:42948,DS-193d0190-c9c0-4f1a-bce1-36406e2ffa2d,DISK], DatanodeInfoWithStorage[127.0.0.1:34449,DS-817b09b4-d3f8-462d-bb58-64d14d7b5378,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-344793855-172.17.0.9-1597666288902:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39203,DS-b05136a4-8acc-4f89-89fa-9cb469df7024,DISK], DatanodeInfoWithStorage[127.0.0.1:43206,DS-a8ca60c0-9463-4343-99dd-6add86614d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:37836,DS-fd402d0f-9ae5-4571-9c88-55953ce5490a,DISK], DatanodeInfoWithStorage[127.0.0.1:36543,DS-14741b8f-32da-4e2a-8b5b-3b06b9cb1ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:42175,DS-f29d3859-8071-45db-8725-89ba7fa29a72,DISK], DatanodeInfoWithStorage[127.0.0.1:42246,DS-3ca92bf8-82dd-40f4-b13e-8820e6e61a49,DISK], DatanodeInfoWithStorage[127.0.0.1:42948,DS-193d0190-c9c0-4f1a-bce1-36406e2ffa2d,DISK], DatanodeInfoWithStorage[127.0.0.1:34449,DS-817b09b4-d3f8-462d-bb58-64d14d7b5378,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 1073741824
v2: 62914560
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-408253231-172.17.0.9-1597666708449:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45200,DS-6ebc85de-3529-4b14-bdec-69836f7afeb3,DISK], DatanodeInfoWithStorage[127.0.0.1:41928,DS-d3179716-b8a6-4af6-955b-da2120021bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:39121,DS-03d3890d-e349-4784-8968-78d6e310c5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44164,DS-815b1a86-69ef-492c-8166-6827141901c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34299,DS-bfe8339e-b588-4119-b472-794aa66140d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41785,DS-4b2bec13-d164-49e0-b6ce-0e2261eab08f,DISK], DatanodeInfoWithStorage[127.0.0.1:36788,DS-ba7a2582-5255-4571-83c2-5367634ff7fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43458,DS-8ba15a4b-a588-4d66-b94d-42f0a1ec361f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-408253231-172.17.0.9-1597666708449:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45200,DS-6ebc85de-3529-4b14-bdec-69836f7afeb3,DISK], DatanodeInfoWithStorage[127.0.0.1:41928,DS-d3179716-b8a6-4af6-955b-da2120021bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:39121,DS-03d3890d-e349-4784-8968-78d6e310c5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44164,DS-815b1a86-69ef-492c-8166-6827141901c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34299,DS-bfe8339e-b588-4119-b472-794aa66140d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41785,DS-4b2bec13-d164-49e0-b6ce-0e2261eab08f,DISK], DatanodeInfoWithStorage[127.0.0.1:36788,DS-ba7a2582-5255-4571-83c2-5367634ff7fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43458,DS-8ba15a4b-a588-4d66-b94d-42f0a1ec361f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 1073741824
v2: 62914560
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-866333424-172.17.0.9-1597666932798:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35203,DS-6f22f2bd-5125-41be-a263-9c36a13ca903,DISK], DatanodeInfoWithStorage[127.0.0.1:40765,DS-b862cab7-031c-4c18-a2ea-456d47efc718,DISK], DatanodeInfoWithStorage[127.0.0.1:33619,DS-216f9e2b-2a17-4d7f-8757-716c5080eeba,DISK], DatanodeInfoWithStorage[127.0.0.1:34448,DS-4cdd5480-f451-4a6a-941d-a703159abb19,DISK], DatanodeInfoWithStorage[127.0.0.1:36672,DS-ae77c5ce-5468-465e-a663-2b96ac386df2,DISK], DatanodeInfoWithStorage[127.0.0.1:38631,DS-db54114e-97d6-46f9-9ca7-1867aff0b2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39145,DS-ea806a09-0ccb-4fb2-8df1-ccc87dabc012,DISK], DatanodeInfoWithStorage[127.0.0.1:46472,DS-e76ed4bb-99ab-4d0d-9ff0-02781d7c21ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-866333424-172.17.0.9-1597666932798:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35203,DS-6f22f2bd-5125-41be-a263-9c36a13ca903,DISK], DatanodeInfoWithStorage[127.0.0.1:40765,DS-b862cab7-031c-4c18-a2ea-456d47efc718,DISK], DatanodeInfoWithStorage[127.0.0.1:33619,DS-216f9e2b-2a17-4d7f-8757-716c5080eeba,DISK], DatanodeInfoWithStorage[127.0.0.1:34448,DS-4cdd5480-f451-4a6a-941d-a703159abb19,DISK], DatanodeInfoWithStorage[127.0.0.1:36672,DS-ae77c5ce-5468-465e-a663-2b96ac386df2,DISK], DatanodeInfoWithStorage[127.0.0.1:38631,DS-db54114e-97d6-46f9-9ca7-1867aff0b2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39145,DS-ea806a09-0ccb-4fb2-8df1-ccc87dabc012,DISK], DatanodeInfoWithStorage[127.0.0.1:46472,DS-e76ed4bb-99ab-4d0d-9ff0-02781d7c21ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 1073741824
v2: 62914560
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1819293442-172.17.0.9-1597666977333:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46642,DS-2c12b3c4-9bdd-487c-adb7-36cd0aee6808,DISK], DatanodeInfoWithStorage[127.0.0.1:46453,DS-d63905f9-8a6e-4566-aeb5-b2220446309d,DISK], DatanodeInfoWithStorage[127.0.0.1:45979,DS-987c2b0f-1969-4210-b128-9085e0a5bbac,DISK], DatanodeInfoWithStorage[127.0.0.1:34339,DS-3c5f41c7-8771-4c85-b34e-babb7ab6a5cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46530,DS-28e4d347-76ee-4a21-9c35-da92decdd556,DISK], DatanodeInfoWithStorage[127.0.0.1:33995,DS-7e5a05a9-7030-454a-991e-43d0fcb39672,DISK], DatanodeInfoWithStorage[127.0.0.1:38037,DS-b5a1332b-2597-4dca-991b-d39a916e4d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34423,DS-962c7498-bdd7-4c7d-a376-051bd24642e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1819293442-172.17.0.9-1597666977333:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46642,DS-2c12b3c4-9bdd-487c-adb7-36cd0aee6808,DISK], DatanodeInfoWithStorage[127.0.0.1:46453,DS-d63905f9-8a6e-4566-aeb5-b2220446309d,DISK], DatanodeInfoWithStorage[127.0.0.1:45979,DS-987c2b0f-1969-4210-b128-9085e0a5bbac,DISK], DatanodeInfoWithStorage[127.0.0.1:34339,DS-3c5f41c7-8771-4c85-b34e-babb7ab6a5cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46530,DS-28e4d347-76ee-4a21-9c35-da92decdd556,DISK], DatanodeInfoWithStorage[127.0.0.1:33995,DS-7e5a05a9-7030-454a-991e-43d0fcb39672,DISK], DatanodeInfoWithStorage[127.0.0.1:38037,DS-b5a1332b-2597-4dca-991b-d39a916e4d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34423,DS-962c7498-bdd7-4c7d-a376-051bd24642e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 1073741824
v2: 62914560
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1145903006-172.17.0.9-1597667025892:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39836,DS-79a2394a-cb99-49da-be90-5281cfe21a19,DISK], DatanodeInfoWithStorage[127.0.0.1:33202,DS-90c981dd-4369-4279-bc68-669b9756e559,DISK], DatanodeInfoWithStorage[127.0.0.1:41468,DS-4eded94f-1015-4ea6-aa0e-f0daa6c5cb2d,DISK], DatanodeInfoWithStorage[127.0.0.1:34795,DS-83c9a1c2-9b82-4054-85d4-2101e4e2371d,DISK], DatanodeInfoWithStorage[127.0.0.1:36292,DS-706a1be6-e640-4cfe-bf9d-87c15e6758e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40056,DS-361b9241-e356-445f-b57d-64eb2cfdf6e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41827,DS-05c2a080-0405-4632-acf9-61f4c47b7250,DISK], DatanodeInfoWithStorage[127.0.0.1:44100,DS-1986c4b3-2d74-4ee9-bfb5-4c2f12134f03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1145903006-172.17.0.9-1597667025892:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39836,DS-79a2394a-cb99-49da-be90-5281cfe21a19,DISK], DatanodeInfoWithStorage[127.0.0.1:33202,DS-90c981dd-4369-4279-bc68-669b9756e559,DISK], DatanodeInfoWithStorage[127.0.0.1:41468,DS-4eded94f-1015-4ea6-aa0e-f0daa6c5cb2d,DISK], DatanodeInfoWithStorage[127.0.0.1:34795,DS-83c9a1c2-9b82-4054-85d4-2101e4e2371d,DISK], DatanodeInfoWithStorage[127.0.0.1:36292,DS-706a1be6-e640-4cfe-bf9d-87c15e6758e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40056,DS-361b9241-e356-445f-b57d-64eb2cfdf6e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41827,DS-05c2a080-0405-4632-acf9-61f4c47b7250,DISK], DatanodeInfoWithStorage[127.0.0.1:44100,DS-1986c4b3-2d74-4ee9-bfb5-4c2f12134f03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 1073741824
v2: 62914560
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-76840083-172.17.0.9-1597667813251:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41952,DS-d32bea79-4148-49c7-8ce3-16367d8d6fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:43614,DS-99e212c5-20d4-4ca7-8fa6-f3210b10998b,DISK], DatanodeInfoWithStorage[127.0.0.1:44091,DS-780e08a6-27af-4227-a31f-6fd816840cff,DISK], DatanodeInfoWithStorage[127.0.0.1:38024,DS-2b40c4e6-3d57-4bfb-93db-ccfe660a798b,DISK], DatanodeInfoWithStorage[127.0.0.1:34984,DS-8956d527-4c1a-4443-808e-55d1a13c4e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:42598,DS-60741281-eb2c-45cf-95c2-01e14e0eb325,DISK], DatanodeInfoWithStorage[127.0.0.1:34645,DS-3e6ec65c-7b23-44f8-a57a-8eab335243ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45902,DS-14b43bb9-662c-4c6f-af90-33524a13058e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-76840083-172.17.0.9-1597667813251:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41952,DS-d32bea79-4148-49c7-8ce3-16367d8d6fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:43614,DS-99e212c5-20d4-4ca7-8fa6-f3210b10998b,DISK], DatanodeInfoWithStorage[127.0.0.1:44091,DS-780e08a6-27af-4227-a31f-6fd816840cff,DISK], DatanodeInfoWithStorage[127.0.0.1:38024,DS-2b40c4e6-3d57-4bfb-93db-ccfe660a798b,DISK], DatanodeInfoWithStorage[127.0.0.1:34984,DS-8956d527-4c1a-4443-808e-55d1a13c4e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:42598,DS-60741281-eb2c-45cf-95c2-01e14e0eb325,DISK], DatanodeInfoWithStorage[127.0.0.1:34645,DS-3e6ec65c-7b23-44f8-a57a-8eab335243ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45902,DS-14b43bb9-662c-4c6f-af90-33524a13058e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 1073741824
v2: 62914560
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-390321185-172.17.0.9-1597667889738:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38670,DS-acb04a16-23ba-4f69-bc5b-ff8cf2e08d57,DISK], DatanodeInfoWithStorage[127.0.0.1:34249,DS-d403ebd8-83af-4973-979f-e2dfd8fd9b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39550,DS-15831868-4281-42ac-81cd-0aae0b3385ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43393,DS-ddbf58fe-4de8-4f75-9b07-2f10456b1ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:33253,DS-2a67b430-2682-497d-aa3f-d381a48cb23c,DISK], DatanodeInfoWithStorage[127.0.0.1:46789,DS-19ef675b-e7df-48e6-9352-ef5219f55628,DISK], DatanodeInfoWithStorage[127.0.0.1:35286,DS-31eb6019-d89b-4199-ae84-38b753b55ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:44969,DS-0b4982a2-7a91-4c6d-b103-e3e1ad1524c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-390321185-172.17.0.9-1597667889738:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38670,DS-acb04a16-23ba-4f69-bc5b-ff8cf2e08d57,DISK], DatanodeInfoWithStorage[127.0.0.1:34249,DS-d403ebd8-83af-4973-979f-e2dfd8fd9b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39550,DS-15831868-4281-42ac-81cd-0aae0b3385ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43393,DS-ddbf58fe-4de8-4f75-9b07-2f10456b1ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:33253,DS-2a67b430-2682-497d-aa3f-d381a48cb23c,DISK], DatanodeInfoWithStorage[127.0.0.1:46789,DS-19ef675b-e7df-48e6-9352-ef5219f55628,DISK], DatanodeInfoWithStorage[127.0.0.1:35286,DS-31eb6019-d89b-4199-ae84-38b753b55ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:44969,DS-0b4982a2-7a91-4c6d-b103-e3e1ad1524c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 1073741824
v2: 62914560
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1356823842-172.17.0.9-1597668047743:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40339,DS-53a32b06-93bd-4fb6-8ab6-25d931fecc67,DISK], DatanodeInfoWithStorage[127.0.0.1:42053,DS-ece780e1-86e7-4fd3-9ca2-ad9efbbb2c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35394,DS-cba4ab31-8964-4428-8cfb-285cc0afa845,DISK], DatanodeInfoWithStorage[127.0.0.1:41353,DS-3534ced7-c17e-4cb1-bcf2-1d4314347f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42763,DS-a9d8a105-5ac6-45f6-8918-56ed2c42ac2e,DISK], DatanodeInfoWithStorage[127.0.0.1:45445,DS-59899f13-6fd8-4abe-bbbb-b919c9acb87c,DISK], DatanodeInfoWithStorage[127.0.0.1:33956,DS-02047c53-85c0-4010-a1c4-d12ac19a52bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35025,DS-22a815e3-3e3c-46da-b693-d0d5ec3ba8bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1356823842-172.17.0.9-1597668047743:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40339,DS-53a32b06-93bd-4fb6-8ab6-25d931fecc67,DISK], DatanodeInfoWithStorage[127.0.0.1:42053,DS-ece780e1-86e7-4fd3-9ca2-ad9efbbb2c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35394,DS-cba4ab31-8964-4428-8cfb-285cc0afa845,DISK], DatanodeInfoWithStorage[127.0.0.1:41353,DS-3534ced7-c17e-4cb1-bcf2-1d4314347f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42763,DS-a9d8a105-5ac6-45f6-8918-56ed2c42ac2e,DISK], DatanodeInfoWithStorage[127.0.0.1:45445,DS-59899f13-6fd8-4abe-bbbb-b919c9acb87c,DISK], DatanodeInfoWithStorage[127.0.0.1:33956,DS-02047c53-85c0-4010-a1c4-d12ac19a52bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35025,DS-22a815e3-3e3c-46da-b693-d0d5ec3ba8bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 1073741824
v2: 62914560
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-141393027-172.17.0.9-1597668680352:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33067,DS-02f09597-fcdf-4456-96a2-904ea0fe9da2,DISK], DatanodeInfoWithStorage[127.0.0.1:38311,DS-0060dfec-59a1-42b3-b0d1-0f63b1ed4977,DISK], DatanodeInfoWithStorage[127.0.0.1:43388,DS-67a90439-8a60-4e2d-97a0-c6f658686d33,DISK], DatanodeInfoWithStorage[127.0.0.1:38790,DS-1d99643c-4222-462b-92d9-15da4b2c7bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:39252,DS-bd9db8d3-de51-4aaa-8bd2-19d9dd3e5d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:38953,DS-82b406d3-a8c7-4695-9b0c-b208798becbe,DISK], DatanodeInfoWithStorage[127.0.0.1:35778,DS-5ebbc51d-4241-412d-9f19-821713c93572,DISK], DatanodeInfoWithStorage[127.0.0.1:34848,DS-6947af5d-b342-40ce-8590-57cfae4e230b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-141393027-172.17.0.9-1597668680352:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33067,DS-02f09597-fcdf-4456-96a2-904ea0fe9da2,DISK], DatanodeInfoWithStorage[127.0.0.1:38311,DS-0060dfec-59a1-42b3-b0d1-0f63b1ed4977,DISK], DatanodeInfoWithStorage[127.0.0.1:43388,DS-67a90439-8a60-4e2d-97a0-c6f658686d33,DISK], DatanodeInfoWithStorage[127.0.0.1:38790,DS-1d99643c-4222-462b-92d9-15da4b2c7bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:39252,DS-bd9db8d3-de51-4aaa-8bd2-19d9dd3e5d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:38953,DS-82b406d3-a8c7-4695-9b0c-b208798becbe,DISK], DatanodeInfoWithStorage[127.0.0.1:35778,DS-5ebbc51d-4241-412d-9f19-821713c93572,DISK], DatanodeInfoWithStorage[127.0.0.1:34848,DS-6947af5d-b342-40ce-8590-57cfae4e230b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 1073741824
v2: 62914560
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1462285086-172.17.0.9-1597669160404:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36808,DS-76a24e5e-8b6f-49cf-a82a-6f4f14196955,DISK], DatanodeInfoWithStorage[127.0.0.1:42292,DS-b42ac6e9-097d-48f1-b130-6a09269982e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35071,DS-1f6c0aa6-9f19-4968-a796-0910bb4568c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43770,DS-484b765e-12ec-4b0b-858c-800c468abe5a,DISK], DatanodeInfoWithStorage[127.0.0.1:33461,DS-b2683173-e8f1-4cd7-a78c-be1b0c0fd570,DISK], DatanodeInfoWithStorage[127.0.0.1:36019,DS-62719930-4dd6-4c4f-9e8b-d4b0737737b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33128,DS-af703ee6-5434-4bb5-a3d0-5ad3d94f3e96,DISK], DatanodeInfoWithStorage[127.0.0.1:34887,DS-8cdb1f37-4480-4991-bf95-8d18e3a338e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1462285086-172.17.0.9-1597669160404:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36808,DS-76a24e5e-8b6f-49cf-a82a-6f4f14196955,DISK], DatanodeInfoWithStorage[127.0.0.1:42292,DS-b42ac6e9-097d-48f1-b130-6a09269982e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35071,DS-1f6c0aa6-9f19-4968-a796-0910bb4568c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43770,DS-484b765e-12ec-4b0b-858c-800c468abe5a,DISK], DatanodeInfoWithStorage[127.0.0.1:33461,DS-b2683173-e8f1-4cd7-a78c-be1b0c0fd570,DISK], DatanodeInfoWithStorage[127.0.0.1:36019,DS-62719930-4dd6-4c4f-9e8b-d4b0737737b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33128,DS-af703ee6-5434-4bb5-a3d0-5ad3d94f3e96,DISK], DatanodeInfoWithStorage[127.0.0.1:34887,DS-8cdb1f37-4480-4991-bf95-8d18e3a338e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5747
