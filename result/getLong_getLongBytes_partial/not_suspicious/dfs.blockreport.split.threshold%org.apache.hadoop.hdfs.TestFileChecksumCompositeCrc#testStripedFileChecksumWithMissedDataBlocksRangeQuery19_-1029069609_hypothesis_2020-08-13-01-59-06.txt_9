reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 0
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 0
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1756939196-172.17.0.16-1597283995686:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42144,DS-d99b8fb8-2f9d-490e-9eda-d920c69d8662,DISK], DatanodeInfoWithStorage[127.0.0.1:34026,DS-f19a7109-742b-4c54-a51d-2d960c982d13,DISK], DatanodeInfoWithStorage[127.0.0.1:45679,DS-c1384dfb-075b-4db1-b851-49cd0e187820,DISK], DatanodeInfoWithStorage[127.0.0.1:40353,DS-60554060-7acd-43f6-9fcd-9e7092bd77eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36938,DS-03927544-2a85-45e3-8ec3-7766314347eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37045,DS-f5a8695c-5a66-4943-8282-d8081012380f,DISK], DatanodeInfoWithStorage[127.0.0.1:33840,DS-2c0bb51f-840c-4a0e-aaa6-1bd7d1456a70,DISK], DatanodeInfoWithStorage[127.0.0.1:38514,DS-1463e6da-fd3e-41ac-9c60-5e944195ac51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1756939196-172.17.0.16-1597283995686:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42144,DS-d99b8fb8-2f9d-490e-9eda-d920c69d8662,DISK], DatanodeInfoWithStorage[127.0.0.1:34026,DS-f19a7109-742b-4c54-a51d-2d960c982d13,DISK], DatanodeInfoWithStorage[127.0.0.1:45679,DS-c1384dfb-075b-4db1-b851-49cd0e187820,DISK], DatanodeInfoWithStorage[127.0.0.1:40353,DS-60554060-7acd-43f6-9fcd-9e7092bd77eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36938,DS-03927544-2a85-45e3-8ec3-7766314347eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37045,DS-f5a8695c-5a66-4943-8282-d8081012380f,DISK], DatanodeInfoWithStorage[127.0.0.1:33840,DS-2c0bb51f-840c-4a0e-aaa6-1bd7d1456a70,DISK], DatanodeInfoWithStorage[127.0.0.1:38514,DS-1463e6da-fd3e-41ac-9c60-5e944195ac51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 0
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1243019731-172.17.0.16-1597284102005:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41256,DS-181bef0e-b197-4f1d-b804-d69824491f29,DISK], DatanodeInfoWithStorage[127.0.0.1:38272,DS-45867552-f8f5-4759-8e50-b818d31728a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33578,DS-f26b727e-d9ae-4030-bcf5-b071a8af5331,DISK], DatanodeInfoWithStorage[127.0.0.1:34608,DS-e5c0b681-ac37-45fb-9d6a-2518f2ad4869,DISK], DatanodeInfoWithStorage[127.0.0.1:40196,DS-8902fce9-28c0-43da-aed3-b28cc173fe29,DISK], DatanodeInfoWithStorage[127.0.0.1:34587,DS-201bd2df-8742-442a-819c-fa5cdcf113ee,DISK], DatanodeInfoWithStorage[127.0.0.1:32947,DS-d01e5112-bc47-4211-b978-7275d841e25a,DISK], DatanodeInfoWithStorage[127.0.0.1:40453,DS-150057d9-bbab-44c1-97cd-d51893eeab1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1243019731-172.17.0.16-1597284102005:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41256,DS-181bef0e-b197-4f1d-b804-d69824491f29,DISK], DatanodeInfoWithStorage[127.0.0.1:38272,DS-45867552-f8f5-4759-8e50-b818d31728a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33578,DS-f26b727e-d9ae-4030-bcf5-b071a8af5331,DISK], DatanodeInfoWithStorage[127.0.0.1:34608,DS-e5c0b681-ac37-45fb-9d6a-2518f2ad4869,DISK], DatanodeInfoWithStorage[127.0.0.1:40196,DS-8902fce9-28c0-43da-aed3-b28cc173fe29,DISK], DatanodeInfoWithStorage[127.0.0.1:34587,DS-201bd2df-8742-442a-819c-fa5cdcf113ee,DISK], DatanodeInfoWithStorage[127.0.0.1:32947,DS-d01e5112-bc47-4211-b978-7275d841e25a,DISK], DatanodeInfoWithStorage[127.0.0.1:40453,DS-150057d9-bbab-44c1-97cd-d51893eeab1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 0
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-129247922-172.17.0.16-1597284323851:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44810,DS-c06f88a8-0154-4419-a2bd-8c121b159691,DISK], DatanodeInfoWithStorage[127.0.0.1:36685,DS-6df6087a-1139-43b8-8e02-21760e0a946d,DISK], DatanodeInfoWithStorage[127.0.0.1:42031,DS-d5ef31a0-20fa-490e-8dec-16646fee581c,DISK], DatanodeInfoWithStorage[127.0.0.1:36234,DS-c42fca30-fadc-48a5-b605-583413a124c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39195,DS-838d8bac-251c-4a59-8f58-123d6004e1af,DISK], DatanodeInfoWithStorage[127.0.0.1:36470,DS-cc690619-1cea-4fe8-8fd9-3264c8429927,DISK], DatanodeInfoWithStorage[127.0.0.1:39696,DS-e40aada3-b55b-47ba-851b-6f9fc7e7ead7,DISK], DatanodeInfoWithStorage[127.0.0.1:41544,DS-4c86674c-31db-4801-a0fd-5fbb2e7ebf9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-129247922-172.17.0.16-1597284323851:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44810,DS-c06f88a8-0154-4419-a2bd-8c121b159691,DISK], DatanodeInfoWithStorage[127.0.0.1:36685,DS-6df6087a-1139-43b8-8e02-21760e0a946d,DISK], DatanodeInfoWithStorage[127.0.0.1:42031,DS-d5ef31a0-20fa-490e-8dec-16646fee581c,DISK], DatanodeInfoWithStorage[127.0.0.1:36234,DS-c42fca30-fadc-48a5-b605-583413a124c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39195,DS-838d8bac-251c-4a59-8f58-123d6004e1af,DISK], DatanodeInfoWithStorage[127.0.0.1:36470,DS-cc690619-1cea-4fe8-8fd9-3264c8429927,DISK], DatanodeInfoWithStorage[127.0.0.1:39696,DS-e40aada3-b55b-47ba-851b-6f9fc7e7ead7,DISK], DatanodeInfoWithStorage[127.0.0.1:41544,DS-4c86674c-31db-4801-a0fd-5fbb2e7ebf9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 0
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-607126968-172.17.0.16-1597285012212:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41417,DS-e6bb94d1-cb98-4a4e-8042-a5b555a979b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36626,DS-5e9d4df8-adeb-4248-b4de-e6949a8456f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44308,DS-c78c7a75-0950-4392-badc-90ac6d6979b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40946,DS-3df49384-1927-42f3-9e1e-d9a5dc8ab3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39480,DS-11d56907-86ad-425d-ad24-226d0fb210eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35135,DS-a8da77ba-c71d-4221-94ec-3370784e629c,DISK], DatanodeInfoWithStorage[127.0.0.1:43393,DS-72406a8f-6642-4620-9fd3-79891fa6a9e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40892,DS-5175e46a-fb68-4418-b733-47404c0c26c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-607126968-172.17.0.16-1597285012212:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41417,DS-e6bb94d1-cb98-4a4e-8042-a5b555a979b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36626,DS-5e9d4df8-adeb-4248-b4de-e6949a8456f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44308,DS-c78c7a75-0950-4392-badc-90ac6d6979b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40946,DS-3df49384-1927-42f3-9e1e-d9a5dc8ab3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39480,DS-11d56907-86ad-425d-ad24-226d0fb210eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35135,DS-a8da77ba-c71d-4221-94ec-3370784e629c,DISK], DatanodeInfoWithStorage[127.0.0.1:43393,DS-72406a8f-6642-4620-9fd3-79891fa6a9e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40892,DS-5175e46a-fb68-4418-b733-47404c0c26c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 0
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1335755380-172.17.0.16-1597285166929:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35168,DS-dd4c65a7-d1d1-413b-914d-4ea0dc2c3d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:36248,DS-e2e53149-04fc-402d-898a-14daf79c5458,DISK], DatanodeInfoWithStorage[127.0.0.1:35167,DS-287b530e-3b18-47ac-b565-1f96fd8ec66c,DISK], DatanodeInfoWithStorage[127.0.0.1:36640,DS-158fda48-304c-4e7f-b8e1-7fba726907ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35538,DS-a8ceea39-333d-4ff4-9a76-223b6985f234,DISK], DatanodeInfoWithStorage[127.0.0.1:46146,DS-9217ac09-5120-465c-bc0d-eafce7c97400,DISK], DatanodeInfoWithStorage[127.0.0.1:35374,DS-bac32773-7acd-43d8-b973-207de57ca881,DISK], DatanodeInfoWithStorage[127.0.0.1:45668,DS-da45216b-131f-4e42-b77d-8ebe02ca0049,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1335755380-172.17.0.16-1597285166929:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35168,DS-dd4c65a7-d1d1-413b-914d-4ea0dc2c3d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:36248,DS-e2e53149-04fc-402d-898a-14daf79c5458,DISK], DatanodeInfoWithStorage[127.0.0.1:35167,DS-287b530e-3b18-47ac-b565-1f96fd8ec66c,DISK], DatanodeInfoWithStorage[127.0.0.1:36640,DS-158fda48-304c-4e7f-b8e1-7fba726907ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35538,DS-a8ceea39-333d-4ff4-9a76-223b6985f234,DISK], DatanodeInfoWithStorage[127.0.0.1:46146,DS-9217ac09-5120-465c-bc0d-eafce7c97400,DISK], DatanodeInfoWithStorage[127.0.0.1:35374,DS-bac32773-7acd-43d8-b973-207de57ca881,DISK], DatanodeInfoWithStorage[127.0.0.1:45668,DS-da45216b-131f-4e42-b77d-8ebe02ca0049,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 0
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1470947582-172.17.0.16-1597285207175:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43024,DS-b76126d5-c473-471e-9d6d-9c95fea26b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:41228,DS-91b1be7d-265d-4ea4-8655-ae331fa05f92,DISK], DatanodeInfoWithStorage[127.0.0.1:44329,DS-d1a4dec9-d8cf-40a0-b203-ba9b74e83913,DISK], DatanodeInfoWithStorage[127.0.0.1:43509,DS-19fbc89a-a5f4-4c20-80ec-c686dbaf0cef,DISK], DatanodeInfoWithStorage[127.0.0.1:33831,DS-5c83b98f-68e8-465f-bd0b-9312149363a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-f91eed8d-0a42-4947-9c96-751fff0e65b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37513,DS-e77d700b-27ad-4a0e-bb29-9d438a846ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:41232,DS-574f2584-ef9f-4c36-be3c-d3936009c001,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1470947582-172.17.0.16-1597285207175:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43024,DS-b76126d5-c473-471e-9d6d-9c95fea26b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:41228,DS-91b1be7d-265d-4ea4-8655-ae331fa05f92,DISK], DatanodeInfoWithStorage[127.0.0.1:44329,DS-d1a4dec9-d8cf-40a0-b203-ba9b74e83913,DISK], DatanodeInfoWithStorage[127.0.0.1:43509,DS-19fbc89a-a5f4-4c20-80ec-c686dbaf0cef,DISK], DatanodeInfoWithStorage[127.0.0.1:33831,DS-5c83b98f-68e8-465f-bd0b-9312149363a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-f91eed8d-0a42-4947-9c96-751fff0e65b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37513,DS-e77d700b-27ad-4a0e-bb29-9d438a846ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:41232,DS-574f2584-ef9f-4c36-be3c-d3936009c001,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 0
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1904934720-172.17.0.16-1597285563749:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38677,DS-d61e35a1-aeb7-4ac1-bb37-80ae4bde6644,DISK], DatanodeInfoWithStorage[127.0.0.1:36292,DS-3dc581a3-4c12-4ac0-81c5-899c668bc9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42978,DS-8f09697d-4171-4610-a49b-abbc17c28f83,DISK], DatanodeInfoWithStorage[127.0.0.1:40016,DS-97514259-06ea-4966-8aeb-ea18b087b69e,DISK], DatanodeInfoWithStorage[127.0.0.1:34373,DS-f8334b08-232b-4812-8d54-4d2f31f4a493,DISK], DatanodeInfoWithStorage[127.0.0.1:33267,DS-62d2ade7-a195-40e8-a2c4-589c015a95ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41541,DS-76bc1c41-3a23-4c71-8864-1d452e3fb080,DISK], DatanodeInfoWithStorage[127.0.0.1:38933,DS-b49952fc-9343-4414-abf3-0f5b55216feb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1904934720-172.17.0.16-1597285563749:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38677,DS-d61e35a1-aeb7-4ac1-bb37-80ae4bde6644,DISK], DatanodeInfoWithStorage[127.0.0.1:36292,DS-3dc581a3-4c12-4ac0-81c5-899c668bc9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42978,DS-8f09697d-4171-4610-a49b-abbc17c28f83,DISK], DatanodeInfoWithStorage[127.0.0.1:40016,DS-97514259-06ea-4966-8aeb-ea18b087b69e,DISK], DatanodeInfoWithStorage[127.0.0.1:34373,DS-f8334b08-232b-4812-8d54-4d2f31f4a493,DISK], DatanodeInfoWithStorage[127.0.0.1:33267,DS-62d2ade7-a195-40e8-a2c4-589c015a95ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41541,DS-76bc1c41-3a23-4c71-8864-1d452e3fb080,DISK], DatanodeInfoWithStorage[127.0.0.1:38933,DS-b49952fc-9343-4414-abf3-0f5b55216feb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 0
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-516805677-172.17.0.16-1597286136297:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39319,DS-e5e213ac-55b3-42c1-8b26-72db5b9dd00f,DISK], DatanodeInfoWithStorage[127.0.0.1:42220,DS-9fae5cb3-3a2a-42d7-bda7-23d0c6ba6a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:40136,DS-a5d0d938-4ac4-4a51-8706-6c54fe87a075,DISK], DatanodeInfoWithStorage[127.0.0.1:45580,DS-83d8d30f-3863-4f0f-b351-2744ce3d79da,DISK], DatanodeInfoWithStorage[127.0.0.1:42615,DS-ec15e80e-a4af-4044-b5dd-f7e8a45aa2cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46006,DS-2efdddd5-0b11-4481-b2d4-3b3bad72116b,DISK], DatanodeInfoWithStorage[127.0.0.1:34947,DS-93ca6ce6-9a4f-4730-aecc-ffd559749d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:42769,DS-7bf0d2ad-5df1-4b86-b58b-812a76ccc011,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-516805677-172.17.0.16-1597286136297:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39319,DS-e5e213ac-55b3-42c1-8b26-72db5b9dd00f,DISK], DatanodeInfoWithStorage[127.0.0.1:42220,DS-9fae5cb3-3a2a-42d7-bda7-23d0c6ba6a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:40136,DS-a5d0d938-4ac4-4a51-8706-6c54fe87a075,DISK], DatanodeInfoWithStorage[127.0.0.1:45580,DS-83d8d30f-3863-4f0f-b351-2744ce3d79da,DISK], DatanodeInfoWithStorage[127.0.0.1:42615,DS-ec15e80e-a4af-4044-b5dd-f7e8a45aa2cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46006,DS-2efdddd5-0b11-4481-b2d4-3b3bad72116b,DISK], DatanodeInfoWithStorage[127.0.0.1:34947,DS-93ca6ce6-9a4f-4730-aecc-ffd559749d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:42769,DS-7bf0d2ad-5df1-4b86-b58b-812a76ccc011,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 0
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1239603996-172.17.0.16-1597286513424:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42716,DS-554fc563-fb38-467d-9274-9548967414c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42447,DS-4dcd9f1e-fc38-4ac7-8044-cdf4513f6421,DISK], DatanodeInfoWithStorage[127.0.0.1:46062,DS-b338c8dd-dd37-457c-9246-87362083cd66,DISK], DatanodeInfoWithStorage[127.0.0.1:36264,DS-2cb5f726-75b3-4c73-86ce-2b5c4e0c2969,DISK], DatanodeInfoWithStorage[127.0.0.1:40360,DS-f371bf0a-461d-436a-8ea4-fbfb6701dc82,DISK], DatanodeInfoWithStorage[127.0.0.1:38539,DS-3de462f4-6d58-4f77-90b5-01b314d244d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33444,DS-bb9843e5-66b4-477a-a3ea-af46e7ef0ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:41922,DS-61d886c0-4b1a-4fe7-a55a-f41fd20dfe37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1239603996-172.17.0.16-1597286513424:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42716,DS-554fc563-fb38-467d-9274-9548967414c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42447,DS-4dcd9f1e-fc38-4ac7-8044-cdf4513f6421,DISK], DatanodeInfoWithStorage[127.0.0.1:46062,DS-b338c8dd-dd37-457c-9246-87362083cd66,DISK], DatanodeInfoWithStorage[127.0.0.1:36264,DS-2cb5f726-75b3-4c73-86ce-2b5c4e0c2969,DISK], DatanodeInfoWithStorage[127.0.0.1:40360,DS-f371bf0a-461d-436a-8ea4-fbfb6701dc82,DISK], DatanodeInfoWithStorage[127.0.0.1:38539,DS-3de462f4-6d58-4f77-90b5-01b314d244d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33444,DS-bb9843e5-66b4-477a-a3ea-af46e7ef0ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:41922,DS-61d886c0-4b1a-4fe7-a55a-f41fd20dfe37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 0
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-508494137-172.17.0.16-1597286549394:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46284,DS-d315ec66-9b52-4863-b910-fb3bad0f154f,DISK], DatanodeInfoWithStorage[127.0.0.1:32872,DS-2129f9a7-7581-4af2-8a4f-65020773c85e,DISK], DatanodeInfoWithStorage[127.0.0.1:44896,DS-eda6a1e4-4493-43fd-8d1c-b356d3793769,DISK], DatanodeInfoWithStorage[127.0.0.1:42299,DS-b112ab38-57d1-424d-b115-c234500d707f,DISK], DatanodeInfoWithStorage[127.0.0.1:34063,DS-93029b88-23c2-4232-9bec-6756b60c09b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41863,DS-e274955a-4ece-4fb7-ab53-28b0048c8fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:39234,DS-024363d2-b243-4f80-8c22-9f0b0bd8aea2,DISK], DatanodeInfoWithStorage[127.0.0.1:37893,DS-7448463c-10e5-43bf-ba4c-66f378c8bcdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-508494137-172.17.0.16-1597286549394:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46284,DS-d315ec66-9b52-4863-b910-fb3bad0f154f,DISK], DatanodeInfoWithStorage[127.0.0.1:32872,DS-2129f9a7-7581-4af2-8a4f-65020773c85e,DISK], DatanodeInfoWithStorage[127.0.0.1:44896,DS-eda6a1e4-4493-43fd-8d1c-b356d3793769,DISK], DatanodeInfoWithStorage[127.0.0.1:42299,DS-b112ab38-57d1-424d-b115-c234500d707f,DISK], DatanodeInfoWithStorage[127.0.0.1:34063,DS-93029b88-23c2-4232-9bec-6756b60c09b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41863,DS-e274955a-4ece-4fb7-ab53-28b0048c8fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:39234,DS-024363d2-b243-4f80-8c22-9f0b0bd8aea2,DISK], DatanodeInfoWithStorage[127.0.0.1:37893,DS-7448463c-10e5-43bf-ba4c-66f378c8bcdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 0
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1268202819-172.17.0.16-1597287454628:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36285,DS-41709ee3-f1fc-4001-8735-bd0c80946f45,DISK], DatanodeInfoWithStorage[127.0.0.1:39665,DS-ee5f69f2-9eda-44ba-86c4-1463959760b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40167,DS-7ce20589-4aba-4432-80aa-38cf8e212aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:35465,DS-21f5a9da-19cb-49b5-9098-d0d86f7a8297,DISK], DatanodeInfoWithStorage[127.0.0.1:40134,DS-0e55dabf-6475-4166-b51b-5926d7a7491a,DISK], DatanodeInfoWithStorage[127.0.0.1:41240,DS-35a587ba-c261-4873-8141-33a1c081ad58,DISK], DatanodeInfoWithStorage[127.0.0.1:36214,DS-628e0709-9ac8-420a-baaf-c5058c7b9e67,DISK], DatanodeInfoWithStorage[127.0.0.1:42259,DS-94959774-2802-4058-b6c7-ede5a23b5f55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1268202819-172.17.0.16-1597287454628:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36285,DS-41709ee3-f1fc-4001-8735-bd0c80946f45,DISK], DatanodeInfoWithStorage[127.0.0.1:39665,DS-ee5f69f2-9eda-44ba-86c4-1463959760b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40167,DS-7ce20589-4aba-4432-80aa-38cf8e212aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:35465,DS-21f5a9da-19cb-49b5-9098-d0d86f7a8297,DISK], DatanodeInfoWithStorage[127.0.0.1:40134,DS-0e55dabf-6475-4166-b51b-5926d7a7491a,DISK], DatanodeInfoWithStorage[127.0.0.1:41240,DS-35a587ba-c261-4873-8141-33a1c081ad58,DISK], DatanodeInfoWithStorage[127.0.0.1:36214,DS-628e0709-9ac8-420a-baaf-c5058c7b9e67,DISK], DatanodeInfoWithStorage[127.0.0.1:42259,DS-94959774-2802-4058-b6c7-ede5a23b5f55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 0
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1320791133-172.17.0.16-1597287704051:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46297,DS-35ac8033-4541-4f85-9a29-b2a883c98d53,DISK], DatanodeInfoWithStorage[127.0.0.1:42191,DS-2d51245b-e0d6-451e-a039-50f1ed5ee591,DISK], DatanodeInfoWithStorage[127.0.0.1:33823,DS-07d6b75f-8794-426f-954c-cc03edb577c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33235,DS-16408830-772a-4eef-8692-3919ced52aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:40367,DS-81e0a098-760c-4d12-b535-65ce0bdba36a,DISK], DatanodeInfoWithStorage[127.0.0.1:44865,DS-50c477f0-8066-43a0-9fbb-d505657297a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35077,DS-5d8cf29d-425c-4cd2-956c-bf537d4416a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41313,DS-95772861-205b-4ad6-966e-efd841f3594b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1320791133-172.17.0.16-1597287704051:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46297,DS-35ac8033-4541-4f85-9a29-b2a883c98d53,DISK], DatanodeInfoWithStorage[127.0.0.1:42191,DS-2d51245b-e0d6-451e-a039-50f1ed5ee591,DISK], DatanodeInfoWithStorage[127.0.0.1:33823,DS-07d6b75f-8794-426f-954c-cc03edb577c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33235,DS-16408830-772a-4eef-8692-3919ced52aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:40367,DS-81e0a098-760c-4d12-b535-65ce0bdba36a,DISK], DatanodeInfoWithStorage[127.0.0.1:44865,DS-50c477f0-8066-43a0-9fbb-d505657297a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35077,DS-5d8cf29d-425c-4cd2-956c-bf537d4416a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41313,DS-95772861-205b-4ad6-966e-efd841f3594b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 0
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-119852145-172.17.0.16-1597287870288:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40709,DS-09292562-62a1-4848-8812-77a0f143a27c,DISK], DatanodeInfoWithStorage[127.0.0.1:45289,DS-51b0db4f-9962-4f57-916d-61f402abfe2d,DISK], DatanodeInfoWithStorage[127.0.0.1:44648,DS-3ff576b9-43ee-4326-936e-4ce724d8996c,DISK], DatanodeInfoWithStorage[127.0.0.1:38674,DS-cfd4560d-9eab-419b-a01b-299071980077,DISK], DatanodeInfoWithStorage[127.0.0.1:46120,DS-7d464ce6-a300-49c1-adf8-00c49bf61de0,DISK], DatanodeInfoWithStorage[127.0.0.1:38354,DS-dbcd5c1a-ea91-4f42-b3e0-9f00652773e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41174,DS-61a0409d-07b5-4155-9d52-96dacd5247bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33212,DS-45a744e5-41f3-4274-8cba-915285f6156f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-119852145-172.17.0.16-1597287870288:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40709,DS-09292562-62a1-4848-8812-77a0f143a27c,DISK], DatanodeInfoWithStorage[127.0.0.1:45289,DS-51b0db4f-9962-4f57-916d-61f402abfe2d,DISK], DatanodeInfoWithStorage[127.0.0.1:44648,DS-3ff576b9-43ee-4326-936e-4ce724d8996c,DISK], DatanodeInfoWithStorage[127.0.0.1:38674,DS-cfd4560d-9eab-419b-a01b-299071980077,DISK], DatanodeInfoWithStorage[127.0.0.1:46120,DS-7d464ce6-a300-49c1-adf8-00c49bf61de0,DISK], DatanodeInfoWithStorage[127.0.0.1:38354,DS-dbcd5c1a-ea91-4f42-b3e0-9f00652773e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41174,DS-61a0409d-07b5-4155-9d52-96dacd5247bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33212,DS-45a744e5-41f3-4274-8cba-915285f6156f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 0
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1794292876-172.17.0.16-1597287976455:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44057,DS-ceb9fde9-6f1c-436a-b548-ddf09c6db392,DISK], DatanodeInfoWithStorage[127.0.0.1:35888,DS-bcf18996-d860-427b-aa80-d028e876682b,DISK], DatanodeInfoWithStorage[127.0.0.1:40444,DS-835a0832-711b-49e0-9ac7-c5c43f51bc12,DISK], DatanodeInfoWithStorage[127.0.0.1:39853,DS-9e29f022-6194-4ce5-b061-91edd08e5835,DISK], DatanodeInfoWithStorage[127.0.0.1:35570,DS-97c2d1b3-512b-41f0-a3eb-9641cb57e4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42316,DS-3618b4e7-8087-44cd-a728-dc0b9b74c459,DISK], DatanodeInfoWithStorage[127.0.0.1:42332,DS-72d8b077-8ae0-477d-bafb-de4ff1a3f3bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34931,DS-05e08560-afd2-4e4e-8468-d5ede6d86b49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1794292876-172.17.0.16-1597287976455:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44057,DS-ceb9fde9-6f1c-436a-b548-ddf09c6db392,DISK], DatanodeInfoWithStorage[127.0.0.1:35888,DS-bcf18996-d860-427b-aa80-d028e876682b,DISK], DatanodeInfoWithStorage[127.0.0.1:40444,DS-835a0832-711b-49e0-9ac7-c5c43f51bc12,DISK], DatanodeInfoWithStorage[127.0.0.1:39853,DS-9e29f022-6194-4ce5-b061-91edd08e5835,DISK], DatanodeInfoWithStorage[127.0.0.1:35570,DS-97c2d1b3-512b-41f0-a3eb-9641cb57e4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42316,DS-3618b4e7-8087-44cd-a728-dc0b9b74c459,DISK], DatanodeInfoWithStorage[127.0.0.1:42332,DS-72d8b077-8ae0-477d-bafb-de4ff1a3f3bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34931,DS-05e08560-afd2-4e4e-8468-d5ede6d86b49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 0
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1877060182-172.17.0.16-1597288190134:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37105,DS-43541006-659d-44cb-b425-17992c37060a,DISK], DatanodeInfoWithStorage[127.0.0.1:39800,DS-5d908e52-54bf-49c8-8a9b-6c45a56aba62,DISK], DatanodeInfoWithStorage[127.0.0.1:43915,DS-5a8ef681-8aec-49c7-bbee-446af47b1350,DISK], DatanodeInfoWithStorage[127.0.0.1:41818,DS-29bb2027-2eef-4973-80f3-1507c4123f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:43152,DS-c414e0f4-e941-4ba1-9898-4ceda7d2c725,DISK], DatanodeInfoWithStorage[127.0.0.1:44447,DS-e6ce70e2-f2c4-4a7c-a19d-6ce6d89220a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44872,DS-b14457b3-394d-4336-9cf0-51eeb724ffa0,DISK], DatanodeInfoWithStorage[127.0.0.1:32987,DS-5305e3d4-a6d0-4a5f-bed9-7ca938958648,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1877060182-172.17.0.16-1597288190134:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37105,DS-43541006-659d-44cb-b425-17992c37060a,DISK], DatanodeInfoWithStorage[127.0.0.1:39800,DS-5d908e52-54bf-49c8-8a9b-6c45a56aba62,DISK], DatanodeInfoWithStorage[127.0.0.1:43915,DS-5a8ef681-8aec-49c7-bbee-446af47b1350,DISK], DatanodeInfoWithStorage[127.0.0.1:41818,DS-29bb2027-2eef-4973-80f3-1507c4123f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:43152,DS-c414e0f4-e941-4ba1-9898-4ceda7d2c725,DISK], DatanodeInfoWithStorage[127.0.0.1:44447,DS-e6ce70e2-f2c4-4a7c-a19d-6ce6d89220a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44872,DS-b14457b3-394d-4336-9cf0-51eeb724ffa0,DISK], DatanodeInfoWithStorage[127.0.0.1:32987,DS-5305e3d4-a6d0-4a5f-bed9-7ca938958648,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 0
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-83540789-172.17.0.16-1597288866234:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43068,DS-347108d2-9ede-416d-9e27-7bb2310401a4,DISK], DatanodeInfoWithStorage[127.0.0.1:46040,DS-fae2137c-c24b-40ff-b533-237f3e2a5782,DISK], DatanodeInfoWithStorage[127.0.0.1:35359,DS-f238c613-5a93-4c72-8839-bba240f79893,DISK], DatanodeInfoWithStorage[127.0.0.1:42873,DS-a19e45e0-ef7a-4a99-969b-b45f9a0aa4c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41084,DS-b756e3a1-b026-4b7a-b747-3b19466b1525,DISK], DatanodeInfoWithStorage[127.0.0.1:44314,DS-2da29867-8626-4540-8a97-e51d5d313d05,DISK], DatanodeInfoWithStorage[127.0.0.1:41114,DS-f2ed391c-66ea-4bc6-824b-ee16f08c7a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43703,DS-bc564f35-7d32-42c5-a952-6915bfaeec35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-83540789-172.17.0.16-1597288866234:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43068,DS-347108d2-9ede-416d-9e27-7bb2310401a4,DISK], DatanodeInfoWithStorage[127.0.0.1:46040,DS-fae2137c-c24b-40ff-b533-237f3e2a5782,DISK], DatanodeInfoWithStorage[127.0.0.1:35359,DS-f238c613-5a93-4c72-8839-bba240f79893,DISK], DatanodeInfoWithStorage[127.0.0.1:42873,DS-a19e45e0-ef7a-4a99-969b-b45f9a0aa4c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41084,DS-b756e3a1-b026-4b7a-b747-3b19466b1525,DISK], DatanodeInfoWithStorage[127.0.0.1:44314,DS-2da29867-8626-4540-8a97-e51d5d313d05,DISK], DatanodeInfoWithStorage[127.0.0.1:41114,DS-f2ed391c-66ea-4bc6-824b-ee16f08c7a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43703,DS-bc564f35-7d32-42c5-a952-6915bfaeec35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5509
