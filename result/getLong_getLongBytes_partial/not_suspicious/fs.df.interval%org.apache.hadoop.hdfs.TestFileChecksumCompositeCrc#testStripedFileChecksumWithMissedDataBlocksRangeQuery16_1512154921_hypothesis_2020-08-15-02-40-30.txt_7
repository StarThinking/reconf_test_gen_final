reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-107457181-172.17.0.17-1597459693066:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34682,DS-1d665099-5866-4053-8268-057959691819,DISK], DatanodeInfoWithStorage[127.0.0.1:42465,DS-703e9fa0-ff48-46af-adb7-50600a2b771d,DISK], DatanodeInfoWithStorage[127.0.0.1:40857,DS-c87d4a91-fec3-42e6-811b-e9ecb91453e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39093,DS-839379fe-2b82-41c1-8f08-ca3b0792b0b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46151,DS-ad3525af-8b65-4d3c-9cfd-0f4ef7e9fc50,DISK], DatanodeInfoWithStorage[127.0.0.1:45959,DS-37993fa8-3566-416d-a6a3-bb503e7a48ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37719,DS-b74cfb82-80f0-4046-84b5-143eb38065a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33989,DS-5a8a5597-21a4-48c1-b23d-5f69b7a96bf8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-107457181-172.17.0.17-1597459693066:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34682,DS-1d665099-5866-4053-8268-057959691819,DISK], DatanodeInfoWithStorage[127.0.0.1:42465,DS-703e9fa0-ff48-46af-adb7-50600a2b771d,DISK], DatanodeInfoWithStorage[127.0.0.1:40857,DS-c87d4a91-fec3-42e6-811b-e9ecb91453e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39093,DS-839379fe-2b82-41c1-8f08-ca3b0792b0b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46151,DS-ad3525af-8b65-4d3c-9cfd-0f4ef7e9fc50,DISK], DatanodeInfoWithStorage[127.0.0.1:45959,DS-37993fa8-3566-416d-a6a3-bb503e7a48ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37719,DS-b74cfb82-80f0-4046-84b5-143eb38065a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33989,DS-5a8a5597-21a4-48c1-b23d-5f69b7a96bf8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-462337986-172.17.0.17-1597460283676:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46524,DS-15881fd3-1b95-43a7-b6af-e18975193106,DISK], DatanodeInfoWithStorage[127.0.0.1:37220,DS-2b8bcfe8-b088-4179-a9a6-5adb2fbffcd2,DISK], DatanodeInfoWithStorage[127.0.0.1:44924,DS-6e6faffd-830d-4eff-81d7-3cc537b305ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44070,DS-cd9e1328-ca26-4924-a3ed-390e5907dc2b,DISK], DatanodeInfoWithStorage[127.0.0.1:38924,DS-aee379d5-331b-4b88-9b9e-44ecf5820a29,DISK], DatanodeInfoWithStorage[127.0.0.1:43251,DS-e8601dc6-c1cd-4c80-a738-750f1c697869,DISK], DatanodeInfoWithStorage[127.0.0.1:43541,DS-6e3e801f-b614-41b0-ac7f-830d46ac5c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:42606,DS-652dbb15-aeb6-43f5-848a-86b23368564d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-462337986-172.17.0.17-1597460283676:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46524,DS-15881fd3-1b95-43a7-b6af-e18975193106,DISK], DatanodeInfoWithStorage[127.0.0.1:37220,DS-2b8bcfe8-b088-4179-a9a6-5adb2fbffcd2,DISK], DatanodeInfoWithStorage[127.0.0.1:44924,DS-6e6faffd-830d-4eff-81d7-3cc537b305ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44070,DS-cd9e1328-ca26-4924-a3ed-390e5907dc2b,DISK], DatanodeInfoWithStorage[127.0.0.1:38924,DS-aee379d5-331b-4b88-9b9e-44ecf5820a29,DISK], DatanodeInfoWithStorage[127.0.0.1:43251,DS-e8601dc6-c1cd-4c80-a738-750f1c697869,DISK], DatanodeInfoWithStorage[127.0.0.1:43541,DS-6e3e801f-b614-41b0-ac7f-830d46ac5c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:42606,DS-652dbb15-aeb6-43f5-848a-86b23368564d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1705636339-172.17.0.17-1597460464045:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46640,DS-3ee9d91b-a888-46ad-9c3e-6d8214f79c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:33277,DS-767b7ab3-ab14-4cce-b5a6-4a44d63e4b37,DISK], DatanodeInfoWithStorage[127.0.0.1:34412,DS-28f3a1cb-79b4-4597-b8f0-1d52c59df59b,DISK], DatanodeInfoWithStorage[127.0.0.1:46066,DS-4dc5454a-bdd3-4e20-a9b2-14cd32ce139a,DISK], DatanodeInfoWithStorage[127.0.0.1:37042,DS-443dba61-8f03-4189-851b-f2aad0364dda,DISK], DatanodeInfoWithStorage[127.0.0.1:33908,DS-acd22864-ad07-425d-9122-ab591fd88436,DISK], DatanodeInfoWithStorage[127.0.0.1:42172,DS-a29142b7-06bb-4834-8c89-508e0990533d,DISK], DatanodeInfoWithStorage[127.0.0.1:39226,DS-0a531506-9a2e-495f-b6e0-c4ab8063ddcd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1705636339-172.17.0.17-1597460464045:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46640,DS-3ee9d91b-a888-46ad-9c3e-6d8214f79c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:33277,DS-767b7ab3-ab14-4cce-b5a6-4a44d63e4b37,DISK], DatanodeInfoWithStorage[127.0.0.1:34412,DS-28f3a1cb-79b4-4597-b8f0-1d52c59df59b,DISK], DatanodeInfoWithStorage[127.0.0.1:46066,DS-4dc5454a-bdd3-4e20-a9b2-14cd32ce139a,DISK], DatanodeInfoWithStorage[127.0.0.1:37042,DS-443dba61-8f03-4189-851b-f2aad0364dda,DISK], DatanodeInfoWithStorage[127.0.0.1:33908,DS-acd22864-ad07-425d-9122-ab591fd88436,DISK], DatanodeInfoWithStorage[127.0.0.1:42172,DS-a29142b7-06bb-4834-8c89-508e0990533d,DISK], DatanodeInfoWithStorage[127.0.0.1:39226,DS-0a531506-9a2e-495f-b6e0-c4ab8063ddcd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1339319302-172.17.0.17-1597460540996:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41327,DS-557cd9d4-3615-49d3-93d7-9cddef36696d,DISK], DatanodeInfoWithStorage[127.0.0.1:33395,DS-dda286e9-cfce-4f44-bf2f-7a0fb5b8fd2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42390,DS-51892ac1-8844-496c-abc3-914829573086,DISK], DatanodeInfoWithStorage[127.0.0.1:40618,DS-bf26af06-9e8a-4df0-8ed6-d32d930d01a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36356,DS-6379f260-3b06-4800-beaf-2ef74f2f0274,DISK], DatanodeInfoWithStorage[127.0.0.1:33143,DS-dfa0b6e7-eed5-496d-8d7d-1a80208e4208,DISK], DatanodeInfoWithStorage[127.0.0.1:35418,DS-93eaf9dd-53ab-432e-a961-91a7c052d860,DISK], DatanodeInfoWithStorage[127.0.0.1:46754,DS-a2665da2-9e8b-4320-87ab-78c36dff7742,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1339319302-172.17.0.17-1597460540996:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41327,DS-557cd9d4-3615-49d3-93d7-9cddef36696d,DISK], DatanodeInfoWithStorage[127.0.0.1:33395,DS-dda286e9-cfce-4f44-bf2f-7a0fb5b8fd2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42390,DS-51892ac1-8844-496c-abc3-914829573086,DISK], DatanodeInfoWithStorage[127.0.0.1:40618,DS-bf26af06-9e8a-4df0-8ed6-d32d930d01a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36356,DS-6379f260-3b06-4800-beaf-2ef74f2f0274,DISK], DatanodeInfoWithStorage[127.0.0.1:33143,DS-dfa0b6e7-eed5-496d-8d7d-1a80208e4208,DISK], DatanodeInfoWithStorage[127.0.0.1:35418,DS-93eaf9dd-53ab-432e-a961-91a7c052d860,DISK], DatanodeInfoWithStorage[127.0.0.1:46754,DS-a2665da2-9e8b-4320-87ab-78c36dff7742,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-386996713-172.17.0.17-1597460680926:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33899,DS-bd87b84e-b0bd-41b3-b114-5fa91b8126eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35401,DS-0a74b247-9418-40b5-ade2-27bbfaf3d106,DISK], DatanodeInfoWithStorage[127.0.0.1:34658,DS-c73a6c6b-0303-403d-a875-f3d3ea0c14a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43716,DS-9d2f53f0-f564-43e7-b792-0270d3fe9fba,DISK], DatanodeInfoWithStorage[127.0.0.1:36568,DS-2c1ac536-9f4c-48dc-9beb-52e262440b95,DISK], DatanodeInfoWithStorage[127.0.0.1:35678,DS-032c9c5c-9130-4edf-b627-d6e4a20b0591,DISK], DatanodeInfoWithStorage[127.0.0.1:38553,DS-092dff11-94ed-471e-be12-2f074c8fc98f,DISK], DatanodeInfoWithStorage[127.0.0.1:39928,DS-450cfd2f-ad4b-4f6f-9d27-a777ea537c4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-386996713-172.17.0.17-1597460680926:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33899,DS-bd87b84e-b0bd-41b3-b114-5fa91b8126eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35401,DS-0a74b247-9418-40b5-ade2-27bbfaf3d106,DISK], DatanodeInfoWithStorage[127.0.0.1:34658,DS-c73a6c6b-0303-403d-a875-f3d3ea0c14a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43716,DS-9d2f53f0-f564-43e7-b792-0270d3fe9fba,DISK], DatanodeInfoWithStorage[127.0.0.1:36568,DS-2c1ac536-9f4c-48dc-9beb-52e262440b95,DISK], DatanodeInfoWithStorage[127.0.0.1:35678,DS-032c9c5c-9130-4edf-b627-d6e4a20b0591,DISK], DatanodeInfoWithStorage[127.0.0.1:38553,DS-092dff11-94ed-471e-be12-2f074c8fc98f,DISK], DatanodeInfoWithStorage[127.0.0.1:39928,DS-450cfd2f-ad4b-4f6f-9d27-a777ea537c4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1546581970-172.17.0.17-1597460835132:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35632,DS-51fce53c-b075-4409-aa0f-2cf174d8930d,DISK], DatanodeInfoWithStorage[127.0.0.1:45663,DS-17c641e2-7f6b-42ac-a1f9-c83464b0d542,DISK], DatanodeInfoWithStorage[127.0.0.1:37349,DS-8380dce9-603b-4f6f-99f0-1e75b54790bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38268,DS-cba1a4ed-bb57-4308-bee8-e4238ed681f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43367,DS-0fcddcd6-bfdc-4568-b9c0-f38842d6a7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44493,DS-f009d739-0936-4763-b280-706a97b8321f,DISK], DatanodeInfoWithStorage[127.0.0.1:35704,DS-e6e9653c-7592-44f1-a281-3bcf13008adf,DISK], DatanodeInfoWithStorage[127.0.0.1:41900,DS-dd72fa8d-8254-4a74-b3d0-f791069e8812,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1546581970-172.17.0.17-1597460835132:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35632,DS-51fce53c-b075-4409-aa0f-2cf174d8930d,DISK], DatanodeInfoWithStorage[127.0.0.1:45663,DS-17c641e2-7f6b-42ac-a1f9-c83464b0d542,DISK], DatanodeInfoWithStorage[127.0.0.1:37349,DS-8380dce9-603b-4f6f-99f0-1e75b54790bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38268,DS-cba1a4ed-bb57-4308-bee8-e4238ed681f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43367,DS-0fcddcd6-bfdc-4568-b9c0-f38842d6a7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44493,DS-f009d739-0936-4763-b280-706a97b8321f,DISK], DatanodeInfoWithStorage[127.0.0.1:35704,DS-e6e9653c-7592-44f1-a281-3bcf13008adf,DISK], DatanodeInfoWithStorage[127.0.0.1:41900,DS-dd72fa8d-8254-4a74-b3d0-f791069e8812,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-695408715-172.17.0.17-1597460878422:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38415,DS-096ce8c5-ab9e-4265-8278-3700576b140b,DISK], DatanodeInfoWithStorage[127.0.0.1:36612,DS-2c583ef3-8c7a-4791-9dae-73a9922b6f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:39147,DS-2ea906ba-9ee5-49b5-904a-de35abf71663,DISK], DatanodeInfoWithStorage[127.0.0.1:38986,DS-af05d21f-8e9f-4c4a-a333-dcb843d90b97,DISK], DatanodeInfoWithStorage[127.0.0.1:33004,DS-2e39ed37-7386-41af-afdf-8363fed99958,DISK], DatanodeInfoWithStorage[127.0.0.1:43800,DS-20d45cc8-f278-4d93-892b-461b67f41f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:36284,DS-11404910-12c5-45b4-bd9c-72a325ec0e30,DISK], DatanodeInfoWithStorage[127.0.0.1:44583,DS-0b8c7407-f64b-4edf-97e4-c1cdb9c27292,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-695408715-172.17.0.17-1597460878422:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38415,DS-096ce8c5-ab9e-4265-8278-3700576b140b,DISK], DatanodeInfoWithStorage[127.0.0.1:36612,DS-2c583ef3-8c7a-4791-9dae-73a9922b6f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:39147,DS-2ea906ba-9ee5-49b5-904a-de35abf71663,DISK], DatanodeInfoWithStorage[127.0.0.1:38986,DS-af05d21f-8e9f-4c4a-a333-dcb843d90b97,DISK], DatanodeInfoWithStorage[127.0.0.1:33004,DS-2e39ed37-7386-41af-afdf-8363fed99958,DISK], DatanodeInfoWithStorage[127.0.0.1:43800,DS-20d45cc8-f278-4d93-892b-461b67f41f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:36284,DS-11404910-12c5-45b4-bd9c-72a325ec0e30,DISK], DatanodeInfoWithStorage[127.0.0.1:44583,DS-0b8c7407-f64b-4edf-97e4-c1cdb9c27292,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1910134314-172.17.0.17-1597460923881:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38096,DS-8907046d-85e9-420a-adf7-25b3b2040794,DISK], DatanodeInfoWithStorage[127.0.0.1:42283,DS-6784fed4-3bf3-402e-9eed-6714d6f97e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36230,DS-ee301384-d017-4c0c-bf51-5fe3a6514f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:32924,DS-ea7879c8-f170-4ec0-9a1c-686c52c564fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45444,DS-92f32e0e-4e13-4ce0-bd56-9416a79a36f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37826,DS-6dc2b3b7-7e7c-48fe-a7c8-cdacbb29d6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43332,DS-1666d9e8-e9dc-4258-9350-d52c39892283,DISK], DatanodeInfoWithStorage[127.0.0.1:42180,DS-15450d3b-65d7-4178-9089-11f88a0418f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1910134314-172.17.0.17-1597460923881:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38096,DS-8907046d-85e9-420a-adf7-25b3b2040794,DISK], DatanodeInfoWithStorage[127.0.0.1:42283,DS-6784fed4-3bf3-402e-9eed-6714d6f97e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36230,DS-ee301384-d017-4c0c-bf51-5fe3a6514f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:32924,DS-ea7879c8-f170-4ec0-9a1c-686c52c564fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45444,DS-92f32e0e-4e13-4ce0-bd56-9416a79a36f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37826,DS-6dc2b3b7-7e7c-48fe-a7c8-cdacbb29d6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43332,DS-1666d9e8-e9dc-4258-9350-d52c39892283,DISK], DatanodeInfoWithStorage[127.0.0.1:42180,DS-15450d3b-65d7-4178-9089-11f88a0418f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1991674118-172.17.0.17-1597461879373:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39582,DS-f784820e-b558-44cb-9c52-672b540821c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41088,DS-b798e0b3-cec6-412b-be86-3dbc4766e914,DISK], DatanodeInfoWithStorage[127.0.0.1:41066,DS-8806c163-2733-4e33-8b51-37ca0b1fb213,DISK], DatanodeInfoWithStorage[127.0.0.1:37277,DS-0d9d58d2-8ee0-4e0e-b143-679998b528b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40403,DS-8028bebb-91cd-4239-8923-dc8a25b89528,DISK], DatanodeInfoWithStorage[127.0.0.1:46004,DS-4ac8942a-ce79-4752-85b5-c38e3c794901,DISK], DatanodeInfoWithStorage[127.0.0.1:44699,DS-d5550389-ddf4-4a60-948a-56645088980d,DISK], DatanodeInfoWithStorage[127.0.0.1:35776,DS-191f6b33-5966-41d5-bac3-954f8be660ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1991674118-172.17.0.17-1597461879373:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39582,DS-f784820e-b558-44cb-9c52-672b540821c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41088,DS-b798e0b3-cec6-412b-be86-3dbc4766e914,DISK], DatanodeInfoWithStorage[127.0.0.1:41066,DS-8806c163-2733-4e33-8b51-37ca0b1fb213,DISK], DatanodeInfoWithStorage[127.0.0.1:37277,DS-0d9d58d2-8ee0-4e0e-b143-679998b528b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40403,DS-8028bebb-91cd-4239-8923-dc8a25b89528,DISK], DatanodeInfoWithStorage[127.0.0.1:46004,DS-4ac8942a-ce79-4752-85b5-c38e3c794901,DISK], DatanodeInfoWithStorage[127.0.0.1:44699,DS-d5550389-ddf4-4a60-948a-56645088980d,DISK], DatanodeInfoWithStorage[127.0.0.1:35776,DS-191f6b33-5966-41d5-bac3-954f8be660ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1311132069-172.17.0.17-1597462154115:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34836,DS-df42127b-f5eb-4aa5-be3b-7dfbda9adf67,DISK], DatanodeInfoWithStorage[127.0.0.1:36173,DS-46e764b7-4022-4336-bdf3-a1119c726a17,DISK], DatanodeInfoWithStorage[127.0.0.1:46650,DS-a4722977-f29f-4487-9efe-1d691caad05d,DISK], DatanodeInfoWithStorage[127.0.0.1:46388,DS-0decfb4d-164f-4ad0-9cfc-a513b46c7923,DISK], DatanodeInfoWithStorage[127.0.0.1:46495,DS-9207f843-a26a-4d4d-9774-a92bc0ba96e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36424,DS-953ae08c-2096-4c8a-a5bb-685ac832f1b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40308,DS-f0b76578-5741-4aff-9ca6-e607f66219e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45778,DS-4f17a2a1-e0c5-45db-97e0-1e1bf5039c32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1311132069-172.17.0.17-1597462154115:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34836,DS-df42127b-f5eb-4aa5-be3b-7dfbda9adf67,DISK], DatanodeInfoWithStorage[127.0.0.1:36173,DS-46e764b7-4022-4336-bdf3-a1119c726a17,DISK], DatanodeInfoWithStorage[127.0.0.1:46650,DS-a4722977-f29f-4487-9efe-1d691caad05d,DISK], DatanodeInfoWithStorage[127.0.0.1:46388,DS-0decfb4d-164f-4ad0-9cfc-a513b46c7923,DISK], DatanodeInfoWithStorage[127.0.0.1:46495,DS-9207f843-a26a-4d4d-9774-a92bc0ba96e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36424,DS-953ae08c-2096-4c8a-a5bb-685ac832f1b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40308,DS-f0b76578-5741-4aff-9ca6-e607f66219e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45778,DS-4f17a2a1-e0c5-45db-97e0-1e1bf5039c32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2138097182-172.17.0.17-1597462242536:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34469,DS-5f7aa7ce-cfac-444d-a62c-d75a34e8d684,DISK], DatanodeInfoWithStorage[127.0.0.1:37538,DS-f62fcea5-d17f-413f-8f41-5b443558b2d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36003,DS-070f2d85-622b-4dbf-8d6e-ee14806b94eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43726,DS-10d636c1-1660-4971-a348-a4f76920c04e,DISK], DatanodeInfoWithStorage[127.0.0.1:41960,DS-cf090548-2c2f-4acf-8936-0361dae0225f,DISK], DatanodeInfoWithStorage[127.0.0.1:37989,DS-43e7b07d-a636-461d-8368-f4551f82ea50,DISK], DatanodeInfoWithStorage[127.0.0.1:33686,DS-1d250291-56fa-4e02-9b1e-77aea4cf2bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:44737,DS-fe1b378c-4a16-49b8-8c55-ecf95141a2a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2138097182-172.17.0.17-1597462242536:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34469,DS-5f7aa7ce-cfac-444d-a62c-d75a34e8d684,DISK], DatanodeInfoWithStorage[127.0.0.1:37538,DS-f62fcea5-d17f-413f-8f41-5b443558b2d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36003,DS-070f2d85-622b-4dbf-8d6e-ee14806b94eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43726,DS-10d636c1-1660-4971-a348-a4f76920c04e,DISK], DatanodeInfoWithStorage[127.0.0.1:41960,DS-cf090548-2c2f-4acf-8936-0361dae0225f,DISK], DatanodeInfoWithStorage[127.0.0.1:37989,DS-43e7b07d-a636-461d-8368-f4551f82ea50,DISK], DatanodeInfoWithStorage[127.0.0.1:33686,DS-1d250291-56fa-4e02-9b1e-77aea4cf2bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:44737,DS-fe1b378c-4a16-49b8-8c55-ecf95141a2a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1305296145-172.17.0.17-1597462529037:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36018,DS-ff241264-51fc-43ce-b9f3-4b1414990d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:38729,DS-8b116464-28ff-4b6e-a028-03bf852e72d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34169,DS-5e387bef-68d4-4127-8fb2-28bf7fabfe41,DISK], DatanodeInfoWithStorage[127.0.0.1:37368,DS-80f28e92-106e-4538-8c57-edfd29e7d81b,DISK], DatanodeInfoWithStorage[127.0.0.1:40576,DS-f000451c-868c-4308-b6bd-56660b4d58a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37103,DS-c5903f6c-53ec-499f-b3d2-0fc37a2a1d42,DISK], DatanodeInfoWithStorage[127.0.0.1:34670,DS-c2bdab41-f7e7-4e35-8b3c-1a1bf49fb590,DISK], DatanodeInfoWithStorage[127.0.0.1:35120,DS-f8fdf839-12fd-416c-836a-0deef4ba9b63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1305296145-172.17.0.17-1597462529037:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36018,DS-ff241264-51fc-43ce-b9f3-4b1414990d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:38729,DS-8b116464-28ff-4b6e-a028-03bf852e72d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34169,DS-5e387bef-68d4-4127-8fb2-28bf7fabfe41,DISK], DatanodeInfoWithStorage[127.0.0.1:37368,DS-80f28e92-106e-4538-8c57-edfd29e7d81b,DISK], DatanodeInfoWithStorage[127.0.0.1:40576,DS-f000451c-868c-4308-b6bd-56660b4d58a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37103,DS-c5903f6c-53ec-499f-b3d2-0fc37a2a1d42,DISK], DatanodeInfoWithStorage[127.0.0.1:34670,DS-c2bdab41-f7e7-4e35-8b3c-1a1bf49fb590,DISK], DatanodeInfoWithStorage[127.0.0.1:35120,DS-f8fdf839-12fd-416c-836a-0deef4ba9b63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1085320189-172.17.0.17-1597463774403:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43746,DS-e68c8812-12d8-49fb-a575-353cc2117574,DISK], DatanodeInfoWithStorage[127.0.0.1:40987,DS-79cf8a8e-41db-4c03-821e-530eeb31c576,DISK], DatanodeInfoWithStorage[127.0.0.1:40759,DS-f2caf838-b548-4d62-9fa1-cb9fa5206e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44646,DS-0dd4e67c-c5c3-4b32-aeb7-b0101b13ff19,DISK], DatanodeInfoWithStorage[127.0.0.1:44005,DS-bd3666f7-3a94-4e20-9175-3e795ef076fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34096,DS-c3e6bea0-c45d-4f4d-a4a8-b0d9cc2a508f,DISK], DatanodeInfoWithStorage[127.0.0.1:36929,DS-64d760b6-5e0d-457a-ac9b-60078ee6cd95,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-0fd8cddc-54dc-456c-92fe-694528c084d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1085320189-172.17.0.17-1597463774403:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43746,DS-e68c8812-12d8-49fb-a575-353cc2117574,DISK], DatanodeInfoWithStorage[127.0.0.1:40987,DS-79cf8a8e-41db-4c03-821e-530eeb31c576,DISK], DatanodeInfoWithStorage[127.0.0.1:40759,DS-f2caf838-b548-4d62-9fa1-cb9fa5206e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44646,DS-0dd4e67c-c5c3-4b32-aeb7-b0101b13ff19,DISK], DatanodeInfoWithStorage[127.0.0.1:44005,DS-bd3666f7-3a94-4e20-9175-3e795ef076fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34096,DS-c3e6bea0-c45d-4f4d-a4a8-b0d9cc2a508f,DISK], DatanodeInfoWithStorage[127.0.0.1:36929,DS-64d760b6-5e0d-457a-ac9b-60078ee6cd95,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-0fd8cddc-54dc-456c-92fe-694528c084d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1989861237-172.17.0.17-1597464045401:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34012,DS-4be2535f-e351-4ffa-83e0-eddc0b545019,DISK], DatanodeInfoWithStorage[127.0.0.1:34349,DS-14270e4e-84e8-437c-ac48-97a82c6a8d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39608,DS-17675393-77d7-4f89-82f8-74dc6a2449d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40023,DS-d4a3ed16-ddd9-4f26-aede-12a30c43b16e,DISK], DatanodeInfoWithStorage[127.0.0.1:46185,DS-63127798-2582-405d-99cc-18d55179a844,DISK], DatanodeInfoWithStorage[127.0.0.1:45989,DS-b904d693-ef75-4ed8-8d7f-fa9b40e38afd,DISK], DatanodeInfoWithStorage[127.0.0.1:42370,DS-6358140e-e15f-474e-aa03-bc56a175afeb,DISK], DatanodeInfoWithStorage[127.0.0.1:40052,DS-e0a0b641-40a6-47e2-bb74-e3c9d8b9228e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1989861237-172.17.0.17-1597464045401:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34012,DS-4be2535f-e351-4ffa-83e0-eddc0b545019,DISK], DatanodeInfoWithStorage[127.0.0.1:34349,DS-14270e4e-84e8-437c-ac48-97a82c6a8d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39608,DS-17675393-77d7-4f89-82f8-74dc6a2449d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40023,DS-d4a3ed16-ddd9-4f26-aede-12a30c43b16e,DISK], DatanodeInfoWithStorage[127.0.0.1:46185,DS-63127798-2582-405d-99cc-18d55179a844,DISK], DatanodeInfoWithStorage[127.0.0.1:45989,DS-b904d693-ef75-4ed8-8d7f-fa9b40e38afd,DISK], DatanodeInfoWithStorage[127.0.0.1:42370,DS-6358140e-e15f-474e-aa03-bc56a175afeb,DISK], DatanodeInfoWithStorage[127.0.0.1:40052,DS-e0a0b641-40a6-47e2-bb74-e3c9d8b9228e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-218249779-172.17.0.17-1597464088134:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40824,DS-425b7e2a-eb70-4c0d-8fd8-4a81c054badc,DISK], DatanodeInfoWithStorage[127.0.0.1:46004,DS-523f70e4-9cef-4c32-881d-3ca2aa0aaa8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36847,DS-0db069ca-6552-4a22-8a94-4e529ef72c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:46041,DS-b7cc4dc9-98ef-44eb-b703-2f765da1ac18,DISK], DatanodeInfoWithStorage[127.0.0.1:41878,DS-979cbafe-9942-4669-85b7-5ef49e9199ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43611,DS-35520d7e-cdb7-4d6e-b5d2-cb35b4cedfa8,DISK], DatanodeInfoWithStorage[127.0.0.1:41829,DS-43f22e98-9160-4d53-8bce-217505831592,DISK], DatanodeInfoWithStorage[127.0.0.1:37580,DS-7a2ae679-5973-4c3b-a789-cf2f6595d500,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-218249779-172.17.0.17-1597464088134:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40824,DS-425b7e2a-eb70-4c0d-8fd8-4a81c054badc,DISK], DatanodeInfoWithStorage[127.0.0.1:46004,DS-523f70e4-9cef-4c32-881d-3ca2aa0aaa8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36847,DS-0db069ca-6552-4a22-8a94-4e529ef72c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:46041,DS-b7cc4dc9-98ef-44eb-b703-2f765da1ac18,DISK], DatanodeInfoWithStorage[127.0.0.1:41878,DS-979cbafe-9942-4669-85b7-5ef49e9199ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43611,DS-35520d7e-cdb7-4d6e-b5d2-cb35b4cedfa8,DISK], DatanodeInfoWithStorage[127.0.0.1:41829,DS-43f22e98-9160-4d53-8bce-217505831592,DISK], DatanodeInfoWithStorage[127.0.0.1:37580,DS-7a2ae679-5973-4c3b-a789-cf2f6595d500,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1425309698-172.17.0.17-1597464520053:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40367,DS-ffd10f68-9630-4a60-8fea-5fad7d7ef4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39959,DS-43315fdd-8af0-4b74-bf65-5770a0c96150,DISK], DatanodeInfoWithStorage[127.0.0.1:32922,DS-e02cce34-4819-4a58-8c61-13bfb8f43044,DISK], DatanodeInfoWithStorage[127.0.0.1:39004,DS-772260c8-9cfd-4a6d-af81-87b240b6302c,DISK], DatanodeInfoWithStorage[127.0.0.1:39902,DS-c6a3a36e-01e3-4512-ae72-e0a3df23bb18,DISK], DatanodeInfoWithStorage[127.0.0.1:38623,DS-dd546664-5b01-45c5-a719-004570de1901,DISK], DatanodeInfoWithStorage[127.0.0.1:36065,DS-856a8b60-382f-4810-9d93-f6f5dee1a868,DISK], DatanodeInfoWithStorage[127.0.0.1:39939,DS-8f9ad009-8a08-47c8-90a9-1f54eb01cb23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1425309698-172.17.0.17-1597464520053:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40367,DS-ffd10f68-9630-4a60-8fea-5fad7d7ef4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39959,DS-43315fdd-8af0-4b74-bf65-5770a0c96150,DISK], DatanodeInfoWithStorage[127.0.0.1:32922,DS-e02cce34-4819-4a58-8c61-13bfb8f43044,DISK], DatanodeInfoWithStorage[127.0.0.1:39004,DS-772260c8-9cfd-4a6d-af81-87b240b6302c,DISK], DatanodeInfoWithStorage[127.0.0.1:39902,DS-c6a3a36e-01e3-4512-ae72-e0a3df23bb18,DISK], DatanodeInfoWithStorage[127.0.0.1:38623,DS-dd546664-5b01-45c5-a719-004570de1901,DISK], DatanodeInfoWithStorage[127.0.0.1:36065,DS-856a8b60-382f-4810-9d93-f6f5dee1a868,DISK], DatanodeInfoWithStorage[127.0.0.1:39939,DS-8f9ad009-8a08-47c8-90a9-1f54eb01cb23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-906574965-172.17.0.17-1597465087694:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38105,DS-f6cf429b-b9b9-4291-b6df-5614f8f16390,DISK], DatanodeInfoWithStorage[127.0.0.1:45864,DS-b72c9676-8f06-44df-89ec-a95c28803ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:40538,DS-f52aac7b-4446-4e0e-aa53-0381d6935499,DISK], DatanodeInfoWithStorage[127.0.0.1:40678,DS-39debdb1-aefb-40a0-8298-4eef2d1462a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37676,DS-37de5f94-bb25-4e85-a09e-c67bdde5b372,DISK], DatanodeInfoWithStorage[127.0.0.1:35298,DS-21f06cec-5d0e-4e4e-a416-c53ae0f8f8f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40593,DS-9c56b6bd-e827-4089-a21e-5234b71a0f12,DISK], DatanodeInfoWithStorage[127.0.0.1:39159,DS-32589453-2a3b-4825-b322-504a53efebff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-906574965-172.17.0.17-1597465087694:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38105,DS-f6cf429b-b9b9-4291-b6df-5614f8f16390,DISK], DatanodeInfoWithStorage[127.0.0.1:45864,DS-b72c9676-8f06-44df-89ec-a95c28803ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:40538,DS-f52aac7b-4446-4e0e-aa53-0381d6935499,DISK], DatanodeInfoWithStorage[127.0.0.1:40678,DS-39debdb1-aefb-40a0-8298-4eef2d1462a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37676,DS-37de5f94-bb25-4e85-a09e-c67bdde5b372,DISK], DatanodeInfoWithStorage[127.0.0.1:35298,DS-21f06cec-5d0e-4e4e-a416-c53ae0f8f8f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40593,DS-9c56b6bd-e827-4089-a21e-5234b71a0f12,DISK], DatanodeInfoWithStorage[127.0.0.1:39159,DS-32589453-2a3b-4825-b322-504a53efebff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-352030837-172.17.0.17-1597465164380:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33067,DS-6117d477-950b-42c9-b1d2-854390461bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:44447,DS-5984eb15-93f4-4a2f-bb7d-d05bf8105bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:35396,DS-de94a152-10aa-4630-8530-121d71c8a616,DISK], DatanodeInfoWithStorage[127.0.0.1:36209,DS-31fae197-bd53-4559-b92c-d13d0fbbea9b,DISK], DatanodeInfoWithStorage[127.0.0.1:39960,DS-6e4e6468-8614-4e0b-972a-8a987308c0bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38434,DS-d33020a9-027a-4370-af7d-0ecbadea0f78,DISK], DatanodeInfoWithStorage[127.0.0.1:37474,DS-7062bbf6-38cd-4657-b1bf-06d3a07f183a,DISK], DatanodeInfoWithStorage[127.0.0.1:45619,DS-7e842d51-77ff-430a-8f72-8f82092e027e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-352030837-172.17.0.17-1597465164380:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33067,DS-6117d477-950b-42c9-b1d2-854390461bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:44447,DS-5984eb15-93f4-4a2f-bb7d-d05bf8105bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:35396,DS-de94a152-10aa-4630-8530-121d71c8a616,DISK], DatanodeInfoWithStorage[127.0.0.1:36209,DS-31fae197-bd53-4559-b92c-d13d0fbbea9b,DISK], DatanodeInfoWithStorage[127.0.0.1:39960,DS-6e4e6468-8614-4e0b-972a-8a987308c0bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38434,DS-d33020a9-027a-4370-af7d-0ecbadea0f78,DISK], DatanodeInfoWithStorage[127.0.0.1:37474,DS-7062bbf6-38cd-4657-b1bf-06d3a07f183a,DISK], DatanodeInfoWithStorage[127.0.0.1:45619,DS-7e842d51-77ff-430a-8f72-8f82092e027e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 6630
