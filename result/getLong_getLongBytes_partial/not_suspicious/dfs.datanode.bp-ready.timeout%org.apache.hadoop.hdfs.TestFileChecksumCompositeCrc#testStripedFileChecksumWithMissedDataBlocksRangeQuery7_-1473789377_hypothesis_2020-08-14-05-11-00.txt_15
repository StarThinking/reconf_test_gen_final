reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-699537494-172.17.0.21-1597382016222:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45437,DS-75423f36-a7b8-4c20-a8f0-94e88d0af5e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41827,DS-fa2c065b-a89b-4780-b872-1aa4d5c23dea,DISK], DatanodeInfoWithStorage[127.0.0.1:46648,DS-261a0a4a-e63c-4862-9721-9c0902f0c01f,DISK], DatanodeInfoWithStorage[127.0.0.1:45890,DS-f26711d8-94cd-481d-bdc2-7b149e22e618,DISK], DatanodeInfoWithStorage[127.0.0.1:38580,DS-0d77c6b0-7526-4c9f-8f8b-28cfbf777b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:45095,DS-e0f529d0-d07e-4f03-ade0-cbd2f82d07d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45499,DS-dd33bb01-197a-4f0a-a993-536d1e72288e,DISK], DatanodeInfoWithStorage[127.0.0.1:35170,DS-0dd9fc95-e034-46b6-b4b8-92a4a0ee3809,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-699537494-172.17.0.21-1597382016222:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45437,DS-75423f36-a7b8-4c20-a8f0-94e88d0af5e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41827,DS-fa2c065b-a89b-4780-b872-1aa4d5c23dea,DISK], DatanodeInfoWithStorage[127.0.0.1:46648,DS-261a0a4a-e63c-4862-9721-9c0902f0c01f,DISK], DatanodeInfoWithStorage[127.0.0.1:45890,DS-f26711d8-94cd-481d-bdc2-7b149e22e618,DISK], DatanodeInfoWithStorage[127.0.0.1:38580,DS-0d77c6b0-7526-4c9f-8f8b-28cfbf777b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:45095,DS-e0f529d0-d07e-4f03-ade0-cbd2f82d07d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45499,DS-dd33bb01-197a-4f0a-a993-536d1e72288e,DISK], DatanodeInfoWithStorage[127.0.0.1:35170,DS-0dd9fc95-e034-46b6-b4b8-92a4a0ee3809,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2140379630-172.17.0.21-1597382082987:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42124,DS-49a9519c-24f4-42bf-bebe-229db6bcc3f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40093,DS-c4cdba5b-314b-4e8c-a27d-556ac8b53293,DISK], DatanodeInfoWithStorage[127.0.0.1:41688,DS-2dbe8e40-efc0-4d9a-b404-dfc77dc73ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:39999,DS-444a5f30-d305-4466-a675-f8970bb7c519,DISK], DatanodeInfoWithStorage[127.0.0.1:41943,DS-4c4b3b50-8abc-4922-8d7d-578a9fd57198,DISK], DatanodeInfoWithStorage[127.0.0.1:43393,DS-80bcfcff-09ca-4b35-aa52-1b0fbb1ddf69,DISK], DatanodeInfoWithStorage[127.0.0.1:40528,DS-95f382dd-62f7-4c3f-a63d-cc4f7e1005f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39729,DS-6ce22fbe-9067-4137-8561-377c4fcf1da3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2140379630-172.17.0.21-1597382082987:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42124,DS-49a9519c-24f4-42bf-bebe-229db6bcc3f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40093,DS-c4cdba5b-314b-4e8c-a27d-556ac8b53293,DISK], DatanodeInfoWithStorage[127.0.0.1:41688,DS-2dbe8e40-efc0-4d9a-b404-dfc77dc73ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:39999,DS-444a5f30-d305-4466-a675-f8970bb7c519,DISK], DatanodeInfoWithStorage[127.0.0.1:41943,DS-4c4b3b50-8abc-4922-8d7d-578a9fd57198,DISK], DatanodeInfoWithStorage[127.0.0.1:43393,DS-80bcfcff-09ca-4b35-aa52-1b0fbb1ddf69,DISK], DatanodeInfoWithStorage[127.0.0.1:40528,DS-95f382dd-62f7-4c3f-a63d-cc4f7e1005f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39729,DS-6ce22fbe-9067-4137-8561-377c4fcf1da3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-406186591-172.17.0.21-1597382376928:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38569,DS-93dc5140-7a48-4b6a-b1a8-a371bf199893,DISK], DatanodeInfoWithStorage[127.0.0.1:37853,DS-474a6f8e-04fe-49b3-9cbc-b05af54bb11a,DISK], DatanodeInfoWithStorage[127.0.0.1:35558,DS-3d49eb6c-675e-4c55-8d54-60ee0f189287,DISK], DatanodeInfoWithStorage[127.0.0.1:40756,DS-faeec51d-eeb9-4d02-982c-2863643a7615,DISK], DatanodeInfoWithStorage[127.0.0.1:37767,DS-c633bd24-a57b-45c6-a5f9-da8a6ff7e7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35339,DS-0298b5da-80a0-4be5-9031-6b41626664dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41937,DS-c6e430e1-b5fc-4278-9b85-f1fa5a0e813e,DISK], DatanodeInfoWithStorage[127.0.0.1:36691,DS-c4ed3ace-5680-4ae1-8df2-e378f4c6f652,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-406186591-172.17.0.21-1597382376928:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38569,DS-93dc5140-7a48-4b6a-b1a8-a371bf199893,DISK], DatanodeInfoWithStorage[127.0.0.1:37853,DS-474a6f8e-04fe-49b3-9cbc-b05af54bb11a,DISK], DatanodeInfoWithStorage[127.0.0.1:35558,DS-3d49eb6c-675e-4c55-8d54-60ee0f189287,DISK], DatanodeInfoWithStorage[127.0.0.1:40756,DS-faeec51d-eeb9-4d02-982c-2863643a7615,DISK], DatanodeInfoWithStorage[127.0.0.1:37767,DS-c633bd24-a57b-45c6-a5f9-da8a6ff7e7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35339,DS-0298b5da-80a0-4be5-9031-6b41626664dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41937,DS-c6e430e1-b5fc-4278-9b85-f1fa5a0e813e,DISK], DatanodeInfoWithStorage[127.0.0.1:36691,DS-c4ed3ace-5680-4ae1-8df2-e378f4c6f652,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1370533265-172.17.0.21-1597382416387:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44159,DS-143242d8-17f9-4c86-b6f2-73274abae483,DISK], DatanodeInfoWithStorage[127.0.0.1:34459,DS-1eadfb99-92e4-41c2-8b02-63d2468b2b16,DISK], DatanodeInfoWithStorage[127.0.0.1:40393,DS-f9f1b074-7f2c-4ddf-b022-f4432b738ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:34278,DS-12e3dec9-14f4-4961-8916-fd552392a146,DISK], DatanodeInfoWithStorage[127.0.0.1:34265,DS-81e23a2a-00c3-4fe5-bfa3-707e9f0a2e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34933,DS-4e699ba5-2c6b-464f-8016-05976c69dae0,DISK], DatanodeInfoWithStorage[127.0.0.1:41119,DS-87f17310-427d-4339-a98f-919bcbe27ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:40586,DS-7fcdba32-2bf3-42a5-b768-53e06fcd0700,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1370533265-172.17.0.21-1597382416387:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44159,DS-143242d8-17f9-4c86-b6f2-73274abae483,DISK], DatanodeInfoWithStorage[127.0.0.1:34459,DS-1eadfb99-92e4-41c2-8b02-63d2468b2b16,DISK], DatanodeInfoWithStorage[127.0.0.1:40393,DS-f9f1b074-7f2c-4ddf-b022-f4432b738ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:34278,DS-12e3dec9-14f4-4961-8916-fd552392a146,DISK], DatanodeInfoWithStorage[127.0.0.1:34265,DS-81e23a2a-00c3-4fe5-bfa3-707e9f0a2e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34933,DS-4e699ba5-2c6b-464f-8016-05976c69dae0,DISK], DatanodeInfoWithStorage[127.0.0.1:41119,DS-87f17310-427d-4339-a98f-919bcbe27ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:40586,DS-7fcdba32-2bf3-42a5-b768-53e06fcd0700,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1059780222-172.17.0.21-1597382454987:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36076,DS-d392135e-5c08-4eb9-8774-071f6c11fa5f,DISK], DatanodeInfoWithStorage[127.0.0.1:34593,DS-4b0d5d7c-0521-4d79-b941-d7159aba88fc,DISK], DatanodeInfoWithStorage[127.0.0.1:32787,DS-67277a51-0e79-4f71-8364-17699cfd02cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45477,DS-de16c0cd-f43c-41c8-b385-d26ffee395f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44474,DS-f422e54b-112d-49f1-8119-de7047e5f7d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34966,DS-3716f48f-a5a5-43b9-b4fc-faae79302668,DISK], DatanodeInfoWithStorage[127.0.0.1:43168,DS-09a18661-db90-42c4-978b-506767d0a69c,DISK], DatanodeInfoWithStorage[127.0.0.1:36994,DS-4dd9618d-0453-4c13-b860-7079e88afd30,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1059780222-172.17.0.21-1597382454987:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36076,DS-d392135e-5c08-4eb9-8774-071f6c11fa5f,DISK], DatanodeInfoWithStorage[127.0.0.1:34593,DS-4b0d5d7c-0521-4d79-b941-d7159aba88fc,DISK], DatanodeInfoWithStorage[127.0.0.1:32787,DS-67277a51-0e79-4f71-8364-17699cfd02cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45477,DS-de16c0cd-f43c-41c8-b385-d26ffee395f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44474,DS-f422e54b-112d-49f1-8119-de7047e5f7d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34966,DS-3716f48f-a5a5-43b9-b4fc-faae79302668,DISK], DatanodeInfoWithStorage[127.0.0.1:43168,DS-09a18661-db90-42c4-978b-506767d0a69c,DISK], DatanodeInfoWithStorage[127.0.0.1:36994,DS-4dd9618d-0453-4c13-b860-7079e88afd30,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-245239888-172.17.0.21-1597382560712:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39772,DS-f8af8cc5-ae9e-4081-8a93-1971434fe089,DISK], DatanodeInfoWithStorage[127.0.0.1:45107,DS-cb3ab765-cd20-4b41-9885-35ddf41fe188,DISK], DatanodeInfoWithStorage[127.0.0.1:38569,DS-f4d8a55e-ce0a-45f0-91f3-f2627616043c,DISK], DatanodeInfoWithStorage[127.0.0.1:33946,DS-5eae4e24-46d1-4062-9707-e2a229d61c17,DISK], DatanodeInfoWithStorage[127.0.0.1:43201,DS-a693c17a-3826-4f86-b6dc-4fef919bf95c,DISK], DatanodeInfoWithStorage[127.0.0.1:43635,DS-d4ab3d8b-67db-437c-91f6-b1e934a911cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43888,DS-aa8fd820-a196-46af-87b0-0386cc97be28,DISK], DatanodeInfoWithStorage[127.0.0.1:39917,DS-a42a2958-3f0b-4c7b-b9fc-7aad3c34954a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-245239888-172.17.0.21-1597382560712:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39772,DS-f8af8cc5-ae9e-4081-8a93-1971434fe089,DISK], DatanodeInfoWithStorage[127.0.0.1:45107,DS-cb3ab765-cd20-4b41-9885-35ddf41fe188,DISK], DatanodeInfoWithStorage[127.0.0.1:38569,DS-f4d8a55e-ce0a-45f0-91f3-f2627616043c,DISK], DatanodeInfoWithStorage[127.0.0.1:33946,DS-5eae4e24-46d1-4062-9707-e2a229d61c17,DISK], DatanodeInfoWithStorage[127.0.0.1:43201,DS-a693c17a-3826-4f86-b6dc-4fef919bf95c,DISK], DatanodeInfoWithStorage[127.0.0.1:43635,DS-d4ab3d8b-67db-437c-91f6-b1e934a911cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43888,DS-aa8fd820-a196-46af-87b0-0386cc97be28,DISK], DatanodeInfoWithStorage[127.0.0.1:39917,DS-a42a2958-3f0b-4c7b-b9fc-7aad3c34954a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-611963642-172.17.0.21-1597382592494:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38989,DS-c1387b69-bf6f-4a89-803b-0f4aa58b2d92,DISK], DatanodeInfoWithStorage[127.0.0.1:42345,DS-4a023624-2d38-4dfb-b758-d04e3c92c1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36054,DS-11c47d60-6a0f-4fa5-b8b9-f23392309c65,DISK], DatanodeInfoWithStorage[127.0.0.1:33510,DS-0504c21d-4e9c-49b5-af46-168f33ddb6d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40840,DS-d5379053-8e58-4d7b-8a99-4a89c930d244,DISK], DatanodeInfoWithStorage[127.0.0.1:42727,DS-014b6edb-89a5-4dd6-be31-f575d2a1c83f,DISK], DatanodeInfoWithStorage[127.0.0.1:41972,DS-2f787d04-6fd4-4d14-9583-5e05ac00ae79,DISK], DatanodeInfoWithStorage[127.0.0.1:37100,DS-fbe960c9-d333-4b5e-80a4-8a2653b14990,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-611963642-172.17.0.21-1597382592494:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38989,DS-c1387b69-bf6f-4a89-803b-0f4aa58b2d92,DISK], DatanodeInfoWithStorage[127.0.0.1:42345,DS-4a023624-2d38-4dfb-b758-d04e3c92c1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36054,DS-11c47d60-6a0f-4fa5-b8b9-f23392309c65,DISK], DatanodeInfoWithStorage[127.0.0.1:33510,DS-0504c21d-4e9c-49b5-af46-168f33ddb6d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40840,DS-d5379053-8e58-4d7b-8a99-4a89c930d244,DISK], DatanodeInfoWithStorage[127.0.0.1:42727,DS-014b6edb-89a5-4dd6-be31-f575d2a1c83f,DISK], DatanodeInfoWithStorage[127.0.0.1:41972,DS-2f787d04-6fd4-4d14-9583-5e05ac00ae79,DISK], DatanodeInfoWithStorage[127.0.0.1:37100,DS-fbe960c9-d333-4b5e-80a4-8a2653b14990,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-942377676-172.17.0.21-1597382702707:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40196,DS-8a0559ea-c903-4ddc-b36e-218f10606fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-aee875ae-8d37-4ec5-a1f6-0fe414bd7c21,DISK], DatanodeInfoWithStorage[127.0.0.1:42007,DS-c0628b20-2e43-4a55-a2e1-4e4172b27743,DISK], DatanodeInfoWithStorage[127.0.0.1:43067,DS-7e5a5e69-59d2-49e2-a87d-ac2746a6aa10,DISK], DatanodeInfoWithStorage[127.0.0.1:37875,DS-fbbaa71f-1658-448e-a9b1-6c7c91544239,DISK], DatanodeInfoWithStorage[127.0.0.1:33903,DS-bad4d8ec-5f0c-4ac7-b59d-ce34040f87c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34839,DS-d20cabc5-2711-4c9c-ac65-32287d07b6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37701,DS-f1b4dbeb-462a-46e0-874c-3112999073b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-942377676-172.17.0.21-1597382702707:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40196,DS-8a0559ea-c903-4ddc-b36e-218f10606fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-aee875ae-8d37-4ec5-a1f6-0fe414bd7c21,DISK], DatanodeInfoWithStorage[127.0.0.1:42007,DS-c0628b20-2e43-4a55-a2e1-4e4172b27743,DISK], DatanodeInfoWithStorage[127.0.0.1:43067,DS-7e5a5e69-59d2-49e2-a87d-ac2746a6aa10,DISK], DatanodeInfoWithStorage[127.0.0.1:37875,DS-fbbaa71f-1658-448e-a9b1-6c7c91544239,DISK], DatanodeInfoWithStorage[127.0.0.1:33903,DS-bad4d8ec-5f0c-4ac7-b59d-ce34040f87c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34839,DS-d20cabc5-2711-4c9c-ac65-32287d07b6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37701,DS-f1b4dbeb-462a-46e0-874c-3112999073b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-204796362-172.17.0.21-1597383046777:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45609,DS-b4bf6d59-23d5-4edf-9d2e-34e1887dfd80,DISK], DatanodeInfoWithStorage[127.0.0.1:46595,DS-4677cdd6-48c4-4f9f-8226-4e9ed42627a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36824,DS-6a8d5f73-8dd0-4af9-94e5-01b6e634fb34,DISK], DatanodeInfoWithStorage[127.0.0.1:38631,DS-2add2377-f970-4665-aec4-ccf3ce23e136,DISK], DatanodeInfoWithStorage[127.0.0.1:38419,DS-102ee115-1b29-4f29-a800-bdcef8888d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38698,DS-84016c62-d31f-4156-9da0-1e8629939067,DISK], DatanodeInfoWithStorage[127.0.0.1:38115,DS-08bb2440-890a-43d6-ab97-341ef18c2d21,DISK], DatanodeInfoWithStorage[127.0.0.1:38645,DS-e15dc731-f07e-481e-bb2c-8928c25ee893,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-204796362-172.17.0.21-1597383046777:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45609,DS-b4bf6d59-23d5-4edf-9d2e-34e1887dfd80,DISK], DatanodeInfoWithStorage[127.0.0.1:46595,DS-4677cdd6-48c4-4f9f-8226-4e9ed42627a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36824,DS-6a8d5f73-8dd0-4af9-94e5-01b6e634fb34,DISK], DatanodeInfoWithStorage[127.0.0.1:38631,DS-2add2377-f970-4665-aec4-ccf3ce23e136,DISK], DatanodeInfoWithStorage[127.0.0.1:38419,DS-102ee115-1b29-4f29-a800-bdcef8888d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38698,DS-84016c62-d31f-4156-9da0-1e8629939067,DISK], DatanodeInfoWithStorage[127.0.0.1:38115,DS-08bb2440-890a-43d6-ab97-341ef18c2d21,DISK], DatanodeInfoWithStorage[127.0.0.1:38645,DS-e15dc731-f07e-481e-bb2c-8928c25ee893,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-297010943-172.17.0.21-1597383083323:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36794,DS-cbad3c14-933e-4004-9f31-56f686381afc,DISK], DatanodeInfoWithStorage[127.0.0.1:41560,DS-ddc2248f-9458-4cf1-a439-94fa5d01f12e,DISK], DatanodeInfoWithStorage[127.0.0.1:35422,DS-59441fe9-6564-4b03-bb83-d739758faf59,DISK], DatanodeInfoWithStorage[127.0.0.1:45994,DS-562661a8-1076-485f-9361-49dddf16f90f,DISK], DatanodeInfoWithStorage[127.0.0.1:40592,DS-1323d819-cf06-44cd-bd1f-7cdeadcf5179,DISK], DatanodeInfoWithStorage[127.0.0.1:45341,DS-bcf5c043-09ed-44c5-a35c-cf5c397dce13,DISK], DatanodeInfoWithStorage[127.0.0.1:37395,DS-3331d70a-cc14-4649-a8af-7708d1cf462e,DISK], DatanodeInfoWithStorage[127.0.0.1:37127,DS-ce679650-c430-44d9-ad97-cee45b724de9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-297010943-172.17.0.21-1597383083323:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36794,DS-cbad3c14-933e-4004-9f31-56f686381afc,DISK], DatanodeInfoWithStorage[127.0.0.1:41560,DS-ddc2248f-9458-4cf1-a439-94fa5d01f12e,DISK], DatanodeInfoWithStorage[127.0.0.1:35422,DS-59441fe9-6564-4b03-bb83-d739758faf59,DISK], DatanodeInfoWithStorage[127.0.0.1:45994,DS-562661a8-1076-485f-9361-49dddf16f90f,DISK], DatanodeInfoWithStorage[127.0.0.1:40592,DS-1323d819-cf06-44cd-bd1f-7cdeadcf5179,DISK], DatanodeInfoWithStorage[127.0.0.1:45341,DS-bcf5c043-09ed-44c5-a35c-cf5c397dce13,DISK], DatanodeInfoWithStorage[127.0.0.1:37395,DS-3331d70a-cc14-4649-a8af-7708d1cf462e,DISK], DatanodeInfoWithStorage[127.0.0.1:37127,DS-ce679650-c430-44d9-ad97-cee45b724de9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-93061119-172.17.0.21-1597383195169:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44132,DS-98ff5b2c-8fcb-48f8-b408-55d9b169f4ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37615,DS-6ece6c67-01a7-4d88-94dd-ce3ca30e4170,DISK], DatanodeInfoWithStorage[127.0.0.1:36689,DS-f0c5ccd7-3ebe-489d-8a50-a811b994071e,DISK], DatanodeInfoWithStorage[127.0.0.1:33891,DS-1f141655-babf-4c8a-a8a3-6358098f5965,DISK], DatanodeInfoWithStorage[127.0.0.1:39245,DS-ce34b305-0e61-402f-bd9e-40dd98cefcd7,DISK], DatanodeInfoWithStorage[127.0.0.1:44444,DS-bcdefcaf-3184-47c2-9a4e-913baa7b8a72,DISK], DatanodeInfoWithStorage[127.0.0.1:44479,DS-639b4fe9-180e-4486-b6b8-85caa6fecd93,DISK], DatanodeInfoWithStorage[127.0.0.1:33103,DS-49d96eb8-6c2e-4a19-9457-3afcbf18ae90,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-93061119-172.17.0.21-1597383195169:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44132,DS-98ff5b2c-8fcb-48f8-b408-55d9b169f4ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37615,DS-6ece6c67-01a7-4d88-94dd-ce3ca30e4170,DISK], DatanodeInfoWithStorage[127.0.0.1:36689,DS-f0c5ccd7-3ebe-489d-8a50-a811b994071e,DISK], DatanodeInfoWithStorage[127.0.0.1:33891,DS-1f141655-babf-4c8a-a8a3-6358098f5965,DISK], DatanodeInfoWithStorage[127.0.0.1:39245,DS-ce34b305-0e61-402f-bd9e-40dd98cefcd7,DISK], DatanodeInfoWithStorage[127.0.0.1:44444,DS-bcdefcaf-3184-47c2-9a4e-913baa7b8a72,DISK], DatanodeInfoWithStorage[127.0.0.1:44479,DS-639b4fe9-180e-4486-b6b8-85caa6fecd93,DISK], DatanodeInfoWithStorage[127.0.0.1:33103,DS-49d96eb8-6c2e-4a19-9457-3afcbf18ae90,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1050611357-172.17.0.21-1597383232328:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38858,DS-94e82d50-9650-4361-9650-578f131e00c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35778,DS-666b1357-59c5-41f0-aba3-3f4758d92f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:38495,DS-e78dd1c0-ae2b-4341-a2c2-6c9fece9b713,DISK], DatanodeInfoWithStorage[127.0.0.1:33162,DS-1c366a3b-1046-45c2-8761-98a13ec92ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:33545,DS-8845afc5-542a-429d-983c-684b04ce3932,DISK], DatanodeInfoWithStorage[127.0.0.1:36056,DS-ccbf198f-57cf-41cd-be05-37761d28cf0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37578,DS-9a45d641-2f11-4318-b85e-1dafaf5f10f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39729,DS-2b304875-8915-46eb-be52-040e27020283,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1050611357-172.17.0.21-1597383232328:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38858,DS-94e82d50-9650-4361-9650-578f131e00c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35778,DS-666b1357-59c5-41f0-aba3-3f4758d92f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:38495,DS-e78dd1c0-ae2b-4341-a2c2-6c9fece9b713,DISK], DatanodeInfoWithStorage[127.0.0.1:33162,DS-1c366a3b-1046-45c2-8761-98a13ec92ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:33545,DS-8845afc5-542a-429d-983c-684b04ce3932,DISK], DatanodeInfoWithStorage[127.0.0.1:36056,DS-ccbf198f-57cf-41cd-be05-37761d28cf0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37578,DS-9a45d641-2f11-4318-b85e-1dafaf5f10f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39729,DS-2b304875-8915-46eb-be52-040e27020283,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1699879312-172.17.0.21-1597383260667:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35207,DS-4b2adfe0-7373-42f9-9251-18393347a330,DISK], DatanodeInfoWithStorage[127.0.0.1:35457,DS-1d626507-6b14-48ab-b94f-c185939cf6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35568,DS-a7cfa8fe-9e25-48f6-9a33-adc27a24ad7f,DISK], DatanodeInfoWithStorage[127.0.0.1:41250,DS-066d59ac-0fa9-42a5-81ff-3f3b7c29918a,DISK], DatanodeInfoWithStorage[127.0.0.1:45701,DS-6091524b-0998-464e-9a40-3f9c147d812d,DISK], DatanodeInfoWithStorage[127.0.0.1:42588,DS-617460da-1ea4-4cb5-a35c-c06e49dcd97e,DISK], DatanodeInfoWithStorage[127.0.0.1:36870,DS-5c14dfee-e6fd-4ccd-9cfd-34b8c1eab075,DISK], DatanodeInfoWithStorage[127.0.0.1:45297,DS-80b6f517-1e39-4ff9-a27f-c2ceef0d0fc1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1699879312-172.17.0.21-1597383260667:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35207,DS-4b2adfe0-7373-42f9-9251-18393347a330,DISK], DatanodeInfoWithStorage[127.0.0.1:35457,DS-1d626507-6b14-48ab-b94f-c185939cf6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35568,DS-a7cfa8fe-9e25-48f6-9a33-adc27a24ad7f,DISK], DatanodeInfoWithStorage[127.0.0.1:41250,DS-066d59ac-0fa9-42a5-81ff-3f3b7c29918a,DISK], DatanodeInfoWithStorage[127.0.0.1:45701,DS-6091524b-0998-464e-9a40-3f9c147d812d,DISK], DatanodeInfoWithStorage[127.0.0.1:42588,DS-617460da-1ea4-4cb5-a35c-c06e49dcd97e,DISK], DatanodeInfoWithStorage[127.0.0.1:36870,DS-5c14dfee-e6fd-4ccd-9cfd-34b8c1eab075,DISK], DatanodeInfoWithStorage[127.0.0.1:45297,DS-80b6f517-1e39-4ff9-a27f-c2ceef0d0fc1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1895055015-172.17.0.21-1597383447645:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43971,DS-32d53b1c-1af6-41f6-8a4d-954b3f51d411,DISK], DatanodeInfoWithStorage[127.0.0.1:36168,DS-6e8fbf26-b498-4cda-9bd4-f3b7c9309935,DISK], DatanodeInfoWithStorage[127.0.0.1:45649,DS-d02fe138-781b-4161-91d4-45352ffa183d,DISK], DatanodeInfoWithStorage[127.0.0.1:38266,DS-0f7946a4-1fe8-46ad-8bff-dd12d693c2a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43115,DS-2e21404a-3613-4735-b2f3-46fd73a60fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:39727,DS-f9cf906c-68ec-440e-a63b-378368deba14,DISK], DatanodeInfoWithStorage[127.0.0.1:32784,DS-6b4c0228-86af-4cdc-8767-56058ebfc48e,DISK], DatanodeInfoWithStorage[127.0.0.1:39502,DS-019fd38a-70fe-4933-aa08-b01f5b7eb933,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1895055015-172.17.0.21-1597383447645:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43971,DS-32d53b1c-1af6-41f6-8a4d-954b3f51d411,DISK], DatanodeInfoWithStorage[127.0.0.1:36168,DS-6e8fbf26-b498-4cda-9bd4-f3b7c9309935,DISK], DatanodeInfoWithStorage[127.0.0.1:45649,DS-d02fe138-781b-4161-91d4-45352ffa183d,DISK], DatanodeInfoWithStorage[127.0.0.1:38266,DS-0f7946a4-1fe8-46ad-8bff-dd12d693c2a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43115,DS-2e21404a-3613-4735-b2f3-46fd73a60fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:39727,DS-f9cf906c-68ec-440e-a63b-378368deba14,DISK], DatanodeInfoWithStorage[127.0.0.1:32784,DS-6b4c0228-86af-4cdc-8767-56058ebfc48e,DISK], DatanodeInfoWithStorage[127.0.0.1:39502,DS-019fd38a-70fe-4933-aa08-b01f5b7eb933,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1736200914-172.17.0.21-1597383485102:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41092,DS-72e9d65b-bbb9-40f7-8ff0-6b63b23cc19e,DISK], DatanodeInfoWithStorage[127.0.0.1:35407,DS-843cd6e7-62f6-4901-9fbc-adeb1709c633,DISK], DatanodeInfoWithStorage[127.0.0.1:42367,DS-24a147d7-2f3c-49e3-8fa2-192ecacb0a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36935,DS-88c89eb4-88a1-4092-83b6-208bfcb20c05,DISK], DatanodeInfoWithStorage[127.0.0.1:35703,DS-08bea4ba-61eb-47e7-bc43-be5ef8deb47f,DISK], DatanodeInfoWithStorage[127.0.0.1:38135,DS-753c5d7d-a295-4e35-908b-3f08c8e8e465,DISK], DatanodeInfoWithStorage[127.0.0.1:45846,DS-6da43188-5a9e-450e-b009-eef6d2618666,DISK], DatanodeInfoWithStorage[127.0.0.1:34455,DS-886264c0-463a-408c-b019-fee26498f1fe,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1736200914-172.17.0.21-1597383485102:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41092,DS-72e9d65b-bbb9-40f7-8ff0-6b63b23cc19e,DISK], DatanodeInfoWithStorage[127.0.0.1:35407,DS-843cd6e7-62f6-4901-9fbc-adeb1709c633,DISK], DatanodeInfoWithStorage[127.0.0.1:42367,DS-24a147d7-2f3c-49e3-8fa2-192ecacb0a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36935,DS-88c89eb4-88a1-4092-83b6-208bfcb20c05,DISK], DatanodeInfoWithStorage[127.0.0.1:35703,DS-08bea4ba-61eb-47e7-bc43-be5ef8deb47f,DISK], DatanodeInfoWithStorage[127.0.0.1:38135,DS-753c5d7d-a295-4e35-908b-3f08c8e8e465,DISK], DatanodeInfoWithStorage[127.0.0.1:45846,DS-6da43188-5a9e-450e-b009-eef6d2618666,DISK], DatanodeInfoWithStorage[127.0.0.1:34455,DS-886264c0-463a-408c-b019-fee26498f1fe,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1563167860-172.17.0.21-1597383598551:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44064,DS-2f91f5ba-ff88-4c46-8ea4-78b9a02ffc4f,DISK], DatanodeInfoWithStorage[127.0.0.1:33979,DS-f5bfc360-06be-4675-ad24-84e74b05c4b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34641,DS-d0f346f3-f7aa-4d78-bb69-543c7455f374,DISK], DatanodeInfoWithStorage[127.0.0.1:45189,DS-4443c475-4962-4870-8707-54fc351f6126,DISK], DatanodeInfoWithStorage[127.0.0.1:40634,DS-804852ea-6469-4629-b1d3-dc97242f37fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37170,DS-5b673fbe-9f83-45be-9ef6-421668b309ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37670,DS-0c7f523c-ed87-4d7e-a378-60860ec40de5,DISK], DatanodeInfoWithStorage[127.0.0.1:35973,DS-f83aa6ba-cfa5-4b4b-971a-19520936d58e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1563167860-172.17.0.21-1597383598551:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44064,DS-2f91f5ba-ff88-4c46-8ea4-78b9a02ffc4f,DISK], DatanodeInfoWithStorage[127.0.0.1:33979,DS-f5bfc360-06be-4675-ad24-84e74b05c4b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34641,DS-d0f346f3-f7aa-4d78-bb69-543c7455f374,DISK], DatanodeInfoWithStorage[127.0.0.1:45189,DS-4443c475-4962-4870-8707-54fc351f6126,DISK], DatanodeInfoWithStorage[127.0.0.1:40634,DS-804852ea-6469-4629-b1d3-dc97242f37fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37170,DS-5b673fbe-9f83-45be-9ef6-421668b309ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37670,DS-0c7f523c-ed87-4d7e-a378-60860ec40de5,DISK], DatanodeInfoWithStorage[127.0.0.1:35973,DS-f83aa6ba-cfa5-4b4b-971a-19520936d58e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-22592287-172.17.0.21-1597383883319:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40801,DS-a0d86882-62ed-4728-aab7-9e3297b58e31,DISK], DatanodeInfoWithStorage[127.0.0.1:33494,DS-eb6cb3b0-3734-456f-b645-681cc2278c57,DISK], DatanodeInfoWithStorage[127.0.0.1:36322,DS-000f50ec-ce8e-492a-8af9-88c113530d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39828,DS-00822d01-4cf3-4dfd-9bc0-cd7709e67470,DISK], DatanodeInfoWithStorage[127.0.0.1:43574,DS-3a6f1967-7a46-411c-b327-ab3fb16ad109,DISK], DatanodeInfoWithStorage[127.0.0.1:39506,DS-84844a60-279d-4f58-952a-45e44b08b58d,DISK], DatanodeInfoWithStorage[127.0.0.1:35791,DS-79c11e14-1a80-4b8b-b030-434d2a82bcfd,DISK], DatanodeInfoWithStorage[127.0.0.1:45423,DS-987927a6-4ccf-4148-9973-3948d8c8e6b9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-22592287-172.17.0.21-1597383883319:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40801,DS-a0d86882-62ed-4728-aab7-9e3297b58e31,DISK], DatanodeInfoWithStorage[127.0.0.1:33494,DS-eb6cb3b0-3734-456f-b645-681cc2278c57,DISK], DatanodeInfoWithStorage[127.0.0.1:36322,DS-000f50ec-ce8e-492a-8af9-88c113530d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39828,DS-00822d01-4cf3-4dfd-9bc0-cd7709e67470,DISK], DatanodeInfoWithStorage[127.0.0.1:43574,DS-3a6f1967-7a46-411c-b327-ab3fb16ad109,DISK], DatanodeInfoWithStorage[127.0.0.1:39506,DS-84844a60-279d-4f58-952a-45e44b08b58d,DISK], DatanodeInfoWithStorage[127.0.0.1:35791,DS-79c11e14-1a80-4b8b-b030-434d2a82bcfd,DISK], DatanodeInfoWithStorage[127.0.0.1:45423,DS-987927a6-4ccf-4148-9973-3948d8c8e6b9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-760178284-172.17.0.21-1597384053330:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38806,DS-060918b0-c9ae-4727-a8fa-6aaeed9b4ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:34752,DS-eed48a88-8dc9-465c-a3ca-1a43eb72b553,DISK], DatanodeInfoWithStorage[127.0.0.1:40547,DS-7da5be29-65cf-4b6b-b880-74ac4ce393f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44141,DS-b998c175-bcda-4bfd-9bd1-7b8d38de5ded,DISK], DatanodeInfoWithStorage[127.0.0.1:40550,DS-5f8ba376-5c1d-4789-9dc3-116e0fd7158e,DISK], DatanodeInfoWithStorage[127.0.0.1:36895,DS-ee268e95-1d87-44a8-8863-05ddc72b8c30,DISK], DatanodeInfoWithStorage[127.0.0.1:44794,DS-d9242540-c79f-4fb8-9265-f1d610f9c1ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36932,DS-6a667264-1e44-4950-98a1-9854f795becc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-760178284-172.17.0.21-1597384053330:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38806,DS-060918b0-c9ae-4727-a8fa-6aaeed9b4ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:34752,DS-eed48a88-8dc9-465c-a3ca-1a43eb72b553,DISK], DatanodeInfoWithStorage[127.0.0.1:40547,DS-7da5be29-65cf-4b6b-b880-74ac4ce393f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44141,DS-b998c175-bcda-4bfd-9bd1-7b8d38de5ded,DISK], DatanodeInfoWithStorage[127.0.0.1:40550,DS-5f8ba376-5c1d-4789-9dc3-116e0fd7158e,DISK], DatanodeInfoWithStorage[127.0.0.1:36895,DS-ee268e95-1d87-44a8-8863-05ddc72b8c30,DISK], DatanodeInfoWithStorage[127.0.0.1:44794,DS-d9242540-c79f-4fb8-9265-f1d610f9c1ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36932,DS-6a667264-1e44-4950-98a1-9854f795becc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-592159633-172.17.0.21-1597384243057:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36319,DS-a8cb9cd5-5702-49e0-82f6-fe05e761b112,DISK], DatanodeInfoWithStorage[127.0.0.1:41310,DS-2ad7dffa-b7ec-4c00-a9f5-2268173749be,DISK], DatanodeInfoWithStorage[127.0.0.1:40014,DS-99816366-9f04-4b61-ab26-e286ade1424d,DISK], DatanodeInfoWithStorage[127.0.0.1:46113,DS-a847e062-a991-4ad3-8997-782de67e1a09,DISK], DatanodeInfoWithStorage[127.0.0.1:44955,DS-ab82f6e9-c99c-4578-a50c-5bdc2a2420b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42927,DS-29223731-72fc-409d-b9fb-fd8132ae52ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39438,DS-98c5ee00-1e1a-4b23-98fe-6b102d9a34ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37618,DS-8ac41094-d9e4-4986-befb-b8cb8bcc5687,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-592159633-172.17.0.21-1597384243057:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36319,DS-a8cb9cd5-5702-49e0-82f6-fe05e761b112,DISK], DatanodeInfoWithStorage[127.0.0.1:41310,DS-2ad7dffa-b7ec-4c00-a9f5-2268173749be,DISK], DatanodeInfoWithStorage[127.0.0.1:40014,DS-99816366-9f04-4b61-ab26-e286ade1424d,DISK], DatanodeInfoWithStorage[127.0.0.1:46113,DS-a847e062-a991-4ad3-8997-782de67e1a09,DISK], DatanodeInfoWithStorage[127.0.0.1:44955,DS-ab82f6e9-c99c-4578-a50c-5bdc2a2420b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42927,DS-29223731-72fc-409d-b9fb-fd8132ae52ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39438,DS-98c5ee00-1e1a-4b23-98fe-6b102d9a34ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37618,DS-8ac41094-d9e4-4986-befb-b8cb8bcc5687,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-291428503-172.17.0.21-1597384275763:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43152,DS-ed3b98bc-006a-4e9c-a2e4-fc3d124633c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40520,DS-1b917fc8-2794-45d1-a763-e50075ac4a83,DISK], DatanodeInfoWithStorage[127.0.0.1:43128,DS-1e5d3892-f387-4bf1-8d6f-20884c257746,DISK], DatanodeInfoWithStorage[127.0.0.1:34562,DS-b9d8a339-5868-448a-86cc-89245bc1e76b,DISK], DatanodeInfoWithStorage[127.0.0.1:32956,DS-d95be7c4-dd79-4f05-9380-b2fc7b3130b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45195,DS-2c326ed8-9446-49c0-9e87-2e977cd134d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-300ed059-960c-4666-99ed-b9df0a869c15,DISK], DatanodeInfoWithStorage[127.0.0.1:39387,DS-2f66780a-863c-44ca-be45-9f96249c078d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-291428503-172.17.0.21-1597384275763:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43152,DS-ed3b98bc-006a-4e9c-a2e4-fc3d124633c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40520,DS-1b917fc8-2794-45d1-a763-e50075ac4a83,DISK], DatanodeInfoWithStorage[127.0.0.1:43128,DS-1e5d3892-f387-4bf1-8d6f-20884c257746,DISK], DatanodeInfoWithStorage[127.0.0.1:34562,DS-b9d8a339-5868-448a-86cc-89245bc1e76b,DISK], DatanodeInfoWithStorage[127.0.0.1:32956,DS-d95be7c4-dd79-4f05-9380-b2fc7b3130b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45195,DS-2c326ed8-9446-49c0-9e87-2e977cd134d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-300ed059-960c-4666-99ed-b9df0a869c15,DISK], DatanodeInfoWithStorage[127.0.0.1:39387,DS-2f66780a-863c-44ca-be45-9f96249c078d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-859164233-172.17.0.21-1597384457628:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40829,DS-df6bd2de-89ef-4414-a46c-da1cdab0c3e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39365,DS-607a958c-16f4-4324-aa3e-653503e59bde,DISK], DatanodeInfoWithStorage[127.0.0.1:39683,DS-787bf323-4c6a-4e4d-ad3c-7ce06bf9af4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-9baae7cb-af68-4adb-b3f6-61deee469573,DISK], DatanodeInfoWithStorage[127.0.0.1:37385,DS-54688b3d-8c02-4889-be15-28fd02dbf5e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36210,DS-2eeee10d-adb5-4728-9012-40a508963da0,DISK], DatanodeInfoWithStorage[127.0.0.1:42953,DS-c84347be-cf95-453b-a227-682a836a718b,DISK], DatanodeInfoWithStorage[127.0.0.1:37832,DS-5818d052-435e-47b4-a48f-0164036a64b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-859164233-172.17.0.21-1597384457628:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40829,DS-df6bd2de-89ef-4414-a46c-da1cdab0c3e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39365,DS-607a958c-16f4-4324-aa3e-653503e59bde,DISK], DatanodeInfoWithStorage[127.0.0.1:39683,DS-787bf323-4c6a-4e4d-ad3c-7ce06bf9af4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-9baae7cb-af68-4adb-b3f6-61deee469573,DISK], DatanodeInfoWithStorage[127.0.0.1:37385,DS-54688b3d-8c02-4889-be15-28fd02dbf5e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36210,DS-2eeee10d-adb5-4728-9012-40a508963da0,DISK], DatanodeInfoWithStorage[127.0.0.1:42953,DS-c84347be-cf95-453b-a227-682a836a718b,DISK], DatanodeInfoWithStorage[127.0.0.1:37832,DS-5818d052-435e-47b4-a48f-0164036a64b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1765360202-172.17.0.21-1597384530299:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44505,DS-5c07c320-9584-4c50-9031-27b6ec2dd9dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33203,DS-47b84c88-8ec8-40f1-8623-78291898217b,DISK], DatanodeInfoWithStorage[127.0.0.1:37472,DS-0effbaab-cdfd-4785-8ccd-f84f0c4877d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-d32e87dd-5f3a-4ae6-94a0-9dfd3cc0adb5,DISK], DatanodeInfoWithStorage[127.0.0.1:34721,DS-95d8ed90-ef3f-4b89-8b83-48dbe21fe83d,DISK], DatanodeInfoWithStorage[127.0.0.1:35736,DS-bb066925-ed24-4a4e-af39-4a8ec3ad3203,DISK], DatanodeInfoWithStorage[127.0.0.1:39906,DS-4585a10f-de2a-46ca-b21d-c9e0efb5877d,DISK], DatanodeInfoWithStorage[127.0.0.1:44985,DS-34a126ea-18e1-4c62-9db0-6e99818a1c3b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1765360202-172.17.0.21-1597384530299:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44505,DS-5c07c320-9584-4c50-9031-27b6ec2dd9dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33203,DS-47b84c88-8ec8-40f1-8623-78291898217b,DISK], DatanodeInfoWithStorage[127.0.0.1:37472,DS-0effbaab-cdfd-4785-8ccd-f84f0c4877d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-d32e87dd-5f3a-4ae6-94a0-9dfd3cc0adb5,DISK], DatanodeInfoWithStorage[127.0.0.1:34721,DS-95d8ed90-ef3f-4b89-8b83-48dbe21fe83d,DISK], DatanodeInfoWithStorage[127.0.0.1:35736,DS-bb066925-ed24-4a4e-af39-4a8ec3ad3203,DISK], DatanodeInfoWithStorage[127.0.0.1:39906,DS-4585a10f-de2a-46ca-b21d-c9e0efb5877d,DISK], DatanodeInfoWithStorage[127.0.0.1:44985,DS-34a126ea-18e1-4c62-9db0-6e99818a1c3b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1608509681-172.17.0.21-1597384636280:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35482,DS-a0e67cda-66cb-41e1-b7fa-fd09fb30edac,DISK], DatanodeInfoWithStorage[127.0.0.1:33676,DS-6eef665c-b012-4aed-9f8f-8e500f1c0dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:45718,DS-ed084ae2-d3f6-4733-a4af-c017efb5ef35,DISK], DatanodeInfoWithStorage[127.0.0.1:45663,DS-822e9ec5-c8db-4378-96e9-d517137b9f22,DISK], DatanodeInfoWithStorage[127.0.0.1:33546,DS-dc12b236-ead2-4d70-ad80-a942e7f1b982,DISK], DatanodeInfoWithStorage[127.0.0.1:46518,DS-162eb450-8c9b-4b2a-9634-2c027240a985,DISK], DatanodeInfoWithStorage[127.0.0.1:43353,DS-8a348232-ec04-4bcc-9884-5e4f62de433b,DISK], DatanodeInfoWithStorage[127.0.0.1:34816,DS-55f8cd70-77ec-46e9-978a-8ec99593c65a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1608509681-172.17.0.21-1597384636280:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35482,DS-a0e67cda-66cb-41e1-b7fa-fd09fb30edac,DISK], DatanodeInfoWithStorage[127.0.0.1:33676,DS-6eef665c-b012-4aed-9f8f-8e500f1c0dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:45718,DS-ed084ae2-d3f6-4733-a4af-c017efb5ef35,DISK], DatanodeInfoWithStorage[127.0.0.1:45663,DS-822e9ec5-c8db-4378-96e9-d517137b9f22,DISK], DatanodeInfoWithStorage[127.0.0.1:33546,DS-dc12b236-ead2-4d70-ad80-a942e7f1b982,DISK], DatanodeInfoWithStorage[127.0.0.1:46518,DS-162eb450-8c9b-4b2a-9634-2c027240a985,DISK], DatanodeInfoWithStorage[127.0.0.1:43353,DS-8a348232-ec04-4bcc-9884-5e4f62de433b,DISK], DatanodeInfoWithStorage[127.0.0.1:34816,DS-55f8cd70-77ec-46e9-978a-8ec99593c65a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1557219181-172.17.0.21-1597384704749:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44509,DS-fddff4d6-cc47-4005-a8a2-610a0cf45008,DISK], DatanodeInfoWithStorage[127.0.0.1:39846,DS-e52f8b17-3b8f-4847-b12f-b5f29e465709,DISK], DatanodeInfoWithStorage[127.0.0.1:39093,DS-b5e9a173-3a47-4b41-95f2-e100c410300f,DISK], DatanodeInfoWithStorage[127.0.0.1:38128,DS-13f2a9f9-7e17-4a85-9ff1-36528e3cbd3e,DISK], DatanodeInfoWithStorage[127.0.0.1:35725,DS-569272ba-13b3-4ae2-b05f-d0de463ec460,DISK], DatanodeInfoWithStorage[127.0.0.1:38328,DS-acea10f8-6391-42f2-8110-8aa3b452fa05,DISK], DatanodeInfoWithStorage[127.0.0.1:40938,DS-774ffa93-740e-44eb-8f65-5bb30d1be04e,DISK], DatanodeInfoWithStorage[127.0.0.1:40218,DS-99df374e-4679-4639-b8af-9c04be98d185,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1557219181-172.17.0.21-1597384704749:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44509,DS-fddff4d6-cc47-4005-a8a2-610a0cf45008,DISK], DatanodeInfoWithStorage[127.0.0.1:39846,DS-e52f8b17-3b8f-4847-b12f-b5f29e465709,DISK], DatanodeInfoWithStorage[127.0.0.1:39093,DS-b5e9a173-3a47-4b41-95f2-e100c410300f,DISK], DatanodeInfoWithStorage[127.0.0.1:38128,DS-13f2a9f9-7e17-4a85-9ff1-36528e3cbd3e,DISK], DatanodeInfoWithStorage[127.0.0.1:35725,DS-569272ba-13b3-4ae2-b05f-d0de463ec460,DISK], DatanodeInfoWithStorage[127.0.0.1:38328,DS-acea10f8-6391-42f2-8110-8aa3b452fa05,DISK], DatanodeInfoWithStorage[127.0.0.1:40938,DS-774ffa93-740e-44eb-8f65-5bb30d1be04e,DISK], DatanodeInfoWithStorage[127.0.0.1:40218,DS-99df374e-4679-4639-b8af-9c04be98d185,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1331863886-172.17.0.21-1597384816977:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45661,DS-59e56349-4b61-41de-a0b4-4e638076263e,DISK], DatanodeInfoWithStorage[127.0.0.1:34401,DS-fd010a41-31e5-43de-83aa-186ffab4f553,DISK], DatanodeInfoWithStorage[127.0.0.1:42749,DS-e249d742-6495-4ecb-98a1-5107a2161a83,DISK], DatanodeInfoWithStorage[127.0.0.1:46434,DS-c780091d-d4b3-4306-88a2-671ecd08924a,DISK], DatanodeInfoWithStorage[127.0.0.1:33134,DS-3b43d70f-8ed1-417c-b4b0-9f24cd79cdf9,DISK], DatanodeInfoWithStorage[127.0.0.1:41355,DS-79948373-7824-46a2-a4bc-8e2718a9722d,DISK], DatanodeInfoWithStorage[127.0.0.1:38260,DS-4a14144a-4fa7-4d59-91ed-e4b331025d01,DISK], DatanodeInfoWithStorage[127.0.0.1:37556,DS-62ee6532-f2ad-4159-a06d-08d98ff3e03c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1331863886-172.17.0.21-1597384816977:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45661,DS-59e56349-4b61-41de-a0b4-4e638076263e,DISK], DatanodeInfoWithStorage[127.0.0.1:34401,DS-fd010a41-31e5-43de-83aa-186ffab4f553,DISK], DatanodeInfoWithStorage[127.0.0.1:42749,DS-e249d742-6495-4ecb-98a1-5107a2161a83,DISK], DatanodeInfoWithStorage[127.0.0.1:46434,DS-c780091d-d4b3-4306-88a2-671ecd08924a,DISK], DatanodeInfoWithStorage[127.0.0.1:33134,DS-3b43d70f-8ed1-417c-b4b0-9f24cd79cdf9,DISK], DatanodeInfoWithStorage[127.0.0.1:41355,DS-79948373-7824-46a2-a4bc-8e2718a9722d,DISK], DatanodeInfoWithStorage[127.0.0.1:38260,DS-4a14144a-4fa7-4d59-91ed-e4b331025d01,DISK], DatanodeInfoWithStorage[127.0.0.1:37556,DS-62ee6532-f2ad-4159-a06d-08d98ff3e03c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1168364517-172.17.0.21-1597385144570:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34163,DS-8970ecae-c88f-455f-a2fe-934189d2846a,DISK], DatanodeInfoWithStorage[127.0.0.1:35931,DS-d038bb15-3311-463d-93e0-4479ef9bfc6e,DISK], DatanodeInfoWithStorage[127.0.0.1:46050,DS-8211aef8-b1d1-4d0b-9e4c-fb8151fb7907,DISK], DatanodeInfoWithStorage[127.0.0.1:33078,DS-5657b409-cda6-4ba9-8f33-c6d0765eddce,DISK], DatanodeInfoWithStorage[127.0.0.1:44831,DS-d4298d5b-4f57-4eb1-99dc-a976b9be5fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:38899,DS-1f62561e-5537-4745-acc7-a1be55a4efb4,DISK], DatanodeInfoWithStorage[127.0.0.1:46483,DS-c73aec43-906e-48c6-8b14-750a401152c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35708,DS-c8de5c94-5e22-4820-88d6-238deda64168,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1168364517-172.17.0.21-1597385144570:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34163,DS-8970ecae-c88f-455f-a2fe-934189d2846a,DISK], DatanodeInfoWithStorage[127.0.0.1:35931,DS-d038bb15-3311-463d-93e0-4479ef9bfc6e,DISK], DatanodeInfoWithStorage[127.0.0.1:46050,DS-8211aef8-b1d1-4d0b-9e4c-fb8151fb7907,DISK], DatanodeInfoWithStorage[127.0.0.1:33078,DS-5657b409-cda6-4ba9-8f33-c6d0765eddce,DISK], DatanodeInfoWithStorage[127.0.0.1:44831,DS-d4298d5b-4f57-4eb1-99dc-a976b9be5fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:38899,DS-1f62561e-5537-4745-acc7-a1be55a4efb4,DISK], DatanodeInfoWithStorage[127.0.0.1:46483,DS-c73aec43-906e-48c6-8b14-750a401152c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35708,DS-c8de5c94-5e22-4820-88d6-238deda64168,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1090327964-172.17.0.21-1597385186142:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33132,DS-42e88d08-f8d7-4d92-b9b7-b855c365b5ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42020,DS-6b6de49e-b34c-4f36-84b9-816ad62a7c65,DISK], DatanodeInfoWithStorage[127.0.0.1:37728,DS-7f1a7452-0c84-4ea8-a3fe-3bd47b7c9728,DISK], DatanodeInfoWithStorage[127.0.0.1:43197,DS-5ba173ac-d2af-4814-8b2f-7a2a277a6225,DISK], DatanodeInfoWithStorage[127.0.0.1:46141,DS-4fc4170a-12ec-410e-a0c0-0086b5060e40,DISK], DatanodeInfoWithStorage[127.0.0.1:43184,DS-f32ca037-4fd4-4ad5-8421-4ab1a4624c45,DISK], DatanodeInfoWithStorage[127.0.0.1:36383,DS-93e4cd15-c45d-43c7-83cb-00f1fb1d3577,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-d322dd50-82df-453a-818e-f6682131cd30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1090327964-172.17.0.21-1597385186142:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33132,DS-42e88d08-f8d7-4d92-b9b7-b855c365b5ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42020,DS-6b6de49e-b34c-4f36-84b9-816ad62a7c65,DISK], DatanodeInfoWithStorage[127.0.0.1:37728,DS-7f1a7452-0c84-4ea8-a3fe-3bd47b7c9728,DISK], DatanodeInfoWithStorage[127.0.0.1:43197,DS-5ba173ac-d2af-4814-8b2f-7a2a277a6225,DISK], DatanodeInfoWithStorage[127.0.0.1:46141,DS-4fc4170a-12ec-410e-a0c0-0086b5060e40,DISK], DatanodeInfoWithStorage[127.0.0.1:43184,DS-f32ca037-4fd4-4ad5-8421-4ab1a4624c45,DISK], DatanodeInfoWithStorage[127.0.0.1:36383,DS-93e4cd15-c45d-43c7-83cb-00f1fb1d3577,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-d322dd50-82df-453a-818e-f6682131cd30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2120379467-172.17.0.21-1597385323935:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40371,DS-5b61aa61-5887-4248-82a7-119ee15b026b,DISK], DatanodeInfoWithStorage[127.0.0.1:44598,DS-c2e57be6-47e3-48e3-afa0-892e9865ee54,DISK], DatanodeInfoWithStorage[127.0.0.1:46708,DS-74958738-b51f-439c-82cf-8eab1a105f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:37170,DS-73a6dceb-af91-4981-8308-4aa792994766,DISK], DatanodeInfoWithStorage[127.0.0.1:36718,DS-9be37e77-8b79-490a-98ba-3929ae5cc791,DISK], DatanodeInfoWithStorage[127.0.0.1:33033,DS-06757821-4b10-4c81-8036-99e75237b68e,DISK], DatanodeInfoWithStorage[127.0.0.1:40365,DS-1a45b3c0-849a-487a-84a9-f75e59e9ec8a,DISK], DatanodeInfoWithStorage[127.0.0.1:37705,DS-6168cba1-4ae0-495f-b271-d944445b2aaa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2120379467-172.17.0.21-1597385323935:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40371,DS-5b61aa61-5887-4248-82a7-119ee15b026b,DISK], DatanodeInfoWithStorage[127.0.0.1:44598,DS-c2e57be6-47e3-48e3-afa0-892e9865ee54,DISK], DatanodeInfoWithStorage[127.0.0.1:46708,DS-74958738-b51f-439c-82cf-8eab1a105f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:37170,DS-73a6dceb-af91-4981-8308-4aa792994766,DISK], DatanodeInfoWithStorage[127.0.0.1:36718,DS-9be37e77-8b79-490a-98ba-3929ae5cc791,DISK], DatanodeInfoWithStorage[127.0.0.1:33033,DS-06757821-4b10-4c81-8036-99e75237b68e,DISK], DatanodeInfoWithStorage[127.0.0.1:40365,DS-1a45b3c0-849a-487a-84a9-f75e59e9ec8a,DISK], DatanodeInfoWithStorage[127.0.0.1:37705,DS-6168cba1-4ae0-495f-b271-d944445b2aaa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-388516015-172.17.0.21-1597385422716:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40156,DS-fe81bbbd-65af-40c6-805c-6263a456647d,DISK], DatanodeInfoWithStorage[127.0.0.1:43212,DS-9cf11fdf-b333-4594-b92f-f8e30c520157,DISK], DatanodeInfoWithStorage[127.0.0.1:41943,DS-2c99510e-8af0-4cbc-8986-af88d507d3ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34151,DS-3d218b4c-72a9-4702-9e57-c5d4645c5849,DISK], DatanodeInfoWithStorage[127.0.0.1:36276,DS-b7d64833-4c1c-4e7b-88c5-7527cea1a979,DISK], DatanodeInfoWithStorage[127.0.0.1:45110,DS-d711f169-ced8-4628-8308-a0f388b2b6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34384,DS-14f10dc7-1008-4147-bd8f-627b22340599,DISK], DatanodeInfoWithStorage[127.0.0.1:37421,DS-f46fb31b-91bc-479c-8b03-b15f5b07eeb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-388516015-172.17.0.21-1597385422716:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40156,DS-fe81bbbd-65af-40c6-805c-6263a456647d,DISK], DatanodeInfoWithStorage[127.0.0.1:43212,DS-9cf11fdf-b333-4594-b92f-f8e30c520157,DISK], DatanodeInfoWithStorage[127.0.0.1:41943,DS-2c99510e-8af0-4cbc-8986-af88d507d3ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34151,DS-3d218b4c-72a9-4702-9e57-c5d4645c5849,DISK], DatanodeInfoWithStorage[127.0.0.1:36276,DS-b7d64833-4c1c-4e7b-88c5-7527cea1a979,DISK], DatanodeInfoWithStorage[127.0.0.1:45110,DS-d711f169-ced8-4628-8308-a0f388b2b6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34384,DS-14f10dc7-1008-4147-bd8f-627b22340599,DISK], DatanodeInfoWithStorage[127.0.0.1:37421,DS-f46fb31b-91bc-479c-8b03-b15f5b07eeb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1557409614-172.17.0.21-1597385486813:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44689,DS-a3629d9a-4d8d-46e2-962a-a050409e1125,DISK], DatanodeInfoWithStorage[127.0.0.1:38691,DS-8fb1e842-04f4-403d-b48e-bae2c1b11e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40341,DS-ca035d65-1560-4517-b6cd-440a17acb88f,DISK], DatanodeInfoWithStorage[127.0.0.1:33047,DS-d1ffc9a5-e92a-446c-ae3f-86039d8d88b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43664,DS-dd96fed0-7637-4a96-8fd8-af6bd0f30f96,DISK], DatanodeInfoWithStorage[127.0.0.1:42339,DS-93be30c2-aadb-4991-8b52-37a96a6124d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41062,DS-2ace71ad-75c5-410e-b005-678c12e71c59,DISK], DatanodeInfoWithStorage[127.0.0.1:37383,DS-b57e8229-85e5-4aef-b9ce-eec3bfe55d86,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1557409614-172.17.0.21-1597385486813:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44689,DS-a3629d9a-4d8d-46e2-962a-a050409e1125,DISK], DatanodeInfoWithStorage[127.0.0.1:38691,DS-8fb1e842-04f4-403d-b48e-bae2c1b11e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40341,DS-ca035d65-1560-4517-b6cd-440a17acb88f,DISK], DatanodeInfoWithStorage[127.0.0.1:33047,DS-d1ffc9a5-e92a-446c-ae3f-86039d8d88b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43664,DS-dd96fed0-7637-4a96-8fd8-af6bd0f30f96,DISK], DatanodeInfoWithStorage[127.0.0.1:42339,DS-93be30c2-aadb-4991-8b52-37a96a6124d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41062,DS-2ace71ad-75c5-410e-b005-678c12e71c59,DISK], DatanodeInfoWithStorage[127.0.0.1:37383,DS-b57e8229-85e5-4aef-b9ce-eec3bfe55d86,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-593839687-172.17.0.21-1597385847299:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44419,DS-6136aab3-9242-46e9-9dc6-f35a443fb382,DISK], DatanodeInfoWithStorage[127.0.0.1:33329,DS-81fb512a-a2da-481a-931d-d6965fd838bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45042,DS-6a58ce0b-14b8-4cd7-b168-9253eee5cc6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41749,DS-e01a4723-b600-485a-a360-0f787972f4af,DISK], DatanodeInfoWithStorage[127.0.0.1:33815,DS-dbb1f178-6bd9-4a86-8008-ac7f40b5599b,DISK], DatanodeInfoWithStorage[127.0.0.1:34109,DS-82a66d53-cb2c-4400-80d3-6c773bb13055,DISK], DatanodeInfoWithStorage[127.0.0.1:46652,DS-7f9fe6d3-1f89-430d-b519-1387b763f9b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37409,DS-83856a11-0775-41f6-8a97-8c7434b76750,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-593839687-172.17.0.21-1597385847299:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44419,DS-6136aab3-9242-46e9-9dc6-f35a443fb382,DISK], DatanodeInfoWithStorage[127.0.0.1:33329,DS-81fb512a-a2da-481a-931d-d6965fd838bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45042,DS-6a58ce0b-14b8-4cd7-b168-9253eee5cc6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41749,DS-e01a4723-b600-485a-a360-0f787972f4af,DISK], DatanodeInfoWithStorage[127.0.0.1:33815,DS-dbb1f178-6bd9-4a86-8008-ac7f40b5599b,DISK], DatanodeInfoWithStorage[127.0.0.1:34109,DS-82a66d53-cb2c-4400-80d3-6c773bb13055,DISK], DatanodeInfoWithStorage[127.0.0.1:46652,DS-7f9fe6d3-1f89-430d-b519-1387b763f9b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37409,DS-83856a11-0775-41f6-8a97-8c7434b76750,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1685104282-172.17.0.21-1597385913190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38946,DS-3bbaf04b-225c-4b4c-8d70-1e28c2961517,DISK], DatanodeInfoWithStorage[127.0.0.1:42122,DS-490f53a9-3618-4890-9e4d-e64359306b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:36644,DS-7a56879a-7142-49c7-96f5-df557eb8d5eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46409,DS-b8c5614d-9716-4981-a5ce-3656b7043303,DISK], DatanodeInfoWithStorage[127.0.0.1:42328,DS-3f7391cd-a2d5-4452-bb56-bb85d5c34d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44236,DS-6ccf13a1-e030-455b-ad4a-3c39ef367103,DISK], DatanodeInfoWithStorage[127.0.0.1:41820,DS-87185f5a-74e0-457b-8b95-41463031d434,DISK], DatanodeInfoWithStorage[127.0.0.1:43372,DS-e4bd1575-0b66-4d96-8fb8-9cc9531382d6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1685104282-172.17.0.21-1597385913190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38946,DS-3bbaf04b-225c-4b4c-8d70-1e28c2961517,DISK], DatanodeInfoWithStorage[127.0.0.1:42122,DS-490f53a9-3618-4890-9e4d-e64359306b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:36644,DS-7a56879a-7142-49c7-96f5-df557eb8d5eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46409,DS-b8c5614d-9716-4981-a5ce-3656b7043303,DISK], DatanodeInfoWithStorage[127.0.0.1:42328,DS-3f7391cd-a2d5-4452-bb56-bb85d5c34d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44236,DS-6ccf13a1-e030-455b-ad4a-3c39ef367103,DISK], DatanodeInfoWithStorage[127.0.0.1:41820,DS-87185f5a-74e0-457b-8b95-41463031d434,DISK], DatanodeInfoWithStorage[127.0.0.1:43372,DS-e4bd1575-0b66-4d96-8fb8-9cc9531382d6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2093404428-172.17.0.21-1597386016433:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46557,DS-a2ed70f5-054f-4fd7-81b6-3a2a89a13a48,DISK], DatanodeInfoWithStorage[127.0.0.1:39151,DS-8b3817a9-8811-4323-88d6-06550dc11e08,DISK], DatanodeInfoWithStorage[127.0.0.1:35243,DS-02d9d3ba-c72a-48a9-ab7a-aa0c7c24161a,DISK], DatanodeInfoWithStorage[127.0.0.1:37542,DS-16ef865c-4c78-4e3b-8a6d-1cf5e2e0b7f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38249,DS-e602f273-815b-451c-aac8-822635ce6088,DISK], DatanodeInfoWithStorage[127.0.0.1:46459,DS-ec956230-3d75-4608-b645-1435ee4aed2a,DISK], DatanodeInfoWithStorage[127.0.0.1:36060,DS-912790ba-b19e-450d-873a-e30012fbb977,DISK], DatanodeInfoWithStorage[127.0.0.1:34198,DS-9e13e8f4-42b2-479d-9128-9f8de3399b41,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2093404428-172.17.0.21-1597386016433:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46557,DS-a2ed70f5-054f-4fd7-81b6-3a2a89a13a48,DISK], DatanodeInfoWithStorage[127.0.0.1:39151,DS-8b3817a9-8811-4323-88d6-06550dc11e08,DISK], DatanodeInfoWithStorage[127.0.0.1:35243,DS-02d9d3ba-c72a-48a9-ab7a-aa0c7c24161a,DISK], DatanodeInfoWithStorage[127.0.0.1:37542,DS-16ef865c-4c78-4e3b-8a6d-1cf5e2e0b7f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38249,DS-e602f273-815b-451c-aac8-822635ce6088,DISK], DatanodeInfoWithStorage[127.0.0.1:46459,DS-ec956230-3d75-4608-b645-1435ee4aed2a,DISK], DatanodeInfoWithStorage[127.0.0.1:36060,DS-912790ba-b19e-450d-873a-e30012fbb977,DISK], DatanodeInfoWithStorage[127.0.0.1:34198,DS-9e13e8f4-42b2-479d-9128-9f8de3399b41,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2045693858-172.17.0.21-1597386090919:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39692,DS-8d3ad730-f0d9-4b70-835c-c13f2936a79a,DISK], DatanodeInfoWithStorage[127.0.0.1:34023,DS-55ae1eec-c861-4750-acf0-8f508c8fa36c,DISK], DatanodeInfoWithStorage[127.0.0.1:42008,DS-d6a3583e-6500-433e-b7ec-2bf22a6a0e55,DISK], DatanodeInfoWithStorage[127.0.0.1:44056,DS-79c57b20-3236-424a-8f69-90adbba15086,DISK], DatanodeInfoWithStorage[127.0.0.1:38812,DS-58bf1dbf-1147-4173-b6b5-dfa7f950f013,DISK], DatanodeInfoWithStorage[127.0.0.1:40757,DS-659b1ac6-4876-4dba-8c4e-e94f26f56e73,DISK], DatanodeInfoWithStorage[127.0.0.1:33881,DS-20cdfffc-6776-4366-80a3-43060cc0ba9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39557,DS-a7b9dd3c-dc33-4830-b003-ee366db5128f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2045693858-172.17.0.21-1597386090919:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39692,DS-8d3ad730-f0d9-4b70-835c-c13f2936a79a,DISK], DatanodeInfoWithStorage[127.0.0.1:34023,DS-55ae1eec-c861-4750-acf0-8f508c8fa36c,DISK], DatanodeInfoWithStorage[127.0.0.1:42008,DS-d6a3583e-6500-433e-b7ec-2bf22a6a0e55,DISK], DatanodeInfoWithStorage[127.0.0.1:44056,DS-79c57b20-3236-424a-8f69-90adbba15086,DISK], DatanodeInfoWithStorage[127.0.0.1:38812,DS-58bf1dbf-1147-4173-b6b5-dfa7f950f013,DISK], DatanodeInfoWithStorage[127.0.0.1:40757,DS-659b1ac6-4876-4dba-8c4e-e94f26f56e73,DISK], DatanodeInfoWithStorage[127.0.0.1:33881,DS-20cdfffc-6776-4366-80a3-43060cc0ba9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39557,DS-a7b9dd3c-dc33-4830-b003-ee366db5128f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-428811831-172.17.0.21-1597386378728:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36163,DS-ae655cac-ae86-4a2f-b840-9f7137c622c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42447,DS-85822e94-4a13-4021-b942-bb7b8fe4ac04,DISK], DatanodeInfoWithStorage[127.0.0.1:34033,DS-5fbae71a-2bb9-43a0-b307-19ae21a7403c,DISK], DatanodeInfoWithStorage[127.0.0.1:35700,DS-6fe2d347-7fad-4f6e-b244-2acfb46f8142,DISK], DatanodeInfoWithStorage[127.0.0.1:46427,DS-6e7ed7fe-53d2-41cb-9eea-d402ba5742f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44678,DS-a59409b6-009c-4fed-b5dc-6362bba7148b,DISK], DatanodeInfoWithStorage[127.0.0.1:34414,DS-0393a1ac-c952-4686-b85c-6e9ceda397ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40262,DS-c2b8ca7f-36b6-41c8-b537-ecf35f2cde60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-428811831-172.17.0.21-1597386378728:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36163,DS-ae655cac-ae86-4a2f-b840-9f7137c622c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42447,DS-85822e94-4a13-4021-b942-bb7b8fe4ac04,DISK], DatanodeInfoWithStorage[127.0.0.1:34033,DS-5fbae71a-2bb9-43a0-b307-19ae21a7403c,DISK], DatanodeInfoWithStorage[127.0.0.1:35700,DS-6fe2d347-7fad-4f6e-b244-2acfb46f8142,DISK], DatanodeInfoWithStorage[127.0.0.1:46427,DS-6e7ed7fe-53d2-41cb-9eea-d402ba5742f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44678,DS-a59409b6-009c-4fed-b5dc-6362bba7148b,DISK], DatanodeInfoWithStorage[127.0.0.1:34414,DS-0393a1ac-c952-4686-b85c-6e9ceda397ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40262,DS-c2b8ca7f-36b6-41c8-b537-ecf35f2cde60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1754628573-172.17.0.21-1597386576007:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37342,DS-5beb15ae-8dae-4a74-8e14-8b956d538df6,DISK], DatanodeInfoWithStorage[127.0.0.1:38809,DS-78a47d65-8656-4586-8b9e-c37d0a6ca36e,DISK], DatanodeInfoWithStorage[127.0.0.1:34479,DS-141390fe-fe0a-4183-81cd-5bd1aad5a9aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35423,DS-4eea0203-ee44-44ca-b4dc-f7afdd165da5,DISK], DatanodeInfoWithStorage[127.0.0.1:39693,DS-e756d4d7-7c4a-4811-86a2-547cfe06428a,DISK], DatanodeInfoWithStorage[127.0.0.1:44027,DS-107df2f7-fafa-413a-9bad-17d58d5036a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45135,DS-27073744-4000-4796-955d-8afaed07917a,DISK], DatanodeInfoWithStorage[127.0.0.1:39455,DS-416c8f75-66be-48ac-affc-c1213a748691,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1754628573-172.17.0.21-1597386576007:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37342,DS-5beb15ae-8dae-4a74-8e14-8b956d538df6,DISK], DatanodeInfoWithStorage[127.0.0.1:38809,DS-78a47d65-8656-4586-8b9e-c37d0a6ca36e,DISK], DatanodeInfoWithStorage[127.0.0.1:34479,DS-141390fe-fe0a-4183-81cd-5bd1aad5a9aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35423,DS-4eea0203-ee44-44ca-b4dc-f7afdd165da5,DISK], DatanodeInfoWithStorage[127.0.0.1:39693,DS-e756d4d7-7c4a-4811-86a2-547cfe06428a,DISK], DatanodeInfoWithStorage[127.0.0.1:44027,DS-107df2f7-fafa-413a-9bad-17d58d5036a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45135,DS-27073744-4000-4796-955d-8afaed07917a,DISK], DatanodeInfoWithStorage[127.0.0.1:39455,DS-416c8f75-66be-48ac-affc-c1213a748691,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1194942494-172.17.0.21-1597386746119:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39600,DS-8af1858f-61a2-4602-a3f1-a782069151cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35553,DS-3653a549-b82e-4266-af33-0faf16954b09,DISK], DatanodeInfoWithStorage[127.0.0.1:45126,DS-96e5d5f1-eb6a-4c34-9a17-51ffd23d60b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43754,DS-ee990903-af8d-49c1-ad3e-d8b71fad63c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35251,DS-4a0e6865-3105-4754-81f0-d6eff6556f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:37229,DS-c1e5f4dd-f9d2-47a2-b9bb-7f7c754f193b,DISK], DatanodeInfoWithStorage[127.0.0.1:35420,DS-6b047e1b-d338-4d15-97f1-145a7f3a8bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:41272,DS-d1ae311c-4eba-4993-9c49-8d3586116c00,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1194942494-172.17.0.21-1597386746119:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39600,DS-8af1858f-61a2-4602-a3f1-a782069151cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35553,DS-3653a549-b82e-4266-af33-0faf16954b09,DISK], DatanodeInfoWithStorage[127.0.0.1:45126,DS-96e5d5f1-eb6a-4c34-9a17-51ffd23d60b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43754,DS-ee990903-af8d-49c1-ad3e-d8b71fad63c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35251,DS-4a0e6865-3105-4754-81f0-d6eff6556f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:37229,DS-c1e5f4dd-f9d2-47a2-b9bb-7f7c754f193b,DISK], DatanodeInfoWithStorage[127.0.0.1:35420,DS-6b047e1b-d338-4d15-97f1-145a7f3a8bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:41272,DS-d1ae311c-4eba-4993-9c49-8d3586116c00,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-636322842-172.17.0.21-1597386973441:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37857,DS-9c263f35-5908-44db-bd9b-195ba45f43d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41846,DS-23791a1a-eee7-4efb-8041-efee3300c840,DISK], DatanodeInfoWithStorage[127.0.0.1:37124,DS-d9fc6b35-f7d8-454d-8207-97849310e30b,DISK], DatanodeInfoWithStorage[127.0.0.1:38689,DS-7dd54d90-c9ca-496f-86ba-7cefc532c30f,DISK], DatanodeInfoWithStorage[127.0.0.1:38262,DS-bb3388ae-1251-4a99-a007-5b53c5c215cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34714,DS-37567601-1e1c-4b11-a1de-dc0723e72311,DISK], DatanodeInfoWithStorage[127.0.0.1:34020,DS-13f4e3e9-d094-4515-a658-32b083416b42,DISK], DatanodeInfoWithStorage[127.0.0.1:36199,DS-d11f1f5b-4615-4605-bf02-7b7299d6d06e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-636322842-172.17.0.21-1597386973441:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37857,DS-9c263f35-5908-44db-bd9b-195ba45f43d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41846,DS-23791a1a-eee7-4efb-8041-efee3300c840,DISK], DatanodeInfoWithStorage[127.0.0.1:37124,DS-d9fc6b35-f7d8-454d-8207-97849310e30b,DISK], DatanodeInfoWithStorage[127.0.0.1:38689,DS-7dd54d90-c9ca-496f-86ba-7cefc532c30f,DISK], DatanodeInfoWithStorage[127.0.0.1:38262,DS-bb3388ae-1251-4a99-a007-5b53c5c215cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34714,DS-37567601-1e1c-4b11-a1de-dc0723e72311,DISK], DatanodeInfoWithStorage[127.0.0.1:34020,DS-13f4e3e9-d094-4515-a658-32b083416b42,DISK], DatanodeInfoWithStorage[127.0.0.1:36199,DS-d11f1f5b-4615-4605-bf02-7b7299d6d06e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1505422262-172.17.0.21-1597387010052:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44078,DS-32d0719d-b374-4e3c-9245-e2672e87a304,DISK], DatanodeInfoWithStorage[127.0.0.1:39612,DS-344de5a5-18c8-4da1-99e5-ff197c567217,DISK], DatanodeInfoWithStorage[127.0.0.1:32790,DS-a45dc812-9537-4448-bb30-ac40a6c2a589,DISK], DatanodeInfoWithStorage[127.0.0.1:40133,DS-c8344a95-8026-4c67-a10f-5a6495b83058,DISK], DatanodeInfoWithStorage[127.0.0.1:45894,DS-ad6e59c3-8d78-4b7b-8eb4-bacce1e3ed7e,DISK], DatanodeInfoWithStorage[127.0.0.1:36931,DS-50b6cd2c-6f54-4a75-b92f-ba2d130b5db0,DISK], DatanodeInfoWithStorage[127.0.0.1:39540,DS-becd171e-ced5-4d69-b605-394f87eaff20,DISK], DatanodeInfoWithStorage[127.0.0.1:33784,DS-19fadf3c-4af1-4508-b330-943989a07cf3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1505422262-172.17.0.21-1597387010052:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44078,DS-32d0719d-b374-4e3c-9245-e2672e87a304,DISK], DatanodeInfoWithStorage[127.0.0.1:39612,DS-344de5a5-18c8-4da1-99e5-ff197c567217,DISK], DatanodeInfoWithStorage[127.0.0.1:32790,DS-a45dc812-9537-4448-bb30-ac40a6c2a589,DISK], DatanodeInfoWithStorage[127.0.0.1:40133,DS-c8344a95-8026-4c67-a10f-5a6495b83058,DISK], DatanodeInfoWithStorage[127.0.0.1:45894,DS-ad6e59c3-8d78-4b7b-8eb4-bacce1e3ed7e,DISK], DatanodeInfoWithStorage[127.0.0.1:36931,DS-50b6cd2c-6f54-4a75-b92f-ba2d130b5db0,DISK], DatanodeInfoWithStorage[127.0.0.1:39540,DS-becd171e-ced5-4d69-b605-394f87eaff20,DISK], DatanodeInfoWithStorage[127.0.0.1:33784,DS-19fadf3c-4af1-4508-b330-943989a07cf3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1820165335-172.17.0.21-1597387080835:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38869,DS-4ae5a0b0-ea89-4794-b3c3-aca234722fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:46314,DS-c7d45b13-3a7d-438a-bd1f-01a2fddb90fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34327,DS-ba999ffa-1060-4bcd-a79f-9f7d2ee9be8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44779,DS-e58a825c-ae3a-4020-90fa-4856704c9c87,DISK], DatanodeInfoWithStorage[127.0.0.1:34845,DS-cee30888-3762-4a52-b685-be6e7bdcdd32,DISK], DatanodeInfoWithStorage[127.0.0.1:37195,DS-f109e9bd-92ee-4488-835a-99fca594d043,DISK], DatanodeInfoWithStorage[127.0.0.1:35244,DS-efc864a3-1be5-432d-b459-f60454a796d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46636,DS-cc7215aa-0c1d-4c32-90c7-4b827e74ba83,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1820165335-172.17.0.21-1597387080835:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38869,DS-4ae5a0b0-ea89-4794-b3c3-aca234722fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:46314,DS-c7d45b13-3a7d-438a-bd1f-01a2fddb90fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34327,DS-ba999ffa-1060-4bcd-a79f-9f7d2ee9be8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44779,DS-e58a825c-ae3a-4020-90fa-4856704c9c87,DISK], DatanodeInfoWithStorage[127.0.0.1:34845,DS-cee30888-3762-4a52-b685-be6e7bdcdd32,DISK], DatanodeInfoWithStorage[127.0.0.1:37195,DS-f109e9bd-92ee-4488-835a-99fca594d043,DISK], DatanodeInfoWithStorage[127.0.0.1:35244,DS-efc864a3-1be5-432d-b459-f60454a796d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46636,DS-cc7215aa-0c1d-4c32-90c7-4b827e74ba83,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 11 out of 50
v1v1v2v2 failed with probability 26 out of 50
result: false positive !!!
Total execution time in seconds : 5349
