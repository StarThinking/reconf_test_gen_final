reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-808611256-172.17.0.14-1597655840416:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42792,DS-bcdf8368-8bec-446a-9626-352b49c12dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:41377,DS-002af4d1-62d8-445e-b7d6-9776e992fcbb,DISK], DatanodeInfoWithStorage[127.0.0.1:43806,DS-7e91253e-d899-4fc2-a21d-94966e558aff,DISK], DatanodeInfoWithStorage[127.0.0.1:39283,DS-0dc87803-b827-42b8-aa7f-232349acbbf4,DISK], DatanodeInfoWithStorage[127.0.0.1:45894,DS-40d2be0b-bf7e-46f8-9f40-fafc54982a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42584,DS-d69e01d2-0977-4e39-9b83-8d7ce379d0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37946,DS-1d2ef943-a921-44ae-9a90-a783bd61dd0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45649,DS-a9e85f72-6616-4482-8410-96bec59d5b7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-808611256-172.17.0.14-1597655840416:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42792,DS-bcdf8368-8bec-446a-9626-352b49c12dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:41377,DS-002af4d1-62d8-445e-b7d6-9776e992fcbb,DISK], DatanodeInfoWithStorage[127.0.0.1:43806,DS-7e91253e-d899-4fc2-a21d-94966e558aff,DISK], DatanodeInfoWithStorage[127.0.0.1:39283,DS-0dc87803-b827-42b8-aa7f-232349acbbf4,DISK], DatanodeInfoWithStorage[127.0.0.1:45894,DS-40d2be0b-bf7e-46f8-9f40-fafc54982a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42584,DS-d69e01d2-0977-4e39-9b83-8d7ce379d0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37946,DS-1d2ef943-a921-44ae-9a90-a783bd61dd0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45649,DS-a9e85f72-6616-4482-8410-96bec59d5b7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1392517348-172.17.0.14-1597656191772:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38015,DS-28b2691d-0a5e-4fd0-af24-b4c5baf0b4f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40742,DS-1503055c-88ff-4545-ae27-57d32359d71e,DISK], DatanodeInfoWithStorage[127.0.0.1:36444,DS-0f4cae44-14b5-40bf-8aa3-051a6d025175,DISK], DatanodeInfoWithStorage[127.0.0.1:32943,DS-435ba86e-dfe6-4000-a7cf-aac31fe80b75,DISK], DatanodeInfoWithStorage[127.0.0.1:38301,DS-55a25757-dc4a-48ca-8f54-0726ec287295,DISK], DatanodeInfoWithStorage[127.0.0.1:35399,DS-7d486c79-87c0-46e7-a2dc-cb56a3b934f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41599,DS-55e89977-4384-4534-b5d3-c11c1b61e53c,DISK], DatanodeInfoWithStorage[127.0.0.1:44812,DS-07c8de48-7d57-4ce9-8f20-5f941cfdbfa8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1392517348-172.17.0.14-1597656191772:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38015,DS-28b2691d-0a5e-4fd0-af24-b4c5baf0b4f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40742,DS-1503055c-88ff-4545-ae27-57d32359d71e,DISK], DatanodeInfoWithStorage[127.0.0.1:36444,DS-0f4cae44-14b5-40bf-8aa3-051a6d025175,DISK], DatanodeInfoWithStorage[127.0.0.1:32943,DS-435ba86e-dfe6-4000-a7cf-aac31fe80b75,DISK], DatanodeInfoWithStorage[127.0.0.1:38301,DS-55a25757-dc4a-48ca-8f54-0726ec287295,DISK], DatanodeInfoWithStorage[127.0.0.1:35399,DS-7d486c79-87c0-46e7-a2dc-cb56a3b934f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41599,DS-55e89977-4384-4534-b5d3-c11c1b61e53c,DISK], DatanodeInfoWithStorage[127.0.0.1:44812,DS-07c8de48-7d57-4ce9-8f20-5f941cfdbfa8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1901359800-172.17.0.14-1597656333988:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41913,DS-072af6ba-9731-434e-8d7b-9d87127c2f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:42656,DS-c9b31371-65b5-4822-a7bd-1eede8191bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:39668,DS-8e1cd03c-ca2f-42b1-803b-c651a148314c,DISK], DatanodeInfoWithStorage[127.0.0.1:34042,DS-3610eb21-4d3f-412e-a8a6-14268f998492,DISK], DatanodeInfoWithStorage[127.0.0.1:34557,DS-399c2b1c-dfb2-411d-b875-c96d8fe6907f,DISK], DatanodeInfoWithStorage[127.0.0.1:38447,DS-5702e48a-64c7-43f1-815b-cc0b0c87ddbe,DISK], DatanodeInfoWithStorage[127.0.0.1:45674,DS-d9db954c-8e55-4872-a94f-911be9395765,DISK], DatanodeInfoWithStorage[127.0.0.1:39356,DS-da651c20-3c18-419f-be04-8d0d6188f16f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1901359800-172.17.0.14-1597656333988:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41913,DS-072af6ba-9731-434e-8d7b-9d87127c2f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:42656,DS-c9b31371-65b5-4822-a7bd-1eede8191bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:39668,DS-8e1cd03c-ca2f-42b1-803b-c651a148314c,DISK], DatanodeInfoWithStorage[127.0.0.1:34042,DS-3610eb21-4d3f-412e-a8a6-14268f998492,DISK], DatanodeInfoWithStorage[127.0.0.1:34557,DS-399c2b1c-dfb2-411d-b875-c96d8fe6907f,DISK], DatanodeInfoWithStorage[127.0.0.1:38447,DS-5702e48a-64c7-43f1-815b-cc0b0c87ddbe,DISK], DatanodeInfoWithStorage[127.0.0.1:45674,DS-d9db954c-8e55-4872-a94f-911be9395765,DISK], DatanodeInfoWithStorage[127.0.0.1:39356,DS-da651c20-3c18-419f-be04-8d0d6188f16f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1211838784-172.17.0.14-1597656531800:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38971,DS-56b64093-4083-4443-aa63-daef0fe5e149,DISK], DatanodeInfoWithStorage[127.0.0.1:36136,DS-8859f44f-6fa9-48b8-887b-388c854c2e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:36854,DS-be6e3897-6563-4d73-b36a-6abbe9080900,DISK], DatanodeInfoWithStorage[127.0.0.1:42554,DS-559456b4-f2c6-49e1-a7db-2efbe10123c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36202,DS-3ebc425f-49ff-4e72-a6b3-401fe4d90dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:37855,DS-b6cf2dac-4586-4245-b1d4-d81818d6da5e,DISK], DatanodeInfoWithStorage[127.0.0.1:43627,DS-9967bb41-874f-4c36-bb5c-c1e82adaa762,DISK], DatanodeInfoWithStorage[127.0.0.1:33921,DS-18fc6a9b-ff59-4869-897a-966ba43642de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1211838784-172.17.0.14-1597656531800:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38971,DS-56b64093-4083-4443-aa63-daef0fe5e149,DISK], DatanodeInfoWithStorage[127.0.0.1:36136,DS-8859f44f-6fa9-48b8-887b-388c854c2e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:36854,DS-be6e3897-6563-4d73-b36a-6abbe9080900,DISK], DatanodeInfoWithStorage[127.0.0.1:42554,DS-559456b4-f2c6-49e1-a7db-2efbe10123c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36202,DS-3ebc425f-49ff-4e72-a6b3-401fe4d90dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:37855,DS-b6cf2dac-4586-4245-b1d4-d81818d6da5e,DISK], DatanodeInfoWithStorage[127.0.0.1:43627,DS-9967bb41-874f-4c36-bb5c-c1e82adaa762,DISK], DatanodeInfoWithStorage[127.0.0.1:33921,DS-18fc6a9b-ff59-4869-897a-966ba43642de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1512542925-172.17.0.14-1597656653588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44166,DS-9de34526-e4a1-480e-8489-6fa5e9b6cc96,DISK], DatanodeInfoWithStorage[127.0.0.1:33950,DS-c66b7dfa-e326-40cd-bfcd-5497b77e1212,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-1faa4d50-7a45-49c7-8d02-24bdbef47aca,DISK], DatanodeInfoWithStorage[127.0.0.1:36236,DS-d5e1989a-95eb-4d16-9be3-f03a3466e33b,DISK], DatanodeInfoWithStorage[127.0.0.1:32903,DS-5d5ac4d3-1144-4483-8c1f-deb663069487,DISK], DatanodeInfoWithStorage[127.0.0.1:38111,DS-9eb998f2-d969-43b4-9353-106594dc087a,DISK], DatanodeInfoWithStorage[127.0.0.1:41105,DS-80576842-af09-43da-bf71-d75a018c86df,DISK], DatanodeInfoWithStorage[127.0.0.1:34143,DS-07d101ad-702d-4865-a594-0f3574f2b78f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1512542925-172.17.0.14-1597656653588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44166,DS-9de34526-e4a1-480e-8489-6fa5e9b6cc96,DISK], DatanodeInfoWithStorage[127.0.0.1:33950,DS-c66b7dfa-e326-40cd-bfcd-5497b77e1212,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-1faa4d50-7a45-49c7-8d02-24bdbef47aca,DISK], DatanodeInfoWithStorage[127.0.0.1:36236,DS-d5e1989a-95eb-4d16-9be3-f03a3466e33b,DISK], DatanodeInfoWithStorage[127.0.0.1:32903,DS-5d5ac4d3-1144-4483-8c1f-deb663069487,DISK], DatanodeInfoWithStorage[127.0.0.1:38111,DS-9eb998f2-d969-43b4-9353-106594dc087a,DISK], DatanodeInfoWithStorage[127.0.0.1:41105,DS-80576842-af09-43da-bf71-d75a018c86df,DISK], DatanodeInfoWithStorage[127.0.0.1:34143,DS-07d101ad-702d-4865-a594-0f3574f2b78f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1778954631-172.17.0.14-1597657475615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34718,DS-68830f71-385f-4d83-8c7f-afd6136e6238,DISK], DatanodeInfoWithStorage[127.0.0.1:38676,DS-4d4ce069-67c3-4132-9463-99a0fd0b92b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33989,DS-8b6b8188-8943-4cfc-b90b-7e0af36e8a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35434,DS-72670925-1720-4dfa-b41f-ea9fda09bbef,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-c84054c0-f296-4170-a37d-1929d205865e,DISK], DatanodeInfoWithStorage[127.0.0.1:43602,DS-b20265b7-a41f-493f-a08c-a233a1cb02d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35760,DS-71a815e7-0e88-43eb-ba06-3007a2439aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:33182,DS-d634c0e6-901a-45b9-ab45-d8b3c45b81ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1778954631-172.17.0.14-1597657475615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34718,DS-68830f71-385f-4d83-8c7f-afd6136e6238,DISK], DatanodeInfoWithStorage[127.0.0.1:38676,DS-4d4ce069-67c3-4132-9463-99a0fd0b92b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33989,DS-8b6b8188-8943-4cfc-b90b-7e0af36e8a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35434,DS-72670925-1720-4dfa-b41f-ea9fda09bbef,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-c84054c0-f296-4170-a37d-1929d205865e,DISK], DatanodeInfoWithStorage[127.0.0.1:43602,DS-b20265b7-a41f-493f-a08c-a233a1cb02d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35760,DS-71a815e7-0e88-43eb-ba06-3007a2439aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:33182,DS-d634c0e6-901a-45b9-ab45-d8b3c45b81ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1814160097-172.17.0.14-1597658313837:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42217,DS-19502632-211b-4ff9-9563-64e901aaf931,DISK], DatanodeInfoWithStorage[127.0.0.1:40366,DS-2485256a-15a8-4737-a838-f67c0366f88d,DISK], DatanodeInfoWithStorage[127.0.0.1:36219,DS-556f6b76-7d0c-43ef-b8d7-7ff507dc7cca,DISK], DatanodeInfoWithStorage[127.0.0.1:36093,DS-b9c52eb2-873f-4a64-b9dc-8d8dc6226ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:45542,DS-3927481d-fd32-4f88-b99f-3467e667e4bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39231,DS-adf92636-23a8-4c43-8d94-956c8aa28ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:35717,DS-15f25430-4bd7-4665-904f-9e7b2e5e8edc,DISK], DatanodeInfoWithStorage[127.0.0.1:46085,DS-97dc3e35-de02-41f0-bc3d-cde8c1ad20c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1814160097-172.17.0.14-1597658313837:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42217,DS-19502632-211b-4ff9-9563-64e901aaf931,DISK], DatanodeInfoWithStorage[127.0.0.1:40366,DS-2485256a-15a8-4737-a838-f67c0366f88d,DISK], DatanodeInfoWithStorage[127.0.0.1:36219,DS-556f6b76-7d0c-43ef-b8d7-7ff507dc7cca,DISK], DatanodeInfoWithStorage[127.0.0.1:36093,DS-b9c52eb2-873f-4a64-b9dc-8d8dc6226ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:45542,DS-3927481d-fd32-4f88-b99f-3467e667e4bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39231,DS-adf92636-23a8-4c43-8d94-956c8aa28ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:35717,DS-15f25430-4bd7-4665-904f-9e7b2e5e8edc,DISK], DatanodeInfoWithStorage[127.0.0.1:46085,DS-97dc3e35-de02-41f0-bc3d-cde8c1ad20c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-510093599-172.17.0.14-1597658730015:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41051,DS-30fec4ec-ff57-47fe-9ea1-a43a4b7f3dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:41543,DS-711696d9-0c1d-4cda-bcb4-114afd9a63ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39475,DS-c8ecb7f7-10d7-49dc-b058-9b601bf86eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:44707,DS-f3eecaba-cde6-47e5-87fc-169f39659478,DISK], DatanodeInfoWithStorage[127.0.0.1:43028,DS-11149d7f-04f6-4327-8839-95b8eb1a978c,DISK], DatanodeInfoWithStorage[127.0.0.1:33338,DS-936b8c67-6e0a-4cd6-94d8-c6d62ef7a68a,DISK], DatanodeInfoWithStorage[127.0.0.1:43764,DS-4293e76c-a5b9-4d0c-b92c-6ecf5caf75b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33120,DS-dc515e7f-95bd-4189-9071-62811781d339,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-510093599-172.17.0.14-1597658730015:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41051,DS-30fec4ec-ff57-47fe-9ea1-a43a4b7f3dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:41543,DS-711696d9-0c1d-4cda-bcb4-114afd9a63ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39475,DS-c8ecb7f7-10d7-49dc-b058-9b601bf86eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:44707,DS-f3eecaba-cde6-47e5-87fc-169f39659478,DISK], DatanodeInfoWithStorage[127.0.0.1:43028,DS-11149d7f-04f6-4327-8839-95b8eb1a978c,DISK], DatanodeInfoWithStorage[127.0.0.1:33338,DS-936b8c67-6e0a-4cd6-94d8-c6d62ef7a68a,DISK], DatanodeInfoWithStorage[127.0.0.1:43764,DS-4293e76c-a5b9-4d0c-b92c-6ecf5caf75b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33120,DS-dc515e7f-95bd-4189-9071-62811781d339,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-113021224-172.17.0.14-1597658785829:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44770,DS-c3ed0823-bc0b-49a3-9fce-9a4e5136e79e,DISK], DatanodeInfoWithStorage[127.0.0.1:36531,DS-f7985d48-aed3-468d-9b84-88c02cf15687,DISK], DatanodeInfoWithStorage[127.0.0.1:33087,DS-51d1aa80-ee75-4f20-a9a9-7ee9ae6a30ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45680,DS-ac8ef860-c254-4d01-9231-2037d33ee652,DISK], DatanodeInfoWithStorage[127.0.0.1:35130,DS-24eef727-5e1d-4e73-a123-4e6b08eac9a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42946,DS-47878031-938e-47d1-8f82-35cdee9ca2a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36104,DS-82e7e5bf-e438-42a7-94e6-90ef64096823,DISK], DatanodeInfoWithStorage[127.0.0.1:33460,DS-c3e882b5-d4cb-41c1-ac21-7a6039e6f946,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-113021224-172.17.0.14-1597658785829:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44770,DS-c3ed0823-bc0b-49a3-9fce-9a4e5136e79e,DISK], DatanodeInfoWithStorage[127.0.0.1:36531,DS-f7985d48-aed3-468d-9b84-88c02cf15687,DISK], DatanodeInfoWithStorage[127.0.0.1:33087,DS-51d1aa80-ee75-4f20-a9a9-7ee9ae6a30ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45680,DS-ac8ef860-c254-4d01-9231-2037d33ee652,DISK], DatanodeInfoWithStorage[127.0.0.1:35130,DS-24eef727-5e1d-4e73-a123-4e6b08eac9a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42946,DS-47878031-938e-47d1-8f82-35cdee9ca2a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36104,DS-82e7e5bf-e438-42a7-94e6-90ef64096823,DISK], DatanodeInfoWithStorage[127.0.0.1:33460,DS-c3e882b5-d4cb-41c1-ac21-7a6039e6f946,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1277596207-172.17.0.14-1597659548364:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34479,DS-222789a2-0884-4863-b2ff-9e4b2e783215,DISK], DatanodeInfoWithStorage[127.0.0.1:34553,DS-29692e10-c5cb-4771-aa09-1cb2b4c9ddab,DISK], DatanodeInfoWithStorage[127.0.0.1:35958,DS-bbc9895f-d7ad-4b79-995b-9f7e110c243f,DISK], DatanodeInfoWithStorage[127.0.0.1:42076,DS-a1c29683-d6d7-471d-9962-b723f496c9de,DISK], DatanodeInfoWithStorage[127.0.0.1:46654,DS-58d9cd30-8081-44f7-bca1-45a9cc8cc50b,DISK], DatanodeInfoWithStorage[127.0.0.1:45742,DS-753da2c7-0ea7-4cb3-bf53-ea72e62cc8b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40888,DS-a62428f2-7a93-434e-b8fe-e6d6b3bf963d,DISK], DatanodeInfoWithStorage[127.0.0.1:45506,DS-6c63aeb2-abbc-4e68-a85b-764cbfd0024b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1277596207-172.17.0.14-1597659548364:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34479,DS-222789a2-0884-4863-b2ff-9e4b2e783215,DISK], DatanodeInfoWithStorage[127.0.0.1:34553,DS-29692e10-c5cb-4771-aa09-1cb2b4c9ddab,DISK], DatanodeInfoWithStorage[127.0.0.1:35958,DS-bbc9895f-d7ad-4b79-995b-9f7e110c243f,DISK], DatanodeInfoWithStorage[127.0.0.1:42076,DS-a1c29683-d6d7-471d-9962-b723f496c9de,DISK], DatanodeInfoWithStorage[127.0.0.1:46654,DS-58d9cd30-8081-44f7-bca1-45a9cc8cc50b,DISK], DatanodeInfoWithStorage[127.0.0.1:45742,DS-753da2c7-0ea7-4cb3-bf53-ea72e62cc8b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40888,DS-a62428f2-7a93-434e-b8fe-e6d6b3bf963d,DISK], DatanodeInfoWithStorage[127.0.0.1:45506,DS-6c63aeb2-abbc-4e68-a85b-764cbfd0024b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1494863801-172.17.0.14-1597659596422:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33645,DS-3c5fd6d7-19af-4225-bdf4-5a2ec827f929,DISK], DatanodeInfoWithStorage[127.0.0.1:40255,DS-871df2a1-456c-46f8-8982-023a5b47ea6e,DISK], DatanodeInfoWithStorage[127.0.0.1:43414,DS-0490f043-ef8b-47ea-9d40-bb95d090db59,DISK], DatanodeInfoWithStorage[127.0.0.1:44720,DS-2b6eca79-0e57-4f17-9df5-8fc366a2640c,DISK], DatanodeInfoWithStorage[127.0.0.1:39526,DS-fd92d4ca-61bd-4537-a1fc-db4c1ffb00ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38442,DS-c415ed1f-1a8b-4caa-99df-30a145987829,DISK], DatanodeInfoWithStorage[127.0.0.1:40379,DS-39442946-71a7-4cc0-a594-7241ce9c0f65,DISK], DatanodeInfoWithStorage[127.0.0.1:41440,DS-8840292d-dff7-4d34-aa39-1c100b703200,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1494863801-172.17.0.14-1597659596422:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33645,DS-3c5fd6d7-19af-4225-bdf4-5a2ec827f929,DISK], DatanodeInfoWithStorage[127.0.0.1:40255,DS-871df2a1-456c-46f8-8982-023a5b47ea6e,DISK], DatanodeInfoWithStorage[127.0.0.1:43414,DS-0490f043-ef8b-47ea-9d40-bb95d090db59,DISK], DatanodeInfoWithStorage[127.0.0.1:44720,DS-2b6eca79-0e57-4f17-9df5-8fc366a2640c,DISK], DatanodeInfoWithStorage[127.0.0.1:39526,DS-fd92d4ca-61bd-4537-a1fc-db4c1ffb00ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38442,DS-c415ed1f-1a8b-4caa-99df-30a145987829,DISK], DatanodeInfoWithStorage[127.0.0.1:40379,DS-39442946-71a7-4cc0-a594-7241ce9c0f65,DISK], DatanodeInfoWithStorage[127.0.0.1:41440,DS-8840292d-dff7-4d34-aa39-1c100b703200,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-332504219-172.17.0.14-1597659793618:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42128,DS-bef018f0-724d-4fba-8757-860bbc42fa91,DISK], DatanodeInfoWithStorage[127.0.0.1:39992,DS-b761c1dc-d70e-475e-bef3-62ce2442d085,DISK], DatanodeInfoWithStorage[127.0.0.1:46833,DS-3f3a165f-03a7-4367-ac29-b1e51e85effa,DISK], DatanodeInfoWithStorage[127.0.0.1:33905,DS-238e2698-1a2a-467c-a874-c3f6c7078f51,DISK], DatanodeInfoWithStorage[127.0.0.1:34075,DS-c4b5f5c4-4aa3-4717-b182-f9d50de33e52,DISK], DatanodeInfoWithStorage[127.0.0.1:42832,DS-6ecd0d73-ec40-400e-8460-caf29a9d75f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36972,DS-2f841fe5-402c-4427-bd12-b41795b9882d,DISK], DatanodeInfoWithStorage[127.0.0.1:34184,DS-a1ed5665-3748-4540-978e-848b04f15350,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-332504219-172.17.0.14-1597659793618:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42128,DS-bef018f0-724d-4fba-8757-860bbc42fa91,DISK], DatanodeInfoWithStorage[127.0.0.1:39992,DS-b761c1dc-d70e-475e-bef3-62ce2442d085,DISK], DatanodeInfoWithStorage[127.0.0.1:46833,DS-3f3a165f-03a7-4367-ac29-b1e51e85effa,DISK], DatanodeInfoWithStorage[127.0.0.1:33905,DS-238e2698-1a2a-467c-a874-c3f6c7078f51,DISK], DatanodeInfoWithStorage[127.0.0.1:34075,DS-c4b5f5c4-4aa3-4717-b182-f9d50de33e52,DISK], DatanodeInfoWithStorage[127.0.0.1:42832,DS-6ecd0d73-ec40-400e-8460-caf29a9d75f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36972,DS-2f841fe5-402c-4427-bd12-b41795b9882d,DISK], DatanodeInfoWithStorage[127.0.0.1:34184,DS-a1ed5665-3748-4540-978e-848b04f15350,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1984373016-172.17.0.14-1597659978841:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33564,DS-dbb9151f-378b-4567-b7b2-7517511ae061,DISK], DatanodeInfoWithStorage[127.0.0.1:46817,DS-cf7d6721-2d78-4bd6-bb0b-c9b21a937ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:34381,DS-df234b5c-c03d-4b91-996e-9fa97c942cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:33455,DS-6dbab98d-4190-4278-975f-dd6e8add8d12,DISK], DatanodeInfoWithStorage[127.0.0.1:35081,DS-b31d2d2d-1c12-4e35-aa5d-660f706ae761,DISK], DatanodeInfoWithStorage[127.0.0.1:45584,DS-06cc2fd7-6122-4763-a257-a73e7a12bc22,DISK], DatanodeInfoWithStorage[127.0.0.1:36398,DS-5fedbe4d-dbdc-4cda-ad6e-caa9cd3c250d,DISK], DatanodeInfoWithStorage[127.0.0.1:41691,DS-9091f055-7e70-47fc-aa5b-3eebe5d95ec3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1984373016-172.17.0.14-1597659978841:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33564,DS-dbb9151f-378b-4567-b7b2-7517511ae061,DISK], DatanodeInfoWithStorage[127.0.0.1:46817,DS-cf7d6721-2d78-4bd6-bb0b-c9b21a937ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:34381,DS-df234b5c-c03d-4b91-996e-9fa97c942cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:33455,DS-6dbab98d-4190-4278-975f-dd6e8add8d12,DISK], DatanodeInfoWithStorage[127.0.0.1:35081,DS-b31d2d2d-1c12-4e35-aa5d-660f706ae761,DISK], DatanodeInfoWithStorage[127.0.0.1:45584,DS-06cc2fd7-6122-4763-a257-a73e7a12bc22,DISK], DatanodeInfoWithStorage[127.0.0.1:36398,DS-5fedbe4d-dbdc-4cda-ad6e-caa9cd3c250d,DISK], DatanodeInfoWithStorage[127.0.0.1:41691,DS-9091f055-7e70-47fc-aa5b-3eebe5d95ec3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1391295254-172.17.0.14-1597660727814:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46067,DS-2f15f12a-dc69-47b7-9064-b7df33f62e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:35015,DS-c298f91b-d220-43d1-94d6-95d71cddc54d,DISK], DatanodeInfoWithStorage[127.0.0.1:44977,DS-dbacce53-0187-480f-a8f2-ee9d7944f920,DISK], DatanodeInfoWithStorage[127.0.0.1:38637,DS-415f6966-be55-4121-aa3d-14555178f01a,DISK], DatanodeInfoWithStorage[127.0.0.1:43715,DS-91b06f6e-27d8-4d5f-a567-86e037eb04fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43091,DS-6a1578a5-eb4f-416d-b1cf-fec96d8400ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37675,DS-b1adca65-ffd3-4bec-9560-1d4857ceea24,DISK], DatanodeInfoWithStorage[127.0.0.1:40405,DS-f0f6b351-1345-436a-a104-7227dc01c24a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1391295254-172.17.0.14-1597660727814:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46067,DS-2f15f12a-dc69-47b7-9064-b7df33f62e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:35015,DS-c298f91b-d220-43d1-94d6-95d71cddc54d,DISK], DatanodeInfoWithStorage[127.0.0.1:44977,DS-dbacce53-0187-480f-a8f2-ee9d7944f920,DISK], DatanodeInfoWithStorage[127.0.0.1:38637,DS-415f6966-be55-4121-aa3d-14555178f01a,DISK], DatanodeInfoWithStorage[127.0.0.1:43715,DS-91b06f6e-27d8-4d5f-a567-86e037eb04fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43091,DS-6a1578a5-eb4f-416d-b1cf-fec96d8400ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37675,DS-b1adca65-ffd3-4bec-9560-1d4857ceea24,DISK], DatanodeInfoWithStorage[127.0.0.1:40405,DS-f0f6b351-1345-436a-a104-7227dc01c24a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-264222213-172.17.0.14-1597661616459:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38727,DS-884ca519-58fc-4550-95b5-c01f1b3d43c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43680,DS-0a49881c-df61-4704-be47-ea002ff206b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39916,DS-5c6a5ade-b125-487a-b041-7b63be62e89d,DISK], DatanodeInfoWithStorage[127.0.0.1:40752,DS-c5e76f33-f2a0-474d-8e5e-a24356a9ff30,DISK], DatanodeInfoWithStorage[127.0.0.1:32930,DS-8679fd0e-cb5a-4c14-a749-93d6068a2582,DISK], DatanodeInfoWithStorage[127.0.0.1:40424,DS-7c95d00a-89ea-43a8-af12-268ef153240a,DISK], DatanodeInfoWithStorage[127.0.0.1:41180,DS-735bd3c7-5903-4572-b17d-b9bbe849d810,DISK], DatanodeInfoWithStorage[127.0.0.1:35745,DS-7a9232af-cc36-419d-b63e-270740b4de01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-264222213-172.17.0.14-1597661616459:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38727,DS-884ca519-58fc-4550-95b5-c01f1b3d43c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43680,DS-0a49881c-df61-4704-be47-ea002ff206b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39916,DS-5c6a5ade-b125-487a-b041-7b63be62e89d,DISK], DatanodeInfoWithStorage[127.0.0.1:40752,DS-c5e76f33-f2a0-474d-8e5e-a24356a9ff30,DISK], DatanodeInfoWithStorage[127.0.0.1:32930,DS-8679fd0e-cb5a-4c14-a749-93d6068a2582,DISK], DatanodeInfoWithStorage[127.0.0.1:40424,DS-7c95d00a-89ea-43a8-af12-268ef153240a,DISK], DatanodeInfoWithStorage[127.0.0.1:41180,DS-735bd3c7-5903-4572-b17d-b9bbe849d810,DISK], DatanodeInfoWithStorage[127.0.0.1:35745,DS-7a9232af-cc36-419d-b63e-270740b4de01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1945131399-172.17.0.14-1597661935707:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32947,DS-7e1b02cb-00e4-4604-9ff2-4991847bfb0e,DISK], DatanodeInfoWithStorage[127.0.0.1:36531,DS-316d64ae-c897-4c4f-8677-ab803050859b,DISK], DatanodeInfoWithStorage[127.0.0.1:36153,DS-fad18fe2-67df-4eea-b95a-7147bc1e85a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44402,DS-678ebc65-2c8d-470d-b3af-458a34c984cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41841,DS-05ebd528-1563-40fe-80fd-fbcb50bf6b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45732,DS-2681253d-1f92-402e-93ca-85591e94dd17,DISK], DatanodeInfoWithStorage[127.0.0.1:36220,DS-21a28450-8b84-478d-993e-7e4aaefdf5eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45927,DS-356639d0-b055-460f-87a5-d3bbf469184e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1945131399-172.17.0.14-1597661935707:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32947,DS-7e1b02cb-00e4-4604-9ff2-4991847bfb0e,DISK], DatanodeInfoWithStorage[127.0.0.1:36531,DS-316d64ae-c897-4c4f-8677-ab803050859b,DISK], DatanodeInfoWithStorage[127.0.0.1:36153,DS-fad18fe2-67df-4eea-b95a-7147bc1e85a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44402,DS-678ebc65-2c8d-470d-b3af-458a34c984cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41841,DS-05ebd528-1563-40fe-80fd-fbcb50bf6b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45732,DS-2681253d-1f92-402e-93ca-85591e94dd17,DISK], DatanodeInfoWithStorage[127.0.0.1:36220,DS-21a28450-8b84-478d-993e-7e4aaefdf5eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45927,DS-356639d0-b055-460f-87a5-d3bbf469184e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 6823
