reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 62914560
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 62914560
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-271271991-172.17.0.3-1597578430846:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44327,DS-d353ceb3-a67b-4e4f-ac69-1040989914e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35099,DS-8c2f85ab-a44d-441c-90b2-f7250f163284,DISK], DatanodeInfoWithStorage[127.0.0.1:46748,DS-102cee1f-6283-4e8a-a9f4-decb9f766e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:41507,DS-dc012f33-e47c-45b0-8247-d1761832b6c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39518,DS-6d189914-9187-41e8-abaf-7ec9a314d7de,DISK], DatanodeInfoWithStorage[127.0.0.1:42734,DS-4ae8febe-e338-40f3-b5b7-b6fcbedcf6c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44190,DS-0d717fa1-1e83-4da6-8861-add65a4bc087,DISK], DatanodeInfoWithStorage[127.0.0.1:37873,DS-a42af963-74ab-489d-81e4-8f35f52b6bdc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-271271991-172.17.0.3-1597578430846:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44327,DS-d353ceb3-a67b-4e4f-ac69-1040989914e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35099,DS-8c2f85ab-a44d-441c-90b2-f7250f163284,DISK], DatanodeInfoWithStorage[127.0.0.1:46748,DS-102cee1f-6283-4e8a-a9f4-decb9f766e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:41507,DS-dc012f33-e47c-45b0-8247-d1761832b6c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39518,DS-6d189914-9187-41e8-abaf-7ec9a314d7de,DISK], DatanodeInfoWithStorage[127.0.0.1:42734,DS-4ae8febe-e338-40f3-b5b7-b6fcbedcf6c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44190,DS-0d717fa1-1e83-4da6-8861-add65a4bc087,DISK], DatanodeInfoWithStorage[127.0.0.1:37873,DS-a42af963-74ab-489d-81e4-8f35f52b6bdc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 62914560
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-603904208-172.17.0.3-1597578628357:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39665,DS-08a034bf-911a-4cb1-a411-528a25b845c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34408,DS-37a96a1c-162b-424d-9030-bdb566b89efb,DISK], DatanodeInfoWithStorage[127.0.0.1:35709,DS-930a8ede-ecf0-43c9-b1dd-f0d23ff2b90c,DISK], DatanodeInfoWithStorage[127.0.0.1:38410,DS-97738d5f-cdc0-4d72-b41e-13b4a964c7b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41239,DS-708f1796-f812-458c-9326-53c8e9bd9eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:42299,DS-b782d12b-803c-4828-9bbc-a62fcdbd2ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-1a720c4a-9b50-4aa0-ae34-f1362e775ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:33911,DS-f7e991df-71ca-4446-9063-8e6686ea6288,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-603904208-172.17.0.3-1597578628357:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39665,DS-08a034bf-911a-4cb1-a411-528a25b845c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34408,DS-37a96a1c-162b-424d-9030-bdb566b89efb,DISK], DatanodeInfoWithStorage[127.0.0.1:35709,DS-930a8ede-ecf0-43c9-b1dd-f0d23ff2b90c,DISK], DatanodeInfoWithStorage[127.0.0.1:38410,DS-97738d5f-cdc0-4d72-b41e-13b4a964c7b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41239,DS-708f1796-f812-458c-9326-53c8e9bd9eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:42299,DS-b782d12b-803c-4828-9bbc-a62fcdbd2ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-1a720c4a-9b50-4aa0-ae34-f1362e775ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:33911,DS-f7e991df-71ca-4446-9063-8e6686ea6288,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 62914560
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-891377160-172.17.0.3-1597579448800:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43141,DS-5da256e2-d1b2-4112-bb2d-300ac8f45d58,DISK], DatanodeInfoWithStorage[127.0.0.1:43024,DS-99360c23-6c81-413a-b4b4-51776de908b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42802,DS-ea72c628-6df6-4952-885e-8decd6e99227,DISK], DatanodeInfoWithStorage[127.0.0.1:45869,DS-3ca8412c-589a-4542-bfd9-c8641a1a6587,DISK], DatanodeInfoWithStorage[127.0.0.1:46600,DS-d983be7a-1ee4-4ca9-a736-d07014fa5715,DISK], DatanodeInfoWithStorage[127.0.0.1:32992,DS-07605940-daaf-4ecf-a766-41c20399a479,DISK], DatanodeInfoWithStorage[127.0.0.1:41349,DS-07138160-c0a1-45f2-bb6d-4892d896ebf9,DISK], DatanodeInfoWithStorage[127.0.0.1:40166,DS-938c0c85-ef65-4a80-8c3d-ac1d361c32af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-891377160-172.17.0.3-1597579448800:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43141,DS-5da256e2-d1b2-4112-bb2d-300ac8f45d58,DISK], DatanodeInfoWithStorage[127.0.0.1:43024,DS-99360c23-6c81-413a-b4b4-51776de908b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42802,DS-ea72c628-6df6-4952-885e-8decd6e99227,DISK], DatanodeInfoWithStorage[127.0.0.1:45869,DS-3ca8412c-589a-4542-bfd9-c8641a1a6587,DISK], DatanodeInfoWithStorage[127.0.0.1:46600,DS-d983be7a-1ee4-4ca9-a736-d07014fa5715,DISK], DatanodeInfoWithStorage[127.0.0.1:32992,DS-07605940-daaf-4ecf-a766-41c20399a479,DISK], DatanodeInfoWithStorage[127.0.0.1:41349,DS-07138160-c0a1-45f2-bb6d-4892d896ebf9,DISK], DatanodeInfoWithStorage[127.0.0.1:40166,DS-938c0c85-ef65-4a80-8c3d-ac1d361c32af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 62914560
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2056892874-172.17.0.3-1597579676107:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38739,DS-4705fcd9-6ba4-4f1d-a124-5d63c597bda2,DISK], DatanodeInfoWithStorage[127.0.0.1:33212,DS-d35a63c4-da51-4911-87da-fad699072700,DISK], DatanodeInfoWithStorage[127.0.0.1:37858,DS-894babbb-a3d0-453c-9446-60a40bfa1994,DISK], DatanodeInfoWithStorage[127.0.0.1:33484,DS-bb576eb3-6da6-4bfe-83fb-41d333a25c54,DISK], DatanodeInfoWithStorage[127.0.0.1:44992,DS-455a72b5-5703-418a-818a-2b18d1a9f07f,DISK], DatanodeInfoWithStorage[127.0.0.1:41142,DS-be507682-76cd-41ae-9e6a-c45f92693fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:33258,DS-15979619-96b8-4249-82d6-4a0a7c0268a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39285,DS-2d74777e-6371-4816-a633-ff3650ae8eeb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2056892874-172.17.0.3-1597579676107:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38739,DS-4705fcd9-6ba4-4f1d-a124-5d63c597bda2,DISK], DatanodeInfoWithStorage[127.0.0.1:33212,DS-d35a63c4-da51-4911-87da-fad699072700,DISK], DatanodeInfoWithStorage[127.0.0.1:37858,DS-894babbb-a3d0-453c-9446-60a40bfa1994,DISK], DatanodeInfoWithStorage[127.0.0.1:33484,DS-bb576eb3-6da6-4bfe-83fb-41d333a25c54,DISK], DatanodeInfoWithStorage[127.0.0.1:44992,DS-455a72b5-5703-418a-818a-2b18d1a9f07f,DISK], DatanodeInfoWithStorage[127.0.0.1:41142,DS-be507682-76cd-41ae-9e6a-c45f92693fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:33258,DS-15979619-96b8-4249-82d6-4a0a7c0268a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39285,DS-2d74777e-6371-4816-a633-ff3650ae8eeb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 62914560
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-542626537-172.17.0.3-1597579750317:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44759,DS-cab2553d-dd9d-4c4d-80f0-8424a4826ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:36590,DS-0eb57489-8d57-4605-b44f-e2269653c883,DISK], DatanodeInfoWithStorage[127.0.0.1:33110,DS-a91f255d-d5f0-4173-bf79-e9b71ead15e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42943,DS-d4925334-9fbd-45f8-b236-8ddc6925270d,DISK], DatanodeInfoWithStorage[127.0.0.1:39620,DS-c004b318-c77e-4d29-8e97-e165c033ba75,DISK], DatanodeInfoWithStorage[127.0.0.1:35695,DS-d13dfba9-130f-4542-8b3e-4c1aee60558f,DISK], DatanodeInfoWithStorage[127.0.0.1:38070,DS-775ddc3e-3905-4d85-a893-192076952d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43167,DS-62bd9725-ba48-430d-b8c3-616d55c735dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-542626537-172.17.0.3-1597579750317:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44759,DS-cab2553d-dd9d-4c4d-80f0-8424a4826ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:36590,DS-0eb57489-8d57-4605-b44f-e2269653c883,DISK], DatanodeInfoWithStorage[127.0.0.1:33110,DS-a91f255d-d5f0-4173-bf79-e9b71ead15e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42943,DS-d4925334-9fbd-45f8-b236-8ddc6925270d,DISK], DatanodeInfoWithStorage[127.0.0.1:39620,DS-c004b318-c77e-4d29-8e97-e165c033ba75,DISK], DatanodeInfoWithStorage[127.0.0.1:35695,DS-d13dfba9-130f-4542-8b3e-4c1aee60558f,DISK], DatanodeInfoWithStorage[127.0.0.1:38070,DS-775ddc3e-3905-4d85-a893-192076952d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43167,DS-62bd9725-ba48-430d-b8c3-616d55c735dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 62914560
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1888320112-172.17.0.3-1597579870912:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33867,DS-2b141578-2328-490d-8f5e-09e8afd617b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45180,DS-fdc9db39-d01f-4136-8405-1dacb6e29509,DISK], DatanodeInfoWithStorage[127.0.0.1:37899,DS-909f7efa-b4ea-414a-b346-2cc944cb88bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46569,DS-f902b655-4016-4724-b6b3-bb8f0ae0552e,DISK], DatanodeInfoWithStorage[127.0.0.1:40320,DS-4052a9bb-abf3-4585-a8fb-54eb7efdf68e,DISK], DatanodeInfoWithStorage[127.0.0.1:44706,DS-d6262c03-bc8f-4d90-b585-5047f3dba2ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40076,DS-0f8b595b-ffe2-4ceb-bc30-1d91ad9f504f,DISK], DatanodeInfoWithStorage[127.0.0.1:36997,DS-42c87aa9-36d7-4f1d-a704-d65567b7168f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1888320112-172.17.0.3-1597579870912:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33867,DS-2b141578-2328-490d-8f5e-09e8afd617b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45180,DS-fdc9db39-d01f-4136-8405-1dacb6e29509,DISK], DatanodeInfoWithStorage[127.0.0.1:37899,DS-909f7efa-b4ea-414a-b346-2cc944cb88bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46569,DS-f902b655-4016-4724-b6b3-bb8f0ae0552e,DISK], DatanodeInfoWithStorage[127.0.0.1:40320,DS-4052a9bb-abf3-4585-a8fb-54eb7efdf68e,DISK], DatanodeInfoWithStorage[127.0.0.1:44706,DS-d6262c03-bc8f-4d90-b585-5047f3dba2ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40076,DS-0f8b595b-ffe2-4ceb-bc30-1d91ad9f504f,DISK], DatanodeInfoWithStorage[127.0.0.1:36997,DS-42c87aa9-36d7-4f1d-a704-d65567b7168f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 62914560
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1847155878-172.17.0.3-1597579920142:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46276,DS-cf975603-51a5-453c-b2c7-259b8b2f73d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35239,DS-64aa638e-b95e-4dea-b5d1-41898f826470,DISK], DatanodeInfoWithStorage[127.0.0.1:34423,DS-47510f9c-4168-4fb2-a0f9-cde2126ff883,DISK], DatanodeInfoWithStorage[127.0.0.1:45113,DS-fd35f922-9ace-47fe-b301-c51ce792d781,DISK], DatanodeInfoWithStorage[127.0.0.1:38088,DS-f2d2a726-b6e5-4963-9442-49194da6ba9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35101,DS-0866edc1-2cab-4b86-8487-3b5d5c682f20,DISK], DatanodeInfoWithStorage[127.0.0.1:45347,DS-fbaf6ac6-dd26-47c0-838b-130ed29bf665,DISK], DatanodeInfoWithStorage[127.0.0.1:36899,DS-ad355c03-ab71-46f6-a0a1-75defa723cbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1847155878-172.17.0.3-1597579920142:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46276,DS-cf975603-51a5-453c-b2c7-259b8b2f73d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35239,DS-64aa638e-b95e-4dea-b5d1-41898f826470,DISK], DatanodeInfoWithStorage[127.0.0.1:34423,DS-47510f9c-4168-4fb2-a0f9-cde2126ff883,DISK], DatanodeInfoWithStorage[127.0.0.1:45113,DS-fd35f922-9ace-47fe-b301-c51ce792d781,DISK], DatanodeInfoWithStorage[127.0.0.1:38088,DS-f2d2a726-b6e5-4963-9442-49194da6ba9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35101,DS-0866edc1-2cab-4b86-8487-3b5d5c682f20,DISK], DatanodeInfoWithStorage[127.0.0.1:45347,DS-fbaf6ac6-dd26-47c0-838b-130ed29bf665,DISK], DatanodeInfoWithStorage[127.0.0.1:36899,DS-ad355c03-ab71-46f6-a0a1-75defa723cbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 62914560
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-22103137-172.17.0.3-1597580426553:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34348,DS-09ce671b-faf2-4a03-9bfb-41cdfc73ac6b,DISK], DatanodeInfoWithStorage[127.0.0.1:37463,DS-116ef1d0-86bc-4559-a434-63053f5f738d,DISK], DatanodeInfoWithStorage[127.0.0.1:40914,DS-e274e461-a5cf-4fb9-96f1-438f528c8a54,DISK], DatanodeInfoWithStorage[127.0.0.1:36557,DS-f4a27b70-4872-49b6-9982-f08b5d135a54,DISK], DatanodeInfoWithStorage[127.0.0.1:40916,DS-0bb985c9-854f-485e-a2b9-1483511aed00,DISK], DatanodeInfoWithStorage[127.0.0.1:34334,DS-a0a70bb8-517d-44cf-8818-88a6b6727421,DISK], DatanodeInfoWithStorage[127.0.0.1:36723,DS-16f676c6-d7ae-421f-bda7-120ecebe3570,DISK], DatanodeInfoWithStorage[127.0.0.1:35426,DS-306d0b7e-23fc-4c06-b0f8-e7788f0ba246,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-22103137-172.17.0.3-1597580426553:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34348,DS-09ce671b-faf2-4a03-9bfb-41cdfc73ac6b,DISK], DatanodeInfoWithStorage[127.0.0.1:37463,DS-116ef1d0-86bc-4559-a434-63053f5f738d,DISK], DatanodeInfoWithStorage[127.0.0.1:40914,DS-e274e461-a5cf-4fb9-96f1-438f528c8a54,DISK], DatanodeInfoWithStorage[127.0.0.1:36557,DS-f4a27b70-4872-49b6-9982-f08b5d135a54,DISK], DatanodeInfoWithStorage[127.0.0.1:40916,DS-0bb985c9-854f-485e-a2b9-1483511aed00,DISK], DatanodeInfoWithStorage[127.0.0.1:34334,DS-a0a70bb8-517d-44cf-8818-88a6b6727421,DISK], DatanodeInfoWithStorage[127.0.0.1:36723,DS-16f676c6-d7ae-421f-bda7-120ecebe3570,DISK], DatanodeInfoWithStorage[127.0.0.1:35426,DS-306d0b7e-23fc-4c06-b0f8-e7788f0ba246,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 62914560
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-301544427-172.17.0.3-1597580672790:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38203,DS-a6c757ce-e520-47dd-a61b-e42d3a4a670f,DISK], DatanodeInfoWithStorage[127.0.0.1:35732,DS-076bd315-8ba0-4527-b230-69525a0be31e,DISK], DatanodeInfoWithStorage[127.0.0.1:40621,DS-8bc5217a-dc26-467e-b011-65527720c1ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44029,DS-0205df45-0255-4821-ad19-57b2ed63d15c,DISK], DatanodeInfoWithStorage[127.0.0.1:41383,DS-52b42383-fc00-46f2-a433-66b4bd9c445e,DISK], DatanodeInfoWithStorage[127.0.0.1:37804,DS-5d51834c-9589-4644-91cd-ba1d931a3a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:43883,DS-b03896e5-1a27-43b3-89e6-48e0021d4ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:35233,DS-ad388a9d-b1bb-4ea4-81a8-ff1ca29c7d57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-301544427-172.17.0.3-1597580672790:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38203,DS-a6c757ce-e520-47dd-a61b-e42d3a4a670f,DISK], DatanodeInfoWithStorage[127.0.0.1:35732,DS-076bd315-8ba0-4527-b230-69525a0be31e,DISK], DatanodeInfoWithStorage[127.0.0.1:40621,DS-8bc5217a-dc26-467e-b011-65527720c1ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44029,DS-0205df45-0255-4821-ad19-57b2ed63d15c,DISK], DatanodeInfoWithStorage[127.0.0.1:41383,DS-52b42383-fc00-46f2-a433-66b4bd9c445e,DISK], DatanodeInfoWithStorage[127.0.0.1:37804,DS-5d51834c-9589-4644-91cd-ba1d931a3a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:43883,DS-b03896e5-1a27-43b3-89e6-48e0021d4ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:35233,DS-ad388a9d-b1bb-4ea4-81a8-ff1ca29c7d57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 62914560
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1784041733-172.17.0.3-1597580951752:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40063,DS-f4999b89-d032-4613-8c93-e2fadd1995a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37090,DS-b768eee0-41de-472f-bb7c-5113de52136a,DISK], DatanodeInfoWithStorage[127.0.0.1:38449,DS-6677c18e-80f2-4720-8054-f85a6f9f72c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39117,DS-a5419b85-f134-45cd-8071-06f87d159b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39693,DS-e9a597ca-ad48-47e4-acef-b679e9f70c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:46135,DS-e74e4d5b-2b1e-4c34-b64d-cb8a7836f46d,DISK], DatanodeInfoWithStorage[127.0.0.1:41385,DS-55bf56d3-832f-48c9-aa44-4868fc8668f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36056,DS-95dbf9ce-67e0-4bd0-9a3b-30cf7e66dfb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1784041733-172.17.0.3-1597580951752:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40063,DS-f4999b89-d032-4613-8c93-e2fadd1995a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37090,DS-b768eee0-41de-472f-bb7c-5113de52136a,DISK], DatanodeInfoWithStorage[127.0.0.1:38449,DS-6677c18e-80f2-4720-8054-f85a6f9f72c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39117,DS-a5419b85-f134-45cd-8071-06f87d159b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39693,DS-e9a597ca-ad48-47e4-acef-b679e9f70c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:46135,DS-e74e4d5b-2b1e-4c34-b64d-cb8a7836f46d,DISK], DatanodeInfoWithStorage[127.0.0.1:41385,DS-55bf56d3-832f-48c9-aa44-4868fc8668f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36056,DS-95dbf9ce-67e0-4bd0-9a3b-30cf7e66dfb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 5 out of 50
result: false positive !!!
Total execution time in seconds : 4021
