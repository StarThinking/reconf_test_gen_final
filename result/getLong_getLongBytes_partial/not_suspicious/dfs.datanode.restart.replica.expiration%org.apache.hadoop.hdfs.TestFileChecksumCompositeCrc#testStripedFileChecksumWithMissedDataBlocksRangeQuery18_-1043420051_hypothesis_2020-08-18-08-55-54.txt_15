reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1540837536-172.17.0.21-1597741123520:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44206,DS-c2f32a5f-70c2-42da-adff-3329475c65a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44020,DS-12b2111e-0b4c-47b4-9ef6-4132e555aa0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39634,DS-250c4fde-0bab-4eb0-809d-062fec3fbefc,DISK], DatanodeInfoWithStorage[127.0.0.1:33113,DS-1734b8a2-bea2-4384-8c61-ab83d689e30c,DISK], DatanodeInfoWithStorage[127.0.0.1:39590,DS-bbbf7df9-6535-4e2d-9baf-2c4242876132,DISK], DatanodeInfoWithStorage[127.0.0.1:37707,DS-8a61f6d6-479b-4df6-82ca-f1dfcec8e8f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37461,DS-6ee0b08d-aa0d-4223-a27d-394761c51a10,DISK], DatanodeInfoWithStorage[127.0.0.1:40997,DS-2b093f17-84b5-4c8d-912a-ec6547d87dfb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1540837536-172.17.0.21-1597741123520:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44206,DS-c2f32a5f-70c2-42da-adff-3329475c65a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44020,DS-12b2111e-0b4c-47b4-9ef6-4132e555aa0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39634,DS-250c4fde-0bab-4eb0-809d-062fec3fbefc,DISK], DatanodeInfoWithStorage[127.0.0.1:33113,DS-1734b8a2-bea2-4384-8c61-ab83d689e30c,DISK], DatanodeInfoWithStorage[127.0.0.1:39590,DS-bbbf7df9-6535-4e2d-9baf-2c4242876132,DISK], DatanodeInfoWithStorage[127.0.0.1:37707,DS-8a61f6d6-479b-4df6-82ca-f1dfcec8e8f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37461,DS-6ee0b08d-aa0d-4223-a27d-394761c51a10,DISK], DatanodeInfoWithStorage[127.0.0.1:40997,DS-2b093f17-84b5-4c8d-912a-ec6547d87dfb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1244896801-172.17.0.21-1597741161943:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39866,DS-0eccfb30-097f-48de-ab02-58cc5e79f499,DISK], DatanodeInfoWithStorage[127.0.0.1:46556,DS-59393d59-cba4-4853-b67b-40f7858c81e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42643,DS-97d22c99-1916-49a8-b3b3-790dbb9b8c74,DISK], DatanodeInfoWithStorage[127.0.0.1:46709,DS-2a38f394-085c-447c-b9aa-5915c74e5b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:33907,DS-fe92695a-578f-4d82-bec8-f46acbf4e567,DISK], DatanodeInfoWithStorage[127.0.0.1:37368,DS-0110770d-10db-4663-9cc3-e2f7bca7bbef,DISK], DatanodeInfoWithStorage[127.0.0.1:44494,DS-16d62fac-bca8-4e08-a976-00b0b13b5e62,DISK], DatanodeInfoWithStorage[127.0.0.1:37743,DS-7c9ade2d-fab1-4ab2-b29b-71b3b2d5f7e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1244896801-172.17.0.21-1597741161943:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39866,DS-0eccfb30-097f-48de-ab02-58cc5e79f499,DISK], DatanodeInfoWithStorage[127.0.0.1:46556,DS-59393d59-cba4-4853-b67b-40f7858c81e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42643,DS-97d22c99-1916-49a8-b3b3-790dbb9b8c74,DISK], DatanodeInfoWithStorage[127.0.0.1:46709,DS-2a38f394-085c-447c-b9aa-5915c74e5b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:33907,DS-fe92695a-578f-4d82-bec8-f46acbf4e567,DISK], DatanodeInfoWithStorage[127.0.0.1:37368,DS-0110770d-10db-4663-9cc3-e2f7bca7bbef,DISK], DatanodeInfoWithStorage[127.0.0.1:44494,DS-16d62fac-bca8-4e08-a976-00b0b13b5e62,DISK], DatanodeInfoWithStorage[127.0.0.1:37743,DS-7c9ade2d-fab1-4ab2-b29b-71b3b2d5f7e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-764587464-172.17.0.21-1597741355081:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38830,DS-b7c3ab8b-33b0-4e3f-b2b0-58a516e12e77,DISK], DatanodeInfoWithStorage[127.0.0.1:41844,DS-bf543570-ac68-45ef-82e1-6e265cfcb26b,DISK], DatanodeInfoWithStorage[127.0.0.1:46201,DS-199b57d1-5d71-46d9-bdbd-725269e5a5cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37338,DS-3fef6c89-996e-450d-b754-7e88be7bda21,DISK], DatanodeInfoWithStorage[127.0.0.1:33535,DS-a36db76e-f030-440f-9f0a-d3e383b39083,DISK], DatanodeInfoWithStorage[127.0.0.1:43395,DS-eb57c8d9-29f0-4752-ae10-57791345bc7a,DISK], DatanodeInfoWithStorage[127.0.0.1:41153,DS-2e9e88cc-02ff-46c0-aabf-b6142266b310,DISK], DatanodeInfoWithStorage[127.0.0.1:33726,DS-3a6b1919-791b-4925-b6f7-b0220fbe2576,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-764587464-172.17.0.21-1597741355081:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38830,DS-b7c3ab8b-33b0-4e3f-b2b0-58a516e12e77,DISK], DatanodeInfoWithStorage[127.0.0.1:41844,DS-bf543570-ac68-45ef-82e1-6e265cfcb26b,DISK], DatanodeInfoWithStorage[127.0.0.1:46201,DS-199b57d1-5d71-46d9-bdbd-725269e5a5cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37338,DS-3fef6c89-996e-450d-b754-7e88be7bda21,DISK], DatanodeInfoWithStorage[127.0.0.1:33535,DS-a36db76e-f030-440f-9f0a-d3e383b39083,DISK], DatanodeInfoWithStorage[127.0.0.1:43395,DS-eb57c8d9-29f0-4752-ae10-57791345bc7a,DISK], DatanodeInfoWithStorage[127.0.0.1:41153,DS-2e9e88cc-02ff-46c0-aabf-b6142266b310,DISK], DatanodeInfoWithStorage[127.0.0.1:33726,DS-3a6b1919-791b-4925-b6f7-b0220fbe2576,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1629837858-172.17.0.21-1597742279284:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32890,DS-95a8cdb0-6f97-43d9-ad89-44d35434d043,DISK], DatanodeInfoWithStorage[127.0.0.1:37935,DS-9ec186a1-06b8-4a75-82c4-a07af697fa1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39600,DS-f8427db4-a84f-4797-8043-b65de1bba10d,DISK], DatanodeInfoWithStorage[127.0.0.1:43180,DS-30aa3b22-0beb-4219-ab7d-f327d1f11601,DISK], DatanodeInfoWithStorage[127.0.0.1:36349,DS-6a100bbf-619f-4478-8b05-9e3e365b52b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40861,DS-30b0d7ed-5882-48c4-b4ec-c867050d72ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40587,DS-c5ff29e4-adc1-4dda-85e8-2c5337efbe39,DISK], DatanodeInfoWithStorage[127.0.0.1:46336,DS-7a84f0be-9b23-4570-b25d-0d80ee2fe2f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1629837858-172.17.0.21-1597742279284:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32890,DS-95a8cdb0-6f97-43d9-ad89-44d35434d043,DISK], DatanodeInfoWithStorage[127.0.0.1:37935,DS-9ec186a1-06b8-4a75-82c4-a07af697fa1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39600,DS-f8427db4-a84f-4797-8043-b65de1bba10d,DISK], DatanodeInfoWithStorage[127.0.0.1:43180,DS-30aa3b22-0beb-4219-ab7d-f327d1f11601,DISK], DatanodeInfoWithStorage[127.0.0.1:36349,DS-6a100bbf-619f-4478-8b05-9e3e365b52b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40861,DS-30b0d7ed-5882-48c4-b4ec-c867050d72ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40587,DS-c5ff29e4-adc1-4dda-85e8-2c5337efbe39,DISK], DatanodeInfoWithStorage[127.0.0.1:46336,DS-7a84f0be-9b23-4570-b25d-0d80ee2fe2f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2128932242-172.17.0.21-1597742426617:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40152,DS-5d8c5518-d925-46af-ac5b-716d9a954d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:38218,DS-456bfe3d-8328-41c0-9cdb-b03c1c5e9115,DISK], DatanodeInfoWithStorage[127.0.0.1:36892,DS-f8988530-88cd-4d6f-b8d1-642e83a051f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46679,DS-df6475ac-1159-4d44-8bb6-30a1aca70356,DISK], DatanodeInfoWithStorage[127.0.0.1:41652,DS-bb5f1266-35fc-42f3-9923-0e64304a4e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38393,DS-06cad9c0-8a7d-4e33-a2ae-a516c166e167,DISK], DatanodeInfoWithStorage[127.0.0.1:40700,DS-b35ce1c7-000d-49dd-94a1-e12a0bfb723e,DISK], DatanodeInfoWithStorage[127.0.0.1:44751,DS-1351882b-3b23-44d8-a297-e75ca63c5f72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2128932242-172.17.0.21-1597742426617:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40152,DS-5d8c5518-d925-46af-ac5b-716d9a954d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:38218,DS-456bfe3d-8328-41c0-9cdb-b03c1c5e9115,DISK], DatanodeInfoWithStorage[127.0.0.1:36892,DS-f8988530-88cd-4d6f-b8d1-642e83a051f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46679,DS-df6475ac-1159-4d44-8bb6-30a1aca70356,DISK], DatanodeInfoWithStorage[127.0.0.1:41652,DS-bb5f1266-35fc-42f3-9923-0e64304a4e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38393,DS-06cad9c0-8a7d-4e33-a2ae-a516c166e167,DISK], DatanodeInfoWithStorage[127.0.0.1:40700,DS-b35ce1c7-000d-49dd-94a1-e12a0bfb723e,DISK], DatanodeInfoWithStorage[127.0.0.1:44751,DS-1351882b-3b23-44d8-a297-e75ca63c5f72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1707052498-172.17.0.21-1597742607131:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45065,DS-859d6c74-3c9e-4836-8e2e-1557675c8786,DISK], DatanodeInfoWithStorage[127.0.0.1:44995,DS-15c771bb-c8de-4871-a04f-52b0f8462009,DISK], DatanodeInfoWithStorage[127.0.0.1:38551,DS-f41d3d69-fe66-4294-8ccc-c55452f5085a,DISK], DatanodeInfoWithStorage[127.0.0.1:34147,DS-f0ba72a3-c699-4b59-a85a-fea6926a5eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:43064,DS-c7e1f71b-1cc7-4ae5-907e-a3d0c4499a09,DISK], DatanodeInfoWithStorage[127.0.0.1:41450,DS-1c5c21f1-7189-43a4-93d6-ab6375c20d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:46036,DS-c9a077f6-3118-4c95-9e47-4045bbecdbbe,DISK], DatanodeInfoWithStorage[127.0.0.1:36977,DS-109c3336-10c7-4c14-be3d-46369f0fc270,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1707052498-172.17.0.21-1597742607131:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45065,DS-859d6c74-3c9e-4836-8e2e-1557675c8786,DISK], DatanodeInfoWithStorage[127.0.0.1:44995,DS-15c771bb-c8de-4871-a04f-52b0f8462009,DISK], DatanodeInfoWithStorage[127.0.0.1:38551,DS-f41d3d69-fe66-4294-8ccc-c55452f5085a,DISK], DatanodeInfoWithStorage[127.0.0.1:34147,DS-f0ba72a3-c699-4b59-a85a-fea6926a5eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:43064,DS-c7e1f71b-1cc7-4ae5-907e-a3d0c4499a09,DISK], DatanodeInfoWithStorage[127.0.0.1:41450,DS-1c5c21f1-7189-43a4-93d6-ab6375c20d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:46036,DS-c9a077f6-3118-4c95-9e47-4045bbecdbbe,DISK], DatanodeInfoWithStorage[127.0.0.1:36977,DS-109c3336-10c7-4c14-be3d-46369f0fc270,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-118938156-172.17.0.21-1597743256605:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43799,DS-c4268a94-e57c-48c4-b699-b1bcd5b9afc4,DISK], DatanodeInfoWithStorage[127.0.0.1:33485,DS-13aa5cdd-7590-45d8-881e-3d20afb9ccd0,DISK], DatanodeInfoWithStorage[127.0.0.1:42328,DS-22236250-2f14-49e5-b431-aed3e0f889b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41607,DS-0f07348d-8b2b-4121-9609-5d87ad571a95,DISK], DatanodeInfoWithStorage[127.0.0.1:40388,DS-d797183a-a11b-4a4b-9b30-3e7e84bec5c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41777,DS-3a2deed5-3f92-44e0-9a13-9e2977dd1f26,DISK], DatanodeInfoWithStorage[127.0.0.1:44718,DS-3fc170ef-780e-4c76-b404-c8fff3f0ac38,DISK], DatanodeInfoWithStorage[127.0.0.1:45763,DS-65f5ff8d-24d6-4fc9-8245-b1ba5c977d67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-118938156-172.17.0.21-1597743256605:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43799,DS-c4268a94-e57c-48c4-b699-b1bcd5b9afc4,DISK], DatanodeInfoWithStorage[127.0.0.1:33485,DS-13aa5cdd-7590-45d8-881e-3d20afb9ccd0,DISK], DatanodeInfoWithStorage[127.0.0.1:42328,DS-22236250-2f14-49e5-b431-aed3e0f889b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41607,DS-0f07348d-8b2b-4121-9609-5d87ad571a95,DISK], DatanodeInfoWithStorage[127.0.0.1:40388,DS-d797183a-a11b-4a4b-9b30-3e7e84bec5c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41777,DS-3a2deed5-3f92-44e0-9a13-9e2977dd1f26,DISK], DatanodeInfoWithStorage[127.0.0.1:44718,DS-3fc170ef-780e-4c76-b404-c8fff3f0ac38,DISK], DatanodeInfoWithStorage[127.0.0.1:45763,DS-65f5ff8d-24d6-4fc9-8245-b1ba5c977d67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-987848300-172.17.0.21-1597743468065:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43539,DS-fd122334-b6b1-4281-a188-e49b3b660fad,DISK], DatanodeInfoWithStorage[127.0.0.1:42553,DS-1d96bb7b-0c90-458f-8c1e-e0add159336a,DISK], DatanodeInfoWithStorage[127.0.0.1:42931,DS-57de43a0-1fd5-4616-833e-ed2bee651295,DISK], DatanodeInfoWithStorage[127.0.0.1:39329,DS-158e2ead-03d8-45e0-b95a-ec0daddc9af1,DISK], DatanodeInfoWithStorage[127.0.0.1:37441,DS-72fbad76-212f-44bb-b398-a0b3e55c5000,DISK], DatanodeInfoWithStorage[127.0.0.1:45491,DS-eae3a312-4351-4aa0-b59b-a1e4953355c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40901,DS-83529d6d-5e93-4d1b-8d03-e741b25a1d96,DISK], DatanodeInfoWithStorage[127.0.0.1:45882,DS-36a14295-7fe5-4ee9-9c21-3b9e1d5c04bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-987848300-172.17.0.21-1597743468065:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43539,DS-fd122334-b6b1-4281-a188-e49b3b660fad,DISK], DatanodeInfoWithStorage[127.0.0.1:42553,DS-1d96bb7b-0c90-458f-8c1e-e0add159336a,DISK], DatanodeInfoWithStorage[127.0.0.1:42931,DS-57de43a0-1fd5-4616-833e-ed2bee651295,DISK], DatanodeInfoWithStorage[127.0.0.1:39329,DS-158e2ead-03d8-45e0-b95a-ec0daddc9af1,DISK], DatanodeInfoWithStorage[127.0.0.1:37441,DS-72fbad76-212f-44bb-b398-a0b3e55c5000,DISK], DatanodeInfoWithStorage[127.0.0.1:45491,DS-eae3a312-4351-4aa0-b59b-a1e4953355c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40901,DS-83529d6d-5e93-4d1b-8d03-e741b25a1d96,DISK], DatanodeInfoWithStorage[127.0.0.1:45882,DS-36a14295-7fe5-4ee9-9c21-3b9e1d5c04bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-792402883-172.17.0.21-1597744820033:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46529,DS-8f8484af-86cf-404d-be35-9f3652a85822,DISK], DatanodeInfoWithStorage[127.0.0.1:45281,DS-5a553bbd-8f99-4009-8fdb-a37adffa886d,DISK], DatanodeInfoWithStorage[127.0.0.1:46507,DS-7e6b73fc-3a99-4b06-ba69-e35d3cf541ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40228,DS-fffb0e99-ea51-4a19-9cfb-078a4531f5b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45070,DS-cc2f6916-8a3c-4c8a-8ea4-cd6eac3459fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41195,DS-07e52409-cd09-43a5-b3f3-5f7e09ddcbd0,DISK], DatanodeInfoWithStorage[127.0.0.1:40270,DS-ef8a283a-bd9d-40dd-ba05-3fb54e524246,DISK], DatanodeInfoWithStorage[127.0.0.1:40026,DS-4833da2d-24c2-4869-9547-d6ad777fed7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-792402883-172.17.0.21-1597744820033:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46529,DS-8f8484af-86cf-404d-be35-9f3652a85822,DISK], DatanodeInfoWithStorage[127.0.0.1:45281,DS-5a553bbd-8f99-4009-8fdb-a37adffa886d,DISK], DatanodeInfoWithStorage[127.0.0.1:46507,DS-7e6b73fc-3a99-4b06-ba69-e35d3cf541ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40228,DS-fffb0e99-ea51-4a19-9cfb-078a4531f5b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45070,DS-cc2f6916-8a3c-4c8a-8ea4-cd6eac3459fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41195,DS-07e52409-cd09-43a5-b3f3-5f7e09ddcbd0,DISK], DatanodeInfoWithStorage[127.0.0.1:40270,DS-ef8a283a-bd9d-40dd-ba05-3fb54e524246,DISK], DatanodeInfoWithStorage[127.0.0.1:40026,DS-4833da2d-24c2-4869-9547-d6ad777fed7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1744853684-172.17.0.21-1597744970801:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39195,DS-66ac0fc2-bc86-4b4e-9e48-43039b553dab,DISK], DatanodeInfoWithStorage[127.0.0.1:45373,DS-e8945f7f-925c-46fd-afd6-259c408f506b,DISK], DatanodeInfoWithStorage[127.0.0.1:38817,DS-bf64def0-adf0-495d-843b-29d02ce81139,DISK], DatanodeInfoWithStorage[127.0.0.1:41970,DS-956e79ad-c6c6-4676-97fc-8a05ba43590a,DISK], DatanodeInfoWithStorage[127.0.0.1:44843,DS-14254138-06d4-45b4-a57d-b37402396799,DISK], DatanodeInfoWithStorage[127.0.0.1:37691,DS-e3dba574-9445-408e-919f-fd09f56d2475,DISK], DatanodeInfoWithStorage[127.0.0.1:40890,DS-260f37dd-1ba6-4172-b562-b03d86fdd391,DISK], DatanodeInfoWithStorage[127.0.0.1:41283,DS-fb088b6c-585f-42cc-9d5b-8f1812d5b64f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1744853684-172.17.0.21-1597744970801:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39195,DS-66ac0fc2-bc86-4b4e-9e48-43039b553dab,DISK], DatanodeInfoWithStorage[127.0.0.1:45373,DS-e8945f7f-925c-46fd-afd6-259c408f506b,DISK], DatanodeInfoWithStorage[127.0.0.1:38817,DS-bf64def0-adf0-495d-843b-29d02ce81139,DISK], DatanodeInfoWithStorage[127.0.0.1:41970,DS-956e79ad-c6c6-4676-97fc-8a05ba43590a,DISK], DatanodeInfoWithStorage[127.0.0.1:44843,DS-14254138-06d4-45b4-a57d-b37402396799,DISK], DatanodeInfoWithStorage[127.0.0.1:37691,DS-e3dba574-9445-408e-919f-fd09f56d2475,DISK], DatanodeInfoWithStorage[127.0.0.1:40890,DS-260f37dd-1ba6-4172-b562-b03d86fdd391,DISK], DatanodeInfoWithStorage[127.0.0.1:41283,DS-fb088b6c-585f-42cc-9d5b-8f1812d5b64f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-225287898-172.17.0.21-1597745248676:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34344,DS-071bd972-47a2-4a5d-b1b1-22aca5bd505a,DISK], DatanodeInfoWithStorage[127.0.0.1:36274,DS-cc431158-3c24-463e-82ae-c3a84c555acf,DISK], DatanodeInfoWithStorage[127.0.0.1:43582,DS-5735e229-4644-4921-9130-1a49b8c9852a,DISK], DatanodeInfoWithStorage[127.0.0.1:45686,DS-59898e02-64ac-4d07-8d56-581d5adeb317,DISK], DatanodeInfoWithStorage[127.0.0.1:42566,DS-9f1b506b-8641-46ef-b245-26d1e3d1637a,DISK], DatanodeInfoWithStorage[127.0.0.1:42943,DS-b528f805-7d76-4a22-bfd4-a3178f103eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:37456,DS-f4f81b14-e8e7-46d7-bcb8-463cd5c6d273,DISK], DatanodeInfoWithStorage[127.0.0.1:41592,DS-1f4851f6-2c0f-45a0-ad75-ecb96648619a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-225287898-172.17.0.21-1597745248676:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34344,DS-071bd972-47a2-4a5d-b1b1-22aca5bd505a,DISK], DatanodeInfoWithStorage[127.0.0.1:36274,DS-cc431158-3c24-463e-82ae-c3a84c555acf,DISK], DatanodeInfoWithStorage[127.0.0.1:43582,DS-5735e229-4644-4921-9130-1a49b8c9852a,DISK], DatanodeInfoWithStorage[127.0.0.1:45686,DS-59898e02-64ac-4d07-8d56-581d5adeb317,DISK], DatanodeInfoWithStorage[127.0.0.1:42566,DS-9f1b506b-8641-46ef-b245-26d1e3d1637a,DISK], DatanodeInfoWithStorage[127.0.0.1:42943,DS-b528f805-7d76-4a22-bfd4-a3178f103eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:37456,DS-f4f81b14-e8e7-46d7-bcb8-463cd5c6d273,DISK], DatanodeInfoWithStorage[127.0.0.1:41592,DS-1f4851f6-2c0f-45a0-ad75-ecb96648619a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-361384572-172.17.0.21-1597746103733:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34392,DS-5e641c75-8a3a-440e-a68e-c73a1f2cc696,DISK], DatanodeInfoWithStorage[127.0.0.1:46062,DS-9e8da398-9011-48ce-9423-d3ef5989cad6,DISK], DatanodeInfoWithStorage[127.0.0.1:39323,DS-734d35af-fde5-49ff-b6ae-3ccd9e7da73b,DISK], DatanodeInfoWithStorage[127.0.0.1:39768,DS-a1b1c9fa-9b9b-4330-8939-93cb2b7494b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42573,DS-bb1a5811-13e1-42f9-875b-92fa83718a94,DISK], DatanodeInfoWithStorage[127.0.0.1:43153,DS-544a7210-7193-4fd1-9065-b5e37b6614b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36495,DS-e69ebde4-bd16-42bc-83b3-509446a7e652,DISK], DatanodeInfoWithStorage[127.0.0.1:42615,DS-63baccb9-ddc4-4948-a722-5a400446514b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-361384572-172.17.0.21-1597746103733:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34392,DS-5e641c75-8a3a-440e-a68e-c73a1f2cc696,DISK], DatanodeInfoWithStorage[127.0.0.1:46062,DS-9e8da398-9011-48ce-9423-d3ef5989cad6,DISK], DatanodeInfoWithStorage[127.0.0.1:39323,DS-734d35af-fde5-49ff-b6ae-3ccd9e7da73b,DISK], DatanodeInfoWithStorage[127.0.0.1:39768,DS-a1b1c9fa-9b9b-4330-8939-93cb2b7494b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42573,DS-bb1a5811-13e1-42f9-875b-92fa83718a94,DISK], DatanodeInfoWithStorage[127.0.0.1:43153,DS-544a7210-7193-4fd1-9065-b5e37b6614b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36495,DS-e69ebde4-bd16-42bc-83b3-509446a7e652,DISK], DatanodeInfoWithStorage[127.0.0.1:42615,DS-63baccb9-ddc4-4948-a722-5a400446514b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 1 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5491
