reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-857760443-172.17.0.13-1597674411685:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41466,DS-7d5a30bc-785f-4c5a-a055-90aa16d583a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39781,DS-34337024-e8da-4f6a-9a6e-e79ff1c017a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34198,DS-3eaac4e5-9d6c-411b-b577-9a3dba30680b,DISK], DatanodeInfoWithStorage[127.0.0.1:41073,DS-5c2c13f6-c8b1-42ff-848a-c48ca37a8804,DISK], DatanodeInfoWithStorage[127.0.0.1:32828,DS-6717fd10-eb84-4afc-8a7a-0b149d887979,DISK], DatanodeInfoWithStorage[127.0.0.1:34961,DS-49d9efe8-85aa-44af-a4b3-aab706d6d731,DISK], DatanodeInfoWithStorage[127.0.0.1:34641,DS-cb6f0e97-52d6-429f-8471-28ff369c5e52,DISK], DatanodeInfoWithStorage[127.0.0.1:41371,DS-8c7a34ee-7a05-4a2a-b4c0-94b2bd00f007,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-857760443-172.17.0.13-1597674411685:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41466,DS-7d5a30bc-785f-4c5a-a055-90aa16d583a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39781,DS-34337024-e8da-4f6a-9a6e-e79ff1c017a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34198,DS-3eaac4e5-9d6c-411b-b577-9a3dba30680b,DISK], DatanodeInfoWithStorage[127.0.0.1:41073,DS-5c2c13f6-c8b1-42ff-848a-c48ca37a8804,DISK], DatanodeInfoWithStorage[127.0.0.1:32828,DS-6717fd10-eb84-4afc-8a7a-0b149d887979,DISK], DatanodeInfoWithStorage[127.0.0.1:34961,DS-49d9efe8-85aa-44af-a4b3-aab706d6d731,DISK], DatanodeInfoWithStorage[127.0.0.1:34641,DS-cb6f0e97-52d6-429f-8471-28ff369c5e52,DISK], DatanodeInfoWithStorage[127.0.0.1:41371,DS-8c7a34ee-7a05-4a2a-b4c0-94b2bd00f007,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1896298901-172.17.0.13-1597674720731:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43823,DS-dfb00026-6abb-4f41-afa9-07ca9ced4125,DISK], DatanodeInfoWithStorage[127.0.0.1:43066,DS-b512681b-b7ea-47c8-aa13-84ad24eb886c,DISK], DatanodeInfoWithStorage[127.0.0.1:40079,DS-86eb76b5-9ceb-4da3-a187-ad6346873528,DISK], DatanodeInfoWithStorage[127.0.0.1:35381,DS-7cd8c84c-286f-4bc3-8942-cdd9a3134c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:35275,DS-387865e6-241c-4804-9ed6-835235e73da9,DISK], DatanodeInfoWithStorage[127.0.0.1:41785,DS-fa342642-e1da-47f1-99b8-fa25f35c0e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:42313,DS-3dc995d9-d26b-46bf-8525-81c7bc20c699,DISK], DatanodeInfoWithStorage[127.0.0.1:35775,DS-ac990314-7f6e-48c1-b983-9c9d0f6b8898,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1896298901-172.17.0.13-1597674720731:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43823,DS-dfb00026-6abb-4f41-afa9-07ca9ced4125,DISK], DatanodeInfoWithStorage[127.0.0.1:43066,DS-b512681b-b7ea-47c8-aa13-84ad24eb886c,DISK], DatanodeInfoWithStorage[127.0.0.1:40079,DS-86eb76b5-9ceb-4da3-a187-ad6346873528,DISK], DatanodeInfoWithStorage[127.0.0.1:35381,DS-7cd8c84c-286f-4bc3-8942-cdd9a3134c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:35275,DS-387865e6-241c-4804-9ed6-835235e73da9,DISK], DatanodeInfoWithStorage[127.0.0.1:41785,DS-fa342642-e1da-47f1-99b8-fa25f35c0e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:42313,DS-3dc995d9-d26b-46bf-8525-81c7bc20c699,DISK], DatanodeInfoWithStorage[127.0.0.1:35775,DS-ac990314-7f6e-48c1-b983-9c9d0f6b8898,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1986876127-172.17.0.13-1597674794032:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44648,DS-f8a578f3-0574-4ffc-ade9-f548abb36406,DISK], DatanodeInfoWithStorage[127.0.0.1:38739,DS-ee3defc7-f128-4eb1-a155-2bb443704f74,DISK], DatanodeInfoWithStorage[127.0.0.1:35278,DS-810ecc85-c4db-448c-aeef-96e6c09b1dc1,DISK], DatanodeInfoWithStorage[127.0.0.1:45918,DS-8a98bc57-ef84-44d8-8230-2bc779b1483c,DISK], DatanodeInfoWithStorage[127.0.0.1:42902,DS-1508f360-66e3-4c17-82eb-f517a15562ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44503,DS-08709e56-85a4-4aac-9bd4-a44c7913454d,DISK], DatanodeInfoWithStorage[127.0.0.1:36134,DS-5119c89a-85c0-4e12-8b99-e04625955634,DISK], DatanodeInfoWithStorage[127.0.0.1:38166,DS-9804c6f8-31fe-4043-9445-ca8ac78daa31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1986876127-172.17.0.13-1597674794032:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44648,DS-f8a578f3-0574-4ffc-ade9-f548abb36406,DISK], DatanodeInfoWithStorage[127.0.0.1:38739,DS-ee3defc7-f128-4eb1-a155-2bb443704f74,DISK], DatanodeInfoWithStorage[127.0.0.1:35278,DS-810ecc85-c4db-448c-aeef-96e6c09b1dc1,DISK], DatanodeInfoWithStorage[127.0.0.1:45918,DS-8a98bc57-ef84-44d8-8230-2bc779b1483c,DISK], DatanodeInfoWithStorage[127.0.0.1:42902,DS-1508f360-66e3-4c17-82eb-f517a15562ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44503,DS-08709e56-85a4-4aac-9bd4-a44c7913454d,DISK], DatanodeInfoWithStorage[127.0.0.1:36134,DS-5119c89a-85c0-4e12-8b99-e04625955634,DISK], DatanodeInfoWithStorage[127.0.0.1:38166,DS-9804c6f8-31fe-4043-9445-ca8ac78daa31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-369281995-172.17.0.13-1597675149865:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42738,DS-c253c326-32a3-40e9-8109-6d19507ec873,DISK], DatanodeInfoWithStorage[127.0.0.1:35025,DS-c112572c-f57d-43aa-bd34-601594d55748,DISK], DatanodeInfoWithStorage[127.0.0.1:38539,DS-6f0c6e1b-c7b2-47c2-b6c3-a0bf17d089c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37640,DS-67075472-bdaa-4214-8019-0e090ee1b979,DISK], DatanodeInfoWithStorage[127.0.0.1:39703,DS-086cffeb-148f-4084-8ddc-efa0f75824c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38777,DS-58c39e58-e8bb-4d9b-a088-d13a70ca4e23,DISK], DatanodeInfoWithStorage[127.0.0.1:43197,DS-ed13da97-07b5-403a-8bc0-dcbde4610ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:42965,DS-c70c9006-0e5b-41b6-b82d-f72754c2cc89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-369281995-172.17.0.13-1597675149865:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42738,DS-c253c326-32a3-40e9-8109-6d19507ec873,DISK], DatanodeInfoWithStorage[127.0.0.1:35025,DS-c112572c-f57d-43aa-bd34-601594d55748,DISK], DatanodeInfoWithStorage[127.0.0.1:38539,DS-6f0c6e1b-c7b2-47c2-b6c3-a0bf17d089c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37640,DS-67075472-bdaa-4214-8019-0e090ee1b979,DISK], DatanodeInfoWithStorage[127.0.0.1:39703,DS-086cffeb-148f-4084-8ddc-efa0f75824c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38777,DS-58c39e58-e8bb-4d9b-a088-d13a70ca4e23,DISK], DatanodeInfoWithStorage[127.0.0.1:43197,DS-ed13da97-07b5-403a-8bc0-dcbde4610ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:42965,DS-c70c9006-0e5b-41b6-b82d-f72754c2cc89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1106354222-172.17.0.13-1597675576021:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39936,DS-cd4dd16b-3902-4a4e-9d69-12782102fa69,DISK], DatanodeInfoWithStorage[127.0.0.1:41614,DS-5cb15a4f-daab-484d-8201-8b952f3ff580,DISK], DatanodeInfoWithStorage[127.0.0.1:36337,DS-88e7203c-8b2e-4fe9-925c-dd09aa1b043c,DISK], DatanodeInfoWithStorage[127.0.0.1:34754,DS-438e2883-8d1d-4345-b2b8-cb81384674b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44443,DS-666ffef5-b29e-4e24-bdc8-f08d020a8e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38759,DS-6eb140b6-ee7f-4211-af07-18834aa3c80b,DISK], DatanodeInfoWithStorage[127.0.0.1:33672,DS-dc5d0646-563a-4957-9e75-591ef611a8b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38017,DS-196ade56-29b1-4a77-b7c1-6a8eb5fe2ad2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1106354222-172.17.0.13-1597675576021:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39936,DS-cd4dd16b-3902-4a4e-9d69-12782102fa69,DISK], DatanodeInfoWithStorage[127.0.0.1:41614,DS-5cb15a4f-daab-484d-8201-8b952f3ff580,DISK], DatanodeInfoWithStorage[127.0.0.1:36337,DS-88e7203c-8b2e-4fe9-925c-dd09aa1b043c,DISK], DatanodeInfoWithStorage[127.0.0.1:34754,DS-438e2883-8d1d-4345-b2b8-cb81384674b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44443,DS-666ffef5-b29e-4e24-bdc8-f08d020a8e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38759,DS-6eb140b6-ee7f-4211-af07-18834aa3c80b,DISK], DatanodeInfoWithStorage[127.0.0.1:33672,DS-dc5d0646-563a-4957-9e75-591ef611a8b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38017,DS-196ade56-29b1-4a77-b7c1-6a8eb5fe2ad2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-229657706-172.17.0.13-1597675940078:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46424,DS-9cff8da1-f4d0-4650-a06f-221cba04f384,DISK], DatanodeInfoWithStorage[127.0.0.1:43374,DS-f5f0c6b3-de81-417c-88d6-86c57cd4d4d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34142,DS-7d5c8273-a43a-4127-bf0d-69c8cb98481b,DISK], DatanodeInfoWithStorage[127.0.0.1:41994,DS-e9b57538-6a10-4062-9bcb-92a56ea304da,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-9dfe272e-bb9d-499a-b16d-9c307a6048a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41820,DS-98459beb-a9b7-454c-8b96-04d99056607f,DISK], DatanodeInfoWithStorage[127.0.0.1:33716,DS-db9a2a1f-d7e3-4fc8-a9be-6504906953d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33564,DS-9939b8f7-a79b-4e95-b339-3826fd5ee4e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-229657706-172.17.0.13-1597675940078:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46424,DS-9cff8da1-f4d0-4650-a06f-221cba04f384,DISK], DatanodeInfoWithStorage[127.0.0.1:43374,DS-f5f0c6b3-de81-417c-88d6-86c57cd4d4d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34142,DS-7d5c8273-a43a-4127-bf0d-69c8cb98481b,DISK], DatanodeInfoWithStorage[127.0.0.1:41994,DS-e9b57538-6a10-4062-9bcb-92a56ea304da,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-9dfe272e-bb9d-499a-b16d-9c307a6048a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41820,DS-98459beb-a9b7-454c-8b96-04d99056607f,DISK], DatanodeInfoWithStorage[127.0.0.1:33716,DS-db9a2a1f-d7e3-4fc8-a9be-6504906953d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33564,DS-9939b8f7-a79b-4e95-b339-3826fd5ee4e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-909154424-172.17.0.13-1597676040392:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46568,DS-a650a52d-f2af-4cd0-9827-c105026863c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46338,DS-614992ad-1cda-4e0e-af93-220df22daede,DISK], DatanodeInfoWithStorage[127.0.0.1:43719,DS-09ccf441-aeb0-4988-afeb-08db0bcec0f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42841,DS-ebe23256-c93a-4bf9-b1b6-c23f28ed11f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37973,DS-29f349b5-4b15-4c66-90c6-1581c9165a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42304,DS-87889e24-57d8-42fc-8482-6c11f3a7c5a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33095,DS-ca396860-b029-478e-a576-216666782008,DISK], DatanodeInfoWithStorage[127.0.0.1:36361,DS-c4b6901a-944b-466c-b5a0-24554023632f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-909154424-172.17.0.13-1597676040392:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46568,DS-a650a52d-f2af-4cd0-9827-c105026863c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46338,DS-614992ad-1cda-4e0e-af93-220df22daede,DISK], DatanodeInfoWithStorage[127.0.0.1:43719,DS-09ccf441-aeb0-4988-afeb-08db0bcec0f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42841,DS-ebe23256-c93a-4bf9-b1b6-c23f28ed11f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37973,DS-29f349b5-4b15-4c66-90c6-1581c9165a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42304,DS-87889e24-57d8-42fc-8482-6c11f3a7c5a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33095,DS-ca396860-b029-478e-a576-216666782008,DISK], DatanodeInfoWithStorage[127.0.0.1:36361,DS-c4b6901a-944b-466c-b5a0-24554023632f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1017380447-172.17.0.13-1597676297344:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37716,DS-ca76a3bc-2b86-4056-a899-6fbd0724fed3,DISK], DatanodeInfoWithStorage[127.0.0.1:35371,DS-d38438ef-23c3-40d2-805a-07724c749b98,DISK], DatanodeInfoWithStorage[127.0.0.1:44341,DS-bf36138b-6b9e-41f1-bd6c-dbe20318f34f,DISK], DatanodeInfoWithStorage[127.0.0.1:44483,DS-f11e7872-36f9-440b-9567-06d3812da306,DISK], DatanodeInfoWithStorage[127.0.0.1:41978,DS-98e59110-7597-4057-86af-e75becbe7149,DISK], DatanodeInfoWithStorage[127.0.0.1:46256,DS-e35d681b-f53a-482a-bbbe-ed6707c0feaf,DISK], DatanodeInfoWithStorage[127.0.0.1:34677,DS-486101d1-3f12-4137-b677-0f9efa058f79,DISK], DatanodeInfoWithStorage[127.0.0.1:45407,DS-aa1c5608-12de-456c-8a21-c100e7e783ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1017380447-172.17.0.13-1597676297344:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37716,DS-ca76a3bc-2b86-4056-a899-6fbd0724fed3,DISK], DatanodeInfoWithStorage[127.0.0.1:35371,DS-d38438ef-23c3-40d2-805a-07724c749b98,DISK], DatanodeInfoWithStorage[127.0.0.1:44341,DS-bf36138b-6b9e-41f1-bd6c-dbe20318f34f,DISK], DatanodeInfoWithStorage[127.0.0.1:44483,DS-f11e7872-36f9-440b-9567-06d3812da306,DISK], DatanodeInfoWithStorage[127.0.0.1:41978,DS-98e59110-7597-4057-86af-e75becbe7149,DISK], DatanodeInfoWithStorage[127.0.0.1:46256,DS-e35d681b-f53a-482a-bbbe-ed6707c0feaf,DISK], DatanodeInfoWithStorage[127.0.0.1:34677,DS-486101d1-3f12-4137-b677-0f9efa058f79,DISK], DatanodeInfoWithStorage[127.0.0.1:45407,DS-aa1c5608-12de-456c-8a21-c100e7e783ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1890978278-172.17.0.13-1597677055202:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43800,DS-13fb19bf-3f6e-48e9-ad51-b64a8c996fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:39930,DS-3ab347af-a93c-41d6-b3fe-9cc2e453359a,DISK], DatanodeInfoWithStorage[127.0.0.1:46872,DS-1adfbbd3-3142-4021-929a-6ebd08ea0a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40460,DS-fef752bb-4454-4a26-a6c5-f409fd951ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-1c046123-5d82-45ef-90c9-f8c421cea163,DISK], DatanodeInfoWithStorage[127.0.0.1:43418,DS-3ed44afa-7b26-44ec-85f2-937ef5dd7e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39630,DS-351a22e4-9ab6-468f-b9fe-0b84621bea3b,DISK], DatanodeInfoWithStorage[127.0.0.1:35142,DS-d3411848-ebb3-475c-8aa9-b68dd945b8b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1890978278-172.17.0.13-1597677055202:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43800,DS-13fb19bf-3f6e-48e9-ad51-b64a8c996fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:39930,DS-3ab347af-a93c-41d6-b3fe-9cc2e453359a,DISK], DatanodeInfoWithStorage[127.0.0.1:46872,DS-1adfbbd3-3142-4021-929a-6ebd08ea0a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40460,DS-fef752bb-4454-4a26-a6c5-f409fd951ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-1c046123-5d82-45ef-90c9-f8c421cea163,DISK], DatanodeInfoWithStorage[127.0.0.1:43418,DS-3ed44afa-7b26-44ec-85f2-937ef5dd7e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39630,DS-351a22e4-9ab6-468f-b9fe-0b84621bea3b,DISK], DatanodeInfoWithStorage[127.0.0.1:35142,DS-d3411848-ebb3-475c-8aa9-b68dd945b8b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-65817275-172.17.0.13-1597677482913:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34793,DS-d26b1d64-d174-43da-a1e5-65bf6bf5a447,DISK], DatanodeInfoWithStorage[127.0.0.1:39777,DS-ccaa25c6-4a30-490c-8d90-10100d3e4b14,DISK], DatanodeInfoWithStorage[127.0.0.1:36992,DS-5d590342-12d7-4fcf-a292-9c496ce86a15,DISK], DatanodeInfoWithStorage[127.0.0.1:33376,DS-81834aa8-a681-4b8a-8401-e52db6eccea3,DISK], DatanodeInfoWithStorage[127.0.0.1:34780,DS-d3827ef7-f008-4a38-ae7c-e9a60637ba6f,DISK], DatanodeInfoWithStorage[127.0.0.1:42063,DS-30f1cda5-5cd5-4943-8ed3-42d1b017b6c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39314,DS-450d1479-7ece-40e7-879c-1573baec8c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:37623,DS-7cfada1e-89b7-40b7-8ed4-bfe9fb46e2e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-65817275-172.17.0.13-1597677482913:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34793,DS-d26b1d64-d174-43da-a1e5-65bf6bf5a447,DISK], DatanodeInfoWithStorage[127.0.0.1:39777,DS-ccaa25c6-4a30-490c-8d90-10100d3e4b14,DISK], DatanodeInfoWithStorage[127.0.0.1:36992,DS-5d590342-12d7-4fcf-a292-9c496ce86a15,DISK], DatanodeInfoWithStorage[127.0.0.1:33376,DS-81834aa8-a681-4b8a-8401-e52db6eccea3,DISK], DatanodeInfoWithStorage[127.0.0.1:34780,DS-d3827ef7-f008-4a38-ae7c-e9a60637ba6f,DISK], DatanodeInfoWithStorage[127.0.0.1:42063,DS-30f1cda5-5cd5-4943-8ed3-42d1b017b6c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39314,DS-450d1479-7ece-40e7-879c-1573baec8c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:37623,DS-7cfada1e-89b7-40b7-8ed4-bfe9fb46e2e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1988601791-172.17.0.13-1597677683001:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33059,DS-0555f29e-014e-417f-bcc3-d1e3eac6ab17,DISK], DatanodeInfoWithStorage[127.0.0.1:40870,DS-e3f74ea5-b6a6-42a8-9253-79579fe7466a,DISK], DatanodeInfoWithStorage[127.0.0.1:34461,DS-8954f49e-a00c-4a89-8aa0-1820c8ba92b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36678,DS-d4875309-c62e-47c2-9fb0-8d2650de9f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:37505,DS-66170455-e56c-4315-99c4-a9eb8de8ddbd,DISK], DatanodeInfoWithStorage[127.0.0.1:39236,DS-2a6dd6d7-fb10-4b71-b448-565e14450e92,DISK], DatanodeInfoWithStorage[127.0.0.1:35411,DS-4b0a0a3d-8c61-4087-8496-7f612a4ad825,DISK], DatanodeInfoWithStorage[127.0.0.1:39910,DS-eb149b09-a8a4-4749-9207-a5ed5ff39523,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1988601791-172.17.0.13-1597677683001:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33059,DS-0555f29e-014e-417f-bcc3-d1e3eac6ab17,DISK], DatanodeInfoWithStorage[127.0.0.1:40870,DS-e3f74ea5-b6a6-42a8-9253-79579fe7466a,DISK], DatanodeInfoWithStorage[127.0.0.1:34461,DS-8954f49e-a00c-4a89-8aa0-1820c8ba92b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36678,DS-d4875309-c62e-47c2-9fb0-8d2650de9f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:37505,DS-66170455-e56c-4315-99c4-a9eb8de8ddbd,DISK], DatanodeInfoWithStorage[127.0.0.1:39236,DS-2a6dd6d7-fb10-4b71-b448-565e14450e92,DISK], DatanodeInfoWithStorage[127.0.0.1:35411,DS-4b0a0a3d-8c61-4087-8496-7f612a4ad825,DISK], DatanodeInfoWithStorage[127.0.0.1:39910,DS-eb149b09-a8a4-4749-9207-a5ed5ff39523,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1815366578-172.17.0.13-1597678516619:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35120,DS-abaef4cc-b01c-415c-9225-6339994ba3ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46536,DS-644998cb-43b7-412d-ae03-db787f62b728,DISK], DatanodeInfoWithStorage[127.0.0.1:43907,DS-22e492f6-56be-4ec6-b7a8-80f3b3568b72,DISK], DatanodeInfoWithStorage[127.0.0.1:40262,DS-e3a79452-74c9-46e5-a2be-599b3d3fd112,DISK], DatanodeInfoWithStorage[127.0.0.1:37488,DS-03af1995-e735-4566-9233-e20f7ccc9eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:39359,DS-16fdd503-0247-47fc-8477-4223345317ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43024,DS-1c782445-50e6-433b-adae-426bd762a2f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37318,DS-8afdf416-1594-40fc-9ca6-63ce49fd8f20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1815366578-172.17.0.13-1597678516619:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35120,DS-abaef4cc-b01c-415c-9225-6339994ba3ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46536,DS-644998cb-43b7-412d-ae03-db787f62b728,DISK], DatanodeInfoWithStorage[127.0.0.1:43907,DS-22e492f6-56be-4ec6-b7a8-80f3b3568b72,DISK], DatanodeInfoWithStorage[127.0.0.1:40262,DS-e3a79452-74c9-46e5-a2be-599b3d3fd112,DISK], DatanodeInfoWithStorage[127.0.0.1:37488,DS-03af1995-e735-4566-9233-e20f7ccc9eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:39359,DS-16fdd503-0247-47fc-8477-4223345317ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43024,DS-1c782445-50e6-433b-adae-426bd762a2f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37318,DS-8afdf416-1594-40fc-9ca6-63ce49fd8f20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1099937801-172.17.0.13-1597678608901:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43230,DS-a70a05a0-78f2-499b-aa67-b28f76f25e24,DISK], DatanodeInfoWithStorage[127.0.0.1:33875,DS-f6a78d75-2ef7-4368-a6fc-990b53146a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41027,DS-c7e72a12-5f7b-4af0-a410-5678c8ac95bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38656,DS-ccc9df61-71fc-4395-9854-296e4fdf48a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34220,DS-c5a9b16e-3f82-43e4-993f-4dcd914c8752,DISK], DatanodeInfoWithStorage[127.0.0.1:35013,DS-09ae837b-6383-4641-b485-429789a44953,DISK], DatanodeInfoWithStorage[127.0.0.1:39723,DS-62b19261-4c05-4823-b9da-a5e7f741d0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36123,DS-ae89fc15-07f3-4076-bd26-05bb92604eb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1099937801-172.17.0.13-1597678608901:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43230,DS-a70a05a0-78f2-499b-aa67-b28f76f25e24,DISK], DatanodeInfoWithStorage[127.0.0.1:33875,DS-f6a78d75-2ef7-4368-a6fc-990b53146a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41027,DS-c7e72a12-5f7b-4af0-a410-5678c8ac95bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38656,DS-ccc9df61-71fc-4395-9854-296e4fdf48a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34220,DS-c5a9b16e-3f82-43e4-993f-4dcd914c8752,DISK], DatanodeInfoWithStorage[127.0.0.1:35013,DS-09ae837b-6383-4641-b485-429789a44953,DISK], DatanodeInfoWithStorage[127.0.0.1:39723,DS-62b19261-4c05-4823-b9da-a5e7f741d0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36123,DS-ae89fc15-07f3-4076-bd26-05bb92604eb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-295033911-172.17.0.13-1597679254779:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45724,DS-bfb31d12-86e6-4b47-bebe-e5227cdf2af3,DISK], DatanodeInfoWithStorage[127.0.0.1:34076,DS-b00c8b7b-5c54-42f8-be24-8fbcbbe073eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41677,DS-c6d96cc2-281c-48e7-a600-c607bfdeedd1,DISK], DatanodeInfoWithStorage[127.0.0.1:32859,DS-f254963f-3147-4a85-a9d1-d6e44c4c0e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37031,DS-be613be0-1b71-4f03-b9c0-32b2089492a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43310,DS-52d0672d-1865-4bae-8acb-be85198757e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42129,DS-bffa86c5-bc53-4365-b77b-4cc351d48cef,DISK], DatanodeInfoWithStorage[127.0.0.1:34918,DS-d09c3b3c-8fe5-48ce-a3bc-0732a5dc00c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-295033911-172.17.0.13-1597679254779:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45724,DS-bfb31d12-86e6-4b47-bebe-e5227cdf2af3,DISK], DatanodeInfoWithStorage[127.0.0.1:34076,DS-b00c8b7b-5c54-42f8-be24-8fbcbbe073eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41677,DS-c6d96cc2-281c-48e7-a600-c607bfdeedd1,DISK], DatanodeInfoWithStorage[127.0.0.1:32859,DS-f254963f-3147-4a85-a9d1-d6e44c4c0e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37031,DS-be613be0-1b71-4f03-b9c0-32b2089492a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43310,DS-52d0672d-1865-4bae-8acb-be85198757e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42129,DS-bffa86c5-bc53-4365-b77b-4cc351d48cef,DISK], DatanodeInfoWithStorage[127.0.0.1:34918,DS-d09c3b3c-8fe5-48ce-a3bc-0732a5dc00c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1756664596-172.17.0.13-1597679288609:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32779,DS-fd703a7f-31ff-44a9-8432-00ddc9e1a538,DISK], DatanodeInfoWithStorage[127.0.0.1:32974,DS-f3dd3c1d-f00a-4b2d-9b78-5caacfe0c8e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42474,DS-260e8f5e-14e8-4b5b-9bc8-72279e315dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:36103,DS-4f0db784-4202-433e-9557-dba8fb4203ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41220,DS-55160494-9546-466b-bc1c-5759a95fe4f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40423,DS-60555e79-3968-4daa-aa54-539025ac20d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35416,DS-65324533-7db6-482f-bc86-0fadfde0cc40,DISK], DatanodeInfoWithStorage[127.0.0.1:40916,DS-488c0fba-7ee2-4953-8557-5af0bdc67568,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1756664596-172.17.0.13-1597679288609:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32779,DS-fd703a7f-31ff-44a9-8432-00ddc9e1a538,DISK], DatanodeInfoWithStorage[127.0.0.1:32974,DS-f3dd3c1d-f00a-4b2d-9b78-5caacfe0c8e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42474,DS-260e8f5e-14e8-4b5b-9bc8-72279e315dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:36103,DS-4f0db784-4202-433e-9557-dba8fb4203ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41220,DS-55160494-9546-466b-bc1c-5759a95fe4f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40423,DS-60555e79-3968-4daa-aa54-539025ac20d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35416,DS-65324533-7db6-482f-bc86-0fadfde0cc40,DISK], DatanodeInfoWithStorage[127.0.0.1:40916,DS-488c0fba-7ee2-4953-8557-5af0bdc67568,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5302
