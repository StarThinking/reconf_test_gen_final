reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 99
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 99
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-236337720-172.17.0.10-1597390877526:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38539,DS-a049170d-5945-4d47-8c64-87eb1eecbc5f,DISK], DatanodeInfoWithStorage[127.0.0.1:36844,DS-662a5690-e1eb-4b93-a6ce-6df2cdfb1d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:35930,DS-8f000d99-3740-4912-b06e-25466a8ec228,DISK], DatanodeInfoWithStorage[127.0.0.1:40359,DS-69fb65e5-9be6-488a-bdf6-d348a4d9ce94,DISK], DatanodeInfoWithStorage[127.0.0.1:42738,DS-a40a47e8-5daf-452e-8134-a117c98ec3a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43622,DS-69ab9d4a-c13c-42fb-a925-92f5a3e18f05,DISK], DatanodeInfoWithStorage[127.0.0.1:46392,DS-bb1d4647-5c6c-40e8-a0f3-00d1e796cc33,DISK], DatanodeInfoWithStorage[127.0.0.1:45478,DS-1001210f-1c4a-41be-80c0-a56d90fbf371,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-236337720-172.17.0.10-1597390877526:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38539,DS-a049170d-5945-4d47-8c64-87eb1eecbc5f,DISK], DatanodeInfoWithStorage[127.0.0.1:36844,DS-662a5690-e1eb-4b93-a6ce-6df2cdfb1d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:35930,DS-8f000d99-3740-4912-b06e-25466a8ec228,DISK], DatanodeInfoWithStorage[127.0.0.1:40359,DS-69fb65e5-9be6-488a-bdf6-d348a4d9ce94,DISK], DatanodeInfoWithStorage[127.0.0.1:42738,DS-a40a47e8-5daf-452e-8134-a117c98ec3a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43622,DS-69ab9d4a-c13c-42fb-a925-92f5a3e18f05,DISK], DatanodeInfoWithStorage[127.0.0.1:46392,DS-bb1d4647-5c6c-40e8-a0f3-00d1e796cc33,DISK], DatanodeInfoWithStorage[127.0.0.1:45478,DS-1001210f-1c4a-41be-80c0-a56d90fbf371,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 99
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1791192216-172.17.0.10-1597391356650:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37083,DS-c1dffbb3-239a-44ed-897d-60b57cbcb324,DISK], DatanodeInfoWithStorage[127.0.0.1:44016,DS-0f650a22-76eb-4708-a359-73829eb88723,DISK], DatanodeInfoWithStorage[127.0.0.1:45177,DS-3a21fa95-faf6-49e3-9d47-f993f75c1e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:33937,DS-11a65de4-a8a9-4aff-b00c-1179548ef3d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34961,DS-202c9aa2-78cd-4299-af29-c7d871a14e51,DISK], DatanodeInfoWithStorage[127.0.0.1:34733,DS-d5cbbbb9-709e-47f9-9231-008c4098918c,DISK], DatanodeInfoWithStorage[127.0.0.1:36856,DS-47f9e4ee-e807-4a0d-a9f5-05ee85ecdca9,DISK], DatanodeInfoWithStorage[127.0.0.1:42595,DS-21256a0a-992a-40af-b3cb-1d5b986eb495,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1791192216-172.17.0.10-1597391356650:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37083,DS-c1dffbb3-239a-44ed-897d-60b57cbcb324,DISK], DatanodeInfoWithStorage[127.0.0.1:44016,DS-0f650a22-76eb-4708-a359-73829eb88723,DISK], DatanodeInfoWithStorage[127.0.0.1:45177,DS-3a21fa95-faf6-49e3-9d47-f993f75c1e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:33937,DS-11a65de4-a8a9-4aff-b00c-1179548ef3d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34961,DS-202c9aa2-78cd-4299-af29-c7d871a14e51,DISK], DatanodeInfoWithStorage[127.0.0.1:34733,DS-d5cbbbb9-709e-47f9-9231-008c4098918c,DISK], DatanodeInfoWithStorage[127.0.0.1:36856,DS-47f9e4ee-e807-4a0d-a9f5-05ee85ecdca9,DISK], DatanodeInfoWithStorage[127.0.0.1:42595,DS-21256a0a-992a-40af-b3cb-1d5b986eb495,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 99
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-734342693-172.17.0.10-1597391468570:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36557,DS-8c7b408e-dfd9-4213-88e5-8ca3a05a74fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44792,DS-429a8b7b-4e58-446d-af7a-7c4845621119,DISK], DatanodeInfoWithStorage[127.0.0.1:38574,DS-e37bf852-c254-4f98-9a4b-c7151ad7edf9,DISK], DatanodeInfoWithStorage[127.0.0.1:34972,DS-9275be94-f610-4614-baf8-35b15bb4e367,DISK], DatanodeInfoWithStorage[127.0.0.1:35119,DS-2f92fceb-fc27-4e80-9d77-ed519d63a947,DISK], DatanodeInfoWithStorage[127.0.0.1:39120,DS-3b738dee-92de-4334-8fbb-9b5af15a510d,DISK], DatanodeInfoWithStorage[127.0.0.1:43272,DS-8fa03b98-4825-4dcc-bbfa-d16b703d6501,DISK], DatanodeInfoWithStorage[127.0.0.1:43601,DS-1c859712-9bb8-47b9-b1ff-10d77364533f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-734342693-172.17.0.10-1597391468570:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36557,DS-8c7b408e-dfd9-4213-88e5-8ca3a05a74fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44792,DS-429a8b7b-4e58-446d-af7a-7c4845621119,DISK], DatanodeInfoWithStorage[127.0.0.1:38574,DS-e37bf852-c254-4f98-9a4b-c7151ad7edf9,DISK], DatanodeInfoWithStorage[127.0.0.1:34972,DS-9275be94-f610-4614-baf8-35b15bb4e367,DISK], DatanodeInfoWithStorage[127.0.0.1:35119,DS-2f92fceb-fc27-4e80-9d77-ed519d63a947,DISK], DatanodeInfoWithStorage[127.0.0.1:39120,DS-3b738dee-92de-4334-8fbb-9b5af15a510d,DISK], DatanodeInfoWithStorage[127.0.0.1:43272,DS-8fa03b98-4825-4dcc-bbfa-d16b703d6501,DISK], DatanodeInfoWithStorage[127.0.0.1:43601,DS-1c859712-9bb8-47b9-b1ff-10d77364533f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 99
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1340045304-172.17.0.10-1597391725778:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35672,DS-9346b865-3e7d-43d2-82ab-a959e1ad1dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:39385,DS-ec6a13b1-93bb-4e5b-a515-8b0b4904210c,DISK], DatanodeInfoWithStorage[127.0.0.1:41080,DS-ad83642e-5c36-43a6-bb16-6cae64ec70a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45592,DS-73c13587-136f-48ef-a1e6-a42b6054d574,DISK], DatanodeInfoWithStorage[127.0.0.1:33684,DS-7d187cca-02af-471b-aa14-a9aa5d5d02bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39780,DS-75f0e522-492a-46df-b18a-3e0e0b38d418,DISK], DatanodeInfoWithStorage[127.0.0.1:44944,DS-35ba4dd7-ed57-4c16-84ed-90198646252d,DISK], DatanodeInfoWithStorage[127.0.0.1:39433,DS-974b35f9-8bd7-4c66-8a38-f7b84f4d0d2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1340045304-172.17.0.10-1597391725778:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35672,DS-9346b865-3e7d-43d2-82ab-a959e1ad1dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:39385,DS-ec6a13b1-93bb-4e5b-a515-8b0b4904210c,DISK], DatanodeInfoWithStorage[127.0.0.1:41080,DS-ad83642e-5c36-43a6-bb16-6cae64ec70a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45592,DS-73c13587-136f-48ef-a1e6-a42b6054d574,DISK], DatanodeInfoWithStorage[127.0.0.1:33684,DS-7d187cca-02af-471b-aa14-a9aa5d5d02bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39780,DS-75f0e522-492a-46df-b18a-3e0e0b38d418,DISK], DatanodeInfoWithStorage[127.0.0.1:44944,DS-35ba4dd7-ed57-4c16-84ed-90198646252d,DISK], DatanodeInfoWithStorage[127.0.0.1:39433,DS-974b35f9-8bd7-4c66-8a38-f7b84f4d0d2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 99
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1073317848-172.17.0.10-1597391767221:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37307,DS-8563483e-1a66-4bd7-a39a-429d37b4c91a,DISK], DatanodeInfoWithStorage[127.0.0.1:39303,DS-b3c63182-0c4b-479f-96c2-b8940f33e9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46278,DS-111ca583-b1a6-4117-9f0e-02addb977da6,DISK], DatanodeInfoWithStorage[127.0.0.1:45015,DS-0e79fae6-9ec8-4169-8365-8b95e0f5817e,DISK], DatanodeInfoWithStorage[127.0.0.1:45696,DS-bbf18211-197a-4986-9655-ec86bcd4a684,DISK], DatanodeInfoWithStorage[127.0.0.1:43823,DS-09a3cf33-52b2-49d3-8f8d-d5aa82164a11,DISK], DatanodeInfoWithStorage[127.0.0.1:38263,DS-eea86269-a224-416d-80c4-b9213df3eea1,DISK], DatanodeInfoWithStorage[127.0.0.1:39986,DS-b89780da-bde5-44eb-998b-6edf2039ff7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1073317848-172.17.0.10-1597391767221:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37307,DS-8563483e-1a66-4bd7-a39a-429d37b4c91a,DISK], DatanodeInfoWithStorage[127.0.0.1:39303,DS-b3c63182-0c4b-479f-96c2-b8940f33e9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46278,DS-111ca583-b1a6-4117-9f0e-02addb977da6,DISK], DatanodeInfoWithStorage[127.0.0.1:45015,DS-0e79fae6-9ec8-4169-8365-8b95e0f5817e,DISK], DatanodeInfoWithStorage[127.0.0.1:45696,DS-bbf18211-197a-4986-9655-ec86bcd4a684,DISK], DatanodeInfoWithStorage[127.0.0.1:43823,DS-09a3cf33-52b2-49d3-8f8d-d5aa82164a11,DISK], DatanodeInfoWithStorage[127.0.0.1:38263,DS-eea86269-a224-416d-80c4-b9213df3eea1,DISK], DatanodeInfoWithStorage[127.0.0.1:39986,DS-b89780da-bde5-44eb-998b-6edf2039ff7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 99
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1361425977-172.17.0.10-1597391950306:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33117,DS-2205818d-9b54-49a8-9ab6-ccc133e22f21,DISK], DatanodeInfoWithStorage[127.0.0.1:43290,DS-990615b2-562a-47fe-915e-e2a47a5226f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33726,DS-a68e4de7-aad3-4d7d-abe1-897d22a7a177,DISK], DatanodeInfoWithStorage[127.0.0.1:42293,DS-55f623da-2b26-4b91-81db-acf96ba8f95d,DISK], DatanodeInfoWithStorage[127.0.0.1:38776,DS-6277852c-91cd-442e-9d20-9fcbeab80bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:33584,DS-cd6b0d41-35c2-4633-9d94-6557af6a32c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42873,DS-d9f589e8-cfe0-42d9-8413-930df4659e82,DISK], DatanodeInfoWithStorage[127.0.0.1:42772,DS-c325affa-2edf-4193-a7f6-c68bd5ba64f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1361425977-172.17.0.10-1597391950306:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33117,DS-2205818d-9b54-49a8-9ab6-ccc133e22f21,DISK], DatanodeInfoWithStorage[127.0.0.1:43290,DS-990615b2-562a-47fe-915e-e2a47a5226f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33726,DS-a68e4de7-aad3-4d7d-abe1-897d22a7a177,DISK], DatanodeInfoWithStorage[127.0.0.1:42293,DS-55f623da-2b26-4b91-81db-acf96ba8f95d,DISK], DatanodeInfoWithStorage[127.0.0.1:38776,DS-6277852c-91cd-442e-9d20-9fcbeab80bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:33584,DS-cd6b0d41-35c2-4633-9d94-6557af6a32c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42873,DS-d9f589e8-cfe0-42d9-8413-930df4659e82,DISK], DatanodeInfoWithStorage[127.0.0.1:42772,DS-c325affa-2edf-4193-a7f6-c68bd5ba64f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 99
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-911106179-172.17.0.10-1597392063857:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36860,DS-24228c7b-447d-4331-9d6c-2b4f34feec0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37581,DS-23263fc7-c031-4d70-ac5b-1bb5ecdb634a,DISK], DatanodeInfoWithStorage[127.0.0.1:45013,DS-78a925e3-c3a8-4255-88a3-69b11d18cea6,DISK], DatanodeInfoWithStorage[127.0.0.1:35344,DS-a095c1e4-bf7d-42a7-b823-ae38d0fb8091,DISK], DatanodeInfoWithStorage[127.0.0.1:45134,DS-02148674-09c0-4867-9d09-3eb966611af7,DISK], DatanodeInfoWithStorage[127.0.0.1:44538,DS-60da78cd-8c01-4688-9347-c8d983fecf62,DISK], DatanodeInfoWithStorage[127.0.0.1:44324,DS-721c1dca-7963-4634-97fb-09301a8281d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36000,DS-d5860999-a600-4ce3-8740-5396675a4eae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-911106179-172.17.0.10-1597392063857:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36860,DS-24228c7b-447d-4331-9d6c-2b4f34feec0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37581,DS-23263fc7-c031-4d70-ac5b-1bb5ecdb634a,DISK], DatanodeInfoWithStorage[127.0.0.1:45013,DS-78a925e3-c3a8-4255-88a3-69b11d18cea6,DISK], DatanodeInfoWithStorage[127.0.0.1:35344,DS-a095c1e4-bf7d-42a7-b823-ae38d0fb8091,DISK], DatanodeInfoWithStorage[127.0.0.1:45134,DS-02148674-09c0-4867-9d09-3eb966611af7,DISK], DatanodeInfoWithStorage[127.0.0.1:44538,DS-60da78cd-8c01-4688-9347-c8d983fecf62,DISK], DatanodeInfoWithStorage[127.0.0.1:44324,DS-721c1dca-7963-4634-97fb-09301a8281d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36000,DS-d5860999-a600-4ce3-8740-5396675a4eae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 99
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1269996542-172.17.0.10-1597392298111:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40220,DS-a29a2d50-7335-4c43-a25f-c8ca1f22c733,DISK], DatanodeInfoWithStorage[127.0.0.1:41238,DS-af78f957-3742-47b7-a6d2-feffa7598a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:34779,DS-ef9d1483-2956-47a1-9969-841106e78a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:38748,DS-07dab8bc-750d-4a84-98ac-da80ec4fa40c,DISK], DatanodeInfoWithStorage[127.0.0.1:43368,DS-84dc7f14-ace6-4caf-9d9e-0d57804ad95a,DISK], DatanodeInfoWithStorage[127.0.0.1:44457,DS-ff3f976d-d65f-4c99-9386-54c22c5c13d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42116,DS-f976de33-40c7-4ea7-b2ba-e554704b6175,DISK], DatanodeInfoWithStorage[127.0.0.1:41770,DS-f98a10ad-f73c-4742-99fa-83b53dd41417,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1269996542-172.17.0.10-1597392298111:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40220,DS-a29a2d50-7335-4c43-a25f-c8ca1f22c733,DISK], DatanodeInfoWithStorage[127.0.0.1:41238,DS-af78f957-3742-47b7-a6d2-feffa7598a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:34779,DS-ef9d1483-2956-47a1-9969-841106e78a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:38748,DS-07dab8bc-750d-4a84-98ac-da80ec4fa40c,DISK], DatanodeInfoWithStorage[127.0.0.1:43368,DS-84dc7f14-ace6-4caf-9d9e-0d57804ad95a,DISK], DatanodeInfoWithStorage[127.0.0.1:44457,DS-ff3f976d-d65f-4c99-9386-54c22c5c13d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42116,DS-f976de33-40c7-4ea7-b2ba-e554704b6175,DISK], DatanodeInfoWithStorage[127.0.0.1:41770,DS-f98a10ad-f73c-4742-99fa-83b53dd41417,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 99
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-130759279-172.17.0.10-1597392525717:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34249,DS-bb779d66-1d38-40fb-a8fe-0d401413d7f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39481,DS-09b1cb7d-8e00-4cf1-ab18-5fee701c4517,DISK], DatanodeInfoWithStorage[127.0.0.1:44570,DS-62c91fa6-5dec-485f-8150-ef4234bb7510,DISK], DatanodeInfoWithStorage[127.0.0.1:33212,DS-712a3512-385d-434c-9cbe-5145d4f14f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37211,DS-6646c931-182f-4bc2-9669-e6e1ce558d09,DISK], DatanodeInfoWithStorage[127.0.0.1:34623,DS-c7f68dd2-90b4-4a99-85f4-7169d2debdd6,DISK], DatanodeInfoWithStorage[127.0.0.1:45632,DS-8900dfcb-a4f3-4c66-aa53-a1e25344dbc9,DISK], DatanodeInfoWithStorage[127.0.0.1:40830,DS-e7bc9bb5-d8c8-4053-ac42-0060ffcfcb6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-130759279-172.17.0.10-1597392525717:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34249,DS-bb779d66-1d38-40fb-a8fe-0d401413d7f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39481,DS-09b1cb7d-8e00-4cf1-ab18-5fee701c4517,DISK], DatanodeInfoWithStorage[127.0.0.1:44570,DS-62c91fa6-5dec-485f-8150-ef4234bb7510,DISK], DatanodeInfoWithStorage[127.0.0.1:33212,DS-712a3512-385d-434c-9cbe-5145d4f14f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37211,DS-6646c931-182f-4bc2-9669-e6e1ce558d09,DISK], DatanodeInfoWithStorage[127.0.0.1:34623,DS-c7f68dd2-90b4-4a99-85f4-7169d2debdd6,DISK], DatanodeInfoWithStorage[127.0.0.1:45632,DS-8900dfcb-a4f3-4c66-aa53-a1e25344dbc9,DISK], DatanodeInfoWithStorage[127.0.0.1:40830,DS-e7bc9bb5-d8c8-4053-ac42-0060ffcfcb6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 99
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-975035892-172.17.0.10-1597392682365:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36805,DS-e2b5cf06-3014-495b-b351-adbc4a5ac863,DISK], DatanodeInfoWithStorage[127.0.0.1:34196,DS-4285447f-691d-4c75-9f69-65640a75045a,DISK], DatanodeInfoWithStorage[127.0.0.1:38510,DS-165ef4d3-1ceb-4bc6-92ff-dbccd66c2633,DISK], DatanodeInfoWithStorage[127.0.0.1:44070,DS-96870d40-c519-4fb5-9167-211df9f65ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:37040,DS-d6c13ab7-a11a-439e-9387-ba45bfebebfa,DISK], DatanodeInfoWithStorage[127.0.0.1:38588,DS-80efaeea-6e26-4e02-a51a-d69e0b4ff8e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33743,DS-be9d4e3f-fa52-4fba-86d1-d5090ac1a748,DISK], DatanodeInfoWithStorage[127.0.0.1:39792,DS-c76a87f8-7e98-4458-898b-226376c857cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-975035892-172.17.0.10-1597392682365:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36805,DS-e2b5cf06-3014-495b-b351-adbc4a5ac863,DISK], DatanodeInfoWithStorage[127.0.0.1:34196,DS-4285447f-691d-4c75-9f69-65640a75045a,DISK], DatanodeInfoWithStorage[127.0.0.1:38510,DS-165ef4d3-1ceb-4bc6-92ff-dbccd66c2633,DISK], DatanodeInfoWithStorage[127.0.0.1:44070,DS-96870d40-c519-4fb5-9167-211df9f65ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:37040,DS-d6c13ab7-a11a-439e-9387-ba45bfebebfa,DISK], DatanodeInfoWithStorage[127.0.0.1:38588,DS-80efaeea-6e26-4e02-a51a-d69e0b4ff8e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33743,DS-be9d4e3f-fa52-4fba-86d1-d5090ac1a748,DISK], DatanodeInfoWithStorage[127.0.0.1:39792,DS-c76a87f8-7e98-4458-898b-226376c857cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 99
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1337668775-172.17.0.10-1597392794140:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39759,DS-2468ac1b-ab3b-457f-9634-4620251beb27,DISK], DatanodeInfoWithStorage[127.0.0.1:39849,DS-b3e6422a-3d99-453c-a024-c7a98d5cc18c,DISK], DatanodeInfoWithStorage[127.0.0.1:33586,DS-9e870b6c-6cd6-4d39-b340-c197ea14abfb,DISK], DatanodeInfoWithStorage[127.0.0.1:36101,DS-4ace8497-89de-4bfb-a91f-0180d99aaf28,DISK], DatanodeInfoWithStorage[127.0.0.1:43789,DS-3d180113-c6c4-4a5d-bfb5-a1b16126d1e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37602,DS-5f6f186e-32ca-470e-ba2e-7e23e67a546e,DISK], DatanodeInfoWithStorage[127.0.0.1:35925,DS-ec425db4-68fd-4bd9-bbbd-f1bf18f3bfb4,DISK], DatanodeInfoWithStorage[127.0.0.1:45149,DS-334fdbe7-24ba-4934-a2da-2f2bb4b17930,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1337668775-172.17.0.10-1597392794140:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39759,DS-2468ac1b-ab3b-457f-9634-4620251beb27,DISK], DatanodeInfoWithStorage[127.0.0.1:39849,DS-b3e6422a-3d99-453c-a024-c7a98d5cc18c,DISK], DatanodeInfoWithStorage[127.0.0.1:33586,DS-9e870b6c-6cd6-4d39-b340-c197ea14abfb,DISK], DatanodeInfoWithStorage[127.0.0.1:36101,DS-4ace8497-89de-4bfb-a91f-0180d99aaf28,DISK], DatanodeInfoWithStorage[127.0.0.1:43789,DS-3d180113-c6c4-4a5d-bfb5-a1b16126d1e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37602,DS-5f6f186e-32ca-470e-ba2e-7e23e67a546e,DISK], DatanodeInfoWithStorage[127.0.0.1:35925,DS-ec425db4-68fd-4bd9-bbbd-f1bf18f3bfb4,DISK], DatanodeInfoWithStorage[127.0.0.1:45149,DS-334fdbe7-24ba-4934-a2da-2f2bb4b17930,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 99
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1004147029-172.17.0.10-1597393695127:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41360,DS-78069c4b-d6ff-4061-b2cd-2b344e313203,DISK], DatanodeInfoWithStorage[127.0.0.1:35727,DS-e8448869-789b-4945-8626-f3097449ce96,DISK], DatanodeInfoWithStorage[127.0.0.1:38773,DS-115a7b75-b1fb-4dbf-bf65-61ed8c5f5285,DISK], DatanodeInfoWithStorage[127.0.0.1:41599,DS-414dd89d-7515-4df1-a125-25b8dd76028b,DISK], DatanodeInfoWithStorage[127.0.0.1:44970,DS-3f2fd62e-e04f-46b3-9550-642c7c26e3b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43861,DS-4cdee9ba-88fa-49ce-bb39-3963872092b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36986,DS-33d1a49b-c659-496c-89a2-da982f799973,DISK], DatanodeInfoWithStorage[127.0.0.1:40473,DS-6e69c1d4-99b4-45a8-9cfc-2ccea6a8c520,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1004147029-172.17.0.10-1597393695127:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41360,DS-78069c4b-d6ff-4061-b2cd-2b344e313203,DISK], DatanodeInfoWithStorage[127.0.0.1:35727,DS-e8448869-789b-4945-8626-f3097449ce96,DISK], DatanodeInfoWithStorage[127.0.0.1:38773,DS-115a7b75-b1fb-4dbf-bf65-61ed8c5f5285,DISK], DatanodeInfoWithStorage[127.0.0.1:41599,DS-414dd89d-7515-4df1-a125-25b8dd76028b,DISK], DatanodeInfoWithStorage[127.0.0.1:44970,DS-3f2fd62e-e04f-46b3-9550-642c7c26e3b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43861,DS-4cdee9ba-88fa-49ce-bb39-3963872092b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36986,DS-33d1a49b-c659-496c-89a2-da982f799973,DISK], DatanodeInfoWithStorage[127.0.0.1:40473,DS-6e69c1d4-99b4-45a8-9cfc-2ccea6a8c520,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 99
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1802772958-172.17.0.10-1597394151403:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40064,DS-da5ae6fa-7a80-4ccd-8122-c8379a7bd0b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34276,DS-ae4753c1-a405-4186-aab5-693e6ad4ee6f,DISK], DatanodeInfoWithStorage[127.0.0.1:41923,DS-27cd90da-6e7b-4b4b-a94c-8608b1daa5dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35622,DS-74259a6b-1161-45e2-8678-d15b8f44b64d,DISK], DatanodeInfoWithStorage[127.0.0.1:36385,DS-98a5ff52-dc50-48ce-bd2a-6f557745186f,DISK], DatanodeInfoWithStorage[127.0.0.1:43675,DS-c1988b5b-a158-465d-8d2b-e229348cc5d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34905,DS-bb0810ca-f440-403c-9438-a9bae41a2484,DISK], DatanodeInfoWithStorage[127.0.0.1:40637,DS-4807eeb8-baa4-4531-9218-1cb9f067f0c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1802772958-172.17.0.10-1597394151403:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40064,DS-da5ae6fa-7a80-4ccd-8122-c8379a7bd0b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34276,DS-ae4753c1-a405-4186-aab5-693e6ad4ee6f,DISK], DatanodeInfoWithStorage[127.0.0.1:41923,DS-27cd90da-6e7b-4b4b-a94c-8608b1daa5dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35622,DS-74259a6b-1161-45e2-8678-d15b8f44b64d,DISK], DatanodeInfoWithStorage[127.0.0.1:36385,DS-98a5ff52-dc50-48ce-bd2a-6f557745186f,DISK], DatanodeInfoWithStorage[127.0.0.1:43675,DS-c1988b5b-a158-465d-8d2b-e229348cc5d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34905,DS-bb0810ca-f440-403c-9438-a9bae41a2484,DISK], DatanodeInfoWithStorage[127.0.0.1:40637,DS-4807eeb8-baa4-4531-9218-1cb9f067f0c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 99
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-744709856-172.17.0.10-1597394224878:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35747,DS-3ed217fa-609a-4a88-b40a-c1b8643f165a,DISK], DatanodeInfoWithStorage[127.0.0.1:46475,DS-f015f1ab-6578-4154-928a-78dfec8bdcaa,DISK], DatanodeInfoWithStorage[127.0.0.1:40671,DS-4d361be2-fa94-4176-80f1-bef952e868e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44447,DS-f107f555-5be0-4657-9f35-b0ffb0317085,DISK], DatanodeInfoWithStorage[127.0.0.1:41676,DS-5bdd0777-d633-409e-9ab1-c081ee39bca5,DISK], DatanodeInfoWithStorage[127.0.0.1:37745,DS-a9bd6ef8-0b69-4a7f-868a-101efaf6cec3,DISK], DatanodeInfoWithStorage[127.0.0.1:44913,DS-15cc7e1b-f046-4edd-bf3f-5a8d279d3c62,DISK], DatanodeInfoWithStorage[127.0.0.1:39359,DS-3f698dc0-1c41-4cc3-af14-36cd70156d64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-744709856-172.17.0.10-1597394224878:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35747,DS-3ed217fa-609a-4a88-b40a-c1b8643f165a,DISK], DatanodeInfoWithStorage[127.0.0.1:46475,DS-f015f1ab-6578-4154-928a-78dfec8bdcaa,DISK], DatanodeInfoWithStorage[127.0.0.1:40671,DS-4d361be2-fa94-4176-80f1-bef952e868e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44447,DS-f107f555-5be0-4657-9f35-b0ffb0317085,DISK], DatanodeInfoWithStorage[127.0.0.1:41676,DS-5bdd0777-d633-409e-9ab1-c081ee39bca5,DISK], DatanodeInfoWithStorage[127.0.0.1:37745,DS-a9bd6ef8-0b69-4a7f-868a-101efaf6cec3,DISK], DatanodeInfoWithStorage[127.0.0.1:44913,DS-15cc7e1b-f046-4edd-bf3f-5a8d279d3c62,DISK], DatanodeInfoWithStorage[127.0.0.1:39359,DS-3f698dc0-1c41-4cc3-af14-36cd70156d64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 99
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1909417065-172.17.0.10-1597394615913:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46857,DS-d94ab442-eb18-4dfa-b547-e2f160a8b7d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42905,DS-f0ac62a0-3476-44ce-987b-608712fc6440,DISK], DatanodeInfoWithStorage[127.0.0.1:44404,DS-3e726168-a749-40c1-a61b-bf206adf176c,DISK], DatanodeInfoWithStorage[127.0.0.1:46760,DS-60c0974a-8e60-4764-b2c8-bcb5696d2668,DISK], DatanodeInfoWithStorage[127.0.0.1:34332,DS-5b153852-85a4-4638-83f5-585d3a51bbf9,DISK], DatanodeInfoWithStorage[127.0.0.1:37276,DS-1f0d5c5c-a935-4c18-bcd3-7dc857e7ccfa,DISK], DatanodeInfoWithStorage[127.0.0.1:35120,DS-66c8b43b-24d4-4f6a-a638-5812d2e25e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:43212,DS-b19e1592-d9dc-448c-ba01-12aec9454474,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1909417065-172.17.0.10-1597394615913:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46857,DS-d94ab442-eb18-4dfa-b547-e2f160a8b7d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42905,DS-f0ac62a0-3476-44ce-987b-608712fc6440,DISK], DatanodeInfoWithStorage[127.0.0.1:44404,DS-3e726168-a749-40c1-a61b-bf206adf176c,DISK], DatanodeInfoWithStorage[127.0.0.1:46760,DS-60c0974a-8e60-4764-b2c8-bcb5696d2668,DISK], DatanodeInfoWithStorage[127.0.0.1:34332,DS-5b153852-85a4-4638-83f5-585d3a51bbf9,DISK], DatanodeInfoWithStorage[127.0.0.1:37276,DS-1f0d5c5c-a935-4c18-bcd3-7dc857e7ccfa,DISK], DatanodeInfoWithStorage[127.0.0.1:35120,DS-66c8b43b-24d4-4f6a-a638-5812d2e25e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:43212,DS-b19e1592-d9dc-448c-ba01-12aec9454474,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 99
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1279952553-172.17.0.10-1597395032595:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44601,DS-bcfbad39-ae0d-47b5-888f-e0b61abb23d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43494,DS-b4915189-145f-4e50-90eb-4b42b44ed23d,DISK], DatanodeInfoWithStorage[127.0.0.1:33795,DS-b04d3335-5258-4fb3-b479-ce6be7ae0573,DISK], DatanodeInfoWithStorage[127.0.0.1:34531,DS-fd34447d-9860-4544-9ade-8f88e13a42f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44528,DS-ba5457e3-e2cf-493e-80a2-af863b5e7f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34714,DS-3c1cd1fd-bccc-4aa2-83cf-8f13ef760d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:39678,DS-2a5b1b03-bc44-4580-847e-f3297d3f44fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40324,DS-786b11ec-50b9-4ba8-90c8-21195140983f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1279952553-172.17.0.10-1597395032595:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44601,DS-bcfbad39-ae0d-47b5-888f-e0b61abb23d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43494,DS-b4915189-145f-4e50-90eb-4b42b44ed23d,DISK], DatanodeInfoWithStorage[127.0.0.1:33795,DS-b04d3335-5258-4fb3-b479-ce6be7ae0573,DISK], DatanodeInfoWithStorage[127.0.0.1:34531,DS-fd34447d-9860-4544-9ade-8f88e13a42f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44528,DS-ba5457e3-e2cf-493e-80a2-af863b5e7f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34714,DS-3c1cd1fd-bccc-4aa2-83cf-8f13ef760d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:39678,DS-2a5b1b03-bc44-4580-847e-f3297d3f44fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40324,DS-786b11ec-50b9-4ba8-90c8-21195140983f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 99
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1667794150-172.17.0.10-1597395686205:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42954,DS-0918cfea-a765-4ac4-b68f-9760b3ad542f,DISK], DatanodeInfoWithStorage[127.0.0.1:38481,DS-eb901b6d-6801-4c42-840f-6eccdb08ed61,DISK], DatanodeInfoWithStorage[127.0.0.1:46609,DS-dc68cf5f-7b60-4794-ab85-6ce22b2416b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40251,DS-cf9d1771-b070-4c62-a5a7-800a7c67abc9,DISK], DatanodeInfoWithStorage[127.0.0.1:38316,DS-7a169345-344e-4a1c-af75-d95e18d985bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36673,DS-79c1463c-651c-4d0c-b082-5740328c38af,DISK], DatanodeInfoWithStorage[127.0.0.1:42789,DS-c3afa896-dc7d-4da5-9cb8-9fcaaf4f2294,DISK], DatanodeInfoWithStorage[127.0.0.1:36720,DS-28b590be-5c58-49ed-b9c7-7a42d96fe826,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1667794150-172.17.0.10-1597395686205:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42954,DS-0918cfea-a765-4ac4-b68f-9760b3ad542f,DISK], DatanodeInfoWithStorage[127.0.0.1:38481,DS-eb901b6d-6801-4c42-840f-6eccdb08ed61,DISK], DatanodeInfoWithStorage[127.0.0.1:46609,DS-dc68cf5f-7b60-4794-ab85-6ce22b2416b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40251,DS-cf9d1771-b070-4c62-a5a7-800a7c67abc9,DISK], DatanodeInfoWithStorage[127.0.0.1:38316,DS-7a169345-344e-4a1c-af75-d95e18d985bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36673,DS-79c1463c-651c-4d0c-b082-5740328c38af,DISK], DatanodeInfoWithStorage[127.0.0.1:42789,DS-c3afa896-dc7d-4da5-9cb8-9fcaaf4f2294,DISK], DatanodeInfoWithStorage[127.0.0.1:36720,DS-28b590be-5c58-49ed-b9c7-7a42d96fe826,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5641
