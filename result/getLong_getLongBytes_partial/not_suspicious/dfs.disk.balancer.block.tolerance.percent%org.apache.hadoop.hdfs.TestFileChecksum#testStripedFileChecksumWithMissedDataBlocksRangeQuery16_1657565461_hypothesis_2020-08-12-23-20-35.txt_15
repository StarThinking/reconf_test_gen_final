reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1283129244-172.17.0.4-1597274488588:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42645,DS-602953e8-47a8-4a4e-91d6-9b2f850aa0d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39292,DS-cd3853db-bde9-45e7-88d9-10f345c2296b,DISK], DatanodeInfoWithStorage[127.0.0.1:42586,DS-ec8c841c-510a-4b8f-b350-6419a4be50a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35588,DS-39416cd0-b5c9-4748-8051-85e725fca590,DISK], DatanodeInfoWithStorage[127.0.0.1:38193,DS-e69c12e2-3257-44bd-a501-cc7759bb2383,DISK], DatanodeInfoWithStorage[127.0.0.1:43195,DS-e0e768cc-0320-49c5-bc59-0604d0a80559,DISK], DatanodeInfoWithStorage[127.0.0.1:43364,DS-826ba91c-cda3-411c-a452-fd9b218d87a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39053,DS-246bb4cc-140c-4e87-8bcd-000f3f48b852,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1283129244-172.17.0.4-1597274488588:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42645,DS-602953e8-47a8-4a4e-91d6-9b2f850aa0d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39292,DS-cd3853db-bde9-45e7-88d9-10f345c2296b,DISK], DatanodeInfoWithStorage[127.0.0.1:42586,DS-ec8c841c-510a-4b8f-b350-6419a4be50a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35588,DS-39416cd0-b5c9-4748-8051-85e725fca590,DISK], DatanodeInfoWithStorage[127.0.0.1:38193,DS-e69c12e2-3257-44bd-a501-cc7759bb2383,DISK], DatanodeInfoWithStorage[127.0.0.1:43195,DS-e0e768cc-0320-49c5-bc59-0604d0a80559,DISK], DatanodeInfoWithStorage[127.0.0.1:43364,DS-826ba91c-cda3-411c-a452-fd9b218d87a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39053,DS-246bb4cc-140c-4e87-8bcd-000f3f48b852,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-405795061-172.17.0.4-1597274524218:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45020,DS-b1653ea9-a362-453b-af0b-ff6150ef08a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41610,DS-d58067fc-0701-46b2-890a-042fa7b21ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:44862,DS-3e1253ad-7008-4a5c-861a-6a5b15359cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:40988,DS-53d64b87-6476-4a94-bc5f-a03a56ecace8,DISK], DatanodeInfoWithStorage[127.0.0.1:38553,DS-9d7686f6-3e09-4881-9c91-c74f30050c66,DISK], DatanodeInfoWithStorage[127.0.0.1:35311,DS-b20ebbd3-a364-42f9-a5d4-25851e309109,DISK], DatanodeInfoWithStorage[127.0.0.1:34848,DS-170aa923-e629-4228-83a9-2120e53f458f,DISK], DatanodeInfoWithStorage[127.0.0.1:35399,DS-8e08ce31-94ae-42d8-913f-a90fa249b457,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-405795061-172.17.0.4-1597274524218:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45020,DS-b1653ea9-a362-453b-af0b-ff6150ef08a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41610,DS-d58067fc-0701-46b2-890a-042fa7b21ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:44862,DS-3e1253ad-7008-4a5c-861a-6a5b15359cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:40988,DS-53d64b87-6476-4a94-bc5f-a03a56ecace8,DISK], DatanodeInfoWithStorage[127.0.0.1:38553,DS-9d7686f6-3e09-4881-9c91-c74f30050c66,DISK], DatanodeInfoWithStorage[127.0.0.1:35311,DS-b20ebbd3-a364-42f9-a5d4-25851e309109,DISK], DatanodeInfoWithStorage[127.0.0.1:34848,DS-170aa923-e629-4228-83a9-2120e53f458f,DISK], DatanodeInfoWithStorage[127.0.0.1:35399,DS-8e08ce31-94ae-42d8-913f-a90fa249b457,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1685116790-172.17.0.4-1597274557458:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41483,DS-c0894db6-64d3-4bef-a63a-303d290e932a,DISK], DatanodeInfoWithStorage[127.0.0.1:38612,DS-3618837e-24a1-4246-812a-14b829598ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:40711,DS-efcf0b78-9c36-43d5-b6c8-1f2fa7bcc604,DISK], DatanodeInfoWithStorage[127.0.0.1:43280,DS-3cf26e7b-1541-4498-abcf-07948225a6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36528,DS-8f432d76-4320-4789-93d9-a1ad7408ef58,DISK], DatanodeInfoWithStorage[127.0.0.1:39235,DS-62d6cc70-7b3b-455d-88dd-5f394ab0141b,DISK], DatanodeInfoWithStorage[127.0.0.1:38631,DS-4588ff4a-b9b2-4f11-84f2-76ecafdd250d,DISK], DatanodeInfoWithStorage[127.0.0.1:43526,DS-ba6bcc39-cf82-46ba-854b-84c2261fc8e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1685116790-172.17.0.4-1597274557458:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41483,DS-c0894db6-64d3-4bef-a63a-303d290e932a,DISK], DatanodeInfoWithStorage[127.0.0.1:38612,DS-3618837e-24a1-4246-812a-14b829598ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:40711,DS-efcf0b78-9c36-43d5-b6c8-1f2fa7bcc604,DISK], DatanodeInfoWithStorage[127.0.0.1:43280,DS-3cf26e7b-1541-4498-abcf-07948225a6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36528,DS-8f432d76-4320-4789-93d9-a1ad7408ef58,DISK], DatanodeInfoWithStorage[127.0.0.1:39235,DS-62d6cc70-7b3b-455d-88dd-5f394ab0141b,DISK], DatanodeInfoWithStorage[127.0.0.1:38631,DS-4588ff4a-b9b2-4f11-84f2-76ecafdd250d,DISK], DatanodeInfoWithStorage[127.0.0.1:43526,DS-ba6bcc39-cf82-46ba-854b-84c2261fc8e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-166445014-172.17.0.4-1597274817760:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40190,DS-190cfe69-ad53-4544-9171-f18536dc7c17,DISK], DatanodeInfoWithStorage[127.0.0.1:36927,DS-b0352a4e-d003-4989-88fe-8846506adf7f,DISK], DatanodeInfoWithStorage[127.0.0.1:42657,DS-112e2261-b0a7-4c89-b8f0-0fc4d625af26,DISK], DatanodeInfoWithStorage[127.0.0.1:44527,DS-dfd707ed-73d3-461a-85fb-5b1ebf1ef328,DISK], DatanodeInfoWithStorage[127.0.0.1:41706,DS-3f1363dd-a7d4-49ff-b7d8-4072bdb049d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33769,DS-54764a8b-64bc-4ba1-9931-7587940c28e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40049,DS-bb189a7c-ebd4-416b-9868-3088d9fb4626,DISK], DatanodeInfoWithStorage[127.0.0.1:42272,DS-b7c33f9b-f8ff-4099-9342-fa440b10761b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-166445014-172.17.0.4-1597274817760:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40190,DS-190cfe69-ad53-4544-9171-f18536dc7c17,DISK], DatanodeInfoWithStorage[127.0.0.1:36927,DS-b0352a4e-d003-4989-88fe-8846506adf7f,DISK], DatanodeInfoWithStorage[127.0.0.1:42657,DS-112e2261-b0a7-4c89-b8f0-0fc4d625af26,DISK], DatanodeInfoWithStorage[127.0.0.1:44527,DS-dfd707ed-73d3-461a-85fb-5b1ebf1ef328,DISK], DatanodeInfoWithStorage[127.0.0.1:41706,DS-3f1363dd-a7d4-49ff-b7d8-4072bdb049d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33769,DS-54764a8b-64bc-4ba1-9931-7587940c28e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40049,DS-bb189a7c-ebd4-416b-9868-3088d9fb4626,DISK], DatanodeInfoWithStorage[127.0.0.1:42272,DS-b7c33f9b-f8ff-4099-9342-fa440b10761b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1945366798-172.17.0.4-1597275351958:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42509,DS-afee8f98-f4eb-4f4f-849d-1bf039d4b056,DISK], DatanodeInfoWithStorage[127.0.0.1:38092,DS-5d02d70e-607d-41f2-be31-2e4e8d99773f,DISK], DatanodeInfoWithStorage[127.0.0.1:36873,DS-66e6b68c-0126-4740-a539-0203802c1f80,DISK], DatanodeInfoWithStorage[127.0.0.1:45631,DS-10524364-c56c-4a95-8caa-a217de97b525,DISK], DatanodeInfoWithStorage[127.0.0.1:36530,DS-6369bc37-14b7-4364-890c-55e08085b103,DISK], DatanodeInfoWithStorage[127.0.0.1:33901,DS-45cf54f0-2c5c-4753-809a-f2b2438afaf6,DISK], DatanodeInfoWithStorage[127.0.0.1:33298,DS-3c6222bf-5649-49d4-9155-32e77b1b401c,DISK], DatanodeInfoWithStorage[127.0.0.1:44289,DS-749d4472-1625-4c19-8336-2b2942ac9f9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1945366798-172.17.0.4-1597275351958:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42509,DS-afee8f98-f4eb-4f4f-849d-1bf039d4b056,DISK], DatanodeInfoWithStorage[127.0.0.1:38092,DS-5d02d70e-607d-41f2-be31-2e4e8d99773f,DISK], DatanodeInfoWithStorage[127.0.0.1:36873,DS-66e6b68c-0126-4740-a539-0203802c1f80,DISK], DatanodeInfoWithStorage[127.0.0.1:45631,DS-10524364-c56c-4a95-8caa-a217de97b525,DISK], DatanodeInfoWithStorage[127.0.0.1:36530,DS-6369bc37-14b7-4364-890c-55e08085b103,DISK], DatanodeInfoWithStorage[127.0.0.1:33901,DS-45cf54f0-2c5c-4753-809a-f2b2438afaf6,DISK], DatanodeInfoWithStorage[127.0.0.1:33298,DS-3c6222bf-5649-49d4-9155-32e77b1b401c,DISK], DatanodeInfoWithStorage[127.0.0.1:44289,DS-749d4472-1625-4c19-8336-2b2942ac9f9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1429574382-172.17.0.4-1597275687109:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33843,DS-772d0b53-4ed4-45cb-9dbf-e85c433a3c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:45396,DS-6c50e46e-2fec-4743-8b3c-099bfb302dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:39208,DS-3de908ca-60b7-4b22-a3f1-ad45043cecf3,DISK], DatanodeInfoWithStorage[127.0.0.1:41042,DS-2ba22917-0d8d-428c-808e-a04784b1f740,DISK], DatanodeInfoWithStorage[127.0.0.1:38743,DS-566a1065-52ae-4ea9-b631-8465c96a117e,DISK], DatanodeInfoWithStorage[127.0.0.1:37473,DS-032f1af3-813b-4906-a62c-367d039407a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37751,DS-2f92e865-9fd8-4df1-8f53-c333c379c8d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46725,DS-9b700737-f980-4ee0-87cf-fc62d69b67e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1429574382-172.17.0.4-1597275687109:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33843,DS-772d0b53-4ed4-45cb-9dbf-e85c433a3c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:45396,DS-6c50e46e-2fec-4743-8b3c-099bfb302dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:39208,DS-3de908ca-60b7-4b22-a3f1-ad45043cecf3,DISK], DatanodeInfoWithStorage[127.0.0.1:41042,DS-2ba22917-0d8d-428c-808e-a04784b1f740,DISK], DatanodeInfoWithStorage[127.0.0.1:38743,DS-566a1065-52ae-4ea9-b631-8465c96a117e,DISK], DatanodeInfoWithStorage[127.0.0.1:37473,DS-032f1af3-813b-4906-a62c-367d039407a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37751,DS-2f92e865-9fd8-4df1-8f53-c333c379c8d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46725,DS-9b700737-f980-4ee0-87cf-fc62d69b67e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-250718105-172.17.0.4-1597276396968:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32801,DS-a8938055-2727-452f-beb6-cac5dd54ca27,DISK], DatanodeInfoWithStorage[127.0.0.1:41740,DS-b8680bc2-04a0-406d-aba5-a6028aaa251d,DISK], DatanodeInfoWithStorage[127.0.0.1:43590,DS-19e58ecf-f300-41c6-bf6d-5a765df81a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35162,DS-7eb01f43-3509-4007-ad6f-415adddacc22,DISK], DatanodeInfoWithStorage[127.0.0.1:38157,DS-8d74f567-8770-4c24-8dc5-2393c8c2b0fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38086,DS-1e436207-2fe4-49da-93d7-9af938f23d09,DISK], DatanodeInfoWithStorage[127.0.0.1:45989,DS-2923c53a-fb52-41f3-9504-f026fd9fe1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40970,DS-18a058b9-5b03-4dc7-baef-02ce8f2e423d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-250718105-172.17.0.4-1597276396968:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32801,DS-a8938055-2727-452f-beb6-cac5dd54ca27,DISK], DatanodeInfoWithStorage[127.0.0.1:41740,DS-b8680bc2-04a0-406d-aba5-a6028aaa251d,DISK], DatanodeInfoWithStorage[127.0.0.1:43590,DS-19e58ecf-f300-41c6-bf6d-5a765df81a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35162,DS-7eb01f43-3509-4007-ad6f-415adddacc22,DISK], DatanodeInfoWithStorage[127.0.0.1:38157,DS-8d74f567-8770-4c24-8dc5-2393c8c2b0fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38086,DS-1e436207-2fe4-49da-93d7-9af938f23d09,DISK], DatanodeInfoWithStorage[127.0.0.1:45989,DS-2923c53a-fb52-41f3-9504-f026fd9fe1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40970,DS-18a058b9-5b03-4dc7-baef-02ce8f2e423d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-802949882-172.17.0.4-1597276547493:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46283,DS-a796f572-d5b2-4b2c-9bf2-e5d2cabb441b,DISK], DatanodeInfoWithStorage[127.0.0.1:36012,DS-9de0257a-39ca-40d5-91df-2b0dd0537bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:46174,DS-53018e6d-4fb4-4bad-b188-0e4720449fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:46580,DS-1bca36a0-5b75-4de7-b3bf-99b30acc9659,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-c161bec3-720e-4f3b-8e01-d0a0ff10ee6e,DISK], DatanodeInfoWithStorage[127.0.0.1:33859,DS-e497d901-83e3-4383-9e7e-a4162be114c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34159,DS-b736911e-e92a-40cf-b7f6-d60792bd2301,DISK], DatanodeInfoWithStorage[127.0.0.1:40754,DS-1046978c-9091-432a-b2e3-94b9d4953b12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-802949882-172.17.0.4-1597276547493:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46283,DS-a796f572-d5b2-4b2c-9bf2-e5d2cabb441b,DISK], DatanodeInfoWithStorage[127.0.0.1:36012,DS-9de0257a-39ca-40d5-91df-2b0dd0537bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:46174,DS-53018e6d-4fb4-4bad-b188-0e4720449fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:46580,DS-1bca36a0-5b75-4de7-b3bf-99b30acc9659,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-c161bec3-720e-4f3b-8e01-d0a0ff10ee6e,DISK], DatanodeInfoWithStorage[127.0.0.1:33859,DS-e497d901-83e3-4383-9e7e-a4162be114c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34159,DS-b736911e-e92a-40cf-b7f6-d60792bd2301,DISK], DatanodeInfoWithStorage[127.0.0.1:40754,DS-1046978c-9091-432a-b2e3-94b9d4953b12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-673483630-172.17.0.4-1597276659704:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42617,DS-f0f7a44b-978d-4f99-bedd-96f75356b1c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33719,DS-1a7c94e5-92ac-488b-b472-6441dc2c5091,DISK], DatanodeInfoWithStorage[127.0.0.1:36151,DS-9c5f7e5c-5855-42b8-aac4-e850278c50fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34703,DS-d847c468-885d-4bc0-8f02-44a65a1d2e61,DISK], DatanodeInfoWithStorage[127.0.0.1:42789,DS-3f114be4-6ff2-4d43-a075-c82543f911b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38841,DS-447142cd-10b5-4c17-9ec3-7c50b920247e,DISK], DatanodeInfoWithStorage[127.0.0.1:39610,DS-d7f816e0-4c75-4d67-b30c-9a6246445207,DISK], DatanodeInfoWithStorage[127.0.0.1:46302,DS-d68684b7-c718-42b8-aa33-592173c80f43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-673483630-172.17.0.4-1597276659704:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42617,DS-f0f7a44b-978d-4f99-bedd-96f75356b1c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33719,DS-1a7c94e5-92ac-488b-b472-6441dc2c5091,DISK], DatanodeInfoWithStorage[127.0.0.1:36151,DS-9c5f7e5c-5855-42b8-aac4-e850278c50fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34703,DS-d847c468-885d-4bc0-8f02-44a65a1d2e61,DISK], DatanodeInfoWithStorage[127.0.0.1:42789,DS-3f114be4-6ff2-4d43-a075-c82543f911b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38841,DS-447142cd-10b5-4c17-9ec3-7c50b920247e,DISK], DatanodeInfoWithStorage[127.0.0.1:39610,DS-d7f816e0-4c75-4d67-b30c-9a6246445207,DISK], DatanodeInfoWithStorage[127.0.0.1:46302,DS-d68684b7-c718-42b8-aa33-592173c80f43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1301152219-172.17.0.4-1597276731257:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35368,DS-3045b58a-fc09-4cad-b3d4-0e91fa305df2,DISK], DatanodeInfoWithStorage[127.0.0.1:43337,DS-13762114-d05c-47ba-99ee-6c8f1c5e0c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:46641,DS-10b72b11-1700-4310-8781-4b6cd03908c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39612,DS-f2937414-5ada-4a24-a6c8-59aec6acfd82,DISK], DatanodeInfoWithStorage[127.0.0.1:43308,DS-9aa8625e-3cfc-467b-b711-e7b2c267d32d,DISK], DatanodeInfoWithStorage[127.0.0.1:45951,DS-52321dae-f10c-4992-863d-48d7c9fde903,DISK], DatanodeInfoWithStorage[127.0.0.1:45666,DS-7857494b-4746-4e9d-8c00-6360d87e91dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36847,DS-7c840fd5-91fa-44f9-8844-8eb50eaff993,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1301152219-172.17.0.4-1597276731257:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35368,DS-3045b58a-fc09-4cad-b3d4-0e91fa305df2,DISK], DatanodeInfoWithStorage[127.0.0.1:43337,DS-13762114-d05c-47ba-99ee-6c8f1c5e0c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:46641,DS-10b72b11-1700-4310-8781-4b6cd03908c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39612,DS-f2937414-5ada-4a24-a6c8-59aec6acfd82,DISK], DatanodeInfoWithStorage[127.0.0.1:43308,DS-9aa8625e-3cfc-467b-b711-e7b2c267d32d,DISK], DatanodeInfoWithStorage[127.0.0.1:45951,DS-52321dae-f10c-4992-863d-48d7c9fde903,DISK], DatanodeInfoWithStorage[127.0.0.1:45666,DS-7857494b-4746-4e9d-8c00-6360d87e91dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36847,DS-7c840fd5-91fa-44f9-8844-8eb50eaff993,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2109398253-172.17.0.4-1597276805049:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40770,DS-b5650666-f6dd-4b11-b302-7070cf425a59,DISK], DatanodeInfoWithStorage[127.0.0.1:46547,DS-de3edb36-8f7f-4289-81f9-620e47a75a60,DISK], DatanodeInfoWithStorage[127.0.0.1:45911,DS-c77a4a73-ba1a-4363-99fa-d4495d846530,DISK], DatanodeInfoWithStorage[127.0.0.1:36178,DS-c6985099-2ead-44e3-9f99-0a50cb982838,DISK], DatanodeInfoWithStorage[127.0.0.1:39085,DS-2cd25837-f037-4be6-9f88-323c2de25e87,DISK], DatanodeInfoWithStorage[127.0.0.1:38919,DS-81bbae08-62ed-4cfa-8694-a605553b14a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38597,DS-57a7092e-429a-4700-993a-4ae0d1f0c904,DISK], DatanodeInfoWithStorage[127.0.0.1:44651,DS-d7a8b3d0-20bb-4190-b091-3f39edef646e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2109398253-172.17.0.4-1597276805049:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40770,DS-b5650666-f6dd-4b11-b302-7070cf425a59,DISK], DatanodeInfoWithStorage[127.0.0.1:46547,DS-de3edb36-8f7f-4289-81f9-620e47a75a60,DISK], DatanodeInfoWithStorage[127.0.0.1:45911,DS-c77a4a73-ba1a-4363-99fa-d4495d846530,DISK], DatanodeInfoWithStorage[127.0.0.1:36178,DS-c6985099-2ead-44e3-9f99-0a50cb982838,DISK], DatanodeInfoWithStorage[127.0.0.1:39085,DS-2cd25837-f037-4be6-9f88-323c2de25e87,DISK], DatanodeInfoWithStorage[127.0.0.1:38919,DS-81bbae08-62ed-4cfa-8694-a605553b14a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38597,DS-57a7092e-429a-4700-993a-4ae0d1f0c904,DISK], DatanodeInfoWithStorage[127.0.0.1:44651,DS-d7a8b3d0-20bb-4190-b091-3f39edef646e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1699883983-172.17.0.4-1597276878258:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37427,DS-79695590-a588-4086-ac61-f24492331491,DISK], DatanodeInfoWithStorage[127.0.0.1:46091,DS-24370602-dd15-447e-bbaa-6381953777a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43022,DS-2c9b24d7-c3b4-443e-96a1-f2b518507efa,DISK], DatanodeInfoWithStorage[127.0.0.1:41026,DS-10a31665-3baf-4848-b12e-a5f0df1862b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45384,DS-03d41fd6-5307-4095-a897-50714eafca81,DISK], DatanodeInfoWithStorage[127.0.0.1:45230,DS-305b14a8-d75e-484c-b291-dc453ad52414,DISK], DatanodeInfoWithStorage[127.0.0.1:39007,DS-262f4a45-0088-4cb1-86f0-2dd31e0beea1,DISK], DatanodeInfoWithStorage[127.0.0.1:38247,DS-1cec340f-eb1a-4888-ba1a-e5c836c84a8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1699883983-172.17.0.4-1597276878258:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37427,DS-79695590-a588-4086-ac61-f24492331491,DISK], DatanodeInfoWithStorage[127.0.0.1:46091,DS-24370602-dd15-447e-bbaa-6381953777a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43022,DS-2c9b24d7-c3b4-443e-96a1-f2b518507efa,DISK], DatanodeInfoWithStorage[127.0.0.1:41026,DS-10a31665-3baf-4848-b12e-a5f0df1862b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45384,DS-03d41fd6-5307-4095-a897-50714eafca81,DISK], DatanodeInfoWithStorage[127.0.0.1:45230,DS-305b14a8-d75e-484c-b291-dc453ad52414,DISK], DatanodeInfoWithStorage[127.0.0.1:39007,DS-262f4a45-0088-4cb1-86f0-2dd31e0beea1,DISK], DatanodeInfoWithStorage[127.0.0.1:38247,DS-1cec340f-eb1a-4888-ba1a-e5c836c84a8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1108177083-172.17.0.4-1597277029722:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36685,DS-320c8ec1-335d-4ca2-b45d-1c9e079b3755,DISK], DatanodeInfoWithStorage[127.0.0.1:37643,DS-a78fdcb5-e30a-4609-bd2d-dddf17422981,DISK], DatanodeInfoWithStorage[127.0.0.1:45809,DS-e83d16f7-9c15-408b-a220-5e69d784628b,DISK], DatanodeInfoWithStorage[127.0.0.1:36732,DS-2577f236-8442-4a61-948b-3b6771ab94ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46452,DS-fc767a1d-0521-4dd2-bc40-83721e04c805,DISK], DatanodeInfoWithStorage[127.0.0.1:39177,DS-676b2792-2d2b-434c-8ed1-6f276b5145ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45412,DS-a6da6f9c-0998-471c-a380-b3f4dd653c95,DISK], DatanodeInfoWithStorage[127.0.0.1:41951,DS-7d8dc388-db1a-42fe-ac07-6fab38a89c6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1108177083-172.17.0.4-1597277029722:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36685,DS-320c8ec1-335d-4ca2-b45d-1c9e079b3755,DISK], DatanodeInfoWithStorage[127.0.0.1:37643,DS-a78fdcb5-e30a-4609-bd2d-dddf17422981,DISK], DatanodeInfoWithStorage[127.0.0.1:45809,DS-e83d16f7-9c15-408b-a220-5e69d784628b,DISK], DatanodeInfoWithStorage[127.0.0.1:36732,DS-2577f236-8442-4a61-948b-3b6771ab94ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46452,DS-fc767a1d-0521-4dd2-bc40-83721e04c805,DISK], DatanodeInfoWithStorage[127.0.0.1:39177,DS-676b2792-2d2b-434c-8ed1-6f276b5145ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45412,DS-a6da6f9c-0998-471c-a380-b3f4dd653c95,DISK], DatanodeInfoWithStorage[127.0.0.1:41951,DS-7d8dc388-db1a-42fe-ac07-6fab38a89c6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1827764913-172.17.0.4-1597277535639:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42129,DS-ff088cbc-5e0e-4e92-95fe-54bf666312ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38131,DS-aa87a99e-b378-438e-8e51-c35a19135c88,DISK], DatanodeInfoWithStorage[127.0.0.1:38519,DS-395f1eda-440f-4d5e-b5a1-0b6982a80fad,DISK], DatanodeInfoWithStorage[127.0.0.1:42257,DS-8374a11e-c96f-42ea-a1df-4a107d8680bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34711,DS-9e61908b-dbc1-447b-9a3d-5f669c31fa43,DISK], DatanodeInfoWithStorage[127.0.0.1:35699,DS-099abada-dbc7-4190-bc95-22ab189f42bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35913,DS-2543a76c-f290-43a2-bec7-053af091131a,DISK], DatanodeInfoWithStorage[127.0.0.1:34656,DS-278e2adc-64a8-4b63-a322-408c6f1a0c55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1827764913-172.17.0.4-1597277535639:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42129,DS-ff088cbc-5e0e-4e92-95fe-54bf666312ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38131,DS-aa87a99e-b378-438e-8e51-c35a19135c88,DISK], DatanodeInfoWithStorage[127.0.0.1:38519,DS-395f1eda-440f-4d5e-b5a1-0b6982a80fad,DISK], DatanodeInfoWithStorage[127.0.0.1:42257,DS-8374a11e-c96f-42ea-a1df-4a107d8680bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34711,DS-9e61908b-dbc1-447b-9a3d-5f669c31fa43,DISK], DatanodeInfoWithStorage[127.0.0.1:35699,DS-099abada-dbc7-4190-bc95-22ab189f42bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35913,DS-2543a76c-f290-43a2-bec7-053af091131a,DISK], DatanodeInfoWithStorage[127.0.0.1:34656,DS-278e2adc-64a8-4b63-a322-408c6f1a0c55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-845105557-172.17.0.4-1597277858506:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33748,DS-3a72e4d3-c082-4263-b168-defd7fda589c,DISK], DatanodeInfoWithStorage[127.0.0.1:38132,DS-696490d7-3783-433c-b1ea-d3d1c1288beb,DISK], DatanodeInfoWithStorage[127.0.0.1:40397,DS-6b0bab6d-f268-49e0-9537-c643b189bc8b,DISK], DatanodeInfoWithStorage[127.0.0.1:38923,DS-ef711beb-ece1-41f3-89e0-5adb828e2688,DISK], DatanodeInfoWithStorage[127.0.0.1:46319,DS-c62227bf-5cbb-42ae-98bc-e8799fea594d,DISK], DatanodeInfoWithStorage[127.0.0.1:35848,DS-bc057f3d-d2ae-43aa-bd2e-0056826b1f88,DISK], DatanodeInfoWithStorage[127.0.0.1:39971,DS-39dcf06b-07be-43ff-91a3-e631ed7bb7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35472,DS-f58f3dfe-c53c-4682-b74d-dadc23e06eb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-845105557-172.17.0.4-1597277858506:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33748,DS-3a72e4d3-c082-4263-b168-defd7fda589c,DISK], DatanodeInfoWithStorage[127.0.0.1:38132,DS-696490d7-3783-433c-b1ea-d3d1c1288beb,DISK], DatanodeInfoWithStorage[127.0.0.1:40397,DS-6b0bab6d-f268-49e0-9537-c643b189bc8b,DISK], DatanodeInfoWithStorage[127.0.0.1:38923,DS-ef711beb-ece1-41f3-89e0-5adb828e2688,DISK], DatanodeInfoWithStorage[127.0.0.1:46319,DS-c62227bf-5cbb-42ae-98bc-e8799fea594d,DISK], DatanodeInfoWithStorage[127.0.0.1:35848,DS-bc057f3d-d2ae-43aa-bd2e-0056826b1f88,DISK], DatanodeInfoWithStorage[127.0.0.1:39971,DS-39dcf06b-07be-43ff-91a3-e631ed7bb7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35472,DS-f58f3dfe-c53c-4682-b74d-dadc23e06eb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1831588387-172.17.0.4-1597278333111:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41056,DS-527eecb5-2870-43b0-aaa1-c94cb1592387,DISK], DatanodeInfoWithStorage[127.0.0.1:37395,DS-dac4f66e-2ed8-4798-a72f-a66b8901b52c,DISK], DatanodeInfoWithStorage[127.0.0.1:41298,DS-dfdb25a8-beaa-4af3-98e2-143d730eaef6,DISK], DatanodeInfoWithStorage[127.0.0.1:44909,DS-1ed36bab-6d51-48e7-b4a4-968a00592a86,DISK], DatanodeInfoWithStorage[127.0.0.1:37094,DS-fd113554-0c2f-4787-8e1e-28f0e60f0fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:42415,DS-5e10e2db-3e4d-40cf-8949-96f4163cf12b,DISK], DatanodeInfoWithStorage[127.0.0.1:42374,DS-58ce1e4b-0f07-4818-88bc-cf3683fc1c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:35929,DS-a4143b6a-18e5-46c0-9a56-2f5b4edf60a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1831588387-172.17.0.4-1597278333111:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41056,DS-527eecb5-2870-43b0-aaa1-c94cb1592387,DISK], DatanodeInfoWithStorage[127.0.0.1:37395,DS-dac4f66e-2ed8-4798-a72f-a66b8901b52c,DISK], DatanodeInfoWithStorage[127.0.0.1:41298,DS-dfdb25a8-beaa-4af3-98e2-143d730eaef6,DISK], DatanodeInfoWithStorage[127.0.0.1:44909,DS-1ed36bab-6d51-48e7-b4a4-968a00592a86,DISK], DatanodeInfoWithStorage[127.0.0.1:37094,DS-fd113554-0c2f-4787-8e1e-28f0e60f0fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:42415,DS-5e10e2db-3e4d-40cf-8949-96f4163cf12b,DISK], DatanodeInfoWithStorage[127.0.0.1:42374,DS-58ce1e4b-0f07-4818-88bc-cf3683fc1c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:35929,DS-a4143b6a-18e5-46c0-9a56-2f5b4edf60a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1411976734-172.17.0.4-1597278366681:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40080,DS-cd4317c5-b62d-4608-a1da-fc5fb2fb509c,DISK], DatanodeInfoWithStorage[127.0.0.1:40474,DS-f68b75f3-cf9e-4b3a-a074-cb6d48906e41,DISK], DatanodeInfoWithStorage[127.0.0.1:42670,DS-d3d68139-8a8d-49e4-9638-a86d2d1a6bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:44889,DS-7ca92e30-5148-4917-97fe-68d87c640f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:46382,DS-06dc9309-5bda-4f8b-aa1f-019ea8230996,DISK], DatanodeInfoWithStorage[127.0.0.1:44847,DS-db69999d-1fba-4109-b59b-9d73a0bba05c,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-a8098c20-95ce-45cb-b936-77c74a455658,DISK], DatanodeInfoWithStorage[127.0.0.1:32966,DS-70b9f2ff-aa3d-4984-8007-5dae2bb8518e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1411976734-172.17.0.4-1597278366681:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40080,DS-cd4317c5-b62d-4608-a1da-fc5fb2fb509c,DISK], DatanodeInfoWithStorage[127.0.0.1:40474,DS-f68b75f3-cf9e-4b3a-a074-cb6d48906e41,DISK], DatanodeInfoWithStorage[127.0.0.1:42670,DS-d3d68139-8a8d-49e4-9638-a86d2d1a6bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:44889,DS-7ca92e30-5148-4917-97fe-68d87c640f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:46382,DS-06dc9309-5bda-4f8b-aa1f-019ea8230996,DISK], DatanodeInfoWithStorage[127.0.0.1:44847,DS-db69999d-1fba-4109-b59b-9d73a0bba05c,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-a8098c20-95ce-45cb-b936-77c74a455658,DISK], DatanodeInfoWithStorage[127.0.0.1:32966,DS-70b9f2ff-aa3d-4984-8007-5dae2bb8518e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1492182736-172.17.0.4-1597278742936:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45219,DS-37a57019-6eba-49e9-9f2c-b7215d4e9c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:33631,DS-b102db7e-19f9-4e55-a364-7d9153045b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:35492,DS-8a062bd7-3884-42ec-9913-a33cda49afee,DISK], DatanodeInfoWithStorage[127.0.0.1:37383,DS-032ba3c1-e8bc-49d6-ae62-969e8d4a7d01,DISK], DatanodeInfoWithStorage[127.0.0.1:42449,DS-bbac700a-35a6-47e8-9c75-2997c2939669,DISK], DatanodeInfoWithStorage[127.0.0.1:40316,DS-a4673523-38f9-4d30-8c8c-db37cb616fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:39109,DS-7b02a8bf-aa23-4f56-b644-42d0d0f7792b,DISK], DatanodeInfoWithStorage[127.0.0.1:35976,DS-5798d62c-b5b6-4b84-abd9-dfe88fcf5c0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1492182736-172.17.0.4-1597278742936:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45219,DS-37a57019-6eba-49e9-9f2c-b7215d4e9c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:33631,DS-b102db7e-19f9-4e55-a364-7d9153045b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:35492,DS-8a062bd7-3884-42ec-9913-a33cda49afee,DISK], DatanodeInfoWithStorage[127.0.0.1:37383,DS-032ba3c1-e8bc-49d6-ae62-969e8d4a7d01,DISK], DatanodeInfoWithStorage[127.0.0.1:42449,DS-bbac700a-35a6-47e8-9c75-2997c2939669,DISK], DatanodeInfoWithStorage[127.0.0.1:40316,DS-a4673523-38f9-4d30-8c8c-db37cb616fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:39109,DS-7b02a8bf-aa23-4f56-b644-42d0d0f7792b,DISK], DatanodeInfoWithStorage[127.0.0.1:35976,DS-5798d62c-b5b6-4b84-abd9-dfe88fcf5c0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-606420192-172.17.0.4-1597279711908:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45583,DS-1029743e-2c87-4ad3-ab59-0bcb03203bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:45744,DS-c57d9c7f-2193-4bb7-a461-9288e18c728f,DISK], DatanodeInfoWithStorage[127.0.0.1:42829,DS-f00c1aba-9f6e-487a-9b5f-6dc5597f9cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:46078,DS-6004443d-0ff6-4274-be2e-df29c639eb0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34533,DS-1e0e5c50-7972-483f-a147-1b88fc6312de,DISK], DatanodeInfoWithStorage[127.0.0.1:45149,DS-c8a2d1da-730c-4d45-96fc-ca2876de2646,DISK], DatanodeInfoWithStorage[127.0.0.1:35524,DS-f1882ab7-26d4-4abb-b551-ce8377e55b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39272,DS-2da91489-fb52-4db0-893d-7294a552f9e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-606420192-172.17.0.4-1597279711908:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45583,DS-1029743e-2c87-4ad3-ab59-0bcb03203bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:45744,DS-c57d9c7f-2193-4bb7-a461-9288e18c728f,DISK], DatanodeInfoWithStorage[127.0.0.1:42829,DS-f00c1aba-9f6e-487a-9b5f-6dc5597f9cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:46078,DS-6004443d-0ff6-4274-be2e-df29c639eb0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34533,DS-1e0e5c50-7972-483f-a147-1b88fc6312de,DISK], DatanodeInfoWithStorage[127.0.0.1:45149,DS-c8a2d1da-730c-4d45-96fc-ca2876de2646,DISK], DatanodeInfoWithStorage[127.0.0.1:35524,DS-f1882ab7-26d4-4abb-b551-ce8377e55b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39272,DS-2da91489-fb52-4db0-893d-7294a552f9e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-430117587-172.17.0.4-1597279944211:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43662,DS-a5c78697-6935-4579-9b52-3379c1581223,DISK], DatanodeInfoWithStorage[127.0.0.1:45961,DS-cad93a16-45d3-48ab-b4dc-9e777021de75,DISK], DatanodeInfoWithStorage[127.0.0.1:39706,DS-f6a00104-bf1a-41f8-b80d-3c782df614bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42631,DS-5f7aac4a-a1fc-470e-bb08-0d35f0bf4ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:33793,DS-697d5715-730d-4591-b1a1-b47476e4854d,DISK], DatanodeInfoWithStorage[127.0.0.1:35638,DS-9e55b4f8-8da5-4670-bc44-13cfa56be6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-8ff46894-0e6b-4940-9cdd-2c454e6c3c97,DISK], DatanodeInfoWithStorage[127.0.0.1:39923,DS-a7715eeb-c938-47c2-937f-068f2b15dfab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-430117587-172.17.0.4-1597279944211:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43662,DS-a5c78697-6935-4579-9b52-3379c1581223,DISK], DatanodeInfoWithStorage[127.0.0.1:45961,DS-cad93a16-45d3-48ab-b4dc-9e777021de75,DISK], DatanodeInfoWithStorage[127.0.0.1:39706,DS-f6a00104-bf1a-41f8-b80d-3c782df614bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42631,DS-5f7aac4a-a1fc-470e-bb08-0d35f0bf4ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:33793,DS-697d5715-730d-4591-b1a1-b47476e4854d,DISK], DatanodeInfoWithStorage[127.0.0.1:35638,DS-9e55b4f8-8da5-4670-bc44-13cfa56be6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-8ff46894-0e6b-4940-9cdd-2c454e6c3c97,DISK], DatanodeInfoWithStorage[127.0.0.1:39923,DS-a7715eeb-c938-47c2-937f-068f2b15dfab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5650
