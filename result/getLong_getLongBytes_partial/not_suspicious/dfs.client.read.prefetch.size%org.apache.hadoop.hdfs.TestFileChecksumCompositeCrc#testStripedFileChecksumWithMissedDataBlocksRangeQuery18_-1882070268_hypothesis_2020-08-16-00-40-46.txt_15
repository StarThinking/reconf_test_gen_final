reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 62914560
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 62914560
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-726227048-172.17.0.20-1597538497454:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45052,DS-ab85b0b1-d4af-49c7-a081-14f3ae0033fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44958,DS-288c54a1-da6f-402e-99a2-7ab89a3e149f,DISK], DatanodeInfoWithStorage[127.0.0.1:34749,DS-6407a6de-743f-4bdb-85ed-8a03c7f7b23f,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-4a356942-40c5-4a68-a636-0c80db3cdde1,DISK], DatanodeInfoWithStorage[127.0.0.1:33619,DS-705af52b-e7b9-4d80-85b0-74df52f65959,DISK], DatanodeInfoWithStorage[127.0.0.1:34229,DS-08185d91-e2f6-4ae3-a8a9-b0270e4f8cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:43080,DS-696f0f20-02cb-4694-a481-8322211a1ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:40153,DS-fd901679-42cc-4846-a98c-ff75bc42fbd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-726227048-172.17.0.20-1597538497454:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45052,DS-ab85b0b1-d4af-49c7-a081-14f3ae0033fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44958,DS-288c54a1-da6f-402e-99a2-7ab89a3e149f,DISK], DatanodeInfoWithStorage[127.0.0.1:34749,DS-6407a6de-743f-4bdb-85ed-8a03c7f7b23f,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-4a356942-40c5-4a68-a636-0c80db3cdde1,DISK], DatanodeInfoWithStorage[127.0.0.1:33619,DS-705af52b-e7b9-4d80-85b0-74df52f65959,DISK], DatanodeInfoWithStorage[127.0.0.1:34229,DS-08185d91-e2f6-4ae3-a8a9-b0270e4f8cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:43080,DS-696f0f20-02cb-4694-a481-8322211a1ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:40153,DS-fd901679-42cc-4846-a98c-ff75bc42fbd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 62914560
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-807225172-172.17.0.20-1597539085463:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46168,DS-acfce837-5934-4e3d-a6c4-2aa716b6a93f,DISK], DatanodeInfoWithStorage[127.0.0.1:38272,DS-59470ae5-ed3d-4a64-b15e-d635e1e0d304,DISK], DatanodeInfoWithStorage[127.0.0.1:42441,DS-49f9156d-f905-461a-99f8-55ef9d51afc0,DISK], DatanodeInfoWithStorage[127.0.0.1:35256,DS-094c7af2-6d21-4f0f-a7ac-353668c1bac0,DISK], DatanodeInfoWithStorage[127.0.0.1:45987,DS-9b76477a-ecbc-4ba6-91cf-f7482df7ace7,DISK], DatanodeInfoWithStorage[127.0.0.1:45689,DS-5e023c4f-0565-406f-8a7a-6a5382347f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40364,DS-811fd2d7-0902-4f7d-b6d1-ccf959272fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:46458,DS-62ae6de3-f024-42a3-8f29-8b91c365049e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-807225172-172.17.0.20-1597539085463:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46168,DS-acfce837-5934-4e3d-a6c4-2aa716b6a93f,DISK], DatanodeInfoWithStorage[127.0.0.1:38272,DS-59470ae5-ed3d-4a64-b15e-d635e1e0d304,DISK], DatanodeInfoWithStorage[127.0.0.1:42441,DS-49f9156d-f905-461a-99f8-55ef9d51afc0,DISK], DatanodeInfoWithStorage[127.0.0.1:35256,DS-094c7af2-6d21-4f0f-a7ac-353668c1bac0,DISK], DatanodeInfoWithStorage[127.0.0.1:45987,DS-9b76477a-ecbc-4ba6-91cf-f7482df7ace7,DISK], DatanodeInfoWithStorage[127.0.0.1:45689,DS-5e023c4f-0565-406f-8a7a-6a5382347f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40364,DS-811fd2d7-0902-4f7d-b6d1-ccf959272fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:46458,DS-62ae6de3-f024-42a3-8f29-8b91c365049e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 62914560
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1223918858-172.17.0.20-1597539373303:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42151,DS-0d08f61a-4957-4d3b-bb69-624dd2d7a8c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36698,DS-b6f6fb19-fcce-4a99-9d84-39222a7f49ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40200,DS-a230ac6a-ab66-4ce4-90b4-0caceb72a0f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39080,DS-39ff8460-582d-433b-8b3a-cd436617318e,DISK], DatanodeInfoWithStorage[127.0.0.1:32768,DS-d9232b9f-7cd8-4db7-ad2f-62a410664a19,DISK], DatanodeInfoWithStorage[127.0.0.1:38887,DS-41bc4674-2ec1-47bd-a707-fe3b7d6ca97c,DISK], DatanodeInfoWithStorage[127.0.0.1:33347,DS-03413646-ab89-46ef-96e8-1cc36fcb6ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:44953,DS-de4e4030-03b5-461e-9795-f34b62082696,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1223918858-172.17.0.20-1597539373303:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42151,DS-0d08f61a-4957-4d3b-bb69-624dd2d7a8c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36698,DS-b6f6fb19-fcce-4a99-9d84-39222a7f49ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40200,DS-a230ac6a-ab66-4ce4-90b4-0caceb72a0f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39080,DS-39ff8460-582d-433b-8b3a-cd436617318e,DISK], DatanodeInfoWithStorage[127.0.0.1:32768,DS-d9232b9f-7cd8-4db7-ad2f-62a410664a19,DISK], DatanodeInfoWithStorage[127.0.0.1:38887,DS-41bc4674-2ec1-47bd-a707-fe3b7d6ca97c,DISK], DatanodeInfoWithStorage[127.0.0.1:33347,DS-03413646-ab89-46ef-96e8-1cc36fcb6ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:44953,DS-de4e4030-03b5-461e-9795-f34b62082696,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 62914560
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-10876992-172.17.0.20-1597539479851:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42038,DS-adcfa103-4d7f-40ed-a773-eda452105fde,DISK], DatanodeInfoWithStorage[127.0.0.1:40722,DS-96a623ee-2841-410d-8c02-37af6df32d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33626,DS-8c678910-a8ba-45a7-99ec-4d8676a68b31,DISK], DatanodeInfoWithStorage[127.0.0.1:45371,DS-39a44e2d-b6ef-4af8-a9e5-c3050de7edeb,DISK], DatanodeInfoWithStorage[127.0.0.1:40975,DS-6f924f19-4cae-4b29-9f01-4c1d17bfff6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45598,DS-19890803-6805-4020-8b25-cf1996ca0915,DISK], DatanodeInfoWithStorage[127.0.0.1:43860,DS-8dc06988-4b97-4797-87eb-b502724b6df1,DISK], DatanodeInfoWithStorage[127.0.0.1:32931,DS-61d74294-d776-44fd-8e07-551a6568912d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-10876992-172.17.0.20-1597539479851:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42038,DS-adcfa103-4d7f-40ed-a773-eda452105fde,DISK], DatanodeInfoWithStorage[127.0.0.1:40722,DS-96a623ee-2841-410d-8c02-37af6df32d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33626,DS-8c678910-a8ba-45a7-99ec-4d8676a68b31,DISK], DatanodeInfoWithStorage[127.0.0.1:45371,DS-39a44e2d-b6ef-4af8-a9e5-c3050de7edeb,DISK], DatanodeInfoWithStorage[127.0.0.1:40975,DS-6f924f19-4cae-4b29-9f01-4c1d17bfff6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45598,DS-19890803-6805-4020-8b25-cf1996ca0915,DISK], DatanodeInfoWithStorage[127.0.0.1:43860,DS-8dc06988-4b97-4797-87eb-b502724b6df1,DISK], DatanodeInfoWithStorage[127.0.0.1:32931,DS-61d74294-d776-44fd-8e07-551a6568912d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 62914560
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-862483848-172.17.0.20-1597539651371:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34069,DS-5081fede-be4e-4e91-afe3-9a829ca6ce58,DISK], DatanodeInfoWithStorage[127.0.0.1:41596,DS-8f5df50c-fa8b-49e6-803f-456e74605c83,DISK], DatanodeInfoWithStorage[127.0.0.1:36583,DS-0ee978b1-de99-4726-b877-61ee53db1fde,DISK], DatanodeInfoWithStorage[127.0.0.1:43758,DS-e8b2cb8c-49cb-435c-b1f7-8468c10b267b,DISK], DatanodeInfoWithStorage[127.0.0.1:40631,DS-c4024b01-e93c-4ce8-9dd6-edc755b36bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:39781,DS-1ee7a76f-084c-4e03-8cd8-b7f7ee240c24,DISK], DatanodeInfoWithStorage[127.0.0.1:38920,DS-72363675-f77e-41eb-a682-7688fd79cf2e,DISK], DatanodeInfoWithStorage[127.0.0.1:37418,DS-27c7b37f-ee82-4d62-bace-9de91c8c2d77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-862483848-172.17.0.20-1597539651371:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34069,DS-5081fede-be4e-4e91-afe3-9a829ca6ce58,DISK], DatanodeInfoWithStorage[127.0.0.1:41596,DS-8f5df50c-fa8b-49e6-803f-456e74605c83,DISK], DatanodeInfoWithStorage[127.0.0.1:36583,DS-0ee978b1-de99-4726-b877-61ee53db1fde,DISK], DatanodeInfoWithStorage[127.0.0.1:43758,DS-e8b2cb8c-49cb-435c-b1f7-8468c10b267b,DISK], DatanodeInfoWithStorage[127.0.0.1:40631,DS-c4024b01-e93c-4ce8-9dd6-edc755b36bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:39781,DS-1ee7a76f-084c-4e03-8cd8-b7f7ee240c24,DISK], DatanodeInfoWithStorage[127.0.0.1:38920,DS-72363675-f77e-41eb-a682-7688fd79cf2e,DISK], DatanodeInfoWithStorage[127.0.0.1:37418,DS-27c7b37f-ee82-4d62-bace-9de91c8c2d77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 62914560
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1968797978-172.17.0.20-1597540027921:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39609,DS-46e90aa2-ef0c-467a-a55f-1181055c9053,DISK], DatanodeInfoWithStorage[127.0.0.1:42018,DS-2cbcd9f0-4e1c-4c3a-bea2-6efbc730eaa9,DISK], DatanodeInfoWithStorage[127.0.0.1:35053,DS-32b9208b-935b-47b1-bbf4-aec4b0931415,DISK], DatanodeInfoWithStorage[127.0.0.1:33460,DS-9be8229e-9ac5-4ea7-9392-0e7fb689597a,DISK], DatanodeInfoWithStorage[127.0.0.1:43129,DS-5aedf7e6-8f17-49fb-960d-263670d2192f,DISK], DatanodeInfoWithStorage[127.0.0.1:34519,DS-0580208e-8d86-47b0-8674-b35adc589689,DISK], DatanodeInfoWithStorage[127.0.0.1:33230,DS-bce723ca-bbe1-4ac0-bb4e-634de596eaf0,DISK], DatanodeInfoWithStorage[127.0.0.1:46644,DS-45090240-d6f9-4a49-a7cf-585007671cd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1968797978-172.17.0.20-1597540027921:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39609,DS-46e90aa2-ef0c-467a-a55f-1181055c9053,DISK], DatanodeInfoWithStorage[127.0.0.1:42018,DS-2cbcd9f0-4e1c-4c3a-bea2-6efbc730eaa9,DISK], DatanodeInfoWithStorage[127.0.0.1:35053,DS-32b9208b-935b-47b1-bbf4-aec4b0931415,DISK], DatanodeInfoWithStorage[127.0.0.1:33460,DS-9be8229e-9ac5-4ea7-9392-0e7fb689597a,DISK], DatanodeInfoWithStorage[127.0.0.1:43129,DS-5aedf7e6-8f17-49fb-960d-263670d2192f,DISK], DatanodeInfoWithStorage[127.0.0.1:34519,DS-0580208e-8d86-47b0-8674-b35adc589689,DISK], DatanodeInfoWithStorage[127.0.0.1:33230,DS-bce723ca-bbe1-4ac0-bb4e-634de596eaf0,DISK], DatanodeInfoWithStorage[127.0.0.1:46644,DS-45090240-d6f9-4a49-a7cf-585007671cd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 62914560
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1237727323-172.17.0.20-1597540268963:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42013,DS-a4543582-c21c-483e-9268-3262877a386a,DISK], DatanodeInfoWithStorage[127.0.0.1:39084,DS-7cb81e20-6feb-4b93-87a9-9cb33d800199,DISK], DatanodeInfoWithStorage[127.0.0.1:35678,DS-9ca1dd71-f0ed-4675-8640-ca109a9b1e58,DISK], DatanodeInfoWithStorage[127.0.0.1:45566,DS-1e2f0cab-ccec-48e0-8904-bd1ce99f9ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:40731,DS-2fbbd251-639c-4f75-95fa-c49e6d1c57d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37767,DS-79321972-c385-49a7-901e-854f7c73d78c,DISK], DatanodeInfoWithStorage[127.0.0.1:36650,DS-7e851fb1-7fb9-41ef-9142-49423ee9a261,DISK], DatanodeInfoWithStorage[127.0.0.1:35096,DS-b0ae4b5c-ac6c-4b54-863d-af8696d14524,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1237727323-172.17.0.20-1597540268963:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42013,DS-a4543582-c21c-483e-9268-3262877a386a,DISK], DatanodeInfoWithStorage[127.0.0.1:39084,DS-7cb81e20-6feb-4b93-87a9-9cb33d800199,DISK], DatanodeInfoWithStorage[127.0.0.1:35678,DS-9ca1dd71-f0ed-4675-8640-ca109a9b1e58,DISK], DatanodeInfoWithStorage[127.0.0.1:45566,DS-1e2f0cab-ccec-48e0-8904-bd1ce99f9ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:40731,DS-2fbbd251-639c-4f75-95fa-c49e6d1c57d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37767,DS-79321972-c385-49a7-901e-854f7c73d78c,DISK], DatanodeInfoWithStorage[127.0.0.1:36650,DS-7e851fb1-7fb9-41ef-9142-49423ee9a261,DISK], DatanodeInfoWithStorage[127.0.0.1:35096,DS-b0ae4b5c-ac6c-4b54-863d-af8696d14524,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 62914560
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1664897424-172.17.0.20-1597540508705:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44234,DS-fd73c2a6-5503-42f1-8237-8faa17f2e0a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34142,DS-cc1c049d-af1d-495e-beb3-f10f0796b18b,DISK], DatanodeInfoWithStorage[127.0.0.1:34183,DS-99c92974-a7ad-4b99-a434-d876d5aa5e95,DISK], DatanodeInfoWithStorage[127.0.0.1:41384,DS-5c4d1fe0-4736-44e5-bf64-9602226cc895,DISK], DatanodeInfoWithStorage[127.0.0.1:35426,DS-9ab4a02d-b83d-4233-a648-c605d7dabfda,DISK], DatanodeInfoWithStorage[127.0.0.1:43631,DS-207e5124-a9c3-4271-9b3e-81eeb8458af9,DISK], DatanodeInfoWithStorage[127.0.0.1:33550,DS-20891df9-de4d-486f-9735-bcdea4135def,DISK], DatanodeInfoWithStorage[127.0.0.1:36249,DS-25f2a33e-a814-43b6-a2ae-0dcd8e9b7338,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1664897424-172.17.0.20-1597540508705:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44234,DS-fd73c2a6-5503-42f1-8237-8faa17f2e0a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34142,DS-cc1c049d-af1d-495e-beb3-f10f0796b18b,DISK], DatanodeInfoWithStorage[127.0.0.1:34183,DS-99c92974-a7ad-4b99-a434-d876d5aa5e95,DISK], DatanodeInfoWithStorage[127.0.0.1:41384,DS-5c4d1fe0-4736-44e5-bf64-9602226cc895,DISK], DatanodeInfoWithStorage[127.0.0.1:35426,DS-9ab4a02d-b83d-4233-a648-c605d7dabfda,DISK], DatanodeInfoWithStorage[127.0.0.1:43631,DS-207e5124-a9c3-4271-9b3e-81eeb8458af9,DISK], DatanodeInfoWithStorage[127.0.0.1:33550,DS-20891df9-de4d-486f-9735-bcdea4135def,DISK], DatanodeInfoWithStorage[127.0.0.1:36249,DS-25f2a33e-a814-43b6-a2ae-0dcd8e9b7338,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 62914560
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1439637425-172.17.0.20-1597540852238:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39761,DS-f8bb9be7-6aaf-4d89-bd64-3fdf33e3f97a,DISK], DatanodeInfoWithStorage[127.0.0.1:41725,DS-e669470a-8286-4849-a96c-7fc0b47b656a,DISK], DatanodeInfoWithStorage[127.0.0.1:46610,DS-c75469ab-9c3c-4731-a341-f7cb93adb5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46021,DS-3aa4b00e-c790-498f-8e34-c321f6aad995,DISK], DatanodeInfoWithStorage[127.0.0.1:39206,DS-9ac7dbe4-a61b-48bf-9e47-d1a813699b12,DISK], DatanodeInfoWithStorage[127.0.0.1:35913,DS-faffd398-5b8c-40e3-b837-e8a027ee0244,DISK], DatanodeInfoWithStorage[127.0.0.1:37969,DS-26301208-a327-424a-9c74-1de95e1a1aea,DISK], DatanodeInfoWithStorage[127.0.0.1:42397,DS-b2b59bd4-c462-4a49-b4f6-772ebf43621c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1439637425-172.17.0.20-1597540852238:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39761,DS-f8bb9be7-6aaf-4d89-bd64-3fdf33e3f97a,DISK], DatanodeInfoWithStorage[127.0.0.1:41725,DS-e669470a-8286-4849-a96c-7fc0b47b656a,DISK], DatanodeInfoWithStorage[127.0.0.1:46610,DS-c75469ab-9c3c-4731-a341-f7cb93adb5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46021,DS-3aa4b00e-c790-498f-8e34-c321f6aad995,DISK], DatanodeInfoWithStorage[127.0.0.1:39206,DS-9ac7dbe4-a61b-48bf-9e47-d1a813699b12,DISK], DatanodeInfoWithStorage[127.0.0.1:35913,DS-faffd398-5b8c-40e3-b837-e8a027ee0244,DISK], DatanodeInfoWithStorage[127.0.0.1:37969,DS-26301208-a327-424a-9c74-1de95e1a1aea,DISK], DatanodeInfoWithStorage[127.0.0.1:42397,DS-b2b59bd4-c462-4a49-b4f6-772ebf43621c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 62914560
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-94497170-172.17.0.20-1597541117688:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34905,DS-d70a7b32-4a5e-4b28-91c5-31d34ba2a523,DISK], DatanodeInfoWithStorage[127.0.0.1:45774,DS-8885e91e-26d8-44ae-b3b0-653fab54ff4b,DISK], DatanodeInfoWithStorage[127.0.0.1:36846,DS-3f055f54-eb1c-45ec-8f61-a6451df1edb0,DISK], DatanodeInfoWithStorage[127.0.0.1:45731,DS-34adb47d-91c2-4bdf-a1e6-40209878f7f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40951,DS-18fd3768-01db-44b2-8683-dc2d2beea68a,DISK], DatanodeInfoWithStorage[127.0.0.1:42322,DS-1ea3fdaa-6fca-4a41-80bb-3b955c1cda3d,DISK], DatanodeInfoWithStorage[127.0.0.1:40939,DS-5b7b7a37-5ff8-42b0-8ab4-bb8ad2207a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:32971,DS-3a11d713-d546-42e8-953b-5f7c4452214a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-94497170-172.17.0.20-1597541117688:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34905,DS-d70a7b32-4a5e-4b28-91c5-31d34ba2a523,DISK], DatanodeInfoWithStorage[127.0.0.1:45774,DS-8885e91e-26d8-44ae-b3b0-653fab54ff4b,DISK], DatanodeInfoWithStorage[127.0.0.1:36846,DS-3f055f54-eb1c-45ec-8f61-a6451df1edb0,DISK], DatanodeInfoWithStorage[127.0.0.1:45731,DS-34adb47d-91c2-4bdf-a1e6-40209878f7f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40951,DS-18fd3768-01db-44b2-8683-dc2d2beea68a,DISK], DatanodeInfoWithStorage[127.0.0.1:42322,DS-1ea3fdaa-6fca-4a41-80bb-3b955c1cda3d,DISK], DatanodeInfoWithStorage[127.0.0.1:40939,DS-5b7b7a37-5ff8-42b0-8ab4-bb8ad2207a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:32971,DS-3a11d713-d546-42e8-953b-5f7c4452214a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 62914560
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-850842912-172.17.0.20-1597541224665:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35856,DS-c16a36c6-463f-4065-a125-7817c183e7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35931,DS-2d7794fa-8011-45f8-9ad1-41adc851bbc9,DISK], DatanodeInfoWithStorage[127.0.0.1:45881,DS-c6db2aea-00ee-4562-8673-264ee76049d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37684,DS-07d71574-2126-449b-9074-a78a4413e402,DISK], DatanodeInfoWithStorage[127.0.0.1:43409,DS-4faadb4a-f4c2-44d4-9916-03f02b69deb6,DISK], DatanodeInfoWithStorage[127.0.0.1:37140,DS-5f469b33-ea67-4f0b-9f31-effd7bec1257,DISK], DatanodeInfoWithStorage[127.0.0.1:33944,DS-16c46fad-f959-4ab0-9d38-7640f393f97b,DISK], DatanodeInfoWithStorage[127.0.0.1:37918,DS-127c4966-e676-4dfa-8859-959fa6269487,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-850842912-172.17.0.20-1597541224665:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35856,DS-c16a36c6-463f-4065-a125-7817c183e7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35931,DS-2d7794fa-8011-45f8-9ad1-41adc851bbc9,DISK], DatanodeInfoWithStorage[127.0.0.1:45881,DS-c6db2aea-00ee-4562-8673-264ee76049d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37684,DS-07d71574-2126-449b-9074-a78a4413e402,DISK], DatanodeInfoWithStorage[127.0.0.1:43409,DS-4faadb4a-f4c2-44d4-9916-03f02b69deb6,DISK], DatanodeInfoWithStorage[127.0.0.1:37140,DS-5f469b33-ea67-4f0b-9f31-effd7bec1257,DISK], DatanodeInfoWithStorage[127.0.0.1:33944,DS-16c46fad-f959-4ab0-9d38-7640f393f97b,DISK], DatanodeInfoWithStorage[127.0.0.1:37918,DS-127c4966-e676-4dfa-8859-959fa6269487,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 62914560
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1124030113-172.17.0.20-1597541358369:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32869,DS-c9543e90-cdc6-4e2b-b727-1166e717a2b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43087,DS-2694c29e-66c0-49c1-a4cc-d94a0b792f67,DISK], DatanodeInfoWithStorage[127.0.0.1:44034,DS-2efe08ce-829f-4c16-8ebb-ead32c0ef527,DISK], DatanodeInfoWithStorage[127.0.0.1:41285,DS-76c17bdc-557c-420c-bb4a-d76dc85adbb1,DISK], DatanodeInfoWithStorage[127.0.0.1:45780,DS-3b3686b4-6e88-466a-b480-6e75256f9ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:42362,DS-92fc2c4a-a826-4761-b20d-4e3e59e6caa4,DISK], DatanodeInfoWithStorage[127.0.0.1:45328,DS-e5576269-db65-41fa-b84c-f0420b793df5,DISK], DatanodeInfoWithStorage[127.0.0.1:39187,DS-b94b0c87-3e18-4a76-ab99-80d0f4e76b09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1124030113-172.17.0.20-1597541358369:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32869,DS-c9543e90-cdc6-4e2b-b727-1166e717a2b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43087,DS-2694c29e-66c0-49c1-a4cc-d94a0b792f67,DISK], DatanodeInfoWithStorage[127.0.0.1:44034,DS-2efe08ce-829f-4c16-8ebb-ead32c0ef527,DISK], DatanodeInfoWithStorage[127.0.0.1:41285,DS-76c17bdc-557c-420c-bb4a-d76dc85adbb1,DISK], DatanodeInfoWithStorage[127.0.0.1:45780,DS-3b3686b4-6e88-466a-b480-6e75256f9ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:42362,DS-92fc2c4a-a826-4761-b20d-4e3e59e6caa4,DISK], DatanodeInfoWithStorage[127.0.0.1:45328,DS-e5576269-db65-41fa-b84c-f0420b793df5,DISK], DatanodeInfoWithStorage[127.0.0.1:39187,DS-b94b0c87-3e18-4a76-ab99-80d0f4e76b09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 62914560
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1153493465-172.17.0.20-1597541427013:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40490,DS-574b1fc4-b3b1-40f6-bc29-5d1481746c51,DISK], DatanodeInfoWithStorage[127.0.0.1:44068,DS-d1b34474-cc43-431e-9396-85fa62c30392,DISK], DatanodeInfoWithStorage[127.0.0.1:36294,DS-682f9b9a-95a0-4e78-af3f-7e4839f74222,DISK], DatanodeInfoWithStorage[127.0.0.1:41074,DS-99362f33-2191-42da-9ac6-73877ff91d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:37777,DS-697d8b5c-a824-490d-850c-097e0f963dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:42128,DS-527693c7-7ad2-48f6-87bf-03a077703179,DISK], DatanodeInfoWithStorage[127.0.0.1:45576,DS-88427aff-32a2-430e-9468-82ca4387ca59,DISK], DatanodeInfoWithStorage[127.0.0.1:42523,DS-eeb48ea2-ed69-41b9-967b-7385f9f272aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1153493465-172.17.0.20-1597541427013:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40490,DS-574b1fc4-b3b1-40f6-bc29-5d1481746c51,DISK], DatanodeInfoWithStorage[127.0.0.1:44068,DS-d1b34474-cc43-431e-9396-85fa62c30392,DISK], DatanodeInfoWithStorage[127.0.0.1:36294,DS-682f9b9a-95a0-4e78-af3f-7e4839f74222,DISK], DatanodeInfoWithStorage[127.0.0.1:41074,DS-99362f33-2191-42da-9ac6-73877ff91d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:37777,DS-697d8b5c-a824-490d-850c-097e0f963dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:42128,DS-527693c7-7ad2-48f6-87bf-03a077703179,DISK], DatanodeInfoWithStorage[127.0.0.1:45576,DS-88427aff-32a2-430e-9468-82ca4387ca59,DISK], DatanodeInfoWithStorage[127.0.0.1:42523,DS-eeb48ea2-ed69-41b9-967b-7385f9f272aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 62914560
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2133192135-172.17.0.20-1597541496149:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40023,DS-687cc6b0-b16f-4f2f-bcd2-7716d97ae515,DISK], DatanodeInfoWithStorage[127.0.0.1:33440,DS-93db8b23-441b-4ae9-a6c4-f4fc22f3257c,DISK], DatanodeInfoWithStorage[127.0.0.1:45508,DS-07fcd97f-18c3-447b-a87b-7c122e4d8f89,DISK], DatanodeInfoWithStorage[127.0.0.1:34967,DS-e66454ee-39d9-4ab6-8fa7-20ec3b3345f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42073,DS-db052d55-0469-459f-85da-de1cb3c4f38c,DISK], DatanodeInfoWithStorage[127.0.0.1:37017,DS-225c864d-1797-4dd6-aaec-08564cd08f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:38479,DS-d02a27d4-eabc-4b9a-9b22-13165acd1491,DISK], DatanodeInfoWithStorage[127.0.0.1:35124,DS-7a35b9b9-41a6-4492-ab9f-c3d1ba4275f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2133192135-172.17.0.20-1597541496149:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40023,DS-687cc6b0-b16f-4f2f-bcd2-7716d97ae515,DISK], DatanodeInfoWithStorage[127.0.0.1:33440,DS-93db8b23-441b-4ae9-a6c4-f4fc22f3257c,DISK], DatanodeInfoWithStorage[127.0.0.1:45508,DS-07fcd97f-18c3-447b-a87b-7c122e4d8f89,DISK], DatanodeInfoWithStorage[127.0.0.1:34967,DS-e66454ee-39d9-4ab6-8fa7-20ec3b3345f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42073,DS-db052d55-0469-459f-85da-de1cb3c4f38c,DISK], DatanodeInfoWithStorage[127.0.0.1:37017,DS-225c864d-1797-4dd6-aaec-08564cd08f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:38479,DS-d02a27d4-eabc-4b9a-9b22-13165acd1491,DISK], DatanodeInfoWithStorage[127.0.0.1:35124,DS-7a35b9b9-41a6-4492-ab9f-c3d1ba4275f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 62914560
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-446736218-172.17.0.20-1597541641090:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41651,DS-84f9b6a0-dd9e-42dc-a305-11d3d4b9d705,DISK], DatanodeInfoWithStorage[127.0.0.1:44740,DS-37b4e1c2-e197-47d7-9885-53cbc4a98129,DISK], DatanodeInfoWithStorage[127.0.0.1:45949,DS-31150841-7842-4fc5-88a6-a3e6c12d2595,DISK], DatanodeInfoWithStorage[127.0.0.1:36993,DS-95c0a32c-19d6-4e89-acd1-78154b815568,DISK], DatanodeInfoWithStorage[127.0.0.1:41420,DS-484f756f-21a1-4a39-bcee-4f9303aee880,DISK], DatanodeInfoWithStorage[127.0.0.1:39114,DS-4f2c289e-d897-438e-a6f2-bafbf3db1a88,DISK], DatanodeInfoWithStorage[127.0.0.1:46851,DS-901ccef7-6052-4c81-93e2-9847859b9052,DISK], DatanodeInfoWithStorage[127.0.0.1:33511,DS-404e8619-acb8-47d3-be86-bd504d8b4c51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-446736218-172.17.0.20-1597541641090:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41651,DS-84f9b6a0-dd9e-42dc-a305-11d3d4b9d705,DISK], DatanodeInfoWithStorage[127.0.0.1:44740,DS-37b4e1c2-e197-47d7-9885-53cbc4a98129,DISK], DatanodeInfoWithStorage[127.0.0.1:45949,DS-31150841-7842-4fc5-88a6-a3e6c12d2595,DISK], DatanodeInfoWithStorage[127.0.0.1:36993,DS-95c0a32c-19d6-4e89-acd1-78154b815568,DISK], DatanodeInfoWithStorage[127.0.0.1:41420,DS-484f756f-21a1-4a39-bcee-4f9303aee880,DISK], DatanodeInfoWithStorage[127.0.0.1:39114,DS-4f2c289e-d897-438e-a6f2-bafbf3db1a88,DISK], DatanodeInfoWithStorage[127.0.0.1:46851,DS-901ccef7-6052-4c81-93e2-9847859b9052,DISK], DatanodeInfoWithStorage[127.0.0.1:33511,DS-404e8619-acb8-47d3-be86-bd504d8b4c51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 62914560
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-581741163-172.17.0.20-1597541750562:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43120,DS-610cef38-e25f-4dd9-8343-7c62896aadb4,DISK], DatanodeInfoWithStorage[127.0.0.1:42139,DS-c225e9ee-19f7-4fd1-95bc-0b3d9407516f,DISK], DatanodeInfoWithStorage[127.0.0.1:40778,DS-fb0c5e94-ffb6-4700-a6c7-395f61c184d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36972,DS-e5292f8d-9653-4f28-9062-9dee8c77f3af,DISK], DatanodeInfoWithStorage[127.0.0.1:41131,DS-a1df892e-af2d-4bc0-849d-fc23b3ff35e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45689,DS-73e2ac24-fc5f-461f-be6a-513bb259c853,DISK], DatanodeInfoWithStorage[127.0.0.1:45778,DS-ff7a48be-0705-40d6-a457-3eacf649c3a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45961,DS-71d2dca8-0281-4184-ad64-426ade2367bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-581741163-172.17.0.20-1597541750562:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43120,DS-610cef38-e25f-4dd9-8343-7c62896aadb4,DISK], DatanodeInfoWithStorage[127.0.0.1:42139,DS-c225e9ee-19f7-4fd1-95bc-0b3d9407516f,DISK], DatanodeInfoWithStorage[127.0.0.1:40778,DS-fb0c5e94-ffb6-4700-a6c7-395f61c184d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36972,DS-e5292f8d-9653-4f28-9062-9dee8c77f3af,DISK], DatanodeInfoWithStorage[127.0.0.1:41131,DS-a1df892e-af2d-4bc0-849d-fc23b3ff35e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45689,DS-73e2ac24-fc5f-461f-be6a-513bb259c853,DISK], DatanodeInfoWithStorage[127.0.0.1:45778,DS-ff7a48be-0705-40d6-a457-3eacf649c3a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45961,DS-71d2dca8-0281-4184-ad64-426ade2367bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 62914560
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1614932333-172.17.0.20-1597541814960:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46788,DS-6fa69f42-8102-48ce-87dd-f975bfcee2a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34403,DS-45ff40b3-4cb0-4d5d-b432-c4aa500168de,DISK], DatanodeInfoWithStorage[127.0.0.1:37036,DS-8b649c2d-90ae-450f-807f-af02a0ab5be0,DISK], DatanodeInfoWithStorage[127.0.0.1:41835,DS-12bb6bc0-f387-4042-a9b1-257bb87383c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43322,DS-f72b3131-d16c-41f8-825f-3dc765315601,DISK], DatanodeInfoWithStorage[127.0.0.1:43991,DS-491563fe-4a79-4674-8282-40bb59ce845b,DISK], DatanodeInfoWithStorage[127.0.0.1:34312,DS-e8d91c12-e2aa-4e95-a653-212d794abe44,DISK], DatanodeInfoWithStorage[127.0.0.1:32795,DS-7998d4c9-1d0f-47f2-9300-ba9d21eb0012,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1614932333-172.17.0.20-1597541814960:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46788,DS-6fa69f42-8102-48ce-87dd-f975bfcee2a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34403,DS-45ff40b3-4cb0-4d5d-b432-c4aa500168de,DISK], DatanodeInfoWithStorage[127.0.0.1:37036,DS-8b649c2d-90ae-450f-807f-af02a0ab5be0,DISK], DatanodeInfoWithStorage[127.0.0.1:41835,DS-12bb6bc0-f387-4042-a9b1-257bb87383c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43322,DS-f72b3131-d16c-41f8-825f-3dc765315601,DISK], DatanodeInfoWithStorage[127.0.0.1:43991,DS-491563fe-4a79-4674-8282-40bb59ce845b,DISK], DatanodeInfoWithStorage[127.0.0.1:34312,DS-e8d91c12-e2aa-4e95-a653-212d794abe44,DISK], DatanodeInfoWithStorage[127.0.0.1:32795,DS-7998d4c9-1d0f-47f2-9300-ba9d21eb0012,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 62914560
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1717444431-172.17.0.20-1597542099278:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44248,DS-1bc8ef79-3fca-47e1-8d95-c5b87961724d,DISK], DatanodeInfoWithStorage[127.0.0.1:32797,DS-aa6662a4-1aa7-42f3-87ad-26e9388821d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42271,DS-43f54dbe-cdd0-41e6-a0f5-1a065f23cd4f,DISK], DatanodeInfoWithStorage[127.0.0.1:38333,DS-d1cb8174-be4c-4b85-84ce-fd1ad9685f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:45538,DS-fc11af56-06fd-4b7f-8410-de0d251c2c44,DISK], DatanodeInfoWithStorage[127.0.0.1:35621,DS-82156e18-2e51-4353-bad5-f9a84cccb56d,DISK], DatanodeInfoWithStorage[127.0.0.1:38229,DS-5346b2db-f8b3-4130-8b8f-a7650198dbc0,DISK], DatanodeInfoWithStorage[127.0.0.1:43710,DS-29f2bf9d-5124-4057-8f82-f5a3f2dacb16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1717444431-172.17.0.20-1597542099278:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44248,DS-1bc8ef79-3fca-47e1-8d95-c5b87961724d,DISK], DatanodeInfoWithStorage[127.0.0.1:32797,DS-aa6662a4-1aa7-42f3-87ad-26e9388821d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42271,DS-43f54dbe-cdd0-41e6-a0f5-1a065f23cd4f,DISK], DatanodeInfoWithStorage[127.0.0.1:38333,DS-d1cb8174-be4c-4b85-84ce-fd1ad9685f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:45538,DS-fc11af56-06fd-4b7f-8410-de0d251c2c44,DISK], DatanodeInfoWithStorage[127.0.0.1:35621,DS-82156e18-2e51-4353-bad5-f9a84cccb56d,DISK], DatanodeInfoWithStorage[127.0.0.1:38229,DS-5346b2db-f8b3-4130-8b8f-a7650198dbc0,DISK], DatanodeInfoWithStorage[127.0.0.1:43710,DS-29f2bf9d-5124-4057-8f82-f5a3f2dacb16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 62914560
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2022529917-172.17.0.20-1597542377676:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38113,DS-ad61e8cc-bfd4-475c-8741-c7b7c9ba478d,DISK], DatanodeInfoWithStorage[127.0.0.1:43676,DS-ec529164-c75b-4096-9755-a57cc61f329f,DISK], DatanodeInfoWithStorage[127.0.0.1:37680,DS-a9cf2333-cb84-4a08-a898-66bc4624abba,DISK], DatanodeInfoWithStorage[127.0.0.1:46243,DS-82a28b19-06fd-4fab-91cb-10f77c969180,DISK], DatanodeInfoWithStorage[127.0.0.1:45870,DS-5bb52ae6-0112-413c-a4d1-9a19b072e5f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33755,DS-d6860c2b-9737-41f6-8bd9-7ab402f53d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:39666,DS-a12d37c6-5ff8-4d78-b04f-6e221fc26315,DISK], DatanodeInfoWithStorage[127.0.0.1:43675,DS-c2e6edbc-c6d7-4f0c-8956-1bc0ff144ba7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2022529917-172.17.0.20-1597542377676:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38113,DS-ad61e8cc-bfd4-475c-8741-c7b7c9ba478d,DISK], DatanodeInfoWithStorage[127.0.0.1:43676,DS-ec529164-c75b-4096-9755-a57cc61f329f,DISK], DatanodeInfoWithStorage[127.0.0.1:37680,DS-a9cf2333-cb84-4a08-a898-66bc4624abba,DISK], DatanodeInfoWithStorage[127.0.0.1:46243,DS-82a28b19-06fd-4fab-91cb-10f77c969180,DISK], DatanodeInfoWithStorage[127.0.0.1:45870,DS-5bb52ae6-0112-413c-a4d1-9a19b072e5f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33755,DS-d6860c2b-9737-41f6-8bd9-7ab402f53d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:39666,DS-a12d37c6-5ff8-4d78-b04f-6e221fc26315,DISK], DatanodeInfoWithStorage[127.0.0.1:43675,DS-c2e6edbc-c6d7-4f0c-8956-1bc0ff144ba7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 62914560
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-128098251-172.17.0.20-1597542489479:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35972,DS-f9b7a428-b316-4533-b203-1c2a05d22d27,DISK], DatanodeInfoWithStorage[127.0.0.1:42987,DS-e2e86e94-3f00-4f09-9d6c-858feafbe870,DISK], DatanodeInfoWithStorage[127.0.0.1:38706,DS-997b198b-4465-4a23-86fa-e86f93c0b16f,DISK], DatanodeInfoWithStorage[127.0.0.1:42495,DS-ba98932e-1651-497f-b0c5-e63a0c115dec,DISK], DatanodeInfoWithStorage[127.0.0.1:39961,DS-c1a9efda-b6c1-4dcc-a9df-6f564cd408eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43491,DS-f41a6e14-0153-4631-a1fb-3929ff5ebbef,DISK], DatanodeInfoWithStorage[127.0.0.1:42646,DS-f95834bc-7927-4165-bd61-a53d427e2753,DISK], DatanodeInfoWithStorage[127.0.0.1:33964,DS-4d1dd2ef-de52-4a70-8a8c-630a37d1d9ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-128098251-172.17.0.20-1597542489479:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35972,DS-f9b7a428-b316-4533-b203-1c2a05d22d27,DISK], DatanodeInfoWithStorage[127.0.0.1:42987,DS-e2e86e94-3f00-4f09-9d6c-858feafbe870,DISK], DatanodeInfoWithStorage[127.0.0.1:38706,DS-997b198b-4465-4a23-86fa-e86f93c0b16f,DISK], DatanodeInfoWithStorage[127.0.0.1:42495,DS-ba98932e-1651-497f-b0c5-e63a0c115dec,DISK], DatanodeInfoWithStorage[127.0.0.1:39961,DS-c1a9efda-b6c1-4dcc-a9df-6f564cd408eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43491,DS-f41a6e14-0153-4631-a1fb-3929ff5ebbef,DISK], DatanodeInfoWithStorage[127.0.0.1:42646,DS-f95834bc-7927-4165-bd61-a53d427e2753,DISK], DatanodeInfoWithStorage[127.0.0.1:33964,DS-4d1dd2ef-de52-4a70-8a8c-630a37d1d9ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 62914560
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-561464552-172.17.0.20-1597542522230:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34984,DS-028d7f5a-d54f-46b5-99ee-4c175213f8d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38933,DS-bbcc42e9-20a7-426f-b7c0-e0c47e3988f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42280,DS-00a62e8a-a011-43a3-8131-23ad4705f1ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35730,DS-41216edc-0ddd-4944-aae0-ae9a79798c67,DISK], DatanodeInfoWithStorage[127.0.0.1:45576,DS-66067d1f-37b4-4544-9264-3da2afb13980,DISK], DatanodeInfoWithStorage[127.0.0.1:46159,DS-fb376fe5-b5ee-4c20-8e94-312d028fd5b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43408,DS-93e2e5b0-2a17-47ce-bdcd-3ea5aee10880,DISK], DatanodeInfoWithStorage[127.0.0.1:36230,DS-b4e26be6-def7-43bd-bf7f-6bba71df6b54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-561464552-172.17.0.20-1597542522230:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34984,DS-028d7f5a-d54f-46b5-99ee-4c175213f8d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38933,DS-bbcc42e9-20a7-426f-b7c0-e0c47e3988f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42280,DS-00a62e8a-a011-43a3-8131-23ad4705f1ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35730,DS-41216edc-0ddd-4944-aae0-ae9a79798c67,DISK], DatanodeInfoWithStorage[127.0.0.1:45576,DS-66067d1f-37b4-4544-9264-3da2afb13980,DISK], DatanodeInfoWithStorage[127.0.0.1:46159,DS-fb376fe5-b5ee-4c20-8e94-312d028fd5b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43408,DS-93e2e5b0-2a17-47ce-bdcd-3ea5aee10880,DISK], DatanodeInfoWithStorage[127.0.0.1:36230,DS-b4e26be6-def7-43bd-bf7f-6bba71df6b54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 62914560
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-331164002-172.17.0.20-1597542697510:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42619,DS-0888ec40-d15d-463f-8a6b-a283917b9fce,DISK], DatanodeInfoWithStorage[127.0.0.1:43012,DS-caf0ea86-0bae-4d95-9739-b821e13413a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34151,DS-4a8fa396-2a92-47de-9080-f197c997265c,DISK], DatanodeInfoWithStorage[127.0.0.1:36451,DS-2b1ad0cc-1bdc-4d4d-9571-4ce9d4e8c386,DISK], DatanodeInfoWithStorage[127.0.0.1:43572,DS-945f8b9a-0701-4192-9996-3c58a3e57eba,DISK], DatanodeInfoWithStorage[127.0.0.1:34587,DS-1bff23a0-35b4-4523-a06f-5763b26cea29,DISK], DatanodeInfoWithStorage[127.0.0.1:38710,DS-f1a494a6-b4d5-413c-8cea-e9c8d99038b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36636,DS-47a94c7c-c1e4-4805-b7ec-e8a24f38d211,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-331164002-172.17.0.20-1597542697510:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42619,DS-0888ec40-d15d-463f-8a6b-a283917b9fce,DISK], DatanodeInfoWithStorage[127.0.0.1:43012,DS-caf0ea86-0bae-4d95-9739-b821e13413a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34151,DS-4a8fa396-2a92-47de-9080-f197c997265c,DISK], DatanodeInfoWithStorage[127.0.0.1:36451,DS-2b1ad0cc-1bdc-4d4d-9571-4ce9d4e8c386,DISK], DatanodeInfoWithStorage[127.0.0.1:43572,DS-945f8b9a-0701-4192-9996-3c58a3e57eba,DISK], DatanodeInfoWithStorage[127.0.0.1:34587,DS-1bff23a0-35b4-4523-a06f-5763b26cea29,DISK], DatanodeInfoWithStorage[127.0.0.1:38710,DS-f1a494a6-b4d5-413c-8cea-e9c8d99038b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36636,DS-47a94c7c-c1e4-4805-b7ec-e8a24f38d211,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 62914560
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-466777624-172.17.0.20-1597542766106:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32950,DS-c85dcc27-159b-4394-a638-43f6212492b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38068,DS-07c913fb-a678-4c35-bce3-9374385ec442,DISK], DatanodeInfoWithStorage[127.0.0.1:40140,DS-354385a5-bee7-4070-8baa-7fc74de57f69,DISK], DatanodeInfoWithStorage[127.0.0.1:35175,DS-d1cfa339-8a08-48e4-8506-1f5a428c405d,DISK], DatanodeInfoWithStorage[127.0.0.1:44961,DS-f1b743c6-8beb-42e9-a44b-79d27a57801d,DISK], DatanodeInfoWithStorage[127.0.0.1:42430,DS-c283c055-c838-4fb0-9ef0-b0175af40007,DISK], DatanodeInfoWithStorage[127.0.0.1:37234,DS-a84f5d48-db8a-4715-b278-b9d568690be9,DISK], DatanodeInfoWithStorage[127.0.0.1:45719,DS-e99e8921-b6ae-489a-a904-1339e874ff4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-466777624-172.17.0.20-1597542766106:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32950,DS-c85dcc27-159b-4394-a638-43f6212492b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38068,DS-07c913fb-a678-4c35-bce3-9374385ec442,DISK], DatanodeInfoWithStorage[127.0.0.1:40140,DS-354385a5-bee7-4070-8baa-7fc74de57f69,DISK], DatanodeInfoWithStorage[127.0.0.1:35175,DS-d1cfa339-8a08-48e4-8506-1f5a428c405d,DISK], DatanodeInfoWithStorage[127.0.0.1:44961,DS-f1b743c6-8beb-42e9-a44b-79d27a57801d,DISK], DatanodeInfoWithStorage[127.0.0.1:42430,DS-c283c055-c838-4fb0-9ef0-b0175af40007,DISK], DatanodeInfoWithStorage[127.0.0.1:37234,DS-a84f5d48-db8a-4715-b278-b9d568690be9,DISK], DatanodeInfoWithStorage[127.0.0.1:45719,DS-e99e8921-b6ae-489a-a904-1339e874ff4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 62914560
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1085910070-172.17.0.20-1597542971966:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40279,DS-d07b88f3-07fc-4103-ba50-4658f9cada38,DISK], DatanodeInfoWithStorage[127.0.0.1:36150,DS-0b22be03-9334-4c88-ae19-a1abdb852bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:41422,DS-873fb1d5-737c-4805-80ec-15d2018a0c46,DISK], DatanodeInfoWithStorage[127.0.0.1:40607,DS-c6de06c4-0233-429a-8f3d-397bfbf28534,DISK], DatanodeInfoWithStorage[127.0.0.1:38795,DS-6d43b6f6-2a75-49fa-9e20-7d7e485989a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44256,DS-71f18de9-91a0-4c91-bd6e-a02880ef47cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36866,DS-ba9eb60b-a07d-4ad7-8783-049980693cba,DISK], DatanodeInfoWithStorage[127.0.0.1:34371,DS-54b65234-42ce-4b69-8106-c0860ea26aec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1085910070-172.17.0.20-1597542971966:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40279,DS-d07b88f3-07fc-4103-ba50-4658f9cada38,DISK], DatanodeInfoWithStorage[127.0.0.1:36150,DS-0b22be03-9334-4c88-ae19-a1abdb852bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:41422,DS-873fb1d5-737c-4805-80ec-15d2018a0c46,DISK], DatanodeInfoWithStorage[127.0.0.1:40607,DS-c6de06c4-0233-429a-8f3d-397bfbf28534,DISK], DatanodeInfoWithStorage[127.0.0.1:38795,DS-6d43b6f6-2a75-49fa-9e20-7d7e485989a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44256,DS-71f18de9-91a0-4c91-bd6e-a02880ef47cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36866,DS-ba9eb60b-a07d-4ad7-8783-049980693cba,DISK], DatanodeInfoWithStorage[127.0.0.1:34371,DS-54b65234-42ce-4b69-8106-c0860ea26aec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 62914560
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1581669427-172.17.0.20-1597543141417:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38243,DS-ae5fb4ce-6115-48ca-9f69-b653d2b26ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:41931,DS-15a80138-600f-4b44-a6d6-9cdf8237c628,DISK], DatanodeInfoWithStorage[127.0.0.1:45452,DS-724f3260-e53d-4dad-922f-8eb9ac574bea,DISK], DatanodeInfoWithStorage[127.0.0.1:39590,DS-826cef2f-49cf-41c8-9a0c-8f7adada09fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46185,DS-04ce180b-347c-400c-86b2-08504988f980,DISK], DatanodeInfoWithStorage[127.0.0.1:36013,DS-50c25b6d-a723-4d3d-b95b-d3fd39716259,DISK], DatanodeInfoWithStorage[127.0.0.1:43712,DS-0f32b533-0d88-4733-892a-f513cf824834,DISK], DatanodeInfoWithStorage[127.0.0.1:41309,DS-038b7b3d-94d3-424c-89ae-8d803b145696,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1581669427-172.17.0.20-1597543141417:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38243,DS-ae5fb4ce-6115-48ca-9f69-b653d2b26ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:41931,DS-15a80138-600f-4b44-a6d6-9cdf8237c628,DISK], DatanodeInfoWithStorage[127.0.0.1:45452,DS-724f3260-e53d-4dad-922f-8eb9ac574bea,DISK], DatanodeInfoWithStorage[127.0.0.1:39590,DS-826cef2f-49cf-41c8-9a0c-8f7adada09fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46185,DS-04ce180b-347c-400c-86b2-08504988f980,DISK], DatanodeInfoWithStorage[127.0.0.1:36013,DS-50c25b6d-a723-4d3d-b95b-d3fd39716259,DISK], DatanodeInfoWithStorage[127.0.0.1:43712,DS-0f32b533-0d88-4733-892a-f513cf824834,DISK], DatanodeInfoWithStorage[127.0.0.1:41309,DS-038b7b3d-94d3-424c-89ae-8d803b145696,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 62914560
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-675043224-172.17.0.20-1597543570351:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41938,DS-3d926b5c-e85a-4929-8533-b9ea58593626,DISK], DatanodeInfoWithStorage[127.0.0.1:44662,DS-a18ba20c-f5e4-4e61-adae-8fb2709fdc2b,DISK], DatanodeInfoWithStorage[127.0.0.1:39314,DS-e45c4c41-bf02-49ca-8a16-1dbd8991913f,DISK], DatanodeInfoWithStorage[127.0.0.1:35416,DS-532dc345-aab9-4a21-a580-5de56cb5750a,DISK], DatanodeInfoWithStorage[127.0.0.1:44822,DS-fdc047c6-b536-42d8-8a3f-22c124a2fe44,DISK], DatanodeInfoWithStorage[127.0.0.1:32874,DS-5c6d4106-6119-4490-a30a-661de96d6714,DISK], DatanodeInfoWithStorage[127.0.0.1:34886,DS-d952d997-3ae1-430d-bc9f-9b18b51cb259,DISK], DatanodeInfoWithStorage[127.0.0.1:42610,DS-c0909ed2-575c-4214-ab88-506733ca6cb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-675043224-172.17.0.20-1597543570351:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41938,DS-3d926b5c-e85a-4929-8533-b9ea58593626,DISK], DatanodeInfoWithStorage[127.0.0.1:44662,DS-a18ba20c-f5e4-4e61-adae-8fb2709fdc2b,DISK], DatanodeInfoWithStorage[127.0.0.1:39314,DS-e45c4c41-bf02-49ca-8a16-1dbd8991913f,DISK], DatanodeInfoWithStorage[127.0.0.1:35416,DS-532dc345-aab9-4a21-a580-5de56cb5750a,DISK], DatanodeInfoWithStorage[127.0.0.1:44822,DS-fdc047c6-b536-42d8-8a3f-22c124a2fe44,DISK], DatanodeInfoWithStorage[127.0.0.1:32874,DS-5c6d4106-6119-4490-a30a-661de96d6714,DISK], DatanodeInfoWithStorage[127.0.0.1:34886,DS-d952d997-3ae1-430d-bc9f-9b18b51cb259,DISK], DatanodeInfoWithStorage[127.0.0.1:42610,DS-c0909ed2-575c-4214-ab88-506733ca6cb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 62914560
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-506956083-172.17.0.20-1597543635372:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40834,DS-ba787981-b405-4c40-a73e-eb1f50e6d6de,DISK], DatanodeInfoWithStorage[127.0.0.1:40926,DS-bb4a3b6c-770d-4f93-8b4d-8f909aabcefe,DISK], DatanodeInfoWithStorage[127.0.0.1:46606,DS-34ae3530-c067-4537-bff6-550c10d95bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:37811,DS-7beadad5-4e3b-4770-af02-ab84fda252fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36358,DS-037bf055-826b-4679-8b28-c24a372696f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46758,DS-21e59ef9-be06-4891-9ac8-320599851459,DISK], DatanodeInfoWithStorage[127.0.0.1:44915,DS-5c8d3b91-c8e7-4ab7-b2a3-9dbc229798ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39335,DS-330f1af5-6d27-495d-87a5-12a62d7d5800,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-506956083-172.17.0.20-1597543635372:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40834,DS-ba787981-b405-4c40-a73e-eb1f50e6d6de,DISK], DatanodeInfoWithStorage[127.0.0.1:40926,DS-bb4a3b6c-770d-4f93-8b4d-8f909aabcefe,DISK], DatanodeInfoWithStorage[127.0.0.1:46606,DS-34ae3530-c067-4537-bff6-550c10d95bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:37811,DS-7beadad5-4e3b-4770-af02-ab84fda252fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36358,DS-037bf055-826b-4679-8b28-c24a372696f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46758,DS-21e59ef9-be06-4891-9ac8-320599851459,DISK], DatanodeInfoWithStorage[127.0.0.1:44915,DS-5c8d3b91-c8e7-4ab7-b2a3-9dbc229798ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39335,DS-330f1af5-6d27-495d-87a5-12a62d7d5800,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 19 out of 50
result: false positive !!!
Total execution time in seconds : 5205
