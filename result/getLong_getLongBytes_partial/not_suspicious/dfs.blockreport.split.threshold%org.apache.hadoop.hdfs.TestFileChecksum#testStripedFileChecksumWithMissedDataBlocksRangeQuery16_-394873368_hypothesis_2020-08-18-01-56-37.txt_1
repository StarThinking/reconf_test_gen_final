reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1376498669-172.17.0.18-1597715884541:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43257,DS-61883152-834a-4b3e-b8c6-fb167caa2caf,DISK], DatanodeInfoWithStorage[127.0.0.1:39637,DS-91811c02-8394-4d4c-a28b-217e60e20054,DISK], DatanodeInfoWithStorage[127.0.0.1:36651,DS-714e2042-12d1-4031-9c54-4b03005f6279,DISK], DatanodeInfoWithStorage[127.0.0.1:42731,DS-f373cd31-5f5c-49cd-b3ec-d73782948ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:37700,DS-5f2f4d44-d8b6-46d7-a727-45798adeecca,DISK], DatanodeInfoWithStorage[127.0.0.1:45389,DS-bb7954c6-53ec-491b-8560-4427c2070076,DISK], DatanodeInfoWithStorage[127.0.0.1:44371,DS-c54dbe08-8fa2-460b-aff2-719581daf522,DISK], DatanodeInfoWithStorage[127.0.0.1:42200,DS-6036cc47-98c2-4f16-ab34-c4a81b66673a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1376498669-172.17.0.18-1597715884541:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43257,DS-61883152-834a-4b3e-b8c6-fb167caa2caf,DISK], DatanodeInfoWithStorage[127.0.0.1:39637,DS-91811c02-8394-4d4c-a28b-217e60e20054,DISK], DatanodeInfoWithStorage[127.0.0.1:36651,DS-714e2042-12d1-4031-9c54-4b03005f6279,DISK], DatanodeInfoWithStorage[127.0.0.1:42731,DS-f373cd31-5f5c-49cd-b3ec-d73782948ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:37700,DS-5f2f4d44-d8b6-46d7-a727-45798adeecca,DISK], DatanodeInfoWithStorage[127.0.0.1:45389,DS-bb7954c6-53ec-491b-8560-4427c2070076,DISK], DatanodeInfoWithStorage[127.0.0.1:44371,DS-c54dbe08-8fa2-460b-aff2-719581daf522,DISK], DatanodeInfoWithStorage[127.0.0.1:42200,DS-6036cc47-98c2-4f16-ab34-c4a81b66673a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1867285405-172.17.0.18-1597716129606:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42088,DS-d5fe4556-2a51-44f2-ac9c-655014cb135a,DISK], DatanodeInfoWithStorage[127.0.0.1:34948,DS-891ec8f5-cf1d-4ff8-b513-1e15efe65aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:33711,DS-a91765fe-5945-48fa-9a20-067a54a5fb28,DISK], DatanodeInfoWithStorage[127.0.0.1:42960,DS-1bdf33c1-66ae-4231-a859-2148c6f702ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42928,DS-9fd0eb7a-5bb4-4843-aa14-13bcd16daa76,DISK], DatanodeInfoWithStorage[127.0.0.1:36081,DS-4405e1a7-5990-4537-b407-baa7d9cb7ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:40397,DS-b6fcc009-ad4f-423a-8aa8-b34f64ccdb52,DISK], DatanodeInfoWithStorage[127.0.0.1:36692,DS-e9f94100-39af-46e4-b62d-9f6a34d3fd98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1867285405-172.17.0.18-1597716129606:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42088,DS-d5fe4556-2a51-44f2-ac9c-655014cb135a,DISK], DatanodeInfoWithStorage[127.0.0.1:34948,DS-891ec8f5-cf1d-4ff8-b513-1e15efe65aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:33711,DS-a91765fe-5945-48fa-9a20-067a54a5fb28,DISK], DatanodeInfoWithStorage[127.0.0.1:42960,DS-1bdf33c1-66ae-4231-a859-2148c6f702ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42928,DS-9fd0eb7a-5bb4-4843-aa14-13bcd16daa76,DISK], DatanodeInfoWithStorage[127.0.0.1:36081,DS-4405e1a7-5990-4537-b407-baa7d9cb7ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:40397,DS-b6fcc009-ad4f-423a-8aa8-b34f64ccdb52,DISK], DatanodeInfoWithStorage[127.0.0.1:36692,DS-e9f94100-39af-46e4-b62d-9f6a34d3fd98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-781937293-172.17.0.18-1597716202018:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45110,DS-4ad431bc-bee3-463f-9a2f-07ace0298bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:36722,DS-be262db6-3b05-4c5c-9f9e-fa7b23acb2a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39085,DS-51db65f2-9e61-4599-a794-c03700f95b08,DISK], DatanodeInfoWithStorage[127.0.0.1:38034,DS-6a9bf380-9a58-4a4a-acd9-d0b714b560fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34555,DS-1a22f0fe-3ff9-4fbe-9886-914b9e63d7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46862,DS-38cb50d6-a30e-4b66-b896-827c81edc8e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33958,DS-c9bbf659-2e3e-4ff3-9fcc-fd388bbf55a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46416,DS-85eb8cb8-1ea5-4647-8cb3-e861ab963f9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-781937293-172.17.0.18-1597716202018:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45110,DS-4ad431bc-bee3-463f-9a2f-07ace0298bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:36722,DS-be262db6-3b05-4c5c-9f9e-fa7b23acb2a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39085,DS-51db65f2-9e61-4599-a794-c03700f95b08,DISK], DatanodeInfoWithStorage[127.0.0.1:38034,DS-6a9bf380-9a58-4a4a-acd9-d0b714b560fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34555,DS-1a22f0fe-3ff9-4fbe-9886-914b9e63d7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46862,DS-38cb50d6-a30e-4b66-b896-827c81edc8e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33958,DS-c9bbf659-2e3e-4ff3-9fcc-fd388bbf55a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46416,DS-85eb8cb8-1ea5-4647-8cb3-e861ab963f9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2110998239-172.17.0.18-1597716623635:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42127,DS-c884443a-8508-4b18-b249-f8bf9b7ea241,DISK], DatanodeInfoWithStorage[127.0.0.1:39684,DS-aa3c4e74-6ec8-4d75-b768-b7a568838c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38536,DS-8aa8b1bf-b192-4a73-8a1a-5cc0e3980af7,DISK], DatanodeInfoWithStorage[127.0.0.1:37961,DS-94c22646-c561-49d5-8432-127fe628592a,DISK], DatanodeInfoWithStorage[127.0.0.1:45684,DS-1244ec85-c192-4f75-9e58-6db9cdb56270,DISK], DatanodeInfoWithStorage[127.0.0.1:46202,DS-cdd01384-a447-4bcf-a552-3d08cdd3d489,DISK], DatanodeInfoWithStorage[127.0.0.1:44220,DS-e0b175e0-0733-40b6-982c-6f4a0a55489f,DISK], DatanodeInfoWithStorage[127.0.0.1:41037,DS-edd56755-4102-44ad-9d73-741dea7d18dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2110998239-172.17.0.18-1597716623635:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42127,DS-c884443a-8508-4b18-b249-f8bf9b7ea241,DISK], DatanodeInfoWithStorage[127.0.0.1:39684,DS-aa3c4e74-6ec8-4d75-b768-b7a568838c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38536,DS-8aa8b1bf-b192-4a73-8a1a-5cc0e3980af7,DISK], DatanodeInfoWithStorage[127.0.0.1:37961,DS-94c22646-c561-49d5-8432-127fe628592a,DISK], DatanodeInfoWithStorage[127.0.0.1:45684,DS-1244ec85-c192-4f75-9e58-6db9cdb56270,DISK], DatanodeInfoWithStorage[127.0.0.1:46202,DS-cdd01384-a447-4bcf-a552-3d08cdd3d489,DISK], DatanodeInfoWithStorage[127.0.0.1:44220,DS-e0b175e0-0733-40b6-982c-6f4a0a55489f,DISK], DatanodeInfoWithStorage[127.0.0.1:41037,DS-edd56755-4102-44ad-9d73-741dea7d18dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-640763177-172.17.0.18-1597717228387:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44174,DS-48e79e5b-9fdf-4311-a282-bcc06633395a,DISK], DatanodeInfoWithStorage[127.0.0.1:34567,DS-a8661a11-3e73-4ff9-ab14-fe1acca0e36e,DISK], DatanodeInfoWithStorage[127.0.0.1:33253,DS-6a33f762-4397-4382-9889-ad752334365e,DISK], DatanodeInfoWithStorage[127.0.0.1:41577,DS-f3d149af-6772-4107-849d-bd5f9d261fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:34705,DS-9183bb0e-0c49-43a0-8f9a-1671b49a79dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43692,DS-a4e3803c-e299-428f-aa5d-c3b540bf1e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40302,DS-ca03a9cb-a479-4bf5-a378-6fcd367c2d19,DISK], DatanodeInfoWithStorage[127.0.0.1:41261,DS-0d644a28-520c-46a7-8a6c-0e6a63ac9723,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-640763177-172.17.0.18-1597717228387:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44174,DS-48e79e5b-9fdf-4311-a282-bcc06633395a,DISK], DatanodeInfoWithStorage[127.0.0.1:34567,DS-a8661a11-3e73-4ff9-ab14-fe1acca0e36e,DISK], DatanodeInfoWithStorage[127.0.0.1:33253,DS-6a33f762-4397-4382-9889-ad752334365e,DISK], DatanodeInfoWithStorage[127.0.0.1:41577,DS-f3d149af-6772-4107-849d-bd5f9d261fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:34705,DS-9183bb0e-0c49-43a0-8f9a-1671b49a79dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43692,DS-a4e3803c-e299-428f-aa5d-c3b540bf1e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40302,DS-ca03a9cb-a479-4bf5-a378-6fcd367c2d19,DISK], DatanodeInfoWithStorage[127.0.0.1:41261,DS-0d644a28-520c-46a7-8a6c-0e6a63ac9723,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1125980953-172.17.0.18-1597717618086:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44876,DS-7653c301-3115-487e-aed1-b7bd93a123b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33587,DS-7f20d62a-e07f-4c35-b6ae-1153af6d1371,DISK], DatanodeInfoWithStorage[127.0.0.1:46417,DS-0454d9ca-5eae-40d6-aacd-f196c4c95c54,DISK], DatanodeInfoWithStorage[127.0.0.1:35919,DS-ef4d23c2-c4c6-4c26-8a15-d9153a8dd442,DISK], DatanodeInfoWithStorage[127.0.0.1:32928,DS-d044ec74-284b-4494-ad1e-ec97c3ec1cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:42768,DS-8bc4a85e-90b0-47c1-a2d3-b9d1d5ac3ade,DISK], DatanodeInfoWithStorage[127.0.0.1:34331,DS-b1764581-376b-469a-9f12-4029d93917cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38526,DS-f0afd567-0d6d-4dc8-ae9d-9ff3d9c42ebf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1125980953-172.17.0.18-1597717618086:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44876,DS-7653c301-3115-487e-aed1-b7bd93a123b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33587,DS-7f20d62a-e07f-4c35-b6ae-1153af6d1371,DISK], DatanodeInfoWithStorage[127.0.0.1:46417,DS-0454d9ca-5eae-40d6-aacd-f196c4c95c54,DISK], DatanodeInfoWithStorage[127.0.0.1:35919,DS-ef4d23c2-c4c6-4c26-8a15-d9153a8dd442,DISK], DatanodeInfoWithStorage[127.0.0.1:32928,DS-d044ec74-284b-4494-ad1e-ec97c3ec1cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:42768,DS-8bc4a85e-90b0-47c1-a2d3-b9d1d5ac3ade,DISK], DatanodeInfoWithStorage[127.0.0.1:34331,DS-b1764581-376b-469a-9f12-4029d93917cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38526,DS-f0afd567-0d6d-4dc8-ae9d-9ff3d9c42ebf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1372465853-172.17.0.18-1597717895103:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38538,DS-0d568812-727a-4f84-a924-070094bb825a,DISK], DatanodeInfoWithStorage[127.0.0.1:33677,DS-9c04baf9-3511-4080-a63e-89786a2d4054,DISK], DatanodeInfoWithStorage[127.0.0.1:40200,DS-2322aa37-03c4-4dd3-8cde-928423cc8a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:40198,DS-11808b40-0f21-47c1-a702-bb0d8b90ffe2,DISK], DatanodeInfoWithStorage[127.0.0.1:39032,DS-a083416a-01ea-4409-8af9-1c6af290439a,DISK], DatanodeInfoWithStorage[127.0.0.1:32865,DS-9b6c761c-2ae7-4eb3-b7c3-6f2bdc83184f,DISK], DatanodeInfoWithStorage[127.0.0.1:38967,DS-92aee63d-4d26-4a88-aa08-1cbf2173b358,DISK], DatanodeInfoWithStorage[127.0.0.1:39981,DS-b9124b8c-f6bf-4807-8bd7-3fd899829bde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1372465853-172.17.0.18-1597717895103:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38538,DS-0d568812-727a-4f84-a924-070094bb825a,DISK], DatanodeInfoWithStorage[127.0.0.1:33677,DS-9c04baf9-3511-4080-a63e-89786a2d4054,DISK], DatanodeInfoWithStorage[127.0.0.1:40200,DS-2322aa37-03c4-4dd3-8cde-928423cc8a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:40198,DS-11808b40-0f21-47c1-a702-bb0d8b90ffe2,DISK], DatanodeInfoWithStorage[127.0.0.1:39032,DS-a083416a-01ea-4409-8af9-1c6af290439a,DISK], DatanodeInfoWithStorage[127.0.0.1:32865,DS-9b6c761c-2ae7-4eb3-b7c3-6f2bdc83184f,DISK], DatanodeInfoWithStorage[127.0.0.1:38967,DS-92aee63d-4d26-4a88-aa08-1cbf2173b358,DISK], DatanodeInfoWithStorage[127.0.0.1:39981,DS-b9124b8c-f6bf-4807-8bd7-3fd899829bde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1728234934-172.17.0.18-1597717926245:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42422,DS-c981394c-8cf5-47aa-a30d-dd7c6966c4c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42711,DS-a4b544eb-fa90-47ee-8aaa-a55e0eb9be3a,DISK], DatanodeInfoWithStorage[127.0.0.1:35117,DS-22143d73-490d-426d-b92e-18070519158e,DISK], DatanodeInfoWithStorage[127.0.0.1:46066,DS-094982eb-5fb8-4773-b666-b75f60bd181d,DISK], DatanodeInfoWithStorage[127.0.0.1:43064,DS-fa70547f-72a2-46e3-a883-f076d78e7a58,DISK], DatanodeInfoWithStorage[127.0.0.1:45819,DS-05ff3f63-5964-4738-a794-e994858761ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35464,DS-26984ec7-547f-4ef3-abbb-d5b774963638,DISK], DatanodeInfoWithStorage[127.0.0.1:42252,DS-7cb7cc8b-afbd-43af-80a5-fa60f6442d07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1728234934-172.17.0.18-1597717926245:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42422,DS-c981394c-8cf5-47aa-a30d-dd7c6966c4c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42711,DS-a4b544eb-fa90-47ee-8aaa-a55e0eb9be3a,DISK], DatanodeInfoWithStorage[127.0.0.1:35117,DS-22143d73-490d-426d-b92e-18070519158e,DISK], DatanodeInfoWithStorage[127.0.0.1:46066,DS-094982eb-5fb8-4773-b666-b75f60bd181d,DISK], DatanodeInfoWithStorage[127.0.0.1:43064,DS-fa70547f-72a2-46e3-a883-f076d78e7a58,DISK], DatanodeInfoWithStorage[127.0.0.1:45819,DS-05ff3f63-5964-4738-a794-e994858761ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35464,DS-26984ec7-547f-4ef3-abbb-d5b774963638,DISK], DatanodeInfoWithStorage[127.0.0.1:42252,DS-7cb7cc8b-afbd-43af-80a5-fa60f6442d07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-55194154-172.17.0.18-1597718313111:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33258,DS-2d8a1999-86de-496d-8101-d49964be8b71,DISK], DatanodeInfoWithStorage[127.0.0.1:45325,DS-9a6d8b0a-5844-4b90-a9f5-5fcffcefca5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38594,DS-1534fc5c-b4a9-4993-950d-1c671f619148,DISK], DatanodeInfoWithStorage[127.0.0.1:39688,DS-f5f1ce0a-0c27-4845-acf1-17bdf77772e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35378,DS-de0d8989-9711-4782-9145-fe7b9b8f2acd,DISK], DatanodeInfoWithStorage[127.0.0.1:45964,DS-a497dcee-b00f-468b-afa2-10ea15424792,DISK], DatanodeInfoWithStorage[127.0.0.1:34636,DS-4f50daa9-bea5-408a-9ca9-17b44ca7eb71,DISK], DatanodeInfoWithStorage[127.0.0.1:34960,DS-d9c130ad-f575-4d7a-9e4b-e09d517c098a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-55194154-172.17.0.18-1597718313111:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33258,DS-2d8a1999-86de-496d-8101-d49964be8b71,DISK], DatanodeInfoWithStorage[127.0.0.1:45325,DS-9a6d8b0a-5844-4b90-a9f5-5fcffcefca5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38594,DS-1534fc5c-b4a9-4993-950d-1c671f619148,DISK], DatanodeInfoWithStorage[127.0.0.1:39688,DS-f5f1ce0a-0c27-4845-acf1-17bdf77772e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35378,DS-de0d8989-9711-4782-9145-fe7b9b8f2acd,DISK], DatanodeInfoWithStorage[127.0.0.1:45964,DS-a497dcee-b00f-468b-afa2-10ea15424792,DISK], DatanodeInfoWithStorage[127.0.0.1:34636,DS-4f50daa9-bea5-408a-9ca9-17b44ca7eb71,DISK], DatanodeInfoWithStorage[127.0.0.1:34960,DS-d9c130ad-f575-4d7a-9e4b-e09d517c098a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-543404802-172.17.0.18-1597718553861:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35282,DS-4f8cd869-731b-4e97-a4b7-c05343fecd60,DISK], DatanodeInfoWithStorage[127.0.0.1:45460,DS-699cdf34-22d0-4417-844c-f0222e9af0f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45716,DS-f5babc4e-a83a-4440-8b90-1ca2a3293757,DISK], DatanodeInfoWithStorage[127.0.0.1:34920,DS-a9e1c213-0682-4a5e-85ac-4bde5ab659b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36154,DS-e729011c-d43d-4d56-a9ce-1b898d650954,DISK], DatanodeInfoWithStorage[127.0.0.1:39144,DS-3183a58f-34f6-4d85-abb5-e43ccda29bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:44633,DS-2eec1fba-3ccd-45e5-936a-3c2de98bc73f,DISK], DatanodeInfoWithStorage[127.0.0.1:38554,DS-fc0dc2b1-1e3a-405d-ad07-3fbec94ce59d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-543404802-172.17.0.18-1597718553861:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35282,DS-4f8cd869-731b-4e97-a4b7-c05343fecd60,DISK], DatanodeInfoWithStorage[127.0.0.1:45460,DS-699cdf34-22d0-4417-844c-f0222e9af0f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45716,DS-f5babc4e-a83a-4440-8b90-1ca2a3293757,DISK], DatanodeInfoWithStorage[127.0.0.1:34920,DS-a9e1c213-0682-4a5e-85ac-4bde5ab659b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36154,DS-e729011c-d43d-4d56-a9ce-1b898d650954,DISK], DatanodeInfoWithStorage[127.0.0.1:39144,DS-3183a58f-34f6-4d85-abb5-e43ccda29bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:44633,DS-2eec1fba-3ccd-45e5-936a-3c2de98bc73f,DISK], DatanodeInfoWithStorage[127.0.0.1:38554,DS-fc0dc2b1-1e3a-405d-ad07-3fbec94ce59d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1446315709-172.17.0.18-1597718659499:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44189,DS-094d6dd4-91ca-4096-9bfa-5025efa5e8b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37924,DS-424c0af3-88e7-41f4-a757-bb8ee06dd7b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39540,DS-a569676a-d4af-4071-84df-48791302b20d,DISK], DatanodeInfoWithStorage[127.0.0.1:34083,DS-b2a96951-ced3-4f7d-8d17-173c24d51704,DISK], DatanodeInfoWithStorage[127.0.0.1:40512,DS-1e0da9bc-1224-4888-954a-b617a70c5f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34416,DS-3c921a64-1e43-4723-ba3f-7189f47bf244,DISK], DatanodeInfoWithStorage[127.0.0.1:39483,DS-74baddf4-0180-4158-b2a5-934f3fb4e1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37203,DS-9a09cba4-e720-485c-bc91-178200bfea38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1446315709-172.17.0.18-1597718659499:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44189,DS-094d6dd4-91ca-4096-9bfa-5025efa5e8b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37924,DS-424c0af3-88e7-41f4-a757-bb8ee06dd7b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39540,DS-a569676a-d4af-4071-84df-48791302b20d,DISK], DatanodeInfoWithStorage[127.0.0.1:34083,DS-b2a96951-ced3-4f7d-8d17-173c24d51704,DISK], DatanodeInfoWithStorage[127.0.0.1:40512,DS-1e0da9bc-1224-4888-954a-b617a70c5f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34416,DS-3c921a64-1e43-4723-ba3f-7189f47bf244,DISK], DatanodeInfoWithStorage[127.0.0.1:39483,DS-74baddf4-0180-4158-b2a5-934f3fb4e1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37203,DS-9a09cba4-e720-485c-bc91-178200bfea38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-213248678-172.17.0.18-1597719702403:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36125,DS-e78027fd-f841-4274-884b-506d0aaaf94c,DISK], DatanodeInfoWithStorage[127.0.0.1:46026,DS-816f63dc-6b75-4470-9d00-00b9e02fb36f,DISK], DatanodeInfoWithStorage[127.0.0.1:36301,DS-768ae851-b8ed-4282-8c1d-8fe86b300df6,DISK], DatanodeInfoWithStorage[127.0.0.1:43098,DS-aa3a6a9d-1dd9-47d3-8359-19a4721670c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42573,DS-8633f2f4-2e39-444c-bb1d-36b3a092873a,DISK], DatanodeInfoWithStorage[127.0.0.1:44742,DS-520ce298-c6e5-4571-bc65-5ef51e94ada3,DISK], DatanodeInfoWithStorage[127.0.0.1:42934,DS-5414d2d9-1801-48cc-be77-939b717a28ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42016,DS-785c6567-fcd4-44d7-9088-db931bcf8446,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-213248678-172.17.0.18-1597719702403:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36125,DS-e78027fd-f841-4274-884b-506d0aaaf94c,DISK], DatanodeInfoWithStorage[127.0.0.1:46026,DS-816f63dc-6b75-4470-9d00-00b9e02fb36f,DISK], DatanodeInfoWithStorage[127.0.0.1:36301,DS-768ae851-b8ed-4282-8c1d-8fe86b300df6,DISK], DatanodeInfoWithStorage[127.0.0.1:43098,DS-aa3a6a9d-1dd9-47d3-8359-19a4721670c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42573,DS-8633f2f4-2e39-444c-bb1d-36b3a092873a,DISK], DatanodeInfoWithStorage[127.0.0.1:44742,DS-520ce298-c6e5-4571-bc65-5ef51e94ada3,DISK], DatanodeInfoWithStorage[127.0.0.1:42934,DS-5414d2d9-1801-48cc-be77-939b717a28ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42016,DS-785c6567-fcd4-44d7-9088-db931bcf8446,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1541395981-172.17.0.18-1597720154234:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42067,DS-bfdc5a50-80a9-41b8-81b7-84536e06a49d,DISK], DatanodeInfoWithStorage[127.0.0.1:42531,DS-a313915f-a318-41cb-8412-732e9b51c210,DISK], DatanodeInfoWithStorage[127.0.0.1:40619,DS-1772f70a-7351-41bf-aecd-3de9f2fdb546,DISK], DatanodeInfoWithStorage[127.0.0.1:41795,DS-ed03ea4a-e74c-4e9a-8028-4a67de97df80,DISK], DatanodeInfoWithStorage[127.0.0.1:39321,DS-63d1166d-209f-4da8-b7c3-7e136e328522,DISK], DatanodeInfoWithStorage[127.0.0.1:46500,DS-f9498ecf-86e5-416d-8aeb-868082685271,DISK], DatanodeInfoWithStorage[127.0.0.1:42313,DS-23aa8b1d-5724-4455-8669-5c163483e8a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38198,DS-46d569b2-7eff-4471-9761-f9c9112cafd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1541395981-172.17.0.18-1597720154234:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42067,DS-bfdc5a50-80a9-41b8-81b7-84536e06a49d,DISK], DatanodeInfoWithStorage[127.0.0.1:42531,DS-a313915f-a318-41cb-8412-732e9b51c210,DISK], DatanodeInfoWithStorage[127.0.0.1:40619,DS-1772f70a-7351-41bf-aecd-3de9f2fdb546,DISK], DatanodeInfoWithStorage[127.0.0.1:41795,DS-ed03ea4a-e74c-4e9a-8028-4a67de97df80,DISK], DatanodeInfoWithStorage[127.0.0.1:39321,DS-63d1166d-209f-4da8-b7c3-7e136e328522,DISK], DatanodeInfoWithStorage[127.0.0.1:46500,DS-f9498ecf-86e5-416d-8aeb-868082685271,DISK], DatanodeInfoWithStorage[127.0.0.1:42313,DS-23aa8b1d-5724-4455-8669-5c163483e8a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38198,DS-46d569b2-7eff-4471-9761-f9c9112cafd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-791004021-172.17.0.18-1597720300216:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37561,DS-fe206cb6-78e6-470a-9ee0-6cc5a0b8ba90,DISK], DatanodeInfoWithStorage[127.0.0.1:38535,DS-a4be2973-a2a8-4df7-8d17-d26f530065c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45292,DS-27e5247a-eefe-445e-a637-42c5f618a94c,DISK], DatanodeInfoWithStorage[127.0.0.1:42428,DS-bc79417f-1930-4a2a-b413-15ad6003e503,DISK], DatanodeInfoWithStorage[127.0.0.1:44856,DS-43c18269-acfa-47a0-894e-8fdb4746a9e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44469,DS-f22a7c13-687d-4c08-9ba8-2ed35eec6245,DISK], DatanodeInfoWithStorage[127.0.0.1:35802,DS-a8bbd424-de8c-4741-a172-a8aae86f3f14,DISK], DatanodeInfoWithStorage[127.0.0.1:34345,DS-3ef2a2e8-9386-4c37-a5da-16e2ccecfb07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-791004021-172.17.0.18-1597720300216:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37561,DS-fe206cb6-78e6-470a-9ee0-6cc5a0b8ba90,DISK], DatanodeInfoWithStorage[127.0.0.1:38535,DS-a4be2973-a2a8-4df7-8d17-d26f530065c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45292,DS-27e5247a-eefe-445e-a637-42c5f618a94c,DISK], DatanodeInfoWithStorage[127.0.0.1:42428,DS-bc79417f-1930-4a2a-b413-15ad6003e503,DISK], DatanodeInfoWithStorage[127.0.0.1:44856,DS-43c18269-acfa-47a0-894e-8fdb4746a9e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44469,DS-f22a7c13-687d-4c08-9ba8-2ed35eec6245,DISK], DatanodeInfoWithStorage[127.0.0.1:35802,DS-a8bbd424-de8c-4741-a172-a8aae86f3f14,DISK], DatanodeInfoWithStorage[127.0.0.1:34345,DS-3ef2a2e8-9386-4c37-a5da-16e2ccecfb07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-714185451-172.17.0.18-1597720474870:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36123,DS-bda09932-e64a-4a9c-b8ca-6309d8339caa,DISK], DatanodeInfoWithStorage[127.0.0.1:45117,DS-8c5f309d-45d2-4463-8d44-64ec0981f7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35100,DS-5f97e31a-3d40-4964-9c6a-fb929ba05e77,DISK], DatanodeInfoWithStorage[127.0.0.1:38995,DS-fe652c5f-fa5b-42dc-ac05-af0e9edf4b32,DISK], DatanodeInfoWithStorage[127.0.0.1:35440,DS-ebaa910a-9741-4171-ba2e-6d0cc3260052,DISK], DatanodeInfoWithStorage[127.0.0.1:41188,DS-d295a213-0d96-4aa9-81b9-ba3c2131ab9d,DISK], DatanodeInfoWithStorage[127.0.0.1:46503,DS-e2b620fc-f270-49ee-a701-535918094d53,DISK], DatanodeInfoWithStorage[127.0.0.1:44312,DS-432eec58-c5f6-4580-9606-e0e7b3a7cfb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-714185451-172.17.0.18-1597720474870:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36123,DS-bda09932-e64a-4a9c-b8ca-6309d8339caa,DISK], DatanodeInfoWithStorage[127.0.0.1:45117,DS-8c5f309d-45d2-4463-8d44-64ec0981f7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35100,DS-5f97e31a-3d40-4964-9c6a-fb929ba05e77,DISK], DatanodeInfoWithStorage[127.0.0.1:38995,DS-fe652c5f-fa5b-42dc-ac05-af0e9edf4b32,DISK], DatanodeInfoWithStorage[127.0.0.1:35440,DS-ebaa910a-9741-4171-ba2e-6d0cc3260052,DISK], DatanodeInfoWithStorage[127.0.0.1:41188,DS-d295a213-0d96-4aa9-81b9-ba3c2131ab9d,DISK], DatanodeInfoWithStorage[127.0.0.1:46503,DS-e2b620fc-f270-49ee-a701-535918094d53,DISK], DatanodeInfoWithStorage[127.0.0.1:44312,DS-432eec58-c5f6-4580-9606-e0e7b3a7cfb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-151413998-172.17.0.18-1597720542959:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42341,DS-257cb596-b55b-4825-8f51-f820b2b0b4b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41353,DS-015b78e9-694b-4a62-a5f6-a740a51f48da,DISK], DatanodeInfoWithStorage[127.0.0.1:34185,DS-8a9e1b88-d70b-492f-b2e7-bd636187b871,DISK], DatanodeInfoWithStorage[127.0.0.1:44276,DS-4153c694-7f73-4527-bce7-cd1f64f8172f,DISK], DatanodeInfoWithStorage[127.0.0.1:42779,DS-c51c6752-9048-4d5b-9f56-e8eec36a9380,DISK], DatanodeInfoWithStorage[127.0.0.1:34635,DS-45c0732a-2130-4937-8dd5-02f5ad864539,DISK], DatanodeInfoWithStorage[127.0.0.1:35359,DS-a118bbfc-6d67-4934-8e8e-b3790072a522,DISK], DatanodeInfoWithStorage[127.0.0.1:45901,DS-dee77211-db91-4507-a9c1-0626d8a64eb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-151413998-172.17.0.18-1597720542959:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42341,DS-257cb596-b55b-4825-8f51-f820b2b0b4b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41353,DS-015b78e9-694b-4a62-a5f6-a740a51f48da,DISK], DatanodeInfoWithStorage[127.0.0.1:34185,DS-8a9e1b88-d70b-492f-b2e7-bd636187b871,DISK], DatanodeInfoWithStorage[127.0.0.1:44276,DS-4153c694-7f73-4527-bce7-cd1f64f8172f,DISK], DatanodeInfoWithStorage[127.0.0.1:42779,DS-c51c6752-9048-4d5b-9f56-e8eec36a9380,DISK], DatanodeInfoWithStorage[127.0.0.1:34635,DS-45c0732a-2130-4937-8dd5-02f5ad864539,DISK], DatanodeInfoWithStorage[127.0.0.1:35359,DS-a118bbfc-6d67-4934-8e8e-b3790072a522,DISK], DatanodeInfoWithStorage[127.0.0.1:45901,DS-dee77211-db91-4507-a9c1-0626d8a64eb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-96831265-172.17.0.18-1597720718525:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33397,DS-00e29ccf-e347-4a5d-962b-b56ffe739a60,DISK], DatanodeInfoWithStorage[127.0.0.1:36025,DS-06a5e486-1048-499f-9240-b4ae7b29641b,DISK], DatanodeInfoWithStorage[127.0.0.1:39731,DS-416e01ca-16c7-42f1-8e35-9b990db14085,DISK], DatanodeInfoWithStorage[127.0.0.1:37246,DS-9b512c3a-06e6-47a6-9ec6-8b63707f8633,DISK], DatanodeInfoWithStorage[127.0.0.1:33524,DS-33472c44-9e95-4b81-a48a-115fbdad6ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:38927,DS-77f23aa2-0737-49fa-90f7-21046cd7e022,DISK], DatanodeInfoWithStorage[127.0.0.1:43044,DS-889ef0d5-8f25-4266-9dba-6f0815d815ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45935,DS-f1e4957f-6900-49cc-a3c6-bf453f8c536a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-96831265-172.17.0.18-1597720718525:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33397,DS-00e29ccf-e347-4a5d-962b-b56ffe739a60,DISK], DatanodeInfoWithStorage[127.0.0.1:36025,DS-06a5e486-1048-499f-9240-b4ae7b29641b,DISK], DatanodeInfoWithStorage[127.0.0.1:39731,DS-416e01ca-16c7-42f1-8e35-9b990db14085,DISK], DatanodeInfoWithStorage[127.0.0.1:37246,DS-9b512c3a-06e6-47a6-9ec6-8b63707f8633,DISK], DatanodeInfoWithStorage[127.0.0.1:33524,DS-33472c44-9e95-4b81-a48a-115fbdad6ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:38927,DS-77f23aa2-0737-49fa-90f7-21046cd7e022,DISK], DatanodeInfoWithStorage[127.0.0.1:43044,DS-889ef0d5-8f25-4266-9dba-6f0815d815ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45935,DS-f1e4957f-6900-49cc-a3c6-bf453f8c536a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-996298474-172.17.0.18-1597720763068:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33887,DS-b2268408-38ca-4cf9-b9fe-cb1c7602719d,DISK], DatanodeInfoWithStorage[127.0.0.1:34342,DS-808a1b95-ce44-485f-ad26-1e18c5853548,DISK], DatanodeInfoWithStorage[127.0.0.1:43755,DS-f4a86310-3fc0-4f7a-9caa-3569eecbf09a,DISK], DatanodeInfoWithStorage[127.0.0.1:46591,DS-2878d9b6-ca26-40d8-9a6d-313b696ba241,DISK], DatanodeInfoWithStorage[127.0.0.1:41411,DS-ea2780fa-ea4c-448d-830f-c2516ab6439a,DISK], DatanodeInfoWithStorage[127.0.0.1:32808,DS-e6a0beb6-4c68-439e-a385-e567de11e8fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35179,DS-097c7792-fafc-4454-bc73-1f63cbdb4b00,DISK], DatanodeInfoWithStorage[127.0.0.1:39400,DS-7e788b21-2888-4ce7-aa0a-097ce8de6225,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-996298474-172.17.0.18-1597720763068:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33887,DS-b2268408-38ca-4cf9-b9fe-cb1c7602719d,DISK], DatanodeInfoWithStorage[127.0.0.1:34342,DS-808a1b95-ce44-485f-ad26-1e18c5853548,DISK], DatanodeInfoWithStorage[127.0.0.1:43755,DS-f4a86310-3fc0-4f7a-9caa-3569eecbf09a,DISK], DatanodeInfoWithStorage[127.0.0.1:46591,DS-2878d9b6-ca26-40d8-9a6d-313b696ba241,DISK], DatanodeInfoWithStorage[127.0.0.1:41411,DS-ea2780fa-ea4c-448d-830f-c2516ab6439a,DISK], DatanodeInfoWithStorage[127.0.0.1:32808,DS-e6a0beb6-4c68-439e-a385-e567de11e8fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35179,DS-097c7792-fafc-4454-bc73-1f63cbdb4b00,DISK], DatanodeInfoWithStorage[127.0.0.1:39400,DS-7e788b21-2888-4ce7-aa0a-097ce8de6225,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-696864760-172.17.0.18-1597720841740:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39280,DS-c4707741-050c-43e5-ba45-2613712f1cde,DISK], DatanodeInfoWithStorage[127.0.0.1:42868,DS-6ef32f48-3a53-41f6-87b2-dc17fba0f219,DISK], DatanodeInfoWithStorage[127.0.0.1:33389,DS-6f79cba1-036b-4c5d-bcef-9ffe318c66ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39971,DS-c6c24a53-e093-4141-9d4f-7c1b0cd04470,DISK], DatanodeInfoWithStorage[127.0.0.1:34500,DS-a3ac9532-21a2-412e-8d5e-c33d7f0c48a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35085,DS-7fea5a33-804b-481d-a582-a9fa6fbd8060,DISK], DatanodeInfoWithStorage[127.0.0.1:39448,DS-6f8bd0ef-d17c-4715-978b-a30ea6bf9ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:45571,DS-69ff96f1-574f-404a-942c-7bbce8e0ce02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-696864760-172.17.0.18-1597720841740:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39280,DS-c4707741-050c-43e5-ba45-2613712f1cde,DISK], DatanodeInfoWithStorage[127.0.0.1:42868,DS-6ef32f48-3a53-41f6-87b2-dc17fba0f219,DISK], DatanodeInfoWithStorage[127.0.0.1:33389,DS-6f79cba1-036b-4c5d-bcef-9ffe318c66ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39971,DS-c6c24a53-e093-4141-9d4f-7c1b0cd04470,DISK], DatanodeInfoWithStorage[127.0.0.1:34500,DS-a3ac9532-21a2-412e-8d5e-c33d7f0c48a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35085,DS-7fea5a33-804b-481d-a582-a9fa6fbd8060,DISK], DatanodeInfoWithStorage[127.0.0.1:39448,DS-6f8bd0ef-d17c-4715-978b-a30ea6bf9ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:45571,DS-69ff96f1-574f-404a-942c-7bbce8e0ce02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1819245221-172.17.0.18-1597720978858:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46720,DS-960974e9-e417-40ee-98a5-0ac3143e7e67,DISK], DatanodeInfoWithStorage[127.0.0.1:36181,DS-3bc74dfe-1de3-45a7-b616-5b59e8471192,DISK], DatanodeInfoWithStorage[127.0.0.1:46883,DS-59c1173d-ddf5-4779-be9e-a6eb805e314e,DISK], DatanodeInfoWithStorage[127.0.0.1:38287,DS-2732c5e7-c416-49f6-8643-52eaff7bd023,DISK], DatanodeInfoWithStorage[127.0.0.1:35578,DS-ae42b377-c820-493f-af2f-d0b1b2cb28d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41131,DS-9f9a0df6-45bd-4a69-9a70-0d0d3f87422f,DISK], DatanodeInfoWithStorage[127.0.0.1:36454,DS-b8761929-15fe-4b9b-8169-dcfa61b5d75a,DISK], DatanodeInfoWithStorage[127.0.0.1:36666,DS-b33ada77-671e-4b03-8a6a-fcf2bebf6b03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1819245221-172.17.0.18-1597720978858:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46720,DS-960974e9-e417-40ee-98a5-0ac3143e7e67,DISK], DatanodeInfoWithStorage[127.0.0.1:36181,DS-3bc74dfe-1de3-45a7-b616-5b59e8471192,DISK], DatanodeInfoWithStorage[127.0.0.1:46883,DS-59c1173d-ddf5-4779-be9e-a6eb805e314e,DISK], DatanodeInfoWithStorage[127.0.0.1:38287,DS-2732c5e7-c416-49f6-8643-52eaff7bd023,DISK], DatanodeInfoWithStorage[127.0.0.1:35578,DS-ae42b377-c820-493f-af2f-d0b1b2cb28d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41131,DS-9f9a0df6-45bd-4a69-9a70-0d0d3f87422f,DISK], DatanodeInfoWithStorage[127.0.0.1:36454,DS-b8761929-15fe-4b9b-8169-dcfa61b5d75a,DISK], DatanodeInfoWithStorage[127.0.0.1:36666,DS-b33ada77-671e-4b03-8a6a-fcf2bebf6b03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1538286689-172.17.0.18-1597721022476:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40141,DS-f9254d70-37b5-417a-8e51-4df1edfc0971,DISK], DatanodeInfoWithStorage[127.0.0.1:34450,DS-d0917d65-321c-4f9e-99ba-c4a2fc37d1a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37091,DS-eac62722-de59-4d46-9e8c-60b087917ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:34451,DS-16bff26b-89b9-46c8-bd01-ff1f835c4aea,DISK], DatanodeInfoWithStorage[127.0.0.1:35005,DS-cb529214-b84e-43a9-99d1-bfb9769ae809,DISK], DatanodeInfoWithStorage[127.0.0.1:39064,DS-1e2a5c05-5aa7-4b4a-9e55-2f0b9ad5d358,DISK], DatanodeInfoWithStorage[127.0.0.1:44139,DS-c9cd1c2a-106c-4a18-ba7c-26b656de2a75,DISK], DatanodeInfoWithStorage[127.0.0.1:40751,DS-61d2c185-06cb-46dc-96b2-c320c129a2a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1538286689-172.17.0.18-1597721022476:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40141,DS-f9254d70-37b5-417a-8e51-4df1edfc0971,DISK], DatanodeInfoWithStorage[127.0.0.1:34450,DS-d0917d65-321c-4f9e-99ba-c4a2fc37d1a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37091,DS-eac62722-de59-4d46-9e8c-60b087917ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:34451,DS-16bff26b-89b9-46c8-bd01-ff1f835c4aea,DISK], DatanodeInfoWithStorage[127.0.0.1:35005,DS-cb529214-b84e-43a9-99d1-bfb9769ae809,DISK], DatanodeInfoWithStorage[127.0.0.1:39064,DS-1e2a5c05-5aa7-4b4a-9e55-2f0b9ad5d358,DISK], DatanodeInfoWithStorage[127.0.0.1:44139,DS-c9cd1c2a-106c-4a18-ba7c-26b656de2a75,DISK], DatanodeInfoWithStorage[127.0.0.1:40751,DS-61d2c185-06cb-46dc-96b2-c320c129a2a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5249
