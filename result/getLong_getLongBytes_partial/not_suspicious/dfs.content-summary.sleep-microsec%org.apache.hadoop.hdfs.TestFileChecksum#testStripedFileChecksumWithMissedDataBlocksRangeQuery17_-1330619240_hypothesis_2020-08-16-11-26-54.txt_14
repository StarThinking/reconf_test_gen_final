reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1864664494-172.17.0.21-1597577383104:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42407,DS-27a271ca-d8b0-45fe-b55a-0a4c1c3eb153,DISK], DatanodeInfoWithStorage[127.0.0.1:43506,DS-af4e9619-0858-4e98-93e0-ba27131f2bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:33021,DS-b3fd2235-4e14-46a2-b624-980262626e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:40794,DS-cc453abf-6ad1-4b36-bc79-6bdd5d7843e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37991,DS-9b0e4486-dec7-48cf-bbc0-3e2171d51eb6,DISK], DatanodeInfoWithStorage[127.0.0.1:46831,DS-bb41b8e1-7f25-431e-9d4a-b4b30a43b134,DISK], DatanodeInfoWithStorage[127.0.0.1:34204,DS-1a9b4bd2-1dd1-4456-944a-b633284a85eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37946,DS-09775797-1ea5-441d-97a7-e071ec8dea89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1864664494-172.17.0.21-1597577383104:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42407,DS-27a271ca-d8b0-45fe-b55a-0a4c1c3eb153,DISK], DatanodeInfoWithStorage[127.0.0.1:43506,DS-af4e9619-0858-4e98-93e0-ba27131f2bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:33021,DS-b3fd2235-4e14-46a2-b624-980262626e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:40794,DS-cc453abf-6ad1-4b36-bc79-6bdd5d7843e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37991,DS-9b0e4486-dec7-48cf-bbc0-3e2171d51eb6,DISK], DatanodeInfoWithStorage[127.0.0.1:46831,DS-bb41b8e1-7f25-431e-9d4a-b4b30a43b134,DISK], DatanodeInfoWithStorage[127.0.0.1:34204,DS-1a9b4bd2-1dd1-4456-944a-b633284a85eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37946,DS-09775797-1ea5-441d-97a7-e071ec8dea89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1991015415-172.17.0.21-1597578030582:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43336,DS-eff88b54-0cb5-43f4-8d36-5e67ecab8971,DISK], DatanodeInfoWithStorage[127.0.0.1:36670,DS-d3213c7a-f780-4f45-8f2b-395a96c301fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39849,DS-9fb8614c-5279-4c34-8b2b-14ccb6c7400b,DISK], DatanodeInfoWithStorage[127.0.0.1:36953,DS-480ee568-a8dd-485a-8e0d-aa98a42f9fca,DISK], DatanodeInfoWithStorage[127.0.0.1:43480,DS-fcaabc2f-6c0e-4373-980b-99f9c440e217,DISK], DatanodeInfoWithStorage[127.0.0.1:39360,DS-729bba1a-ac9f-4571-852a-6ef05a5b0e24,DISK], DatanodeInfoWithStorage[127.0.0.1:33346,DS-f87d9998-61bc-4636-96b0-a5d3ac4060ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42753,DS-35d85f2f-c04e-4ff6-ab0c-d7c75c987a7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1991015415-172.17.0.21-1597578030582:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43336,DS-eff88b54-0cb5-43f4-8d36-5e67ecab8971,DISK], DatanodeInfoWithStorage[127.0.0.1:36670,DS-d3213c7a-f780-4f45-8f2b-395a96c301fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39849,DS-9fb8614c-5279-4c34-8b2b-14ccb6c7400b,DISK], DatanodeInfoWithStorage[127.0.0.1:36953,DS-480ee568-a8dd-485a-8e0d-aa98a42f9fca,DISK], DatanodeInfoWithStorage[127.0.0.1:43480,DS-fcaabc2f-6c0e-4373-980b-99f9c440e217,DISK], DatanodeInfoWithStorage[127.0.0.1:39360,DS-729bba1a-ac9f-4571-852a-6ef05a5b0e24,DISK], DatanodeInfoWithStorage[127.0.0.1:33346,DS-f87d9998-61bc-4636-96b0-a5d3ac4060ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42753,DS-35d85f2f-c04e-4ff6-ab0c-d7c75c987a7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-283077952-172.17.0.21-1597578067926:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35716,DS-e122c407-09e8-485b-b8e2-3395c029901e,DISK], DatanodeInfoWithStorage[127.0.0.1:35721,DS-89dc9593-f507-45f9-8040-53da33f06240,DISK], DatanodeInfoWithStorage[127.0.0.1:45710,DS-214ab554-3412-4109-8007-7540d7dbfbf9,DISK], DatanodeInfoWithStorage[127.0.0.1:46131,DS-f1e9e282-3dcd-4709-9641-f01148c8ff1e,DISK], DatanodeInfoWithStorage[127.0.0.1:33224,DS-5b47aec7-f71b-498c-bd6e-0e6bbf396125,DISK], DatanodeInfoWithStorage[127.0.0.1:39426,DS-4a8315a5-2ace-452e-8102-f47c9065943a,DISK], DatanodeInfoWithStorage[127.0.0.1:35188,DS-44a78545-80f1-45e7-acf2-72f838c1bddd,DISK], DatanodeInfoWithStorage[127.0.0.1:38947,DS-4db15055-2e28-41c4-b47e-c857acf6b7d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-283077952-172.17.0.21-1597578067926:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35716,DS-e122c407-09e8-485b-b8e2-3395c029901e,DISK], DatanodeInfoWithStorage[127.0.0.1:35721,DS-89dc9593-f507-45f9-8040-53da33f06240,DISK], DatanodeInfoWithStorage[127.0.0.1:45710,DS-214ab554-3412-4109-8007-7540d7dbfbf9,DISK], DatanodeInfoWithStorage[127.0.0.1:46131,DS-f1e9e282-3dcd-4709-9641-f01148c8ff1e,DISK], DatanodeInfoWithStorage[127.0.0.1:33224,DS-5b47aec7-f71b-498c-bd6e-0e6bbf396125,DISK], DatanodeInfoWithStorage[127.0.0.1:39426,DS-4a8315a5-2ace-452e-8102-f47c9065943a,DISK], DatanodeInfoWithStorage[127.0.0.1:35188,DS-44a78545-80f1-45e7-acf2-72f838c1bddd,DISK], DatanodeInfoWithStorage[127.0.0.1:38947,DS-4db15055-2e28-41c4-b47e-c857acf6b7d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-279593527-172.17.0.21-1597579209832:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38591,DS-71f56003-b73e-45be-8aea-3a774acda6e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44405,DS-7d0592b6-07e8-4886-8c25-6fe422521f16,DISK], DatanodeInfoWithStorage[127.0.0.1:42293,DS-5d857272-06fb-45ba-9bc0-3443db99b948,DISK], DatanodeInfoWithStorage[127.0.0.1:40403,DS-4c4670a4-6ce2-4325-b5a4-662357331a09,DISK], DatanodeInfoWithStorage[127.0.0.1:36803,DS-87ec2b97-fdaa-4732-b3a6-b3919f185ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:39230,DS-bbaaae83-66dc-4c63-9116-5917544e6b81,DISK], DatanodeInfoWithStorage[127.0.0.1:44301,DS-476d1d00-aa83-4877-b8e4-70f327c16ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:36187,DS-2d5313fc-d134-4115-be7d-350fee9f4ecd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-279593527-172.17.0.21-1597579209832:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38591,DS-71f56003-b73e-45be-8aea-3a774acda6e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44405,DS-7d0592b6-07e8-4886-8c25-6fe422521f16,DISK], DatanodeInfoWithStorage[127.0.0.1:42293,DS-5d857272-06fb-45ba-9bc0-3443db99b948,DISK], DatanodeInfoWithStorage[127.0.0.1:40403,DS-4c4670a4-6ce2-4325-b5a4-662357331a09,DISK], DatanodeInfoWithStorage[127.0.0.1:36803,DS-87ec2b97-fdaa-4732-b3a6-b3919f185ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:39230,DS-bbaaae83-66dc-4c63-9116-5917544e6b81,DISK], DatanodeInfoWithStorage[127.0.0.1:44301,DS-476d1d00-aa83-4877-b8e4-70f327c16ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:36187,DS-2d5313fc-d134-4115-be7d-350fee9f4ecd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-960472994-172.17.0.21-1597579593616:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34174,DS-a8625687-c091-4674-9f31-05187a8422ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46839,DS-57acca88-64f1-4c1f-bfae-d3d344ebb5d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46657,DS-ffc6ae77-2806-4ce7-b33f-d91858d536ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40654,DS-3c392297-afe9-46b4-8f5d-702453c349c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34040,DS-a3898668-2dfc-4c73-a75e-fb68786ef06d,DISK], DatanodeInfoWithStorage[127.0.0.1:43136,DS-6b06eac1-01a0-4db7-b465-eec657cbbf33,DISK], DatanodeInfoWithStorage[127.0.0.1:35520,DS-283d906a-fc63-4b54-9344-7696ac2af782,DISK], DatanodeInfoWithStorage[127.0.0.1:36383,DS-f9557d45-d52e-4b5d-8100-aa5aa4400e1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-960472994-172.17.0.21-1597579593616:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34174,DS-a8625687-c091-4674-9f31-05187a8422ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46839,DS-57acca88-64f1-4c1f-bfae-d3d344ebb5d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46657,DS-ffc6ae77-2806-4ce7-b33f-d91858d536ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40654,DS-3c392297-afe9-46b4-8f5d-702453c349c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34040,DS-a3898668-2dfc-4c73-a75e-fb68786ef06d,DISK], DatanodeInfoWithStorage[127.0.0.1:43136,DS-6b06eac1-01a0-4db7-b465-eec657cbbf33,DISK], DatanodeInfoWithStorage[127.0.0.1:35520,DS-283d906a-fc63-4b54-9344-7696ac2af782,DISK], DatanodeInfoWithStorage[127.0.0.1:36383,DS-f9557d45-d52e-4b5d-8100-aa5aa4400e1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-982039657-172.17.0.21-1597579681233:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34320,DS-c781e960-abe3-4c9a-838b-16c49c30857b,DISK], DatanodeInfoWithStorage[127.0.0.1:33782,DS-0af3b3fe-8d6c-4944-840f-0b21578d1590,DISK], DatanodeInfoWithStorage[127.0.0.1:39915,DS-18006190-9721-45f6-91fe-639fe0326a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39033,DS-58284fe5-32c3-4199-b267-4b43d3f4b28d,DISK], DatanodeInfoWithStorage[127.0.0.1:39114,DS-918b8e94-e3d7-4450-9175-5af770442271,DISK], DatanodeInfoWithStorage[127.0.0.1:37843,DS-65b5fa43-fa6e-41e2-9097-57fe69941ada,DISK], DatanodeInfoWithStorage[127.0.0.1:36194,DS-a7be8152-6ebc-4969-b0c8-2baa1fad7c55,DISK], DatanodeInfoWithStorage[127.0.0.1:36991,DS-b413b611-93e7-4a2a-a33a-a0447dd186ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-982039657-172.17.0.21-1597579681233:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34320,DS-c781e960-abe3-4c9a-838b-16c49c30857b,DISK], DatanodeInfoWithStorage[127.0.0.1:33782,DS-0af3b3fe-8d6c-4944-840f-0b21578d1590,DISK], DatanodeInfoWithStorage[127.0.0.1:39915,DS-18006190-9721-45f6-91fe-639fe0326a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39033,DS-58284fe5-32c3-4199-b267-4b43d3f4b28d,DISK], DatanodeInfoWithStorage[127.0.0.1:39114,DS-918b8e94-e3d7-4450-9175-5af770442271,DISK], DatanodeInfoWithStorage[127.0.0.1:37843,DS-65b5fa43-fa6e-41e2-9097-57fe69941ada,DISK], DatanodeInfoWithStorage[127.0.0.1:36194,DS-a7be8152-6ebc-4969-b0c8-2baa1fad7c55,DISK], DatanodeInfoWithStorage[127.0.0.1:36991,DS-b413b611-93e7-4a2a-a33a-a0447dd186ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-136321206-172.17.0.21-1597579715530:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42161,DS-5273031c-1f5e-4d7e-ba32-a498a1687027,DISK], DatanodeInfoWithStorage[127.0.0.1:37591,DS-0756e90d-8518-4ade-86f1-983aabc5f117,DISK], DatanodeInfoWithStorage[127.0.0.1:43165,DS-0b0f23a8-058c-40f7-bcc7-bf39b24f2de2,DISK], DatanodeInfoWithStorage[127.0.0.1:44796,DS-a4f0a293-75af-441e-a006-599f54be1446,DISK], DatanodeInfoWithStorage[127.0.0.1:40313,DS-24eec015-7992-4be0-a877-ab98073bf0fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35139,DS-c011db5d-bc47-4723-96e5-e8b26f31f7b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33348,DS-05a0b417-37cb-4889-b720-f7e7760f2aed,DISK], DatanodeInfoWithStorage[127.0.0.1:45675,DS-d192bdbc-3846-4fe0-8a6f-937901c2f121,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-136321206-172.17.0.21-1597579715530:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42161,DS-5273031c-1f5e-4d7e-ba32-a498a1687027,DISK], DatanodeInfoWithStorage[127.0.0.1:37591,DS-0756e90d-8518-4ade-86f1-983aabc5f117,DISK], DatanodeInfoWithStorage[127.0.0.1:43165,DS-0b0f23a8-058c-40f7-bcc7-bf39b24f2de2,DISK], DatanodeInfoWithStorage[127.0.0.1:44796,DS-a4f0a293-75af-441e-a006-599f54be1446,DISK], DatanodeInfoWithStorage[127.0.0.1:40313,DS-24eec015-7992-4be0-a877-ab98073bf0fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35139,DS-c011db5d-bc47-4723-96e5-e8b26f31f7b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33348,DS-05a0b417-37cb-4889-b720-f7e7760f2aed,DISK], DatanodeInfoWithStorage[127.0.0.1:45675,DS-d192bdbc-3846-4fe0-8a6f-937901c2f121,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1565825866-172.17.0.21-1597579853476:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43998,DS-5ae55a8a-7405-4dc9-b2d6-2a09f6e3cada,DISK], DatanodeInfoWithStorage[127.0.0.1:44097,DS-f94d650b-1c05-42cc-b2cd-1d6c969cec91,DISK], DatanodeInfoWithStorage[127.0.0.1:41364,DS-1d9f3508-f033-4e1b-a22c-fc6b48a1a5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43567,DS-2c8abe8b-f29f-426c-8fee-8f2c26201471,DISK], DatanodeInfoWithStorage[127.0.0.1:46259,DS-75eec0e9-db4a-45e3-882b-7bbb91edb84b,DISK], DatanodeInfoWithStorage[127.0.0.1:43525,DS-8b724c16-9c50-4d9c-b57e-9b5f88333eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:39630,DS-5bf3a003-f8d9-4250-9697-75fd062bfe43,DISK], DatanodeInfoWithStorage[127.0.0.1:41708,DS-c8bdb045-b449-459f-acb3-486afa59d66a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1565825866-172.17.0.21-1597579853476:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43998,DS-5ae55a8a-7405-4dc9-b2d6-2a09f6e3cada,DISK], DatanodeInfoWithStorage[127.0.0.1:44097,DS-f94d650b-1c05-42cc-b2cd-1d6c969cec91,DISK], DatanodeInfoWithStorage[127.0.0.1:41364,DS-1d9f3508-f033-4e1b-a22c-fc6b48a1a5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43567,DS-2c8abe8b-f29f-426c-8fee-8f2c26201471,DISK], DatanodeInfoWithStorage[127.0.0.1:46259,DS-75eec0e9-db4a-45e3-882b-7bbb91edb84b,DISK], DatanodeInfoWithStorage[127.0.0.1:43525,DS-8b724c16-9c50-4d9c-b57e-9b5f88333eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:39630,DS-5bf3a003-f8d9-4250-9697-75fd062bfe43,DISK], DatanodeInfoWithStorage[127.0.0.1:41708,DS-c8bdb045-b449-459f-acb3-486afa59d66a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2047072304-172.17.0.21-1597580022769:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45024,DS-8b6bf05f-73d9-4c3a-8e3f-aed4eb60f184,DISK], DatanodeInfoWithStorage[127.0.0.1:45627,DS-21692550-3499-4eb0-8ea2-ee1598b6f9a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42912,DS-446b4ae7-d446-45d9-86bb-0d691009ce2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37026,DS-c4df935b-5624-4b3b-abf3-b5c4bb2fed88,DISK], DatanodeInfoWithStorage[127.0.0.1:38192,DS-fae2de8d-799a-464e-a2af-039c89367e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:42525,DS-18321630-17ac-4a87-9ad8-28bd1ca73835,DISK], DatanodeInfoWithStorage[127.0.0.1:43088,DS-f2a0df3e-64e5-4a8a-b357-c2bc11cf2739,DISK], DatanodeInfoWithStorage[127.0.0.1:37642,DS-9b7d2c23-b994-4a95-8f4f-1af4abf1445b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2047072304-172.17.0.21-1597580022769:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45024,DS-8b6bf05f-73d9-4c3a-8e3f-aed4eb60f184,DISK], DatanodeInfoWithStorage[127.0.0.1:45627,DS-21692550-3499-4eb0-8ea2-ee1598b6f9a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42912,DS-446b4ae7-d446-45d9-86bb-0d691009ce2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37026,DS-c4df935b-5624-4b3b-abf3-b5c4bb2fed88,DISK], DatanodeInfoWithStorage[127.0.0.1:38192,DS-fae2de8d-799a-464e-a2af-039c89367e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:42525,DS-18321630-17ac-4a87-9ad8-28bd1ca73835,DISK], DatanodeInfoWithStorage[127.0.0.1:43088,DS-f2a0df3e-64e5-4a8a-b357-c2bc11cf2739,DISK], DatanodeInfoWithStorage[127.0.0.1:37642,DS-9b7d2c23-b994-4a95-8f4f-1af4abf1445b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1462670503-172.17.0.21-1597580091489:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41584,DS-b689ca94-c9f9-4587-99b5-1de286fb85f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40573,DS-e779f275-6aeb-4de1-8844-d3458b30584b,DISK], DatanodeInfoWithStorage[127.0.0.1:34501,DS-c0dadadd-84f8-4c37-b90b-21bc39cf87ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35668,DS-555939fd-cd11-4cd9-8d3f-226a7adcf42b,DISK], DatanodeInfoWithStorage[127.0.0.1:43349,DS-4914e0c1-1cfd-4d41-8cec-4ffa2005b7e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40897,DS-a68f887d-711c-4d8b-b402-e54e04e6570f,DISK], DatanodeInfoWithStorage[127.0.0.1:45948,DS-e32d8fa7-948a-4911-991e-6ca84444a579,DISK], DatanodeInfoWithStorage[127.0.0.1:37361,DS-c798748d-f0fa-4834-ad6e-c7c14d287dfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1462670503-172.17.0.21-1597580091489:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41584,DS-b689ca94-c9f9-4587-99b5-1de286fb85f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40573,DS-e779f275-6aeb-4de1-8844-d3458b30584b,DISK], DatanodeInfoWithStorage[127.0.0.1:34501,DS-c0dadadd-84f8-4c37-b90b-21bc39cf87ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35668,DS-555939fd-cd11-4cd9-8d3f-226a7adcf42b,DISK], DatanodeInfoWithStorage[127.0.0.1:43349,DS-4914e0c1-1cfd-4d41-8cec-4ffa2005b7e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40897,DS-a68f887d-711c-4d8b-b402-e54e04e6570f,DISK], DatanodeInfoWithStorage[127.0.0.1:45948,DS-e32d8fa7-948a-4911-991e-6ca84444a579,DISK], DatanodeInfoWithStorage[127.0.0.1:37361,DS-c798748d-f0fa-4834-ad6e-c7c14d287dfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2024600576-172.17.0.21-1597580212384:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38763,DS-11f6b8d3-116b-4e02-934e-87e18c16282e,DISK], DatanodeInfoWithStorage[127.0.0.1:37685,DS-d7c11d9f-99d1-4e25-a280-a6a01938ae95,DISK], DatanodeInfoWithStorage[127.0.0.1:39969,DS-06ff6ea3-4421-4627-98d2-f298175c6e47,DISK], DatanodeInfoWithStorage[127.0.0.1:42160,DS-2141752d-4502-41b1-9c9b-83e221d4028a,DISK], DatanodeInfoWithStorage[127.0.0.1:33755,DS-0ef66cc0-aea8-47e8-a7be-24f09b48b438,DISK], DatanodeInfoWithStorage[127.0.0.1:42908,DS-01e9c7bc-6c7a-41e6-914c-308dd7518a35,DISK], DatanodeInfoWithStorage[127.0.0.1:34151,DS-87537f8b-dddd-4b64-b5ef-d3bdb7613e99,DISK], DatanodeInfoWithStorage[127.0.0.1:34261,DS-e3ac5d17-70de-47ba-8ad7-0ba3a2c3b8b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2024600576-172.17.0.21-1597580212384:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38763,DS-11f6b8d3-116b-4e02-934e-87e18c16282e,DISK], DatanodeInfoWithStorage[127.0.0.1:37685,DS-d7c11d9f-99d1-4e25-a280-a6a01938ae95,DISK], DatanodeInfoWithStorage[127.0.0.1:39969,DS-06ff6ea3-4421-4627-98d2-f298175c6e47,DISK], DatanodeInfoWithStorage[127.0.0.1:42160,DS-2141752d-4502-41b1-9c9b-83e221d4028a,DISK], DatanodeInfoWithStorage[127.0.0.1:33755,DS-0ef66cc0-aea8-47e8-a7be-24f09b48b438,DISK], DatanodeInfoWithStorage[127.0.0.1:42908,DS-01e9c7bc-6c7a-41e6-914c-308dd7518a35,DISK], DatanodeInfoWithStorage[127.0.0.1:34151,DS-87537f8b-dddd-4b64-b5ef-d3bdb7613e99,DISK], DatanodeInfoWithStorage[127.0.0.1:34261,DS-e3ac5d17-70de-47ba-8ad7-0ba3a2c3b8b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-424206365-172.17.0.21-1597580302628:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39518,DS-7cab72aa-53cb-4841-9a85-4b7a5c19109e,DISK], DatanodeInfoWithStorage[127.0.0.1:41002,DS-1678c408-67c2-46ef-a89a-fd4eb0fffc56,DISK], DatanodeInfoWithStorage[127.0.0.1:36524,DS-0be5ca37-b92b-4ff8-b4b7-9c1b43555e58,DISK], DatanodeInfoWithStorage[127.0.0.1:43793,DS-27860b35-ff9b-42a9-b619-1ded7747ec31,DISK], DatanodeInfoWithStorage[127.0.0.1:40922,DS-dd72e168-7366-4e0c-92c8-8b8afb1236bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36676,DS-ba05e9f4-59a6-4594-b836-c9034fb2b76f,DISK], DatanodeInfoWithStorage[127.0.0.1:39857,DS-754b026c-56ad-4d33-9ba8-6bbe66c3f73a,DISK], DatanodeInfoWithStorage[127.0.0.1:41293,DS-147ea483-ac61-420e-8fb1-21a04b78bb22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-424206365-172.17.0.21-1597580302628:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39518,DS-7cab72aa-53cb-4841-9a85-4b7a5c19109e,DISK], DatanodeInfoWithStorage[127.0.0.1:41002,DS-1678c408-67c2-46ef-a89a-fd4eb0fffc56,DISK], DatanodeInfoWithStorage[127.0.0.1:36524,DS-0be5ca37-b92b-4ff8-b4b7-9c1b43555e58,DISK], DatanodeInfoWithStorage[127.0.0.1:43793,DS-27860b35-ff9b-42a9-b619-1ded7747ec31,DISK], DatanodeInfoWithStorage[127.0.0.1:40922,DS-dd72e168-7366-4e0c-92c8-8b8afb1236bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36676,DS-ba05e9f4-59a6-4594-b836-c9034fb2b76f,DISK], DatanodeInfoWithStorage[127.0.0.1:39857,DS-754b026c-56ad-4d33-9ba8-6bbe66c3f73a,DISK], DatanodeInfoWithStorage[127.0.0.1:41293,DS-147ea483-ac61-420e-8fb1-21a04b78bb22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1448460700-172.17.0.21-1597580337148:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46031,DS-20bb2db0-7fb5-43c5-a75b-8a581cac1aea,DISK], DatanodeInfoWithStorage[127.0.0.1:40763,DS-ef48a809-f4fb-4149-aa8d-a97bb4decbbc,DISK], DatanodeInfoWithStorage[127.0.0.1:41755,DS-346e6142-8f4e-472d-930a-bbac9c8b2e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:39041,DS-be055e43-2bd7-4953-a5f3-96304dd577e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39888,DS-1ba68a32-22e7-41a3-a15d-aee529216328,DISK], DatanodeInfoWithStorage[127.0.0.1:42202,DS-17b9839c-9e37-4833-96c4-87010693f1f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34129,DS-238af022-5d5b-4c26-a197-20ffe65d9a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37093,DS-d9884cf8-0774-4402-a5af-fdbbc01833d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1448460700-172.17.0.21-1597580337148:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46031,DS-20bb2db0-7fb5-43c5-a75b-8a581cac1aea,DISK], DatanodeInfoWithStorage[127.0.0.1:40763,DS-ef48a809-f4fb-4149-aa8d-a97bb4decbbc,DISK], DatanodeInfoWithStorage[127.0.0.1:41755,DS-346e6142-8f4e-472d-930a-bbac9c8b2e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:39041,DS-be055e43-2bd7-4953-a5f3-96304dd577e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39888,DS-1ba68a32-22e7-41a3-a15d-aee529216328,DISK], DatanodeInfoWithStorage[127.0.0.1:42202,DS-17b9839c-9e37-4833-96c4-87010693f1f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34129,DS-238af022-5d5b-4c26-a197-20ffe65d9a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37093,DS-d9884cf8-0774-4402-a5af-fdbbc01833d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1479092380-172.17.0.21-1597580423401:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40428,DS-77c780b6-1701-4e23-8879-8ef61c7176a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35962,DS-ea3b95a1-0d95-4697-a366-f502d7d73773,DISK], DatanodeInfoWithStorage[127.0.0.1:35817,DS-666b0b63-1f20-4b39-8c1d-85d602ef4850,DISK], DatanodeInfoWithStorage[127.0.0.1:33827,DS-368f135b-9bd8-4b05-bcc7-c7c62ac4ae84,DISK], DatanodeInfoWithStorage[127.0.0.1:45650,DS-73f1e050-8aba-45fc-a52a-8e592ff81df0,DISK], DatanodeInfoWithStorage[127.0.0.1:37813,DS-370de577-e386-4a2a-9f31-82e035a7f686,DISK], DatanodeInfoWithStorage[127.0.0.1:41887,DS-98fa7065-babe-4f00-92a5-2c6f4ddff193,DISK], DatanodeInfoWithStorage[127.0.0.1:41397,DS-129e34f2-4551-42f5-8168-984e891ba949,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1479092380-172.17.0.21-1597580423401:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40428,DS-77c780b6-1701-4e23-8879-8ef61c7176a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35962,DS-ea3b95a1-0d95-4697-a366-f502d7d73773,DISK], DatanodeInfoWithStorage[127.0.0.1:35817,DS-666b0b63-1f20-4b39-8c1d-85d602ef4850,DISK], DatanodeInfoWithStorage[127.0.0.1:33827,DS-368f135b-9bd8-4b05-bcc7-c7c62ac4ae84,DISK], DatanodeInfoWithStorage[127.0.0.1:45650,DS-73f1e050-8aba-45fc-a52a-8e592ff81df0,DISK], DatanodeInfoWithStorage[127.0.0.1:37813,DS-370de577-e386-4a2a-9f31-82e035a7f686,DISK], DatanodeInfoWithStorage[127.0.0.1:41887,DS-98fa7065-babe-4f00-92a5-2c6f4ddff193,DISK], DatanodeInfoWithStorage[127.0.0.1:41397,DS-129e34f2-4551-42f5-8168-984e891ba949,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-3439012-172.17.0.21-1597580492544:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39527,DS-40d25362-3541-4cf4-b524-3cafa80ba3d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44508,DS-0ca66d21-c826-418c-bf45-800dd88986c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38792,DS-18d2fce5-b1be-491d-8034-89d6a3561405,DISK], DatanodeInfoWithStorage[127.0.0.1:40058,DS-02eb0d11-8273-4226-89f2-7f2c73a39212,DISK], DatanodeInfoWithStorage[127.0.0.1:34690,DS-990cfd3c-51a3-4972-b347-ac7326bd5759,DISK], DatanodeInfoWithStorage[127.0.0.1:35461,DS-31bb2184-2dd4-449f-ae90-7920ce315615,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-e1d0ad69-a93e-44c6-9aab-a30f82afb10e,DISK], DatanodeInfoWithStorage[127.0.0.1:44037,DS-ee950a75-e32c-44fe-ab6d-1e351d85e10f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-3439012-172.17.0.21-1597580492544:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39527,DS-40d25362-3541-4cf4-b524-3cafa80ba3d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44508,DS-0ca66d21-c826-418c-bf45-800dd88986c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38792,DS-18d2fce5-b1be-491d-8034-89d6a3561405,DISK], DatanodeInfoWithStorage[127.0.0.1:40058,DS-02eb0d11-8273-4226-89f2-7f2c73a39212,DISK], DatanodeInfoWithStorage[127.0.0.1:34690,DS-990cfd3c-51a3-4972-b347-ac7326bd5759,DISK], DatanodeInfoWithStorage[127.0.0.1:35461,DS-31bb2184-2dd4-449f-ae90-7920ce315615,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-e1d0ad69-a93e-44c6-9aab-a30f82afb10e,DISK], DatanodeInfoWithStorage[127.0.0.1:44037,DS-ee950a75-e32c-44fe-ab6d-1e351d85e10f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1789352428-172.17.0.21-1597580628185:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43676,DS-2003c383-6c0a-4f50-a2bd-788107008b03,DISK], DatanodeInfoWithStorage[127.0.0.1:33334,DS-ede1b37d-a519-4a12-a6e4-d7b9bb387928,DISK], DatanodeInfoWithStorage[127.0.0.1:35508,DS-09a47b42-0014-47a3-aaef-a1d87a61fb9c,DISK], DatanodeInfoWithStorage[127.0.0.1:34427,DS-dfb603db-e9a9-47ce-bc8e-3f4afd8065a9,DISK], DatanodeInfoWithStorage[127.0.0.1:32815,DS-247ea553-4b63-423d-8888-58e55502ba99,DISK], DatanodeInfoWithStorage[127.0.0.1:39776,DS-732678a3-3dec-456e-9b74-8f0ce89a08c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35279,DS-c2008d80-80a2-4108-9bcc-928f7fa7bdce,DISK], DatanodeInfoWithStorage[127.0.0.1:34166,DS-70c428d7-ba42-4f79-b294-1d53fd91dc5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1789352428-172.17.0.21-1597580628185:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43676,DS-2003c383-6c0a-4f50-a2bd-788107008b03,DISK], DatanodeInfoWithStorage[127.0.0.1:33334,DS-ede1b37d-a519-4a12-a6e4-d7b9bb387928,DISK], DatanodeInfoWithStorage[127.0.0.1:35508,DS-09a47b42-0014-47a3-aaef-a1d87a61fb9c,DISK], DatanodeInfoWithStorage[127.0.0.1:34427,DS-dfb603db-e9a9-47ce-bc8e-3f4afd8065a9,DISK], DatanodeInfoWithStorage[127.0.0.1:32815,DS-247ea553-4b63-423d-8888-58e55502ba99,DISK], DatanodeInfoWithStorage[127.0.0.1:39776,DS-732678a3-3dec-456e-9b74-8f0ce89a08c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35279,DS-c2008d80-80a2-4108-9bcc-928f7fa7bdce,DISK], DatanodeInfoWithStorage[127.0.0.1:34166,DS-70c428d7-ba42-4f79-b294-1d53fd91dc5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-638722410-172.17.0.21-1597581003350:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36726,DS-f8681db0-16ef-4c3b-8d13-f840418cf888,DISK], DatanodeInfoWithStorage[127.0.0.1:43461,DS-46c2f4df-3522-49fe-9e21-1a3bdb83c7f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38379,DS-da481f79-a83c-4ffe-9c24-0e959046e291,DISK], DatanodeInfoWithStorage[127.0.0.1:39722,DS-00368360-f3ea-4603-b533-3b7b8106fb6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39105,DS-3d3de236-9ea7-4683-9771-323bb38000d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42793,DS-f5eec9bd-94ae-449d-8661-0f6148b31f81,DISK], DatanodeInfoWithStorage[127.0.0.1:36383,DS-6c018879-190e-415b-a658-924fb9b1d81f,DISK], DatanodeInfoWithStorage[127.0.0.1:41186,DS-8839a7b4-6532-41eb-938d-2e3b25a8ef30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-638722410-172.17.0.21-1597581003350:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36726,DS-f8681db0-16ef-4c3b-8d13-f840418cf888,DISK], DatanodeInfoWithStorage[127.0.0.1:43461,DS-46c2f4df-3522-49fe-9e21-1a3bdb83c7f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38379,DS-da481f79-a83c-4ffe-9c24-0e959046e291,DISK], DatanodeInfoWithStorage[127.0.0.1:39722,DS-00368360-f3ea-4603-b533-3b7b8106fb6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39105,DS-3d3de236-9ea7-4683-9771-323bb38000d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42793,DS-f5eec9bd-94ae-449d-8661-0f6148b31f81,DISK], DatanodeInfoWithStorage[127.0.0.1:36383,DS-6c018879-190e-415b-a658-924fb9b1d81f,DISK], DatanodeInfoWithStorage[127.0.0.1:41186,DS-8839a7b4-6532-41eb-938d-2e3b25a8ef30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 3865
