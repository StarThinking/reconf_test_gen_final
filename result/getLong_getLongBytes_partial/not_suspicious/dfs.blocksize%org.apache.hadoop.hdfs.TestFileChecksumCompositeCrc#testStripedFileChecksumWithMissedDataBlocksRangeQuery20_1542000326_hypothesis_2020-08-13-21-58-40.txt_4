reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 536870912
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 536870912
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-434919639-172.17.0.3-1597356121242:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36926,DS-755b9f98-65ee-4397-aeb5-17929d50f72e,DISK], DatanodeInfoWithStorage[127.0.0.1:41828,DS-7a9d089c-1d9b-41d0-a527-f7cb1bf6c85d,DISK], DatanodeInfoWithStorage[127.0.0.1:39947,DS-31413e5b-dd2c-4f74-a1c4-5cb8913a77eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41198,DS-9a3c2ee2-253c-4511-8c12-288b3b38b04b,DISK], DatanodeInfoWithStorage[127.0.0.1:40667,DS-93b8d5c3-4169-4206-a120-31c24a9f5b32,DISK], DatanodeInfoWithStorage[127.0.0.1:43764,DS-7b7d5968-ba22-4bb6-8148-ae2cfc766dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:42132,DS-51ac5cdf-96a6-465d-9f05-344832dbbba6,DISK], DatanodeInfoWithStorage[127.0.0.1:42985,DS-24ad2064-12b7-42cb-9c43-240085afd2b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-434919639-172.17.0.3-1597356121242:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36926,DS-755b9f98-65ee-4397-aeb5-17929d50f72e,DISK], DatanodeInfoWithStorage[127.0.0.1:41828,DS-7a9d089c-1d9b-41d0-a527-f7cb1bf6c85d,DISK], DatanodeInfoWithStorage[127.0.0.1:39947,DS-31413e5b-dd2c-4f74-a1c4-5cb8913a77eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41198,DS-9a3c2ee2-253c-4511-8c12-288b3b38b04b,DISK], DatanodeInfoWithStorage[127.0.0.1:40667,DS-93b8d5c3-4169-4206-a120-31c24a9f5b32,DISK], DatanodeInfoWithStorage[127.0.0.1:43764,DS-7b7d5968-ba22-4bb6-8148-ae2cfc766dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:42132,DS-51ac5cdf-96a6-465d-9f05-344832dbbba6,DISK], DatanodeInfoWithStorage[127.0.0.1:42985,DS-24ad2064-12b7-42cb-9c43-240085afd2b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 536870912
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1564978934-172.17.0.3-1597356250543:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43050,DS-b7188037-c041-4c8c-9ae9-c6b2fb184107,DISK], DatanodeInfoWithStorage[127.0.0.1:46383,DS-475c6046-56af-4bd9-b872-61252901f49e,DISK], DatanodeInfoWithStorage[127.0.0.1:46625,DS-1ea55ca5-4070-4aaf-a370-899a5659da0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45923,DS-531c6603-ca5b-4d54-bd18-8501f5d39e94,DISK], DatanodeInfoWithStorage[127.0.0.1:35075,DS-1a2b351d-3c5f-4aec-98fb-07c4abc2caf6,DISK], DatanodeInfoWithStorage[127.0.0.1:34448,DS-b6681642-e14b-44bd-9499-37160c34559c,DISK], DatanodeInfoWithStorage[127.0.0.1:37520,DS-e45c8677-ab84-473a-a792-e5c7cd25b028,DISK], DatanodeInfoWithStorage[127.0.0.1:39329,DS-0fca967c-63e4-491c-a6f4-128420627d73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1564978934-172.17.0.3-1597356250543:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43050,DS-b7188037-c041-4c8c-9ae9-c6b2fb184107,DISK], DatanodeInfoWithStorage[127.0.0.1:46383,DS-475c6046-56af-4bd9-b872-61252901f49e,DISK], DatanodeInfoWithStorage[127.0.0.1:46625,DS-1ea55ca5-4070-4aaf-a370-899a5659da0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45923,DS-531c6603-ca5b-4d54-bd18-8501f5d39e94,DISK], DatanodeInfoWithStorage[127.0.0.1:35075,DS-1a2b351d-3c5f-4aec-98fb-07c4abc2caf6,DISK], DatanodeInfoWithStorage[127.0.0.1:34448,DS-b6681642-e14b-44bd-9499-37160c34559c,DISK], DatanodeInfoWithStorage[127.0.0.1:37520,DS-e45c8677-ab84-473a-a792-e5c7cd25b028,DISK], DatanodeInfoWithStorage[127.0.0.1:39329,DS-0fca967c-63e4-491c-a6f4-128420627d73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 536870912
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1159508132-172.17.0.3-1597356290049:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42156,DS-4efb5d82-486b-4c92-95d6-93914eee04b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43262,DS-385d6adb-6850-42c6-a3d8-273ada916019,DISK], DatanodeInfoWithStorage[127.0.0.1:39199,DS-f0f3a3c5-541f-4a3d-918f-a8ca921cadfa,DISK], DatanodeInfoWithStorage[127.0.0.1:36643,DS-381d8330-1bd9-4081-9047-60280ec219b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40326,DS-60a6f95c-8690-4545-9182-f5143a57f9b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40206,DS-2fdb9181-890d-40aa-9244-b2bb20bb3d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:46832,DS-7b4c2eaa-c7d1-44d6-86a5-44d739954d29,DISK], DatanodeInfoWithStorage[127.0.0.1:44507,DS-f162e620-03d1-4a5c-8f78-d6d71cda1126,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1159508132-172.17.0.3-1597356290049:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42156,DS-4efb5d82-486b-4c92-95d6-93914eee04b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43262,DS-385d6adb-6850-42c6-a3d8-273ada916019,DISK], DatanodeInfoWithStorage[127.0.0.1:39199,DS-f0f3a3c5-541f-4a3d-918f-a8ca921cadfa,DISK], DatanodeInfoWithStorage[127.0.0.1:36643,DS-381d8330-1bd9-4081-9047-60280ec219b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40326,DS-60a6f95c-8690-4545-9182-f5143a57f9b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40206,DS-2fdb9181-890d-40aa-9244-b2bb20bb3d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:46832,DS-7b4c2eaa-c7d1-44d6-86a5-44d739954d29,DISK], DatanodeInfoWithStorage[127.0.0.1:44507,DS-f162e620-03d1-4a5c-8f78-d6d71cda1126,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 536870912
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1361434373-172.17.0.3-1597356464748:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38878,DS-78241740-dc1d-421e-84ff-7067c08b33e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34687,DS-b8508269-0cd3-4787-991a-ce95e0918c70,DISK], DatanodeInfoWithStorage[127.0.0.1:33438,DS-bf4d8d96-3580-4547-9c5c-d777c6a075de,DISK], DatanodeInfoWithStorage[127.0.0.1:44221,DS-7540082c-62b1-479f-9d91-2349df423391,DISK], DatanodeInfoWithStorage[127.0.0.1:32793,DS-65531291-ad07-4867-9f78-bb985c44016c,DISK], DatanodeInfoWithStorage[127.0.0.1:42741,DS-f2b6b8c7-d782-4820-938c-38ea69c2d06e,DISK], DatanodeInfoWithStorage[127.0.0.1:39863,DS-91e6b6ed-4f9f-4cc9-bff6-27a8e0bdbe1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35970,DS-67e81c45-f76f-4c0c-a13b-cae078818ef7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1361434373-172.17.0.3-1597356464748:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38878,DS-78241740-dc1d-421e-84ff-7067c08b33e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34687,DS-b8508269-0cd3-4787-991a-ce95e0918c70,DISK], DatanodeInfoWithStorage[127.0.0.1:33438,DS-bf4d8d96-3580-4547-9c5c-d777c6a075de,DISK], DatanodeInfoWithStorage[127.0.0.1:44221,DS-7540082c-62b1-479f-9d91-2349df423391,DISK], DatanodeInfoWithStorage[127.0.0.1:32793,DS-65531291-ad07-4867-9f78-bb985c44016c,DISK], DatanodeInfoWithStorage[127.0.0.1:42741,DS-f2b6b8c7-d782-4820-938c-38ea69c2d06e,DISK], DatanodeInfoWithStorage[127.0.0.1:39863,DS-91e6b6ed-4f9f-4cc9-bff6-27a8e0bdbe1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35970,DS-67e81c45-f76f-4c0c-a13b-cae078818ef7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 536870912
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1590810992-172.17.0.3-1597356672351:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41278,DS-99bd178c-3624-458f-a820-87fa4b9309a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44511,DS-e49d5afa-0912-4b65-adf3-01b4fd256600,DISK], DatanodeInfoWithStorage[127.0.0.1:36411,DS-fb7d9b30-5777-4f23-adc1-f005c1657a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41985,DS-6ba449dd-9c36-436e-9430-3deee67d4a72,DISK], DatanodeInfoWithStorage[127.0.0.1:34042,DS-ede980a3-2112-4f21-98eb-2009494ecbb1,DISK], DatanodeInfoWithStorage[127.0.0.1:39976,DS-7e46dd30-a0b8-43a9-acee-1dcf43acae3b,DISK], DatanodeInfoWithStorage[127.0.0.1:42944,DS-b4c8189d-e294-4f15-ad94-c96f3527e289,DISK], DatanodeInfoWithStorage[127.0.0.1:34857,DS-594b08b4-0f91-4b06-bc50-587126dac900,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1590810992-172.17.0.3-1597356672351:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41278,DS-99bd178c-3624-458f-a820-87fa4b9309a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44511,DS-e49d5afa-0912-4b65-adf3-01b4fd256600,DISK], DatanodeInfoWithStorage[127.0.0.1:36411,DS-fb7d9b30-5777-4f23-adc1-f005c1657a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41985,DS-6ba449dd-9c36-436e-9430-3deee67d4a72,DISK], DatanodeInfoWithStorage[127.0.0.1:34042,DS-ede980a3-2112-4f21-98eb-2009494ecbb1,DISK], DatanodeInfoWithStorage[127.0.0.1:39976,DS-7e46dd30-a0b8-43a9-acee-1dcf43acae3b,DISK], DatanodeInfoWithStorage[127.0.0.1:42944,DS-b4c8189d-e294-4f15-ad94-c96f3527e289,DISK], DatanodeInfoWithStorage[127.0.0.1:34857,DS-594b08b4-0f91-4b06-bc50-587126dac900,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 536870912
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-406573760-172.17.0.3-1597357539848:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38006,DS-417dc67b-0882-4632-b574-24c976ffca3a,DISK], DatanodeInfoWithStorage[127.0.0.1:43163,DS-b402e37a-eaf7-4c67-b04c-10b128e6b0ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38076,DS-8085dc85-18b4-4a82-addf-ed3870e3d951,DISK], DatanodeInfoWithStorage[127.0.0.1:42613,DS-221e4559-62fe-4a3e-b190-d05dbd52ad99,DISK], DatanodeInfoWithStorage[127.0.0.1:37787,DS-e94ccec8-0be0-4275-aebe-f8723b79b67b,DISK], DatanodeInfoWithStorage[127.0.0.1:46028,DS-f616e7dd-b12a-4068-9344-7e7007a53862,DISK], DatanodeInfoWithStorage[127.0.0.1:34232,DS-07459e12-1b41-4fcc-b8e8-58ec70ec30f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37351,DS-d88aba21-d220-4b7a-9b1a-c0c5056c28f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-406573760-172.17.0.3-1597357539848:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38006,DS-417dc67b-0882-4632-b574-24c976ffca3a,DISK], DatanodeInfoWithStorage[127.0.0.1:43163,DS-b402e37a-eaf7-4c67-b04c-10b128e6b0ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38076,DS-8085dc85-18b4-4a82-addf-ed3870e3d951,DISK], DatanodeInfoWithStorage[127.0.0.1:42613,DS-221e4559-62fe-4a3e-b190-d05dbd52ad99,DISK], DatanodeInfoWithStorage[127.0.0.1:37787,DS-e94ccec8-0be0-4275-aebe-f8723b79b67b,DISK], DatanodeInfoWithStorage[127.0.0.1:46028,DS-f616e7dd-b12a-4068-9344-7e7007a53862,DISK], DatanodeInfoWithStorage[127.0.0.1:34232,DS-07459e12-1b41-4fcc-b8e8-58ec70ec30f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37351,DS-d88aba21-d220-4b7a-9b1a-c0c5056c28f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 536870912
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1451519103-172.17.0.3-1597357577336:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37007,DS-afdf86be-f0ee-4ded-a109-7b12d9ba8fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:44120,DS-67de92c6-111c-407b-a35f-b4e5997a95a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37850,DS-0a1b0a55-8aca-44cf-ae8a-c35bf49f0a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39360,DS-27251426-ca65-407c-a3dc-e3a68bdcf690,DISK], DatanodeInfoWithStorage[127.0.0.1:44121,DS-d940e567-4f19-46e7-877e-0eba3fa5a905,DISK], DatanodeInfoWithStorage[127.0.0.1:41492,DS-d875e2e8-c893-4354-90bb-5f008542d89d,DISK], DatanodeInfoWithStorage[127.0.0.1:39930,DS-f9ea4c4c-eb8f-4ec0-bec3-0f8153c39c89,DISK], DatanodeInfoWithStorage[127.0.0.1:34323,DS-185717a1-5e68-4fff-bf7b-02948a5acfb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1451519103-172.17.0.3-1597357577336:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37007,DS-afdf86be-f0ee-4ded-a109-7b12d9ba8fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:44120,DS-67de92c6-111c-407b-a35f-b4e5997a95a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37850,DS-0a1b0a55-8aca-44cf-ae8a-c35bf49f0a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39360,DS-27251426-ca65-407c-a3dc-e3a68bdcf690,DISK], DatanodeInfoWithStorage[127.0.0.1:44121,DS-d940e567-4f19-46e7-877e-0eba3fa5a905,DISK], DatanodeInfoWithStorage[127.0.0.1:41492,DS-d875e2e8-c893-4354-90bb-5f008542d89d,DISK], DatanodeInfoWithStorage[127.0.0.1:39930,DS-f9ea4c4c-eb8f-4ec0-bec3-0f8153c39c89,DISK], DatanodeInfoWithStorage[127.0.0.1:34323,DS-185717a1-5e68-4fff-bf7b-02948a5acfb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 536870912
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-636703040-172.17.0.3-1597357613944:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45933,DS-046bb1ee-3924-4250-bd90-6ffbfc0945c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46752,DS-95a85ad7-0cec-45c6-aaae-dda6c5d33382,DISK], DatanodeInfoWithStorage[127.0.0.1:46829,DS-5efe1ca4-a5fb-4944-8411-f21c3f5d0a27,DISK], DatanodeInfoWithStorage[127.0.0.1:34103,DS-48462deb-6e36-48f4-ac6b-3a088738260f,DISK], DatanodeInfoWithStorage[127.0.0.1:36962,DS-fd49c310-9d03-4fbc-af7d-d71c902fa3f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37455,DS-7dc5882e-c8e6-4619-945e-f0bc8f311003,DISK], DatanodeInfoWithStorage[127.0.0.1:38402,DS-76083786-a28a-4b44-9ded-d6828831f874,DISK], DatanodeInfoWithStorage[127.0.0.1:34846,DS-2fad994b-965d-4525-9ece-9b03467f71e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-636703040-172.17.0.3-1597357613944:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45933,DS-046bb1ee-3924-4250-bd90-6ffbfc0945c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46752,DS-95a85ad7-0cec-45c6-aaae-dda6c5d33382,DISK], DatanodeInfoWithStorage[127.0.0.1:46829,DS-5efe1ca4-a5fb-4944-8411-f21c3f5d0a27,DISK], DatanodeInfoWithStorage[127.0.0.1:34103,DS-48462deb-6e36-48f4-ac6b-3a088738260f,DISK], DatanodeInfoWithStorage[127.0.0.1:36962,DS-fd49c310-9d03-4fbc-af7d-d71c902fa3f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37455,DS-7dc5882e-c8e6-4619-945e-f0bc8f311003,DISK], DatanodeInfoWithStorage[127.0.0.1:38402,DS-76083786-a28a-4b44-9ded-d6828831f874,DISK], DatanodeInfoWithStorage[127.0.0.1:34846,DS-2fad994b-965d-4525-9ece-9b03467f71e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 536870912
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2140094646-172.17.0.3-1597357646302:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43981,DS-fc9b9d7d-f535-4bdd-b82d-8bcce98b5305,DISK], DatanodeInfoWithStorage[127.0.0.1:37106,DS-e7628820-feb9-4f4b-ba6d-43773db25a36,DISK], DatanodeInfoWithStorage[127.0.0.1:38407,DS-8485bc7c-66a8-41ea-a225-1c5d0f6ecf2d,DISK], DatanodeInfoWithStorage[127.0.0.1:38226,DS-32161477-af40-43fc-9965-81eb8bb10efa,DISK], DatanodeInfoWithStorage[127.0.0.1:38384,DS-1d30603e-778b-48bf-99aa-b4bd9a18d432,DISK], DatanodeInfoWithStorage[127.0.0.1:41059,DS-a81a1cc8-2359-47dd-b3b3-d0b73c47b502,DISK], DatanodeInfoWithStorage[127.0.0.1:40241,DS-a4d90abc-dd2d-4830-9278-1f90cdd32d72,DISK], DatanodeInfoWithStorage[127.0.0.1:41136,DS-3caffa9c-b2ad-41c9-9c1c-494df77b8b05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2140094646-172.17.0.3-1597357646302:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43981,DS-fc9b9d7d-f535-4bdd-b82d-8bcce98b5305,DISK], DatanodeInfoWithStorage[127.0.0.1:37106,DS-e7628820-feb9-4f4b-ba6d-43773db25a36,DISK], DatanodeInfoWithStorage[127.0.0.1:38407,DS-8485bc7c-66a8-41ea-a225-1c5d0f6ecf2d,DISK], DatanodeInfoWithStorage[127.0.0.1:38226,DS-32161477-af40-43fc-9965-81eb8bb10efa,DISK], DatanodeInfoWithStorage[127.0.0.1:38384,DS-1d30603e-778b-48bf-99aa-b4bd9a18d432,DISK], DatanodeInfoWithStorage[127.0.0.1:41059,DS-a81a1cc8-2359-47dd-b3b3-d0b73c47b502,DISK], DatanodeInfoWithStorage[127.0.0.1:40241,DS-a4d90abc-dd2d-4830-9278-1f90cdd32d72,DISK], DatanodeInfoWithStorage[127.0.0.1:41136,DS-3caffa9c-b2ad-41c9-9c1c-494df77b8b05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 536870912
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1592383769-172.17.0.3-1597357959087:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35964,DS-732a55cb-b91b-41de-80b3-1ff239d89962,DISK], DatanodeInfoWithStorage[127.0.0.1:34353,DS-3558bfcf-c4bb-49ab-a659-ce19e33bce93,DISK], DatanodeInfoWithStorage[127.0.0.1:42813,DS-af9a2d63-5c2f-40c7-b93e-d208f7df6301,DISK], DatanodeInfoWithStorage[127.0.0.1:39402,DS-f4676080-92da-4a0f-b35c-477f9cb38b68,DISK], DatanodeInfoWithStorage[127.0.0.1:36124,DS-cb41813b-9ba2-4893-97af-6cd98e649b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:35344,DS-2fbe0fa0-266e-4916-93de-c1d264cfd8a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40224,DS-ce2da479-388d-4a43-8a51-8d8acff7ad3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41267,DS-ce091668-ca04-46b1-a2c0-44ce848714ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1592383769-172.17.0.3-1597357959087:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35964,DS-732a55cb-b91b-41de-80b3-1ff239d89962,DISK], DatanodeInfoWithStorage[127.0.0.1:34353,DS-3558bfcf-c4bb-49ab-a659-ce19e33bce93,DISK], DatanodeInfoWithStorage[127.0.0.1:42813,DS-af9a2d63-5c2f-40c7-b93e-d208f7df6301,DISK], DatanodeInfoWithStorage[127.0.0.1:39402,DS-f4676080-92da-4a0f-b35c-477f9cb38b68,DISK], DatanodeInfoWithStorage[127.0.0.1:36124,DS-cb41813b-9ba2-4893-97af-6cd98e649b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:35344,DS-2fbe0fa0-266e-4916-93de-c1d264cfd8a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40224,DS-ce2da479-388d-4a43-8a51-8d8acff7ad3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41267,DS-ce091668-ca04-46b1-a2c0-44ce848714ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 536870912
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2123841608-172.17.0.3-1597358028630:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33982,DS-f5397c59-b083-4e77-8d6f-44becded33ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40241,DS-a05bb10e-c3e6-4559-9cf8-c5149e5ce557,DISK], DatanodeInfoWithStorage[127.0.0.1:39099,DS-debff7a3-0662-424f-8f4a-31fb4649e399,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-9c4e73ed-f089-4e62-b5ea-e32946e40194,DISK], DatanodeInfoWithStorage[127.0.0.1:42409,DS-4083aac9-1099-4b90-8997-094e76c9fb57,DISK], DatanodeInfoWithStorage[127.0.0.1:43425,DS-a4474f54-76ea-4499-91f7-c26b66a317f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42062,DS-75e2ae72-53bc-43b3-97c8-25dba97c5535,DISK], DatanodeInfoWithStorage[127.0.0.1:42593,DS-79811c3f-8eb0-4811-b2b9-f6e168678e1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2123841608-172.17.0.3-1597358028630:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33982,DS-f5397c59-b083-4e77-8d6f-44becded33ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40241,DS-a05bb10e-c3e6-4559-9cf8-c5149e5ce557,DISK], DatanodeInfoWithStorage[127.0.0.1:39099,DS-debff7a3-0662-424f-8f4a-31fb4649e399,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-9c4e73ed-f089-4e62-b5ea-e32946e40194,DISK], DatanodeInfoWithStorage[127.0.0.1:42409,DS-4083aac9-1099-4b90-8997-094e76c9fb57,DISK], DatanodeInfoWithStorage[127.0.0.1:43425,DS-a4474f54-76ea-4499-91f7-c26b66a317f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42062,DS-75e2ae72-53bc-43b3-97c8-25dba97c5535,DISK], DatanodeInfoWithStorage[127.0.0.1:42593,DS-79811c3f-8eb0-4811-b2b9-f6e168678e1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 536870912
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1963629424-172.17.0.3-1597358188162:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35292,DS-3fd6a8b3-746b-442b-97fd-9ead4ccecf68,DISK], DatanodeInfoWithStorage[127.0.0.1:40375,DS-5061b38e-ee80-4e2e-ab45-b516bfb751b8,DISK], DatanodeInfoWithStorage[127.0.0.1:32889,DS-7d95f677-abdb-4263-bc5a-52f36622118a,DISK], DatanodeInfoWithStorage[127.0.0.1:46092,DS-efe71bc3-71ca-4e82-a560-7dc879102b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:41383,DS-239d2045-e45d-4336-bef3-21d190f56b05,DISK], DatanodeInfoWithStorage[127.0.0.1:36497,DS-e1f7e181-f5bb-4775-b1e1-0dc4d31793d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39096,DS-786cf766-9589-42bb-ab97-1a7843742dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:45968,DS-d4445c6e-8f11-446f-8c12-d73af5112e7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1963629424-172.17.0.3-1597358188162:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35292,DS-3fd6a8b3-746b-442b-97fd-9ead4ccecf68,DISK], DatanodeInfoWithStorage[127.0.0.1:40375,DS-5061b38e-ee80-4e2e-ab45-b516bfb751b8,DISK], DatanodeInfoWithStorage[127.0.0.1:32889,DS-7d95f677-abdb-4263-bc5a-52f36622118a,DISK], DatanodeInfoWithStorage[127.0.0.1:46092,DS-efe71bc3-71ca-4e82-a560-7dc879102b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:41383,DS-239d2045-e45d-4336-bef3-21d190f56b05,DISK], DatanodeInfoWithStorage[127.0.0.1:36497,DS-e1f7e181-f5bb-4775-b1e1-0dc4d31793d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39096,DS-786cf766-9589-42bb-ab97-1a7843742dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:45968,DS-d4445c6e-8f11-446f-8c12-d73af5112e7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 536870912
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2048372529-172.17.0.3-1597359428954:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41744,DS-cf3dd721-da27-4178-a6d5-27565841eeb0,DISK], DatanodeInfoWithStorage[127.0.0.1:38055,DS-c06c729e-8a26-4917-a1ea-e38f41d69b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:46153,DS-1f66929e-48ea-4230-b9f0-cdb8c3d4ae44,DISK], DatanodeInfoWithStorage[127.0.0.1:35005,DS-0e5680b0-d453-48e0-b249-e3c6d51a2206,DISK], DatanodeInfoWithStorage[127.0.0.1:40028,DS-fe885937-44fd-40d9-bfb9-1196662e00cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37537,DS-37cd25a7-11e7-4650-805d-c9ce12b1cd44,DISK], DatanodeInfoWithStorage[127.0.0.1:39127,DS-2b311fe2-77c3-4b43-81ba-e3b0f35fcce5,DISK], DatanodeInfoWithStorage[127.0.0.1:34408,DS-a3f5228d-7cd2-4a9a-999f-982348f36015,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2048372529-172.17.0.3-1597359428954:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41744,DS-cf3dd721-da27-4178-a6d5-27565841eeb0,DISK], DatanodeInfoWithStorage[127.0.0.1:38055,DS-c06c729e-8a26-4917-a1ea-e38f41d69b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:46153,DS-1f66929e-48ea-4230-b9f0-cdb8c3d4ae44,DISK], DatanodeInfoWithStorage[127.0.0.1:35005,DS-0e5680b0-d453-48e0-b249-e3c6d51a2206,DISK], DatanodeInfoWithStorage[127.0.0.1:40028,DS-fe885937-44fd-40d9-bfb9-1196662e00cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37537,DS-37cd25a7-11e7-4650-805d-c9ce12b1cd44,DISK], DatanodeInfoWithStorage[127.0.0.1:39127,DS-2b311fe2-77c3-4b43-81ba-e3b0f35fcce5,DISK], DatanodeInfoWithStorage[127.0.0.1:34408,DS-a3f5228d-7cd2-4a9a-999f-982348f36015,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 536870912
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1832896690-172.17.0.3-1597359845506:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38680,DS-87d3ac58-099a-4943-8991-ab3ca7641fba,DISK], DatanodeInfoWithStorage[127.0.0.1:40045,DS-27560eff-049a-4f5b-8e13-ddbc1a1df1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36963,DS-8c8f8b64-a8bb-47fb-b861-535cc62889a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43794,DS-5182baa3-bd7f-4e6f-878c-47831ecb80c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46642,DS-0346b2fb-061f-4f58-a274-928b5a7c2a64,DISK], DatanodeInfoWithStorage[127.0.0.1:35586,DS-8198d05b-5850-4f02-bf49-5911275e4aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:43622,DS-2dbf59fc-7b3f-4093-a594-d638903a784d,DISK], DatanodeInfoWithStorage[127.0.0.1:42180,DS-4419174d-3b2f-4a78-9816-8c7235ef4407,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1832896690-172.17.0.3-1597359845506:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38680,DS-87d3ac58-099a-4943-8991-ab3ca7641fba,DISK], DatanodeInfoWithStorage[127.0.0.1:40045,DS-27560eff-049a-4f5b-8e13-ddbc1a1df1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36963,DS-8c8f8b64-a8bb-47fb-b861-535cc62889a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43794,DS-5182baa3-bd7f-4e6f-878c-47831ecb80c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46642,DS-0346b2fb-061f-4f58-a274-928b5a7c2a64,DISK], DatanodeInfoWithStorage[127.0.0.1:35586,DS-8198d05b-5850-4f02-bf49-5911275e4aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:43622,DS-2dbf59fc-7b3f-4093-a594-d638903a784d,DISK], DatanodeInfoWithStorage[127.0.0.1:42180,DS-4419174d-3b2f-4a78-9816-8c7235ef4407,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 536870912
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-769334438-172.17.0.3-1597359921453:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42094,DS-f3f1c008-cb7c-4bf0-96c4-d88f4f1d218f,DISK], DatanodeInfoWithStorage[127.0.0.1:39299,DS-30c511ec-e3ff-466f-a2fc-9870bca7461f,DISK], DatanodeInfoWithStorage[127.0.0.1:41436,DS-e71d4e3c-698f-4ea9-b69f-84af90d7d32f,DISK], DatanodeInfoWithStorage[127.0.0.1:44947,DS-87658a28-f27f-4d92-8f80-4634f4eae1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34807,DS-ffe2302c-d3a4-405e-a878-d8df5a275d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36273,DS-67588fb6-50f5-476b-a59e-e944993a05a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-87003624-87c5-4e5d-8478-d7573c8d6813,DISK], DatanodeInfoWithStorage[127.0.0.1:34814,DS-1eac410d-f222-4283-928c-fcc276e083dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-769334438-172.17.0.3-1597359921453:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42094,DS-f3f1c008-cb7c-4bf0-96c4-d88f4f1d218f,DISK], DatanodeInfoWithStorage[127.0.0.1:39299,DS-30c511ec-e3ff-466f-a2fc-9870bca7461f,DISK], DatanodeInfoWithStorage[127.0.0.1:41436,DS-e71d4e3c-698f-4ea9-b69f-84af90d7d32f,DISK], DatanodeInfoWithStorage[127.0.0.1:44947,DS-87658a28-f27f-4d92-8f80-4634f4eae1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34807,DS-ffe2302c-d3a4-405e-a878-d8df5a275d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36273,DS-67588fb6-50f5-476b-a59e-e944993a05a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-87003624-87c5-4e5d-8478-d7573c8d6813,DISK], DatanodeInfoWithStorage[127.0.0.1:34814,DS-1eac410d-f222-4283-928c-fcc276e083dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 536870912
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1192220474-172.17.0.3-1597360204999:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34698,DS-9ea5e259-8f20-4989-b64e-dbe86947681b,DISK], DatanodeInfoWithStorage[127.0.0.1:46401,DS-41211336-7986-4eb5-a1d8-ae91f98791a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41690,DS-fc75b46e-f84d-49fe-8be2-38803eaa0d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43099,DS-87e84b58-77a9-4f5f-8516-d9ac800ff81e,DISK], DatanodeInfoWithStorage[127.0.0.1:36004,DS-877cc23c-044e-47c4-a1b2-f24c1954406a,DISK], DatanodeInfoWithStorage[127.0.0.1:40881,DS-cf85ded6-2705-4bb3-b889-731480858be3,DISK], DatanodeInfoWithStorage[127.0.0.1:45324,DS-1bc5d593-71f2-4c10-9ae8-276aa61dcfef,DISK], DatanodeInfoWithStorage[127.0.0.1:37002,DS-bd2a0e87-8bd8-4476-81eb-9e211e5ad47f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1192220474-172.17.0.3-1597360204999:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34698,DS-9ea5e259-8f20-4989-b64e-dbe86947681b,DISK], DatanodeInfoWithStorage[127.0.0.1:46401,DS-41211336-7986-4eb5-a1d8-ae91f98791a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41690,DS-fc75b46e-f84d-49fe-8be2-38803eaa0d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43099,DS-87e84b58-77a9-4f5f-8516-d9ac800ff81e,DISK], DatanodeInfoWithStorage[127.0.0.1:36004,DS-877cc23c-044e-47c4-a1b2-f24c1954406a,DISK], DatanodeInfoWithStorage[127.0.0.1:40881,DS-cf85ded6-2705-4bb3-b889-731480858be3,DISK], DatanodeInfoWithStorage[127.0.0.1:45324,DS-1bc5d593-71f2-4c10-9ae8-276aa61dcfef,DISK], DatanodeInfoWithStorage[127.0.0.1:37002,DS-bd2a0e87-8bd8-4476-81eb-9e211e5ad47f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 536870912
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-71935254-172.17.0.3-1597360893560:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38572,DS-1339cf43-f53a-4975-a6b3-0ad58e5e155d,DISK], DatanodeInfoWithStorage[127.0.0.1:37818,DS-7c1eac38-1bca-4f4d-b399-def996fb3e61,DISK], DatanodeInfoWithStorage[127.0.0.1:45821,DS-7d7a0484-cd4f-4245-bdfc-dce93180b87b,DISK], DatanodeInfoWithStorage[127.0.0.1:33126,DS-6e44e735-db23-42cc-b203-e0ea1c7d0b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33733,DS-2bb9a019-4965-4c8c-a2be-c47efb70d803,DISK], DatanodeInfoWithStorage[127.0.0.1:39119,DS-0f607320-2120-4b9f-bd50-0f1f44840a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:42992,DS-753151d1-490f-4825-9e3e-d9ceb416351c,DISK], DatanodeInfoWithStorage[127.0.0.1:40331,DS-cc0674ad-ec26-4121-8da2-43eb4757a28b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-71935254-172.17.0.3-1597360893560:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38572,DS-1339cf43-f53a-4975-a6b3-0ad58e5e155d,DISK], DatanodeInfoWithStorage[127.0.0.1:37818,DS-7c1eac38-1bca-4f4d-b399-def996fb3e61,DISK], DatanodeInfoWithStorage[127.0.0.1:45821,DS-7d7a0484-cd4f-4245-bdfc-dce93180b87b,DISK], DatanodeInfoWithStorage[127.0.0.1:33126,DS-6e44e735-db23-42cc-b203-e0ea1c7d0b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33733,DS-2bb9a019-4965-4c8c-a2be-c47efb70d803,DISK], DatanodeInfoWithStorage[127.0.0.1:39119,DS-0f607320-2120-4b9f-bd50-0f1f44840a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:42992,DS-753151d1-490f-4825-9e3e-d9ceb416351c,DISK], DatanodeInfoWithStorage[127.0.0.1:40331,DS-cc0674ad-ec26-4121-8da2-43eb4757a28b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 536870912
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1488395097-172.17.0.3-1597361069527:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45639,DS-b95fa2f6-83a4-4784-bb94-0eb453a6dc63,DISK], DatanodeInfoWithStorage[127.0.0.1:35066,DS-90427189-d125-440e-93b3-9080d4cb7974,DISK], DatanodeInfoWithStorage[127.0.0.1:45489,DS-ed967d70-90ab-46ad-9a25-d3d83fdbc9bf,DISK], DatanodeInfoWithStorage[127.0.0.1:32806,DS-de2860b2-015b-43da-8192-15a520003f83,DISK], DatanodeInfoWithStorage[127.0.0.1:33819,DS-5900cf56-376b-4acd-91b1-de583ae7eb12,DISK], DatanodeInfoWithStorage[127.0.0.1:45844,DS-346c10fc-c934-4a31-a760-8ab5d7dd94dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39837,DS-2b1e2815-9c49-4bcd-9874-9f0d86d1216f,DISK], DatanodeInfoWithStorage[127.0.0.1:45731,DS-098b4f16-5de6-4089-a35c-e73e03898e25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1488395097-172.17.0.3-1597361069527:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45639,DS-b95fa2f6-83a4-4784-bb94-0eb453a6dc63,DISK], DatanodeInfoWithStorage[127.0.0.1:35066,DS-90427189-d125-440e-93b3-9080d4cb7974,DISK], DatanodeInfoWithStorage[127.0.0.1:45489,DS-ed967d70-90ab-46ad-9a25-d3d83fdbc9bf,DISK], DatanodeInfoWithStorage[127.0.0.1:32806,DS-de2860b2-015b-43da-8192-15a520003f83,DISK], DatanodeInfoWithStorage[127.0.0.1:33819,DS-5900cf56-376b-4acd-91b1-de583ae7eb12,DISK], DatanodeInfoWithStorage[127.0.0.1:45844,DS-346c10fc-c934-4a31-a760-8ab5d7dd94dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39837,DS-2b1e2815-9c49-4bcd-9874-9f0d86d1216f,DISK], DatanodeInfoWithStorage[127.0.0.1:45731,DS-098b4f16-5de6-4089-a35c-e73e03898e25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5170
