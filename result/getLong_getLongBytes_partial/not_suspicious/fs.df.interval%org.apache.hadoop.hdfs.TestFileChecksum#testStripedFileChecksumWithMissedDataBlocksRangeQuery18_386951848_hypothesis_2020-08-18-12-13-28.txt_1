reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 70000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 70000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-430749972-172.17.0.16-1597753718453:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45246,DS-3b69e785-8568-4930-8d82-23f3bc170d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:35563,DS-077e5638-2f58-4343-8a7a-f658c1578792,DISK], DatanodeInfoWithStorage[127.0.0.1:46569,DS-99ecab1f-93bc-4feb-9447-eaa914321330,DISK], DatanodeInfoWithStorage[127.0.0.1:41569,DS-1686d3f1-6718-466c-97ef-393700cfbf28,DISK], DatanodeInfoWithStorage[127.0.0.1:36660,DS-e00964dc-ad25-4351-be41-6ae48dde3502,DISK], DatanodeInfoWithStorage[127.0.0.1:38549,DS-e3ee3508-dc02-444f-a8a7-509d0001a104,DISK], DatanodeInfoWithStorage[127.0.0.1:42957,DS-d590f879-0c81-4308-91ee-9583b286aeb8,DISK], DatanodeInfoWithStorage[127.0.0.1:34343,DS-be941902-0c04-4144-b2bc-d63aa8002db3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-430749972-172.17.0.16-1597753718453:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45246,DS-3b69e785-8568-4930-8d82-23f3bc170d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:35563,DS-077e5638-2f58-4343-8a7a-f658c1578792,DISK], DatanodeInfoWithStorage[127.0.0.1:46569,DS-99ecab1f-93bc-4feb-9447-eaa914321330,DISK], DatanodeInfoWithStorage[127.0.0.1:41569,DS-1686d3f1-6718-466c-97ef-393700cfbf28,DISK], DatanodeInfoWithStorage[127.0.0.1:36660,DS-e00964dc-ad25-4351-be41-6ae48dde3502,DISK], DatanodeInfoWithStorage[127.0.0.1:38549,DS-e3ee3508-dc02-444f-a8a7-509d0001a104,DISK], DatanodeInfoWithStorage[127.0.0.1:42957,DS-d590f879-0c81-4308-91ee-9583b286aeb8,DISK], DatanodeInfoWithStorage[127.0.0.1:34343,DS-be941902-0c04-4144-b2bc-d63aa8002db3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 70000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1672656094-172.17.0.16-1597753754148:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33799,DS-2b5ff52c-9162-4a90-873e-01b81992134a,DISK], DatanodeInfoWithStorage[127.0.0.1:42867,DS-0d095d3f-3ee0-4680-9195-736f948e7cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:38264,DS-fc94b4f7-1afb-4055-929b-5a55c977537e,DISK], DatanodeInfoWithStorage[127.0.0.1:34211,DS-345392ca-8c2d-4984-a6f7-06b0d181f95f,DISK], DatanodeInfoWithStorage[127.0.0.1:45856,DS-14a57b4a-7990-42fb-bb7a-a6ea39c90afd,DISK], DatanodeInfoWithStorage[127.0.0.1:43176,DS-8b861054-8c0f-44d9-b0ed-7a8d398fafc7,DISK], DatanodeInfoWithStorage[127.0.0.1:42696,DS-cd881282-5777-4ee4-b7ca-dbbfbcc923bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40463,DS-4e47bd94-2984-47d8-9110-d7cf325d0c14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1672656094-172.17.0.16-1597753754148:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33799,DS-2b5ff52c-9162-4a90-873e-01b81992134a,DISK], DatanodeInfoWithStorage[127.0.0.1:42867,DS-0d095d3f-3ee0-4680-9195-736f948e7cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:38264,DS-fc94b4f7-1afb-4055-929b-5a55c977537e,DISK], DatanodeInfoWithStorage[127.0.0.1:34211,DS-345392ca-8c2d-4984-a6f7-06b0d181f95f,DISK], DatanodeInfoWithStorage[127.0.0.1:45856,DS-14a57b4a-7990-42fb-bb7a-a6ea39c90afd,DISK], DatanodeInfoWithStorage[127.0.0.1:43176,DS-8b861054-8c0f-44d9-b0ed-7a8d398fafc7,DISK], DatanodeInfoWithStorage[127.0.0.1:42696,DS-cd881282-5777-4ee4-b7ca-dbbfbcc923bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40463,DS-4e47bd94-2984-47d8-9110-d7cf325d0c14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 70000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1780045954-172.17.0.16-1597753892809:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36758,DS-ab1b6119-204c-4138-927d-c0d11e5816ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44048,DS-1693bc62-0f68-4302-83b1-217df48aa073,DISK], DatanodeInfoWithStorage[127.0.0.1:43370,DS-6b0ccc0c-11aa-45b0-9c8d-aa4d78e8e6ce,DISK], DatanodeInfoWithStorage[127.0.0.1:35941,DS-c805009a-85aa-4a5b-a3a4-63f27be6f1f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36527,DS-77331dca-f5a6-4b42-8b1f-24d2221bfe79,DISK], DatanodeInfoWithStorage[127.0.0.1:41911,DS-983dddce-157b-43ae-8c4a-2d168e0da8f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33691,DS-0fb916c7-3a4d-429c-9ab5-7a12a574be49,DISK], DatanodeInfoWithStorage[127.0.0.1:37026,DS-d9cd49ef-8df4-41e0-89e0-5b35f3b72041,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1780045954-172.17.0.16-1597753892809:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36758,DS-ab1b6119-204c-4138-927d-c0d11e5816ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44048,DS-1693bc62-0f68-4302-83b1-217df48aa073,DISK], DatanodeInfoWithStorage[127.0.0.1:43370,DS-6b0ccc0c-11aa-45b0-9c8d-aa4d78e8e6ce,DISK], DatanodeInfoWithStorage[127.0.0.1:35941,DS-c805009a-85aa-4a5b-a3a4-63f27be6f1f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36527,DS-77331dca-f5a6-4b42-8b1f-24d2221bfe79,DISK], DatanodeInfoWithStorage[127.0.0.1:41911,DS-983dddce-157b-43ae-8c4a-2d168e0da8f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33691,DS-0fb916c7-3a4d-429c-9ab5-7a12a574be49,DISK], DatanodeInfoWithStorage[127.0.0.1:37026,DS-d9cd49ef-8df4-41e0-89e0-5b35f3b72041,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 70000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1015957722-172.17.0.16-1597754537695:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45215,DS-5d497580-bb8a-4b78-a1c6-35c10efe9850,DISK], DatanodeInfoWithStorage[127.0.0.1:46660,DS-9867cf89-8408-4440-bff7-90784ec7f3aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44375,DS-9149dc6d-916e-40a4-9056-9bf9a24749a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35501,DS-05194526-0f4b-4e4b-8094-88c07c5c28f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42787,DS-99f45444-4609-4f9a-9f91-328ade8d65cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41069,DS-27840402-fd6e-4642-92ed-c8f1cdab82a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35840,DS-5ac6dabc-b550-4d06-acab-757ff94bbcb8,DISK], DatanodeInfoWithStorage[127.0.0.1:32867,DS-d49657d5-4b05-4290-a5e2-193306cd5934,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1015957722-172.17.0.16-1597754537695:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45215,DS-5d497580-bb8a-4b78-a1c6-35c10efe9850,DISK], DatanodeInfoWithStorage[127.0.0.1:46660,DS-9867cf89-8408-4440-bff7-90784ec7f3aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44375,DS-9149dc6d-916e-40a4-9056-9bf9a24749a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35501,DS-05194526-0f4b-4e4b-8094-88c07c5c28f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42787,DS-99f45444-4609-4f9a-9f91-328ade8d65cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41069,DS-27840402-fd6e-4642-92ed-c8f1cdab82a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35840,DS-5ac6dabc-b550-4d06-acab-757ff94bbcb8,DISK], DatanodeInfoWithStorage[127.0.0.1:32867,DS-d49657d5-4b05-4290-a5e2-193306cd5934,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 70000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-888766003-172.17.0.16-1597754574500:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42508,DS-7752b2e0-e54e-425b-8c73-da2810fd4b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34638,DS-3a354c34-9a8b-4a8d-9d83-8902431d2984,DISK], DatanodeInfoWithStorage[127.0.0.1:39347,DS-c769024d-985f-4dd9-bf8e-2e6f1c9dfc6b,DISK], DatanodeInfoWithStorage[127.0.0.1:44077,DS-9532e770-a8eb-4461-a54e-af8ef4599473,DISK], DatanodeInfoWithStorage[127.0.0.1:38101,DS-4fb9b0f0-6bed-4f6c-a251-c49c4561b7c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43677,DS-be070bb4-cc79-46b3-a990-56fc7fc0a4eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39467,DS-0366ea08-ba88-4268-ba3d-ccf5a4d38354,DISK], DatanodeInfoWithStorage[127.0.0.1:40926,DS-f7857851-06ac-4d14-a127-d8a0d1c43c71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-888766003-172.17.0.16-1597754574500:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42508,DS-7752b2e0-e54e-425b-8c73-da2810fd4b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34638,DS-3a354c34-9a8b-4a8d-9d83-8902431d2984,DISK], DatanodeInfoWithStorage[127.0.0.1:39347,DS-c769024d-985f-4dd9-bf8e-2e6f1c9dfc6b,DISK], DatanodeInfoWithStorage[127.0.0.1:44077,DS-9532e770-a8eb-4461-a54e-af8ef4599473,DISK], DatanodeInfoWithStorage[127.0.0.1:38101,DS-4fb9b0f0-6bed-4f6c-a251-c49c4561b7c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43677,DS-be070bb4-cc79-46b3-a990-56fc7fc0a4eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39467,DS-0366ea08-ba88-4268-ba3d-ccf5a4d38354,DISK], DatanodeInfoWithStorage[127.0.0.1:40926,DS-f7857851-06ac-4d14-a127-d8a0d1c43c71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 70000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1169843172-172.17.0.16-1597754938850:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46701,DS-c33542b1-8977-4c25-ad5f-ad8f4f9a98c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39186,DS-182d4dee-192f-4bce-bd3b-8e77d45636d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38035,DS-654ae231-9ab1-48cc-8aea-11ec40c543dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45441,DS-135a488e-463e-4616-a85e-ca13249feac9,DISK], DatanodeInfoWithStorage[127.0.0.1:38602,DS-6c833037-4cbb-4dca-98df-fe225eb46591,DISK], DatanodeInfoWithStorage[127.0.0.1:43818,DS-ab940107-22b9-474a-a053-9fd98331ac9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36509,DS-1b3e6bd6-e931-46dc-9905-31e988cc3f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:45151,DS-1d241e4e-8699-4168-86ec-ab692936c960,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1169843172-172.17.0.16-1597754938850:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46701,DS-c33542b1-8977-4c25-ad5f-ad8f4f9a98c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39186,DS-182d4dee-192f-4bce-bd3b-8e77d45636d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38035,DS-654ae231-9ab1-48cc-8aea-11ec40c543dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45441,DS-135a488e-463e-4616-a85e-ca13249feac9,DISK], DatanodeInfoWithStorage[127.0.0.1:38602,DS-6c833037-4cbb-4dca-98df-fe225eb46591,DISK], DatanodeInfoWithStorage[127.0.0.1:43818,DS-ab940107-22b9-474a-a053-9fd98331ac9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36509,DS-1b3e6bd6-e931-46dc-9905-31e988cc3f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:45151,DS-1d241e4e-8699-4168-86ec-ab692936c960,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 70000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-540873499-172.17.0.16-1597755307707:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36950,DS-cc159a47-8648-4289-a1a3-dec35d9ab778,DISK], DatanodeInfoWithStorage[127.0.0.1:40718,DS-cc0bb8e1-fcaa-4628-bd41-c3caa4f4f8e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35474,DS-aec1351e-c660-43bf-bd75-f9b96364bf30,DISK], DatanodeInfoWithStorage[127.0.0.1:34607,DS-040f6ad7-9187-4943-b063-1d7f8ce6e762,DISK], DatanodeInfoWithStorage[127.0.0.1:42150,DS-c9ffc585-12b5-440a-9dff-eb65debab16f,DISK], DatanodeInfoWithStorage[127.0.0.1:42814,DS-7ce25859-780c-49a7-9be6-5564f2295e7c,DISK], DatanodeInfoWithStorage[127.0.0.1:37826,DS-ee50a23b-1e4c-4692-89ea-05cd6dbe401c,DISK], DatanodeInfoWithStorage[127.0.0.1:40902,DS-eb925510-34aa-4ebd-b83f-cfbd3bc7ab03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-540873499-172.17.0.16-1597755307707:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36950,DS-cc159a47-8648-4289-a1a3-dec35d9ab778,DISK], DatanodeInfoWithStorage[127.0.0.1:40718,DS-cc0bb8e1-fcaa-4628-bd41-c3caa4f4f8e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35474,DS-aec1351e-c660-43bf-bd75-f9b96364bf30,DISK], DatanodeInfoWithStorage[127.0.0.1:34607,DS-040f6ad7-9187-4943-b063-1d7f8ce6e762,DISK], DatanodeInfoWithStorage[127.0.0.1:42150,DS-c9ffc585-12b5-440a-9dff-eb65debab16f,DISK], DatanodeInfoWithStorage[127.0.0.1:42814,DS-7ce25859-780c-49a7-9be6-5564f2295e7c,DISK], DatanodeInfoWithStorage[127.0.0.1:37826,DS-ee50a23b-1e4c-4692-89ea-05cd6dbe401c,DISK], DatanodeInfoWithStorage[127.0.0.1:40902,DS-eb925510-34aa-4ebd-b83f-cfbd3bc7ab03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 70000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1265856179-172.17.0.16-1597755412704:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43667,DS-98233501-e5a9-4e20-860b-ec21a721360b,DISK], DatanodeInfoWithStorage[127.0.0.1:38737,DS-cfcc1657-c54d-4a73-b37f-0f1d1bc0800b,DISK], DatanodeInfoWithStorage[127.0.0.1:35528,DS-463419c8-7cf2-4053-bd97-bdf909cc0311,DISK], DatanodeInfoWithStorage[127.0.0.1:44818,DS-f3d82bbf-433a-43a9-82c0-94e16e9111bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44433,DS-3d774436-1d45-4b53-8271-e05b3881b4e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38071,DS-7dbe8535-2f3b-4fec-bf12-1eef88232328,DISK], DatanodeInfoWithStorage[127.0.0.1:36878,DS-d7f126bf-7aaf-48f9-b864-8adaa85ef197,DISK], DatanodeInfoWithStorage[127.0.0.1:44969,DS-79a82f86-92c2-4157-88c2-ec36e2203150,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1265856179-172.17.0.16-1597755412704:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43667,DS-98233501-e5a9-4e20-860b-ec21a721360b,DISK], DatanodeInfoWithStorage[127.0.0.1:38737,DS-cfcc1657-c54d-4a73-b37f-0f1d1bc0800b,DISK], DatanodeInfoWithStorage[127.0.0.1:35528,DS-463419c8-7cf2-4053-bd97-bdf909cc0311,DISK], DatanodeInfoWithStorage[127.0.0.1:44818,DS-f3d82bbf-433a-43a9-82c0-94e16e9111bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44433,DS-3d774436-1d45-4b53-8271-e05b3881b4e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38071,DS-7dbe8535-2f3b-4fec-bf12-1eef88232328,DISK], DatanodeInfoWithStorage[127.0.0.1:36878,DS-d7f126bf-7aaf-48f9-b864-8adaa85ef197,DISK], DatanodeInfoWithStorage[127.0.0.1:44969,DS-79a82f86-92c2-4157-88c2-ec36e2203150,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 70000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-46101860-172.17.0.16-1597755986818:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34430,DS-7b275ef7-25d3-42ff-ac9d-213ee99e19f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45413,DS-da202c41-3bff-4ab3-9ee6-efcc07f56486,DISK], DatanodeInfoWithStorage[127.0.0.1:34254,DS-3bc49b10-4756-47dd-986d-09086fced05c,DISK], DatanodeInfoWithStorage[127.0.0.1:33856,DS-56fb616b-6094-4826-b2df-45de4aa90b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44088,DS-977a2765-f295-42d3-86e7-40a1e5a5c057,DISK], DatanodeInfoWithStorage[127.0.0.1:36762,DS-0e2d801e-1486-40d8-8d2d-767d50071341,DISK], DatanodeInfoWithStorage[127.0.0.1:41827,DS-71e66acf-6d52-42e7-bdaf-69cd25035df2,DISK], DatanodeInfoWithStorage[127.0.0.1:43612,DS-83bffc93-440c-445f-bad1-eb7fd71718bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-46101860-172.17.0.16-1597755986818:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34430,DS-7b275ef7-25d3-42ff-ac9d-213ee99e19f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45413,DS-da202c41-3bff-4ab3-9ee6-efcc07f56486,DISK], DatanodeInfoWithStorage[127.0.0.1:34254,DS-3bc49b10-4756-47dd-986d-09086fced05c,DISK], DatanodeInfoWithStorage[127.0.0.1:33856,DS-56fb616b-6094-4826-b2df-45de4aa90b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44088,DS-977a2765-f295-42d3-86e7-40a1e5a5c057,DISK], DatanodeInfoWithStorage[127.0.0.1:36762,DS-0e2d801e-1486-40d8-8d2d-767d50071341,DISK], DatanodeInfoWithStorage[127.0.0.1:41827,DS-71e66acf-6d52-42e7-bdaf-69cd25035df2,DISK], DatanodeInfoWithStorage[127.0.0.1:43612,DS-83bffc93-440c-445f-bad1-eb7fd71718bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 70000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1569192946-172.17.0.16-1597756056755:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45870,DS-90d1d026-c2b6-449a-b771-bfeecbdd0cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:42344,DS-8af96fe5-df47-4985-be21-744eb63c36cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42910,DS-c7bf3dd6-fafb-4d3d-90c0-3c3854477cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:46496,DS-ca238d63-efbf-4cce-ad41-b1b71c813d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37445,DS-bd81958c-cbcc-4c49-9e2b-7630c1747c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:35212,DS-9b5b4dda-3042-403e-85d1-3ed0fb56616e,DISK], DatanodeInfoWithStorage[127.0.0.1:40334,DS-babfab29-869f-4005-bf06-408049fc8f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36300,DS-a171757f-2636-4aa8-86a2-527b9a689d4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1569192946-172.17.0.16-1597756056755:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45870,DS-90d1d026-c2b6-449a-b771-bfeecbdd0cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:42344,DS-8af96fe5-df47-4985-be21-744eb63c36cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42910,DS-c7bf3dd6-fafb-4d3d-90c0-3c3854477cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:46496,DS-ca238d63-efbf-4cce-ad41-b1b71c813d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37445,DS-bd81958c-cbcc-4c49-9e2b-7630c1747c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:35212,DS-9b5b4dda-3042-403e-85d1-3ed0fb56616e,DISK], DatanodeInfoWithStorage[127.0.0.1:40334,DS-babfab29-869f-4005-bf06-408049fc8f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36300,DS-a171757f-2636-4aa8-86a2-527b9a689d4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 70000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-335862496-172.17.0.16-1597756125132:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35222,DS-f815d6db-f1ee-4d0b-9ac6-017a506bb20b,DISK], DatanodeInfoWithStorage[127.0.0.1:39329,DS-c1992a97-d30c-4728-be33-8119d7d33e45,DISK], DatanodeInfoWithStorage[127.0.0.1:43571,DS-6df9a0cc-05b7-4a6f-a407-f284b7413de2,DISK], DatanodeInfoWithStorage[127.0.0.1:45752,DS-962f2d57-7c6f-4860-96d2-a3fc1e227b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41400,DS-1cb4b8be-fba6-4d3d-9212-1e78262eb5ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38730,DS-461e94b7-3ee1-4315-8627-416d42fd9501,DISK], DatanodeInfoWithStorage[127.0.0.1:34767,DS-2cbd108d-c12f-401f-890d-83fdd2e214c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35201,DS-d8578a67-e697-4cb1-af67-0b88a88ff635,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-335862496-172.17.0.16-1597756125132:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35222,DS-f815d6db-f1ee-4d0b-9ac6-017a506bb20b,DISK], DatanodeInfoWithStorage[127.0.0.1:39329,DS-c1992a97-d30c-4728-be33-8119d7d33e45,DISK], DatanodeInfoWithStorage[127.0.0.1:43571,DS-6df9a0cc-05b7-4a6f-a407-f284b7413de2,DISK], DatanodeInfoWithStorage[127.0.0.1:45752,DS-962f2d57-7c6f-4860-96d2-a3fc1e227b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41400,DS-1cb4b8be-fba6-4d3d-9212-1e78262eb5ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38730,DS-461e94b7-3ee1-4315-8627-416d42fd9501,DISK], DatanodeInfoWithStorage[127.0.0.1:34767,DS-2cbd108d-c12f-401f-890d-83fdd2e214c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35201,DS-d8578a67-e697-4cb1-af67-0b88a88ff635,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 70000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-617766710-172.17.0.16-1597756202155:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40080,DS-8c21b91d-5a6d-41cc-b32f-0e828f7d52fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42016,DS-1b8ec3fd-3b4f-4574-ad44-b78c5baf36e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45507,DS-f93662da-2387-47c7-bbd2-dcf2072878dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38686,DS-2d6d456d-1fc7-4db3-a91f-c3096c1687db,DISK], DatanodeInfoWithStorage[127.0.0.1:41593,DS-cc4614fa-d19a-4b87-bfd3-7d32273386df,DISK], DatanodeInfoWithStorage[127.0.0.1:33775,DS-0502639b-fa5c-47a1-b2e9-e761af1a94f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35964,DS-16767b66-0a05-4ff3-bbd9-9a2b5fca5057,DISK], DatanodeInfoWithStorage[127.0.0.1:43045,DS-8fd1ca94-977e-48b6-8dcf-b4aa21ba55ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-617766710-172.17.0.16-1597756202155:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40080,DS-8c21b91d-5a6d-41cc-b32f-0e828f7d52fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42016,DS-1b8ec3fd-3b4f-4574-ad44-b78c5baf36e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45507,DS-f93662da-2387-47c7-bbd2-dcf2072878dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38686,DS-2d6d456d-1fc7-4db3-a91f-c3096c1687db,DISK], DatanodeInfoWithStorage[127.0.0.1:41593,DS-cc4614fa-d19a-4b87-bfd3-7d32273386df,DISK], DatanodeInfoWithStorage[127.0.0.1:33775,DS-0502639b-fa5c-47a1-b2e9-e761af1a94f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35964,DS-16767b66-0a05-4ff3-bbd9-9a2b5fca5057,DISK], DatanodeInfoWithStorage[127.0.0.1:43045,DS-8fd1ca94-977e-48b6-8dcf-b4aa21ba55ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 70000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-941629531-172.17.0.16-1597756561686:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46195,DS-ef405e58-45aa-4807-b64f-2c60349bdc55,DISK], DatanodeInfoWithStorage[127.0.0.1:42918,DS-9c8716f4-748e-4c1c-8bff-3ff3847923ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44189,DS-2fc6b64a-239a-40ef-a773-94b9416d0e50,DISK], DatanodeInfoWithStorage[127.0.0.1:33019,DS-ad7914ee-bdd4-41eb-818f-79fc84496ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:38362,DS-5f122b7b-538a-4a18-92e9-d1eeed38ee30,DISK], DatanodeInfoWithStorage[127.0.0.1:40703,DS-9d3ff079-982d-4e04-ab6c-c7684f06a0de,DISK], DatanodeInfoWithStorage[127.0.0.1:41886,DS-ba3bec38-d9bd-41fc-9364-dc0d98ad7ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:44285,DS-09ae3933-c18a-4675-ab17-b7d27836fbeb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-941629531-172.17.0.16-1597756561686:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46195,DS-ef405e58-45aa-4807-b64f-2c60349bdc55,DISK], DatanodeInfoWithStorage[127.0.0.1:42918,DS-9c8716f4-748e-4c1c-8bff-3ff3847923ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44189,DS-2fc6b64a-239a-40ef-a773-94b9416d0e50,DISK], DatanodeInfoWithStorage[127.0.0.1:33019,DS-ad7914ee-bdd4-41eb-818f-79fc84496ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:38362,DS-5f122b7b-538a-4a18-92e9-d1eeed38ee30,DISK], DatanodeInfoWithStorage[127.0.0.1:40703,DS-9d3ff079-982d-4e04-ab6c-c7684f06a0de,DISK], DatanodeInfoWithStorage[127.0.0.1:41886,DS-ba3bec38-d9bd-41fc-9364-dc0d98ad7ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:44285,DS-09ae3933-c18a-4675-ab17-b7d27836fbeb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 70000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-110641998-172.17.0.16-1597756598714:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37587,DS-ef08f19c-5b9e-428f-9c47-0eb30457e8f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41486,DS-11d3a5e0-65d4-49ad-8959-d4cc6c35e5aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40357,DS-7e027591-d0a0-4685-977d-3ad1393eb815,DISK], DatanodeInfoWithStorage[127.0.0.1:32965,DS-5883d910-4ddd-475b-9e20-e8726edaecbf,DISK], DatanodeInfoWithStorage[127.0.0.1:39703,DS-acb2cef1-c5ae-4cf2-b7e3-2916b31e3649,DISK], DatanodeInfoWithStorage[127.0.0.1:45745,DS-67ed5ccd-5dce-4839-800c-a466f1e5355b,DISK], DatanodeInfoWithStorage[127.0.0.1:38078,DS-22587f0a-f9f8-489e-aab7-fac9777e6728,DISK], DatanodeInfoWithStorage[127.0.0.1:37060,DS-050773ed-282f-4ec2-9a3e-52ae7aa58480,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-110641998-172.17.0.16-1597756598714:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37587,DS-ef08f19c-5b9e-428f-9c47-0eb30457e8f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41486,DS-11d3a5e0-65d4-49ad-8959-d4cc6c35e5aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40357,DS-7e027591-d0a0-4685-977d-3ad1393eb815,DISK], DatanodeInfoWithStorage[127.0.0.1:32965,DS-5883d910-4ddd-475b-9e20-e8726edaecbf,DISK], DatanodeInfoWithStorage[127.0.0.1:39703,DS-acb2cef1-c5ae-4cf2-b7e3-2916b31e3649,DISK], DatanodeInfoWithStorage[127.0.0.1:45745,DS-67ed5ccd-5dce-4839-800c-a466f1e5355b,DISK], DatanodeInfoWithStorage[127.0.0.1:38078,DS-22587f0a-f9f8-489e-aab7-fac9777e6728,DISK], DatanodeInfoWithStorage[127.0.0.1:37060,DS-050773ed-282f-4ec2-9a3e-52ae7aa58480,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 70000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1595653869-172.17.0.16-1597757170806:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45705,DS-5fe3debf-0cf7-415c-ba88-799af9c4fc59,DISK], DatanodeInfoWithStorage[127.0.0.1:33589,DS-53c1d6b5-d9f8-4a26-89e4-6d3423270440,DISK], DatanodeInfoWithStorage[127.0.0.1:33202,DS-847afa85-911c-4f27-8a76-e1a8225088dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35339,DS-90381a51-9338-468b-9bde-000ce1dd44e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33351,DS-d744310b-9353-41f6-bfe7-ec88a3bcc952,DISK], DatanodeInfoWithStorage[127.0.0.1:39529,DS-db0de056-be6b-4405-b4ff-a1690186f3e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46661,DS-b2c209b7-06d8-4ccf-985f-8382feb43ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:44644,DS-142d2b38-d868-451a-9a1e-bd982612064d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1595653869-172.17.0.16-1597757170806:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45705,DS-5fe3debf-0cf7-415c-ba88-799af9c4fc59,DISK], DatanodeInfoWithStorage[127.0.0.1:33589,DS-53c1d6b5-d9f8-4a26-89e4-6d3423270440,DISK], DatanodeInfoWithStorage[127.0.0.1:33202,DS-847afa85-911c-4f27-8a76-e1a8225088dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35339,DS-90381a51-9338-468b-9bde-000ce1dd44e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33351,DS-d744310b-9353-41f6-bfe7-ec88a3bcc952,DISK], DatanodeInfoWithStorage[127.0.0.1:39529,DS-db0de056-be6b-4405-b4ff-a1690186f3e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46661,DS-b2c209b7-06d8-4ccf-985f-8382feb43ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:44644,DS-142d2b38-d868-451a-9a1e-bd982612064d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 70000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-392289375-172.17.0.16-1597757232302:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44933,DS-46eeb8fe-af5f-48e0-959b-250cd440ed63,DISK], DatanodeInfoWithStorage[127.0.0.1:43258,DS-b1b1b8f6-1bac-4ba6-b869-0c6af73482b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34226,DS-b6b837f9-c18d-47e6-a625-1cbdd9a8b327,DISK], DatanodeInfoWithStorage[127.0.0.1:40843,DS-83794a1f-b0dc-4768-9a7f-7de086cf83e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44996,DS-d518b10a-1e65-40a9-8682-a389c72a6a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39539,DS-170591aa-e327-48e6-b36d-3f2b2a1a7d94,DISK], DatanodeInfoWithStorage[127.0.0.1:38116,DS-4723a1d9-29e5-4bbf-a849-0aabcf00cccf,DISK], DatanodeInfoWithStorage[127.0.0.1:42335,DS-8f27d754-02d6-415c-8bc0-9a08775f75b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-392289375-172.17.0.16-1597757232302:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44933,DS-46eeb8fe-af5f-48e0-959b-250cd440ed63,DISK], DatanodeInfoWithStorage[127.0.0.1:43258,DS-b1b1b8f6-1bac-4ba6-b869-0c6af73482b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34226,DS-b6b837f9-c18d-47e6-a625-1cbdd9a8b327,DISK], DatanodeInfoWithStorage[127.0.0.1:40843,DS-83794a1f-b0dc-4768-9a7f-7de086cf83e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44996,DS-d518b10a-1e65-40a9-8682-a389c72a6a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39539,DS-170591aa-e327-48e6-b36d-3f2b2a1a7d94,DISK], DatanodeInfoWithStorage[127.0.0.1:38116,DS-4723a1d9-29e5-4bbf-a849-0aabcf00cccf,DISK], DatanodeInfoWithStorage[127.0.0.1:42335,DS-8f27d754-02d6-415c-8bc0-9a08775f75b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 70000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1033870261-172.17.0.16-1597757306586:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32862,DS-ae5b8605-5e6b-45e7-a1ed-a4b34e3f05ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41676,DS-b234b7e7-329a-4d5b-8c28-e2f49f863f86,DISK], DatanodeInfoWithStorage[127.0.0.1:35194,DS-fe63a8ad-9a6a-4772-81db-54219511e726,DISK], DatanodeInfoWithStorage[127.0.0.1:46156,DS-10833ee0-14bd-4ae6-834a-7f0ec3e3fcd8,DISK], DatanodeInfoWithStorage[127.0.0.1:39835,DS-5e5099b2-7637-428f-9d4b-a20f69c48bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:32792,DS-a33cade5-4f68-4367-b33a-ef6b721169fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37215,DS-e9dad992-279e-4133-974b-ad520731c4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44662,DS-48bd2da1-c129-4ac8-af96-1f26bf27db0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1033870261-172.17.0.16-1597757306586:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32862,DS-ae5b8605-5e6b-45e7-a1ed-a4b34e3f05ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41676,DS-b234b7e7-329a-4d5b-8c28-e2f49f863f86,DISK], DatanodeInfoWithStorage[127.0.0.1:35194,DS-fe63a8ad-9a6a-4772-81db-54219511e726,DISK], DatanodeInfoWithStorage[127.0.0.1:46156,DS-10833ee0-14bd-4ae6-834a-7f0ec3e3fcd8,DISK], DatanodeInfoWithStorage[127.0.0.1:39835,DS-5e5099b2-7637-428f-9d4b-a20f69c48bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:32792,DS-a33cade5-4f68-4367-b33a-ef6b721169fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37215,DS-e9dad992-279e-4133-974b-ad520731c4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44662,DS-48bd2da1-c129-4ac8-af96-1f26bf27db0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 70000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-877636644-172.17.0.16-1597757384071:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44965,DS-d872c364-14cd-44ee-872a-c56b7b0c7a19,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-ddc5fded-f34a-4b32-bdef-79e0f8d96586,DISK], DatanodeInfoWithStorage[127.0.0.1:33839,DS-039ff087-8a90-4dc3-b2ff-3b8959b41039,DISK], DatanodeInfoWithStorage[127.0.0.1:42537,DS-1ffd8c0f-0225-45cb-94cb-0ff59b913666,DISK], DatanodeInfoWithStorage[127.0.0.1:40891,DS-a12c9213-2f85-472b-87f1-5207415f5120,DISK], DatanodeInfoWithStorage[127.0.0.1:44808,DS-4f07459f-0936-44a4-85a1-dfba97a7b0b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41688,DS-c69373cc-ed76-4d9c-a409-d89f9c49e4a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35809,DS-536fc328-9240-40b7-86ce-25f9809d04a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-877636644-172.17.0.16-1597757384071:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44965,DS-d872c364-14cd-44ee-872a-c56b7b0c7a19,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-ddc5fded-f34a-4b32-bdef-79e0f8d96586,DISK], DatanodeInfoWithStorage[127.0.0.1:33839,DS-039ff087-8a90-4dc3-b2ff-3b8959b41039,DISK], DatanodeInfoWithStorage[127.0.0.1:42537,DS-1ffd8c0f-0225-45cb-94cb-0ff59b913666,DISK], DatanodeInfoWithStorage[127.0.0.1:40891,DS-a12c9213-2f85-472b-87f1-5207415f5120,DISK], DatanodeInfoWithStorage[127.0.0.1:44808,DS-4f07459f-0936-44a4-85a1-dfba97a7b0b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41688,DS-c69373cc-ed76-4d9c-a409-d89f9c49e4a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35809,DS-536fc328-9240-40b7-86ce-25f9809d04a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 4893
