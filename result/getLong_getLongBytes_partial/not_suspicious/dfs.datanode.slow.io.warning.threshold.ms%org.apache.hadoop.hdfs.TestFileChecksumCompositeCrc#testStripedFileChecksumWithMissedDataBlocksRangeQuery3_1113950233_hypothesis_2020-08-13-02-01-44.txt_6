reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2093069998-172.17.0.14-1597284624055:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43313,DS-176cdd71-4adc-4891-bf11-88ddeff5db9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40864,DS-2841a316-17ec-4f6d-b233-7c5946a4b66f,DISK], DatanodeInfoWithStorage[127.0.0.1:46758,DS-d3757854-462f-4ceb-a8ba-264d46496434,DISK], DatanodeInfoWithStorage[127.0.0.1:39187,DS-9d41f733-283c-4795-9911-80673aa99b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:41306,DS-3c01feca-58df-4cc6-bad8-9cdeb80a648c,DISK], DatanodeInfoWithStorage[127.0.0.1:41511,DS-15e42833-4160-4608-842d-bf1f0caaa7b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39645,DS-31ff07de-0442-4b5c-a2cd-3d3655b52a10,DISK], DatanodeInfoWithStorage[127.0.0.1:35791,DS-c4525450-1298-4083-a7c2-6fc39c710caa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2093069998-172.17.0.14-1597284624055:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43313,DS-176cdd71-4adc-4891-bf11-88ddeff5db9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40864,DS-2841a316-17ec-4f6d-b233-7c5946a4b66f,DISK], DatanodeInfoWithStorage[127.0.0.1:46758,DS-d3757854-462f-4ceb-a8ba-264d46496434,DISK], DatanodeInfoWithStorage[127.0.0.1:39187,DS-9d41f733-283c-4795-9911-80673aa99b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:41306,DS-3c01feca-58df-4cc6-bad8-9cdeb80a648c,DISK], DatanodeInfoWithStorage[127.0.0.1:41511,DS-15e42833-4160-4608-842d-bf1f0caaa7b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39645,DS-31ff07de-0442-4b5c-a2cd-3d3655b52a10,DISK], DatanodeInfoWithStorage[127.0.0.1:35791,DS-c4525450-1298-4083-a7c2-6fc39c710caa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1139485340-172.17.0.14-1597284667217:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44561,DS-5b4bca29-9055-409f-b790-8cb4c5c6c31c,DISK], DatanodeInfoWithStorage[127.0.0.1:32912,DS-4b6fbe98-09c3-48ee-8a6d-e3b358f7494f,DISK], DatanodeInfoWithStorage[127.0.0.1:46432,DS-c78dea3a-5dc9-4565-ae4f-bc9b66abce5e,DISK], DatanodeInfoWithStorage[127.0.0.1:33092,DS-c8da6188-76a8-40bd-ba7b-fec42ea6b69c,DISK], DatanodeInfoWithStorage[127.0.0.1:42366,DS-99804d36-0422-4cb7-8b8b-c6d451e6850f,DISK], DatanodeInfoWithStorage[127.0.0.1:43793,DS-34de88d9-6bcb-41b5-b3de-24904e3a84ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39435,DS-487d9280-6718-4263-9e5d-8a8fe0b31e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34733,DS-431ba108-3396-4347-91a7-c10a2fcc1a03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1139485340-172.17.0.14-1597284667217:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44561,DS-5b4bca29-9055-409f-b790-8cb4c5c6c31c,DISK], DatanodeInfoWithStorage[127.0.0.1:32912,DS-4b6fbe98-09c3-48ee-8a6d-e3b358f7494f,DISK], DatanodeInfoWithStorage[127.0.0.1:46432,DS-c78dea3a-5dc9-4565-ae4f-bc9b66abce5e,DISK], DatanodeInfoWithStorage[127.0.0.1:33092,DS-c8da6188-76a8-40bd-ba7b-fec42ea6b69c,DISK], DatanodeInfoWithStorage[127.0.0.1:42366,DS-99804d36-0422-4cb7-8b8b-c6d451e6850f,DISK], DatanodeInfoWithStorage[127.0.0.1:43793,DS-34de88d9-6bcb-41b5-b3de-24904e3a84ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39435,DS-487d9280-6718-4263-9e5d-8a8fe0b31e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34733,DS-431ba108-3396-4347-91a7-c10a2fcc1a03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-770712830-172.17.0.14-1597285244525:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42646,DS-6de8b841-9ce9-4846-8b73-7e6c45ae3a75,DISK], DatanodeInfoWithStorage[127.0.0.1:36773,DS-dc3c0d19-ce70-4f82-834c-2bf3e728e98d,DISK], DatanodeInfoWithStorage[127.0.0.1:41829,DS-0de35840-c7d9-4cdb-a2b7-d66ec1f8b92d,DISK], DatanodeInfoWithStorage[127.0.0.1:40023,DS-22220cad-52c9-426e-9912-92da81ab11b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33907,DS-62bf74cb-9197-4283-82e0-9c3f38db64d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33135,DS-a69e19d6-3a8f-4dfc-a0b2-fd74d84148da,DISK], DatanodeInfoWithStorage[127.0.0.1:34544,DS-f3ff34bf-10f2-44d9-8975-2528ef95df69,DISK], DatanodeInfoWithStorage[127.0.0.1:42557,DS-f1d4c860-d0b9-4472-9817-53afad87ee32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-770712830-172.17.0.14-1597285244525:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42646,DS-6de8b841-9ce9-4846-8b73-7e6c45ae3a75,DISK], DatanodeInfoWithStorage[127.0.0.1:36773,DS-dc3c0d19-ce70-4f82-834c-2bf3e728e98d,DISK], DatanodeInfoWithStorage[127.0.0.1:41829,DS-0de35840-c7d9-4cdb-a2b7-d66ec1f8b92d,DISK], DatanodeInfoWithStorage[127.0.0.1:40023,DS-22220cad-52c9-426e-9912-92da81ab11b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33907,DS-62bf74cb-9197-4283-82e0-9c3f38db64d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33135,DS-a69e19d6-3a8f-4dfc-a0b2-fd74d84148da,DISK], DatanodeInfoWithStorage[127.0.0.1:34544,DS-f3ff34bf-10f2-44d9-8975-2528ef95df69,DISK], DatanodeInfoWithStorage[127.0.0.1:42557,DS-f1d4c860-d0b9-4472-9817-53afad87ee32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-139505910-172.17.0.14-1597285837097:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34322,DS-cd31249e-14f7-459b-8a6a-b4f2b9365aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:41970,DS-e3001190-8f6a-4a7b-b7d4-74093ddb683c,DISK], DatanodeInfoWithStorage[127.0.0.1:39436,DS-1e5567d0-1421-4197-a013-04519392d82e,DISK], DatanodeInfoWithStorage[127.0.0.1:35895,DS-4cdce636-1f27-4749-8d25-c4845c0a3764,DISK], DatanodeInfoWithStorage[127.0.0.1:44242,DS-6c3c2ac5-6b72-4bde-9e60-3e900c72cafa,DISK], DatanodeInfoWithStorage[127.0.0.1:37100,DS-64a2af2e-d556-4139-a1c7-a4b35f6ac2f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36327,DS-1ada1653-876c-4ada-bc14-b7969001c125,DISK], DatanodeInfoWithStorage[127.0.0.1:45253,DS-3890d361-556d-4ca3-934b-1d6c88108911,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-139505910-172.17.0.14-1597285837097:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34322,DS-cd31249e-14f7-459b-8a6a-b4f2b9365aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:41970,DS-e3001190-8f6a-4a7b-b7d4-74093ddb683c,DISK], DatanodeInfoWithStorage[127.0.0.1:39436,DS-1e5567d0-1421-4197-a013-04519392d82e,DISK], DatanodeInfoWithStorage[127.0.0.1:35895,DS-4cdce636-1f27-4749-8d25-c4845c0a3764,DISK], DatanodeInfoWithStorage[127.0.0.1:44242,DS-6c3c2ac5-6b72-4bde-9e60-3e900c72cafa,DISK], DatanodeInfoWithStorage[127.0.0.1:37100,DS-64a2af2e-d556-4139-a1c7-a4b35f6ac2f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36327,DS-1ada1653-876c-4ada-bc14-b7969001c125,DISK], DatanodeInfoWithStorage[127.0.0.1:45253,DS-3890d361-556d-4ca3-934b-1d6c88108911,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1036946246-172.17.0.14-1597286180577:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45850,DS-cf6e9bd6-706e-4293-9320-f888cc76ba16,DISK], DatanodeInfoWithStorage[127.0.0.1:40795,DS-6115cbcf-a348-4d0b-b9cd-e6d6bdb032a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41908,DS-94f8377d-3c66-48ff-9561-1d66352661e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36936,DS-aada9c43-9526-4d73-9d12-3a9e0f35b6ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44985,DS-a4a88ff6-ea81-4ac3-a4c9-5797815bc8c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42236,DS-19009cdb-fb7c-41f4-b328-783a4a89d419,DISK], DatanodeInfoWithStorage[127.0.0.1:36138,DS-71bc0a1e-d8e7-4475-b1cd-0f67870b23ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42953,DS-ca31ec0d-4918-4a90-a550-27ef49728334,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1036946246-172.17.0.14-1597286180577:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45850,DS-cf6e9bd6-706e-4293-9320-f888cc76ba16,DISK], DatanodeInfoWithStorage[127.0.0.1:40795,DS-6115cbcf-a348-4d0b-b9cd-e6d6bdb032a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41908,DS-94f8377d-3c66-48ff-9561-1d66352661e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36936,DS-aada9c43-9526-4d73-9d12-3a9e0f35b6ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44985,DS-a4a88ff6-ea81-4ac3-a4c9-5797815bc8c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42236,DS-19009cdb-fb7c-41f4-b328-783a4a89d419,DISK], DatanodeInfoWithStorage[127.0.0.1:36138,DS-71bc0a1e-d8e7-4475-b1cd-0f67870b23ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42953,DS-ca31ec0d-4918-4a90-a550-27ef49728334,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1995866110-172.17.0.14-1597287301916:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34421,DS-9d63ac1d-c572-4e2e-b9ea-b634b1db5774,DISK], DatanodeInfoWithStorage[127.0.0.1:41205,DS-199fbcd4-36bb-44c7-88ce-7c8a8b386945,DISK], DatanodeInfoWithStorage[127.0.0.1:38036,DS-e3d9576f-ffb0-48f8-ab7a-c3549e6ff23d,DISK], DatanodeInfoWithStorage[127.0.0.1:37101,DS-6b039b98-4d38-445d-be31-769dcc8d94dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45792,DS-2aa8c857-76f3-471d-b498-064638a75aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:40941,DS-a147ad6a-d3d7-47d4-8165-9d14045d50ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44568,DS-ef960c3b-b999-4c72-8c5c-ee33c30ec0b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43188,DS-38f782e1-689c-48f6-9f69-4a076107ecc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1995866110-172.17.0.14-1597287301916:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34421,DS-9d63ac1d-c572-4e2e-b9ea-b634b1db5774,DISK], DatanodeInfoWithStorage[127.0.0.1:41205,DS-199fbcd4-36bb-44c7-88ce-7c8a8b386945,DISK], DatanodeInfoWithStorage[127.0.0.1:38036,DS-e3d9576f-ffb0-48f8-ab7a-c3549e6ff23d,DISK], DatanodeInfoWithStorage[127.0.0.1:37101,DS-6b039b98-4d38-445d-be31-769dcc8d94dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45792,DS-2aa8c857-76f3-471d-b498-064638a75aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:40941,DS-a147ad6a-d3d7-47d4-8165-9d14045d50ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44568,DS-ef960c3b-b999-4c72-8c5c-ee33c30ec0b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43188,DS-38f782e1-689c-48f6-9f69-4a076107ecc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1067301160-172.17.0.14-1597287339066:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45536,DS-88f5f2aa-8126-41b3-b0a3-d8fbc0eeebed,DISK], DatanodeInfoWithStorage[127.0.0.1:41818,DS-0d2e31c6-5fe8-4e6c-b918-186a0d7dcd5b,DISK], DatanodeInfoWithStorage[127.0.0.1:46493,DS-496330e2-5a14-4f71-98e3-68c17432bce5,DISK], DatanodeInfoWithStorage[127.0.0.1:39152,DS-55279a0f-441f-490a-9b68-641a5642e4e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37134,DS-03976daf-6db0-489e-8508-4e37bb7da3db,DISK], DatanodeInfoWithStorage[127.0.0.1:39689,DS-ca8f4ff2-8d97-4953-876a-81392b0295c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46848,DS-fff1ea8a-6b52-413f-a30c-b5c2ffdd57b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38247,DS-9410a4b3-d1d1-4fe0-b21a-c985deb618f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1067301160-172.17.0.14-1597287339066:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45536,DS-88f5f2aa-8126-41b3-b0a3-d8fbc0eeebed,DISK], DatanodeInfoWithStorage[127.0.0.1:41818,DS-0d2e31c6-5fe8-4e6c-b918-186a0d7dcd5b,DISK], DatanodeInfoWithStorage[127.0.0.1:46493,DS-496330e2-5a14-4f71-98e3-68c17432bce5,DISK], DatanodeInfoWithStorage[127.0.0.1:39152,DS-55279a0f-441f-490a-9b68-641a5642e4e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37134,DS-03976daf-6db0-489e-8508-4e37bb7da3db,DISK], DatanodeInfoWithStorage[127.0.0.1:39689,DS-ca8f4ff2-8d97-4953-876a-81392b0295c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46848,DS-fff1ea8a-6b52-413f-a30c-b5c2ffdd57b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38247,DS-9410a4b3-d1d1-4fe0-b21a-c985deb618f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1215039672-172.17.0.14-1597287657672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41347,DS-01aacd7d-bcaf-4749-93a6-e769ebfaffe7,DISK], DatanodeInfoWithStorage[127.0.0.1:40460,DS-368ab2a0-283a-4825-bfe3-0ee479c49e34,DISK], DatanodeInfoWithStorage[127.0.0.1:39269,DS-98f3f9d6-788c-4f42-8365-6e66dcadba32,DISK], DatanodeInfoWithStorage[127.0.0.1:38592,DS-ae453670-1019-4af7-bcf4-a62ea294fd31,DISK], DatanodeInfoWithStorage[127.0.0.1:35037,DS-224b785b-1dd8-4cdf-904d-d2fa23534c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:37429,DS-7fd1c54d-f701-470d-b6fe-b7f21345e33b,DISK], DatanodeInfoWithStorage[127.0.0.1:33889,DS-e96915dc-d6f1-40fc-86ae-1c7ba84cc976,DISK], DatanodeInfoWithStorage[127.0.0.1:38828,DS-1533e61e-7500-41fe-b02a-7c3f7ca0ab2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1215039672-172.17.0.14-1597287657672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41347,DS-01aacd7d-bcaf-4749-93a6-e769ebfaffe7,DISK], DatanodeInfoWithStorage[127.0.0.1:40460,DS-368ab2a0-283a-4825-bfe3-0ee479c49e34,DISK], DatanodeInfoWithStorage[127.0.0.1:39269,DS-98f3f9d6-788c-4f42-8365-6e66dcadba32,DISK], DatanodeInfoWithStorage[127.0.0.1:38592,DS-ae453670-1019-4af7-bcf4-a62ea294fd31,DISK], DatanodeInfoWithStorage[127.0.0.1:35037,DS-224b785b-1dd8-4cdf-904d-d2fa23534c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:37429,DS-7fd1c54d-f701-470d-b6fe-b7f21345e33b,DISK], DatanodeInfoWithStorage[127.0.0.1:33889,DS-e96915dc-d6f1-40fc-86ae-1c7ba84cc976,DISK], DatanodeInfoWithStorage[127.0.0.1:38828,DS-1533e61e-7500-41fe-b02a-7c3f7ca0ab2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1879763712-172.17.0.14-1597287732563:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33388,DS-42213962-adfa-4860-bf42-9c059b0f5a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40593,DS-cfa0781d-fa16-4060-8cb7-a2724e597e66,DISK], DatanodeInfoWithStorage[127.0.0.1:34139,DS-1f0fc269-be9e-469b-ae69-3276443fc4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45690,DS-6c532777-0d7a-4a89-b400-d5278a31afc9,DISK], DatanodeInfoWithStorage[127.0.0.1:36899,DS-bbf70eb9-1ab7-4761-be4f-cbeb1523af1b,DISK], DatanodeInfoWithStorage[127.0.0.1:37831,DS-c063fc02-428e-4c04-bb98-a966f0ffac75,DISK], DatanodeInfoWithStorage[127.0.0.1:45167,DS-c58d0117-a9e3-4311-97b1-c66cd32ee59a,DISK], DatanodeInfoWithStorage[127.0.0.1:41351,DS-9a4c8ced-3eff-4dcb-8ff0-03ae6ec67ade,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1879763712-172.17.0.14-1597287732563:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33388,DS-42213962-adfa-4860-bf42-9c059b0f5a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40593,DS-cfa0781d-fa16-4060-8cb7-a2724e597e66,DISK], DatanodeInfoWithStorage[127.0.0.1:34139,DS-1f0fc269-be9e-469b-ae69-3276443fc4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45690,DS-6c532777-0d7a-4a89-b400-d5278a31afc9,DISK], DatanodeInfoWithStorage[127.0.0.1:36899,DS-bbf70eb9-1ab7-4761-be4f-cbeb1523af1b,DISK], DatanodeInfoWithStorage[127.0.0.1:37831,DS-c063fc02-428e-4c04-bb98-a966f0ffac75,DISK], DatanodeInfoWithStorage[127.0.0.1:45167,DS-c58d0117-a9e3-4311-97b1-c66cd32ee59a,DISK], DatanodeInfoWithStorage[127.0.0.1:41351,DS-9a4c8ced-3eff-4dcb-8ff0-03ae6ec67ade,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-963023424-172.17.0.14-1597288205858:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40453,DS-f75567f8-1523-426f-8845-ee4c918b22c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34916,DS-9985cf31-df0e-457e-ac41-06bdec463898,DISK], DatanodeInfoWithStorage[127.0.0.1:44552,DS-d8e07e5c-c1a3-4cc3-a00d-1a281062e83b,DISK], DatanodeInfoWithStorage[127.0.0.1:34705,DS-a647a7d6-afd8-4281-909b-a3c8eae7b531,DISK], DatanodeInfoWithStorage[127.0.0.1:39050,DS-96023c90-db4f-46dd-a1a3-663a7aac920a,DISK], DatanodeInfoWithStorage[127.0.0.1:44923,DS-fa08da54-4253-47fe-86af-750e6b3aea7d,DISK], DatanodeInfoWithStorage[127.0.0.1:37438,DS-611a9dc5-fcf5-4952-8626-47c9d7a9c3f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40752,DS-0e29b80b-65b9-4645-8f70-2a2ede118127,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-963023424-172.17.0.14-1597288205858:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40453,DS-f75567f8-1523-426f-8845-ee4c918b22c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34916,DS-9985cf31-df0e-457e-ac41-06bdec463898,DISK], DatanodeInfoWithStorage[127.0.0.1:44552,DS-d8e07e5c-c1a3-4cc3-a00d-1a281062e83b,DISK], DatanodeInfoWithStorage[127.0.0.1:34705,DS-a647a7d6-afd8-4281-909b-a3c8eae7b531,DISK], DatanodeInfoWithStorage[127.0.0.1:39050,DS-96023c90-db4f-46dd-a1a3-663a7aac920a,DISK], DatanodeInfoWithStorage[127.0.0.1:44923,DS-fa08da54-4253-47fe-86af-750e6b3aea7d,DISK], DatanodeInfoWithStorage[127.0.0.1:37438,DS-611a9dc5-fcf5-4952-8626-47c9d7a9c3f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40752,DS-0e29b80b-65b9-4645-8f70-2a2ede118127,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1398828437-172.17.0.14-1597288443782:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42927,DS-9bd4b6f9-3fb4-4d19-bdb1-b24e9a3f9995,DISK], DatanodeInfoWithStorage[127.0.0.1:39585,DS-4731b09f-6bb2-4593-8501-6478ad72fa7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35945,DS-195b43f5-0467-473c-be08-09d15bc02705,DISK], DatanodeInfoWithStorage[127.0.0.1:44709,DS-0380d522-9a2b-47e8-ab4a-981f5d579abf,DISK], DatanodeInfoWithStorage[127.0.0.1:41448,DS-79515119-e101-4bb5-ae9f-2aed2aed4ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:33680,DS-6ded89f0-2c62-4d07-bab9-4c47f9719008,DISK], DatanodeInfoWithStorage[127.0.0.1:37608,DS-5fc0abf6-7c52-4f66-9965-bddb404a5d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:41751,DS-a0fcb725-78fe-469e-bd95-cf2afc3c6d46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1398828437-172.17.0.14-1597288443782:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42927,DS-9bd4b6f9-3fb4-4d19-bdb1-b24e9a3f9995,DISK], DatanodeInfoWithStorage[127.0.0.1:39585,DS-4731b09f-6bb2-4593-8501-6478ad72fa7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35945,DS-195b43f5-0467-473c-be08-09d15bc02705,DISK], DatanodeInfoWithStorage[127.0.0.1:44709,DS-0380d522-9a2b-47e8-ab4a-981f5d579abf,DISK], DatanodeInfoWithStorage[127.0.0.1:41448,DS-79515119-e101-4bb5-ae9f-2aed2aed4ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:33680,DS-6ded89f0-2c62-4d07-bab9-4c47f9719008,DISK], DatanodeInfoWithStorage[127.0.0.1:37608,DS-5fc0abf6-7c52-4f66-9965-bddb404a5d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:41751,DS-a0fcb725-78fe-469e-bd95-cf2afc3c6d46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-703423188-172.17.0.14-1597288642593:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39546,DS-56e06244-f3cd-4200-8bac-e7c44a82dfba,DISK], DatanodeInfoWithStorage[127.0.0.1:34129,DS-f20a8b9d-d0bd-4489-b0bd-44f1459a628c,DISK], DatanodeInfoWithStorage[127.0.0.1:45707,DS-2ead0255-263f-4bc5-935a-8aa76d6e10d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37740,DS-2480a5cd-86c4-4c3e-b8e9-fb3edd47f541,DISK], DatanodeInfoWithStorage[127.0.0.1:41851,DS-1393551f-ab0e-4ac0-a6f5-f99f929b0b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36571,DS-2654a501-a1da-4b81-93a3-0e94affc2032,DISK], DatanodeInfoWithStorage[127.0.0.1:34243,DS-c8504d73-96a1-4fa3-b61b-7933fd68b1a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33569,DS-bb34aec4-9c17-4bb8-ad17-6a00b1b34792,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-703423188-172.17.0.14-1597288642593:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39546,DS-56e06244-f3cd-4200-8bac-e7c44a82dfba,DISK], DatanodeInfoWithStorage[127.0.0.1:34129,DS-f20a8b9d-d0bd-4489-b0bd-44f1459a628c,DISK], DatanodeInfoWithStorage[127.0.0.1:45707,DS-2ead0255-263f-4bc5-935a-8aa76d6e10d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37740,DS-2480a5cd-86c4-4c3e-b8e9-fb3edd47f541,DISK], DatanodeInfoWithStorage[127.0.0.1:41851,DS-1393551f-ab0e-4ac0-a6f5-f99f929b0b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36571,DS-2654a501-a1da-4b81-93a3-0e94affc2032,DISK], DatanodeInfoWithStorage[127.0.0.1:34243,DS-c8504d73-96a1-4fa3-b61b-7933fd68b1a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33569,DS-bb34aec4-9c17-4bb8-ad17-6a00b1b34792,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2053994797-172.17.0.14-1597288680824:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46120,DS-a80cbeed-166b-4bcd-a145-7c55165d0030,DISK], DatanodeInfoWithStorage[127.0.0.1:35212,DS-c3796a65-d5ca-434f-ac81-db5a0d1c24f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41491,DS-e90eec83-b942-4b7f-b1ab-ad990a634c72,DISK], DatanodeInfoWithStorage[127.0.0.1:41215,DS-479e5358-a62f-4115-b96b-041ae22e26d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38467,DS-84ec9edf-a9b1-4125-9e67-d38308665fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:34650,DS-f148accd-1ae0-4440-add1-8b082b9e4ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:37830,DS-a0e43e06-40f3-4f63-b986-0d8b5c9b14d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40859,DS-03a2e96b-777a-42ff-a902-b4ea5ea54c48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2053994797-172.17.0.14-1597288680824:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46120,DS-a80cbeed-166b-4bcd-a145-7c55165d0030,DISK], DatanodeInfoWithStorage[127.0.0.1:35212,DS-c3796a65-d5ca-434f-ac81-db5a0d1c24f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41491,DS-e90eec83-b942-4b7f-b1ab-ad990a634c72,DISK], DatanodeInfoWithStorage[127.0.0.1:41215,DS-479e5358-a62f-4115-b96b-041ae22e26d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38467,DS-84ec9edf-a9b1-4125-9e67-d38308665fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:34650,DS-f148accd-1ae0-4440-add1-8b082b9e4ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:37830,DS-a0e43e06-40f3-4f63-b986-0d8b5c9b14d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40859,DS-03a2e96b-777a-42ff-a902-b4ea5ea54c48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-672276876-172.17.0.14-1597288879698:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42372,DS-1fb2c219-4c72-46e1-8d42-5dfdf9d1e2b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39047,DS-88e5a022-65ee-453d-85ac-bcf11dffe0b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39627,DS-a93b2fc7-771f-4b72-99fd-9aa89c33f55e,DISK], DatanodeInfoWithStorage[127.0.0.1:42793,DS-98b00025-171e-423b-9ec7-8df1f7cab30e,DISK], DatanodeInfoWithStorage[127.0.0.1:45228,DS-4f93f386-040a-4801-8fb5-298ec278bad5,DISK], DatanodeInfoWithStorage[127.0.0.1:38749,DS-9eec5787-92f9-4211-b41f-965e397a1519,DISK], DatanodeInfoWithStorage[127.0.0.1:33840,DS-9e998b07-f011-41ae-af11-1e8a703b3629,DISK], DatanodeInfoWithStorage[127.0.0.1:46341,DS-2ea75722-7957-4b02-a695-10659dc3bf17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-672276876-172.17.0.14-1597288879698:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42372,DS-1fb2c219-4c72-46e1-8d42-5dfdf9d1e2b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39047,DS-88e5a022-65ee-453d-85ac-bcf11dffe0b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39627,DS-a93b2fc7-771f-4b72-99fd-9aa89c33f55e,DISK], DatanodeInfoWithStorage[127.0.0.1:42793,DS-98b00025-171e-423b-9ec7-8df1f7cab30e,DISK], DatanodeInfoWithStorage[127.0.0.1:45228,DS-4f93f386-040a-4801-8fb5-298ec278bad5,DISK], DatanodeInfoWithStorage[127.0.0.1:38749,DS-9eec5787-92f9-4211-b41f-965e397a1519,DISK], DatanodeInfoWithStorage[127.0.0.1:33840,DS-9e998b07-f011-41ae-af11-1e8a703b3629,DISK], DatanodeInfoWithStorage[127.0.0.1:46341,DS-2ea75722-7957-4b02-a695-10659dc3bf17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-617164314-172.17.0.14-1597289051087:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35380,DS-6168e237-8070-4ed2-83ef-9cac6838f90b,DISK], DatanodeInfoWithStorage[127.0.0.1:38555,DS-d3370dc1-04ac-481c-af48-57093961272c,DISK], DatanodeInfoWithStorage[127.0.0.1:35990,DS-484799c7-0449-4a4b-aa2d-b4c670b394a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34085,DS-21865f6e-be7c-4feb-bc3c-70b72a713e31,DISK], DatanodeInfoWithStorage[127.0.0.1:38933,DS-ee10dffe-eea7-4f52-b866-696474ec9917,DISK], DatanodeInfoWithStorage[127.0.0.1:36130,DS-ec82499b-642d-4305-ad43-f5cc24fee275,DISK], DatanodeInfoWithStorage[127.0.0.1:36115,DS-6c277b6b-bee9-4753-8971-bb1acdaca6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37971,DS-a9696175-908f-4be1-b769-0d9011926c5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-617164314-172.17.0.14-1597289051087:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35380,DS-6168e237-8070-4ed2-83ef-9cac6838f90b,DISK], DatanodeInfoWithStorage[127.0.0.1:38555,DS-d3370dc1-04ac-481c-af48-57093961272c,DISK], DatanodeInfoWithStorage[127.0.0.1:35990,DS-484799c7-0449-4a4b-aa2d-b4c670b394a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34085,DS-21865f6e-be7c-4feb-bc3c-70b72a713e31,DISK], DatanodeInfoWithStorage[127.0.0.1:38933,DS-ee10dffe-eea7-4f52-b866-696474ec9917,DISK], DatanodeInfoWithStorage[127.0.0.1:36130,DS-ec82499b-642d-4305-ad43-f5cc24fee275,DISK], DatanodeInfoWithStorage[127.0.0.1:36115,DS-6c277b6b-bee9-4753-8971-bb1acdaca6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37971,DS-a9696175-908f-4be1-b769-0d9011926c5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-293589976-172.17.0.14-1597289734247:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39811,DS-e1b3771b-e1a3-49a8-b213-63faeb970458,DISK], DatanodeInfoWithStorage[127.0.0.1:35826,DS-4784cd20-1328-4633-98e8-39e55d8b3dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:36621,DS-3deb3e45-ddeb-49aa-8f26-3689202c429c,DISK], DatanodeInfoWithStorage[127.0.0.1:39263,DS-e554f273-1924-4da7-89cc-4ebe108eadcb,DISK], DatanodeInfoWithStorage[127.0.0.1:40741,DS-f5a21afd-3307-4f60-b0aa-40334fa9bf5d,DISK], DatanodeInfoWithStorage[127.0.0.1:46846,DS-ef3cbcd3-7165-4763-99af-a5627eba16e9,DISK], DatanodeInfoWithStorage[127.0.0.1:32786,DS-c4daa96a-b0db-4cb3-bcd7-47a13dec6246,DISK], DatanodeInfoWithStorage[127.0.0.1:36118,DS-b74917f2-9114-4bba-99e7-c92e45b5ac3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-293589976-172.17.0.14-1597289734247:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39811,DS-e1b3771b-e1a3-49a8-b213-63faeb970458,DISK], DatanodeInfoWithStorage[127.0.0.1:35826,DS-4784cd20-1328-4633-98e8-39e55d8b3dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:36621,DS-3deb3e45-ddeb-49aa-8f26-3689202c429c,DISK], DatanodeInfoWithStorage[127.0.0.1:39263,DS-e554f273-1924-4da7-89cc-4ebe108eadcb,DISK], DatanodeInfoWithStorage[127.0.0.1:40741,DS-f5a21afd-3307-4f60-b0aa-40334fa9bf5d,DISK], DatanodeInfoWithStorage[127.0.0.1:46846,DS-ef3cbcd3-7165-4763-99af-a5627eba16e9,DISK], DatanodeInfoWithStorage[127.0.0.1:32786,DS-c4daa96a-b0db-4cb3-bcd7-47a13dec6246,DISK], DatanodeInfoWithStorage[127.0.0.1:36118,DS-b74917f2-9114-4bba-99e7-c92e45b5ac3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5763
