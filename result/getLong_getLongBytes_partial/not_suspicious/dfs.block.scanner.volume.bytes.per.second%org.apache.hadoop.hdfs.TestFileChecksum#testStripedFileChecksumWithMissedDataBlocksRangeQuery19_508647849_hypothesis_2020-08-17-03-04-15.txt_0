reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-234110128-172.17.0.8-1597634136727:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44326,DS-1a98e73b-c871-407b-9721-19674b12888c,DISK], DatanodeInfoWithStorage[127.0.0.1:40081,DS-cc0b3c48-307a-4b33-88f5-53b9ba77fc4e,DISK], DatanodeInfoWithStorage[127.0.0.1:41274,DS-1a5e1e44-8b12-4450-b4d0-2d4b9f86e571,DISK], DatanodeInfoWithStorage[127.0.0.1:40858,DS-2b511e2b-3622-4b98-8804-ef80a22ff0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38182,DS-ce9f86db-db67-4da0-b5bc-7a31e5996eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:37464,DS-dc828bd8-3965-4ea8-b6b9-bb2dd060c9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42094,DS-4b53ddf4-7628-41e2-a482-f97c9ccbf5c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42234,DS-db021aba-957f-41aa-9966-15055acf1ccc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-234110128-172.17.0.8-1597634136727:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44326,DS-1a98e73b-c871-407b-9721-19674b12888c,DISK], DatanodeInfoWithStorage[127.0.0.1:40081,DS-cc0b3c48-307a-4b33-88f5-53b9ba77fc4e,DISK], DatanodeInfoWithStorage[127.0.0.1:41274,DS-1a5e1e44-8b12-4450-b4d0-2d4b9f86e571,DISK], DatanodeInfoWithStorage[127.0.0.1:40858,DS-2b511e2b-3622-4b98-8804-ef80a22ff0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38182,DS-ce9f86db-db67-4da0-b5bc-7a31e5996eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:37464,DS-dc828bd8-3965-4ea8-b6b9-bb2dd060c9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42094,DS-4b53ddf4-7628-41e2-a482-f97c9ccbf5c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42234,DS-db021aba-957f-41aa-9966-15055acf1ccc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-676787321-172.17.0.8-1597634551593:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42343,DS-5862c6aa-3cc6-49b2-b4aa-d6fb8946cc66,DISK], DatanodeInfoWithStorage[127.0.0.1:44212,DS-49db4a4f-c3ba-4624-9271-af217e4dfc4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38316,DS-2cbd4c61-b851-423c-8ead-40f828801a82,DISK], DatanodeInfoWithStorage[127.0.0.1:44038,DS-3f778be2-139c-4c6f-996a-dc340756c21f,DISK], DatanodeInfoWithStorage[127.0.0.1:37690,DS-7ad13d80-57b1-4063-88aa-747de9b05d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:42701,DS-921167cd-fada-47e2-8aa0-a78af329fa30,DISK], DatanodeInfoWithStorage[127.0.0.1:43280,DS-852568de-bbd5-4f53-8b9b-4faaf615f02e,DISK], DatanodeInfoWithStorage[127.0.0.1:38825,DS-2f062422-7382-45b8-ad37-5fa0f6eefae3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-676787321-172.17.0.8-1597634551593:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42343,DS-5862c6aa-3cc6-49b2-b4aa-d6fb8946cc66,DISK], DatanodeInfoWithStorage[127.0.0.1:44212,DS-49db4a4f-c3ba-4624-9271-af217e4dfc4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38316,DS-2cbd4c61-b851-423c-8ead-40f828801a82,DISK], DatanodeInfoWithStorage[127.0.0.1:44038,DS-3f778be2-139c-4c6f-996a-dc340756c21f,DISK], DatanodeInfoWithStorage[127.0.0.1:37690,DS-7ad13d80-57b1-4063-88aa-747de9b05d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:42701,DS-921167cd-fada-47e2-8aa0-a78af329fa30,DISK], DatanodeInfoWithStorage[127.0.0.1:43280,DS-852568de-bbd5-4f53-8b9b-4faaf615f02e,DISK], DatanodeInfoWithStorage[127.0.0.1:38825,DS-2f062422-7382-45b8-ad37-5fa0f6eefae3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1174639839-172.17.0.8-1597634623901:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35438,DS-ee1a0562-cbea-4554-ad7d-4ff2fab2b264,DISK], DatanodeInfoWithStorage[127.0.0.1:38890,DS-fd381caa-a0ec-4466-84c7-c6b5df47c18f,DISK], DatanodeInfoWithStorage[127.0.0.1:39107,DS-8eddbebf-b831-44af-b9bb-6f0c5e0bcee4,DISK], DatanodeInfoWithStorage[127.0.0.1:41639,DS-94aee9e5-4229-4fb7-9529-866f2ae595b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44329,DS-9c291203-e664-47d5-9850-7dce5dceb5e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36644,DS-7a43e060-03e7-4970-ae25-ef0699c3d360,DISK], DatanodeInfoWithStorage[127.0.0.1:39439,DS-f853acf4-4e10-4699-abda-074fd7d504d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37337,DS-28cdec53-c56b-4323-80ba-48832250958a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1174639839-172.17.0.8-1597634623901:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35438,DS-ee1a0562-cbea-4554-ad7d-4ff2fab2b264,DISK], DatanodeInfoWithStorage[127.0.0.1:38890,DS-fd381caa-a0ec-4466-84c7-c6b5df47c18f,DISK], DatanodeInfoWithStorage[127.0.0.1:39107,DS-8eddbebf-b831-44af-b9bb-6f0c5e0bcee4,DISK], DatanodeInfoWithStorage[127.0.0.1:41639,DS-94aee9e5-4229-4fb7-9529-866f2ae595b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44329,DS-9c291203-e664-47d5-9850-7dce5dceb5e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36644,DS-7a43e060-03e7-4970-ae25-ef0699c3d360,DISK], DatanodeInfoWithStorage[127.0.0.1:39439,DS-f853acf4-4e10-4699-abda-074fd7d504d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37337,DS-28cdec53-c56b-4323-80ba-48832250958a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-592645460-172.17.0.8-1597634695037:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45238,DS-52805d5b-0e9f-4b48-ba70-fb9217d67604,DISK], DatanodeInfoWithStorage[127.0.0.1:42974,DS-e0a401ec-112d-417a-9bfd-23de293ea2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35579,DS-1cb3bf78-4309-41b6-83c5-5216ce7d5933,DISK], DatanodeInfoWithStorage[127.0.0.1:40730,DS-1387701b-a78c-444a-a873-3426bb65985d,DISK], DatanodeInfoWithStorage[127.0.0.1:46608,DS-9edc0ce5-2d6a-4d36-978a-eae3ffacad07,DISK], DatanodeInfoWithStorage[127.0.0.1:42102,DS-f3f36e5f-bac8-4c87-87c1-024d0da72c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34419,DS-9d08504c-97a5-41d7-943d-a526fc417cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:40759,DS-9a51a1aa-1bcc-4102-94cd-b00fd1c39ed1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-592645460-172.17.0.8-1597634695037:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45238,DS-52805d5b-0e9f-4b48-ba70-fb9217d67604,DISK], DatanodeInfoWithStorage[127.0.0.1:42974,DS-e0a401ec-112d-417a-9bfd-23de293ea2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35579,DS-1cb3bf78-4309-41b6-83c5-5216ce7d5933,DISK], DatanodeInfoWithStorage[127.0.0.1:40730,DS-1387701b-a78c-444a-a873-3426bb65985d,DISK], DatanodeInfoWithStorage[127.0.0.1:46608,DS-9edc0ce5-2d6a-4d36-978a-eae3ffacad07,DISK], DatanodeInfoWithStorage[127.0.0.1:42102,DS-f3f36e5f-bac8-4c87-87c1-024d0da72c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34419,DS-9d08504c-97a5-41d7-943d-a526fc417cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:40759,DS-9a51a1aa-1bcc-4102-94cd-b00fd1c39ed1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2101760986-172.17.0.8-1597634802059:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44859,DS-0af87683-a431-4a06-ad9f-58b460499516,DISK], DatanodeInfoWithStorage[127.0.0.1:45700,DS-0956347b-e481-42fa-842a-671455b18af5,DISK], DatanodeInfoWithStorage[127.0.0.1:33130,DS-31f68ce0-25c8-429b-84b9-df94ccdb2262,DISK], DatanodeInfoWithStorage[127.0.0.1:38419,DS-5c782047-b630-4113-8239-79486d571cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:37291,DS-f7c8744c-aba6-49fd-8f77-e72cd7b896a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45232,DS-51b0e5b9-80e0-40ac-b930-b5a6ad82f40c,DISK], DatanodeInfoWithStorage[127.0.0.1:43486,DS-37caf743-8771-4af0-8160-5fc74345ed54,DISK], DatanodeInfoWithStorage[127.0.0.1:34004,DS-b5afd03d-acae-464a-b4a3-19aa855a8cf6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2101760986-172.17.0.8-1597634802059:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44859,DS-0af87683-a431-4a06-ad9f-58b460499516,DISK], DatanodeInfoWithStorage[127.0.0.1:45700,DS-0956347b-e481-42fa-842a-671455b18af5,DISK], DatanodeInfoWithStorage[127.0.0.1:33130,DS-31f68ce0-25c8-429b-84b9-df94ccdb2262,DISK], DatanodeInfoWithStorage[127.0.0.1:38419,DS-5c782047-b630-4113-8239-79486d571cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:37291,DS-f7c8744c-aba6-49fd-8f77-e72cd7b896a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45232,DS-51b0e5b9-80e0-40ac-b930-b5a6ad82f40c,DISK], DatanodeInfoWithStorage[127.0.0.1:43486,DS-37caf743-8771-4af0-8160-5fc74345ed54,DISK], DatanodeInfoWithStorage[127.0.0.1:34004,DS-b5afd03d-acae-464a-b4a3-19aa855a8cf6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-765314356-172.17.0.8-1597635369751:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36406,DS-2eaf2927-1162-49e0-8d35-a14c65a82616,DISK], DatanodeInfoWithStorage[127.0.0.1:45031,DS-347c9f8d-0edd-4f04-ab59-a5eb90ee53b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40601,DS-2be5b668-0fd6-44df-81e2-3e2b76f61816,DISK], DatanodeInfoWithStorage[127.0.0.1:36824,DS-5bec9158-a175-4b55-a16f-9e0d50fe61a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42087,DS-c7ca1825-e3b2-4baf-a5e2-ce0a63641c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:38877,DS-3839876f-7892-4477-aab9-93acaf17f8cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33466,DS-eafb0018-e42d-4892-85d0-c6ad65a99e26,DISK], DatanodeInfoWithStorage[127.0.0.1:39715,DS-465d1940-2e07-47c1-b1f6-f504627d6515,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-765314356-172.17.0.8-1597635369751:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36406,DS-2eaf2927-1162-49e0-8d35-a14c65a82616,DISK], DatanodeInfoWithStorage[127.0.0.1:45031,DS-347c9f8d-0edd-4f04-ab59-a5eb90ee53b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40601,DS-2be5b668-0fd6-44df-81e2-3e2b76f61816,DISK], DatanodeInfoWithStorage[127.0.0.1:36824,DS-5bec9158-a175-4b55-a16f-9e0d50fe61a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42087,DS-c7ca1825-e3b2-4baf-a5e2-ce0a63641c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:38877,DS-3839876f-7892-4477-aab9-93acaf17f8cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33466,DS-eafb0018-e42d-4892-85d0-c6ad65a99e26,DISK], DatanodeInfoWithStorage[127.0.0.1:39715,DS-465d1940-2e07-47c1-b1f6-f504627d6515,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-708213898-172.17.0.8-1597636105077:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38329,DS-55b057a5-0514-4a9b-a7a8-802f3dddf476,DISK], DatanodeInfoWithStorage[127.0.0.1:38031,DS-2cfe1854-ed06-4455-94b2-a79a154bab72,DISK], DatanodeInfoWithStorage[127.0.0.1:35590,DS-59dfb5df-732d-4708-9bd8-5191be6f86e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44903,DS-17d64079-3b58-4a3f-89f2-85d2622dfd70,DISK], DatanodeInfoWithStorage[127.0.0.1:43673,DS-4fb1f56a-1baf-4a13-b24e-95e015850023,DISK], DatanodeInfoWithStorage[127.0.0.1:34813,DS-dd9d9c7d-c906-403e-85b9-74e43b254f16,DISK], DatanodeInfoWithStorage[127.0.0.1:33229,DS-c50f0dbd-2e4e-4f6c-b945-4d05c412cf5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40590,DS-cf0a2f6c-8b13-405b-b8f7-91942674916c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-708213898-172.17.0.8-1597636105077:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38329,DS-55b057a5-0514-4a9b-a7a8-802f3dddf476,DISK], DatanodeInfoWithStorage[127.0.0.1:38031,DS-2cfe1854-ed06-4455-94b2-a79a154bab72,DISK], DatanodeInfoWithStorage[127.0.0.1:35590,DS-59dfb5df-732d-4708-9bd8-5191be6f86e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44903,DS-17d64079-3b58-4a3f-89f2-85d2622dfd70,DISK], DatanodeInfoWithStorage[127.0.0.1:43673,DS-4fb1f56a-1baf-4a13-b24e-95e015850023,DISK], DatanodeInfoWithStorage[127.0.0.1:34813,DS-dd9d9c7d-c906-403e-85b9-74e43b254f16,DISK], DatanodeInfoWithStorage[127.0.0.1:33229,DS-c50f0dbd-2e4e-4f6c-b945-4d05c412cf5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40590,DS-cf0a2f6c-8b13-405b-b8f7-91942674916c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-870189336-172.17.0.8-1597636356337:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37921,DS-0745f281-ade3-442a-90e3-904015578afe,DISK], DatanodeInfoWithStorage[127.0.0.1:35404,DS-3b146011-cd22-4adc-9cfa-0bc3a5580593,DISK], DatanodeInfoWithStorage[127.0.0.1:45978,DS-b1625296-bd8d-414d-bc13-b64b9e05d5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35356,DS-f092c492-e0c1-466f-bd90-cdd5d8f39c17,DISK], DatanodeInfoWithStorage[127.0.0.1:45504,DS-6a4c6c03-8ab3-454a-aaf5-ee70f3fb16c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34083,DS-8963bb05-a42e-4f1e-be51-5b14b5509296,DISK], DatanodeInfoWithStorage[127.0.0.1:38468,DS-b1db8145-104d-43a5-a1d8-90237b6f8daa,DISK], DatanodeInfoWithStorage[127.0.0.1:45009,DS-990b85e8-e918-4051-ba26-3534ee3f6eb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-870189336-172.17.0.8-1597636356337:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37921,DS-0745f281-ade3-442a-90e3-904015578afe,DISK], DatanodeInfoWithStorage[127.0.0.1:35404,DS-3b146011-cd22-4adc-9cfa-0bc3a5580593,DISK], DatanodeInfoWithStorage[127.0.0.1:45978,DS-b1625296-bd8d-414d-bc13-b64b9e05d5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35356,DS-f092c492-e0c1-466f-bd90-cdd5d8f39c17,DISK], DatanodeInfoWithStorage[127.0.0.1:45504,DS-6a4c6c03-8ab3-454a-aaf5-ee70f3fb16c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34083,DS-8963bb05-a42e-4f1e-be51-5b14b5509296,DISK], DatanodeInfoWithStorage[127.0.0.1:38468,DS-b1db8145-104d-43a5-a1d8-90237b6f8daa,DISK], DatanodeInfoWithStorage[127.0.0.1:45009,DS-990b85e8-e918-4051-ba26-3534ee3f6eb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-370205778-172.17.0.8-1597636538350:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37533,DS-ca6fe57b-d112-4832-8f80-3e97bf9fe25d,DISK], DatanodeInfoWithStorage[127.0.0.1:41386,DS-42a42301-338f-4901-a720-e43b640a455b,DISK], DatanodeInfoWithStorage[127.0.0.1:41285,DS-52701cf5-04a4-4083-8be0-883410177200,DISK], DatanodeInfoWithStorage[127.0.0.1:34832,DS-1371672f-ef21-4c7c-b234-6aa8c87273b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33519,DS-ca790cb1-1b43-4e32-8c53-5498f3106f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:36681,DS-9323357e-2930-43db-9823-69bb17acfeb2,DISK], DatanodeInfoWithStorage[127.0.0.1:35244,DS-caa05de3-5ce0-4379-a643-f58299ab848d,DISK], DatanodeInfoWithStorage[127.0.0.1:41539,DS-95437226-5d72-4123-a7ba-f79a20d6732f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-370205778-172.17.0.8-1597636538350:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37533,DS-ca6fe57b-d112-4832-8f80-3e97bf9fe25d,DISK], DatanodeInfoWithStorage[127.0.0.1:41386,DS-42a42301-338f-4901-a720-e43b640a455b,DISK], DatanodeInfoWithStorage[127.0.0.1:41285,DS-52701cf5-04a4-4083-8be0-883410177200,DISK], DatanodeInfoWithStorage[127.0.0.1:34832,DS-1371672f-ef21-4c7c-b234-6aa8c87273b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33519,DS-ca790cb1-1b43-4e32-8c53-5498f3106f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:36681,DS-9323357e-2930-43db-9823-69bb17acfeb2,DISK], DatanodeInfoWithStorage[127.0.0.1:35244,DS-caa05de3-5ce0-4379-a643-f58299ab848d,DISK], DatanodeInfoWithStorage[127.0.0.1:41539,DS-95437226-5d72-4123-a7ba-f79a20d6732f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-272012706-172.17.0.8-1597636609422:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40142,DS-e4422c48-d7a5-4d78-b06d-1e6e5c5f9d99,DISK], DatanodeInfoWithStorage[127.0.0.1:41555,DS-cf0761b0-11d8-4439-a964-32e4d6704c66,DISK], DatanodeInfoWithStorage[127.0.0.1:41780,DS-be74300b-89ef-40e5-8584-2aeb61e5a953,DISK], DatanodeInfoWithStorage[127.0.0.1:46322,DS-62814927-099a-4460-91a6-4f24384bb0bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46266,DS-1182b96a-bc36-4022-9d93-fcde1eca2e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:34713,DS-c29b3f49-9b68-4aee-8fd7-1de86194c9d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44296,DS-903a54a8-0016-4c0f-b6e9-7059e79ad957,DISK], DatanodeInfoWithStorage[127.0.0.1:33556,DS-56a912ef-b2d1-4006-8ca3-a77f8be0a40f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-272012706-172.17.0.8-1597636609422:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40142,DS-e4422c48-d7a5-4d78-b06d-1e6e5c5f9d99,DISK], DatanodeInfoWithStorage[127.0.0.1:41555,DS-cf0761b0-11d8-4439-a964-32e4d6704c66,DISK], DatanodeInfoWithStorage[127.0.0.1:41780,DS-be74300b-89ef-40e5-8584-2aeb61e5a953,DISK], DatanodeInfoWithStorage[127.0.0.1:46322,DS-62814927-099a-4460-91a6-4f24384bb0bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46266,DS-1182b96a-bc36-4022-9d93-fcde1eca2e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:34713,DS-c29b3f49-9b68-4aee-8fd7-1de86194c9d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44296,DS-903a54a8-0016-4c0f-b6e9-7059e79ad957,DISK], DatanodeInfoWithStorage[127.0.0.1:33556,DS-56a912ef-b2d1-4006-8ca3-a77f8be0a40f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-93765828-172.17.0.8-1597636682539:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37069,DS-dc0b083a-bdf5-483a-83b9-76a29026698f,DISK], DatanodeInfoWithStorage[127.0.0.1:41742,DS-729c0b54-30b2-4fc7-8823-ca232d3a58f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45913,DS-60dc2578-c1c5-4711-9784-2e8bc71515d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43565,DS-5a7559a3-5c3f-4d6e-914b-e8692cc0dd52,DISK], DatanodeInfoWithStorage[127.0.0.1:42828,DS-578d1f7c-450c-4198-80cc-237ee38de9d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36730,DS-5de549ee-0160-4b8f-bf2c-5c57d9b9dc07,DISK], DatanodeInfoWithStorage[127.0.0.1:38933,DS-72eecb8b-4b71-4145-8c8a-70cdc8670efd,DISK], DatanodeInfoWithStorage[127.0.0.1:42109,DS-2f10fcf7-2328-46fa-a287-b720b10cbad6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-93765828-172.17.0.8-1597636682539:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37069,DS-dc0b083a-bdf5-483a-83b9-76a29026698f,DISK], DatanodeInfoWithStorage[127.0.0.1:41742,DS-729c0b54-30b2-4fc7-8823-ca232d3a58f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45913,DS-60dc2578-c1c5-4711-9784-2e8bc71515d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43565,DS-5a7559a3-5c3f-4d6e-914b-e8692cc0dd52,DISK], DatanodeInfoWithStorage[127.0.0.1:42828,DS-578d1f7c-450c-4198-80cc-237ee38de9d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36730,DS-5de549ee-0160-4b8f-bf2c-5c57d9b9dc07,DISK], DatanodeInfoWithStorage[127.0.0.1:38933,DS-72eecb8b-4b71-4145-8c8a-70cdc8670efd,DISK], DatanodeInfoWithStorage[127.0.0.1:42109,DS-2f10fcf7-2328-46fa-a287-b720b10cbad6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-593285555-172.17.0.8-1597637103064:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34902,DS-a507e1d4-3423-46cd-8863-cf803fda70f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43243,DS-f30a007c-0c17-46b2-8fff-a7d69874db72,DISK], DatanodeInfoWithStorage[127.0.0.1:41084,DS-66930734-0394-4099-bee2-0cac75e65edf,DISK], DatanodeInfoWithStorage[127.0.0.1:39090,DS-772dad4c-9c31-4fda-880a-1a4dc9a7ea87,DISK], DatanodeInfoWithStorage[127.0.0.1:36856,DS-7bf13240-f091-47d7-9406-bb4747f2a003,DISK], DatanodeInfoWithStorage[127.0.0.1:35499,DS-e8d58ef3-4a2e-4ce7-82f8-506b55d2830c,DISK], DatanodeInfoWithStorage[127.0.0.1:44394,DS-7f1a7192-c76b-450d-ab71-6a37064925a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44769,DS-52ac4567-bf74-446b-8e3c-e95ad71b80f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-593285555-172.17.0.8-1597637103064:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34902,DS-a507e1d4-3423-46cd-8863-cf803fda70f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43243,DS-f30a007c-0c17-46b2-8fff-a7d69874db72,DISK], DatanodeInfoWithStorage[127.0.0.1:41084,DS-66930734-0394-4099-bee2-0cac75e65edf,DISK], DatanodeInfoWithStorage[127.0.0.1:39090,DS-772dad4c-9c31-4fda-880a-1a4dc9a7ea87,DISK], DatanodeInfoWithStorage[127.0.0.1:36856,DS-7bf13240-f091-47d7-9406-bb4747f2a003,DISK], DatanodeInfoWithStorage[127.0.0.1:35499,DS-e8d58ef3-4a2e-4ce7-82f8-506b55d2830c,DISK], DatanodeInfoWithStorage[127.0.0.1:44394,DS-7f1a7192-c76b-450d-ab71-6a37064925a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44769,DS-52ac4567-bf74-446b-8e3c-e95ad71b80f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-533586820-172.17.0.8-1597637177956:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38789,DS-f2a11fbe-29bd-4a3d-9a66-53f2be9b3580,DISK], DatanodeInfoWithStorage[127.0.0.1:40693,DS-83c7804f-a1fa-4d4c-bf56-6ec4b991d3e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40439,DS-954987f3-066c-4ae9-92b7-d9a8476d57e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43702,DS-cb55def1-0ed6-4b5c-bc99-bce22546df24,DISK], DatanodeInfoWithStorage[127.0.0.1:41870,DS-d75ef992-cc9a-4a33-a22e-f3ec983ffdf7,DISK], DatanodeInfoWithStorage[127.0.0.1:41642,DS-b9d9791b-068d-40a6-9b88-95672fc36705,DISK], DatanodeInfoWithStorage[127.0.0.1:34594,DS-3f206261-30d2-4178-8abd-4d2c77c066ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41171,DS-511e1e05-4e5f-43bb-afaa-92590464d468,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-533586820-172.17.0.8-1597637177956:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38789,DS-f2a11fbe-29bd-4a3d-9a66-53f2be9b3580,DISK], DatanodeInfoWithStorage[127.0.0.1:40693,DS-83c7804f-a1fa-4d4c-bf56-6ec4b991d3e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40439,DS-954987f3-066c-4ae9-92b7-d9a8476d57e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43702,DS-cb55def1-0ed6-4b5c-bc99-bce22546df24,DISK], DatanodeInfoWithStorage[127.0.0.1:41870,DS-d75ef992-cc9a-4a33-a22e-f3ec983ffdf7,DISK], DatanodeInfoWithStorage[127.0.0.1:41642,DS-b9d9791b-068d-40a6-9b88-95672fc36705,DISK], DatanodeInfoWithStorage[127.0.0.1:34594,DS-3f206261-30d2-4178-8abd-4d2c77c066ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41171,DS-511e1e05-4e5f-43bb-afaa-92590464d468,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-973909453-172.17.0.8-1597637422993:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40167,DS-6db8b2df-d2a9-47be-b108-36368c7b0b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:45379,DS-7192da61-a628-4bfe-b5f1-e582340830e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40552,DS-ca7925a7-8689-435f-a189-53b635977e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33000,DS-03590496-ad1d-45b6-a93e-e758a5eb2ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:40511,DS-977eac10-9dbe-4df1-b1e5-e7937116a5cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46363,DS-a997ef78-85d9-413d-bdfb-3cb241337e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:46448,DS-a9299816-da19-4420-9267-c550a589a720,DISK], DatanodeInfoWithStorage[127.0.0.1:44221,DS-e209fe3c-4835-4a7f-baed-415a7a00d207,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-973909453-172.17.0.8-1597637422993:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40167,DS-6db8b2df-d2a9-47be-b108-36368c7b0b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:45379,DS-7192da61-a628-4bfe-b5f1-e582340830e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40552,DS-ca7925a7-8689-435f-a189-53b635977e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33000,DS-03590496-ad1d-45b6-a93e-e758a5eb2ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:40511,DS-977eac10-9dbe-4df1-b1e5-e7937116a5cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46363,DS-a997ef78-85d9-413d-bdfb-3cb241337e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:46448,DS-a9299816-da19-4420-9267-c550a589a720,DISK], DatanodeInfoWithStorage[127.0.0.1:44221,DS-e209fe3c-4835-4a7f-baed-415a7a00d207,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-120064757-172.17.0.8-1597637603798:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42523,DS-08e7a26e-2eb5-4323-99cb-0fef0ed34ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:41717,DS-e94deb86-eba9-4bf9-b336-3d65d27da2c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33896,DS-c1769d75-8b7c-4f7f-b9d6-360e919b4e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:34477,DS-1d202d4c-adf7-46ca-82e9-1c69e8d3c4a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33334,DS-53ee47a4-a3ea-4b39-a6f1-a5152feb5839,DISK], DatanodeInfoWithStorage[127.0.0.1:38714,DS-b0c21b62-e023-4045-8110-81c3e6195aef,DISK], DatanodeInfoWithStorage[127.0.0.1:44317,DS-50866e24-956c-4cde-8ad8-2b7ab2d94a20,DISK], DatanodeInfoWithStorage[127.0.0.1:35228,DS-3d9ce2ce-2186-4419-9717-e19db981d0de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-120064757-172.17.0.8-1597637603798:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42523,DS-08e7a26e-2eb5-4323-99cb-0fef0ed34ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:41717,DS-e94deb86-eba9-4bf9-b336-3d65d27da2c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33896,DS-c1769d75-8b7c-4f7f-b9d6-360e919b4e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:34477,DS-1d202d4c-adf7-46ca-82e9-1c69e8d3c4a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33334,DS-53ee47a4-a3ea-4b39-a6f1-a5152feb5839,DISK], DatanodeInfoWithStorage[127.0.0.1:38714,DS-b0c21b62-e023-4045-8110-81c3e6195aef,DISK], DatanodeInfoWithStorage[127.0.0.1:44317,DS-50866e24-956c-4cde-8ad8-2b7ab2d94a20,DISK], DatanodeInfoWithStorage[127.0.0.1:35228,DS-3d9ce2ce-2186-4419-9717-e19db981d0de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1758774782-172.17.0.8-1597637636086:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32981,DS-3ea926dd-6f3f-435e-8557-be634d3eb789,DISK], DatanodeInfoWithStorage[127.0.0.1:46234,DS-c8f39b06-1cb8-43d2-b741-8fc7212835c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35605,DS-b07cae0a-5c13-4eba-a4e0-b71a0b519660,DISK], DatanodeInfoWithStorage[127.0.0.1:38258,DS-2663fab5-b5bc-4437-9a5a-24efd7e3b950,DISK], DatanodeInfoWithStorage[127.0.0.1:40168,DS-4eed0728-2196-4c1d-83d2-6153160bf58e,DISK], DatanodeInfoWithStorage[127.0.0.1:37527,DS-97e7bc24-4445-40cc-b403-9f93a55d158a,DISK], DatanodeInfoWithStorage[127.0.0.1:38233,DS-4a83395f-1c10-45cb-aab3-5275ac2a3cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:36939,DS-92790140-86bd-4508-887c-4480f2e95939,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1758774782-172.17.0.8-1597637636086:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32981,DS-3ea926dd-6f3f-435e-8557-be634d3eb789,DISK], DatanodeInfoWithStorage[127.0.0.1:46234,DS-c8f39b06-1cb8-43d2-b741-8fc7212835c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35605,DS-b07cae0a-5c13-4eba-a4e0-b71a0b519660,DISK], DatanodeInfoWithStorage[127.0.0.1:38258,DS-2663fab5-b5bc-4437-9a5a-24efd7e3b950,DISK], DatanodeInfoWithStorage[127.0.0.1:40168,DS-4eed0728-2196-4c1d-83d2-6153160bf58e,DISK], DatanodeInfoWithStorage[127.0.0.1:37527,DS-97e7bc24-4445-40cc-b403-9f93a55d158a,DISK], DatanodeInfoWithStorage[127.0.0.1:38233,DS-4a83395f-1c10-45cb-aab3-5275ac2a3cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:36939,DS-92790140-86bd-4508-887c-4480f2e95939,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-56302320-172.17.0.8-1597637826142:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39182,DS-48506794-f795-44bc-a8ea-764b5e1ceb9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43585,DS-3201cee9-be93-47c1-a37f-86e1aa61e7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38601,DS-2058b2b6-8ddb-44e6-acc5-4c3901592e56,DISK], DatanodeInfoWithStorage[127.0.0.1:37387,DS-49c47668-7368-4c7d-a4e5-93e8cc86c0cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42130,DS-04dfa450-f296-4e05-8d66-67bfe4a07673,DISK], DatanodeInfoWithStorage[127.0.0.1:42184,DS-a398c0e1-a962-42ae-abea-3625fd933574,DISK], DatanodeInfoWithStorage[127.0.0.1:43272,DS-1622949d-90e3-42de-80c2-83901cc21ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:37345,DS-ab0b7b53-3a19-4a0d-95e2-f6733847fbfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-56302320-172.17.0.8-1597637826142:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39182,DS-48506794-f795-44bc-a8ea-764b5e1ceb9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43585,DS-3201cee9-be93-47c1-a37f-86e1aa61e7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38601,DS-2058b2b6-8ddb-44e6-acc5-4c3901592e56,DISK], DatanodeInfoWithStorage[127.0.0.1:37387,DS-49c47668-7368-4c7d-a4e5-93e8cc86c0cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42130,DS-04dfa450-f296-4e05-8d66-67bfe4a07673,DISK], DatanodeInfoWithStorage[127.0.0.1:42184,DS-a398c0e1-a962-42ae-abea-3625fd933574,DISK], DatanodeInfoWithStorage[127.0.0.1:43272,DS-1622949d-90e3-42de-80c2-83901cc21ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:37345,DS-ab0b7b53-3a19-4a0d-95e2-f6733847fbfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1320052766-172.17.0.8-1597637863875:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43306,DS-04a9b49f-9acc-4456-9687-162c96bac085,DISK], DatanodeInfoWithStorage[127.0.0.1:43479,DS-e13f606d-d0d1-4610-b352-4b51bc40db2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33446,DS-c3ac0e05-1f2b-481f-8105-0ef55121d332,DISK], DatanodeInfoWithStorage[127.0.0.1:36528,DS-30d46a75-5627-416e-92ea-e87e1a29e69a,DISK], DatanodeInfoWithStorage[127.0.0.1:34341,DS-d5d6b9f7-ef8c-4ea2-b847-bc95ae747711,DISK], DatanodeInfoWithStorage[127.0.0.1:38216,DS-dee08849-be84-4e20-8f91-da788665dae8,DISK], DatanodeInfoWithStorage[127.0.0.1:33107,DS-e45e6c4f-3785-4cd1-8495-c8e76b6c4b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:42720,DS-456ae2e9-1278-4b3c-a866-ce7cbfc01b29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1320052766-172.17.0.8-1597637863875:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43306,DS-04a9b49f-9acc-4456-9687-162c96bac085,DISK], DatanodeInfoWithStorage[127.0.0.1:43479,DS-e13f606d-d0d1-4610-b352-4b51bc40db2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33446,DS-c3ac0e05-1f2b-481f-8105-0ef55121d332,DISK], DatanodeInfoWithStorage[127.0.0.1:36528,DS-30d46a75-5627-416e-92ea-e87e1a29e69a,DISK], DatanodeInfoWithStorage[127.0.0.1:34341,DS-d5d6b9f7-ef8c-4ea2-b847-bc95ae747711,DISK], DatanodeInfoWithStorage[127.0.0.1:38216,DS-dee08849-be84-4e20-8f91-da788665dae8,DISK], DatanodeInfoWithStorage[127.0.0.1:33107,DS-e45e6c4f-3785-4cd1-8495-c8e76b6c4b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:42720,DS-456ae2e9-1278-4b3c-a866-ce7cbfc01b29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5351
