reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1184771667-172.17.0.6-1597635757644:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43126,DS-ea688468-e560-40b8-8ab0-0fb59413478f,DISK], DatanodeInfoWithStorage[127.0.0.1:40204,DS-3b7f91a0-35df-4b93-95ae-7ea173b2fec7,DISK], DatanodeInfoWithStorage[127.0.0.1:42557,DS-2c5b62d4-8e83-4327-8c38-be5c8b9afa92,DISK], DatanodeInfoWithStorage[127.0.0.1:41897,DS-061a9272-cab1-4c3f-afc8-bc27d41ea703,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-d9baaf67-11d6-42a9-a713-aebeeff7a053,DISK], DatanodeInfoWithStorage[127.0.0.1:33844,DS-5e605d32-0d71-4ed7-b2e6-a88dd9702ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:46148,DS-1083cfcb-3517-415b-b4b3-2b208d2bec14,DISK], DatanodeInfoWithStorage[127.0.0.1:45954,DS-abb3aef0-88bf-40ac-b68a-8c4f710ce60c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1184771667-172.17.0.6-1597635757644:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43126,DS-ea688468-e560-40b8-8ab0-0fb59413478f,DISK], DatanodeInfoWithStorage[127.0.0.1:40204,DS-3b7f91a0-35df-4b93-95ae-7ea173b2fec7,DISK], DatanodeInfoWithStorage[127.0.0.1:42557,DS-2c5b62d4-8e83-4327-8c38-be5c8b9afa92,DISK], DatanodeInfoWithStorage[127.0.0.1:41897,DS-061a9272-cab1-4c3f-afc8-bc27d41ea703,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-d9baaf67-11d6-42a9-a713-aebeeff7a053,DISK], DatanodeInfoWithStorage[127.0.0.1:33844,DS-5e605d32-0d71-4ed7-b2e6-a88dd9702ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:46148,DS-1083cfcb-3517-415b-b4b3-2b208d2bec14,DISK], DatanodeInfoWithStorage[127.0.0.1:45954,DS-abb3aef0-88bf-40ac-b68a-8c4f710ce60c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-69418181-172.17.0.6-1597636160869:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34350,DS-9e2c8b05-cda8-4a3a-b4a2-288d7cbd6beb,DISK], DatanodeInfoWithStorage[127.0.0.1:33846,DS-895eb724-3a8b-4d60-80b3-c44d86f533f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43680,DS-130ba4a7-0176-4de2-9066-3aaa3329b869,DISK], DatanodeInfoWithStorage[127.0.0.1:36503,DS-97859d8c-4c22-4de8-9818-0a7558d649b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35921,DS-69efd17a-d6a4-41fa-8f5f-021d55f607d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45529,DS-6c7dcb58-8754-4537-9b29-ebbb358f97c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44496,DS-94f34433-44a5-47fe-a804-6eff79e09146,DISK], DatanodeInfoWithStorage[127.0.0.1:38504,DS-bcc0a71e-4de2-41e3-a8cd-8b48d423b499,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-69418181-172.17.0.6-1597636160869:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34350,DS-9e2c8b05-cda8-4a3a-b4a2-288d7cbd6beb,DISK], DatanodeInfoWithStorage[127.0.0.1:33846,DS-895eb724-3a8b-4d60-80b3-c44d86f533f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43680,DS-130ba4a7-0176-4de2-9066-3aaa3329b869,DISK], DatanodeInfoWithStorage[127.0.0.1:36503,DS-97859d8c-4c22-4de8-9818-0a7558d649b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35921,DS-69efd17a-d6a4-41fa-8f5f-021d55f607d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45529,DS-6c7dcb58-8754-4537-9b29-ebbb358f97c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44496,DS-94f34433-44a5-47fe-a804-6eff79e09146,DISK], DatanodeInfoWithStorage[127.0.0.1:38504,DS-bcc0a71e-4de2-41e3-a8cd-8b48d423b499,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1822908990-172.17.0.6-1597636508025:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43853,DS-4d6a3751-073a-4a50-a5ba-8d156eb838ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42204,DS-b4ab2463-33fc-4a0b-86b3-f85c6fabe4c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41967,DS-4b96bed1-3f68-43ed-b5df-5b94ac15ff29,DISK], DatanodeInfoWithStorage[127.0.0.1:35801,DS-2cfc0c78-3b3a-438b-8da6-4947d7335547,DISK], DatanodeInfoWithStorage[127.0.0.1:37275,DS-791ee117-b83d-4694-ad82-f573b5cbd870,DISK], DatanodeInfoWithStorage[127.0.0.1:43354,DS-146438ee-ac5b-4352-a358-214e206f3c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39050,DS-dd1405d1-b05f-4e9f-8b7d-6ab83800b5e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-32e3d070-f87e-447f-bb28-56916d295d81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1822908990-172.17.0.6-1597636508025:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43853,DS-4d6a3751-073a-4a50-a5ba-8d156eb838ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42204,DS-b4ab2463-33fc-4a0b-86b3-f85c6fabe4c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41967,DS-4b96bed1-3f68-43ed-b5df-5b94ac15ff29,DISK], DatanodeInfoWithStorage[127.0.0.1:35801,DS-2cfc0c78-3b3a-438b-8da6-4947d7335547,DISK], DatanodeInfoWithStorage[127.0.0.1:37275,DS-791ee117-b83d-4694-ad82-f573b5cbd870,DISK], DatanodeInfoWithStorage[127.0.0.1:43354,DS-146438ee-ac5b-4352-a358-214e206f3c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39050,DS-dd1405d1-b05f-4e9f-8b7d-6ab83800b5e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-32e3d070-f87e-447f-bb28-56916d295d81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1752169861-172.17.0.6-1597636621988:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45959,DS-2193fd72-3c49-45b6-a700-e27b22742b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:44453,DS-2d2932ea-c819-423d-bb5e-0da9b14707ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44534,DS-d3a2e6ba-085c-4d76-8eda-58be401095ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33416,DS-16d9f5f6-274a-4001-b92a-0c92d83d6890,DISK], DatanodeInfoWithStorage[127.0.0.1:40019,DS-37e869e8-4362-4ee0-8414-060ad8678f86,DISK], DatanodeInfoWithStorage[127.0.0.1:45838,DS-1a6f4e73-2466-4348-a275-65dc6b0773e2,DISK], DatanodeInfoWithStorage[127.0.0.1:32966,DS-61a211be-1a1f-4678-9f44-4f8a5a9e5745,DISK], DatanodeInfoWithStorage[127.0.0.1:39641,DS-69c27db6-1c1a-421c-afd6-372037251a74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1752169861-172.17.0.6-1597636621988:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45959,DS-2193fd72-3c49-45b6-a700-e27b22742b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:44453,DS-2d2932ea-c819-423d-bb5e-0da9b14707ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44534,DS-d3a2e6ba-085c-4d76-8eda-58be401095ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33416,DS-16d9f5f6-274a-4001-b92a-0c92d83d6890,DISK], DatanodeInfoWithStorage[127.0.0.1:40019,DS-37e869e8-4362-4ee0-8414-060ad8678f86,DISK], DatanodeInfoWithStorage[127.0.0.1:45838,DS-1a6f4e73-2466-4348-a275-65dc6b0773e2,DISK], DatanodeInfoWithStorage[127.0.0.1:32966,DS-61a211be-1a1f-4678-9f44-4f8a5a9e5745,DISK], DatanodeInfoWithStorage[127.0.0.1:39641,DS-69c27db6-1c1a-421c-afd6-372037251a74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1528038502-172.17.0.6-1597636966487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37702,DS-b3414540-963c-4c05-af59-fc80fe3c2236,DISK], DatanodeInfoWithStorage[127.0.0.1:33756,DS-ba81aaaf-097e-42b7-b6a6-172aa11e28d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41925,DS-c2468d6e-246a-4905-87df-75ceae87f88a,DISK], DatanodeInfoWithStorage[127.0.0.1:37786,DS-2fcac4bf-5efd-434b-8abf-d8e0bd1a49b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42776,DS-17e0c04b-b546-4ada-a96d-08faba7526d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33136,DS-71d8ca0c-e78d-484a-b412-f881c7a67c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:38661,DS-fc0cf55b-881a-4708-837c-bd4ab5b50c47,DISK], DatanodeInfoWithStorage[127.0.0.1:40920,DS-acf338ef-be87-4402-8743-cef3ce871fa9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1528038502-172.17.0.6-1597636966487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37702,DS-b3414540-963c-4c05-af59-fc80fe3c2236,DISK], DatanodeInfoWithStorage[127.0.0.1:33756,DS-ba81aaaf-097e-42b7-b6a6-172aa11e28d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41925,DS-c2468d6e-246a-4905-87df-75ceae87f88a,DISK], DatanodeInfoWithStorage[127.0.0.1:37786,DS-2fcac4bf-5efd-434b-8abf-d8e0bd1a49b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42776,DS-17e0c04b-b546-4ada-a96d-08faba7526d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33136,DS-71d8ca0c-e78d-484a-b412-f881c7a67c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:38661,DS-fc0cf55b-881a-4708-837c-bd4ab5b50c47,DISK], DatanodeInfoWithStorage[127.0.0.1:40920,DS-acf338ef-be87-4402-8743-cef3ce871fa9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-558228337-172.17.0.6-1597637487914:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42364,DS-97327e23-0517-4c53-8334-4fa006888af2,DISK], DatanodeInfoWithStorage[127.0.0.1:33338,DS-04b324e7-c3a4-4afe-870c-d7b2b38a4a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:40104,DS-aebb6d13-5e17-473d-a144-a57e73116a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:32843,DS-1d009562-faa8-4137-a652-023143e285ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43485,DS-583e5994-7df5-4bec-8743-46f204407ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:40083,DS-09bb3aca-4415-4826-b322-6311c2fb8570,DISK], DatanodeInfoWithStorage[127.0.0.1:41477,DS-d1712b2e-c87d-48fd-8eef-2a12635dd7cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36676,DS-240cf74d-2f96-4337-b37a-b2f2c1a7de4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-558228337-172.17.0.6-1597637487914:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42364,DS-97327e23-0517-4c53-8334-4fa006888af2,DISK], DatanodeInfoWithStorage[127.0.0.1:33338,DS-04b324e7-c3a4-4afe-870c-d7b2b38a4a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:40104,DS-aebb6d13-5e17-473d-a144-a57e73116a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:32843,DS-1d009562-faa8-4137-a652-023143e285ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43485,DS-583e5994-7df5-4bec-8743-46f204407ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:40083,DS-09bb3aca-4415-4826-b322-6311c2fb8570,DISK], DatanodeInfoWithStorage[127.0.0.1:41477,DS-d1712b2e-c87d-48fd-8eef-2a12635dd7cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36676,DS-240cf74d-2f96-4337-b37a-b2f2c1a7de4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1972252268-172.17.0.6-1597637570410:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36896,DS-896bac6b-e219-40af-b176-03354e7b4798,DISK], DatanodeInfoWithStorage[127.0.0.1:46576,DS-758d9650-5a24-47ae-a7fe-508fa31e6332,DISK], DatanodeInfoWithStorage[127.0.0.1:37454,DS-40c6f6cd-c245-41ea-83fb-55297a45436c,DISK], DatanodeInfoWithStorage[127.0.0.1:46352,DS-b2c17501-b4dc-4765-8ea3-ac50bb1f4a84,DISK], DatanodeInfoWithStorage[127.0.0.1:37826,DS-f9371851-0755-41a6-b592-e3f3eed07c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33249,DS-ac9e83e2-31b7-471f-a6bc-7eeab2f28ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:37283,DS-ac7e27fd-292a-45f9-bd5c-26c6d2f32dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:46058,DS-c5130d0c-1f3a-4c3b-82b3-38760a41fc36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1972252268-172.17.0.6-1597637570410:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36896,DS-896bac6b-e219-40af-b176-03354e7b4798,DISK], DatanodeInfoWithStorage[127.0.0.1:46576,DS-758d9650-5a24-47ae-a7fe-508fa31e6332,DISK], DatanodeInfoWithStorage[127.0.0.1:37454,DS-40c6f6cd-c245-41ea-83fb-55297a45436c,DISK], DatanodeInfoWithStorage[127.0.0.1:46352,DS-b2c17501-b4dc-4765-8ea3-ac50bb1f4a84,DISK], DatanodeInfoWithStorage[127.0.0.1:37826,DS-f9371851-0755-41a6-b592-e3f3eed07c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33249,DS-ac9e83e2-31b7-471f-a6bc-7eeab2f28ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:37283,DS-ac7e27fd-292a-45f9-bd5c-26c6d2f32dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:46058,DS-c5130d0c-1f3a-4c3b-82b3-38760a41fc36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1206013077-172.17.0.6-1597637688704:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42127,DS-e72aa5ba-8b36-4bd0-b470-fc190dd691bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34889,DS-b61124e4-9503-458e-9de9-a79a71d5d3d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36306,DS-8c5a6a60-5118-4fac-9c97-738fcd46850d,DISK], DatanodeInfoWithStorage[127.0.0.1:45249,DS-17bb4e3d-8ffb-428b-b56a-d633b680d55a,DISK], DatanodeInfoWithStorage[127.0.0.1:35917,DS-e7298963-49bb-4ee7-8f21-eb8b91b4b196,DISK], DatanodeInfoWithStorage[127.0.0.1:37843,DS-f70fa572-5c4b-41f1-80ac-e6360ee11b51,DISK], DatanodeInfoWithStorage[127.0.0.1:37055,DS-b7984591-7ab1-4d29-b04c-3ee2f3784257,DISK], DatanodeInfoWithStorage[127.0.0.1:42195,DS-a269e234-41c8-4640-aa41-aa5d5202319a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1206013077-172.17.0.6-1597637688704:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42127,DS-e72aa5ba-8b36-4bd0-b470-fc190dd691bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34889,DS-b61124e4-9503-458e-9de9-a79a71d5d3d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36306,DS-8c5a6a60-5118-4fac-9c97-738fcd46850d,DISK], DatanodeInfoWithStorage[127.0.0.1:45249,DS-17bb4e3d-8ffb-428b-b56a-d633b680d55a,DISK], DatanodeInfoWithStorage[127.0.0.1:35917,DS-e7298963-49bb-4ee7-8f21-eb8b91b4b196,DISK], DatanodeInfoWithStorage[127.0.0.1:37843,DS-f70fa572-5c4b-41f1-80ac-e6360ee11b51,DISK], DatanodeInfoWithStorage[127.0.0.1:37055,DS-b7984591-7ab1-4d29-b04c-3ee2f3784257,DISK], DatanodeInfoWithStorage[127.0.0.1:42195,DS-a269e234-41c8-4640-aa41-aa5d5202319a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1965088884-172.17.0.6-1597637761368:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43656,DS-39070098-6771-43a0-9ab0-c50373de34a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40988,DS-530a09fa-287d-47cc-bef6-186b6d25948f,DISK], DatanodeInfoWithStorage[127.0.0.1:42947,DS-a1306eba-7651-446f-aaed-33f9d378c2e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35844,DS-dd46fb23-4691-4633-be68-b79e17e8cfca,DISK], DatanodeInfoWithStorage[127.0.0.1:34201,DS-b8b93d66-0395-420c-8f94-886504d9654c,DISK], DatanodeInfoWithStorage[127.0.0.1:41504,DS-cc4dd20a-8373-425c-9bea-bec9e44990de,DISK], DatanodeInfoWithStorage[127.0.0.1:42128,DS-d9f3d063-03a2-4f6a-8be0-7200e1c59f29,DISK], DatanodeInfoWithStorage[127.0.0.1:45850,DS-cb3e08c1-a845-4293-be3d-5e4fc265afed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1965088884-172.17.0.6-1597637761368:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43656,DS-39070098-6771-43a0-9ab0-c50373de34a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40988,DS-530a09fa-287d-47cc-bef6-186b6d25948f,DISK], DatanodeInfoWithStorage[127.0.0.1:42947,DS-a1306eba-7651-446f-aaed-33f9d378c2e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35844,DS-dd46fb23-4691-4633-be68-b79e17e8cfca,DISK], DatanodeInfoWithStorage[127.0.0.1:34201,DS-b8b93d66-0395-420c-8f94-886504d9654c,DISK], DatanodeInfoWithStorage[127.0.0.1:41504,DS-cc4dd20a-8373-425c-9bea-bec9e44990de,DISK], DatanodeInfoWithStorage[127.0.0.1:42128,DS-d9f3d063-03a2-4f6a-8be0-7200e1c59f29,DISK], DatanodeInfoWithStorage[127.0.0.1:45850,DS-cb3e08c1-a845-4293-be3d-5e4fc265afed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1782030408-172.17.0.6-1597637996993:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40238,DS-567a104e-b102-4f85-bb0a-ce93efeecedd,DISK], DatanodeInfoWithStorage[127.0.0.1:33640,DS-79d314fc-a7ba-4e14-83de-5f261ab20305,DISK], DatanodeInfoWithStorage[127.0.0.1:45958,DS-c726cc54-eb9f-425f-9e8c-59740bc09277,DISK], DatanodeInfoWithStorage[127.0.0.1:45975,DS-494c7a3e-591c-4cf7-a078-773936f10015,DISK], DatanodeInfoWithStorage[127.0.0.1:32995,DS-c3468f5f-749c-4ea1-b33d-b68b987c879c,DISK], DatanodeInfoWithStorage[127.0.0.1:34495,DS-df658722-ab9a-4c9d-bbd1-bed98d464778,DISK], DatanodeInfoWithStorage[127.0.0.1:42230,DS-ebc87a53-88b5-4fad-8f6e-510553acd060,DISK], DatanodeInfoWithStorage[127.0.0.1:34562,DS-d29c2dd1-d3bd-4af2-8e55-d9b62b8edb88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1782030408-172.17.0.6-1597637996993:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40238,DS-567a104e-b102-4f85-bb0a-ce93efeecedd,DISK], DatanodeInfoWithStorage[127.0.0.1:33640,DS-79d314fc-a7ba-4e14-83de-5f261ab20305,DISK], DatanodeInfoWithStorage[127.0.0.1:45958,DS-c726cc54-eb9f-425f-9e8c-59740bc09277,DISK], DatanodeInfoWithStorage[127.0.0.1:45975,DS-494c7a3e-591c-4cf7-a078-773936f10015,DISK], DatanodeInfoWithStorage[127.0.0.1:32995,DS-c3468f5f-749c-4ea1-b33d-b68b987c879c,DISK], DatanodeInfoWithStorage[127.0.0.1:34495,DS-df658722-ab9a-4c9d-bbd1-bed98d464778,DISK], DatanodeInfoWithStorage[127.0.0.1:42230,DS-ebc87a53-88b5-4fad-8f6e-510553acd060,DISK], DatanodeInfoWithStorage[127.0.0.1:34562,DS-d29c2dd1-d3bd-4af2-8e55-d9b62b8edb88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-5946181-172.17.0.6-1597638434387:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44700,DS-1d9b35fb-6098-49c6-aa40-d159fb4736e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43688,DS-b19213cf-86b0-4919-8cbb-3eb0d6986263,DISK], DatanodeInfoWithStorage[127.0.0.1:39241,DS-7f9e6190-faae-468d-a0e2-020123393b71,DISK], DatanodeInfoWithStorage[127.0.0.1:39630,DS-ea6703d1-4e6c-4ac4-8a90-a0cb2348be86,DISK], DatanodeInfoWithStorage[127.0.0.1:35307,DS-dee063c2-f0a6-4699-a2bd-e6400bcd0eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:39075,DS-bbe1df8c-3a73-47a4-8e1d-f26a358c9a98,DISK], DatanodeInfoWithStorage[127.0.0.1:43829,DS-b44502b5-3de0-43b9-812e-bb1e51f36ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:45846,DS-3af0cd15-9181-44bb-b14e-83be78537549,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-5946181-172.17.0.6-1597638434387:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44700,DS-1d9b35fb-6098-49c6-aa40-d159fb4736e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43688,DS-b19213cf-86b0-4919-8cbb-3eb0d6986263,DISK], DatanodeInfoWithStorage[127.0.0.1:39241,DS-7f9e6190-faae-468d-a0e2-020123393b71,DISK], DatanodeInfoWithStorage[127.0.0.1:39630,DS-ea6703d1-4e6c-4ac4-8a90-a0cb2348be86,DISK], DatanodeInfoWithStorage[127.0.0.1:35307,DS-dee063c2-f0a6-4699-a2bd-e6400bcd0eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:39075,DS-bbe1df8c-3a73-47a4-8e1d-f26a358c9a98,DISK], DatanodeInfoWithStorage[127.0.0.1:43829,DS-b44502b5-3de0-43b9-812e-bb1e51f36ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:45846,DS-3af0cd15-9181-44bb-b14e-83be78537549,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1571226726-172.17.0.6-1597638771227:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36942,DS-2f6a1a01-bf32-44f6-9791-843d42952ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:38571,DS-02a02b48-6bde-4123-9b9e-ee6a4ba8bf54,DISK], DatanodeInfoWithStorage[127.0.0.1:44930,DS-f18bb3cb-7ad3-479c-a189-0635d86eb084,DISK], DatanodeInfoWithStorage[127.0.0.1:45919,DS-5c226091-61e4-4bdc-a24f-c817ceb0cb89,DISK], DatanodeInfoWithStorage[127.0.0.1:40657,DS-19b441e8-092d-47e6-97a7-67e921809d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:44580,DS-e2a167f6-35c0-4e6d-8ea3-443243202b04,DISK], DatanodeInfoWithStorage[127.0.0.1:41297,DS-283f05b7-1c5a-480c-8267-86d0175db20d,DISK], DatanodeInfoWithStorage[127.0.0.1:36088,DS-43dd7847-4839-44df-bcd7-c712bf99c87f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1571226726-172.17.0.6-1597638771227:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36942,DS-2f6a1a01-bf32-44f6-9791-843d42952ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:38571,DS-02a02b48-6bde-4123-9b9e-ee6a4ba8bf54,DISK], DatanodeInfoWithStorage[127.0.0.1:44930,DS-f18bb3cb-7ad3-479c-a189-0635d86eb084,DISK], DatanodeInfoWithStorage[127.0.0.1:45919,DS-5c226091-61e4-4bdc-a24f-c817ceb0cb89,DISK], DatanodeInfoWithStorage[127.0.0.1:40657,DS-19b441e8-092d-47e6-97a7-67e921809d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:44580,DS-e2a167f6-35c0-4e6d-8ea3-443243202b04,DISK], DatanodeInfoWithStorage[127.0.0.1:41297,DS-283f05b7-1c5a-480c-8267-86d0175db20d,DISK], DatanodeInfoWithStorage[127.0.0.1:36088,DS-43dd7847-4839-44df-bcd7-c712bf99c87f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1379552832-172.17.0.6-1597638954649:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42298,DS-705328d2-9988-4f72-b6b4-88ec4df5e575,DISK], DatanodeInfoWithStorage[127.0.0.1:42315,DS-b77b0341-a5de-45ff-9d49-072b10cb6517,DISK], DatanodeInfoWithStorage[127.0.0.1:40315,DS-e243f069-32e9-4a34-9af7-647e4656ce15,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-6c5d258b-3997-4fce-a566-3bf68b9fc3ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42161,DS-a46c45ab-f1a7-4193-b281-307b2b5ffd40,DISK], DatanodeInfoWithStorage[127.0.0.1:43706,DS-e60251a8-72cc-49cc-b6ef-4200de691e64,DISK], DatanodeInfoWithStorage[127.0.0.1:35225,DS-f5baf40d-55a6-4c56-ab2b-d720d33686a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38429,DS-af864d3a-1734-4ca1-a13f-7623198f2f0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1379552832-172.17.0.6-1597638954649:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42298,DS-705328d2-9988-4f72-b6b4-88ec4df5e575,DISK], DatanodeInfoWithStorage[127.0.0.1:42315,DS-b77b0341-a5de-45ff-9d49-072b10cb6517,DISK], DatanodeInfoWithStorage[127.0.0.1:40315,DS-e243f069-32e9-4a34-9af7-647e4656ce15,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-6c5d258b-3997-4fce-a566-3bf68b9fc3ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42161,DS-a46c45ab-f1a7-4193-b281-307b2b5ffd40,DISK], DatanodeInfoWithStorage[127.0.0.1:43706,DS-e60251a8-72cc-49cc-b6ef-4200de691e64,DISK], DatanodeInfoWithStorage[127.0.0.1:35225,DS-f5baf40d-55a6-4c56-ab2b-d720d33686a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38429,DS-af864d3a-1734-4ca1-a13f-7623198f2f0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2006456863-172.17.0.6-1597639339490:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43775,DS-9a7ad92d-a07a-483e-ac22-9da9d0dfcb3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44272,DS-958d2bf6-f2b5-4443-9143-8b3eef8bf94b,DISK], DatanodeInfoWithStorage[127.0.0.1:39370,DS-f041d61b-a59e-4de4-9dae-65daf063df3d,DISK], DatanodeInfoWithStorage[127.0.0.1:33053,DS-1ea8a268-f5ed-46ee-872a-e7c461fb0450,DISK], DatanodeInfoWithStorage[127.0.0.1:33238,DS-9eb4eaab-13fb-462f-9f73-b5ba63dcd6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36040,DS-79baf2bd-0725-4c23-841f-62990da13821,DISK], DatanodeInfoWithStorage[127.0.0.1:34331,DS-98bc36ee-cdce-4220-8fa1-52ce7edcbd89,DISK], DatanodeInfoWithStorage[127.0.0.1:39926,DS-27f9a85a-21e0-4a5d-a69c-a121f04715cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2006456863-172.17.0.6-1597639339490:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43775,DS-9a7ad92d-a07a-483e-ac22-9da9d0dfcb3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44272,DS-958d2bf6-f2b5-4443-9143-8b3eef8bf94b,DISK], DatanodeInfoWithStorage[127.0.0.1:39370,DS-f041d61b-a59e-4de4-9dae-65daf063df3d,DISK], DatanodeInfoWithStorage[127.0.0.1:33053,DS-1ea8a268-f5ed-46ee-872a-e7c461fb0450,DISK], DatanodeInfoWithStorage[127.0.0.1:33238,DS-9eb4eaab-13fb-462f-9f73-b5ba63dcd6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36040,DS-79baf2bd-0725-4c23-841f-62990da13821,DISK], DatanodeInfoWithStorage[127.0.0.1:34331,DS-98bc36ee-cdce-4220-8fa1-52ce7edcbd89,DISK], DatanodeInfoWithStorage[127.0.0.1:39926,DS-27f9a85a-21e0-4a5d-a69c-a121f04715cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1282286609-172.17.0.6-1597639422872:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33035,DS-1fe04464-e522-472c-971e-e7cacd215a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37487,DS-1f2a5314-0669-43c6-a7b6-e3079b953cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:41654,DS-be6a5615-227a-467d-a5d6-7f15ef51e5fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39446,DS-73d0e5d4-3692-468b-9865-588705b38284,DISK], DatanodeInfoWithStorage[127.0.0.1:41607,DS-5985246c-60f7-4441-836f-5b61812f7a59,DISK], DatanodeInfoWithStorage[127.0.0.1:33896,DS-0febfc16-ff6c-4506-9e0d-bdf2ed425695,DISK], DatanodeInfoWithStorage[127.0.0.1:37359,DS-bffdcc47-1949-4e75-b1a7-cc04d54bc004,DISK], DatanodeInfoWithStorage[127.0.0.1:41742,DS-ea0081ed-ba97-4fd7-b067-30473cbed704,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1282286609-172.17.0.6-1597639422872:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33035,DS-1fe04464-e522-472c-971e-e7cacd215a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37487,DS-1f2a5314-0669-43c6-a7b6-e3079b953cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:41654,DS-be6a5615-227a-467d-a5d6-7f15ef51e5fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39446,DS-73d0e5d4-3692-468b-9865-588705b38284,DISK], DatanodeInfoWithStorage[127.0.0.1:41607,DS-5985246c-60f7-4441-836f-5b61812f7a59,DISK], DatanodeInfoWithStorage[127.0.0.1:33896,DS-0febfc16-ff6c-4506-9e0d-bdf2ed425695,DISK], DatanodeInfoWithStorage[127.0.0.1:37359,DS-bffdcc47-1949-4e75-b1a7-cc04d54bc004,DISK], DatanodeInfoWithStorage[127.0.0.1:41742,DS-ea0081ed-ba97-4fd7-b067-30473cbed704,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-347679079-172.17.0.6-1597639503873:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42117,DS-122ad4d1-7262-4f5a-ae45-30e907e7d861,DISK], DatanodeInfoWithStorage[127.0.0.1:39284,DS-cde356ef-fb4d-43ab-9ef0-a77a0f8f16c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40864,DS-ad75ad1a-0d85-4a28-9b56-d9137c15f0cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45266,DS-e4818522-869d-41ad-8d9d-31b45625ca00,DISK], DatanodeInfoWithStorage[127.0.0.1:44620,DS-38746573-f079-495a-8d1e-9f5bfbbee37a,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-d634b8ed-f57c-497d-9be2-6a0e1998f1cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39794,DS-681d9adc-44bb-49ac-ba07-70737c1f3e26,DISK], DatanodeInfoWithStorage[127.0.0.1:45610,DS-94b92a00-8ff8-47b6-b488-41e2e5a46c59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-347679079-172.17.0.6-1597639503873:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42117,DS-122ad4d1-7262-4f5a-ae45-30e907e7d861,DISK], DatanodeInfoWithStorage[127.0.0.1:39284,DS-cde356ef-fb4d-43ab-9ef0-a77a0f8f16c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40864,DS-ad75ad1a-0d85-4a28-9b56-d9137c15f0cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45266,DS-e4818522-869d-41ad-8d9d-31b45625ca00,DISK], DatanodeInfoWithStorage[127.0.0.1:44620,DS-38746573-f079-495a-8d1e-9f5bfbbee37a,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-d634b8ed-f57c-497d-9be2-6a0e1998f1cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39794,DS-681d9adc-44bb-49ac-ba07-70737c1f3e26,DISK], DatanodeInfoWithStorage[127.0.0.1:45610,DS-94b92a00-8ff8-47b6-b488-41e2e5a46c59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-492125870-172.17.0.6-1597639796541:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46688,DS-30660144-add2-4ce9-8206-5d676d708de6,DISK], DatanodeInfoWithStorage[127.0.0.1:41290,DS-42af22c4-f379-48c7-bd75-6c41a81e4683,DISK], DatanodeInfoWithStorage[127.0.0.1:34272,DS-58de60d0-036e-49f4-8594-ae3a05d2ef5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37298,DS-9513a138-4640-43be-b458-6fe6378991c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41594,DS-229f4717-388e-46fd-a502-f4ed86904435,DISK], DatanodeInfoWithStorage[127.0.0.1:34048,DS-50e7e0ba-cc11-40d0-beb5-827fc4956b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:33943,DS-f8ee683d-b58d-4cc8-a47b-ad7a228120cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34663,DS-c47fce6d-0811-49b5-b489-1b169a4d92e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-492125870-172.17.0.6-1597639796541:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46688,DS-30660144-add2-4ce9-8206-5d676d708de6,DISK], DatanodeInfoWithStorage[127.0.0.1:41290,DS-42af22c4-f379-48c7-bd75-6c41a81e4683,DISK], DatanodeInfoWithStorage[127.0.0.1:34272,DS-58de60d0-036e-49f4-8594-ae3a05d2ef5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37298,DS-9513a138-4640-43be-b458-6fe6378991c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41594,DS-229f4717-388e-46fd-a502-f4ed86904435,DISK], DatanodeInfoWithStorage[127.0.0.1:34048,DS-50e7e0ba-cc11-40d0-beb5-827fc4956b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:33943,DS-f8ee683d-b58d-4cc8-a47b-ad7a228120cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34663,DS-c47fce6d-0811-49b5-b489-1b169a4d92e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2034689511-172.17.0.6-1597640144537:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36653,DS-86aa085f-a83b-4365-9360-77d2c7ff44cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36435,DS-b57e8f7e-0c44-4927-9591-0591888675c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41485,DS-f33ca35d-a865-4717-86f2-3dadc10a4e79,DISK], DatanodeInfoWithStorage[127.0.0.1:45391,DS-da3b665e-fbc2-4d52-b69f-00c4570edf56,DISK], DatanodeInfoWithStorage[127.0.0.1:46376,DS-cb67fa78-5568-4889-a09b-85d7f32a1c39,DISK], DatanodeInfoWithStorage[127.0.0.1:44629,DS-e9569698-7a2e-4efd-85c9-302b844b5fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:35188,DS-63b87df8-754e-485c-a93d-98716248c1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34782,DS-2ae53519-d252-422d-836f-17e4692407d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2034689511-172.17.0.6-1597640144537:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36653,DS-86aa085f-a83b-4365-9360-77d2c7ff44cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36435,DS-b57e8f7e-0c44-4927-9591-0591888675c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41485,DS-f33ca35d-a865-4717-86f2-3dadc10a4e79,DISK], DatanodeInfoWithStorage[127.0.0.1:45391,DS-da3b665e-fbc2-4d52-b69f-00c4570edf56,DISK], DatanodeInfoWithStorage[127.0.0.1:46376,DS-cb67fa78-5568-4889-a09b-85d7f32a1c39,DISK], DatanodeInfoWithStorage[127.0.0.1:44629,DS-e9569698-7a2e-4efd-85c9-302b844b5fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:35188,DS-63b87df8-754e-485c-a93d-98716248c1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34782,DS-2ae53519-d252-422d-836f-17e4692407d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-339032365-172.17.0.6-1597640215820:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38695,DS-48050e94-b105-455a-ad5e-40ccf0590e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:33070,DS-19bc6ded-7951-4ace-b9a1-1e09b28f6afe,DISK], DatanodeInfoWithStorage[127.0.0.1:34730,DS-f59de922-c1c7-4919-a22b-baf55a81b33a,DISK], DatanodeInfoWithStorage[127.0.0.1:37580,DS-fbca6316-cc9c-4b81-ad5a-1f488e9d4d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:35539,DS-eaef9539-2648-4465-9f5d-92f3d5b114b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39049,DS-c083399c-3f5f-45d4-ac05-bb02e3b57fef,DISK], DatanodeInfoWithStorage[127.0.0.1:40947,DS-16f310a8-6a70-4f9d-82bd-341515a20ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:36097,DS-ee1d652c-0713-47d4-8e5f-4dd106bdea9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-339032365-172.17.0.6-1597640215820:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38695,DS-48050e94-b105-455a-ad5e-40ccf0590e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:33070,DS-19bc6ded-7951-4ace-b9a1-1e09b28f6afe,DISK], DatanodeInfoWithStorage[127.0.0.1:34730,DS-f59de922-c1c7-4919-a22b-baf55a81b33a,DISK], DatanodeInfoWithStorage[127.0.0.1:37580,DS-fbca6316-cc9c-4b81-ad5a-1f488e9d4d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:35539,DS-eaef9539-2648-4465-9f5d-92f3d5b114b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39049,DS-c083399c-3f5f-45d4-ac05-bb02e3b57fef,DISK], DatanodeInfoWithStorage[127.0.0.1:40947,DS-16f310a8-6a70-4f9d-82bd-341515a20ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:36097,DS-ee1d652c-0713-47d4-8e5f-4dd106bdea9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5809
