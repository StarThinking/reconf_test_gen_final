reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-681830990-172.17.0.3-1597663873692:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38643,DS-b94e6b4f-c263-4b21-b01b-9c265362063c,DISK], DatanodeInfoWithStorage[127.0.0.1:36401,DS-2947f057-a9df-42eb-acb7-991a66a31c88,DISK], DatanodeInfoWithStorage[127.0.0.1:43030,DS-16531c66-ee82-4499-b755-3a11bce34830,DISK], DatanodeInfoWithStorage[127.0.0.1:44862,DS-99f380e5-79cf-436a-b3dc-a77f52f34f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:33516,DS-39d008ec-0c95-4bee-81ab-cf5d7e029345,DISK], DatanodeInfoWithStorage[127.0.0.1:36789,DS-2d80d451-ef84-4961-8e00-6a9d7ace2abb,DISK], DatanodeInfoWithStorage[127.0.0.1:43000,DS-dee556f6-13e3-4d8f-bee8-63d87b916973,DISK], DatanodeInfoWithStorage[127.0.0.1:35964,DS-e2ba2c83-8519-4dd3-8977-01fbf02d9eee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-681830990-172.17.0.3-1597663873692:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38643,DS-b94e6b4f-c263-4b21-b01b-9c265362063c,DISK], DatanodeInfoWithStorage[127.0.0.1:36401,DS-2947f057-a9df-42eb-acb7-991a66a31c88,DISK], DatanodeInfoWithStorage[127.0.0.1:43030,DS-16531c66-ee82-4499-b755-3a11bce34830,DISK], DatanodeInfoWithStorage[127.0.0.1:44862,DS-99f380e5-79cf-436a-b3dc-a77f52f34f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:33516,DS-39d008ec-0c95-4bee-81ab-cf5d7e029345,DISK], DatanodeInfoWithStorage[127.0.0.1:36789,DS-2d80d451-ef84-4961-8e00-6a9d7ace2abb,DISK], DatanodeInfoWithStorage[127.0.0.1:43000,DS-dee556f6-13e3-4d8f-bee8-63d87b916973,DISK], DatanodeInfoWithStorage[127.0.0.1:35964,DS-e2ba2c83-8519-4dd3-8977-01fbf02d9eee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-590660262-172.17.0.3-1597664027636:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37351,DS-bd25f7c0-ea99-46d7-aaa8-2d9e375d33f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33043,DS-104a5f8d-079d-4e58-8d06-0cd594f5ea6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39841,DS-73bf6544-0865-4116-a87d-4e603a24033d,DISK], DatanodeInfoWithStorage[127.0.0.1:37429,DS-31c802e8-98e3-46d4-bd81-41a5e4a621e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45638,DS-1a5d6c4d-5036-45d4-9dce-28415db0122a,DISK], DatanodeInfoWithStorage[127.0.0.1:34154,DS-fa998497-7f7e-4209-a3b6-d286a0c43a08,DISK], DatanodeInfoWithStorage[127.0.0.1:37314,DS-bf293fb9-9a29-40b8-8eaf-ffee2cacfb3e,DISK], DatanodeInfoWithStorage[127.0.0.1:37449,DS-75ebaa9c-f3e4-41fe-98b1-6445442231cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-590660262-172.17.0.3-1597664027636:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37351,DS-bd25f7c0-ea99-46d7-aaa8-2d9e375d33f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33043,DS-104a5f8d-079d-4e58-8d06-0cd594f5ea6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39841,DS-73bf6544-0865-4116-a87d-4e603a24033d,DISK], DatanodeInfoWithStorage[127.0.0.1:37429,DS-31c802e8-98e3-46d4-bd81-41a5e4a621e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45638,DS-1a5d6c4d-5036-45d4-9dce-28415db0122a,DISK], DatanodeInfoWithStorage[127.0.0.1:34154,DS-fa998497-7f7e-4209-a3b6-d286a0c43a08,DISK], DatanodeInfoWithStorage[127.0.0.1:37314,DS-bf293fb9-9a29-40b8-8eaf-ffee2cacfb3e,DISK], DatanodeInfoWithStorage[127.0.0.1:37449,DS-75ebaa9c-f3e4-41fe-98b1-6445442231cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-854013254-172.17.0.3-1597664528299:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46834,DS-8a6c8656-84cd-4c76-b0f4-7a58d54dee73,DISK], DatanodeInfoWithStorage[127.0.0.1:40958,DS-a2901851-2613-4c63-87ba-e759cb290a50,DISK], DatanodeInfoWithStorage[127.0.0.1:40813,DS-3575280b-705b-4218-9357-7f7139d7f239,DISK], DatanodeInfoWithStorage[127.0.0.1:39232,DS-285de770-f47c-47d4-b142-a9f1da373e70,DISK], DatanodeInfoWithStorage[127.0.0.1:40827,DS-165fa6ae-756a-4921-9427-f4d0be70fdcf,DISK], DatanodeInfoWithStorage[127.0.0.1:37404,DS-729ffe59-2882-455e-b2f3-4218eda8c16d,DISK], DatanodeInfoWithStorage[127.0.0.1:34798,DS-13111e18-41f1-4e3c-92f4-980962d6a040,DISK], DatanodeInfoWithStorage[127.0.0.1:35559,DS-02115aeb-a35f-415a-afae-697b5f2c8279,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-854013254-172.17.0.3-1597664528299:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46834,DS-8a6c8656-84cd-4c76-b0f4-7a58d54dee73,DISK], DatanodeInfoWithStorage[127.0.0.1:40958,DS-a2901851-2613-4c63-87ba-e759cb290a50,DISK], DatanodeInfoWithStorage[127.0.0.1:40813,DS-3575280b-705b-4218-9357-7f7139d7f239,DISK], DatanodeInfoWithStorage[127.0.0.1:39232,DS-285de770-f47c-47d4-b142-a9f1da373e70,DISK], DatanodeInfoWithStorage[127.0.0.1:40827,DS-165fa6ae-756a-4921-9427-f4d0be70fdcf,DISK], DatanodeInfoWithStorage[127.0.0.1:37404,DS-729ffe59-2882-455e-b2f3-4218eda8c16d,DISK], DatanodeInfoWithStorage[127.0.0.1:34798,DS-13111e18-41f1-4e3c-92f4-980962d6a040,DISK], DatanodeInfoWithStorage[127.0.0.1:35559,DS-02115aeb-a35f-415a-afae-697b5f2c8279,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-333287074-172.17.0.3-1597664931015:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40721,DS-56a783da-4731-455e-ac8d-959b1c57da96,DISK], DatanodeInfoWithStorage[127.0.0.1:39502,DS-e50e4f33-1ec9-44fd-b251-6234208e2b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39824,DS-015ca14a-5c3a-4249-8064-b1bcb531e657,DISK], DatanodeInfoWithStorage[127.0.0.1:33705,DS-60369fa6-7306-46fd-8d3d-bd7edd7d7c29,DISK], DatanodeInfoWithStorage[127.0.0.1:41049,DS-1bbd4e56-a72f-49a8-b12c-2a5587d377aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35244,DS-aacdd872-d84b-4a69-b562-733799f55990,DISK], DatanodeInfoWithStorage[127.0.0.1:39097,DS-dcfb56db-cc96-45e0-9bf3-690fc4afec2f,DISK], DatanodeInfoWithStorage[127.0.0.1:46190,DS-10f4c3b1-bf9b-4aec-a8c0-56eb5f88820c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-333287074-172.17.0.3-1597664931015:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40721,DS-56a783da-4731-455e-ac8d-959b1c57da96,DISK], DatanodeInfoWithStorage[127.0.0.1:39502,DS-e50e4f33-1ec9-44fd-b251-6234208e2b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39824,DS-015ca14a-5c3a-4249-8064-b1bcb531e657,DISK], DatanodeInfoWithStorage[127.0.0.1:33705,DS-60369fa6-7306-46fd-8d3d-bd7edd7d7c29,DISK], DatanodeInfoWithStorage[127.0.0.1:41049,DS-1bbd4e56-a72f-49a8-b12c-2a5587d377aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35244,DS-aacdd872-d84b-4a69-b562-733799f55990,DISK], DatanodeInfoWithStorage[127.0.0.1:39097,DS-dcfb56db-cc96-45e0-9bf3-690fc4afec2f,DISK], DatanodeInfoWithStorage[127.0.0.1:46190,DS-10f4c3b1-bf9b-4aec-a8c0-56eb5f88820c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1673143048-172.17.0.3-1597665096718:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43360,DS-11e8f6f1-dec8-4124-b79b-19f0aeff4644,DISK], DatanodeInfoWithStorage[127.0.0.1:42100,DS-1e5f4db0-f1fe-4f45-a446-bbcd8f0d5a13,DISK], DatanodeInfoWithStorage[127.0.0.1:36202,DS-45b92488-e8c7-4849-9df9-e97fbb95e65d,DISK], DatanodeInfoWithStorage[127.0.0.1:44070,DS-c29ce21e-a369-40d6-8e0f-36627d50d327,DISK], DatanodeInfoWithStorage[127.0.0.1:33938,DS-e1ebc6b5-b8b3-4766-9d45-8fc8767fd4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38827,DS-332121be-f9aa-45ad-b53e-a88294f61baf,DISK], DatanodeInfoWithStorage[127.0.0.1:45307,DS-0563cdeb-6772-4d58-898b-2b32e85ca023,DISK], DatanodeInfoWithStorage[127.0.0.1:44691,DS-4dfd70de-dcc6-4fa5-8bf0-f8a4171248a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1673143048-172.17.0.3-1597665096718:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43360,DS-11e8f6f1-dec8-4124-b79b-19f0aeff4644,DISK], DatanodeInfoWithStorage[127.0.0.1:42100,DS-1e5f4db0-f1fe-4f45-a446-bbcd8f0d5a13,DISK], DatanodeInfoWithStorage[127.0.0.1:36202,DS-45b92488-e8c7-4849-9df9-e97fbb95e65d,DISK], DatanodeInfoWithStorage[127.0.0.1:44070,DS-c29ce21e-a369-40d6-8e0f-36627d50d327,DISK], DatanodeInfoWithStorage[127.0.0.1:33938,DS-e1ebc6b5-b8b3-4766-9d45-8fc8767fd4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38827,DS-332121be-f9aa-45ad-b53e-a88294f61baf,DISK], DatanodeInfoWithStorage[127.0.0.1:45307,DS-0563cdeb-6772-4d58-898b-2b32e85ca023,DISK], DatanodeInfoWithStorage[127.0.0.1:44691,DS-4dfd70de-dcc6-4fa5-8bf0-f8a4171248a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-797591268-172.17.0.3-1597665174272:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46216,DS-81e596a6-255d-41a9-80b8-8704543a5b63,DISK], DatanodeInfoWithStorage[127.0.0.1:40603,DS-ae3cdcbc-2630-40ed-a56a-fdedbb6e4b81,DISK], DatanodeInfoWithStorage[127.0.0.1:43950,DS-97a60ce6-df2d-4491-8492-2255dadf61ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34042,DS-2da790f2-3fc8-469f-87eb-9e2409ab0558,DISK], DatanodeInfoWithStorage[127.0.0.1:38631,DS-e0ba14bb-7a5d-4b68-9a76-98dc6b56cc79,DISK], DatanodeInfoWithStorage[127.0.0.1:40461,DS-cb7025be-ab53-4e4e-a003-a711fd2737a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34768,DS-90147b6a-3a87-4875-82ed-e26c1504c9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36568,DS-a0cb0d0d-7f86-427b-a81a-bc56842ff1af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-797591268-172.17.0.3-1597665174272:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46216,DS-81e596a6-255d-41a9-80b8-8704543a5b63,DISK], DatanodeInfoWithStorage[127.0.0.1:40603,DS-ae3cdcbc-2630-40ed-a56a-fdedbb6e4b81,DISK], DatanodeInfoWithStorage[127.0.0.1:43950,DS-97a60ce6-df2d-4491-8492-2255dadf61ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34042,DS-2da790f2-3fc8-469f-87eb-9e2409ab0558,DISK], DatanodeInfoWithStorage[127.0.0.1:38631,DS-e0ba14bb-7a5d-4b68-9a76-98dc6b56cc79,DISK], DatanodeInfoWithStorage[127.0.0.1:40461,DS-cb7025be-ab53-4e4e-a003-a711fd2737a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34768,DS-90147b6a-3a87-4875-82ed-e26c1504c9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36568,DS-a0cb0d0d-7f86-427b-a81a-bc56842ff1af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2024293369-172.17.0.3-1597665561707:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33622,DS-e5464c6b-1931-4a67-a6f5-22c412eef52f,DISK], DatanodeInfoWithStorage[127.0.0.1:37874,DS-a65c94f1-bd98-4477-bd90-659457d53df2,DISK], DatanodeInfoWithStorage[127.0.0.1:35745,DS-f7b25445-6d9a-4917-855d-d87fb6289f23,DISK], DatanodeInfoWithStorage[127.0.0.1:45239,DS-4587276f-52ef-41ea-9a81-dc56eef1260d,DISK], DatanodeInfoWithStorage[127.0.0.1:46054,DS-6285cac2-0e8e-48af-bee6-d929dbfb9a82,DISK], DatanodeInfoWithStorage[127.0.0.1:34241,DS-12de38d0-2fea-487e-adba-316671ebc19f,DISK], DatanodeInfoWithStorage[127.0.0.1:45068,DS-043843e6-d168-4aab-8dc0-fb627fed1ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:45065,DS-80f42342-09dd-4478-841c-7a4f5d802772,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2024293369-172.17.0.3-1597665561707:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33622,DS-e5464c6b-1931-4a67-a6f5-22c412eef52f,DISK], DatanodeInfoWithStorage[127.0.0.1:37874,DS-a65c94f1-bd98-4477-bd90-659457d53df2,DISK], DatanodeInfoWithStorage[127.0.0.1:35745,DS-f7b25445-6d9a-4917-855d-d87fb6289f23,DISK], DatanodeInfoWithStorage[127.0.0.1:45239,DS-4587276f-52ef-41ea-9a81-dc56eef1260d,DISK], DatanodeInfoWithStorage[127.0.0.1:46054,DS-6285cac2-0e8e-48af-bee6-d929dbfb9a82,DISK], DatanodeInfoWithStorage[127.0.0.1:34241,DS-12de38d0-2fea-487e-adba-316671ebc19f,DISK], DatanodeInfoWithStorage[127.0.0.1:45068,DS-043843e6-d168-4aab-8dc0-fb627fed1ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:45065,DS-80f42342-09dd-4478-841c-7a4f5d802772,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-359615845-172.17.0.3-1597665914314:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46069,DS-6953dac7-7aea-4186-920d-c5d983baa03f,DISK], DatanodeInfoWithStorage[127.0.0.1:38703,DS-41c98fc7-f364-4860-afee-6fddd9489129,DISK], DatanodeInfoWithStorage[127.0.0.1:32791,DS-1c9c03fe-497c-473c-aad1-285b62dffe8e,DISK], DatanodeInfoWithStorage[127.0.0.1:32929,DS-6f4fbc71-6304-4468-b6ce-9a88e3ac4c72,DISK], DatanodeInfoWithStorage[127.0.0.1:39448,DS-32acef2d-7a72-4abd-a1fd-ed0054e7d63c,DISK], DatanodeInfoWithStorage[127.0.0.1:45238,DS-30a0c40d-2f59-4d34-84cd-dbf9736ea8bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45623,DS-5858191f-e80c-4896-b492-beb940939d14,DISK], DatanodeInfoWithStorage[127.0.0.1:41635,DS-5de02592-e2ec-4603-819a-9d3a9a804f60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-359615845-172.17.0.3-1597665914314:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46069,DS-6953dac7-7aea-4186-920d-c5d983baa03f,DISK], DatanodeInfoWithStorage[127.0.0.1:38703,DS-41c98fc7-f364-4860-afee-6fddd9489129,DISK], DatanodeInfoWithStorage[127.0.0.1:32791,DS-1c9c03fe-497c-473c-aad1-285b62dffe8e,DISK], DatanodeInfoWithStorage[127.0.0.1:32929,DS-6f4fbc71-6304-4468-b6ce-9a88e3ac4c72,DISK], DatanodeInfoWithStorage[127.0.0.1:39448,DS-32acef2d-7a72-4abd-a1fd-ed0054e7d63c,DISK], DatanodeInfoWithStorage[127.0.0.1:45238,DS-30a0c40d-2f59-4d34-84cd-dbf9736ea8bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45623,DS-5858191f-e80c-4896-b492-beb940939d14,DISK], DatanodeInfoWithStorage[127.0.0.1:41635,DS-5de02592-e2ec-4603-819a-9d3a9a804f60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-794465145-172.17.0.3-1597666038648:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39898,DS-30dc98af-fd88-4bc9-95d5-2e2695a27c21,DISK], DatanodeInfoWithStorage[127.0.0.1:38329,DS-0cff227c-08ea-412d-8c72-eb29baf4a3fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44280,DS-7a30292a-356a-4e92-9109-bfed1d1317bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41286,DS-7fcaae56-234d-4fa2-9ace-f0113efe42d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41390,DS-7d854ea4-afd2-4b4c-a57a-143c40e20f01,DISK], DatanodeInfoWithStorage[127.0.0.1:43541,DS-3a3c421a-3dd0-4723-92c4-62fb767482fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41557,DS-71757cd9-17aa-4da8-b83a-cbd580721814,DISK], DatanodeInfoWithStorage[127.0.0.1:39908,DS-23633f71-b089-46ad-8f08-8968b531dcb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-794465145-172.17.0.3-1597666038648:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39898,DS-30dc98af-fd88-4bc9-95d5-2e2695a27c21,DISK], DatanodeInfoWithStorage[127.0.0.1:38329,DS-0cff227c-08ea-412d-8c72-eb29baf4a3fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44280,DS-7a30292a-356a-4e92-9109-bfed1d1317bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41286,DS-7fcaae56-234d-4fa2-9ace-f0113efe42d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41390,DS-7d854ea4-afd2-4b4c-a57a-143c40e20f01,DISK], DatanodeInfoWithStorage[127.0.0.1:43541,DS-3a3c421a-3dd0-4723-92c4-62fb767482fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41557,DS-71757cd9-17aa-4da8-b83a-cbd580721814,DISK], DatanodeInfoWithStorage[127.0.0.1:39908,DS-23633f71-b089-46ad-8f08-8968b531dcb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1226904997-172.17.0.3-1597666401114:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44448,DS-7e9dba1c-bec7-4664-aac8-f2fece80c7eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-2d9ef3dd-63d7-4f70-aede-2ede686f26ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34425,DS-9f7d1d7f-984d-4e9c-a742-1de3bcb5f83d,DISK], DatanodeInfoWithStorage[127.0.0.1:39309,DS-65c92194-6b43-433f-aa77-c31ce70da768,DISK], DatanodeInfoWithStorage[127.0.0.1:37578,DS-717051d9-9da2-41e7-938d-86acd58fd1bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39393,DS-27113971-1e3d-4f30-a3de-c243e7f5a28d,DISK], DatanodeInfoWithStorage[127.0.0.1:34231,DS-79d439dd-34bf-4c88-aebf-26c895a7f8ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44331,DS-fbac817d-9ee8-4370-bb5f-e3b35c35fe9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1226904997-172.17.0.3-1597666401114:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44448,DS-7e9dba1c-bec7-4664-aac8-f2fece80c7eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-2d9ef3dd-63d7-4f70-aede-2ede686f26ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34425,DS-9f7d1d7f-984d-4e9c-a742-1de3bcb5f83d,DISK], DatanodeInfoWithStorage[127.0.0.1:39309,DS-65c92194-6b43-433f-aa77-c31ce70da768,DISK], DatanodeInfoWithStorage[127.0.0.1:37578,DS-717051d9-9da2-41e7-938d-86acd58fd1bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39393,DS-27113971-1e3d-4f30-a3de-c243e7f5a28d,DISK], DatanodeInfoWithStorage[127.0.0.1:34231,DS-79d439dd-34bf-4c88-aebf-26c895a7f8ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44331,DS-fbac817d-9ee8-4370-bb5f-e3b35c35fe9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2077693603-172.17.0.3-1597666607515:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43205,DS-35f7150f-b23e-4c24-a57b-c69d62127b20,DISK], DatanodeInfoWithStorage[127.0.0.1:37417,DS-89648fdc-110d-441e-bf56-3ca346cbe2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39583,DS-6a346c51-8aff-4359-8672-dd5020c828c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34605,DS-23e3384c-10fc-40a4-973c-0563cbfe5de2,DISK], DatanodeInfoWithStorage[127.0.0.1:43772,DS-0a5250f9-9a0b-41fd-8d0a-416ad424e18d,DISK], DatanodeInfoWithStorage[127.0.0.1:43647,DS-3dab37a9-0c22-44a2-9e75-7500501f8f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:35181,DS-c03ab0d4-652b-452c-a332-bcb4e3b21eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:38365,DS-cd5811cf-e368-4e28-b818-c13244486fa2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2077693603-172.17.0.3-1597666607515:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43205,DS-35f7150f-b23e-4c24-a57b-c69d62127b20,DISK], DatanodeInfoWithStorage[127.0.0.1:37417,DS-89648fdc-110d-441e-bf56-3ca346cbe2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39583,DS-6a346c51-8aff-4359-8672-dd5020c828c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34605,DS-23e3384c-10fc-40a4-973c-0563cbfe5de2,DISK], DatanodeInfoWithStorage[127.0.0.1:43772,DS-0a5250f9-9a0b-41fd-8d0a-416ad424e18d,DISK], DatanodeInfoWithStorage[127.0.0.1:43647,DS-3dab37a9-0c22-44a2-9e75-7500501f8f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:35181,DS-c03ab0d4-652b-452c-a332-bcb4e3b21eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:38365,DS-cd5811cf-e368-4e28-b818-c13244486fa2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-659662464-172.17.0.3-1597667028494:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44952,DS-f3603e84-36ed-4e92-ac66-3424c7b6eb46,DISK], DatanodeInfoWithStorage[127.0.0.1:40339,DS-28726745-cc1c-4ba0-9895-2fe15075fd4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33829,DS-404e87ea-891d-4672-b64c-fa98c682d0fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38470,DS-3e1cd628-4a05-426c-b0dd-5bc6cde91847,DISK], DatanodeInfoWithStorage[127.0.0.1:44872,DS-e7e2ccf1-09f7-425b-89ee-b92d6ac798e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34988,DS-03fe311f-3d36-49e0-8bfa-3e6495112d15,DISK], DatanodeInfoWithStorage[127.0.0.1:35217,DS-ae993c68-d8fc-4571-a552-abba3af8ab6b,DISK], DatanodeInfoWithStorage[127.0.0.1:34114,DS-24784b83-7f95-4010-a745-29c988389e88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-659662464-172.17.0.3-1597667028494:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44952,DS-f3603e84-36ed-4e92-ac66-3424c7b6eb46,DISK], DatanodeInfoWithStorage[127.0.0.1:40339,DS-28726745-cc1c-4ba0-9895-2fe15075fd4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33829,DS-404e87ea-891d-4672-b64c-fa98c682d0fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38470,DS-3e1cd628-4a05-426c-b0dd-5bc6cde91847,DISK], DatanodeInfoWithStorage[127.0.0.1:44872,DS-e7e2ccf1-09f7-425b-89ee-b92d6ac798e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34988,DS-03fe311f-3d36-49e0-8bfa-3e6495112d15,DISK], DatanodeInfoWithStorage[127.0.0.1:35217,DS-ae993c68-d8fc-4571-a552-abba3af8ab6b,DISK], DatanodeInfoWithStorage[127.0.0.1:34114,DS-24784b83-7f95-4010-a745-29c988389e88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1885577742-172.17.0.3-1597667960635:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41062,DS-da66952d-9df3-4a98-bc2a-5e8617a957a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40946,DS-e8f9cc3a-b230-4d03-98a5-d4d262adc910,DISK], DatanodeInfoWithStorage[127.0.0.1:38460,DS-91a6fff9-02cb-4be6-8f96-6c7568024568,DISK], DatanodeInfoWithStorage[127.0.0.1:44102,DS-0526ed22-decd-43e5-8151-9d4cf8a1dabf,DISK], DatanodeInfoWithStorage[127.0.0.1:45453,DS-fb985fbf-d3ab-4f95-8321-13fc4212f412,DISK], DatanodeInfoWithStorage[127.0.0.1:46097,DS-5a7a5fd3-a14b-40c3-839a-1cf6c06317a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45688,DS-f981e484-3bf4-417c-b54f-b93c4828e6a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39114,DS-23d61f8c-ef1f-498e-81e3-d1feaadeb222,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1885577742-172.17.0.3-1597667960635:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41062,DS-da66952d-9df3-4a98-bc2a-5e8617a957a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40946,DS-e8f9cc3a-b230-4d03-98a5-d4d262adc910,DISK], DatanodeInfoWithStorage[127.0.0.1:38460,DS-91a6fff9-02cb-4be6-8f96-6c7568024568,DISK], DatanodeInfoWithStorage[127.0.0.1:44102,DS-0526ed22-decd-43e5-8151-9d4cf8a1dabf,DISK], DatanodeInfoWithStorage[127.0.0.1:45453,DS-fb985fbf-d3ab-4f95-8321-13fc4212f412,DISK], DatanodeInfoWithStorage[127.0.0.1:46097,DS-5a7a5fd3-a14b-40c3-839a-1cf6c06317a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45688,DS-f981e484-3bf4-417c-b54f-b93c4828e6a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39114,DS-23d61f8c-ef1f-498e-81e3-d1feaadeb222,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1928292918-172.17.0.3-1597668082151:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34182,DS-499f9d99-14d4-42af-a29f-603d6512ff84,DISK], DatanodeInfoWithStorage[127.0.0.1:39641,DS-2330643b-767e-4ac7-9c38-afc37e346083,DISK], DatanodeInfoWithStorage[127.0.0.1:41064,DS-7b74e603-12d1-44a3-aaf4-79349d0a2696,DISK], DatanodeInfoWithStorage[127.0.0.1:33423,DS-95c7f172-c698-4a5d-8842-f2c0eaebdaeb,DISK], DatanodeInfoWithStorage[127.0.0.1:41531,DS-97f51338-2f8e-4625-8de9-af3825891717,DISK], DatanodeInfoWithStorage[127.0.0.1:33273,DS-119618e0-d0fa-48c8-bedd-e57cabcf61d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34272,DS-4113ee58-ca76-44e1-9bc5-98d282feb09a,DISK], DatanodeInfoWithStorage[127.0.0.1:34512,DS-5d445333-1874-478f-b429-d24a1919fbad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1928292918-172.17.0.3-1597668082151:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34182,DS-499f9d99-14d4-42af-a29f-603d6512ff84,DISK], DatanodeInfoWithStorage[127.0.0.1:39641,DS-2330643b-767e-4ac7-9c38-afc37e346083,DISK], DatanodeInfoWithStorage[127.0.0.1:41064,DS-7b74e603-12d1-44a3-aaf4-79349d0a2696,DISK], DatanodeInfoWithStorage[127.0.0.1:33423,DS-95c7f172-c698-4a5d-8842-f2c0eaebdaeb,DISK], DatanodeInfoWithStorage[127.0.0.1:41531,DS-97f51338-2f8e-4625-8de9-af3825891717,DISK], DatanodeInfoWithStorage[127.0.0.1:33273,DS-119618e0-d0fa-48c8-bedd-e57cabcf61d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34272,DS-4113ee58-ca76-44e1-9bc5-98d282feb09a,DISK], DatanodeInfoWithStorage[127.0.0.1:34512,DS-5d445333-1874-478f-b429-d24a1919fbad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-801098551-172.17.0.3-1597668156468:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33448,DS-539c166f-12e8-489b-b029-a8d12141672d,DISK], DatanodeInfoWithStorage[127.0.0.1:40086,DS-aeb23874-a363-4c01-8801-aadbcccf50b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39385,DS-269984f9-8fc7-4a3e-a41e-83fb01e65516,DISK], DatanodeInfoWithStorage[127.0.0.1:36963,DS-f097b48d-f354-4dae-a79d-4b50c784b821,DISK], DatanodeInfoWithStorage[127.0.0.1:32946,DS-51736828-a96b-4203-8846-9ce559fbae2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42329,DS-d16c3730-07bf-44e9-bed4-27a16352300f,DISK], DatanodeInfoWithStorage[127.0.0.1:43902,DS-83b910b2-aa48-443b-860c-f532d52c93d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35457,DS-0583f606-3d65-45df-9e5d-55fffca5e713,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-801098551-172.17.0.3-1597668156468:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33448,DS-539c166f-12e8-489b-b029-a8d12141672d,DISK], DatanodeInfoWithStorage[127.0.0.1:40086,DS-aeb23874-a363-4c01-8801-aadbcccf50b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39385,DS-269984f9-8fc7-4a3e-a41e-83fb01e65516,DISK], DatanodeInfoWithStorage[127.0.0.1:36963,DS-f097b48d-f354-4dae-a79d-4b50c784b821,DISK], DatanodeInfoWithStorage[127.0.0.1:32946,DS-51736828-a96b-4203-8846-9ce559fbae2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42329,DS-d16c3730-07bf-44e9-bed4-27a16352300f,DISK], DatanodeInfoWithStorage[127.0.0.1:43902,DS-83b910b2-aa48-443b-860c-f532d52c93d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35457,DS-0583f606-3d65-45df-9e5d-55fffca5e713,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-788702880-172.17.0.3-1597669062280:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46350,DS-ffb33169-ab63-4d43-b020-c6f3de393159,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-5bdc64ff-1463-4f00-81ca-c35d1e5904f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43555,DS-64f5106f-9b76-4221-91cb-0a464d3dcf7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40413,DS-5487dfe8-c9cf-46d4-a40e-cbd986cfe37a,DISK], DatanodeInfoWithStorage[127.0.0.1:41324,DS-3f14ea44-581e-47b6-9323-5ba227fc86ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37610,DS-da449543-7963-4b23-9aea-89d104c73ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:46149,DS-5f5a5491-3f70-43fa-b97e-e5280dea4f29,DISK], DatanodeInfoWithStorage[127.0.0.1:34968,DS-9370d240-f89b-4bf8-a577-ba33593c982c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-788702880-172.17.0.3-1597669062280:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46350,DS-ffb33169-ab63-4d43-b020-c6f3de393159,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-5bdc64ff-1463-4f00-81ca-c35d1e5904f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43555,DS-64f5106f-9b76-4221-91cb-0a464d3dcf7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40413,DS-5487dfe8-c9cf-46d4-a40e-cbd986cfe37a,DISK], DatanodeInfoWithStorage[127.0.0.1:41324,DS-3f14ea44-581e-47b6-9323-5ba227fc86ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37610,DS-da449543-7963-4b23-9aea-89d104c73ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:46149,DS-5f5a5491-3f70-43fa-b97e-e5280dea4f29,DISK], DatanodeInfoWithStorage[127.0.0.1:34968,DS-9370d240-f89b-4bf8-a577-ba33593c982c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-454706420-172.17.0.3-1597669366367:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37262,DS-b33ae7bc-1ede-4be0-a942-b1a6626ec129,DISK], DatanodeInfoWithStorage[127.0.0.1:39913,DS-f7f1b3f0-ceff-4628-9253-7668f4dcd4ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38794,DS-57a74a52-7f27-4072-9111-11fa638c4eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:36772,DS-4d60da3e-2230-469c-b25e-c6e9734b318c,DISK], DatanodeInfoWithStorage[127.0.0.1:43070,DS-1c808fd0-e59f-4fcb-bf04-7d51d612ae0d,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-a2ca677a-429e-4991-894a-cba5a46a83e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46857,DS-17252cc2-8f71-494c-aab0-28cfa54ebef2,DISK], DatanodeInfoWithStorage[127.0.0.1:42298,DS-84c29b7e-74c6-4218-8314-876aee83e5ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-454706420-172.17.0.3-1597669366367:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37262,DS-b33ae7bc-1ede-4be0-a942-b1a6626ec129,DISK], DatanodeInfoWithStorage[127.0.0.1:39913,DS-f7f1b3f0-ceff-4628-9253-7668f4dcd4ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38794,DS-57a74a52-7f27-4072-9111-11fa638c4eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:36772,DS-4d60da3e-2230-469c-b25e-c6e9734b318c,DISK], DatanodeInfoWithStorage[127.0.0.1:43070,DS-1c808fd0-e59f-4fcb-bf04-7d51d612ae0d,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-a2ca677a-429e-4991-894a-cba5a46a83e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46857,DS-17252cc2-8f71-494c-aab0-28cfa54ebef2,DISK], DatanodeInfoWithStorage[127.0.0.1:42298,DS-84c29b7e-74c6-4218-8314-876aee83e5ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5816
