reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1099342297-172.17.0.9-1597501929487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35919,DS-e0e4cda2-b330-4038-a69d-4ad8a86f914b,DISK], DatanodeInfoWithStorage[127.0.0.1:43139,DS-265fcd30-abd0-41ce-a64f-81c4474a3d61,DISK], DatanodeInfoWithStorage[127.0.0.1:40553,DS-430c66cd-cb02-4334-9d7c-882a0e83c72d,DISK], DatanodeInfoWithStorage[127.0.0.1:35229,DS-bc76aaae-3245-40be-a4b7-87fad36a1394,DISK], DatanodeInfoWithStorage[127.0.0.1:41545,DS-893ccaa3-ea8c-482a-9e70-807338ee2957,DISK], DatanodeInfoWithStorage[127.0.0.1:44380,DS-a1230ddf-c576-42ba-aa25-41dfe1afc5a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33558,DS-f7e5cb4e-8014-4a4e-a874-a57fa02e1d28,DISK], DatanodeInfoWithStorage[127.0.0.1:40357,DS-bb601572-4885-48a1-a34d-7660ac4c144a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1099342297-172.17.0.9-1597501929487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35919,DS-e0e4cda2-b330-4038-a69d-4ad8a86f914b,DISK], DatanodeInfoWithStorage[127.0.0.1:43139,DS-265fcd30-abd0-41ce-a64f-81c4474a3d61,DISK], DatanodeInfoWithStorage[127.0.0.1:40553,DS-430c66cd-cb02-4334-9d7c-882a0e83c72d,DISK], DatanodeInfoWithStorage[127.0.0.1:35229,DS-bc76aaae-3245-40be-a4b7-87fad36a1394,DISK], DatanodeInfoWithStorage[127.0.0.1:41545,DS-893ccaa3-ea8c-482a-9e70-807338ee2957,DISK], DatanodeInfoWithStorage[127.0.0.1:44380,DS-a1230ddf-c576-42ba-aa25-41dfe1afc5a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33558,DS-f7e5cb4e-8014-4a4e-a874-a57fa02e1d28,DISK], DatanodeInfoWithStorage[127.0.0.1:40357,DS-bb601572-4885-48a1-a34d-7660ac4c144a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1640301061-172.17.0.9-1597502328479:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33545,DS-f601cd86-efec-48a6-8830-dc81cf4c0645,DISK], DatanodeInfoWithStorage[127.0.0.1:39525,DS-400f62ca-f23c-40b7-a1ac-06ccbb5b3b86,DISK], DatanodeInfoWithStorage[127.0.0.1:45364,DS-5bed5ca0-febd-42f9-82be-240a65537296,DISK], DatanodeInfoWithStorage[127.0.0.1:46561,DS-81766854-b664-443a-9761-4b88cec27342,DISK], DatanodeInfoWithStorage[127.0.0.1:38164,DS-57a521cd-302c-49ad-a4cc-740bca06f1c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37264,DS-2e5c3de0-c991-46e5-b9a6-ef394e0ba5f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36892,DS-91593628-4708-4adc-96f7-160f16163b50,DISK], DatanodeInfoWithStorage[127.0.0.1:43300,DS-a889d2f0-b58a-4b1f-8b5e-b50f4413ff1c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1640301061-172.17.0.9-1597502328479:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33545,DS-f601cd86-efec-48a6-8830-dc81cf4c0645,DISK], DatanodeInfoWithStorage[127.0.0.1:39525,DS-400f62ca-f23c-40b7-a1ac-06ccbb5b3b86,DISK], DatanodeInfoWithStorage[127.0.0.1:45364,DS-5bed5ca0-febd-42f9-82be-240a65537296,DISK], DatanodeInfoWithStorage[127.0.0.1:46561,DS-81766854-b664-443a-9761-4b88cec27342,DISK], DatanodeInfoWithStorage[127.0.0.1:38164,DS-57a521cd-302c-49ad-a4cc-740bca06f1c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37264,DS-2e5c3de0-c991-46e5-b9a6-ef394e0ba5f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36892,DS-91593628-4708-4adc-96f7-160f16163b50,DISK], DatanodeInfoWithStorage[127.0.0.1:43300,DS-a889d2f0-b58a-4b1f-8b5e-b50f4413ff1c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-517593983-172.17.0.9-1597502515017:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39941,DS-6d89c6e1-9da0-4b26-969e-392e2da13779,DISK], DatanodeInfoWithStorage[127.0.0.1:39404,DS-b14cc922-3ebe-485f-8249-a284760bc285,DISK], DatanodeInfoWithStorage[127.0.0.1:37528,DS-8686f54f-214e-40de-bf11-25a83592c6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37467,DS-35d86ba6-6bca-4508-8341-c27b924b63f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37134,DS-89b4f602-4df3-4608-925f-0a388bcfaeb7,DISK], DatanodeInfoWithStorage[127.0.0.1:43222,DS-77c478f7-68ed-4e54-bb4d-f8c505aab793,DISK], DatanodeInfoWithStorage[127.0.0.1:46795,DS-5fb7f808-f095-47d3-9bf4-0abfc841d469,DISK], DatanodeInfoWithStorage[127.0.0.1:33654,DS-8f91ae69-3cfc-4de6-b29d-676fc148149c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-517593983-172.17.0.9-1597502515017:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39941,DS-6d89c6e1-9da0-4b26-969e-392e2da13779,DISK], DatanodeInfoWithStorage[127.0.0.1:39404,DS-b14cc922-3ebe-485f-8249-a284760bc285,DISK], DatanodeInfoWithStorage[127.0.0.1:37528,DS-8686f54f-214e-40de-bf11-25a83592c6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37467,DS-35d86ba6-6bca-4508-8341-c27b924b63f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37134,DS-89b4f602-4df3-4608-925f-0a388bcfaeb7,DISK], DatanodeInfoWithStorage[127.0.0.1:43222,DS-77c478f7-68ed-4e54-bb4d-f8c505aab793,DISK], DatanodeInfoWithStorage[127.0.0.1:46795,DS-5fb7f808-f095-47d3-9bf4-0abfc841d469,DISK], DatanodeInfoWithStorage[127.0.0.1:33654,DS-8f91ae69-3cfc-4de6-b29d-676fc148149c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1732732401-172.17.0.9-1597502659484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36889,DS-40e62ed6-ea31-463c-89e6-6956a9a99f37,DISK], DatanodeInfoWithStorage[127.0.0.1:43381,DS-9b928538-e54f-4fc3-b553-26d7535e99f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44877,DS-793b095e-e580-4deb-8aa2-f76810dee7fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38824,DS-32adf9e8-495f-4047-a0b6-cd07c9b69e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:45951,DS-8bad19bd-a613-48d5-bd47-4e836f415ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:45503,DS-020e01b6-9085-4f1f-99a8-8a3b21e9f96e,DISK], DatanodeInfoWithStorage[127.0.0.1:45379,DS-3bab07bc-2fbf-4122-9c20-1d2003cba357,DISK], DatanodeInfoWithStorage[127.0.0.1:37867,DS-f7933b45-080d-4b3c-a9f1-e4a449965d2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1732732401-172.17.0.9-1597502659484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36889,DS-40e62ed6-ea31-463c-89e6-6956a9a99f37,DISK], DatanodeInfoWithStorage[127.0.0.1:43381,DS-9b928538-e54f-4fc3-b553-26d7535e99f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44877,DS-793b095e-e580-4deb-8aa2-f76810dee7fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38824,DS-32adf9e8-495f-4047-a0b6-cd07c9b69e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:45951,DS-8bad19bd-a613-48d5-bd47-4e836f415ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:45503,DS-020e01b6-9085-4f1f-99a8-8a3b21e9f96e,DISK], DatanodeInfoWithStorage[127.0.0.1:45379,DS-3bab07bc-2fbf-4122-9c20-1d2003cba357,DISK], DatanodeInfoWithStorage[127.0.0.1:37867,DS-f7933b45-080d-4b3c-a9f1-e4a449965d2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-86306537-172.17.0.9-1597502702826:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46619,DS-6b227c4d-0489-4fc5-8bf8-318792bbd627,DISK], DatanodeInfoWithStorage[127.0.0.1:41964,DS-c985f88b-d07f-48ed-8add-6259c98149ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34368,DS-ea843f6a-9509-4da7-82b8-75ea90e8d537,DISK], DatanodeInfoWithStorage[127.0.0.1:42469,DS-f9321ccc-7b31-4bf7-b59b-940c69e24798,DISK], DatanodeInfoWithStorage[127.0.0.1:44363,DS-9e5f61a6-2740-4037-8f17-e8325445c7ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42607,DS-1321b546-0d52-4282-b64b-8320b391a7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41698,DS-2f9d3aef-8a71-4752-90a9-37d75aec31bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45912,DS-d3835994-8919-44b4-8420-50bede893402,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-86306537-172.17.0.9-1597502702826:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46619,DS-6b227c4d-0489-4fc5-8bf8-318792bbd627,DISK], DatanodeInfoWithStorage[127.0.0.1:41964,DS-c985f88b-d07f-48ed-8add-6259c98149ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34368,DS-ea843f6a-9509-4da7-82b8-75ea90e8d537,DISK], DatanodeInfoWithStorage[127.0.0.1:42469,DS-f9321ccc-7b31-4bf7-b59b-940c69e24798,DISK], DatanodeInfoWithStorage[127.0.0.1:44363,DS-9e5f61a6-2740-4037-8f17-e8325445c7ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42607,DS-1321b546-0d52-4282-b64b-8320b391a7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41698,DS-2f9d3aef-8a71-4752-90a9-37d75aec31bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45912,DS-d3835994-8919-44b4-8420-50bede893402,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-675073572-172.17.0.9-1597503053967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37754,DS-a36f93f6-8320-40eb-b251-d34939a81de7,DISK], DatanodeInfoWithStorage[127.0.0.1:43737,DS-eadce4ac-44ae-4de6-bf9a-850580ae592e,DISK], DatanodeInfoWithStorage[127.0.0.1:43666,DS-6811a994-3bbd-4ca2-a427-b4f5b1632e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:38081,DS-ed8080bb-e592-4cb5-af2e-609c82bdf986,DISK], DatanodeInfoWithStorage[127.0.0.1:36958,DS-68ef0c2b-f33c-45ac-8cfc-7924c831f6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44017,DS-bd21e86d-f6ed-4197-8515-7723c06972f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36049,DS-3c6df476-4986-41d2-b7cc-c54503810a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40028,DS-809a68a0-9d82-4c75-ab13-dd850cbe8bc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-675073572-172.17.0.9-1597503053967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37754,DS-a36f93f6-8320-40eb-b251-d34939a81de7,DISK], DatanodeInfoWithStorage[127.0.0.1:43737,DS-eadce4ac-44ae-4de6-bf9a-850580ae592e,DISK], DatanodeInfoWithStorage[127.0.0.1:43666,DS-6811a994-3bbd-4ca2-a427-b4f5b1632e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:38081,DS-ed8080bb-e592-4cb5-af2e-609c82bdf986,DISK], DatanodeInfoWithStorage[127.0.0.1:36958,DS-68ef0c2b-f33c-45ac-8cfc-7924c831f6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44017,DS-bd21e86d-f6ed-4197-8515-7723c06972f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36049,DS-3c6df476-4986-41d2-b7cc-c54503810a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40028,DS-809a68a0-9d82-4c75-ab13-dd850cbe8bc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2105218498-172.17.0.9-1597503295473:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34673,DS-829e0b80-c4b0-49ee-abb7-412f05ad07cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44828,DS-eb41fe75-061d-4692-915d-23e3d023ab5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42909,DS-6f5b36d4-713f-4cf7-bdb5-dfbc3662794e,DISK], DatanodeInfoWithStorage[127.0.0.1:46607,DS-d47b6f93-159c-4c4c-a67e-e29e2e5cd783,DISK], DatanodeInfoWithStorage[127.0.0.1:40177,DS-660a6819-e367-405f-9e5d-19a81c002c93,DISK], DatanodeInfoWithStorage[127.0.0.1:38286,DS-eb74521a-09a0-4d6e-b307-b0b08e4331be,DISK], DatanodeInfoWithStorage[127.0.0.1:34584,DS-6dcbae09-9034-4ae8-a4ef-520b0829de59,DISK], DatanodeInfoWithStorage[127.0.0.1:34707,DS-cf42054e-f3d2-439a-be19-76f9d8d8dd20,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2105218498-172.17.0.9-1597503295473:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34673,DS-829e0b80-c4b0-49ee-abb7-412f05ad07cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44828,DS-eb41fe75-061d-4692-915d-23e3d023ab5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42909,DS-6f5b36d4-713f-4cf7-bdb5-dfbc3662794e,DISK], DatanodeInfoWithStorage[127.0.0.1:46607,DS-d47b6f93-159c-4c4c-a67e-e29e2e5cd783,DISK], DatanodeInfoWithStorage[127.0.0.1:40177,DS-660a6819-e367-405f-9e5d-19a81c002c93,DISK], DatanodeInfoWithStorage[127.0.0.1:38286,DS-eb74521a-09a0-4d6e-b307-b0b08e4331be,DISK], DatanodeInfoWithStorage[127.0.0.1:34584,DS-6dcbae09-9034-4ae8-a4ef-520b0829de59,DISK], DatanodeInfoWithStorage[127.0.0.1:34707,DS-cf42054e-f3d2-439a-be19-76f9d8d8dd20,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1325846148-172.17.0.9-1597503332157:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34779,DS-a67cfccc-f6e4-4b2b-8d15-2e71f670fcd1,DISK], DatanodeInfoWithStorage[127.0.0.1:38154,DS-71817cb7-25e3-4a2b-aaa9-7630a451a8d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38760,DS-34d675ff-b32c-40f8-8757-2e8b1aa1b8de,DISK], DatanodeInfoWithStorage[127.0.0.1:37635,DS-66f6cf15-9739-45cc-857a-7842c53dc707,DISK], DatanodeInfoWithStorage[127.0.0.1:39236,DS-50ce4234-3f7d-4348-b1b7-bdfd99bfd068,DISK], DatanodeInfoWithStorage[127.0.0.1:33624,DS-5debf988-963f-4172-b09f-d43be76452c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37698,DS-d072eb60-a92d-4788-9cba-67d88e566cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:32862,DS-9e85723e-8510-4d54-8be3-2e2959c6fa67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1325846148-172.17.0.9-1597503332157:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34779,DS-a67cfccc-f6e4-4b2b-8d15-2e71f670fcd1,DISK], DatanodeInfoWithStorage[127.0.0.1:38154,DS-71817cb7-25e3-4a2b-aaa9-7630a451a8d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38760,DS-34d675ff-b32c-40f8-8757-2e8b1aa1b8de,DISK], DatanodeInfoWithStorage[127.0.0.1:37635,DS-66f6cf15-9739-45cc-857a-7842c53dc707,DISK], DatanodeInfoWithStorage[127.0.0.1:39236,DS-50ce4234-3f7d-4348-b1b7-bdfd99bfd068,DISK], DatanodeInfoWithStorage[127.0.0.1:33624,DS-5debf988-963f-4172-b09f-d43be76452c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37698,DS-d072eb60-a92d-4788-9cba-67d88e566cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:32862,DS-9e85723e-8510-4d54-8be3-2e2959c6fa67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1095242207-172.17.0.9-1597503629474:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37800,DS-9a1221cf-63fb-492a-a273-1984ffd3abe4,DISK], DatanodeInfoWithStorage[127.0.0.1:43888,DS-2aa0b1f0-46f1-4983-a341-3fea34e74dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:42516,DS-e3b9e45c-dfef-4bc2-be18-a72229978931,DISK], DatanodeInfoWithStorage[127.0.0.1:38472,DS-63b61bac-8bc6-4710-b689-917b64a6630e,DISK], DatanodeInfoWithStorage[127.0.0.1:43424,DS-4a47d6d2-503a-46c0-b4a1-3f495d89d318,DISK], DatanodeInfoWithStorage[127.0.0.1:36648,DS-fabd3fd3-970e-4f23-8cd3-1bd650693147,DISK], DatanodeInfoWithStorage[127.0.0.1:39177,DS-c537d151-18cd-4b9d-9508-1ba99f34fde6,DISK], DatanodeInfoWithStorage[127.0.0.1:36858,DS-b987a7dd-1cb0-4a7a-9ab7-c2678900f026,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1095242207-172.17.0.9-1597503629474:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37800,DS-9a1221cf-63fb-492a-a273-1984ffd3abe4,DISK], DatanodeInfoWithStorage[127.0.0.1:43888,DS-2aa0b1f0-46f1-4983-a341-3fea34e74dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:42516,DS-e3b9e45c-dfef-4bc2-be18-a72229978931,DISK], DatanodeInfoWithStorage[127.0.0.1:38472,DS-63b61bac-8bc6-4710-b689-917b64a6630e,DISK], DatanodeInfoWithStorage[127.0.0.1:43424,DS-4a47d6d2-503a-46c0-b4a1-3f495d89d318,DISK], DatanodeInfoWithStorage[127.0.0.1:36648,DS-fabd3fd3-970e-4f23-8cd3-1bd650693147,DISK], DatanodeInfoWithStorage[127.0.0.1:39177,DS-c537d151-18cd-4b9d-9508-1ba99f34fde6,DISK], DatanodeInfoWithStorage[127.0.0.1:36858,DS-b987a7dd-1cb0-4a7a-9ab7-c2678900f026,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1251922006-172.17.0.9-1597503771631:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43506,DS-f7074ef8-c009-4291-8594-a4188c343cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:38974,DS-e367e13f-e5d8-469b-8d18-68872c57ba27,DISK], DatanodeInfoWithStorage[127.0.0.1:40020,DS-5504cb59-390b-4ebe-81aa-0b6bb82a8864,DISK], DatanodeInfoWithStorage[127.0.0.1:46009,DS-0bc450a9-c3c7-4e15-824c-2eb556916eed,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-42a0d627-8cbb-4fbd-8421-ca7d3f1c31bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46665,DS-cb239183-99d2-4df2-8263-70350f29f7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43147,DS-b3f20a37-7f47-44cd-b19c-71db30869147,DISK], DatanodeInfoWithStorage[127.0.0.1:40703,DS-07c45df7-f146-4b6b-bd41-eb1d58f2a2d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1251922006-172.17.0.9-1597503771631:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43506,DS-f7074ef8-c009-4291-8594-a4188c343cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:38974,DS-e367e13f-e5d8-469b-8d18-68872c57ba27,DISK], DatanodeInfoWithStorage[127.0.0.1:40020,DS-5504cb59-390b-4ebe-81aa-0b6bb82a8864,DISK], DatanodeInfoWithStorage[127.0.0.1:46009,DS-0bc450a9-c3c7-4e15-824c-2eb556916eed,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-42a0d627-8cbb-4fbd-8421-ca7d3f1c31bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46665,DS-cb239183-99d2-4df2-8263-70350f29f7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43147,DS-b3f20a37-7f47-44cd-b19c-71db30869147,DISK], DatanodeInfoWithStorage[127.0.0.1:40703,DS-07c45df7-f146-4b6b-bd41-eb1d58f2a2d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-351233975-172.17.0.9-1597504017775:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35845,DS-97771ade-c8f9-482d-884b-28143f01c8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39756,DS-ab803d3c-a88d-4aa8-8105-cb1238f913e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42257,DS-af698c45-e247-4e57-8756-61128828d4be,DISK], DatanodeInfoWithStorage[127.0.0.1:41476,DS-518c8281-1b1e-4ed3-9fc7-7a06f5df99b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45585,DS-76c0024d-720f-48e3-ba90-823466707f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41747,DS-9907bc21-81fc-463e-994f-234f4026b233,DISK], DatanodeInfoWithStorage[127.0.0.1:43725,DS-37587f7b-1025-4646-b34a-cd857eb6717a,DISK], DatanodeInfoWithStorage[127.0.0.1:44240,DS-15ca12b0-124e-4e4a-98b2-95250da9796e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-351233975-172.17.0.9-1597504017775:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35845,DS-97771ade-c8f9-482d-884b-28143f01c8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39756,DS-ab803d3c-a88d-4aa8-8105-cb1238f913e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42257,DS-af698c45-e247-4e57-8756-61128828d4be,DISK], DatanodeInfoWithStorage[127.0.0.1:41476,DS-518c8281-1b1e-4ed3-9fc7-7a06f5df99b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45585,DS-76c0024d-720f-48e3-ba90-823466707f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41747,DS-9907bc21-81fc-463e-994f-234f4026b233,DISK], DatanodeInfoWithStorage[127.0.0.1:43725,DS-37587f7b-1025-4646-b34a-cd857eb6717a,DISK], DatanodeInfoWithStorage[127.0.0.1:44240,DS-15ca12b0-124e-4e4a-98b2-95250da9796e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1296910692-172.17.0.9-1597504058101:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37258,DS-90d84f3a-9da2-4571-b7cd-3911e959a2b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46058,DS-f5261219-1a95-4053-8cca-80dc0656645b,DISK], DatanodeInfoWithStorage[127.0.0.1:33515,DS-2e7d4de2-f1e9-4847-8c0e-c9b15de28b32,DISK], DatanodeInfoWithStorage[127.0.0.1:43124,DS-87a03c44-ed50-4ba3-a9d3-dcc178558f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:33720,DS-939c94cb-c1da-4576-ac41-6a9fafa0cce8,DISK], DatanodeInfoWithStorage[127.0.0.1:39908,DS-235bf71d-82d6-45d4-a6a8-82c16fb9d4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37603,DS-496f6cf2-c0c9-44ac-8ff4-574e8ff6346b,DISK], DatanodeInfoWithStorage[127.0.0.1:34141,DS-a0f09ece-2d2c-40cb-9827-444d2b98ef1b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1296910692-172.17.0.9-1597504058101:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37258,DS-90d84f3a-9da2-4571-b7cd-3911e959a2b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46058,DS-f5261219-1a95-4053-8cca-80dc0656645b,DISK], DatanodeInfoWithStorage[127.0.0.1:33515,DS-2e7d4de2-f1e9-4847-8c0e-c9b15de28b32,DISK], DatanodeInfoWithStorage[127.0.0.1:43124,DS-87a03c44-ed50-4ba3-a9d3-dcc178558f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:33720,DS-939c94cb-c1da-4576-ac41-6a9fafa0cce8,DISK], DatanodeInfoWithStorage[127.0.0.1:39908,DS-235bf71d-82d6-45d4-a6a8-82c16fb9d4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37603,DS-496f6cf2-c0c9-44ac-8ff4-574e8ff6346b,DISK], DatanodeInfoWithStorage[127.0.0.1:34141,DS-a0f09ece-2d2c-40cb-9827-444d2b98ef1b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1819537568-172.17.0.9-1597504119716:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36745,DS-4fe37551-6210-455e-8ccc-e93aa48465b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37445,DS-f82678fc-183b-4b52-a5e8-ad057d85341a,DISK], DatanodeInfoWithStorage[127.0.0.1:41837,DS-c9ef282e-726d-4e03-b3aa-5b2b1dc2dd20,DISK], DatanodeInfoWithStorage[127.0.0.1:37091,DS-af018821-2242-4d09-b9eb-648a9f642c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37425,DS-f29a1f07-58db-4817-956a-aa6f3e045b65,DISK], DatanodeInfoWithStorage[127.0.0.1:37696,DS-c0ef4145-3231-459f-b6c6-cf5ce842f5bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41865,DS-f217efd9-f947-4aa3-93fc-4841f47c465a,DISK], DatanodeInfoWithStorage[127.0.0.1:43055,DS-0eb68bf6-788a-461c-b2bc-e72a80beb719,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1819537568-172.17.0.9-1597504119716:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36745,DS-4fe37551-6210-455e-8ccc-e93aa48465b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37445,DS-f82678fc-183b-4b52-a5e8-ad057d85341a,DISK], DatanodeInfoWithStorage[127.0.0.1:41837,DS-c9ef282e-726d-4e03-b3aa-5b2b1dc2dd20,DISK], DatanodeInfoWithStorage[127.0.0.1:37091,DS-af018821-2242-4d09-b9eb-648a9f642c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37425,DS-f29a1f07-58db-4817-956a-aa6f3e045b65,DISK], DatanodeInfoWithStorage[127.0.0.1:37696,DS-c0ef4145-3231-459f-b6c6-cf5ce842f5bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41865,DS-f217efd9-f947-4aa3-93fc-4841f47c465a,DISK], DatanodeInfoWithStorage[127.0.0.1:43055,DS-0eb68bf6-788a-461c-b2bc-e72a80beb719,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1964612050-172.17.0.9-1597504383387:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36533,DS-3c93e6be-15e9-4674-aa49-ca2ce6ec4d05,DISK], DatanodeInfoWithStorage[127.0.0.1:34060,DS-8ba3697d-6a6c-4248-a770-3bf468985268,DISK], DatanodeInfoWithStorage[127.0.0.1:37927,DS-a1ea14d2-f066-4fb5-a5fa-e50daddc7422,DISK], DatanodeInfoWithStorage[127.0.0.1:43791,DS-b5ca21cb-a9b8-4df0-abbb-dc9f7554e355,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-30f15ec6-87b2-4e18-8bd0-ac6ac88aff6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39675,DS-96dcfed7-58d2-496a-93e8-974f6c6c5991,DISK], DatanodeInfoWithStorage[127.0.0.1:40968,DS-163fea4b-eb53-454d-a3e7-2db4e44b99e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34116,DS-b2b11cbd-8f05-47ff-a3c5-942ee9fbfea5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1964612050-172.17.0.9-1597504383387:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36533,DS-3c93e6be-15e9-4674-aa49-ca2ce6ec4d05,DISK], DatanodeInfoWithStorage[127.0.0.1:34060,DS-8ba3697d-6a6c-4248-a770-3bf468985268,DISK], DatanodeInfoWithStorage[127.0.0.1:37927,DS-a1ea14d2-f066-4fb5-a5fa-e50daddc7422,DISK], DatanodeInfoWithStorage[127.0.0.1:43791,DS-b5ca21cb-a9b8-4df0-abbb-dc9f7554e355,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-30f15ec6-87b2-4e18-8bd0-ac6ac88aff6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39675,DS-96dcfed7-58d2-496a-93e8-974f6c6c5991,DISK], DatanodeInfoWithStorage[127.0.0.1:40968,DS-163fea4b-eb53-454d-a3e7-2db4e44b99e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34116,DS-b2b11cbd-8f05-47ff-a3c5-942ee9fbfea5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-537303400-172.17.0.9-1597504565170:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35827,DS-788fcf3d-74dd-4db1-b519-7ac366987adc,DISK], DatanodeInfoWithStorage[127.0.0.1:37994,DS-07878d93-a5bc-4583-8454-07feb777a4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44195,DS-a4c79ef4-8ce2-43d2-ae74-5155f26881bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41557,DS-89180dad-3d1e-48a9-86d6-ab649e135a54,DISK], DatanodeInfoWithStorage[127.0.0.1:39606,DS-9745fbea-ded9-4ba7-a810-19db4db2d48a,DISK], DatanodeInfoWithStorage[127.0.0.1:44691,DS-3b7e2d1a-a321-4846-a2a1-2ce0f859aa3e,DISK], DatanodeInfoWithStorage[127.0.0.1:41285,DS-3f74aac4-788b-4828-8953-f43704180b55,DISK], DatanodeInfoWithStorage[127.0.0.1:39511,DS-260e50e9-119a-48d4-b68c-a6d95d80c147,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-537303400-172.17.0.9-1597504565170:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35827,DS-788fcf3d-74dd-4db1-b519-7ac366987adc,DISK], DatanodeInfoWithStorage[127.0.0.1:37994,DS-07878d93-a5bc-4583-8454-07feb777a4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44195,DS-a4c79ef4-8ce2-43d2-ae74-5155f26881bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41557,DS-89180dad-3d1e-48a9-86d6-ab649e135a54,DISK], DatanodeInfoWithStorage[127.0.0.1:39606,DS-9745fbea-ded9-4ba7-a810-19db4db2d48a,DISK], DatanodeInfoWithStorage[127.0.0.1:44691,DS-3b7e2d1a-a321-4846-a2a1-2ce0f859aa3e,DISK], DatanodeInfoWithStorage[127.0.0.1:41285,DS-3f74aac4-788b-4828-8953-f43704180b55,DISK], DatanodeInfoWithStorage[127.0.0.1:39511,DS-260e50e9-119a-48d4-b68c-a6d95d80c147,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1402504267-172.17.0.9-1597504600344:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40620,DS-0d8caba0-8fd9-4013-ba04-03daa2ffb4f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41586,DS-629c6808-3afe-4d2d-ad1b-de8050b34a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:40817,DS-4945f3a5-ae80-49b3-94da-da3fa19f270b,DISK], DatanodeInfoWithStorage[127.0.0.1:44411,DS-478ddd52-6ce8-4417-bf58-1f16b7f647ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46437,DS-62352b0d-fb7f-440b-a0fd-079606338656,DISK], DatanodeInfoWithStorage[127.0.0.1:36242,DS-e5224cbb-a8db-4163-834c-d7d3d65e8d05,DISK], DatanodeInfoWithStorage[127.0.0.1:36752,DS-f2c332e1-8dd5-418d-a2b0-00bdd798754e,DISK], DatanodeInfoWithStorage[127.0.0.1:42289,DS-e0445300-e496-4b0b-b3d1-f98d15295339,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1402504267-172.17.0.9-1597504600344:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40620,DS-0d8caba0-8fd9-4013-ba04-03daa2ffb4f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41586,DS-629c6808-3afe-4d2d-ad1b-de8050b34a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:40817,DS-4945f3a5-ae80-49b3-94da-da3fa19f270b,DISK], DatanodeInfoWithStorage[127.0.0.1:44411,DS-478ddd52-6ce8-4417-bf58-1f16b7f647ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46437,DS-62352b0d-fb7f-440b-a0fd-079606338656,DISK], DatanodeInfoWithStorage[127.0.0.1:36242,DS-e5224cbb-a8db-4163-834c-d7d3d65e8d05,DISK], DatanodeInfoWithStorage[127.0.0.1:36752,DS-f2c332e1-8dd5-418d-a2b0-00bdd798754e,DISK], DatanodeInfoWithStorage[127.0.0.1:42289,DS-e0445300-e496-4b0b-b3d1-f98d15295339,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1650168008-172.17.0.9-1597504862965:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43226,DS-2011f04a-1b23-4195-9945-403ac1dfb39a,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-086731df-d985-4af0-a83f-02015f59c7d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45913,DS-f11fac62-94a2-4110-8dca-905d49c86ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:40214,DS-675f2333-2033-433e-bafa-dda4cd5c72cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35517,DS-5c8c5956-29b9-4f25-a418-d98cf7af6d68,DISK], DatanodeInfoWithStorage[127.0.0.1:35635,DS-46efe9e9-0912-4b3d-baf6-8c088749e6bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33677,DS-3069bcae-ea19-44b5-8b41-cd6f7f77a887,DISK], DatanodeInfoWithStorage[127.0.0.1:38573,DS-82c26d2a-a0e3-47a0-bbdd-25ed844dbff3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1650168008-172.17.0.9-1597504862965:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43226,DS-2011f04a-1b23-4195-9945-403ac1dfb39a,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-086731df-d985-4af0-a83f-02015f59c7d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45913,DS-f11fac62-94a2-4110-8dca-905d49c86ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:40214,DS-675f2333-2033-433e-bafa-dda4cd5c72cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35517,DS-5c8c5956-29b9-4f25-a418-d98cf7af6d68,DISK], DatanodeInfoWithStorage[127.0.0.1:35635,DS-46efe9e9-0912-4b3d-baf6-8c088749e6bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33677,DS-3069bcae-ea19-44b5-8b41-cd6f7f77a887,DISK], DatanodeInfoWithStorage[127.0.0.1:38573,DS-82c26d2a-a0e3-47a0-bbdd-25ed844dbff3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1568683417-172.17.0.9-1597505113723:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38885,DS-bd708b15-225f-4e37-ad7a-49cfbfaab446,DISK], DatanodeInfoWithStorage[127.0.0.1:44958,DS-4e3c8df0-d1a2-45e3-b5e3-e0337ec9f7dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45474,DS-fc30dc2a-b510-45ba-ba08-d961843ef9fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37196,DS-aeb8fe45-d21b-4741-a93e-9f258952fc66,DISK], DatanodeInfoWithStorage[127.0.0.1:37907,DS-b1397740-91bc-41b1-9085-034d6e65b236,DISK], DatanodeInfoWithStorage[127.0.0.1:40490,DS-730c3381-27a9-44d9-a7cc-482b1d94afa2,DISK], DatanodeInfoWithStorage[127.0.0.1:46657,DS-f33a7099-a75f-44fd-bfdb-b5be4dc75bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:42413,DS-a900b26b-effc-4531-8543-16e677baa97a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1568683417-172.17.0.9-1597505113723:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38885,DS-bd708b15-225f-4e37-ad7a-49cfbfaab446,DISK], DatanodeInfoWithStorage[127.0.0.1:44958,DS-4e3c8df0-d1a2-45e3-b5e3-e0337ec9f7dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45474,DS-fc30dc2a-b510-45ba-ba08-d961843ef9fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37196,DS-aeb8fe45-d21b-4741-a93e-9f258952fc66,DISK], DatanodeInfoWithStorage[127.0.0.1:37907,DS-b1397740-91bc-41b1-9085-034d6e65b236,DISK], DatanodeInfoWithStorage[127.0.0.1:40490,DS-730c3381-27a9-44d9-a7cc-482b1d94afa2,DISK], DatanodeInfoWithStorage[127.0.0.1:46657,DS-f33a7099-a75f-44fd-bfdb-b5be4dc75bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:42413,DS-a900b26b-effc-4531-8543-16e677baa97a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-108573513-172.17.0.9-1597505421871:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34313,DS-6911fb49-92ad-4b91-8121-41c2ca218af4,DISK], DatanodeInfoWithStorage[127.0.0.1:33670,DS-a25c7d22-1142-4c9a-839d-801a58f49e56,DISK], DatanodeInfoWithStorage[127.0.0.1:42988,DS-238db8ab-86c9-418d-88c2-7188c59b04b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36973,DS-ab05923e-d800-412a-8bb4-5766eec4f709,DISK], DatanodeInfoWithStorage[127.0.0.1:37399,DS-b027ee2e-9d34-4a0b-84a7-bdcf219de278,DISK], DatanodeInfoWithStorage[127.0.0.1:45899,DS-b07df341-2aa9-4060-bf0f-ca67179bb965,DISK], DatanodeInfoWithStorage[127.0.0.1:39586,DS-8be153d9-d667-4fa5-b48c-0fdac421e00b,DISK], DatanodeInfoWithStorage[127.0.0.1:39096,DS-2cc153e4-5793-43f4-86ed-2ed925a6e506,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-108573513-172.17.0.9-1597505421871:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34313,DS-6911fb49-92ad-4b91-8121-41c2ca218af4,DISK], DatanodeInfoWithStorage[127.0.0.1:33670,DS-a25c7d22-1142-4c9a-839d-801a58f49e56,DISK], DatanodeInfoWithStorage[127.0.0.1:42988,DS-238db8ab-86c9-418d-88c2-7188c59b04b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36973,DS-ab05923e-d800-412a-8bb4-5766eec4f709,DISK], DatanodeInfoWithStorage[127.0.0.1:37399,DS-b027ee2e-9d34-4a0b-84a7-bdcf219de278,DISK], DatanodeInfoWithStorage[127.0.0.1:45899,DS-b07df341-2aa9-4060-bf0f-ca67179bb965,DISK], DatanodeInfoWithStorage[127.0.0.1:39586,DS-8be153d9-d667-4fa5-b48c-0fdac421e00b,DISK], DatanodeInfoWithStorage[127.0.0.1:39096,DS-2cc153e4-5793-43f4-86ed-2ed925a6e506,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1307396142-172.17.0.9-1597505463414:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35485,DS-32da78eb-1089-47dc-b501-1e96240e2ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:36392,DS-7926e943-4dd8-4b99-96a7-ae3bc558ba9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40274,DS-1acd4281-fcd7-4209-a2ac-e6a0ad4c2b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40626,DS-1dd594a8-60fb-4f3c-a09f-fcae7fed05ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37052,DS-3b0192d3-78f6-42b8-84bd-e93c5ba08a62,DISK], DatanodeInfoWithStorage[127.0.0.1:37911,DS-659bdebb-b11d-491d-808d-635995c552ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33243,DS-f1d34264-afe6-42c5-a1e0-cfee24841de7,DISK], DatanodeInfoWithStorage[127.0.0.1:43375,DS-89595bae-bd66-4123-bcb9-c4569b72c801,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1307396142-172.17.0.9-1597505463414:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35485,DS-32da78eb-1089-47dc-b501-1e96240e2ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:36392,DS-7926e943-4dd8-4b99-96a7-ae3bc558ba9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40274,DS-1acd4281-fcd7-4209-a2ac-e6a0ad4c2b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40626,DS-1dd594a8-60fb-4f3c-a09f-fcae7fed05ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37052,DS-3b0192d3-78f6-42b8-84bd-e93c5ba08a62,DISK], DatanodeInfoWithStorage[127.0.0.1:37911,DS-659bdebb-b11d-491d-808d-635995c552ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33243,DS-f1d34264-afe6-42c5-a1e0-cfee24841de7,DISK], DatanodeInfoWithStorage[127.0.0.1:43375,DS-89595bae-bd66-4123-bcb9-c4569b72c801,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-327612869-172.17.0.9-1597505577348:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41623,DS-fdf437fc-cf32-467c-b68b-39698392adac,DISK], DatanodeInfoWithStorage[127.0.0.1:35866,DS-0ae96000-fdb3-44e5-9f24-d7105ca0fa0b,DISK], DatanodeInfoWithStorage[127.0.0.1:42683,DS-7d84d971-8c10-4dd1-8241-70722b496396,DISK], DatanodeInfoWithStorage[127.0.0.1:40683,DS-c847301c-093d-447c-af90-f52ab64aad23,DISK], DatanodeInfoWithStorage[127.0.0.1:38354,DS-1a38e0ea-3444-4726-ad1a-14dc728a1911,DISK], DatanodeInfoWithStorage[127.0.0.1:44571,DS-5f9ffd82-cd34-4793-a898-0711cb97c07d,DISK], DatanodeInfoWithStorage[127.0.0.1:32960,DS-939bff1f-c5f8-43ff-b70e-7f315784bd19,DISK], DatanodeInfoWithStorage[127.0.0.1:35549,DS-abbed057-84c0-4851-a2d6-3d7e904836df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-327612869-172.17.0.9-1597505577348:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41623,DS-fdf437fc-cf32-467c-b68b-39698392adac,DISK], DatanodeInfoWithStorage[127.0.0.1:35866,DS-0ae96000-fdb3-44e5-9f24-d7105ca0fa0b,DISK], DatanodeInfoWithStorage[127.0.0.1:42683,DS-7d84d971-8c10-4dd1-8241-70722b496396,DISK], DatanodeInfoWithStorage[127.0.0.1:40683,DS-c847301c-093d-447c-af90-f52ab64aad23,DISK], DatanodeInfoWithStorage[127.0.0.1:38354,DS-1a38e0ea-3444-4726-ad1a-14dc728a1911,DISK], DatanodeInfoWithStorage[127.0.0.1:44571,DS-5f9ffd82-cd34-4793-a898-0711cb97c07d,DISK], DatanodeInfoWithStorage[127.0.0.1:32960,DS-939bff1f-c5f8-43ff-b70e-7f315784bd19,DISK], DatanodeInfoWithStorage[127.0.0.1:35549,DS-abbed057-84c0-4851-a2d6-3d7e904836df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2129998420-172.17.0.9-1597505675012:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33763,DS-f863ae22-06e5-4927-a6f3-24d554d09875,DISK], DatanodeInfoWithStorage[127.0.0.1:46719,DS-0ba3c155-4477-4ab3-b730-4e91e98a8903,DISK], DatanodeInfoWithStorage[127.0.0.1:34926,DS-74a54e9b-61a4-4d32-80a8-9165e3ddf780,DISK], DatanodeInfoWithStorage[127.0.0.1:42967,DS-69f54692-51a9-4594-b6bb-0b3012bbe86f,DISK], DatanodeInfoWithStorage[127.0.0.1:42255,DS-b2bb59f5-c6c9-4230-975c-8f704fc694d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38579,DS-2cf54995-34e6-4931-a272-303ccecea18a,DISK], DatanodeInfoWithStorage[127.0.0.1:40697,DS-d3810372-44fd-4915-9a59-70ff787c24b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39454,DS-3bc188ee-295b-4ff1-a302-3a00fef60de2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2129998420-172.17.0.9-1597505675012:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33763,DS-f863ae22-06e5-4927-a6f3-24d554d09875,DISK], DatanodeInfoWithStorage[127.0.0.1:46719,DS-0ba3c155-4477-4ab3-b730-4e91e98a8903,DISK], DatanodeInfoWithStorage[127.0.0.1:34926,DS-74a54e9b-61a4-4d32-80a8-9165e3ddf780,DISK], DatanodeInfoWithStorage[127.0.0.1:42967,DS-69f54692-51a9-4594-b6bb-0b3012bbe86f,DISK], DatanodeInfoWithStorage[127.0.0.1:42255,DS-b2bb59f5-c6c9-4230-975c-8f704fc694d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38579,DS-2cf54995-34e6-4931-a272-303ccecea18a,DISK], DatanodeInfoWithStorage[127.0.0.1:40697,DS-d3810372-44fd-4915-9a59-70ff787c24b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39454,DS-3bc188ee-295b-4ff1-a302-3a00fef60de2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1613630330-172.17.0.9-1597505827673:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41101,DS-c90fcc8b-c305-4ec0-99cc-2ba3d2a1832c,DISK], DatanodeInfoWithStorage[127.0.0.1:34141,DS-e5b83481-d349-4e30-ab88-c48b5f7c1f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:34686,DS-8a40ef20-54ff-47d4-a376-f3fab5320834,DISK], DatanodeInfoWithStorage[127.0.0.1:36824,DS-77c053b0-9487-4f2c-bca7-9079d267f311,DISK], DatanodeInfoWithStorage[127.0.0.1:34234,DS-eb3b282b-4be5-43cd-92e6-b02d46b6f895,DISK], DatanodeInfoWithStorage[127.0.0.1:36831,DS-8622735d-c9ef-40ab-b812-6896fb72a032,DISK], DatanodeInfoWithStorage[127.0.0.1:42051,DS-5249e59f-5c49-4bca-9380-4a950ebbecb2,DISK], DatanodeInfoWithStorage[127.0.0.1:37284,DS-28d1128e-4f80-4f23-8171-76c7ea0a966e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1613630330-172.17.0.9-1597505827673:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41101,DS-c90fcc8b-c305-4ec0-99cc-2ba3d2a1832c,DISK], DatanodeInfoWithStorage[127.0.0.1:34141,DS-e5b83481-d349-4e30-ab88-c48b5f7c1f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:34686,DS-8a40ef20-54ff-47d4-a376-f3fab5320834,DISK], DatanodeInfoWithStorage[127.0.0.1:36824,DS-77c053b0-9487-4f2c-bca7-9079d267f311,DISK], DatanodeInfoWithStorage[127.0.0.1:34234,DS-eb3b282b-4be5-43cd-92e6-b02d46b6f895,DISK], DatanodeInfoWithStorage[127.0.0.1:36831,DS-8622735d-c9ef-40ab-b812-6896fb72a032,DISK], DatanodeInfoWithStorage[127.0.0.1:42051,DS-5249e59f-5c49-4bca-9380-4a950ebbecb2,DISK], DatanodeInfoWithStorage[127.0.0.1:37284,DS-28d1128e-4f80-4f23-8171-76c7ea0a966e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1432657760-172.17.0.9-1597505864419:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40229,DS-e7ba67b6-a496-46c0-8fc5-625b04e16270,DISK], DatanodeInfoWithStorage[127.0.0.1:44643,DS-277da785-dfc5-484a-b653-6ce75b6a755f,DISK], DatanodeInfoWithStorage[127.0.0.1:41975,DS-1f6fd206-d6f7-4734-84d3-72ef1a6286c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37899,DS-fb3c6616-7e4a-4b72-813f-90757cc8bf91,DISK], DatanodeInfoWithStorage[127.0.0.1:35079,DS-367be489-bc16-457c-9843-8217169560e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38387,DS-51062f33-75be-4f6b-9b1e-1dbeeaedf167,DISK], DatanodeInfoWithStorage[127.0.0.1:38792,DS-1a002e2a-af4d-4e45-83c4-301acd4973f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46078,DS-05f879e0-4d82-4796-b6f1-fed88fb11873,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1432657760-172.17.0.9-1597505864419:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40229,DS-e7ba67b6-a496-46c0-8fc5-625b04e16270,DISK], DatanodeInfoWithStorage[127.0.0.1:44643,DS-277da785-dfc5-484a-b653-6ce75b6a755f,DISK], DatanodeInfoWithStorage[127.0.0.1:41975,DS-1f6fd206-d6f7-4734-84d3-72ef1a6286c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37899,DS-fb3c6616-7e4a-4b72-813f-90757cc8bf91,DISK], DatanodeInfoWithStorage[127.0.0.1:35079,DS-367be489-bc16-457c-9843-8217169560e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38387,DS-51062f33-75be-4f6b-9b1e-1dbeeaedf167,DISK], DatanodeInfoWithStorage[127.0.0.1:38792,DS-1a002e2a-af4d-4e45-83c4-301acd4973f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46078,DS-05f879e0-4d82-4796-b6f1-fed88fb11873,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-650431295-172.17.0.9-1597506052907:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36895,DS-f1e05cab-236c-4287-9b3d-326aa09d2c03,DISK], DatanodeInfoWithStorage[127.0.0.1:33932,DS-34ad822a-ead2-4096-84fa-029886a06c05,DISK], DatanodeInfoWithStorage[127.0.0.1:36818,DS-026de479-0027-4005-b174-c6e08ac11373,DISK], DatanodeInfoWithStorage[127.0.0.1:42417,DS-c8460d32-1208-4ffe-9d70-dccbe20f38b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34645,DS-8ef2633e-058c-46b2-96ad-5ba5ce37fc89,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-5c76b43f-224e-4dab-92a4-32851dd91923,DISK], DatanodeInfoWithStorage[127.0.0.1:35000,DS-f80d59c4-56da-4970-b254-2509d985184a,DISK], DatanodeInfoWithStorage[127.0.0.1:44844,DS-200ba08a-b991-47d8-af09-de90b5032e9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-650431295-172.17.0.9-1597506052907:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36895,DS-f1e05cab-236c-4287-9b3d-326aa09d2c03,DISK], DatanodeInfoWithStorage[127.0.0.1:33932,DS-34ad822a-ead2-4096-84fa-029886a06c05,DISK], DatanodeInfoWithStorage[127.0.0.1:36818,DS-026de479-0027-4005-b174-c6e08ac11373,DISK], DatanodeInfoWithStorage[127.0.0.1:42417,DS-c8460d32-1208-4ffe-9d70-dccbe20f38b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34645,DS-8ef2633e-058c-46b2-96ad-5ba5ce37fc89,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-5c76b43f-224e-4dab-92a4-32851dd91923,DISK], DatanodeInfoWithStorage[127.0.0.1:35000,DS-f80d59c4-56da-4970-b254-2509d985184a,DISK], DatanodeInfoWithStorage[127.0.0.1:44844,DS-200ba08a-b991-47d8-af09-de90b5032e9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-838548066-172.17.0.9-1597506094301:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37848,DS-259f2613-add9-4f64-81b4-066ca171cf9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38774,DS-033145b6-d6bd-41f9-a3e3-7e37f86eded3,DISK], DatanodeInfoWithStorage[127.0.0.1:39313,DS-47e09b29-3e95-4c7e-8a9b-c3f684c9c392,DISK], DatanodeInfoWithStorage[127.0.0.1:41964,DS-bee4c844-3dec-4d09-afe6-fa703f9e7a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:38418,DS-ebf3b743-6597-43af-9e1a-b63c3b4766aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39965,DS-77aa89d4-7f5a-4d36-804e-1f92cece2b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:36899,DS-41b76aac-2846-40de-ba80-0a7231d47bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:37594,DS-b288d1be-d910-4a23-85d4-12a06721dc24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-838548066-172.17.0.9-1597506094301:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37848,DS-259f2613-add9-4f64-81b4-066ca171cf9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38774,DS-033145b6-d6bd-41f9-a3e3-7e37f86eded3,DISK], DatanodeInfoWithStorage[127.0.0.1:39313,DS-47e09b29-3e95-4c7e-8a9b-c3f684c9c392,DISK], DatanodeInfoWithStorage[127.0.0.1:41964,DS-bee4c844-3dec-4d09-afe6-fa703f9e7a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:38418,DS-ebf3b743-6597-43af-9e1a-b63c3b4766aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39965,DS-77aa89d4-7f5a-4d36-804e-1f92cece2b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:36899,DS-41b76aac-2846-40de-ba80-0a7231d47bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:37594,DS-b288d1be-d910-4a23-85d4-12a06721dc24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-401737958-172.17.0.9-1597506244336:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35407,DS-040fc6cf-9f45-4a83-855a-51ad70858c20,DISK], DatanodeInfoWithStorage[127.0.0.1:39906,DS-69f2ad87-894a-4bb8-a213-b1f60ca806e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35033,DS-4a126670-4cc6-4550-8830-5ec55fbaf793,DISK], DatanodeInfoWithStorage[127.0.0.1:37895,DS-14db247e-4d41-49a4-91f6-7d3fbe1ba707,DISK], DatanodeInfoWithStorage[127.0.0.1:45809,DS-c6b51eb1-ac48-42f2-8a0d-a7db90b4b9ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33387,DS-76ead146-6c96-4594-b333-a75da9ea8ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:38517,DS-4b98c52b-3b82-489a-991e-2a579ebc18d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36494,DS-19f79a03-1fa7-450c-baa3-532c5aaee432,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-401737958-172.17.0.9-1597506244336:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35407,DS-040fc6cf-9f45-4a83-855a-51ad70858c20,DISK], DatanodeInfoWithStorage[127.0.0.1:39906,DS-69f2ad87-894a-4bb8-a213-b1f60ca806e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35033,DS-4a126670-4cc6-4550-8830-5ec55fbaf793,DISK], DatanodeInfoWithStorage[127.0.0.1:37895,DS-14db247e-4d41-49a4-91f6-7d3fbe1ba707,DISK], DatanodeInfoWithStorage[127.0.0.1:45809,DS-c6b51eb1-ac48-42f2-8a0d-a7db90b4b9ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33387,DS-76ead146-6c96-4594-b333-a75da9ea8ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:38517,DS-4b98c52b-3b82-489a-991e-2a579ebc18d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36494,DS-19f79a03-1fa7-450c-baa3-532c5aaee432,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1311667510-172.17.0.9-1597506279820:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40727,DS-63e1db36-1cca-4065-b9d9-8ceea21a597d,DISK], DatanodeInfoWithStorage[127.0.0.1:34307,DS-7a3e870b-882c-439c-a824-a05bce0526b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35390,DS-bbd66423-167b-4344-bc2b-d21f363c1f83,DISK], DatanodeInfoWithStorage[127.0.0.1:42785,DS-96ed3a55-7b84-45fd-81a0-ed26d36211ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33102,DS-ed3c856d-be94-4630-a5aa-7f084611adfc,DISK], DatanodeInfoWithStorage[127.0.0.1:46481,DS-9602fe21-eb12-4c14-8ded-9cf661f827ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44841,DS-6bf9566f-1ab2-42db-9caf-d9c097febfd0,DISK], DatanodeInfoWithStorage[127.0.0.1:43583,DS-53bc179d-5ac0-47ef-8277-f2e22c81d3fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1311667510-172.17.0.9-1597506279820:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40727,DS-63e1db36-1cca-4065-b9d9-8ceea21a597d,DISK], DatanodeInfoWithStorage[127.0.0.1:34307,DS-7a3e870b-882c-439c-a824-a05bce0526b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35390,DS-bbd66423-167b-4344-bc2b-d21f363c1f83,DISK], DatanodeInfoWithStorage[127.0.0.1:42785,DS-96ed3a55-7b84-45fd-81a0-ed26d36211ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33102,DS-ed3c856d-be94-4630-a5aa-7f084611adfc,DISK], DatanodeInfoWithStorage[127.0.0.1:46481,DS-9602fe21-eb12-4c14-8ded-9cf661f827ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44841,DS-6bf9566f-1ab2-42db-9caf-d9c097febfd0,DISK], DatanodeInfoWithStorage[127.0.0.1:43583,DS-53bc179d-5ac0-47ef-8277-f2e22c81d3fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1087219808-172.17.0.9-1597506686237:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46145,DS-bafbe1f0-9006-4aaf-9df5-a978f2f93b97,DISK], DatanodeInfoWithStorage[127.0.0.1:33321,DS-9edfa393-7473-44a0-b4b1-228d87b93947,DISK], DatanodeInfoWithStorage[127.0.0.1:45550,DS-a5b0555b-123d-402e-8bac-1ddbe77c859f,DISK], DatanodeInfoWithStorage[127.0.0.1:46590,DS-a91b5da1-2046-4ae3-abd6-f140f3a7f2e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44367,DS-0550679c-b270-4a91-b4d8-b7568897c248,DISK], DatanodeInfoWithStorage[127.0.0.1:46165,DS-3feede5b-2a4a-4bab-9ffe-a605cf2c621c,DISK], DatanodeInfoWithStorage[127.0.0.1:45721,DS-4f1d36be-77d8-409c-96b7-ea48277365a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41415,DS-0d7af93f-e6ca-4469-8484-ff6dc12a28b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1087219808-172.17.0.9-1597506686237:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46145,DS-bafbe1f0-9006-4aaf-9df5-a978f2f93b97,DISK], DatanodeInfoWithStorage[127.0.0.1:33321,DS-9edfa393-7473-44a0-b4b1-228d87b93947,DISK], DatanodeInfoWithStorage[127.0.0.1:45550,DS-a5b0555b-123d-402e-8bac-1ddbe77c859f,DISK], DatanodeInfoWithStorage[127.0.0.1:46590,DS-a91b5da1-2046-4ae3-abd6-f140f3a7f2e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44367,DS-0550679c-b270-4a91-b4d8-b7568897c248,DISK], DatanodeInfoWithStorage[127.0.0.1:46165,DS-3feede5b-2a4a-4bab-9ffe-a605cf2c621c,DISK], DatanodeInfoWithStorage[127.0.0.1:45721,DS-4f1d36be-77d8-409c-96b7-ea48277365a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41415,DS-0d7af93f-e6ca-4469-8484-ff6dc12a28b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 18 out of 50
result: false positive !!!
Total execution time in seconds : 5547
