reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1434953019-172.17.0.16-1597314725787:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34826,DS-21eb6368-209c-4b33-a964-ae5c89d7d578,DISK], DatanodeInfoWithStorage[127.0.0.1:42613,DS-44559b8d-e510-45c8-b07e-82de6eceb4b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39912,DS-46f9c5cc-4ebf-4197-b6a1-8e4de1c7b16b,DISK], DatanodeInfoWithStorage[127.0.0.1:38619,DS-e457eaf2-5a09-4e2a-a723-8f712916eb1b,DISK], DatanodeInfoWithStorage[127.0.0.1:37901,DS-b059ca68-deb4-41d5-bb30-5cfb00af83cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39917,DS-058990fb-dba4-45e8-9dbe-97281a6bb7ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45577,DS-c9b7ed76-d94c-4e6b-b150-9ba67396c290,DISK], DatanodeInfoWithStorage[127.0.0.1:43001,DS-b66715a9-dc2a-4905-8f9a-3a3ea9f3418a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1434953019-172.17.0.16-1597314725787:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34826,DS-21eb6368-209c-4b33-a964-ae5c89d7d578,DISK], DatanodeInfoWithStorage[127.0.0.1:42613,DS-44559b8d-e510-45c8-b07e-82de6eceb4b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39912,DS-46f9c5cc-4ebf-4197-b6a1-8e4de1c7b16b,DISK], DatanodeInfoWithStorage[127.0.0.1:38619,DS-e457eaf2-5a09-4e2a-a723-8f712916eb1b,DISK], DatanodeInfoWithStorage[127.0.0.1:37901,DS-b059ca68-deb4-41d5-bb30-5cfb00af83cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39917,DS-058990fb-dba4-45e8-9dbe-97281a6bb7ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45577,DS-c9b7ed76-d94c-4e6b-b150-9ba67396c290,DISK], DatanodeInfoWithStorage[127.0.0.1:43001,DS-b66715a9-dc2a-4905-8f9a-3a3ea9f3418a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1732208436-172.17.0.16-1597315467871:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44408,DS-8586973e-0c32-473f-b58c-3349aa2d027e,DISK], DatanodeInfoWithStorage[127.0.0.1:38671,DS-387e501e-f93f-4256-85d4-b41d88ea265b,DISK], DatanodeInfoWithStorage[127.0.0.1:46832,DS-fa5e1fbd-10ed-4cbb-9e93-d35b9acf0758,DISK], DatanodeInfoWithStorage[127.0.0.1:44643,DS-4520fabd-cc7b-4a3e-8de3-947ff17bc143,DISK], DatanodeInfoWithStorage[127.0.0.1:45112,DS-7e5a378b-58e3-42d3-aee5-ff7c22c627c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38632,DS-7dc6e815-5135-486a-8f31-361b356ae4ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35657,DS-7934b76d-af93-4a94-a4fe-b8643c43baf8,DISK], DatanodeInfoWithStorage[127.0.0.1:34268,DS-ada799ae-fb76-4625-aa4d-21c4e1602ddc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1732208436-172.17.0.16-1597315467871:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44408,DS-8586973e-0c32-473f-b58c-3349aa2d027e,DISK], DatanodeInfoWithStorage[127.0.0.1:38671,DS-387e501e-f93f-4256-85d4-b41d88ea265b,DISK], DatanodeInfoWithStorage[127.0.0.1:46832,DS-fa5e1fbd-10ed-4cbb-9e93-d35b9acf0758,DISK], DatanodeInfoWithStorage[127.0.0.1:44643,DS-4520fabd-cc7b-4a3e-8de3-947ff17bc143,DISK], DatanodeInfoWithStorage[127.0.0.1:45112,DS-7e5a378b-58e3-42d3-aee5-ff7c22c627c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38632,DS-7dc6e815-5135-486a-8f31-361b356ae4ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35657,DS-7934b76d-af93-4a94-a4fe-b8643c43baf8,DISK], DatanodeInfoWithStorage[127.0.0.1:34268,DS-ada799ae-fb76-4625-aa4d-21c4e1602ddc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1665282596-172.17.0.16-1597316082761:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39123,DS-0d8020ed-43ad-4410-9a24-7d7b9fdbe66f,DISK], DatanodeInfoWithStorage[127.0.0.1:42036,DS-b5401aa8-bb95-4789-a940-139f5fb4408f,DISK], DatanodeInfoWithStorage[127.0.0.1:40902,DS-deb15c44-2797-4faf-b2d3-47a6b9b143d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40115,DS-1c5946af-8bb0-4f4c-95a5-19c1cfd0a9c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35935,DS-f1ef9600-8a56-4234-afd8-32423f114674,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-e0f0ff1b-1b74-43e7-b124-4a700d4a52b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41137,DS-c244d6bf-c204-403a-935a-fcc5258f3e41,DISK], DatanodeInfoWithStorage[127.0.0.1:40806,DS-04920f76-05db-41fc-8dc0-d64b350b74c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1665282596-172.17.0.16-1597316082761:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39123,DS-0d8020ed-43ad-4410-9a24-7d7b9fdbe66f,DISK], DatanodeInfoWithStorage[127.0.0.1:42036,DS-b5401aa8-bb95-4789-a940-139f5fb4408f,DISK], DatanodeInfoWithStorage[127.0.0.1:40902,DS-deb15c44-2797-4faf-b2d3-47a6b9b143d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40115,DS-1c5946af-8bb0-4f4c-95a5-19c1cfd0a9c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35935,DS-f1ef9600-8a56-4234-afd8-32423f114674,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-e0f0ff1b-1b74-43e7-b124-4a700d4a52b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41137,DS-c244d6bf-c204-403a-935a-fcc5258f3e41,DISK], DatanodeInfoWithStorage[127.0.0.1:40806,DS-04920f76-05db-41fc-8dc0-d64b350b74c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1571343370-172.17.0.16-1597316571052:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39958,DS-032c334a-5049-4a1f-b1bc-a9534cbc3cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:36483,DS-e2fb768b-6485-402f-b680-67df0bf3b827,DISK], DatanodeInfoWithStorage[127.0.0.1:43800,DS-5145d4ad-237a-4581-8c10-17cd72bae83b,DISK], DatanodeInfoWithStorage[127.0.0.1:37253,DS-9cf2b08c-426a-4953-9cb7-1957a5860cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:38525,DS-d50e40b8-25aa-4e27-9805-029819e8a238,DISK], DatanodeInfoWithStorage[127.0.0.1:37583,DS-b7b895c5-e65c-46e8-91fe-9682597c9a43,DISK], DatanodeInfoWithStorage[127.0.0.1:34579,DS-4b3e230f-f9e8-4896-9333-c359b8e0ea13,DISK], DatanodeInfoWithStorage[127.0.0.1:42765,DS-e929f747-39ab-4fa2-bae4-d95fa4f39440,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1571343370-172.17.0.16-1597316571052:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39958,DS-032c334a-5049-4a1f-b1bc-a9534cbc3cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:36483,DS-e2fb768b-6485-402f-b680-67df0bf3b827,DISK], DatanodeInfoWithStorage[127.0.0.1:43800,DS-5145d4ad-237a-4581-8c10-17cd72bae83b,DISK], DatanodeInfoWithStorage[127.0.0.1:37253,DS-9cf2b08c-426a-4953-9cb7-1957a5860cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:38525,DS-d50e40b8-25aa-4e27-9805-029819e8a238,DISK], DatanodeInfoWithStorage[127.0.0.1:37583,DS-b7b895c5-e65c-46e8-91fe-9682597c9a43,DISK], DatanodeInfoWithStorage[127.0.0.1:34579,DS-4b3e230f-f9e8-4896-9333-c359b8e0ea13,DISK], DatanodeInfoWithStorage[127.0.0.1:42765,DS-e929f747-39ab-4fa2-bae4-d95fa4f39440,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-541249828-172.17.0.16-1597317034532:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35463,DS-cbfe0083-4504-41f5-9790-37b60fc30577,DISK], DatanodeInfoWithStorage[127.0.0.1:36292,DS-05406a36-769e-4067-b835-18ee8e0af800,DISK], DatanodeInfoWithStorage[127.0.0.1:33705,DS-0321bb45-5d4f-443c-8ea0-4d87e0c65745,DISK], DatanodeInfoWithStorage[127.0.0.1:35011,DS-09a020b1-8853-410f-aeda-c4c41fe22a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:35834,DS-32aaf2a7-058e-4b47-a8e1-05e815ae05aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41510,DS-1e91eb31-2879-4df1-8467-1417835471cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40106,DS-c7ebd178-7d3c-49e7-a710-b55f32110c07,DISK], DatanodeInfoWithStorage[127.0.0.1:45361,DS-8f828638-4674-47cc-bf85-64721aa06d56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-541249828-172.17.0.16-1597317034532:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35463,DS-cbfe0083-4504-41f5-9790-37b60fc30577,DISK], DatanodeInfoWithStorage[127.0.0.1:36292,DS-05406a36-769e-4067-b835-18ee8e0af800,DISK], DatanodeInfoWithStorage[127.0.0.1:33705,DS-0321bb45-5d4f-443c-8ea0-4d87e0c65745,DISK], DatanodeInfoWithStorage[127.0.0.1:35011,DS-09a020b1-8853-410f-aeda-c4c41fe22a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:35834,DS-32aaf2a7-058e-4b47-a8e1-05e815ae05aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41510,DS-1e91eb31-2879-4df1-8467-1417835471cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40106,DS-c7ebd178-7d3c-49e7-a710-b55f32110c07,DISK], DatanodeInfoWithStorage[127.0.0.1:45361,DS-8f828638-4674-47cc-bf85-64721aa06d56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1746009431-172.17.0.16-1597318012013:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42641,DS-a0b02b3f-1971-41a3-bd95-a1a36972ca82,DISK], DatanodeInfoWithStorage[127.0.0.1:42745,DS-fcb70624-285c-426b-85d9-20e71d0df2b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35066,DS-841c44e3-80f9-4d81-8d54-67b916008224,DISK], DatanodeInfoWithStorage[127.0.0.1:40701,DS-8cf3db53-fcaa-428b-9544-e992a51c8346,DISK], DatanodeInfoWithStorage[127.0.0.1:43507,DS-1247a1ed-12d5-43e8-af9b-9e4a0c6ed47b,DISK], DatanodeInfoWithStorage[127.0.0.1:39008,DS-6dfaa8bf-6542-4d96-852e-041aa296e658,DISK], DatanodeInfoWithStorage[127.0.0.1:41628,DS-d38dcc09-26f9-4818-ac00-b5668413450b,DISK], DatanodeInfoWithStorage[127.0.0.1:39841,DS-ed2e2495-38d6-40f5-901b-d211cd60b63f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1746009431-172.17.0.16-1597318012013:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42641,DS-a0b02b3f-1971-41a3-bd95-a1a36972ca82,DISK], DatanodeInfoWithStorage[127.0.0.1:42745,DS-fcb70624-285c-426b-85d9-20e71d0df2b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35066,DS-841c44e3-80f9-4d81-8d54-67b916008224,DISK], DatanodeInfoWithStorage[127.0.0.1:40701,DS-8cf3db53-fcaa-428b-9544-e992a51c8346,DISK], DatanodeInfoWithStorage[127.0.0.1:43507,DS-1247a1ed-12d5-43e8-af9b-9e4a0c6ed47b,DISK], DatanodeInfoWithStorage[127.0.0.1:39008,DS-6dfaa8bf-6542-4d96-852e-041aa296e658,DISK], DatanodeInfoWithStorage[127.0.0.1:41628,DS-d38dcc09-26f9-4818-ac00-b5668413450b,DISK], DatanodeInfoWithStorage[127.0.0.1:39841,DS-ed2e2495-38d6-40f5-901b-d211cd60b63f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-402607644-172.17.0.16-1597318289615:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44791,DS-450983ba-6b09-4847-8d99-1cb193d8671e,DISK], DatanodeInfoWithStorage[127.0.0.1:45204,DS-83f19102-f0e4-45d6-8e09-314846e74b37,DISK], DatanodeInfoWithStorage[127.0.0.1:36992,DS-f7aa34c9-5fe5-4047-9baa-5881b3b5f22f,DISK], DatanodeInfoWithStorage[127.0.0.1:46030,DS-c8f19e8c-a06b-4b5a-a358-50921daaf67f,DISK], DatanodeInfoWithStorage[127.0.0.1:35230,DS-860210f2-2bd9-4d5b-9240-b83b9bf2874f,DISK], DatanodeInfoWithStorage[127.0.0.1:42769,DS-d9f4e43c-ff2b-47a9-b298-fea9fba8c2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35049,DS-e91b4d96-14dc-4017-b34a-d681b81f639c,DISK], DatanodeInfoWithStorage[127.0.0.1:36172,DS-6d8df397-f01e-4d43-a9c5-9c4855a4bba7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-402607644-172.17.0.16-1597318289615:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44791,DS-450983ba-6b09-4847-8d99-1cb193d8671e,DISK], DatanodeInfoWithStorage[127.0.0.1:45204,DS-83f19102-f0e4-45d6-8e09-314846e74b37,DISK], DatanodeInfoWithStorage[127.0.0.1:36992,DS-f7aa34c9-5fe5-4047-9baa-5881b3b5f22f,DISK], DatanodeInfoWithStorage[127.0.0.1:46030,DS-c8f19e8c-a06b-4b5a-a358-50921daaf67f,DISK], DatanodeInfoWithStorage[127.0.0.1:35230,DS-860210f2-2bd9-4d5b-9240-b83b9bf2874f,DISK], DatanodeInfoWithStorage[127.0.0.1:42769,DS-d9f4e43c-ff2b-47a9-b298-fea9fba8c2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35049,DS-e91b4d96-14dc-4017-b34a-d681b81f639c,DISK], DatanodeInfoWithStorage[127.0.0.1:36172,DS-6d8df397-f01e-4d43-a9c5-9c4855a4bba7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-197238728-172.17.0.16-1597318430969:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46029,DS-e53c6a05-ed99-476c-9d56-9cf1a77d2405,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-01492681-7b09-4bee-acfe-a0cc27896f42,DISK], DatanodeInfoWithStorage[127.0.0.1:35029,DS-23e10a03-1ccd-4d73-a50f-0101654c4bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:34932,DS-e0a07672-53ec-4870-9187-060bb415ea90,DISK], DatanodeInfoWithStorage[127.0.0.1:38004,DS-f6099d23-77d4-4d97-84bd-a9f702c9ced9,DISK], DatanodeInfoWithStorage[127.0.0.1:34833,DS-bb7eaad4-2a7d-4f61-be5d-453072dcea90,DISK], DatanodeInfoWithStorage[127.0.0.1:45452,DS-778ddcd8-968e-4896-a952-00c70b715b33,DISK], DatanodeInfoWithStorage[127.0.0.1:37532,DS-44f0c3df-0fba-4739-b2eb-a3b349e53f3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-197238728-172.17.0.16-1597318430969:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46029,DS-e53c6a05-ed99-476c-9d56-9cf1a77d2405,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-01492681-7b09-4bee-acfe-a0cc27896f42,DISK], DatanodeInfoWithStorage[127.0.0.1:35029,DS-23e10a03-1ccd-4d73-a50f-0101654c4bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:34932,DS-e0a07672-53ec-4870-9187-060bb415ea90,DISK], DatanodeInfoWithStorage[127.0.0.1:38004,DS-f6099d23-77d4-4d97-84bd-a9f702c9ced9,DISK], DatanodeInfoWithStorage[127.0.0.1:34833,DS-bb7eaad4-2a7d-4f61-be5d-453072dcea90,DISK], DatanodeInfoWithStorage[127.0.0.1:45452,DS-778ddcd8-968e-4896-a952-00c70b715b33,DISK], DatanodeInfoWithStorage[127.0.0.1:37532,DS-44f0c3df-0fba-4739-b2eb-a3b349e53f3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1646486673-172.17.0.16-1597318703650:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35944,DS-2136be9b-b232-4451-af2d-3f27f80df97b,DISK], DatanodeInfoWithStorage[127.0.0.1:42995,DS-12790b48-c79e-413e-aee4-f520106773a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41180,DS-240c2964-5b38-47bc-826e-92c3de901af7,DISK], DatanodeInfoWithStorage[127.0.0.1:36144,DS-ca7951a0-f5ad-40ca-911c-241a59631eae,DISK], DatanodeInfoWithStorage[127.0.0.1:39876,DS-ec7d0c54-6f62-4b3f-a045-e6fa88bb20c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33890,DS-f97d3b02-c369-481b-8863-47a545782ada,DISK], DatanodeInfoWithStorage[127.0.0.1:35800,DS-240e6a8d-a2a2-42c1-8750-9e18ac0da67c,DISK], DatanodeInfoWithStorage[127.0.0.1:38740,DS-36869571-3428-4344-8e76-043bda55be55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1646486673-172.17.0.16-1597318703650:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35944,DS-2136be9b-b232-4451-af2d-3f27f80df97b,DISK], DatanodeInfoWithStorage[127.0.0.1:42995,DS-12790b48-c79e-413e-aee4-f520106773a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41180,DS-240c2964-5b38-47bc-826e-92c3de901af7,DISK], DatanodeInfoWithStorage[127.0.0.1:36144,DS-ca7951a0-f5ad-40ca-911c-241a59631eae,DISK], DatanodeInfoWithStorage[127.0.0.1:39876,DS-ec7d0c54-6f62-4b3f-a045-e6fa88bb20c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33890,DS-f97d3b02-c369-481b-8863-47a545782ada,DISK], DatanodeInfoWithStorage[127.0.0.1:35800,DS-240e6a8d-a2a2-42c1-8750-9e18ac0da67c,DISK], DatanodeInfoWithStorage[127.0.0.1:38740,DS-36869571-3428-4344-8e76-043bda55be55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2144728629-172.17.0.16-1597318805783:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33630,DS-2edb3fde-06ae-442f-bc45-972568eef5b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35415,DS-16bf2579-4de8-4946-97ab-4f5fcb2e7a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:33072,DS-18adbe67-08d2-4c55-a97a-09b1ae942d07,DISK], DatanodeInfoWithStorage[127.0.0.1:46371,DS-93f7e28b-b691-48ef-bb64-f6a9dc537d76,DISK], DatanodeInfoWithStorage[127.0.0.1:37599,DS-af365318-32b8-433f-807d-03d5844dba6a,DISK], DatanodeInfoWithStorage[127.0.0.1:38495,DS-a8819f63-e02e-4dbc-a33e-a02ff914b893,DISK], DatanodeInfoWithStorage[127.0.0.1:38564,DS-6c47edb2-e313-4e7b-96c5-2b16125bfd33,DISK], DatanodeInfoWithStorage[127.0.0.1:41665,DS-e7c44f85-1c0a-477b-9136-cb8b7426468c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2144728629-172.17.0.16-1597318805783:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33630,DS-2edb3fde-06ae-442f-bc45-972568eef5b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35415,DS-16bf2579-4de8-4946-97ab-4f5fcb2e7a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:33072,DS-18adbe67-08d2-4c55-a97a-09b1ae942d07,DISK], DatanodeInfoWithStorage[127.0.0.1:46371,DS-93f7e28b-b691-48ef-bb64-f6a9dc537d76,DISK], DatanodeInfoWithStorage[127.0.0.1:37599,DS-af365318-32b8-433f-807d-03d5844dba6a,DISK], DatanodeInfoWithStorage[127.0.0.1:38495,DS-a8819f63-e02e-4dbc-a33e-a02ff914b893,DISK], DatanodeInfoWithStorage[127.0.0.1:38564,DS-6c47edb2-e313-4e7b-96c5-2b16125bfd33,DISK], DatanodeInfoWithStorage[127.0.0.1:41665,DS-e7c44f85-1c0a-477b-9136-cb8b7426468c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-604686556-172.17.0.16-1597318873135:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46084,DS-0f92d881-9422-4b6b-9837-0a2eda7347df,DISK], DatanodeInfoWithStorage[127.0.0.1:45046,DS-299f6e63-3edf-46bf-affa-43a84d49e8bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41570,DS-1941629e-bfb3-4483-b226-f1230e1fe7a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39250,DS-7ee65392-ab5c-447c-96c7-7d7c4a966ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:37545,DS-8274866f-9a88-464e-af21-8c1acfff9e90,DISK], DatanodeInfoWithStorage[127.0.0.1:45418,DS-215d647d-cc91-4cb4-baf1-4f831ba97728,DISK], DatanodeInfoWithStorage[127.0.0.1:37558,DS-7d8d65ef-6e2f-4f14-be73-d74ac6e990c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35586,DS-7be8eeaf-2d4d-467f-a97f-50f3f587d3a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-604686556-172.17.0.16-1597318873135:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46084,DS-0f92d881-9422-4b6b-9837-0a2eda7347df,DISK], DatanodeInfoWithStorage[127.0.0.1:45046,DS-299f6e63-3edf-46bf-affa-43a84d49e8bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41570,DS-1941629e-bfb3-4483-b226-f1230e1fe7a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39250,DS-7ee65392-ab5c-447c-96c7-7d7c4a966ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:37545,DS-8274866f-9a88-464e-af21-8c1acfff9e90,DISK], DatanodeInfoWithStorage[127.0.0.1:45418,DS-215d647d-cc91-4cb4-baf1-4f831ba97728,DISK], DatanodeInfoWithStorage[127.0.0.1:37558,DS-7d8d65ef-6e2f-4f14-be73-d74ac6e990c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35586,DS-7be8eeaf-2d4d-467f-a97f-50f3f587d3a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1212017544-172.17.0.16-1597319277128:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35635,DS-56d3aed7-0477-4be1-8124-dbe4d30778b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35594,DS-3879506b-5245-491a-a8f9-b3a41ff7e30a,DISK], DatanodeInfoWithStorage[127.0.0.1:42050,DS-cab64799-f7b5-4cb9-987b-9d42e16aaca3,DISK], DatanodeInfoWithStorage[127.0.0.1:39180,DS-3b96d715-60f1-4db0-b8e2-20fda526f310,DISK], DatanodeInfoWithStorage[127.0.0.1:36507,DS-6eb90f63-f3f2-498e-9791-01e31d7fc9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45441,DS-0bb981da-580a-4cfd-af5d-8c414cded43f,DISK], DatanodeInfoWithStorage[127.0.0.1:45610,DS-dd93914c-443a-46aa-b8fe-ab354266db42,DISK], DatanodeInfoWithStorage[127.0.0.1:37653,DS-f9cd1473-063f-4301-8236-7889b50f91fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1212017544-172.17.0.16-1597319277128:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35635,DS-56d3aed7-0477-4be1-8124-dbe4d30778b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35594,DS-3879506b-5245-491a-a8f9-b3a41ff7e30a,DISK], DatanodeInfoWithStorage[127.0.0.1:42050,DS-cab64799-f7b5-4cb9-987b-9d42e16aaca3,DISK], DatanodeInfoWithStorage[127.0.0.1:39180,DS-3b96d715-60f1-4db0-b8e2-20fda526f310,DISK], DatanodeInfoWithStorage[127.0.0.1:36507,DS-6eb90f63-f3f2-498e-9791-01e31d7fc9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45441,DS-0bb981da-580a-4cfd-af5d-8c414cded43f,DISK], DatanodeInfoWithStorage[127.0.0.1:45610,DS-dd93914c-443a-46aa-b8fe-ab354266db42,DISK], DatanodeInfoWithStorage[127.0.0.1:37653,DS-f9cd1473-063f-4301-8236-7889b50f91fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-945989258-172.17.0.16-1597319409089:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41070,DS-f0f22cf5-dafb-4d61-90c7-b93ed0b49972,DISK], DatanodeInfoWithStorage[127.0.0.1:35637,DS-8416096e-9932-4ff3-a4f1-e878095939d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43447,DS-d86f8fc9-016a-4cc1-9d43-f5f19294adc2,DISK], DatanodeInfoWithStorage[127.0.0.1:42192,DS-0fee4013-43be-4bb6-b439-a1d8e0313d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40743,DS-62923786-9c0c-454c-a142-42e14eae94f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44819,DS-82debfe9-e2b8-4ed1-920e-f032e877be2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40820,DS-cac77994-f36a-4219-a8a8-ba054c832e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:42383,DS-84083893-99f4-4c4b-bb20-2bc4e5b0f9bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-945989258-172.17.0.16-1597319409089:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41070,DS-f0f22cf5-dafb-4d61-90c7-b93ed0b49972,DISK], DatanodeInfoWithStorage[127.0.0.1:35637,DS-8416096e-9932-4ff3-a4f1-e878095939d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43447,DS-d86f8fc9-016a-4cc1-9d43-f5f19294adc2,DISK], DatanodeInfoWithStorage[127.0.0.1:42192,DS-0fee4013-43be-4bb6-b439-a1d8e0313d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40743,DS-62923786-9c0c-454c-a142-42e14eae94f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44819,DS-82debfe9-e2b8-4ed1-920e-f032e877be2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40820,DS-cac77994-f36a-4219-a8a8-ba054c832e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:42383,DS-84083893-99f4-4c4b-bb20-2bc4e5b0f9bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-411834679-172.17.0.16-1597319468374:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36406,DS-22e1b46f-d1d1-47ef-acaf-95a3078f1323,DISK], DatanodeInfoWithStorage[127.0.0.1:43391,DS-ee1c4baa-cab0-4ec5-acab-972ab9038718,DISK], DatanodeInfoWithStorage[127.0.0.1:45447,DS-edd6ae17-3a41-44bb-a3ed-0eebbe7bdc64,DISK], DatanodeInfoWithStorage[127.0.0.1:35742,DS-c6166fac-1bc3-4665-9707-641b507813d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44116,DS-e394abf5-8071-41e5-96ef-92adac0502fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36597,DS-67031925-2dba-4611-ac30-a211ccd23db0,DISK], DatanodeInfoWithStorage[127.0.0.1:38678,DS-2a5adc78-3e0d-4d6a-9afc-cab6563ac602,DISK], DatanodeInfoWithStorage[127.0.0.1:33516,DS-8d0db924-6ab9-4d1d-b260-e82a51db097d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-411834679-172.17.0.16-1597319468374:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36406,DS-22e1b46f-d1d1-47ef-acaf-95a3078f1323,DISK], DatanodeInfoWithStorage[127.0.0.1:43391,DS-ee1c4baa-cab0-4ec5-acab-972ab9038718,DISK], DatanodeInfoWithStorage[127.0.0.1:45447,DS-edd6ae17-3a41-44bb-a3ed-0eebbe7bdc64,DISK], DatanodeInfoWithStorage[127.0.0.1:35742,DS-c6166fac-1bc3-4665-9707-641b507813d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44116,DS-e394abf5-8071-41e5-96ef-92adac0502fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36597,DS-67031925-2dba-4611-ac30-a211ccd23db0,DISK], DatanodeInfoWithStorage[127.0.0.1:38678,DS-2a5adc78-3e0d-4d6a-9afc-cab6563ac602,DISK], DatanodeInfoWithStorage[127.0.0.1:33516,DS-8d0db924-6ab9-4d1d-b260-e82a51db097d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-125924140-172.17.0.16-1597319763593:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45130,DS-2fbdd290-21ec-4afa-8856-42aea07c3205,DISK], DatanodeInfoWithStorage[127.0.0.1:40699,DS-2c83c0d1-8c73-470b-b4a0-99e6a538314e,DISK], DatanodeInfoWithStorage[127.0.0.1:39736,DS-f472cfc3-a0bf-439f-a308-1ed849853fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:39633,DS-1bf18d1b-42fb-40c4-a55b-8db0c7a3071a,DISK], DatanodeInfoWithStorage[127.0.0.1:38045,DS-cb3ff1cc-d13a-4684-a8e1-ce12a7ceedee,DISK], DatanodeInfoWithStorage[127.0.0.1:36141,DS-1b774dd5-a7fe-47e2-aa42-af72652163f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44517,DS-173e7f97-d777-4b13-b1b3-4ab6ecc0b759,DISK], DatanodeInfoWithStorage[127.0.0.1:39364,DS-75520b81-5be1-4403-9ea9-e0769f7f5225,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-125924140-172.17.0.16-1597319763593:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45130,DS-2fbdd290-21ec-4afa-8856-42aea07c3205,DISK], DatanodeInfoWithStorage[127.0.0.1:40699,DS-2c83c0d1-8c73-470b-b4a0-99e6a538314e,DISK], DatanodeInfoWithStorage[127.0.0.1:39736,DS-f472cfc3-a0bf-439f-a308-1ed849853fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:39633,DS-1bf18d1b-42fb-40c4-a55b-8db0c7a3071a,DISK], DatanodeInfoWithStorage[127.0.0.1:38045,DS-cb3ff1cc-d13a-4684-a8e1-ce12a7ceedee,DISK], DatanodeInfoWithStorage[127.0.0.1:36141,DS-1b774dd5-a7fe-47e2-aa42-af72652163f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44517,DS-173e7f97-d777-4b13-b1b3-4ab6ecc0b759,DISK], DatanodeInfoWithStorage[127.0.0.1:39364,DS-75520b81-5be1-4403-9ea9-e0769f7f5225,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1882515161-172.17.0.16-1597319867744:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36319,DS-86f1b166-1f3c-40e7-a3df-0a8529d98997,DISK], DatanodeInfoWithStorage[127.0.0.1:34533,DS-7a5cade9-6b52-4b89-b144-e0089360e60d,DISK], DatanodeInfoWithStorage[127.0.0.1:40122,DS-9991fd93-b9bc-41c6-8ca1-0c04feb04b27,DISK], DatanodeInfoWithStorage[127.0.0.1:45291,DS-5a71e861-9055-40a1-8490-8b8d214f00ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45734,DS-afef8f74-df5f-4378-b29a-258f64a62549,DISK], DatanodeInfoWithStorage[127.0.0.1:34721,DS-b17eb9dc-7f0d-4a2a-96d1-044ae4e2ab37,DISK], DatanodeInfoWithStorage[127.0.0.1:37968,DS-7998d266-a3fa-422e-88da-ca8130ca34f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42993,DS-5b9d0c7e-1475-417e-8f3b-9384014ad03c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1882515161-172.17.0.16-1597319867744:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36319,DS-86f1b166-1f3c-40e7-a3df-0a8529d98997,DISK], DatanodeInfoWithStorage[127.0.0.1:34533,DS-7a5cade9-6b52-4b89-b144-e0089360e60d,DISK], DatanodeInfoWithStorage[127.0.0.1:40122,DS-9991fd93-b9bc-41c6-8ca1-0c04feb04b27,DISK], DatanodeInfoWithStorage[127.0.0.1:45291,DS-5a71e861-9055-40a1-8490-8b8d214f00ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45734,DS-afef8f74-df5f-4378-b29a-258f64a62549,DISK], DatanodeInfoWithStorage[127.0.0.1:34721,DS-b17eb9dc-7f0d-4a2a-96d1-044ae4e2ab37,DISK], DatanodeInfoWithStorage[127.0.0.1:37968,DS-7998d266-a3fa-422e-88da-ca8130ca34f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42993,DS-5b9d0c7e-1475-417e-8f3b-9384014ad03c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5206
