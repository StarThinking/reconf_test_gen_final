reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1716693621-172.17.0.10-1597671831376:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39445,DS-36ca00b9-5033-4b89-a305-7687c6470318,DISK], DatanodeInfoWithStorage[127.0.0.1:40962,DS-071b0343-e284-4a1b-a50d-519d82d1defc,DISK], DatanodeInfoWithStorage[127.0.0.1:42431,DS-220deda7-b7d2-4e48-ae85-504cdef1e1f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43364,DS-ff202016-4c6d-4da8-bfc4-58c6a3b49df6,DISK], DatanodeInfoWithStorage[127.0.0.1:39135,DS-2cb07ead-bf1d-4ac1-91c6-7fefac2c681b,DISK], DatanodeInfoWithStorage[127.0.0.1:35551,DS-a62bf00e-600b-47b0-ab48-2aec02c0ae8e,DISK], DatanodeInfoWithStorage[127.0.0.1:36500,DS-453bbf38-ed71-492a-8058-9b3c416cf28a,DISK], DatanodeInfoWithStorage[127.0.0.1:44185,DS-e4af74ae-131d-4554-ab13-51e35545d10d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1716693621-172.17.0.10-1597671831376:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39445,DS-36ca00b9-5033-4b89-a305-7687c6470318,DISK], DatanodeInfoWithStorage[127.0.0.1:40962,DS-071b0343-e284-4a1b-a50d-519d82d1defc,DISK], DatanodeInfoWithStorage[127.0.0.1:42431,DS-220deda7-b7d2-4e48-ae85-504cdef1e1f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43364,DS-ff202016-4c6d-4da8-bfc4-58c6a3b49df6,DISK], DatanodeInfoWithStorage[127.0.0.1:39135,DS-2cb07ead-bf1d-4ac1-91c6-7fefac2c681b,DISK], DatanodeInfoWithStorage[127.0.0.1:35551,DS-a62bf00e-600b-47b0-ab48-2aec02c0ae8e,DISK], DatanodeInfoWithStorage[127.0.0.1:36500,DS-453bbf38-ed71-492a-8058-9b3c416cf28a,DISK], DatanodeInfoWithStorage[127.0.0.1:44185,DS-e4af74ae-131d-4554-ab13-51e35545d10d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1782221824-172.17.0.10-1597672264336:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35367,DS-99dc4175-6e46-4b54-9e33-7ee280b242a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42507,DS-3a88a1ff-23ad-43ee-8b64-fb796701a6ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35813,DS-c5d84517-6379-4919-819d-ed74c61d1ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:45146,DS-c8d3720d-268c-4d29-84c3-37a4cb8189ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35467,DS-e33efa93-67ab-4b4b-a862-0bdccf623c80,DISK], DatanodeInfoWithStorage[127.0.0.1:46227,DS-ed19350f-019a-4d77-b058-a9f23fc2c115,DISK], DatanodeInfoWithStorage[127.0.0.1:42546,DS-e7a8b8f2-7cb3-4f71-a66f-d39426e057f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34551,DS-b0cd2b97-4463-42f1-aa6d-ab68b06cc00b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1782221824-172.17.0.10-1597672264336:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35367,DS-99dc4175-6e46-4b54-9e33-7ee280b242a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42507,DS-3a88a1ff-23ad-43ee-8b64-fb796701a6ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35813,DS-c5d84517-6379-4919-819d-ed74c61d1ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:45146,DS-c8d3720d-268c-4d29-84c3-37a4cb8189ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35467,DS-e33efa93-67ab-4b4b-a862-0bdccf623c80,DISK], DatanodeInfoWithStorage[127.0.0.1:46227,DS-ed19350f-019a-4d77-b058-a9f23fc2c115,DISK], DatanodeInfoWithStorage[127.0.0.1:42546,DS-e7a8b8f2-7cb3-4f71-a66f-d39426e057f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34551,DS-b0cd2b97-4463-42f1-aa6d-ab68b06cc00b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1406719007-172.17.0.10-1597672335953:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43087,DS-fd6a4a7b-e6fa-488d-8769-d0e5660e115a,DISK], DatanodeInfoWithStorage[127.0.0.1:37554,DS-74790dbc-19ae-42a8-a892-818135432936,DISK], DatanodeInfoWithStorage[127.0.0.1:40213,DS-75e11686-c4b6-4ae6-b3b0-6be2b7163f64,DISK], DatanodeInfoWithStorage[127.0.0.1:37502,DS-baba8d35-1cd8-4ec9-8b66-1b9a0e8b125e,DISK], DatanodeInfoWithStorage[127.0.0.1:32996,DS-9dbaf580-a49a-4789-ad9c-eb1784dacc84,DISK], DatanodeInfoWithStorage[127.0.0.1:39417,DS-6a4734fa-2e5a-4a85-8053-b5336e750834,DISK], DatanodeInfoWithStorage[127.0.0.1:33496,DS-9b47066b-06a7-40c1-a22b-198cda47d297,DISK], DatanodeInfoWithStorage[127.0.0.1:39021,DS-74cf692b-e198-49fa-853e-c0a577b6e605,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1406719007-172.17.0.10-1597672335953:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43087,DS-fd6a4a7b-e6fa-488d-8769-d0e5660e115a,DISK], DatanodeInfoWithStorage[127.0.0.1:37554,DS-74790dbc-19ae-42a8-a892-818135432936,DISK], DatanodeInfoWithStorage[127.0.0.1:40213,DS-75e11686-c4b6-4ae6-b3b0-6be2b7163f64,DISK], DatanodeInfoWithStorage[127.0.0.1:37502,DS-baba8d35-1cd8-4ec9-8b66-1b9a0e8b125e,DISK], DatanodeInfoWithStorage[127.0.0.1:32996,DS-9dbaf580-a49a-4789-ad9c-eb1784dacc84,DISK], DatanodeInfoWithStorage[127.0.0.1:39417,DS-6a4734fa-2e5a-4a85-8053-b5336e750834,DISK], DatanodeInfoWithStorage[127.0.0.1:33496,DS-9b47066b-06a7-40c1-a22b-198cda47d297,DISK], DatanodeInfoWithStorage[127.0.0.1:39021,DS-74cf692b-e198-49fa-853e-c0a577b6e605,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1473208135-172.17.0.10-1597672407150:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34855,DS-a2d93b5c-3a06-4eb7-8a76-c1430dc1767d,DISK], DatanodeInfoWithStorage[127.0.0.1:41332,DS-8a71e094-7aba-4030-8fe2-299b788aea7b,DISK], DatanodeInfoWithStorage[127.0.0.1:37673,DS-8ce3ec9b-9137-45a7-9db7-3a9ad53b351c,DISK], DatanodeInfoWithStorage[127.0.0.1:45559,DS-88adecb7-be6a-4ce8-9b13-36d329d9cc27,DISK], DatanodeInfoWithStorage[127.0.0.1:33284,DS-e6b40374-3cd9-41a7-bd8a-5cd93071ec3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38717,DS-5f38c23a-1c06-44aa-a047-c840ee38facc,DISK], DatanodeInfoWithStorage[127.0.0.1:44741,DS-6029e49e-a1fd-43a3-a6d9-84692a1cb0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35090,DS-4dd105c3-4ec5-4633-999e-f0a8d6f9dce9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1473208135-172.17.0.10-1597672407150:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34855,DS-a2d93b5c-3a06-4eb7-8a76-c1430dc1767d,DISK], DatanodeInfoWithStorage[127.0.0.1:41332,DS-8a71e094-7aba-4030-8fe2-299b788aea7b,DISK], DatanodeInfoWithStorage[127.0.0.1:37673,DS-8ce3ec9b-9137-45a7-9db7-3a9ad53b351c,DISK], DatanodeInfoWithStorage[127.0.0.1:45559,DS-88adecb7-be6a-4ce8-9b13-36d329d9cc27,DISK], DatanodeInfoWithStorage[127.0.0.1:33284,DS-e6b40374-3cd9-41a7-bd8a-5cd93071ec3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38717,DS-5f38c23a-1c06-44aa-a047-c840ee38facc,DISK], DatanodeInfoWithStorage[127.0.0.1:44741,DS-6029e49e-a1fd-43a3-a6d9-84692a1cb0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35090,DS-4dd105c3-4ec5-4633-999e-f0a8d6f9dce9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1715554789-172.17.0.10-1597672858005:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32786,DS-7bb00342-6e33-49aa-9790-57bb7ebd4fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:39010,DS-b1239a35-84ad-45e9-801b-88f766bef78f,DISK], DatanodeInfoWithStorage[127.0.0.1:46580,DS-c5721f92-27bd-4e34-82a2-0bb8f10e68c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43621,DS-31ff1262-adf9-4763-98b2-93f6790ec688,DISK], DatanodeInfoWithStorage[127.0.0.1:40701,DS-4108194d-6852-4ff1-afe4-1fa6bfba9850,DISK], DatanodeInfoWithStorage[127.0.0.1:44644,DS-7c9a9a4d-9c77-4fb9-a8fd-ab0da278b3ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34360,DS-5bb73016-ce48-4531-a35b-d26215a41fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:46698,DS-5658ef0c-066d-41c1-9dfe-164fa4af2416,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1715554789-172.17.0.10-1597672858005:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32786,DS-7bb00342-6e33-49aa-9790-57bb7ebd4fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:39010,DS-b1239a35-84ad-45e9-801b-88f766bef78f,DISK], DatanodeInfoWithStorage[127.0.0.1:46580,DS-c5721f92-27bd-4e34-82a2-0bb8f10e68c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43621,DS-31ff1262-adf9-4763-98b2-93f6790ec688,DISK], DatanodeInfoWithStorage[127.0.0.1:40701,DS-4108194d-6852-4ff1-afe4-1fa6bfba9850,DISK], DatanodeInfoWithStorage[127.0.0.1:44644,DS-7c9a9a4d-9c77-4fb9-a8fd-ab0da278b3ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34360,DS-5bb73016-ce48-4531-a35b-d26215a41fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:46698,DS-5658ef0c-066d-41c1-9dfe-164fa4af2416,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1609514241-172.17.0.10-1597672965806:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37519,DS-959255b4-7877-4d9b-8c05-b73788c1004e,DISK], DatanodeInfoWithStorage[127.0.0.1:43679,DS-9f82a77a-36aa-41e8-a654-381b00701e24,DISK], DatanodeInfoWithStorage[127.0.0.1:34561,DS-5f081f0a-eb8b-4f85-b288-c08b4c031bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:42883,DS-fee76a08-92d1-4cdb-a1d6-9bb5cde8bb02,DISK], DatanodeInfoWithStorage[127.0.0.1:39596,DS-7408b1c1-9233-455e-99ae-13b6c42aeb9c,DISK], DatanodeInfoWithStorage[127.0.0.1:35832,DS-cd22a569-31cd-4aa8-82ee-e077becd049b,DISK], DatanodeInfoWithStorage[127.0.0.1:40649,DS-57761d02-d80f-4bfe-81eb-afbf4a776b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:37880,DS-e819da6b-06d8-4cf8-8399-e6b51bfd511a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1609514241-172.17.0.10-1597672965806:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37519,DS-959255b4-7877-4d9b-8c05-b73788c1004e,DISK], DatanodeInfoWithStorage[127.0.0.1:43679,DS-9f82a77a-36aa-41e8-a654-381b00701e24,DISK], DatanodeInfoWithStorage[127.0.0.1:34561,DS-5f081f0a-eb8b-4f85-b288-c08b4c031bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:42883,DS-fee76a08-92d1-4cdb-a1d6-9bb5cde8bb02,DISK], DatanodeInfoWithStorage[127.0.0.1:39596,DS-7408b1c1-9233-455e-99ae-13b6c42aeb9c,DISK], DatanodeInfoWithStorage[127.0.0.1:35832,DS-cd22a569-31cd-4aa8-82ee-e077becd049b,DISK], DatanodeInfoWithStorage[127.0.0.1:40649,DS-57761d02-d80f-4bfe-81eb-afbf4a776b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:37880,DS-e819da6b-06d8-4cf8-8399-e6b51bfd511a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1769383475-172.17.0.10-1597673521512:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46829,DS-9cf3894b-a1c2-48ca-bff2-150d7f1041f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46146,DS-35120b23-edd9-4317-b10b-bed6a6276c03,DISK], DatanodeInfoWithStorage[127.0.0.1:43373,DS-c22e792a-5be0-4fcc-b17a-f34f17f73439,DISK], DatanodeInfoWithStorage[127.0.0.1:33841,DS-9afcf902-2253-4cb4-8fcf-b223463c1108,DISK], DatanodeInfoWithStorage[127.0.0.1:32801,DS-084397ed-93b0-4d6b-940a-74fe30bb9508,DISK], DatanodeInfoWithStorage[127.0.0.1:34651,DS-e5e8ea48-8d59-471b-8338-200df794ac59,DISK], DatanodeInfoWithStorage[127.0.0.1:37633,DS-5f3edcc1-31d1-4497-b32f-cb4a0ca548e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35885,DS-5052c8f6-3f0e-497a-a3b8-bf99177ed55e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1769383475-172.17.0.10-1597673521512:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46829,DS-9cf3894b-a1c2-48ca-bff2-150d7f1041f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46146,DS-35120b23-edd9-4317-b10b-bed6a6276c03,DISK], DatanodeInfoWithStorage[127.0.0.1:43373,DS-c22e792a-5be0-4fcc-b17a-f34f17f73439,DISK], DatanodeInfoWithStorage[127.0.0.1:33841,DS-9afcf902-2253-4cb4-8fcf-b223463c1108,DISK], DatanodeInfoWithStorage[127.0.0.1:32801,DS-084397ed-93b0-4d6b-940a-74fe30bb9508,DISK], DatanodeInfoWithStorage[127.0.0.1:34651,DS-e5e8ea48-8d59-471b-8338-200df794ac59,DISK], DatanodeInfoWithStorage[127.0.0.1:37633,DS-5f3edcc1-31d1-4497-b32f-cb4a0ca548e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35885,DS-5052c8f6-3f0e-497a-a3b8-bf99177ed55e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-75802151-172.17.0.10-1597673809135:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41445,DS-92adacf2-ddc0-4010-81d2-5bbf649ac96e,DISK], DatanodeInfoWithStorage[127.0.0.1:39188,DS-406fc79a-0470-44ba-9c59-f3e7c9e901fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33892,DS-c468836b-73d1-427f-a16a-6198cbd95471,DISK], DatanodeInfoWithStorage[127.0.0.1:41994,DS-7b44d157-bca1-45fa-a5fb-256fb25a720e,DISK], DatanodeInfoWithStorage[127.0.0.1:35985,DS-5d11c0c7-4a01-491c-aefc-bb647ca8ca38,DISK], DatanodeInfoWithStorage[127.0.0.1:35509,DS-d651cbae-d996-4ab6-865a-4d2fc65448e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39846,DS-dfb6c520-3728-45f8-8f72-03f412e8d25d,DISK], DatanodeInfoWithStorage[127.0.0.1:33878,DS-c6856445-2ef9-4040-8596-f04e08a0aaa2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-75802151-172.17.0.10-1597673809135:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41445,DS-92adacf2-ddc0-4010-81d2-5bbf649ac96e,DISK], DatanodeInfoWithStorage[127.0.0.1:39188,DS-406fc79a-0470-44ba-9c59-f3e7c9e901fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33892,DS-c468836b-73d1-427f-a16a-6198cbd95471,DISK], DatanodeInfoWithStorage[127.0.0.1:41994,DS-7b44d157-bca1-45fa-a5fb-256fb25a720e,DISK], DatanodeInfoWithStorage[127.0.0.1:35985,DS-5d11c0c7-4a01-491c-aefc-bb647ca8ca38,DISK], DatanodeInfoWithStorage[127.0.0.1:35509,DS-d651cbae-d996-4ab6-865a-4d2fc65448e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39846,DS-dfb6c520-3728-45f8-8f72-03f412e8d25d,DISK], DatanodeInfoWithStorage[127.0.0.1:33878,DS-c6856445-2ef9-4040-8596-f04e08a0aaa2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1743917944-172.17.0.10-1597673989383:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41209,DS-a7b50a49-02ab-4190-afef-f6b38634c3a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39886,DS-8ecaad33-5bea-4a55-ad3b-2264dc8eabd5,DISK], DatanodeInfoWithStorage[127.0.0.1:44137,DS-8d511556-6a77-40b2-bdb6-54ff74412f12,DISK], DatanodeInfoWithStorage[127.0.0.1:39533,DS-ed823abe-33c5-46fb-bf8e-ac5e881ae917,DISK], DatanodeInfoWithStorage[127.0.0.1:43377,DS-6127d4cc-710f-4c66-9082-191668e8226e,DISK], DatanodeInfoWithStorage[127.0.0.1:39639,DS-2119d5b7-4332-4a90-bb3b-2a95ba2ad9dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37432,DS-72cb47c4-6ea6-4a16-874a-5ddb330425a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40384,DS-40f88f2c-3475-413d-a629-6ed611b60057,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1743917944-172.17.0.10-1597673989383:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41209,DS-a7b50a49-02ab-4190-afef-f6b38634c3a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39886,DS-8ecaad33-5bea-4a55-ad3b-2264dc8eabd5,DISK], DatanodeInfoWithStorage[127.0.0.1:44137,DS-8d511556-6a77-40b2-bdb6-54ff74412f12,DISK], DatanodeInfoWithStorage[127.0.0.1:39533,DS-ed823abe-33c5-46fb-bf8e-ac5e881ae917,DISK], DatanodeInfoWithStorage[127.0.0.1:43377,DS-6127d4cc-710f-4c66-9082-191668e8226e,DISK], DatanodeInfoWithStorage[127.0.0.1:39639,DS-2119d5b7-4332-4a90-bb3b-2a95ba2ad9dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37432,DS-72cb47c4-6ea6-4a16-874a-5ddb330425a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40384,DS-40f88f2c-3475-413d-a629-6ed611b60057,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1415704148-172.17.0.10-1597674121600:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42397,DS-f3c2b99b-ed08-48ff-b5c9-b76eebceb9dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41307,DS-f3c1ad63-b266-4af6-9840-147186c236a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38458,DS-1184b92f-edea-49bf-9b73-559c8bb267f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36778,DS-b1d29d61-2b23-4f41-9268-090f288bd140,DISK], DatanodeInfoWithStorage[127.0.0.1:39192,DS-8454ced8-b838-4c10-bf39-1662c9f00250,DISK], DatanodeInfoWithStorage[127.0.0.1:38957,DS-4de4be7e-63fd-4b09-8084-226fe0ad47f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34579,DS-00758d2e-4ebf-433d-871c-be9ea717bcbc,DISK], DatanodeInfoWithStorage[127.0.0.1:38084,DS-ccc072a8-25ab-4b4b-85b5-795538a80057,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1415704148-172.17.0.10-1597674121600:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42397,DS-f3c2b99b-ed08-48ff-b5c9-b76eebceb9dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41307,DS-f3c1ad63-b266-4af6-9840-147186c236a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38458,DS-1184b92f-edea-49bf-9b73-559c8bb267f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36778,DS-b1d29d61-2b23-4f41-9268-090f288bd140,DISK], DatanodeInfoWithStorage[127.0.0.1:39192,DS-8454ced8-b838-4c10-bf39-1662c9f00250,DISK], DatanodeInfoWithStorage[127.0.0.1:38957,DS-4de4be7e-63fd-4b09-8084-226fe0ad47f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34579,DS-00758d2e-4ebf-433d-871c-be9ea717bcbc,DISK], DatanodeInfoWithStorage[127.0.0.1:38084,DS-ccc072a8-25ab-4b4b-85b5-795538a80057,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-226381497-172.17.0.10-1597674306178:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34348,DS-e579d080-429c-4d93-bfc7-7e0d9098d668,DISK], DatanodeInfoWithStorage[127.0.0.1:35965,DS-314cf8b8-f2f5-4346-a987-fc2dd0768ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:44449,DS-a2dc0fb7-acdb-4b5d-a928-326c036d96f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42525,DS-c518c323-f37c-47f1-9c49-e85429a6e838,DISK], DatanodeInfoWithStorage[127.0.0.1:41218,DS-cf20a481-2558-42c9-b5df-ee06132d24af,DISK], DatanodeInfoWithStorage[127.0.0.1:42602,DS-5152ffca-f2e0-4ee8-b7d2-db555d951041,DISK], DatanodeInfoWithStorage[127.0.0.1:44465,DS-8597ad7f-1c3b-4c48-b38a-2ae08aa6970e,DISK], DatanodeInfoWithStorage[127.0.0.1:42441,DS-62c68f66-a4d2-4771-b9c0-2d3480cddd32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-226381497-172.17.0.10-1597674306178:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34348,DS-e579d080-429c-4d93-bfc7-7e0d9098d668,DISK], DatanodeInfoWithStorage[127.0.0.1:35965,DS-314cf8b8-f2f5-4346-a987-fc2dd0768ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:44449,DS-a2dc0fb7-acdb-4b5d-a928-326c036d96f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42525,DS-c518c323-f37c-47f1-9c49-e85429a6e838,DISK], DatanodeInfoWithStorage[127.0.0.1:41218,DS-cf20a481-2558-42c9-b5df-ee06132d24af,DISK], DatanodeInfoWithStorage[127.0.0.1:42602,DS-5152ffca-f2e0-4ee8-b7d2-db555d951041,DISK], DatanodeInfoWithStorage[127.0.0.1:44465,DS-8597ad7f-1c3b-4c48-b38a-2ae08aa6970e,DISK], DatanodeInfoWithStorage[127.0.0.1:42441,DS-62c68f66-a4d2-4771-b9c0-2d3480cddd32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2119862481-172.17.0.10-1597674410278:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33086,DS-0bc5102a-77fd-4c4e-ad50-5b35410c4724,DISK], DatanodeInfoWithStorage[127.0.0.1:41754,DS-56838dc3-9a8a-446c-8d76-0914c68d6df4,DISK], DatanodeInfoWithStorage[127.0.0.1:37513,DS-2656c119-eef1-4c5e-83fb-a9ae72bba2fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-00f091cd-ccdc-4043-8418-72f2b56850e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35993,DS-03fa1946-46f2-4b00-ab7d-7d066a05625e,DISK], DatanodeInfoWithStorage[127.0.0.1:39545,DS-1607ecf0-bdd0-49b4-bfe5-70252703625c,DISK], DatanodeInfoWithStorage[127.0.0.1:34381,DS-ad3aa2c4-b7f6-418b-901b-105aff7e4469,DISK], DatanodeInfoWithStorage[127.0.0.1:46583,DS-0ad15977-771b-40c9-bc7f-c01c831c3574,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2119862481-172.17.0.10-1597674410278:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33086,DS-0bc5102a-77fd-4c4e-ad50-5b35410c4724,DISK], DatanodeInfoWithStorage[127.0.0.1:41754,DS-56838dc3-9a8a-446c-8d76-0914c68d6df4,DISK], DatanodeInfoWithStorage[127.0.0.1:37513,DS-2656c119-eef1-4c5e-83fb-a9ae72bba2fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-00f091cd-ccdc-4043-8418-72f2b56850e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35993,DS-03fa1946-46f2-4b00-ab7d-7d066a05625e,DISK], DatanodeInfoWithStorage[127.0.0.1:39545,DS-1607ecf0-bdd0-49b4-bfe5-70252703625c,DISK], DatanodeInfoWithStorage[127.0.0.1:34381,DS-ad3aa2c4-b7f6-418b-901b-105aff7e4469,DISK], DatanodeInfoWithStorage[127.0.0.1:46583,DS-0ad15977-771b-40c9-bc7f-c01c831c3574,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-46941182-172.17.0.10-1597674481060:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34267,DS-00964575-afe5-42e9-a2ee-20f3208e7c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:45578,DS-6a173de9-fcaa-461b-a1f2-ba07a02e5736,DISK], DatanodeInfoWithStorage[127.0.0.1:36418,DS-f4044bc2-53cd-4d18-9ebf-ab480336be80,DISK], DatanodeInfoWithStorage[127.0.0.1:40869,DS-64453d54-d5a1-400b-b567-b5a6ed682cec,DISK], DatanodeInfoWithStorage[127.0.0.1:44980,DS-a8234082-b163-4356-8f3c-42703cc875cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45536,DS-f2949168-5fb4-4333-b210-9e7555c75fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:42936,DS-8d1ba7fc-a815-44cd-9b8b-27bce5afd62b,DISK], DatanodeInfoWithStorage[127.0.0.1:46521,DS-790131d8-2dd7-4930-8c7e-3fca278b7efb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-46941182-172.17.0.10-1597674481060:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34267,DS-00964575-afe5-42e9-a2ee-20f3208e7c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:45578,DS-6a173de9-fcaa-461b-a1f2-ba07a02e5736,DISK], DatanodeInfoWithStorage[127.0.0.1:36418,DS-f4044bc2-53cd-4d18-9ebf-ab480336be80,DISK], DatanodeInfoWithStorage[127.0.0.1:40869,DS-64453d54-d5a1-400b-b567-b5a6ed682cec,DISK], DatanodeInfoWithStorage[127.0.0.1:44980,DS-a8234082-b163-4356-8f3c-42703cc875cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45536,DS-f2949168-5fb4-4333-b210-9e7555c75fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:42936,DS-8d1ba7fc-a815-44cd-9b8b-27bce5afd62b,DISK], DatanodeInfoWithStorage[127.0.0.1:46521,DS-790131d8-2dd7-4930-8c7e-3fca278b7efb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-789235232-172.17.0.10-1597675624196:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45708,DS-740e661f-e40e-4004-8579-00b7c895f127,DISK], DatanodeInfoWithStorage[127.0.0.1:35666,DS-40f3ac1f-d910-42e7-b742-2e3eb680c4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45647,DS-4562df62-c73d-4794-9d1a-668f2c1dcf05,DISK], DatanodeInfoWithStorage[127.0.0.1:41014,DS-e7c7ec5b-daef-4be3-a3a4-1f5f999a60a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41787,DS-1fb3a4e9-ea24-419a-8bf7-f5635d62d98f,DISK], DatanodeInfoWithStorage[127.0.0.1:43429,DS-f65810f9-db8d-43df-80b1-ead29c432a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39460,DS-f314423f-939f-47ab-9031-758fb832fb98,DISK], DatanodeInfoWithStorage[127.0.0.1:33812,DS-a9673ed6-63ed-48c9-9752-c981992d372c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-789235232-172.17.0.10-1597675624196:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45708,DS-740e661f-e40e-4004-8579-00b7c895f127,DISK], DatanodeInfoWithStorage[127.0.0.1:35666,DS-40f3ac1f-d910-42e7-b742-2e3eb680c4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45647,DS-4562df62-c73d-4794-9d1a-668f2c1dcf05,DISK], DatanodeInfoWithStorage[127.0.0.1:41014,DS-e7c7ec5b-daef-4be3-a3a4-1f5f999a60a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41787,DS-1fb3a4e9-ea24-419a-8bf7-f5635d62d98f,DISK], DatanodeInfoWithStorage[127.0.0.1:43429,DS-f65810f9-db8d-43df-80b1-ead29c432a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39460,DS-f314423f-939f-47ab-9031-758fb832fb98,DISK], DatanodeInfoWithStorage[127.0.0.1:33812,DS-a9673ed6-63ed-48c9-9752-c981992d372c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1429273422-172.17.0.10-1597675978496:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36401,DS-9700883c-93df-494a-b346-afac14c4bc97,DISK], DatanodeInfoWithStorage[127.0.0.1:36576,DS-3f6bc41b-b000-4a3d-a67d-94991ad55922,DISK], DatanodeInfoWithStorage[127.0.0.1:46415,DS-b90fbc1b-e81a-4e8a-b654-14642b4babf0,DISK], DatanodeInfoWithStorage[127.0.0.1:45331,DS-fc699b3e-d30d-447e-a2a5-c51811df9f49,DISK], DatanodeInfoWithStorage[127.0.0.1:45777,DS-28529100-564e-4722-bccf-14d67ec2ef93,DISK], DatanodeInfoWithStorage[127.0.0.1:38675,DS-a8e03018-610b-4385-b8ae-6c4240bb507e,DISK], DatanodeInfoWithStorage[127.0.0.1:37840,DS-10aa48fd-ebd7-4921-8943-1b2ee6d89010,DISK], DatanodeInfoWithStorage[127.0.0.1:43614,DS-8b9b7aa9-cc9b-4e97-8831-99ee9dc1c031,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1429273422-172.17.0.10-1597675978496:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36401,DS-9700883c-93df-494a-b346-afac14c4bc97,DISK], DatanodeInfoWithStorage[127.0.0.1:36576,DS-3f6bc41b-b000-4a3d-a67d-94991ad55922,DISK], DatanodeInfoWithStorage[127.0.0.1:46415,DS-b90fbc1b-e81a-4e8a-b654-14642b4babf0,DISK], DatanodeInfoWithStorage[127.0.0.1:45331,DS-fc699b3e-d30d-447e-a2a5-c51811df9f49,DISK], DatanodeInfoWithStorage[127.0.0.1:45777,DS-28529100-564e-4722-bccf-14d67ec2ef93,DISK], DatanodeInfoWithStorage[127.0.0.1:38675,DS-a8e03018-610b-4385-b8ae-6c4240bb507e,DISK], DatanodeInfoWithStorage[127.0.0.1:37840,DS-10aa48fd-ebd7-4921-8943-1b2ee6d89010,DISK], DatanodeInfoWithStorage[127.0.0.1:43614,DS-8b9b7aa9-cc9b-4e97-8831-99ee9dc1c031,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2136774873-172.17.0.10-1597676279558:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43770,DS-71d1551b-cf9f-4faf-8ebc-e102459cde02,DISK], DatanodeInfoWithStorage[127.0.0.1:34375,DS-6bfa48de-581b-4b9c-8e68-8f7cfd0b5d01,DISK], DatanodeInfoWithStorage[127.0.0.1:44181,DS-b5222365-f2af-46aa-a995-0ffa4d9e3f05,DISK], DatanodeInfoWithStorage[127.0.0.1:37956,DS-45e970ce-4414-4f40-b494-03a31bd00937,DISK], DatanodeInfoWithStorage[127.0.0.1:34794,DS-91d500f8-d084-49d1-8227-bebb9f3431f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37292,DS-79cf1e19-b96a-48cc-8ab8-a720db12e3cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37529,DS-91962687-6d6d-4a87-a140-c0f7b0f1e95a,DISK], DatanodeInfoWithStorage[127.0.0.1:35845,DS-3dfda9a5-9498-43eb-9497-c61dceb47dbd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2136774873-172.17.0.10-1597676279558:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43770,DS-71d1551b-cf9f-4faf-8ebc-e102459cde02,DISK], DatanodeInfoWithStorage[127.0.0.1:34375,DS-6bfa48de-581b-4b9c-8e68-8f7cfd0b5d01,DISK], DatanodeInfoWithStorage[127.0.0.1:44181,DS-b5222365-f2af-46aa-a995-0ffa4d9e3f05,DISK], DatanodeInfoWithStorage[127.0.0.1:37956,DS-45e970ce-4414-4f40-b494-03a31bd00937,DISK], DatanodeInfoWithStorage[127.0.0.1:34794,DS-91d500f8-d084-49d1-8227-bebb9f3431f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37292,DS-79cf1e19-b96a-48cc-8ab8-a720db12e3cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37529,DS-91962687-6d6d-4a87-a140-c0f7b0f1e95a,DISK], DatanodeInfoWithStorage[127.0.0.1:35845,DS-3dfda9a5-9498-43eb-9497-c61dceb47dbd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1135276931-172.17.0.10-1597676319856:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44122,DS-35b5abb1-200d-4696-a021-b295105b8806,DISK], DatanodeInfoWithStorage[127.0.0.1:43849,DS-85783a6c-37ab-4d82-8cd6-a625c83f360a,DISK], DatanodeInfoWithStorage[127.0.0.1:40224,DS-63b1b5cc-30d6-460b-b85d-7b376e614165,DISK], DatanodeInfoWithStorage[127.0.0.1:39782,DS-f4792973-a9cc-49d8-b9c5-17b3c1cae453,DISK], DatanodeInfoWithStorage[127.0.0.1:40602,DS-a14a3be8-0d68-4f10-bf69-0ecfd7857a72,DISK], DatanodeInfoWithStorage[127.0.0.1:35790,DS-9938d619-b50c-41bb-8e22-61c28bd7327a,DISK], DatanodeInfoWithStorage[127.0.0.1:45405,DS-ce9df4f7-0764-4710-ae4e-7023d72c7ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:42833,DS-4ff5709e-2340-46c7-90ce-170813771e9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1135276931-172.17.0.10-1597676319856:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44122,DS-35b5abb1-200d-4696-a021-b295105b8806,DISK], DatanodeInfoWithStorage[127.0.0.1:43849,DS-85783a6c-37ab-4d82-8cd6-a625c83f360a,DISK], DatanodeInfoWithStorage[127.0.0.1:40224,DS-63b1b5cc-30d6-460b-b85d-7b376e614165,DISK], DatanodeInfoWithStorage[127.0.0.1:39782,DS-f4792973-a9cc-49d8-b9c5-17b3c1cae453,DISK], DatanodeInfoWithStorage[127.0.0.1:40602,DS-a14a3be8-0d68-4f10-bf69-0ecfd7857a72,DISK], DatanodeInfoWithStorage[127.0.0.1:35790,DS-9938d619-b50c-41bb-8e22-61c28bd7327a,DISK], DatanodeInfoWithStorage[127.0.0.1:45405,DS-ce9df4f7-0764-4710-ae4e-7023d72c7ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:42833,DS-4ff5709e-2340-46c7-90ce-170813771e9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5492
