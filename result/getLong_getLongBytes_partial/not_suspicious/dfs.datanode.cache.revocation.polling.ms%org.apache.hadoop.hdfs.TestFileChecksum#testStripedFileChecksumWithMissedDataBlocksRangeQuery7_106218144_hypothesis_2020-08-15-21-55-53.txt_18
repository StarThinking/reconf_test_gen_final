reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2678482-172.17.0.16-1597528885222:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43055,DS-9b53aa25-5d8e-4564-af3d-be30636c6a54,DISK], DatanodeInfoWithStorage[127.0.0.1:36023,DS-d08b8858-d11a-4ff7-a869-f0dcea8d6dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:38987,DS-173fb12d-de2f-4c28-8ae3-d5db4cda0c90,DISK], DatanodeInfoWithStorage[127.0.0.1:33817,DS-ea6a0599-ed01-4724-878d-3052679bf665,DISK], DatanodeInfoWithStorage[127.0.0.1:37768,DS-b7a986b9-2a7e-41b8-b32c-216ad62fe9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45347,DS-0f3d5df1-d37c-498f-ade3-c28ec4a25f79,DISK], DatanodeInfoWithStorage[127.0.0.1:32842,DS-c1ac6c4b-d1c7-44e2-b0bd-7e13fe558eef,DISK], DatanodeInfoWithStorage[127.0.0.1:36515,DS-6a37ff2b-6122-4e81-b0e0-185c7cf1a6e3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2678482-172.17.0.16-1597528885222:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43055,DS-9b53aa25-5d8e-4564-af3d-be30636c6a54,DISK], DatanodeInfoWithStorage[127.0.0.1:36023,DS-d08b8858-d11a-4ff7-a869-f0dcea8d6dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:38987,DS-173fb12d-de2f-4c28-8ae3-d5db4cda0c90,DISK], DatanodeInfoWithStorage[127.0.0.1:33817,DS-ea6a0599-ed01-4724-878d-3052679bf665,DISK], DatanodeInfoWithStorage[127.0.0.1:37768,DS-b7a986b9-2a7e-41b8-b32c-216ad62fe9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45347,DS-0f3d5df1-d37c-498f-ade3-c28ec4a25f79,DISK], DatanodeInfoWithStorage[127.0.0.1:32842,DS-c1ac6c4b-d1c7-44e2-b0bd-7e13fe558eef,DISK], DatanodeInfoWithStorage[127.0.0.1:36515,DS-6a37ff2b-6122-4e81-b0e0-185c7cf1a6e3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1838713157-172.17.0.16-1597528965143:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41237,DS-cbf13d42-34e0-4534-abe5-443d3a3f9146,DISK], DatanodeInfoWithStorage[127.0.0.1:36107,DS-5ae86cac-0242-4207-9602-506ed5a9375f,DISK], DatanodeInfoWithStorage[127.0.0.1:38695,DS-83f338ff-ce65-4da8-80c2-1a6acd06107e,DISK], DatanodeInfoWithStorage[127.0.0.1:38466,DS-4eca711a-a06c-4ca7-bd09-f11d9bd182c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35418,DS-4aa28f33-4a13-469c-a351-aa3a69dc7cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:41719,DS-12244203-47b6-429d-ac6c-c1c8da7a06e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45943,DS-1afef89c-3c13-4ba1-8407-077ee961c242,DISK], DatanodeInfoWithStorage[127.0.0.1:44064,DS-721ac191-33a9-4d5d-abdd-70ebebcb5477,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1838713157-172.17.0.16-1597528965143:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41237,DS-cbf13d42-34e0-4534-abe5-443d3a3f9146,DISK], DatanodeInfoWithStorage[127.0.0.1:36107,DS-5ae86cac-0242-4207-9602-506ed5a9375f,DISK], DatanodeInfoWithStorage[127.0.0.1:38695,DS-83f338ff-ce65-4da8-80c2-1a6acd06107e,DISK], DatanodeInfoWithStorage[127.0.0.1:38466,DS-4eca711a-a06c-4ca7-bd09-f11d9bd182c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35418,DS-4aa28f33-4a13-469c-a351-aa3a69dc7cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:41719,DS-12244203-47b6-429d-ac6c-c1c8da7a06e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45943,DS-1afef89c-3c13-4ba1-8407-077ee961c242,DISK], DatanodeInfoWithStorage[127.0.0.1:44064,DS-721ac191-33a9-4d5d-abdd-70ebebcb5477,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-450690429-172.17.0.16-1597529094692:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45215,DS-f04d3384-088b-403c-a1c1-5bae3c964e69,DISK], DatanodeInfoWithStorage[127.0.0.1:34817,DS-cf924e6b-028a-4d93-8334-937634505101,DISK], DatanodeInfoWithStorage[127.0.0.1:40761,DS-fd48142d-f4b9-4a63-95f4-c4fc300da17d,DISK], DatanodeInfoWithStorage[127.0.0.1:41070,DS-af5fadd9-c461-4bb3-8639-ed744d625142,DISK], DatanodeInfoWithStorage[127.0.0.1:46009,DS-789f545e-1313-487e-b146-fc86ec6bb835,DISK], DatanodeInfoWithStorage[127.0.0.1:37407,DS-62dbbe9b-a2d3-40df-a6bb-8dcfe4b52a25,DISK], DatanodeInfoWithStorage[127.0.0.1:46839,DS-4c1b18ea-f154-4210-b3aa-9b7b8e1f5ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:45909,DS-a0e683f3-4880-46e1-862b-0a3f6a1c93bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-450690429-172.17.0.16-1597529094692:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45215,DS-f04d3384-088b-403c-a1c1-5bae3c964e69,DISK], DatanodeInfoWithStorage[127.0.0.1:34817,DS-cf924e6b-028a-4d93-8334-937634505101,DISK], DatanodeInfoWithStorage[127.0.0.1:40761,DS-fd48142d-f4b9-4a63-95f4-c4fc300da17d,DISK], DatanodeInfoWithStorage[127.0.0.1:41070,DS-af5fadd9-c461-4bb3-8639-ed744d625142,DISK], DatanodeInfoWithStorage[127.0.0.1:46009,DS-789f545e-1313-487e-b146-fc86ec6bb835,DISK], DatanodeInfoWithStorage[127.0.0.1:37407,DS-62dbbe9b-a2d3-40df-a6bb-8dcfe4b52a25,DISK], DatanodeInfoWithStorage[127.0.0.1:46839,DS-4c1b18ea-f154-4210-b3aa-9b7b8e1f5ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:45909,DS-a0e683f3-4880-46e1-862b-0a3f6a1c93bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-889108071-172.17.0.16-1597529391136:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36457,DS-9f71771f-2578-4903-94dc-d16f328409d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42116,DS-4c09ec47-3d99-47d8-aee2-9ea4f8d62ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:39215,DS-da902a2d-1424-45e9-9274-53a32b70728e,DISK], DatanodeInfoWithStorage[127.0.0.1:36939,DS-f0ac12f1-fa74-4783-8fbf-97a42ce29536,DISK], DatanodeInfoWithStorage[127.0.0.1:39566,DS-bff25542-3676-4c1c-b2f1-9a83610a3682,DISK], DatanodeInfoWithStorage[127.0.0.1:39009,DS-4421c09c-c009-47f7-802d-b5399e70d4da,DISK], DatanodeInfoWithStorage[127.0.0.1:38592,DS-dda4973c-ded7-457f-9435-5694fe1ed20a,DISK], DatanodeInfoWithStorage[127.0.0.1:42757,DS-f6ab5190-92d2-4f11-bd31-35e91e3034e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-889108071-172.17.0.16-1597529391136:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36457,DS-9f71771f-2578-4903-94dc-d16f328409d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42116,DS-4c09ec47-3d99-47d8-aee2-9ea4f8d62ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:39215,DS-da902a2d-1424-45e9-9274-53a32b70728e,DISK], DatanodeInfoWithStorage[127.0.0.1:36939,DS-f0ac12f1-fa74-4783-8fbf-97a42ce29536,DISK], DatanodeInfoWithStorage[127.0.0.1:39566,DS-bff25542-3676-4c1c-b2f1-9a83610a3682,DISK], DatanodeInfoWithStorage[127.0.0.1:39009,DS-4421c09c-c009-47f7-802d-b5399e70d4da,DISK], DatanodeInfoWithStorage[127.0.0.1:38592,DS-dda4973c-ded7-457f-9435-5694fe1ed20a,DISK], DatanodeInfoWithStorage[127.0.0.1:42757,DS-f6ab5190-92d2-4f11-bd31-35e91e3034e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-427258324-172.17.0.16-1597529538877:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43365,DS-16dc2f54-8d2c-4bf5-84f0-41bd3819bffd,DISK], DatanodeInfoWithStorage[127.0.0.1:46162,DS-92e6e9aa-71da-4f55-8cb5-08b5ea703b11,DISK], DatanodeInfoWithStorage[127.0.0.1:40916,DS-830d1cb1-8220-47e1-bcc5-c7c0621435d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44835,DS-d6c65697-a0b9-4de8-bf44-802e2e472ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:44310,DS-0f2fef10-7e68-421e-afb1-1bbfad789c79,DISK], DatanodeInfoWithStorage[127.0.0.1:39627,DS-d5ff42dc-71dd-463b-9839-f88cbdb115df,DISK], DatanodeInfoWithStorage[127.0.0.1:36492,DS-b4057efa-5c4c-4852-9437-de06ec19e433,DISK], DatanodeInfoWithStorage[127.0.0.1:36806,DS-a31b8f69-aa9c-4075-a066-5a558b681b81,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-427258324-172.17.0.16-1597529538877:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43365,DS-16dc2f54-8d2c-4bf5-84f0-41bd3819bffd,DISK], DatanodeInfoWithStorage[127.0.0.1:46162,DS-92e6e9aa-71da-4f55-8cb5-08b5ea703b11,DISK], DatanodeInfoWithStorage[127.0.0.1:40916,DS-830d1cb1-8220-47e1-bcc5-c7c0621435d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44835,DS-d6c65697-a0b9-4de8-bf44-802e2e472ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:44310,DS-0f2fef10-7e68-421e-afb1-1bbfad789c79,DISK], DatanodeInfoWithStorage[127.0.0.1:39627,DS-d5ff42dc-71dd-463b-9839-f88cbdb115df,DISK], DatanodeInfoWithStorage[127.0.0.1:36492,DS-b4057efa-5c4c-4852-9437-de06ec19e433,DISK], DatanodeInfoWithStorage[127.0.0.1:36806,DS-a31b8f69-aa9c-4075-a066-5a558b681b81,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-524446246-172.17.0.16-1597529670457:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36416,DS-0223b697-b136-4654-a9bb-cc0880705558,DISK], DatanodeInfoWithStorage[127.0.0.1:36731,DS-a72ce9fa-76a0-453a-af8d-fec514ea743c,DISK], DatanodeInfoWithStorage[127.0.0.1:33610,DS-eda8820e-a65a-4d2a-9839-bfcb80a8c88a,DISK], DatanodeInfoWithStorage[127.0.0.1:39550,DS-5d6b0f24-46e9-49aa-83c4-77c6b2fc910c,DISK], DatanodeInfoWithStorage[127.0.0.1:34527,DS-9a2700bd-b929-4484-84ff-aff8dc2c9ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:40626,DS-29755225-20b5-4d40-8cf7-fc234c3378d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40695,DS-6fece383-93e5-495c-9b5f-e645b6e89ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:34695,DS-6615d13d-abbf-4dbe-b127-d7a4189f0d6c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-524446246-172.17.0.16-1597529670457:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36416,DS-0223b697-b136-4654-a9bb-cc0880705558,DISK], DatanodeInfoWithStorage[127.0.0.1:36731,DS-a72ce9fa-76a0-453a-af8d-fec514ea743c,DISK], DatanodeInfoWithStorage[127.0.0.1:33610,DS-eda8820e-a65a-4d2a-9839-bfcb80a8c88a,DISK], DatanodeInfoWithStorage[127.0.0.1:39550,DS-5d6b0f24-46e9-49aa-83c4-77c6b2fc910c,DISK], DatanodeInfoWithStorage[127.0.0.1:34527,DS-9a2700bd-b929-4484-84ff-aff8dc2c9ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:40626,DS-29755225-20b5-4d40-8cf7-fc234c3378d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40695,DS-6fece383-93e5-495c-9b5f-e645b6e89ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:34695,DS-6615d13d-abbf-4dbe-b127-d7a4189f0d6c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-350717418-172.17.0.16-1597529804240:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35910,DS-392360d3-ed47-4e0f-adba-a4a22dafd5fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34740,DS-3fa13522-8b88-4805-80b7-885b28b30ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:38397,DS-4754f8c2-548f-43dd-b809-222f2324bb77,DISK], DatanodeInfoWithStorage[127.0.0.1:32888,DS-8025d3de-3634-4e46-afe8-f724539c74e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39946,DS-bd35b2f8-3585-41cb-bf55-b4a75a92da35,DISK], DatanodeInfoWithStorage[127.0.0.1:45277,DS-8cc4e609-d114-41e9-bbca-8a969cf5e9a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42808,DS-26e9fffc-f510-455b-92b6-32e8d529f688,DISK], DatanodeInfoWithStorage[127.0.0.1:40075,DS-4844a1ad-512f-4a76-878a-e2b18bda00ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-350717418-172.17.0.16-1597529804240:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35910,DS-392360d3-ed47-4e0f-adba-a4a22dafd5fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34740,DS-3fa13522-8b88-4805-80b7-885b28b30ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:38397,DS-4754f8c2-548f-43dd-b809-222f2324bb77,DISK], DatanodeInfoWithStorage[127.0.0.1:32888,DS-8025d3de-3634-4e46-afe8-f724539c74e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39946,DS-bd35b2f8-3585-41cb-bf55-b4a75a92da35,DISK], DatanodeInfoWithStorage[127.0.0.1:45277,DS-8cc4e609-d114-41e9-bbca-8a969cf5e9a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42808,DS-26e9fffc-f510-455b-92b6-32e8d529f688,DISK], DatanodeInfoWithStorage[127.0.0.1:40075,DS-4844a1ad-512f-4a76-878a-e2b18bda00ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1433403392-172.17.0.16-1597529859491:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46568,DS-f34bef53-ade0-4391-b790-e4cc262499dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38553,DS-1d91c909-c013-43a5-8fbe-de3809ab9b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39594,DS-a324ed63-2712-4eea-82d3-4145d8d4e4d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37525,DS-13f3bf3f-5761-4ad3-9921-7b8c10cf1cff,DISK], DatanodeInfoWithStorage[127.0.0.1:33519,DS-bef77bf9-d138-4b49-8169-51e528aeb440,DISK], DatanodeInfoWithStorage[127.0.0.1:45528,DS-ba4b3c01-576e-4961-9380-96ad675366ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42418,DS-f965104e-a7be-4593-933b-db9b93f0ce68,DISK], DatanodeInfoWithStorage[127.0.0.1:39200,DS-ea9cc528-e600-41b9-bc65-461e2159acdb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1433403392-172.17.0.16-1597529859491:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46568,DS-f34bef53-ade0-4391-b790-e4cc262499dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38553,DS-1d91c909-c013-43a5-8fbe-de3809ab9b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39594,DS-a324ed63-2712-4eea-82d3-4145d8d4e4d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37525,DS-13f3bf3f-5761-4ad3-9921-7b8c10cf1cff,DISK], DatanodeInfoWithStorage[127.0.0.1:33519,DS-bef77bf9-d138-4b49-8169-51e528aeb440,DISK], DatanodeInfoWithStorage[127.0.0.1:45528,DS-ba4b3c01-576e-4961-9380-96ad675366ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42418,DS-f965104e-a7be-4593-933b-db9b93f0ce68,DISK], DatanodeInfoWithStorage[127.0.0.1:39200,DS-ea9cc528-e600-41b9-bc65-461e2159acdb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-794944866-172.17.0.16-1597530095296:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39947,DS-b073a8ce-edbb-4667-9a3b-1363d9c79b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40556,DS-7ef985a3-c10d-41e9-9dad-f7667b2358c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41078,DS-aeaec4d0-10cc-4bbf-9b69-7061f549cb20,DISK], DatanodeInfoWithStorage[127.0.0.1:45451,DS-0a07f78c-e19a-4d25-bfe2-c99ae4942b52,DISK], DatanodeInfoWithStorage[127.0.0.1:36322,DS-82ae3eaf-98f4-441d-a116-359509b33ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:40485,DS-5827a4d9-e811-466a-b88e-f376e336f470,DISK], DatanodeInfoWithStorage[127.0.0.1:39593,DS-26ae5331-4c1d-4fc1-b752-45f29b246172,DISK], DatanodeInfoWithStorage[127.0.0.1:42932,DS-55a04215-70bc-4db1-b4d8-035b30abcf15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-794944866-172.17.0.16-1597530095296:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39947,DS-b073a8ce-edbb-4667-9a3b-1363d9c79b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40556,DS-7ef985a3-c10d-41e9-9dad-f7667b2358c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41078,DS-aeaec4d0-10cc-4bbf-9b69-7061f549cb20,DISK], DatanodeInfoWithStorage[127.0.0.1:45451,DS-0a07f78c-e19a-4d25-bfe2-c99ae4942b52,DISK], DatanodeInfoWithStorage[127.0.0.1:36322,DS-82ae3eaf-98f4-441d-a116-359509b33ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:40485,DS-5827a4d9-e811-466a-b88e-f376e336f470,DISK], DatanodeInfoWithStorage[127.0.0.1:39593,DS-26ae5331-4c1d-4fc1-b752-45f29b246172,DISK], DatanodeInfoWithStorage[127.0.0.1:42932,DS-55a04215-70bc-4db1-b4d8-035b30abcf15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-728695344-172.17.0.16-1597530194331:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42395,DS-9b72e1cf-9e48-43a0-bc49-08e9a920ed3c,DISK], DatanodeInfoWithStorage[127.0.0.1:41628,DS-eaf2e618-2f93-4525-8535-344b12496715,DISK], DatanodeInfoWithStorage[127.0.0.1:39535,DS-f3b3cc6a-1d68-4a4a-8a10-dca41431315c,DISK], DatanodeInfoWithStorage[127.0.0.1:36105,DS-b975bab5-b7d2-4617-926d-78d69c0ec3d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40642,DS-fa538112-7662-457c-ad65-8d870ee5888c,DISK], DatanodeInfoWithStorage[127.0.0.1:37045,DS-edb07bdb-fc77-4e2f-967b-46089e3aa8d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40329,DS-695d76ee-1bcd-428b-8f61-fd4eb6d85d23,DISK], DatanodeInfoWithStorage[127.0.0.1:39708,DS-b4cab473-8761-45dd-8a20-d0d7f2e92a4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-728695344-172.17.0.16-1597530194331:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42395,DS-9b72e1cf-9e48-43a0-bc49-08e9a920ed3c,DISK], DatanodeInfoWithStorage[127.0.0.1:41628,DS-eaf2e618-2f93-4525-8535-344b12496715,DISK], DatanodeInfoWithStorage[127.0.0.1:39535,DS-f3b3cc6a-1d68-4a4a-8a10-dca41431315c,DISK], DatanodeInfoWithStorage[127.0.0.1:36105,DS-b975bab5-b7d2-4617-926d-78d69c0ec3d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40642,DS-fa538112-7662-457c-ad65-8d870ee5888c,DISK], DatanodeInfoWithStorage[127.0.0.1:37045,DS-edb07bdb-fc77-4e2f-967b-46089e3aa8d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40329,DS-695d76ee-1bcd-428b-8f61-fd4eb6d85d23,DISK], DatanodeInfoWithStorage[127.0.0.1:39708,DS-b4cab473-8761-45dd-8a20-d0d7f2e92a4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1183642092-172.17.0.16-1597530553491:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39299,DS-9fc088bf-4a09-4cd8-800c-6b55d4912e56,DISK], DatanodeInfoWithStorage[127.0.0.1:43562,DS-a4edc17f-51ac-4df1-8460-40ea1b5c96ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34561,DS-9a23c827-575a-44dd-9162-1956d5a1d9db,DISK], DatanodeInfoWithStorage[127.0.0.1:42196,DS-bfd90304-eb0e-4c24-a5b9-37f21061bee8,DISK], DatanodeInfoWithStorage[127.0.0.1:36384,DS-fccfbf3e-cb7d-4be7-91d6-c70b620bfccc,DISK], DatanodeInfoWithStorage[127.0.0.1:34610,DS-6986df1e-d05c-4507-a16e-432fde0aff83,DISK], DatanodeInfoWithStorage[127.0.0.1:44824,DS-3d15e771-7975-40cb-aba2-9167c12d0015,DISK], DatanodeInfoWithStorage[127.0.0.1:36488,DS-282a7726-0bb3-4d58-bfa2-4cbfcb3ba6b7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1183642092-172.17.0.16-1597530553491:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39299,DS-9fc088bf-4a09-4cd8-800c-6b55d4912e56,DISK], DatanodeInfoWithStorage[127.0.0.1:43562,DS-a4edc17f-51ac-4df1-8460-40ea1b5c96ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34561,DS-9a23c827-575a-44dd-9162-1956d5a1d9db,DISK], DatanodeInfoWithStorage[127.0.0.1:42196,DS-bfd90304-eb0e-4c24-a5b9-37f21061bee8,DISK], DatanodeInfoWithStorage[127.0.0.1:36384,DS-fccfbf3e-cb7d-4be7-91d6-c70b620bfccc,DISK], DatanodeInfoWithStorage[127.0.0.1:34610,DS-6986df1e-d05c-4507-a16e-432fde0aff83,DISK], DatanodeInfoWithStorage[127.0.0.1:44824,DS-3d15e771-7975-40cb-aba2-9167c12d0015,DISK], DatanodeInfoWithStorage[127.0.0.1:36488,DS-282a7726-0bb3-4d58-bfa2-4cbfcb3ba6b7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-133004184-172.17.0.16-1597530781480:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45451,DS-dc9a76b4-26bf-41ab-8ba4-ad907ed2f9db,DISK], DatanodeInfoWithStorage[127.0.0.1:40973,DS-131af04e-0a7a-4ee8-be3a-3a5990624c08,DISK], DatanodeInfoWithStorage[127.0.0.1:41907,DS-8e0dbe83-de65-44e8-9a08-b4127e4d0fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:35321,DS-2c1e6cbe-0b17-48a7-9909-1ce16d655576,DISK], DatanodeInfoWithStorage[127.0.0.1:36501,DS-9158eb19-b340-4801-ac88-19ba2b6fa9ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45854,DS-b231b6aa-3f13-468c-8d9a-9d53672475cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44637,DS-70ea4459-3ebb-42a2-be40-c0b4717bc6a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39927,DS-db5873c2-41b2-43c2-a6d4-4edfaecf1e1d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-133004184-172.17.0.16-1597530781480:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45451,DS-dc9a76b4-26bf-41ab-8ba4-ad907ed2f9db,DISK], DatanodeInfoWithStorage[127.0.0.1:40973,DS-131af04e-0a7a-4ee8-be3a-3a5990624c08,DISK], DatanodeInfoWithStorage[127.0.0.1:41907,DS-8e0dbe83-de65-44e8-9a08-b4127e4d0fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:35321,DS-2c1e6cbe-0b17-48a7-9909-1ce16d655576,DISK], DatanodeInfoWithStorage[127.0.0.1:36501,DS-9158eb19-b340-4801-ac88-19ba2b6fa9ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45854,DS-b231b6aa-3f13-468c-8d9a-9d53672475cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44637,DS-70ea4459-3ebb-42a2-be40-c0b4717bc6a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39927,DS-db5873c2-41b2-43c2-a6d4-4edfaecf1e1d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-606137809-172.17.0.16-1597531056030:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39760,DS-f3237622-fedf-4f62-ada3-2f34de2b2a02,DISK], DatanodeInfoWithStorage[127.0.0.1:33707,DS-6f30316a-bc0b-4c53-b52b-ff1b33a3c8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39996,DS-7937b522-61e9-4ce9-b0ae-e7c9918c73e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38019,DS-07474001-2c9f-4e38-8c38-9c07800dc695,DISK], DatanodeInfoWithStorage[127.0.0.1:33143,DS-f6255274-ad5e-4954-a79c-e67be5fb1e86,DISK], DatanodeInfoWithStorage[127.0.0.1:45464,DS-906db9f5-b065-428e-a2d0-cdce498707e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42293,DS-4449d9e0-7d87-4898-98da-6614b131da2e,DISK], DatanodeInfoWithStorage[127.0.0.1:42521,DS-a40ff8bf-c13e-4faf-9758-edf3b247f079,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-606137809-172.17.0.16-1597531056030:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39760,DS-f3237622-fedf-4f62-ada3-2f34de2b2a02,DISK], DatanodeInfoWithStorage[127.0.0.1:33707,DS-6f30316a-bc0b-4c53-b52b-ff1b33a3c8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39996,DS-7937b522-61e9-4ce9-b0ae-e7c9918c73e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38019,DS-07474001-2c9f-4e38-8c38-9c07800dc695,DISK], DatanodeInfoWithStorage[127.0.0.1:33143,DS-f6255274-ad5e-4954-a79c-e67be5fb1e86,DISK], DatanodeInfoWithStorage[127.0.0.1:45464,DS-906db9f5-b065-428e-a2d0-cdce498707e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42293,DS-4449d9e0-7d87-4898-98da-6614b131da2e,DISK], DatanodeInfoWithStorage[127.0.0.1:42521,DS-a40ff8bf-c13e-4faf-9758-edf3b247f079,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1260600231-172.17.0.16-1597531234527:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44907,DS-5608ea2c-f740-479a-8d5a-36ee7e4d9c65,DISK], DatanodeInfoWithStorage[127.0.0.1:34988,DS-e8c07955-89fa-4c2e-bd65-a3f227d79c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:34721,DS-0bb06cff-9761-4ca5-b4ca-ab53d15ebac5,DISK], DatanodeInfoWithStorage[127.0.0.1:35216,DS-b8f7f071-6a34-41dc-98fa-247fa0c2a86e,DISK], DatanodeInfoWithStorage[127.0.0.1:45056,DS-6f12a7a9-c655-4441-a501-a5a3fe0b1eff,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-64990d14-6e0b-4234-b058-33f5bb8b1442,DISK], DatanodeInfoWithStorage[127.0.0.1:36633,DS-fe9617d8-9266-4ecc-94f9-7a4b32e0a206,DISK], DatanodeInfoWithStorage[127.0.0.1:45265,DS-af2275e7-a25f-4121-827f-6cb3341b5f26,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1260600231-172.17.0.16-1597531234527:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44907,DS-5608ea2c-f740-479a-8d5a-36ee7e4d9c65,DISK], DatanodeInfoWithStorage[127.0.0.1:34988,DS-e8c07955-89fa-4c2e-bd65-a3f227d79c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:34721,DS-0bb06cff-9761-4ca5-b4ca-ab53d15ebac5,DISK], DatanodeInfoWithStorage[127.0.0.1:35216,DS-b8f7f071-6a34-41dc-98fa-247fa0c2a86e,DISK], DatanodeInfoWithStorage[127.0.0.1:45056,DS-6f12a7a9-c655-4441-a501-a5a3fe0b1eff,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-64990d14-6e0b-4234-b058-33f5bb8b1442,DISK], DatanodeInfoWithStorage[127.0.0.1:36633,DS-fe9617d8-9266-4ecc-94f9-7a4b32e0a206,DISK], DatanodeInfoWithStorage[127.0.0.1:45265,DS-af2275e7-a25f-4121-827f-6cb3341b5f26,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1428339722-172.17.0.16-1597531329607:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37580,DS-c54a5e9e-07cb-4b3b-8480-a41ac7942500,DISK], DatanodeInfoWithStorage[127.0.0.1:36606,DS-138ecebb-2215-459b-81c8-286fa774f458,DISK], DatanodeInfoWithStorage[127.0.0.1:36237,DS-398a1461-e659-4f6d-a5b3-fa3c0349baff,DISK], DatanodeInfoWithStorage[127.0.0.1:44286,DS-47d5162c-8694-4058-8558-77b6978ed574,DISK], DatanodeInfoWithStorage[127.0.0.1:34807,DS-3d9c2756-9a2a-4c43-b86e-d48dcc0998bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45513,DS-74185679-91c8-4335-9ee3-22c45980c86b,DISK], DatanodeInfoWithStorage[127.0.0.1:38162,DS-3f6b2532-34f6-4190-9184-5728e35ce568,DISK], DatanodeInfoWithStorage[127.0.0.1:44678,DS-9a6fd97b-03c0-4437-b64d-5c3c09e9020c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1428339722-172.17.0.16-1597531329607:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37580,DS-c54a5e9e-07cb-4b3b-8480-a41ac7942500,DISK], DatanodeInfoWithStorage[127.0.0.1:36606,DS-138ecebb-2215-459b-81c8-286fa774f458,DISK], DatanodeInfoWithStorage[127.0.0.1:36237,DS-398a1461-e659-4f6d-a5b3-fa3c0349baff,DISK], DatanodeInfoWithStorage[127.0.0.1:44286,DS-47d5162c-8694-4058-8558-77b6978ed574,DISK], DatanodeInfoWithStorage[127.0.0.1:34807,DS-3d9c2756-9a2a-4c43-b86e-d48dcc0998bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45513,DS-74185679-91c8-4335-9ee3-22c45980c86b,DISK], DatanodeInfoWithStorage[127.0.0.1:38162,DS-3f6b2532-34f6-4190-9184-5728e35ce568,DISK], DatanodeInfoWithStorage[127.0.0.1:44678,DS-9a6fd97b-03c0-4437-b64d-5c3c09e9020c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2026138178-172.17.0.16-1597531382608:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39356,DS-a3111cdf-302c-45af-b333-026ac7f9308d,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-e54a72f7-298c-4060-9593-4977760cb5c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36343,DS-fb7d3bef-8fd0-469d-b7f1-2e39424afdc0,DISK], DatanodeInfoWithStorage[127.0.0.1:41412,DS-eda0f86f-f86d-4b4e-98e0-6ffb16a25758,DISK], DatanodeInfoWithStorage[127.0.0.1:35945,DS-6b426189-444a-4192-905d-3ab67189ec0c,DISK], DatanodeInfoWithStorage[127.0.0.1:46543,DS-50fc69ed-b32c-4efa-aec8-fad53d2eb287,DISK], DatanodeInfoWithStorage[127.0.0.1:44855,DS-635ea7a7-f6da-4ebf-9794-a387521c5a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42769,DS-d6e1b0fc-5456-4c62-9dea-1aee974e6d36,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2026138178-172.17.0.16-1597531382608:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39356,DS-a3111cdf-302c-45af-b333-026ac7f9308d,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-e54a72f7-298c-4060-9593-4977760cb5c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36343,DS-fb7d3bef-8fd0-469d-b7f1-2e39424afdc0,DISK], DatanodeInfoWithStorage[127.0.0.1:41412,DS-eda0f86f-f86d-4b4e-98e0-6ffb16a25758,DISK], DatanodeInfoWithStorage[127.0.0.1:35945,DS-6b426189-444a-4192-905d-3ab67189ec0c,DISK], DatanodeInfoWithStorage[127.0.0.1:46543,DS-50fc69ed-b32c-4efa-aec8-fad53d2eb287,DISK], DatanodeInfoWithStorage[127.0.0.1:44855,DS-635ea7a7-f6da-4ebf-9794-a387521c5a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42769,DS-d6e1b0fc-5456-4c62-9dea-1aee974e6d36,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1325586437-172.17.0.16-1597531575064:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46627,DS-20b2b35e-8364-4c6d-9641-0301decb7ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:39932,DS-9a94a329-3549-4e23-ac9f-980d47c14345,DISK], DatanodeInfoWithStorage[127.0.0.1:37076,DS-1326df84-0c84-40e6-9457-31eeabe0917b,DISK], DatanodeInfoWithStorage[127.0.0.1:37257,DS-9b3a2a9d-e4aa-4bad-b967-e0275e868c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:42334,DS-9c03431d-1d48-43cc-905d-83b9e1884845,DISK], DatanodeInfoWithStorage[127.0.0.1:39186,DS-1684d291-a099-4c8a-b332-6b5350a10aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:36446,DS-dd31c58d-fddc-4d19-98cd-23e53e263c92,DISK], DatanodeInfoWithStorage[127.0.0.1:36011,DS-5bc8e19d-b9b7-4058-9002-9ee34093a21b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1325586437-172.17.0.16-1597531575064:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46627,DS-20b2b35e-8364-4c6d-9641-0301decb7ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:39932,DS-9a94a329-3549-4e23-ac9f-980d47c14345,DISK], DatanodeInfoWithStorage[127.0.0.1:37076,DS-1326df84-0c84-40e6-9457-31eeabe0917b,DISK], DatanodeInfoWithStorage[127.0.0.1:37257,DS-9b3a2a9d-e4aa-4bad-b967-e0275e868c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:42334,DS-9c03431d-1d48-43cc-905d-83b9e1884845,DISK], DatanodeInfoWithStorage[127.0.0.1:39186,DS-1684d291-a099-4c8a-b332-6b5350a10aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:36446,DS-dd31c58d-fddc-4d19-98cd-23e53e263c92,DISK], DatanodeInfoWithStorage[127.0.0.1:36011,DS-5bc8e19d-b9b7-4058-9002-9ee34093a21b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1372854024-172.17.0.16-1597531897646:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40446,DS-dbfe6a4f-543f-42d5-ad2c-40cdcb312155,DISK], DatanodeInfoWithStorage[127.0.0.1:34002,DS-37f0f1fc-e6ac-4e2b-a7fb-e33b1a915918,DISK], DatanodeInfoWithStorage[127.0.0.1:45237,DS-bf90e159-3d71-45d2-8a47-981059f87d54,DISK], DatanodeInfoWithStorage[127.0.0.1:42494,DS-2182ef4c-8ddf-43b4-a3d5-d5320cc2984e,DISK], DatanodeInfoWithStorage[127.0.0.1:38568,DS-f9e661b8-825a-41ae-9546-7c8cac5cd656,DISK], DatanodeInfoWithStorage[127.0.0.1:46012,DS-16703866-f159-4bc9-834a-8b536fe6da36,DISK], DatanodeInfoWithStorage[127.0.0.1:39730,DS-864a4cf3-a6ca-4b65-a707-a165aa83f889,DISK], DatanodeInfoWithStorage[127.0.0.1:33318,DS-44c865b7-e9c8-46f5-85e9-70db4218e1ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1372854024-172.17.0.16-1597531897646:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40446,DS-dbfe6a4f-543f-42d5-ad2c-40cdcb312155,DISK], DatanodeInfoWithStorage[127.0.0.1:34002,DS-37f0f1fc-e6ac-4e2b-a7fb-e33b1a915918,DISK], DatanodeInfoWithStorage[127.0.0.1:45237,DS-bf90e159-3d71-45d2-8a47-981059f87d54,DISK], DatanodeInfoWithStorage[127.0.0.1:42494,DS-2182ef4c-8ddf-43b4-a3d5-d5320cc2984e,DISK], DatanodeInfoWithStorage[127.0.0.1:38568,DS-f9e661b8-825a-41ae-9546-7c8cac5cd656,DISK], DatanodeInfoWithStorage[127.0.0.1:46012,DS-16703866-f159-4bc9-834a-8b536fe6da36,DISK], DatanodeInfoWithStorage[127.0.0.1:39730,DS-864a4cf3-a6ca-4b65-a707-a165aa83f889,DISK], DatanodeInfoWithStorage[127.0.0.1:33318,DS-44c865b7-e9c8-46f5-85e9-70db4218e1ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2088768603-172.17.0.16-1597532982077:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36994,DS-8f4596f5-d3f8-4843-8cd3-b364e292f173,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-9e1272e9-aa46-4787-ad57-78e846c4672f,DISK], DatanodeInfoWithStorage[127.0.0.1:44867,DS-6347bc95-c7c1-46db-a15d-b354d87f9d27,DISK], DatanodeInfoWithStorage[127.0.0.1:35780,DS-66c08cf5-33d7-4799-b6ce-79231f8bb561,DISK], DatanodeInfoWithStorage[127.0.0.1:33277,DS-3034bdbd-7d1d-401b-bea8-0e9d177a7d35,DISK], DatanodeInfoWithStorage[127.0.0.1:34636,DS-1dbbe549-de2a-4942-95bc-6d7d0a371237,DISK], DatanodeInfoWithStorage[127.0.0.1:46704,DS-d2e3f504-0b77-4ceb-ba6e-455906ecf449,DISK], DatanodeInfoWithStorage[127.0.0.1:35853,DS-83e78992-36f2-467e-9184-53ca4cbea7d1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2088768603-172.17.0.16-1597532982077:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36994,DS-8f4596f5-d3f8-4843-8cd3-b364e292f173,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-9e1272e9-aa46-4787-ad57-78e846c4672f,DISK], DatanodeInfoWithStorage[127.0.0.1:44867,DS-6347bc95-c7c1-46db-a15d-b354d87f9d27,DISK], DatanodeInfoWithStorage[127.0.0.1:35780,DS-66c08cf5-33d7-4799-b6ce-79231f8bb561,DISK], DatanodeInfoWithStorage[127.0.0.1:33277,DS-3034bdbd-7d1d-401b-bea8-0e9d177a7d35,DISK], DatanodeInfoWithStorage[127.0.0.1:34636,DS-1dbbe549-de2a-4942-95bc-6d7d0a371237,DISK], DatanodeInfoWithStorage[127.0.0.1:46704,DS-d2e3f504-0b77-4ceb-ba6e-455906ecf449,DISK], DatanodeInfoWithStorage[127.0.0.1:35853,DS-83e78992-36f2-467e-9184-53ca4cbea7d1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1699042609-172.17.0.16-1597533552348:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33306,DS-3a056857-d792-4c1b-b5e6-7b83fea8455a,DISK], DatanodeInfoWithStorage[127.0.0.1:32821,DS-50c91fa0-252f-446e-88d7-6cc0ad4b5fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:40534,DS-146395fd-17c7-45b9-b7a8-f35a731ebb85,DISK], DatanodeInfoWithStorage[127.0.0.1:45245,DS-9f83ad0c-30e5-4993-a5a5-14113c989c92,DISK], DatanodeInfoWithStorage[127.0.0.1:33199,DS-5cf51333-95aa-4c5b-87c8-b20da64b16f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36286,DS-8d2acfdb-3346-4b58-9f81-fc6620756007,DISK], DatanodeInfoWithStorage[127.0.0.1:44349,DS-9665c3a5-4cec-4f35-a3d3-adaff38d0a05,DISK], DatanodeInfoWithStorage[127.0.0.1:36717,DS-78f40de5-c06d-4dab-92cf-d5bdc6b8bacd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1699042609-172.17.0.16-1597533552348:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33306,DS-3a056857-d792-4c1b-b5e6-7b83fea8455a,DISK], DatanodeInfoWithStorage[127.0.0.1:32821,DS-50c91fa0-252f-446e-88d7-6cc0ad4b5fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:40534,DS-146395fd-17c7-45b9-b7a8-f35a731ebb85,DISK], DatanodeInfoWithStorage[127.0.0.1:45245,DS-9f83ad0c-30e5-4993-a5a5-14113c989c92,DISK], DatanodeInfoWithStorage[127.0.0.1:33199,DS-5cf51333-95aa-4c5b-87c8-b20da64b16f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36286,DS-8d2acfdb-3346-4b58-9f81-fc6620756007,DISK], DatanodeInfoWithStorage[127.0.0.1:44349,DS-9665c3a5-4cec-4f35-a3d3-adaff38d0a05,DISK], DatanodeInfoWithStorage[127.0.0.1:36717,DS-78f40de5-c06d-4dab-92cf-d5bdc6b8bacd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2100000720-172.17.0.16-1597533880716:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44784,DS-895f2550-52f1-4437-9065-d8a19b6160bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46657,DS-4c91f050-c546-4b68-90d8-53e63e08d279,DISK], DatanodeInfoWithStorage[127.0.0.1:39101,DS-1c2ae841-7ca1-45d4-90dc-74b711d12b24,DISK], DatanodeInfoWithStorage[127.0.0.1:46305,DS-0c0a398e-22df-4be2-8240-3c575707b4b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37052,DS-87cd6c08-487a-4026-8b63-c75aa613cf4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38339,DS-53b05df7-85d3-4320-8f33-527c7bd580cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45388,DS-5677d3d1-292e-4d17-b4c5-9774fed1198b,DISK], DatanodeInfoWithStorage[127.0.0.1:42663,DS-9ce335dd-31da-4196-8c34-383394e518bf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2100000720-172.17.0.16-1597533880716:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44784,DS-895f2550-52f1-4437-9065-d8a19b6160bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46657,DS-4c91f050-c546-4b68-90d8-53e63e08d279,DISK], DatanodeInfoWithStorage[127.0.0.1:39101,DS-1c2ae841-7ca1-45d4-90dc-74b711d12b24,DISK], DatanodeInfoWithStorage[127.0.0.1:46305,DS-0c0a398e-22df-4be2-8240-3c575707b4b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37052,DS-87cd6c08-487a-4026-8b63-c75aa613cf4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38339,DS-53b05df7-85d3-4320-8f33-527c7bd580cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45388,DS-5677d3d1-292e-4d17-b4c5-9774fed1198b,DISK], DatanodeInfoWithStorage[127.0.0.1:42663,DS-9ce335dd-31da-4196-8c34-383394e518bf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-422503866-172.17.0.16-1597534122577:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39016,DS-e50864ca-16f9-4190-b316-5bc82205fd2f,DISK], DatanodeInfoWithStorage[127.0.0.1:45517,DS-1765c212-20ff-4607-9d2a-e12f7f10a9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36476,DS-72934d17-32cb-4f14-bd09-5d7d675c056c,DISK], DatanodeInfoWithStorage[127.0.0.1:39261,DS-b2b6ac22-260c-4df2-aac8-303bc2e59fed,DISK], DatanodeInfoWithStorage[127.0.0.1:37646,DS-33cd1b90-0bf2-4053-a6de-afdd88043763,DISK], DatanodeInfoWithStorage[127.0.0.1:33136,DS-5d87ca77-cb06-4655-aa3c-567ba9438b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36219,DS-d4be9a64-2566-43b8-a94b-f8c51df864ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46427,DS-37b685ff-8f8a-4d7e-a3db-da3e29f2725e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-422503866-172.17.0.16-1597534122577:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39016,DS-e50864ca-16f9-4190-b316-5bc82205fd2f,DISK], DatanodeInfoWithStorage[127.0.0.1:45517,DS-1765c212-20ff-4607-9d2a-e12f7f10a9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36476,DS-72934d17-32cb-4f14-bd09-5d7d675c056c,DISK], DatanodeInfoWithStorage[127.0.0.1:39261,DS-b2b6ac22-260c-4df2-aac8-303bc2e59fed,DISK], DatanodeInfoWithStorage[127.0.0.1:37646,DS-33cd1b90-0bf2-4053-a6de-afdd88043763,DISK], DatanodeInfoWithStorage[127.0.0.1:33136,DS-5d87ca77-cb06-4655-aa3c-567ba9438b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36219,DS-d4be9a64-2566-43b8-a94b-f8c51df864ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46427,DS-37b685ff-8f8a-4d7e-a3db-da3e29f2725e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1762891668-172.17.0.16-1597534293864:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32787,DS-9cbc3043-ed3c-44a2-85dd-028790c0d3d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45242,DS-3975e7fd-806e-4574-829e-f151ad05ea10,DISK], DatanodeInfoWithStorage[127.0.0.1:39438,DS-0a1b09cd-8594-4b9a-a9c6-795f53a5677c,DISK], DatanodeInfoWithStorage[127.0.0.1:41293,DS-62fa0aaf-9b51-402e-a84f-b85427e28910,DISK], DatanodeInfoWithStorage[127.0.0.1:45929,DS-9bb95f81-9ab4-42e1-92df-c75ad6823565,DISK], DatanodeInfoWithStorage[127.0.0.1:36778,DS-1d53a4f2-9af9-4824-9835-9c7e5a488e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:32944,DS-79168903-18fc-4f8b-b67b-13bef7f4f5b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45277,DS-65514d11-4925-4986-a455-e8688339e6aa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1762891668-172.17.0.16-1597534293864:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32787,DS-9cbc3043-ed3c-44a2-85dd-028790c0d3d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45242,DS-3975e7fd-806e-4574-829e-f151ad05ea10,DISK], DatanodeInfoWithStorage[127.0.0.1:39438,DS-0a1b09cd-8594-4b9a-a9c6-795f53a5677c,DISK], DatanodeInfoWithStorage[127.0.0.1:41293,DS-62fa0aaf-9b51-402e-a84f-b85427e28910,DISK], DatanodeInfoWithStorage[127.0.0.1:45929,DS-9bb95f81-9ab4-42e1-92df-c75ad6823565,DISK], DatanodeInfoWithStorage[127.0.0.1:36778,DS-1d53a4f2-9af9-4824-9835-9c7e5a488e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:32944,DS-79168903-18fc-4f8b-b67b-13bef7f4f5b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45277,DS-65514d11-4925-4986-a455-e8688339e6aa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1328036134-172.17.0.16-1597534876843:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36774,DS-7ce26e42-3396-475d-bddd-fff1a5d8475f,DISK], DatanodeInfoWithStorage[127.0.0.1:38998,DS-f8b9daa7-5674-4dc8-8f37-370911401280,DISK], DatanodeInfoWithStorage[127.0.0.1:43953,DS-fb84e1c3-5c53-437f-8010-9349339d0bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:36415,DS-471aae6e-0879-4399-8068-860f2692ba1f,DISK], DatanodeInfoWithStorage[127.0.0.1:37235,DS-5c402f6a-fd26-4775-8883-ac8ba2dec9a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36368,DS-55f6ed6e-5a07-4c44-848c-e9e2a084c1ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45721,DS-4185782e-5984-4748-bf31-a818dd8de2bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35398,DS-ccd7bc8b-9a4a-439d-8c16-966cd4b9f4e6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1328036134-172.17.0.16-1597534876843:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36774,DS-7ce26e42-3396-475d-bddd-fff1a5d8475f,DISK], DatanodeInfoWithStorage[127.0.0.1:38998,DS-f8b9daa7-5674-4dc8-8f37-370911401280,DISK], DatanodeInfoWithStorage[127.0.0.1:43953,DS-fb84e1c3-5c53-437f-8010-9349339d0bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:36415,DS-471aae6e-0879-4399-8068-860f2692ba1f,DISK], DatanodeInfoWithStorage[127.0.0.1:37235,DS-5c402f6a-fd26-4775-8883-ac8ba2dec9a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36368,DS-55f6ed6e-5a07-4c44-848c-e9e2a084c1ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45721,DS-4185782e-5984-4748-bf31-a818dd8de2bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35398,DS-ccd7bc8b-9a4a-439d-8c16-966cd4b9f4e6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1752229911-172.17.0.16-1597535274691:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45044,DS-a22240a7-6e1f-40bd-98c8-ceefcf01f97c,DISK], DatanodeInfoWithStorage[127.0.0.1:32980,DS-019f07e2-a90f-4ed2-a943-1e7e4c19e45a,DISK], DatanodeInfoWithStorage[127.0.0.1:37563,DS-647a7156-9038-48d5-b2ef-795edb6335b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34406,DS-cfd01bfe-b5c9-4040-8367-5fa905b9f8ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37223,DS-afdb3bac-0e8d-4a32-ad7f-bea95a616a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:42073,DS-a57ce418-acde-47d3-b45e-9ce84890a215,DISK], DatanodeInfoWithStorage[127.0.0.1:41953,DS-6d87686e-76f7-41bb-94a0-88b0200aa3be,DISK], DatanodeInfoWithStorage[127.0.0.1:41729,DS-631b16f8-2103-4d2e-9580-a15b6903d4ec,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1752229911-172.17.0.16-1597535274691:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45044,DS-a22240a7-6e1f-40bd-98c8-ceefcf01f97c,DISK], DatanodeInfoWithStorage[127.0.0.1:32980,DS-019f07e2-a90f-4ed2-a943-1e7e4c19e45a,DISK], DatanodeInfoWithStorage[127.0.0.1:37563,DS-647a7156-9038-48d5-b2ef-795edb6335b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34406,DS-cfd01bfe-b5c9-4040-8367-5fa905b9f8ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37223,DS-afdb3bac-0e8d-4a32-ad7f-bea95a616a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:42073,DS-a57ce418-acde-47d3-b45e-9ce84890a215,DISK], DatanodeInfoWithStorage[127.0.0.1:41953,DS-6d87686e-76f7-41bb-94a0-88b0200aa3be,DISK], DatanodeInfoWithStorage[127.0.0.1:41729,DS-631b16f8-2103-4d2e-9580-a15b6903d4ec,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2019289609-172.17.0.16-1597535321444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40288,DS-32b8de52-41cf-452b-83e8-76112bc72b21,DISK], DatanodeInfoWithStorage[127.0.0.1:37586,DS-d94081d2-8f8e-4a1b-b075-dfecb8168928,DISK], DatanodeInfoWithStorage[127.0.0.1:32770,DS-519577ba-173b-431e-966e-74453d95a050,DISK], DatanodeInfoWithStorage[127.0.0.1:33074,DS-bde74d99-7133-492f-94e6-f8cf4e9e96df,DISK], DatanodeInfoWithStorage[127.0.0.1:32794,DS-5383cbe4-efe9-42dd-ba95-48274e55a9a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45107,DS-e17fc8eb-b104-44aa-a0b2-ca493923a52e,DISK], DatanodeInfoWithStorage[127.0.0.1:36392,DS-1a7b8489-f52c-451f-bb71-ae27ea3d3655,DISK], DatanodeInfoWithStorage[127.0.0.1:45964,DS-946806b0-fb44-45e2-b395-a4bcff4a34cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2019289609-172.17.0.16-1597535321444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40288,DS-32b8de52-41cf-452b-83e8-76112bc72b21,DISK], DatanodeInfoWithStorage[127.0.0.1:37586,DS-d94081d2-8f8e-4a1b-b075-dfecb8168928,DISK], DatanodeInfoWithStorage[127.0.0.1:32770,DS-519577ba-173b-431e-966e-74453d95a050,DISK], DatanodeInfoWithStorage[127.0.0.1:33074,DS-bde74d99-7133-492f-94e6-f8cf4e9e96df,DISK], DatanodeInfoWithStorage[127.0.0.1:32794,DS-5383cbe4-efe9-42dd-ba95-48274e55a9a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45107,DS-e17fc8eb-b104-44aa-a0b2-ca493923a52e,DISK], DatanodeInfoWithStorage[127.0.0.1:36392,DS-1a7b8489-f52c-451f-bb71-ae27ea3d3655,DISK], DatanodeInfoWithStorage[127.0.0.1:45964,DS-946806b0-fb44-45e2-b395-a4bcff4a34cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-727050639-172.17.0.16-1597535358160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43827,DS-28ef8a1b-a039-40eb-a939-968d680463be,DISK], DatanodeInfoWithStorage[127.0.0.1:34092,DS-39d752e5-9ece-494c-aadf-dcdcf5046c66,DISK], DatanodeInfoWithStorage[127.0.0.1:46630,DS-e33a9fd4-0a73-4bd0-b071-132012bc882c,DISK], DatanodeInfoWithStorage[127.0.0.1:46714,DS-d0211ece-0151-4da1-b8f6-a44852e3df65,DISK], DatanodeInfoWithStorage[127.0.0.1:43417,DS-929d767b-c0ee-4e32-98b1-012f2a6d6611,DISK], DatanodeInfoWithStorage[127.0.0.1:34155,DS-244e3d68-da12-40f1-b54e-d832d38d405a,DISK], DatanodeInfoWithStorage[127.0.0.1:37278,DS-c7a0eea9-f048-4562-a70e-71d64286d83d,DISK], DatanodeInfoWithStorage[127.0.0.1:35363,DS-3c7a5a9d-495d-4168-8d4a-504df5cf27fa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-727050639-172.17.0.16-1597535358160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43827,DS-28ef8a1b-a039-40eb-a939-968d680463be,DISK], DatanodeInfoWithStorage[127.0.0.1:34092,DS-39d752e5-9ece-494c-aadf-dcdcf5046c66,DISK], DatanodeInfoWithStorage[127.0.0.1:46630,DS-e33a9fd4-0a73-4bd0-b071-132012bc882c,DISK], DatanodeInfoWithStorage[127.0.0.1:46714,DS-d0211ece-0151-4da1-b8f6-a44852e3df65,DISK], DatanodeInfoWithStorage[127.0.0.1:43417,DS-929d767b-c0ee-4e32-98b1-012f2a6d6611,DISK], DatanodeInfoWithStorage[127.0.0.1:34155,DS-244e3d68-da12-40f1-b54e-d832d38d405a,DISK], DatanodeInfoWithStorage[127.0.0.1:37278,DS-c7a0eea9-f048-4562-a70e-71d64286d83d,DISK], DatanodeInfoWithStorage[127.0.0.1:35363,DS-3c7a5a9d-495d-4168-8d4a-504df5cf27fa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 14 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: might be true error
Total execution time in seconds : 7072
