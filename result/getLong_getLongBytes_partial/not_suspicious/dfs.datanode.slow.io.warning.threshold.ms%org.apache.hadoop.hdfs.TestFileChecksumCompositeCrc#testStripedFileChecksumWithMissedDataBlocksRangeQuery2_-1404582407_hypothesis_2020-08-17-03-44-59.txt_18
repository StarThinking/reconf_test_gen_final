reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-856171294-172.17.0.16-1597636212995:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34090,DS-c98d1b34-1fe8-40f3-8dbf-8c739f32a73b,DISK], DatanodeInfoWithStorage[127.0.0.1:45134,DS-5ffdacc0-99cc-4e10-a2df-37a9cc277f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43148,DS-d6477849-6fdd-4cd5-bf34-2593c0bc0065,DISK], DatanodeInfoWithStorage[127.0.0.1:44315,DS-26a5b41b-d680-42c2-a2dc-ca386eb857ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37594,DS-ad2d15ff-519b-4679-8b72-f28b7c1dfcf2,DISK], DatanodeInfoWithStorage[127.0.0.1:45756,DS-5b21312c-541a-46e8-a375-9bbaed888333,DISK], DatanodeInfoWithStorage[127.0.0.1:42833,DS-53b4b26f-34b3-48c5-be83-00ce8a6a0edf,DISK], DatanodeInfoWithStorage[127.0.0.1:37647,DS-e7349484-18fd-449e-ab38-873ce6c5783a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-856171294-172.17.0.16-1597636212995:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34090,DS-c98d1b34-1fe8-40f3-8dbf-8c739f32a73b,DISK], DatanodeInfoWithStorage[127.0.0.1:45134,DS-5ffdacc0-99cc-4e10-a2df-37a9cc277f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43148,DS-d6477849-6fdd-4cd5-bf34-2593c0bc0065,DISK], DatanodeInfoWithStorage[127.0.0.1:44315,DS-26a5b41b-d680-42c2-a2dc-ca386eb857ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37594,DS-ad2d15ff-519b-4679-8b72-f28b7c1dfcf2,DISK], DatanodeInfoWithStorage[127.0.0.1:45756,DS-5b21312c-541a-46e8-a375-9bbaed888333,DISK], DatanodeInfoWithStorage[127.0.0.1:42833,DS-53b4b26f-34b3-48c5-be83-00ce8a6a0edf,DISK], DatanodeInfoWithStorage[127.0.0.1:37647,DS-e7349484-18fd-449e-ab38-873ce6c5783a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-167967937-172.17.0.16-1597636300232:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33079,DS-957d5070-7a5d-439b-9151-ac351a8dac33,DISK], DatanodeInfoWithStorage[127.0.0.1:37714,DS-d6741174-c041-4188-a55a-65d9b86a3440,DISK], DatanodeInfoWithStorage[127.0.0.1:33992,DS-ec8189e8-4949-41aa-9bcb-2ee6f91f04e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37348,DS-c9366896-f3a9-466d-906a-35315cbee088,DISK], DatanodeInfoWithStorage[127.0.0.1:34122,DS-fae2c291-0d12-4217-bd89-fbc5f7a98809,DISK], DatanodeInfoWithStorage[127.0.0.1:45623,DS-7dfd1dc3-f666-4db8-92c8-ed129ec46d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38662,DS-9521417d-13a0-4f9b-bb08-49ce2a5bb1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38037,DS-25d56570-35e5-4324-9699-c16bdc0272c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-167967937-172.17.0.16-1597636300232:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33079,DS-957d5070-7a5d-439b-9151-ac351a8dac33,DISK], DatanodeInfoWithStorage[127.0.0.1:37714,DS-d6741174-c041-4188-a55a-65d9b86a3440,DISK], DatanodeInfoWithStorage[127.0.0.1:33992,DS-ec8189e8-4949-41aa-9bcb-2ee6f91f04e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37348,DS-c9366896-f3a9-466d-906a-35315cbee088,DISK], DatanodeInfoWithStorage[127.0.0.1:34122,DS-fae2c291-0d12-4217-bd89-fbc5f7a98809,DISK], DatanodeInfoWithStorage[127.0.0.1:45623,DS-7dfd1dc3-f666-4db8-92c8-ed129ec46d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38662,DS-9521417d-13a0-4f9b-bb08-49ce2a5bb1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38037,DS-25d56570-35e5-4324-9699-c16bdc0272c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-324215285-172.17.0.16-1597636391223:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37929,DS-d0f8de5b-a5aa-4c43-b6b5-e39e0bcd40ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37497,DS-d94c312d-972a-4a22-a52e-8be59e644173,DISK], DatanodeInfoWithStorage[127.0.0.1:40183,DS-313fd9b8-27b6-4d76-9d13-4618fdc4212c,DISK], DatanodeInfoWithStorage[127.0.0.1:45176,DS-5db882cb-46b5-48dc-a5f9-23e50f6529e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38651,DS-f1903208-f588-402e-9329-3a275435b231,DISK], DatanodeInfoWithStorage[127.0.0.1:36530,DS-ac8032fc-7c90-4070-aa49-343d0b1573c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37765,DS-158b9fe3-6f4e-46fe-8fde-dabb973f55f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44133,DS-635fad27-3626-4639-95cc-089068e998f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-324215285-172.17.0.16-1597636391223:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37929,DS-d0f8de5b-a5aa-4c43-b6b5-e39e0bcd40ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37497,DS-d94c312d-972a-4a22-a52e-8be59e644173,DISK], DatanodeInfoWithStorage[127.0.0.1:40183,DS-313fd9b8-27b6-4d76-9d13-4618fdc4212c,DISK], DatanodeInfoWithStorage[127.0.0.1:45176,DS-5db882cb-46b5-48dc-a5f9-23e50f6529e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38651,DS-f1903208-f588-402e-9329-3a275435b231,DISK], DatanodeInfoWithStorage[127.0.0.1:36530,DS-ac8032fc-7c90-4070-aa49-343d0b1573c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37765,DS-158b9fe3-6f4e-46fe-8fde-dabb973f55f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44133,DS-635fad27-3626-4639-95cc-089068e998f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-674987945-172.17.0.16-1597636748237:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44008,DS-a418590b-6b09-4ea1-bb69-b90f3736e7ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44347,DS-99fd1c47-cde6-4407-acdc-99b7e4df9b35,DISK], DatanodeInfoWithStorage[127.0.0.1:38901,DS-434e107c-1ba7-464e-9adc-5461e5369ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:42762,DS-02fd7232-2d62-4801-970a-60f172b069a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37255,DS-0852cc7f-d04c-42c9-9f82-0bc758469fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:32939,DS-09e063b1-2b54-463a-8b7b-534c6feeaa9b,DISK], DatanodeInfoWithStorage[127.0.0.1:38725,DS-3dceca9c-24fc-44f1-a4be-c6e032fb0893,DISK], DatanodeInfoWithStorage[127.0.0.1:39270,DS-7c1abdf1-ef3b-4757-ba37-d58d6efff739,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-674987945-172.17.0.16-1597636748237:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44008,DS-a418590b-6b09-4ea1-bb69-b90f3736e7ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44347,DS-99fd1c47-cde6-4407-acdc-99b7e4df9b35,DISK], DatanodeInfoWithStorage[127.0.0.1:38901,DS-434e107c-1ba7-464e-9adc-5461e5369ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:42762,DS-02fd7232-2d62-4801-970a-60f172b069a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37255,DS-0852cc7f-d04c-42c9-9f82-0bc758469fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:32939,DS-09e063b1-2b54-463a-8b7b-534c6feeaa9b,DISK], DatanodeInfoWithStorage[127.0.0.1:38725,DS-3dceca9c-24fc-44f1-a4be-c6e032fb0893,DISK], DatanodeInfoWithStorage[127.0.0.1:39270,DS-7c1abdf1-ef3b-4757-ba37-d58d6efff739,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1662155811-172.17.0.16-1597636869506:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33101,DS-0ccc7ea2-b3d2-4a16-a40d-f03eadc7b2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33191,DS-9ed9dce0-b0f9-48ff-9d54-07172576911b,DISK], DatanodeInfoWithStorage[127.0.0.1:34269,DS-d93a7de9-3afb-4e35-b952-542ea3af2063,DISK], DatanodeInfoWithStorage[127.0.0.1:45633,DS-00825e58-276c-48e2-aef7-65484e1d7e85,DISK], DatanodeInfoWithStorage[127.0.0.1:41703,DS-86f7ba46-d6f4-49c4-bd19-40d3988d6726,DISK], DatanodeInfoWithStorage[127.0.0.1:42244,DS-97a4d6e0-0342-42ae-ba35-10e4299e751f,DISK], DatanodeInfoWithStorage[127.0.0.1:37590,DS-d1a92cd9-458a-4998-b373-3fb8090854a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36797,DS-103af240-d44d-4e71-83e3-afe541d5c06f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1662155811-172.17.0.16-1597636869506:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33101,DS-0ccc7ea2-b3d2-4a16-a40d-f03eadc7b2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33191,DS-9ed9dce0-b0f9-48ff-9d54-07172576911b,DISK], DatanodeInfoWithStorage[127.0.0.1:34269,DS-d93a7de9-3afb-4e35-b952-542ea3af2063,DISK], DatanodeInfoWithStorage[127.0.0.1:45633,DS-00825e58-276c-48e2-aef7-65484e1d7e85,DISK], DatanodeInfoWithStorage[127.0.0.1:41703,DS-86f7ba46-d6f4-49c4-bd19-40d3988d6726,DISK], DatanodeInfoWithStorage[127.0.0.1:42244,DS-97a4d6e0-0342-42ae-ba35-10e4299e751f,DISK], DatanodeInfoWithStorage[127.0.0.1:37590,DS-d1a92cd9-458a-4998-b373-3fb8090854a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36797,DS-103af240-d44d-4e71-83e3-afe541d5c06f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2113031135-172.17.0.16-1597637089563:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33956,DS-9e18047c-723d-484d-a70f-5c221fa61910,DISK], DatanodeInfoWithStorage[127.0.0.1:37544,DS-1821e869-f95b-4783-8c9b-753a4c23875d,DISK], DatanodeInfoWithStorage[127.0.0.1:42384,DS-50711533-bcd5-4f46-b36a-af595cc45a15,DISK], DatanodeInfoWithStorage[127.0.0.1:33778,DS-6b7cd32d-591c-4c2b-b5eb-dd6abcd5fad1,DISK], DatanodeInfoWithStorage[127.0.0.1:45540,DS-e73bfaaf-f99e-4e4f-a624-50b67e0d3cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:41058,DS-c93e219a-cfa5-4efe-8dc0-926e29b1cab3,DISK], DatanodeInfoWithStorage[127.0.0.1:38742,DS-9ce2f51b-8e25-40c4-8b35-3d1882a6bbc6,DISK], DatanodeInfoWithStorage[127.0.0.1:41835,DS-260661c3-d631-4da1-a161-2983cac50fe1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2113031135-172.17.0.16-1597637089563:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33956,DS-9e18047c-723d-484d-a70f-5c221fa61910,DISK], DatanodeInfoWithStorage[127.0.0.1:37544,DS-1821e869-f95b-4783-8c9b-753a4c23875d,DISK], DatanodeInfoWithStorage[127.0.0.1:42384,DS-50711533-bcd5-4f46-b36a-af595cc45a15,DISK], DatanodeInfoWithStorage[127.0.0.1:33778,DS-6b7cd32d-591c-4c2b-b5eb-dd6abcd5fad1,DISK], DatanodeInfoWithStorage[127.0.0.1:45540,DS-e73bfaaf-f99e-4e4f-a624-50b67e0d3cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:41058,DS-c93e219a-cfa5-4efe-8dc0-926e29b1cab3,DISK], DatanodeInfoWithStorage[127.0.0.1:38742,DS-9ce2f51b-8e25-40c4-8b35-3d1882a6bbc6,DISK], DatanodeInfoWithStorage[127.0.0.1:41835,DS-260661c3-d631-4da1-a161-2983cac50fe1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1198103625-172.17.0.16-1597637190061:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43878,DS-11f2d138-83d2-4faf-8891-c5aaaa7a9da1,DISK], DatanodeInfoWithStorage[127.0.0.1:37620,DS-b632407b-7017-4f0e-8b8b-9bec6757942f,DISK], DatanodeInfoWithStorage[127.0.0.1:34920,DS-6f7ed8df-014c-475e-95d3-9e8668328ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:37160,DS-0da43231-284f-4a30-b263-0f17fb32a08c,DISK], DatanodeInfoWithStorage[127.0.0.1:37906,DS-d2d32ad0-f472-46e1-b3e5-c2bb59a647fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42002,DS-f1b39db7-1414-485d-a6c5-e64d243b66fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36821,DS-6c1bb9ca-c9ee-4cbb-a459-b2125ef00596,DISK], DatanodeInfoWithStorage[127.0.0.1:46486,DS-cb4e7ccc-ab57-4f88-abfd-5a619c0bf18e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1198103625-172.17.0.16-1597637190061:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43878,DS-11f2d138-83d2-4faf-8891-c5aaaa7a9da1,DISK], DatanodeInfoWithStorage[127.0.0.1:37620,DS-b632407b-7017-4f0e-8b8b-9bec6757942f,DISK], DatanodeInfoWithStorage[127.0.0.1:34920,DS-6f7ed8df-014c-475e-95d3-9e8668328ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:37160,DS-0da43231-284f-4a30-b263-0f17fb32a08c,DISK], DatanodeInfoWithStorage[127.0.0.1:37906,DS-d2d32ad0-f472-46e1-b3e5-c2bb59a647fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42002,DS-f1b39db7-1414-485d-a6c5-e64d243b66fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36821,DS-6c1bb9ca-c9ee-4cbb-a459-b2125ef00596,DISK], DatanodeInfoWithStorage[127.0.0.1:46486,DS-cb4e7ccc-ab57-4f88-abfd-5a619c0bf18e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1568819182-172.17.0.16-1597637876994:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45066,DS-c1dc2174-af4e-466c-97cc-4aa6ec3286f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44470,DS-15819a80-4ab8-4c48-b320-fa284a3ecbce,DISK], DatanodeInfoWithStorage[127.0.0.1:41991,DS-8a0ebe42-8653-48cb-953e-0f274eb190e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41793,DS-8b6a66d1-edda-409d-931e-1cd7cf1ae21b,DISK], DatanodeInfoWithStorage[127.0.0.1:38199,DS-6dfe94b0-ac0b-4858-8284-f2116c665cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:44725,DS-5d5c135a-24f0-40dd-a534-03e6979d3366,DISK], DatanodeInfoWithStorage[127.0.0.1:34655,DS-7fc7b59b-da8c-400e-90f2-975d8b20f55f,DISK], DatanodeInfoWithStorage[127.0.0.1:45784,DS-025746d6-205a-4f16-b1e8-bd057950d581,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1568819182-172.17.0.16-1597637876994:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45066,DS-c1dc2174-af4e-466c-97cc-4aa6ec3286f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44470,DS-15819a80-4ab8-4c48-b320-fa284a3ecbce,DISK], DatanodeInfoWithStorage[127.0.0.1:41991,DS-8a0ebe42-8653-48cb-953e-0f274eb190e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41793,DS-8b6a66d1-edda-409d-931e-1cd7cf1ae21b,DISK], DatanodeInfoWithStorage[127.0.0.1:38199,DS-6dfe94b0-ac0b-4858-8284-f2116c665cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:44725,DS-5d5c135a-24f0-40dd-a534-03e6979d3366,DISK], DatanodeInfoWithStorage[127.0.0.1:34655,DS-7fc7b59b-da8c-400e-90f2-975d8b20f55f,DISK], DatanodeInfoWithStorage[127.0.0.1:45784,DS-025746d6-205a-4f16-b1e8-bd057950d581,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2012424746-172.17.0.16-1597637925429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40881,DS-90e90eaa-8c61-4b12-8a5b-18f428ccf732,DISK], DatanodeInfoWithStorage[127.0.0.1:34923,DS-6cc9f6a2-cc26-4b80-8c26-8f6c87735bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:44221,DS-eb95dd44-8e9a-484d-8c15-b4f40f812327,DISK], DatanodeInfoWithStorage[127.0.0.1:36049,DS-6d807759-7557-4e74-8963-2dbde8f6be87,DISK], DatanodeInfoWithStorage[127.0.0.1:46552,DS-27eada25-628a-4292-af64-7097a7637e58,DISK], DatanodeInfoWithStorage[127.0.0.1:45481,DS-9fdce75c-2879-4894-aefd-c36934d46742,DISK], DatanodeInfoWithStorage[127.0.0.1:45175,DS-7dc926c9-4d9d-4770-b135-a656494d5e09,DISK], DatanodeInfoWithStorage[127.0.0.1:39563,DS-0bb44fbf-ca73-45c4-a8e8-c7d4ab4f8951,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2012424746-172.17.0.16-1597637925429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40881,DS-90e90eaa-8c61-4b12-8a5b-18f428ccf732,DISK], DatanodeInfoWithStorage[127.0.0.1:34923,DS-6cc9f6a2-cc26-4b80-8c26-8f6c87735bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:44221,DS-eb95dd44-8e9a-484d-8c15-b4f40f812327,DISK], DatanodeInfoWithStorage[127.0.0.1:36049,DS-6d807759-7557-4e74-8963-2dbde8f6be87,DISK], DatanodeInfoWithStorage[127.0.0.1:46552,DS-27eada25-628a-4292-af64-7097a7637e58,DISK], DatanodeInfoWithStorage[127.0.0.1:45481,DS-9fdce75c-2879-4894-aefd-c36934d46742,DISK], DatanodeInfoWithStorage[127.0.0.1:45175,DS-7dc926c9-4d9d-4770-b135-a656494d5e09,DISK], DatanodeInfoWithStorage[127.0.0.1:39563,DS-0bb44fbf-ca73-45c4-a8e8-c7d4ab4f8951,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1454237611-172.17.0.16-1597638146653:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41413,DS-a5886325-17cb-42c3-b887-6cc129754cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:40162,DS-f9c079eb-6c0b-4bd0-84b0-a8165096a5e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33291,DS-d8028bd2-0f87-45a6-89c0-e71bc8e31b36,DISK], DatanodeInfoWithStorage[127.0.0.1:41676,DS-001ca9fb-5a40-4336-864d-ab9e8b061bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:44456,DS-f660fc6d-4bd7-4d59-951a-c8b1363680ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42638,DS-3725478f-2cb5-4681-963c-33e26319c10e,DISK], DatanodeInfoWithStorage[127.0.0.1:44689,DS-09993863-0187-4083-a4d0-1ce5f4a934ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33764,DS-6978527f-808e-43a7-b9d0-f5eaee5106fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1454237611-172.17.0.16-1597638146653:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41413,DS-a5886325-17cb-42c3-b887-6cc129754cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:40162,DS-f9c079eb-6c0b-4bd0-84b0-a8165096a5e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33291,DS-d8028bd2-0f87-45a6-89c0-e71bc8e31b36,DISK], DatanodeInfoWithStorage[127.0.0.1:41676,DS-001ca9fb-5a40-4336-864d-ab9e8b061bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:44456,DS-f660fc6d-4bd7-4d59-951a-c8b1363680ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42638,DS-3725478f-2cb5-4681-963c-33e26319c10e,DISK], DatanodeInfoWithStorage[127.0.0.1:44689,DS-09993863-0187-4083-a4d0-1ce5f4a934ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33764,DS-6978527f-808e-43a7-b9d0-f5eaee5106fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1894631504-172.17.0.16-1597639359014:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46122,DS-21095c5d-fb74-4af9-b23d-8b248cc1066a,DISK], DatanodeInfoWithStorage[127.0.0.1:43539,DS-007f4b1b-17ff-47e7-97c8-a63b1688d079,DISK], DatanodeInfoWithStorage[127.0.0.1:41771,DS-067c06a5-4827-4b6b-832e-ea321972db7e,DISK], DatanodeInfoWithStorage[127.0.0.1:38251,DS-3736d5a4-3a4d-44dc-9a4a-ed011d96091d,DISK], DatanodeInfoWithStorage[127.0.0.1:41700,DS-fdd78f21-c994-4e53-889c-526496990b23,DISK], DatanodeInfoWithStorage[127.0.0.1:39376,DS-e3c67d5b-701b-45fc-a63f-a911ccc28493,DISK], DatanodeInfoWithStorage[127.0.0.1:38609,DS-b259789e-c5a0-470e-9e87-dce37aeeb1a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36344,DS-8c41b055-c8fa-40a5-8d50-28a45c38249c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1894631504-172.17.0.16-1597639359014:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46122,DS-21095c5d-fb74-4af9-b23d-8b248cc1066a,DISK], DatanodeInfoWithStorage[127.0.0.1:43539,DS-007f4b1b-17ff-47e7-97c8-a63b1688d079,DISK], DatanodeInfoWithStorage[127.0.0.1:41771,DS-067c06a5-4827-4b6b-832e-ea321972db7e,DISK], DatanodeInfoWithStorage[127.0.0.1:38251,DS-3736d5a4-3a4d-44dc-9a4a-ed011d96091d,DISK], DatanodeInfoWithStorage[127.0.0.1:41700,DS-fdd78f21-c994-4e53-889c-526496990b23,DISK], DatanodeInfoWithStorage[127.0.0.1:39376,DS-e3c67d5b-701b-45fc-a63f-a911ccc28493,DISK], DatanodeInfoWithStorage[127.0.0.1:38609,DS-b259789e-c5a0-470e-9e87-dce37aeeb1a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36344,DS-8c41b055-c8fa-40a5-8d50-28a45c38249c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-718106495-172.17.0.16-1597639474617:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46785,DS-aaa93876-0c31-4aac-99b3-22b295a2f6b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44710,DS-bc01662b-fcb4-4068-b046-679652f74661,DISK], DatanodeInfoWithStorage[127.0.0.1:39519,DS-52e6ae0c-3f31-45b4-8de5-7ff05ac0c4c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45373,DS-1519ff4c-860a-4e7a-9c33-b2e013dc97ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35173,DS-95d62b14-5deb-4d12-962f-e3453fd0719c,DISK], DatanodeInfoWithStorage[127.0.0.1:32986,DS-38bb74cf-255c-4819-8f5b-387d1b029b03,DISK], DatanodeInfoWithStorage[127.0.0.1:35822,DS-2c03970f-53ce-4c42-ad73-50e48fc7989b,DISK], DatanodeInfoWithStorage[127.0.0.1:46419,DS-6f3835ae-b89a-43b3-bcbc-af17438c5cb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-718106495-172.17.0.16-1597639474617:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46785,DS-aaa93876-0c31-4aac-99b3-22b295a2f6b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44710,DS-bc01662b-fcb4-4068-b046-679652f74661,DISK], DatanodeInfoWithStorage[127.0.0.1:39519,DS-52e6ae0c-3f31-45b4-8de5-7ff05ac0c4c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45373,DS-1519ff4c-860a-4e7a-9c33-b2e013dc97ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35173,DS-95d62b14-5deb-4d12-962f-e3453fd0719c,DISK], DatanodeInfoWithStorage[127.0.0.1:32986,DS-38bb74cf-255c-4819-8f5b-387d1b029b03,DISK], DatanodeInfoWithStorage[127.0.0.1:35822,DS-2c03970f-53ce-4c42-ad73-50e48fc7989b,DISK], DatanodeInfoWithStorage[127.0.0.1:46419,DS-6f3835ae-b89a-43b3-bcbc-af17438c5cb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-805175202-172.17.0.16-1597639838400:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33709,DS-e9c3d634-48de-4690-8df6-eab6bebf4ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:37352,DS-a6cf6ed3-fb07-4c9f-b1ab-48f93f30689b,DISK], DatanodeInfoWithStorage[127.0.0.1:40067,DS-0217a2f1-f5ee-47d1-b8a1-b7abcbb1747e,DISK], DatanodeInfoWithStorage[127.0.0.1:32803,DS-937d3e95-e262-4413-8129-fc6ae38b3427,DISK], DatanodeInfoWithStorage[127.0.0.1:34410,DS-a0c6ff8a-8aa9-4145-b99e-52f5538c484d,DISK], DatanodeInfoWithStorage[127.0.0.1:39969,DS-a2d6c1c5-2182-429d-bc6a-6d3731bc3613,DISK], DatanodeInfoWithStorage[127.0.0.1:45294,DS-44583a08-5748-47f2-8ccd-322e1d5064e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38225,DS-0ed42e0c-446b-4e93-9ec0-8e3df19c0b4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-805175202-172.17.0.16-1597639838400:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33709,DS-e9c3d634-48de-4690-8df6-eab6bebf4ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:37352,DS-a6cf6ed3-fb07-4c9f-b1ab-48f93f30689b,DISK], DatanodeInfoWithStorage[127.0.0.1:40067,DS-0217a2f1-f5ee-47d1-b8a1-b7abcbb1747e,DISK], DatanodeInfoWithStorage[127.0.0.1:32803,DS-937d3e95-e262-4413-8129-fc6ae38b3427,DISK], DatanodeInfoWithStorage[127.0.0.1:34410,DS-a0c6ff8a-8aa9-4145-b99e-52f5538c484d,DISK], DatanodeInfoWithStorage[127.0.0.1:39969,DS-a2d6c1c5-2182-429d-bc6a-6d3731bc3613,DISK], DatanodeInfoWithStorage[127.0.0.1:45294,DS-44583a08-5748-47f2-8ccd-322e1d5064e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38225,DS-0ed42e0c-446b-4e93-9ec0-8e3df19c0b4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1636410147-172.17.0.16-1597640117051:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32832,DS-764579d7-e45e-4687-a927-237bd6452677,DISK], DatanodeInfoWithStorage[127.0.0.1:37838,DS-3699534a-4b9c-4535-a174-fea2dfc53fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:43748,DS-8c579994-bc5f-489a-b690-54cc9f5788eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40384,DS-515ffa09-5dbe-4eea-bfe2-6d22f74e99ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44530,DS-a7b2443f-8706-4195-9144-f8ee312886eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42318,DS-b3510525-1f93-4dd2-a16b-187b356f7c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44830,DS-1b1fac8a-d7b2-4af1-a5ea-66e953d5afbe,DISK], DatanodeInfoWithStorage[127.0.0.1:43922,DS-ad20c3b5-a9ec-450a-b496-3db9bfc0d65a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1636410147-172.17.0.16-1597640117051:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32832,DS-764579d7-e45e-4687-a927-237bd6452677,DISK], DatanodeInfoWithStorage[127.0.0.1:37838,DS-3699534a-4b9c-4535-a174-fea2dfc53fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:43748,DS-8c579994-bc5f-489a-b690-54cc9f5788eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40384,DS-515ffa09-5dbe-4eea-bfe2-6d22f74e99ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44530,DS-a7b2443f-8706-4195-9144-f8ee312886eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42318,DS-b3510525-1f93-4dd2-a16b-187b356f7c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44830,DS-1b1fac8a-d7b2-4af1-a5ea-66e953d5afbe,DISK], DatanodeInfoWithStorage[127.0.0.1:43922,DS-ad20c3b5-a9ec-450a-b496-3db9bfc0d65a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-534527439-172.17.0.16-1597640508092:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44268,DS-1bead20e-f9f7-4c82-8475-f94f1e30b293,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-3d0315fa-fd83-49f0-bedc-5e18f3e24bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:37745,DS-b97f5d36-a7eb-4bc7-bbd8-90c0b36e0726,DISK], DatanodeInfoWithStorage[127.0.0.1:39517,DS-a4c1a135-fedb-4b88-80ff-cc6e395c270d,DISK], DatanodeInfoWithStorage[127.0.0.1:33773,DS-53bd65b0-8382-48d5-afef-028415082855,DISK], DatanodeInfoWithStorage[127.0.0.1:43038,DS-81eace00-c8eb-46a4-8127-16279d452b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:46635,DS-7dba11ed-27ac-4bd3-ab77-bca6338894eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33993,DS-0b37e7ad-a462-4d8c-a430-77d1b37a9269,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-534527439-172.17.0.16-1597640508092:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44268,DS-1bead20e-f9f7-4c82-8475-f94f1e30b293,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-3d0315fa-fd83-49f0-bedc-5e18f3e24bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:37745,DS-b97f5d36-a7eb-4bc7-bbd8-90c0b36e0726,DISK], DatanodeInfoWithStorage[127.0.0.1:39517,DS-a4c1a135-fedb-4b88-80ff-cc6e395c270d,DISK], DatanodeInfoWithStorage[127.0.0.1:33773,DS-53bd65b0-8382-48d5-afef-028415082855,DISK], DatanodeInfoWithStorage[127.0.0.1:43038,DS-81eace00-c8eb-46a4-8127-16279d452b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:46635,DS-7dba11ed-27ac-4bd3-ab77-bca6338894eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33993,DS-0b37e7ad-a462-4d8c-a430-77d1b37a9269,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1761752237-172.17.0.16-1597640727089:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36431,DS-49f98de9-5fa9-41c8-9ee7-7eae04aa4bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:38586,DS-97880c90-0ef9-43e0-b6fa-26f128a8f09f,DISK], DatanodeInfoWithStorage[127.0.0.1:45857,DS-10dbb99d-19d0-4777-a491-335e173c5177,DISK], DatanodeInfoWithStorage[127.0.0.1:34949,DS-54a51c27-9613-4d0e-9395-8357704e2e75,DISK], DatanodeInfoWithStorage[127.0.0.1:43556,DS-0fd2bc9b-d947-4625-a2a3-f11f66c9ec27,DISK], DatanodeInfoWithStorage[127.0.0.1:34229,DS-de51cbe6-f4b6-44ac-a111-57f655340d44,DISK], DatanodeInfoWithStorage[127.0.0.1:34899,DS-39116a9d-5a5a-4bbd-a1fa-4ef7d11150c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37189,DS-7db97781-12de-48d9-9d26-76353c082148,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1761752237-172.17.0.16-1597640727089:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36431,DS-49f98de9-5fa9-41c8-9ee7-7eae04aa4bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:38586,DS-97880c90-0ef9-43e0-b6fa-26f128a8f09f,DISK], DatanodeInfoWithStorage[127.0.0.1:45857,DS-10dbb99d-19d0-4777-a491-335e173c5177,DISK], DatanodeInfoWithStorage[127.0.0.1:34949,DS-54a51c27-9613-4d0e-9395-8357704e2e75,DISK], DatanodeInfoWithStorage[127.0.0.1:43556,DS-0fd2bc9b-d947-4625-a2a3-f11f66c9ec27,DISK], DatanodeInfoWithStorage[127.0.0.1:34229,DS-de51cbe6-f4b6-44ac-a111-57f655340d44,DISK], DatanodeInfoWithStorage[127.0.0.1:34899,DS-39116a9d-5a5a-4bbd-a1fa-4ef7d11150c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37189,DS-7db97781-12de-48d9-9d26-76353c082148,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-217379876-172.17.0.16-1597641274699:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33193,DS-d33dfa24-1311-47fe-962d-a3fd1729b708,DISK], DatanodeInfoWithStorage[127.0.0.1:33958,DS-15bfde2b-f664-4a1b-b82e-efc2aed95b50,DISK], DatanodeInfoWithStorage[127.0.0.1:35509,DS-37a5c13b-83ea-4a77-b209-98722fb5d1c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44674,DS-1f226963-f024-41c2-ab2b-b9a73a115ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:35894,DS-dafe6e3f-5143-4be9-a3be-e6c0e8c90100,DISK], DatanodeInfoWithStorage[127.0.0.1:42683,DS-2cc82555-d729-483c-86e7-a5e79d10b86d,DISK], DatanodeInfoWithStorage[127.0.0.1:37296,DS-b0f6f224-935f-484e-9277-5f62b48b61dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41436,DS-c96856a5-2869-428c-ba3e-2941b3658fea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-217379876-172.17.0.16-1597641274699:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33193,DS-d33dfa24-1311-47fe-962d-a3fd1729b708,DISK], DatanodeInfoWithStorage[127.0.0.1:33958,DS-15bfde2b-f664-4a1b-b82e-efc2aed95b50,DISK], DatanodeInfoWithStorage[127.0.0.1:35509,DS-37a5c13b-83ea-4a77-b209-98722fb5d1c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44674,DS-1f226963-f024-41c2-ab2b-b9a73a115ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:35894,DS-dafe6e3f-5143-4be9-a3be-e6c0e8c90100,DISK], DatanodeInfoWithStorage[127.0.0.1:42683,DS-2cc82555-d729-483c-86e7-a5e79d10b86d,DISK], DatanodeInfoWithStorage[127.0.0.1:37296,DS-b0f6f224-935f-484e-9277-5f62b48b61dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41436,DS-c96856a5-2869-428c-ba3e-2941b3658fea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1555063541-172.17.0.16-1597641310077:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40103,DS-cee767d8-77b1-4fe3-832a-f9373a2e3923,DISK], DatanodeInfoWithStorage[127.0.0.1:42638,DS-c22e7f03-d4e0-4f2b-b53a-16ea5bc13968,DISK], DatanodeInfoWithStorage[127.0.0.1:39698,DS-20fb1c46-6792-493d-95c0-2570bf9f1540,DISK], DatanodeInfoWithStorage[127.0.0.1:38184,DS-6fe6156c-2fae-41f8-914a-39cc037ad483,DISK], DatanodeInfoWithStorage[127.0.0.1:42038,DS-fc4221fc-9ff3-4f44-a5f3-dfc8678ef609,DISK], DatanodeInfoWithStorage[127.0.0.1:41111,DS-d454b9de-0a4f-4b55-9edc-cc994f67ba47,DISK], DatanodeInfoWithStorage[127.0.0.1:38574,DS-5cdb027f-0408-430d-a03e-72b4f27ee942,DISK], DatanodeInfoWithStorage[127.0.0.1:36252,DS-0e8a5a70-733d-4db3-92fd-a1fcf0500c3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1555063541-172.17.0.16-1597641310077:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40103,DS-cee767d8-77b1-4fe3-832a-f9373a2e3923,DISK], DatanodeInfoWithStorage[127.0.0.1:42638,DS-c22e7f03-d4e0-4f2b-b53a-16ea5bc13968,DISK], DatanodeInfoWithStorage[127.0.0.1:39698,DS-20fb1c46-6792-493d-95c0-2570bf9f1540,DISK], DatanodeInfoWithStorage[127.0.0.1:38184,DS-6fe6156c-2fae-41f8-914a-39cc037ad483,DISK], DatanodeInfoWithStorage[127.0.0.1:42038,DS-fc4221fc-9ff3-4f44-a5f3-dfc8678ef609,DISK], DatanodeInfoWithStorage[127.0.0.1:41111,DS-d454b9de-0a4f-4b55-9edc-cc994f67ba47,DISK], DatanodeInfoWithStorage[127.0.0.1:38574,DS-5cdb027f-0408-430d-a03e-72b4f27ee942,DISK], DatanodeInfoWithStorage[127.0.0.1:36252,DS-0e8a5a70-733d-4db3-92fd-a1fcf0500c3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-670464759-172.17.0.16-1597642544183:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40054,DS-6d6db61b-0bbd-4af6-948a-645c535a8461,DISK], DatanodeInfoWithStorage[127.0.0.1:35608,DS-560bfa41-8d10-4dc3-bd25-01d78e64295d,DISK], DatanodeInfoWithStorage[127.0.0.1:43988,DS-60c2ea34-7870-4db0-b45d-a281b519ed0f,DISK], DatanodeInfoWithStorage[127.0.0.1:46067,DS-82f4bf79-5976-4ec1-bdd1-093ee485991a,DISK], DatanodeInfoWithStorage[127.0.0.1:35094,DS-725a741f-8fc1-4166-a342-36215aab6ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:34840,DS-70cfa4ce-8c1d-4fe6-868e-debc494e4f94,DISK], DatanodeInfoWithStorage[127.0.0.1:42460,DS-92f94c9b-ee88-425e-a783-e4a51c68483e,DISK], DatanodeInfoWithStorage[127.0.0.1:44992,DS-81f75d6d-e508-491a-8155-148e84bec045,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-670464759-172.17.0.16-1597642544183:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40054,DS-6d6db61b-0bbd-4af6-948a-645c535a8461,DISK], DatanodeInfoWithStorage[127.0.0.1:35608,DS-560bfa41-8d10-4dc3-bd25-01d78e64295d,DISK], DatanodeInfoWithStorage[127.0.0.1:43988,DS-60c2ea34-7870-4db0-b45d-a281b519ed0f,DISK], DatanodeInfoWithStorage[127.0.0.1:46067,DS-82f4bf79-5976-4ec1-bdd1-093ee485991a,DISK], DatanodeInfoWithStorage[127.0.0.1:35094,DS-725a741f-8fc1-4166-a342-36215aab6ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:34840,DS-70cfa4ce-8c1d-4fe6-868e-debc494e4f94,DISK], DatanodeInfoWithStorage[127.0.0.1:42460,DS-92f94c9b-ee88-425e-a783-e4a51c68483e,DISK], DatanodeInfoWithStorage[127.0.0.1:44992,DS-81f75d6d-e508-491a-8155-148e84bec045,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 6818
