reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-699480101-172.17.0.11-1597758743552:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37532,DS-a8c4585a-8478-45a6-9efe-3a3c6304e3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40519,DS-cfa81cdc-676c-43f2-b1d2-83cd7ddf05c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45568,DS-21abe658-9393-4ea8-ac2e-b9926431e9a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45021,DS-dc06603e-cdde-4043-968f-71cdd75b2c54,DISK], DatanodeInfoWithStorage[127.0.0.1:37174,DS-8c002912-78c6-4918-9a1c-3f6e364df3cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42841,DS-1ed9cdc4-7d38-4f54-8f91-c361d32622e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-404a4ccf-4592-4f20-af04-6d2c612d76f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37375,DS-7a5f978b-d834-4567-b887-586ad115db21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-699480101-172.17.0.11-1597758743552:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37532,DS-a8c4585a-8478-45a6-9efe-3a3c6304e3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40519,DS-cfa81cdc-676c-43f2-b1d2-83cd7ddf05c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45568,DS-21abe658-9393-4ea8-ac2e-b9926431e9a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45021,DS-dc06603e-cdde-4043-968f-71cdd75b2c54,DISK], DatanodeInfoWithStorage[127.0.0.1:37174,DS-8c002912-78c6-4918-9a1c-3f6e364df3cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42841,DS-1ed9cdc4-7d38-4f54-8f91-c361d32622e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-404a4ccf-4592-4f20-af04-6d2c612d76f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37375,DS-7a5f978b-d834-4567-b887-586ad115db21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-479781862-172.17.0.11-1597758777187:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42322,DS-7993f8fe-6d2f-4ce5-ae09-1a41a5d32651,DISK], DatanodeInfoWithStorage[127.0.0.1:36487,DS-3021407c-9a3c-463e-8e6f-badc13d41cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:34740,DS-a5792e45-0c96-4ef1-9427-dd38110a04dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38762,DS-c4ab33e4-ac16-46f9-aafe-4c2a5b54198e,DISK], DatanodeInfoWithStorage[127.0.0.1:38665,DS-01eaffcf-f1a9-41a9-9955-82da386235e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35187,DS-418fa881-1cf1-4d8d-b30e-a6c124600383,DISK], DatanodeInfoWithStorage[127.0.0.1:38380,DS-4a452f4f-a048-4497-9193-f9880c88ac13,DISK], DatanodeInfoWithStorage[127.0.0.1:35042,DS-081ad402-ba94-4ba8-8854-b177e9d30956,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-479781862-172.17.0.11-1597758777187:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42322,DS-7993f8fe-6d2f-4ce5-ae09-1a41a5d32651,DISK], DatanodeInfoWithStorage[127.0.0.1:36487,DS-3021407c-9a3c-463e-8e6f-badc13d41cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:34740,DS-a5792e45-0c96-4ef1-9427-dd38110a04dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38762,DS-c4ab33e4-ac16-46f9-aafe-4c2a5b54198e,DISK], DatanodeInfoWithStorage[127.0.0.1:38665,DS-01eaffcf-f1a9-41a9-9955-82da386235e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35187,DS-418fa881-1cf1-4d8d-b30e-a6c124600383,DISK], DatanodeInfoWithStorage[127.0.0.1:38380,DS-4a452f4f-a048-4497-9193-f9880c88ac13,DISK], DatanodeInfoWithStorage[127.0.0.1:35042,DS-081ad402-ba94-4ba8-8854-b177e9d30956,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-739034298-172.17.0.11-1597758942558:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33496,DS-dcb99c09-93f0-485b-a6c9-082363cfc9cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38158,DS-15f40ba9-5d5c-4587-a412-24581a6a9199,DISK], DatanodeInfoWithStorage[127.0.0.1:33856,DS-bc837189-6b75-408c-9627-c78f35c83bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:34670,DS-e971164f-16d3-415e-8a8a-cf723b7a4c53,DISK], DatanodeInfoWithStorage[127.0.0.1:45958,DS-01cea321-c247-4d46-8774-fa00baeb0c83,DISK], DatanodeInfoWithStorage[127.0.0.1:42496,DS-9032af16-764d-4cbd-80e7-d20c56e51d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:36520,DS-b4c732da-4b7f-4be3-94ff-ca10382bc4ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34239,DS-eefab1b1-ca1d-4bbc-8ce4-7a88351e3fc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-739034298-172.17.0.11-1597758942558:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33496,DS-dcb99c09-93f0-485b-a6c9-082363cfc9cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38158,DS-15f40ba9-5d5c-4587-a412-24581a6a9199,DISK], DatanodeInfoWithStorage[127.0.0.1:33856,DS-bc837189-6b75-408c-9627-c78f35c83bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:34670,DS-e971164f-16d3-415e-8a8a-cf723b7a4c53,DISK], DatanodeInfoWithStorage[127.0.0.1:45958,DS-01cea321-c247-4d46-8774-fa00baeb0c83,DISK], DatanodeInfoWithStorage[127.0.0.1:42496,DS-9032af16-764d-4cbd-80e7-d20c56e51d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:36520,DS-b4c732da-4b7f-4be3-94ff-ca10382bc4ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34239,DS-eefab1b1-ca1d-4bbc-8ce4-7a88351e3fc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1781671517-172.17.0.11-1597759057699:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38254,DS-d15d1832-3187-471c-887f-6495a3e2182d,DISK], DatanodeInfoWithStorage[127.0.0.1:46484,DS-12ad4134-9d7b-4d0d-aa71-5cacaa17abdc,DISK], DatanodeInfoWithStorage[127.0.0.1:37278,DS-46bbd558-a51f-4a39-b050-de2ffc8c108d,DISK], DatanodeInfoWithStorage[127.0.0.1:44225,DS-c8ef4531-379a-476c-bd20-eac86299b17f,DISK], DatanodeInfoWithStorage[127.0.0.1:39172,DS-d73741cb-2235-41cc-a030-3fb82cfe4145,DISK], DatanodeInfoWithStorage[127.0.0.1:38682,DS-5b1c0edb-5886-45d9-9923-598d0a3111cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43281,DS-38485a8c-225d-416c-bb8e-23b675759faa,DISK], DatanodeInfoWithStorage[127.0.0.1:39620,DS-f75fd35c-10ab-46c1-b3b4-c59e097f23e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1781671517-172.17.0.11-1597759057699:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38254,DS-d15d1832-3187-471c-887f-6495a3e2182d,DISK], DatanodeInfoWithStorage[127.0.0.1:46484,DS-12ad4134-9d7b-4d0d-aa71-5cacaa17abdc,DISK], DatanodeInfoWithStorage[127.0.0.1:37278,DS-46bbd558-a51f-4a39-b050-de2ffc8c108d,DISK], DatanodeInfoWithStorage[127.0.0.1:44225,DS-c8ef4531-379a-476c-bd20-eac86299b17f,DISK], DatanodeInfoWithStorage[127.0.0.1:39172,DS-d73741cb-2235-41cc-a030-3fb82cfe4145,DISK], DatanodeInfoWithStorage[127.0.0.1:38682,DS-5b1c0edb-5886-45d9-9923-598d0a3111cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43281,DS-38485a8c-225d-416c-bb8e-23b675759faa,DISK], DatanodeInfoWithStorage[127.0.0.1:39620,DS-f75fd35c-10ab-46c1-b3b4-c59e097f23e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-72267913-172.17.0.11-1597759534901:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33955,DS-2e593438-c5f3-4e0f-a64d-db9c3bda157b,DISK], DatanodeInfoWithStorage[127.0.0.1:42094,DS-0a052d87-ac23-4004-b662-5ae8479c7533,DISK], DatanodeInfoWithStorage[127.0.0.1:42166,DS-c98d4c46-2fe0-426e-b634-dfe732ba6a45,DISK], DatanodeInfoWithStorage[127.0.0.1:37076,DS-fa0009a2-0ac2-4bee-8f61-e330061d82a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45627,DS-f57a65be-1945-4ab0-980b-475c69e8ca16,DISK], DatanodeInfoWithStorage[127.0.0.1:41587,DS-6f0a213f-b26a-454f-9dbe-50e57eeddc2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43984,DS-00ce1731-78f5-4520-92b4-bd4fc39d13c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39936,DS-abbceecf-31a6-442d-9863-d11a15dd914c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-72267913-172.17.0.11-1597759534901:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33955,DS-2e593438-c5f3-4e0f-a64d-db9c3bda157b,DISK], DatanodeInfoWithStorage[127.0.0.1:42094,DS-0a052d87-ac23-4004-b662-5ae8479c7533,DISK], DatanodeInfoWithStorage[127.0.0.1:42166,DS-c98d4c46-2fe0-426e-b634-dfe732ba6a45,DISK], DatanodeInfoWithStorage[127.0.0.1:37076,DS-fa0009a2-0ac2-4bee-8f61-e330061d82a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45627,DS-f57a65be-1945-4ab0-980b-475c69e8ca16,DISK], DatanodeInfoWithStorage[127.0.0.1:41587,DS-6f0a213f-b26a-454f-9dbe-50e57eeddc2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43984,DS-00ce1731-78f5-4520-92b4-bd4fc39d13c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39936,DS-abbceecf-31a6-442d-9863-d11a15dd914c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-217540187-172.17.0.11-1597759729415:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33812,DS-14fcbc5a-afb4-4769-935f-34f213c0facf,DISK], DatanodeInfoWithStorage[127.0.0.1:37748,DS-f6cd8b88-5752-4e13-bfbf-5c3caae8fc6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39090,DS-5a78b2da-5f10-46f2-8562-ffc2ef46bcc6,DISK], DatanodeInfoWithStorage[127.0.0.1:41117,DS-8ea7d131-977d-4738-bd86-4f48d530a854,DISK], DatanodeInfoWithStorage[127.0.0.1:36991,DS-e2ddf93d-8f49-4aab-a776-76c503bb758b,DISK], DatanodeInfoWithStorage[127.0.0.1:45770,DS-28b616b8-8293-4468-b76a-590b95481890,DISK], DatanodeInfoWithStorage[127.0.0.1:45892,DS-17f14b60-ecbc-4fb9-9e73-a635c293fc2c,DISK], DatanodeInfoWithStorage[127.0.0.1:40498,DS-88e118c7-fc52-4345-88d1-682eeeed6979,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-217540187-172.17.0.11-1597759729415:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33812,DS-14fcbc5a-afb4-4769-935f-34f213c0facf,DISK], DatanodeInfoWithStorage[127.0.0.1:37748,DS-f6cd8b88-5752-4e13-bfbf-5c3caae8fc6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39090,DS-5a78b2da-5f10-46f2-8562-ffc2ef46bcc6,DISK], DatanodeInfoWithStorage[127.0.0.1:41117,DS-8ea7d131-977d-4738-bd86-4f48d530a854,DISK], DatanodeInfoWithStorage[127.0.0.1:36991,DS-e2ddf93d-8f49-4aab-a776-76c503bb758b,DISK], DatanodeInfoWithStorage[127.0.0.1:45770,DS-28b616b8-8293-4468-b76a-590b95481890,DISK], DatanodeInfoWithStorage[127.0.0.1:45892,DS-17f14b60-ecbc-4fb9-9e73-a635c293fc2c,DISK], DatanodeInfoWithStorage[127.0.0.1:40498,DS-88e118c7-fc52-4345-88d1-682eeeed6979,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1930812053-172.17.0.11-1597759811816:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44187,DS-9801b289-d4f0-45b3-8dbe-9213e8810032,DISK], DatanodeInfoWithStorage[127.0.0.1:36462,DS-227b6fa2-e2ee-4a4a-a5c4-18bcfad2fdf5,DISK], DatanodeInfoWithStorage[127.0.0.1:40080,DS-f0069af7-bb78-4a62-9c1e-b1fa11c38322,DISK], DatanodeInfoWithStorage[127.0.0.1:42054,DS-b79150aa-7988-403d-ae1b-0af0912c8523,DISK], DatanodeInfoWithStorage[127.0.0.1:39751,DS-6fe26081-62bc-4ea3-9c69-e40293edcc18,DISK], DatanodeInfoWithStorage[127.0.0.1:41963,DS-2339fae0-d2fb-41e9-90bb-b346455e90c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40332,DS-d5840328-89e6-4cc3-b093-9874d149c1ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43027,DS-6fab2a92-4935-499e-a873-fc9cdcf2b685,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1930812053-172.17.0.11-1597759811816:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44187,DS-9801b289-d4f0-45b3-8dbe-9213e8810032,DISK], DatanodeInfoWithStorage[127.0.0.1:36462,DS-227b6fa2-e2ee-4a4a-a5c4-18bcfad2fdf5,DISK], DatanodeInfoWithStorage[127.0.0.1:40080,DS-f0069af7-bb78-4a62-9c1e-b1fa11c38322,DISK], DatanodeInfoWithStorage[127.0.0.1:42054,DS-b79150aa-7988-403d-ae1b-0af0912c8523,DISK], DatanodeInfoWithStorage[127.0.0.1:39751,DS-6fe26081-62bc-4ea3-9c69-e40293edcc18,DISK], DatanodeInfoWithStorage[127.0.0.1:41963,DS-2339fae0-d2fb-41e9-90bb-b346455e90c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40332,DS-d5840328-89e6-4cc3-b093-9874d149c1ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43027,DS-6fab2a92-4935-499e-a873-fc9cdcf2b685,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1883749828-172.17.0.11-1597760042167:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41995,DS-e4c04ac6-c7e8-4367-9095-e11fd8ce1b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-791051c7-1ee9-4f58-b31f-8641a8115cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:35848,DS-e214aafd-ce6c-43a7-9a4a-e463b64fe813,DISK], DatanodeInfoWithStorage[127.0.0.1:40216,DS-d0831185-51f1-4bc3-9714-28dcf6252574,DISK], DatanodeInfoWithStorage[127.0.0.1:38086,DS-a1e3e3be-b054-4a84-9c16-587b7fc41328,DISK], DatanodeInfoWithStorage[127.0.0.1:45506,DS-e609af07-f9cf-4e25-9d4c-dab1c051a715,DISK], DatanodeInfoWithStorage[127.0.0.1:42132,DS-606fa07c-d52d-4ae2-95be-09b50e64fac8,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-cd42e610-71bc-45a4-ab2d-95f8dcca0d91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1883749828-172.17.0.11-1597760042167:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41995,DS-e4c04ac6-c7e8-4367-9095-e11fd8ce1b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-791051c7-1ee9-4f58-b31f-8641a8115cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:35848,DS-e214aafd-ce6c-43a7-9a4a-e463b64fe813,DISK], DatanodeInfoWithStorage[127.0.0.1:40216,DS-d0831185-51f1-4bc3-9714-28dcf6252574,DISK], DatanodeInfoWithStorage[127.0.0.1:38086,DS-a1e3e3be-b054-4a84-9c16-587b7fc41328,DISK], DatanodeInfoWithStorage[127.0.0.1:45506,DS-e609af07-f9cf-4e25-9d4c-dab1c051a715,DISK], DatanodeInfoWithStorage[127.0.0.1:42132,DS-606fa07c-d52d-4ae2-95be-09b50e64fac8,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-cd42e610-71bc-45a4-ab2d-95f8dcca0d91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-994616911-172.17.0.11-1597760140565:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42909,DS-a7043120-d50c-42fa-a4fa-6a2c87cb3523,DISK], DatanodeInfoWithStorage[127.0.0.1:41235,DS-8703f353-6ffd-4a35-a19f-2f3320eb7bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:35815,DS-5537dce6-8a83-4999-b946-e215a930c1be,DISK], DatanodeInfoWithStorage[127.0.0.1:41208,DS-f261c154-cd0a-48f8-abd7-ce7701d0c148,DISK], DatanodeInfoWithStorage[127.0.0.1:36840,DS-0dd820de-dbb8-45da-b5a0-07b10ab6b4a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41967,DS-e7deae26-c2ec-46a0-9e46-9122475930d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39866,DS-7405732e-630d-476e-ba59-6fe15857fbd6,DISK], DatanodeInfoWithStorage[127.0.0.1:45018,DS-b46d8131-3ffb-41ab-95c2-27f6408270e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-994616911-172.17.0.11-1597760140565:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42909,DS-a7043120-d50c-42fa-a4fa-6a2c87cb3523,DISK], DatanodeInfoWithStorage[127.0.0.1:41235,DS-8703f353-6ffd-4a35-a19f-2f3320eb7bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:35815,DS-5537dce6-8a83-4999-b946-e215a930c1be,DISK], DatanodeInfoWithStorage[127.0.0.1:41208,DS-f261c154-cd0a-48f8-abd7-ce7701d0c148,DISK], DatanodeInfoWithStorage[127.0.0.1:36840,DS-0dd820de-dbb8-45da-b5a0-07b10ab6b4a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41967,DS-e7deae26-c2ec-46a0-9e46-9122475930d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39866,DS-7405732e-630d-476e-ba59-6fe15857fbd6,DISK], DatanodeInfoWithStorage[127.0.0.1:45018,DS-b46d8131-3ffb-41ab-95c2-27f6408270e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1752351967-172.17.0.11-1597760238713:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33917,DS-c35d5a47-e080-4146-a43e-c59c1851bb86,DISK], DatanodeInfoWithStorage[127.0.0.1:40603,DS-c7656cf9-795c-4c08-af09-e2da680a07a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38019,DS-46aa2d6b-a7bf-430b-91d4-447a5e4df89b,DISK], DatanodeInfoWithStorage[127.0.0.1:42930,DS-5e9d4a33-a445-43ca-9446-03023f15de53,DISK], DatanodeInfoWithStorage[127.0.0.1:33486,DS-819282b2-4f6b-466d-a33a-8fcd32adb471,DISK], DatanodeInfoWithStorage[127.0.0.1:45947,DS-684e8d38-8ff6-4907-8502-8ea52081000b,DISK], DatanodeInfoWithStorage[127.0.0.1:39126,DS-a012b6dc-d68b-4fec-a071-cb129fbff4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36634,DS-7f5c0ab8-a52d-4d03-9390-8d897b12511e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1752351967-172.17.0.11-1597760238713:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33917,DS-c35d5a47-e080-4146-a43e-c59c1851bb86,DISK], DatanodeInfoWithStorage[127.0.0.1:40603,DS-c7656cf9-795c-4c08-af09-e2da680a07a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38019,DS-46aa2d6b-a7bf-430b-91d4-447a5e4df89b,DISK], DatanodeInfoWithStorage[127.0.0.1:42930,DS-5e9d4a33-a445-43ca-9446-03023f15de53,DISK], DatanodeInfoWithStorage[127.0.0.1:33486,DS-819282b2-4f6b-466d-a33a-8fcd32adb471,DISK], DatanodeInfoWithStorage[127.0.0.1:45947,DS-684e8d38-8ff6-4907-8502-8ea52081000b,DISK], DatanodeInfoWithStorage[127.0.0.1:39126,DS-a012b6dc-d68b-4fec-a071-cb129fbff4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36634,DS-7f5c0ab8-a52d-4d03-9390-8d897b12511e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1265539187-172.17.0.11-1597760782338:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41486,DS-e0ebd5b0-2941-4255-84fc-bb6b6a679349,DISK], DatanodeInfoWithStorage[127.0.0.1:44123,DS-2f819e7b-5295-4fe3-b86e-4df0e318f841,DISK], DatanodeInfoWithStorage[127.0.0.1:39045,DS-8fbe78b4-d473-4254-bc57-c13109ec6706,DISK], DatanodeInfoWithStorage[127.0.0.1:43932,DS-6c95c142-e106-4e1a-9f44-a1f4b725e70d,DISK], DatanodeInfoWithStorage[127.0.0.1:41259,DS-7d11ffd9-693f-4319-b3c8-6c93c22e49e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40074,DS-440032a8-cc5f-405d-bed7-365e6373aeb7,DISK], DatanodeInfoWithStorage[127.0.0.1:46202,DS-017232f2-02de-4e98-8889-033bdc88575a,DISK], DatanodeInfoWithStorage[127.0.0.1:44129,DS-2bf1c46f-835a-4dff-bcbd-d814fe3b6b92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1265539187-172.17.0.11-1597760782338:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41486,DS-e0ebd5b0-2941-4255-84fc-bb6b6a679349,DISK], DatanodeInfoWithStorage[127.0.0.1:44123,DS-2f819e7b-5295-4fe3-b86e-4df0e318f841,DISK], DatanodeInfoWithStorage[127.0.0.1:39045,DS-8fbe78b4-d473-4254-bc57-c13109ec6706,DISK], DatanodeInfoWithStorage[127.0.0.1:43932,DS-6c95c142-e106-4e1a-9f44-a1f4b725e70d,DISK], DatanodeInfoWithStorage[127.0.0.1:41259,DS-7d11ffd9-693f-4319-b3c8-6c93c22e49e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40074,DS-440032a8-cc5f-405d-bed7-365e6373aeb7,DISK], DatanodeInfoWithStorage[127.0.0.1:46202,DS-017232f2-02de-4e98-8889-033bdc88575a,DISK], DatanodeInfoWithStorage[127.0.0.1:44129,DS-2bf1c46f-835a-4dff-bcbd-d814fe3b6b92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2020011243-172.17.0.11-1597761079538:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33390,DS-5849d154-45d5-473a-b5e3-06eefff4a0e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33036,DS-f581c10f-9216-4747-acc3-6bfe96c8288a,DISK], DatanodeInfoWithStorage[127.0.0.1:42862,DS-d8700f77-3fed-47e2-a64c-37b1432105da,DISK], DatanodeInfoWithStorage[127.0.0.1:36615,DS-0ef47799-8dd1-4a05-9150-2ca3554cfe35,DISK], DatanodeInfoWithStorage[127.0.0.1:42943,DS-47d4cd49-cc74-4908-9609-960a6d857d91,DISK], DatanodeInfoWithStorage[127.0.0.1:36188,DS-00a6ce2c-7e64-4132-a3a2-f1af848b8504,DISK], DatanodeInfoWithStorage[127.0.0.1:44247,DS-dab1ce60-eef2-4526-96bb-3b45c9185337,DISK], DatanodeInfoWithStorage[127.0.0.1:45981,DS-a60baa25-fdfb-4b97-a021-72366fe8db0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2020011243-172.17.0.11-1597761079538:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33390,DS-5849d154-45d5-473a-b5e3-06eefff4a0e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33036,DS-f581c10f-9216-4747-acc3-6bfe96c8288a,DISK], DatanodeInfoWithStorage[127.0.0.1:42862,DS-d8700f77-3fed-47e2-a64c-37b1432105da,DISK], DatanodeInfoWithStorage[127.0.0.1:36615,DS-0ef47799-8dd1-4a05-9150-2ca3554cfe35,DISK], DatanodeInfoWithStorage[127.0.0.1:42943,DS-47d4cd49-cc74-4908-9609-960a6d857d91,DISK], DatanodeInfoWithStorage[127.0.0.1:36188,DS-00a6ce2c-7e64-4132-a3a2-f1af848b8504,DISK], DatanodeInfoWithStorage[127.0.0.1:44247,DS-dab1ce60-eef2-4526-96bb-3b45c9185337,DISK], DatanodeInfoWithStorage[127.0.0.1:45981,DS-a60baa25-fdfb-4b97-a021-72366fe8db0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-801417868-172.17.0.11-1597761113341:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35375,DS-389a95fb-57c6-4948-8c0c-5d1f2b05a072,DISK], DatanodeInfoWithStorage[127.0.0.1:43181,DS-e42c699f-6cf6-436e-875e-ad0301f2f4e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41715,DS-c6da5cd1-9deb-4437-acc8-ecd7c0333d19,DISK], DatanodeInfoWithStorage[127.0.0.1:37966,DS-e52c7b63-b4c5-4e12-8ebf-8648ffd4ba15,DISK], DatanodeInfoWithStorage[127.0.0.1:43622,DS-35b1436e-9e9e-4535-8123-6b72ed0bb4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38037,DS-00c77c37-d79c-4ec8-958f-e6cabf6cbc48,DISK], DatanodeInfoWithStorage[127.0.0.1:36756,DS-f1a78818-c95b-4cc8-b566-4fbf6c54af5c,DISK], DatanodeInfoWithStorage[127.0.0.1:41293,DS-7b992067-c894-47d4-9b23-dec5c65e9d77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-801417868-172.17.0.11-1597761113341:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35375,DS-389a95fb-57c6-4948-8c0c-5d1f2b05a072,DISK], DatanodeInfoWithStorage[127.0.0.1:43181,DS-e42c699f-6cf6-436e-875e-ad0301f2f4e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41715,DS-c6da5cd1-9deb-4437-acc8-ecd7c0333d19,DISK], DatanodeInfoWithStorage[127.0.0.1:37966,DS-e52c7b63-b4c5-4e12-8ebf-8648ffd4ba15,DISK], DatanodeInfoWithStorage[127.0.0.1:43622,DS-35b1436e-9e9e-4535-8123-6b72ed0bb4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38037,DS-00c77c37-d79c-4ec8-958f-e6cabf6cbc48,DISK], DatanodeInfoWithStorage[127.0.0.1:36756,DS-f1a78818-c95b-4cc8-b566-4fbf6c54af5c,DISK], DatanodeInfoWithStorage[127.0.0.1:41293,DS-7b992067-c894-47d4-9b23-dec5c65e9d77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1217875670-172.17.0.11-1597761129355:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46585,DS-0d3a63c8-0171-4867-9ef5-1a7cb2a67b77,DISK], DatanodeInfoWithStorage[127.0.0.1:34516,DS-f6ed5fd3-e6f4-4041-ac4e-c52bee768a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33982,DS-6c8d6b49-1d7a-469c-9a34-6261cd548360,DISK], DatanodeInfoWithStorage[127.0.0.1:38062,DS-66c85398-d7cd-467c-85ee-b30c6d729b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:40714,DS-2c963fca-9b77-48a6-b4d4-ad674257d6a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35250,DS-b307c775-ae1f-4948-ba09-d78a6c12abb0,DISK], DatanodeInfoWithStorage[127.0.0.1:33680,DS-12411ee6-2999-4f4f-b90e-399af5a38aff,DISK], DatanodeInfoWithStorage[127.0.0.1:45133,DS-4306a6b3-4954-4088-a990-b4a17790a1fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1217875670-172.17.0.11-1597761129355:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46585,DS-0d3a63c8-0171-4867-9ef5-1a7cb2a67b77,DISK], DatanodeInfoWithStorage[127.0.0.1:34516,DS-f6ed5fd3-e6f4-4041-ac4e-c52bee768a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33982,DS-6c8d6b49-1d7a-469c-9a34-6261cd548360,DISK], DatanodeInfoWithStorage[127.0.0.1:38062,DS-66c85398-d7cd-467c-85ee-b30c6d729b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:40714,DS-2c963fca-9b77-48a6-b4d4-ad674257d6a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35250,DS-b307c775-ae1f-4948-ba09-d78a6c12abb0,DISK], DatanodeInfoWithStorage[127.0.0.1:33680,DS-12411ee6-2999-4f4f-b90e-399af5a38aff,DISK], DatanodeInfoWithStorage[127.0.0.1:45133,DS-4306a6b3-4954-4088-a990-b4a17790a1fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 2486
